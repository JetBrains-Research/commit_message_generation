stage: test
dataset:
  dataset_root: raw_data/multilang_v1

  generation_with_history: true

  encoder_context_max_len: 500
  decoder_context_max_len: 200

  context_ratio: 0.05

  diff_tokenizer_name_or_path: raw_data/multilang_v1/diff_tokenizer.json
  msg_tokenizer_name_or_path: distilgpt2

  decoder_sep_tokens: "\n"

  test_dataloader_conf:
    batch_size: 1
    num_workers: 1

logger:
  name: distilgpt2_0.05
  project: commit_message_generation

model:
  encoder_decoder: false
  wandb_artifact_name: distilgpt2_preds
  wandb_artifact_type: multilang preds
  wandb_table_name: context_ratio_0.05

generation_kwargs:
  num_beams: 5
  repetition_penalty: 1.0
  length_penalty: 1.0
  no_repeat_ngram_size: 4
  min_length: 1
  max_length: 15

trainer:
  gpus: 1

artifact:
  name: saridormi/commit_message_generation/distilgpt2:v0
  artifact_path: last.ckpt
  local_path: artifacts/distilgpt2

ckpt_path: path/to/checkpoint