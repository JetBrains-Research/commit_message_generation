"new file \n benchmarks \ README . md \n + OkHttp Benchmarks \n + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n + \n + This module allows you to test the performance of HTTP clients . \n + \n + # # # Running \n + 1 . If you made modifications to ` com . squareup . okhttp . benchmarks . Benchmark ` run ` mvn compile ` . \n + 2 . Run ` mvn exec : exec ` to launch a new JVM , which will execute the benchmark . \n benchmarks \ pom . xml \n + < build > \n + < plugins > \n + < plugin > \n + < groupId > org . codehaus . mojo < / groupId > \n + < artifactId > exec - maven - plugin < / artifactId > \n + < executions > \n + < execution > \n + < goals > \n + < goal > java < / goal > \n + < / goals > \n + < / execution > \n + < / executions > \n + < configuration > \n + < executable > java < / executable > \n + < arguments > \n + < argument > - Xms512m < / argument > \n + < argument > - Xmx512m < / argument > \n + < commandlineArgs > - Xbootclasspath / p : $ { settings . localRepository } / org / mortbay / jetty / npn / npn - boot / $ { npn . version } / npn - boot - $ { npn . version } . jar < / commandlineArgs > \n + < argument > - classpath < / argument > \n + < classpath / > \n + < argument > com . squareup . okhttp . benchmarks . Benchmark < / argument > \n + < / arguments > \n + < / configuration > \n + < / plugin > \n + < / plugins > \n + < / build > \n",Add instructions to execute the benchmark with correct JVM parameters .,2
okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Http20Draft09 . java \n + out . flush ( ) ; \n + out . flush ( ) ; \n + out . flush ( ) ; \n + out . flush ( ) ; \n + out . flush ( ) ; \n okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Spdy3 . java \n - out . flush ( ) ; \n,Flush control frames ; don ' t flush user frames .,2
"okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ Platform . java \n - / * * When server , this is the protocol the client selected . * / \n + / * * The protocol the client selected . * / \n - return serverProtocols . get ( i ) ; \n + return selected = serverProtocols . get ( i ) ; \n - return protocols . get ( 0 ) ; \n + return selected = protocols . get ( 0 ) ; \n okhttp \ src \ test \ java \ com \ squareup \ okhttp \ internal \ http \ ExternalHttp2Example . java \n + import java . util . List ; \n + import static com . squareup . okhttp . internal . http . OkHeaders . SELECTED _ PROTOCOL ; \n + \n - System . out . println ( connection . getHeaderFields ( ) ) ; \n - \n + List < String > protocolValues = connection . getHeaderFields ( ) . get ( SELECTED _ PROTOCOL ) ; \n + / / If null , probably you didn ' t add jetty ' s npn jar to your boot classpath ! \n + if ( protocolValues ! = null & & ! protocolValues . isEmpty ( ) ) { \n + System . out . println ( "" PROTOCOL "" + protocolValues . get ( 0 ) ) ; \n + } \n okhttp \ src \ test \ java \ com \ squareup \ okhttp \ internal \ http \ ExternalSpdyExample . java \n + import java . util . List ; \n + import static com . squareup . okhttp . internal . http . OkHeaders . SELECTED _ PROTOCOL ; \n + \n + List < String > protocolValues = connection . getHeaderFields ( ) . get ( SELECTED _ PROTOCOL ) ; \n + / / If null , probably you didn ' t add jetty ' s npn jar to your boot classpath ! \n + if ( protocolValues ! = null & & ! protocolValues . isEmpty ( ) ) { \n + System . out . println ( "" PROTOCOL "" + protocolValues . get ( 0 ) ) ; \n + } \n",fix # 447 : Fix JettyNpnProvider . invoke ( ) to pick the right protocol,2
"okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ Platform . java \n + / * * This peer ' s supported protocols . * / \n + / * * Set when remote peer notifies NPN is unsupported . * / \n + / * * When server , this is the protocol the client selected . * / \n - return true ; \n + return true ; / / Client supports NPN . \n - this . unsupported = true ; \n + this . unsupported = true ; / / Remote peer doesn ' t support NPN . \n - return protocols ; \n - } else if ( methodName . equals ( "" selectProtocol "" ) \n + return protocols ; / / Server advertises these protocols . \n + } else if ( methodName . equals ( "" selectProtocol "" ) / / Called when client . \n - / / TODO : use OpenSSL ' s algorithm which uses both lists \n - List < ? > serverProtocols = ( List ) args [ 0 ] ; \n - this . selected = protocols . get ( 0 ) ; \n - return selected ; \n + List < String > serverProtocols = ( List ) args [ 0 ] ; \n + / / Pick the first protocol the server advertises and client knows . \n + for ( int i = 0 , size = serverProtocols . size ( ) ; i < size ; i + + ) { \n + if ( protocols . contains ( serverProtocols . get ( i ) ) ) { \n + return serverProtocols . get ( i ) ; \n + } \n + } \n + / / On no intersection , try client ' s first protocol . \n + return protocols . get ( 0 ) ; \n - this . selected = ( String ) args [ 0 ] ; \n + this . selected = ( String ) args [ 0 ] ; / / Client selected this protocol . \n",fix # 447 : Fix JettyNpnProvider . invoke ( ) to pick the right protocol,2
okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ ByteString . java \n - if ( ascii = = this . utf8 ) { \n - return true ; \n - } \n + if ( ascii = = this . utf8 ) { \n + return true ; \n + } \n okhttp - protocols \ src \ test \ java \ com \ squareup \ okhttp \ internal \ ByteStringTest . java \n + assertFalse ( ByteString . of ( ( byte ) 0x63 ) . equalsAscii ( null ) ) ; \n,Fix bug in ByteString . equalsAscii when param is null and ByteString not yet initialized .,2
"okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ HpackDraft05 . java \n - / / TODO : huffman encoding ! \n - / * * Evicts entries as needed . * / \n + / * * \n + * Called by the reader when the peer sent a new header table size setting . \n + * \n + * Evicts entries or clears the table as needed . \n + * / \n - if ( newMaxHeaderTableByteCount < headerTableByteCount ) { \n - evictToRecoverBytes ( headerTableByteCount - newMaxHeaderTableByteCount ) ; \n - } \n + if ( maxHeaderTableByteCount < headerTableByteCount ) { \n + if ( maxHeaderTableByteCount = = 0 ) { \n + clearHeaderTable ( ) ; \n + } else { \n + evictToRecoverBytes ( headerTableByteCount - maxHeaderTableByteCount ) ; \n + } \n + } \n + } \n + \n + private void clearHeaderTable ( ) { \n + clearReferenceSet ( ) ; \n + Arrays . fill ( headerTable , null ) ; \n + nextHeaderIndex = headerTable . length - 1 ; \n + headerCount = 0 ; \n + headerTableByteCount = 0 ; \n - clearReferenceSet ( ) ; \n - Arrays . fill ( headerTable , null ) ; \n - nextHeaderIndex = headerTable . length - 1 ; \n - headerCount = 0 ; \n - headerTableByteCount = 0 ; \n + clearHeaderTable ( ) ; \n",Clarify action taken when hpack reader applies new header table size .,2
"benchmarks \ pom . xml \n + < ! - - caliper needs to be updated to be compatible with guava 16 - - > \n + < dependency > \n + < groupId > com . google . guava < / groupId > \n + < artifactId > guava < / artifactId > \n + < version > 14 . 0 . 1 < / version > \n + < / dependency > \n okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ SpdyConnection . java \n + \n + / / Flow control was designed more for servers , or proxies than edge clients . \n + / / If we are a client , set the flow control window to 16MiB . This avoids \n + / / thrashing window updates every 64KiB , yet small enough to avoid blowing \n + / / up the heap . \n + if ( builder . client ) { \n + okHttpSettings . set ( Settings . INITIAL _ WINDOW _ SIZE , 0 , 16 * 1024 * 1024 ) ; \n + } \n + \n okhttp - protocols \ src \ test \ java \ com \ squareup \ okhttp \ internal \ spdy \ SpdyConnectionTest . java \n - @ Test public void remoteSendsTooMuchData ( ) throws Exception { \n + @ Test public void clientDoesNotLimitFlowControl ( ) throws Exception { \n - peer . acceptFrame ( ) ; / / RST _ STREAM \n - MockSpdyPeer . InFrame rstStream = peer . takeFrame ( ) ; \n - assertEquals ( TYPE _ RST _ STREAM , rstStream . type ) ; \n - assertEquals ( 1 , rstStream . streamId ) ; \n - assertEquals ( FLOW _ CONTROL _ ERROR , rstStream . errorCode ) ; \n + connection . okHttpSettings . set ( Settings . INITIAL _ WINDOW _ SIZE , 0 , INITIAL _ WINDOW _ SIZE ) ; \n","When a SPDY client , use a large flow - control window .",2
"okhttp - protocols \ src \ test \ java \ com \ squareup \ okhttp \ internal \ spdy \ MockSpdyPeer . java \n + / * * Count of frames sent or received . * / \n okhttp - protocols \ src \ test \ java \ com \ squareup \ okhttp \ internal \ spdy \ SpdyConnectionTest . java \n + peer . acceptFrame ( ) ; / / DATA \n - client . getOutputStream ( ) . write ( Util . EMPTY _ BYTE _ ARRAY ) ; \n - client . getOutputStream ( ) . flush ( ) ; \n - client . getOutputStream ( ) . close ( ) ; \n + OutputStream out = client . getOutputStream ( ) ; \n + out . write ( Util . EMPTY _ BYTE _ ARRAY ) ; \n + out . flush ( ) ; \n + out . close ( ) ; \n - MockSpdyPeer . InFrame synStream = peer . takeFrame ( ) ; \n - assertEquals ( TYPE _ HEADERS , synStream . type ) ; \n - assertEquals ( 2 , peer . frameCount ( ) ) ; \n + assertEquals ( TYPE _ HEADERS , peer . takeFrame ( ) . type ) ; \n + assertEquals ( TYPE _ DATA , peer . takeFrame ( ) . type ) ; \n + assertEquals ( 3 , peer . frameCount ( ) ) ; \n - peer . acceptFrame ( ) ; / / SYN _ STREAM \n + peer . acceptFrame ( ) ; / / SYN _ STREAM on stream 1 \n + peer . acceptFrame ( ) ; / / SYN _ STREAM on stream 2 \n",Fix flakey SpdyConnection tests that closed before reading all frames .,2
okhttp \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ HpackDraft05 . java \n - private static final int PREFIX _ 8 _ BITS = 0xff ; \n - \n - / * * \n - * Set bit positions indicate { @ code STATIC _ HEADER _ TABLE [ pos ] } should be \n - * emitted . \n - * / \n - / / Using a long since the static table < 64 entries . \n - long referencedStaticHeaders = 0L ; \n - referencedStaticHeaders = 0L ; \n - for ( int i = 0 ; i < STATIC _ HEADER _ TABLE . length ; + + i ) { \n - if ( ( ( referencedStaticHeaders > > i ) & 1L ) = = 1 ) { \n - emittedHeaders . add ( STATIC _ HEADER _ TABLE [ i ] ) ; \n - } \n - } \n + Header staticEntry = STATIC _ HEADER _ TABLE [ index - headerCount ] ; \n - referencedStaticHeaders | = ( 1L < < ( index - headerCount ) ) ; \n + emittedHeaders . add ( staticEntry ) ; \n - Header staticEntry = STATIC _ HEADER _ TABLE [ index - headerCount ] ; \n,Simplify HPACK E . 1 . 4 . Indexed Header Field from Static Table,2
"okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ internal \ spdy \ HpackDraft05Test . java \n + import java . util . Arrays ; \n + / * * \n + * Variable - length quantity special cases strings which are longer than 127 \n + * bytes . Values such as cookies can be 4KiB , and should be possible to send . \n + * \n + * < p > http : / / tools . ietf . org / html / draft - ietf - httpbis - header - compression - 05 # section - 4 . 1 . 2 \n + * / \n + @ Test public void largeHeaderValue ( ) throws IOException { \n + char [ ] value = new char [ 4096 ] ; \n + Arrays . fill ( value , ' ! ' ) ; \n + List < Header > headerBlock = headerEntries ( "" cookie "" , new String ( value ) ) ; \n + \n + hpackWriter . writeHeaders ( headerBlock ) ; \n + bytesIn . write ( bytesOut , bytesOut . size ( ) ) ; \n + hpackReader . readHeaders ( ) ; \n + hpackReader . emitReferenceSet ( ) ; \n + \n + assertEquals ( 0 , hpackReader . headerCount ) ; \n + \n + assertEquals ( headerBlock , hpackReader . getAndReset ( ) ) ; \n + } \n + \n okhttp \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ HpackDraft05 . java \n - int length = readInt ( firstByte , PREFIX _ 8 _ BITS ) ; \n - \n - boolean huffmanDecode = false ; \n - if ( ( length & 0x80 ) = = 0x80 ) { / / 1NNNNNNN \n - length & = ~ 0x80 ; \n - huffmanDecode = true ; \n - } \n + boolean huffmanDecode = ( firstByte & 0x80 ) = = 0x80 ; / / 1NNNNNNN \n + int length = readInt ( firstByte , PREFIX _ 7 _ BITS ) ; \n - writeInt ( data . size ( ) , PREFIX _ 8 _ BITS , 0 ) ; \n + writeInt ( data . size ( ) , PREFIX _ 7 _ BITS , 0 ) ; \n",fix # 596 : incorrect processing of variable - length quantity in http / 2 hpack .,2
"okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ CallTest . java \n + server . play ( ) ; \n + Request requestA = new Request . Builder ( ) . url ( server . getUrl ( "" / a "" ) ) . tag ( "" request A "" ) . build ( ) ; \n + final Call call = client . newCall ( requestA ) ; \n - client . cancel ( "" request A "" ) ; \n + call . cancel ( ) ; \n - server . play ( ) ; \n - Request requestA = new Request . Builder ( ) . url ( server . getUrl ( "" / a "" ) ) . tag ( "" request A "" ) . build ( ) ; \n - client . newCall ( requestA ) . enqueue ( callback ) ; \n + call . enqueue ( callback ) ; \n",fix # 789 : Reorder test to ensure call is canceled before its body is returned .,2
pom . xml \n - < npn . version > 8 . 1 . 2 . v20120308 < / npn . version > \n + < ! - - Targetted to jdk7u60 - b13 ; Oracle jdk7u55 - b13 . - - > \n + < npn . version > 1 . 1 . 7 . v20140316 < / npn . version > \n,Update NPN dependency to target jdk7u60 - b13 and Oracle jdk7u55 - b13 .,2
"okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ CallTest . java \n + import java . util . concurrent . CancellationException ; \n - assertNull ( call . execute ( ) ) ; \n + try { \n + call . execute ( ) ; \n + fail ( ) ; \n + } catch ( CancellationException e ) { \n + } \n okhttp \ src \ main \ java \ com \ squareup \ okhttp \ Call . java \n - * @ return null if the call was canceled . \n + * @ throws CancellationException if the call was canceled . \n - Response result = getResponse ( ) ; / / Since we don ' t cancel , this won ' t be null . \n + Response result = getResponse ( ) ; \n + if ( result = = null ) throw new CancellationException ( "" Cancelled "" ) ; \n",Throw CancellationException when blocking call cancelled as opposed to returning null .,2
"okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ internal \ spdy \ SpdyConnectionTest . java \n - MockSpdyPeer . InFrame windowUpdate = peer . takeFrame ( ) ; \n - assertEquals ( TYPE _ WINDOW _ UPDATE , windowUpdate . type ) ; \n - assertEquals ( 1 , windowUpdate . streamId ) ; \n - assertEquals ( windowUpdateThreshold , windowUpdate . windowSizeIncrement ) ; \n - windowUpdate = peer . takeFrame ( ) ; \n - assertEquals ( TYPE _ WINDOW _ UPDATE , windowUpdate . type ) ; \n - assertEquals ( 0 , windowUpdate . streamId ) ; / / connection window update \n - assertEquals ( windowUpdateThreshold , windowUpdate . windowSizeIncrement ) ; \n + List < Integer > windowUpdateStreamIds = new ArrayList ( 2 ) ; \n + for ( int j = 0 ; j < 2 ; j + + ) { \n + MockSpdyPeer . InFrame windowUpdate = peer . takeFrame ( ) ; \n + assertEquals ( TYPE _ WINDOW _ UPDATE , windowUpdate . type ) ; \n + windowUpdateStreamIds . add ( windowUpdate . streamId ) ; \n + assertEquals ( windowUpdateThreshold , windowUpdate . windowSizeIncrement ) ; \n + } \n + assertTrue ( windowUpdateStreamIds . contains ( 0 ) ) ; / / connection \n + assertTrue ( windowUpdateStreamIds . contains ( 1 ) ) ; / / stream \n",Attempt to deflake readSendsWindowUpdate by not enforcing order of window update frames .,2
okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ OkHttpClientTest . java \n + import java . net . CookieHandler ; \n + private static final ProxySelector DEFAULT _ PROXY _ SELECTOR = ProxySelector . getDefault ( ) ; \n + private static final CookieHandler DEFAULT _ COOKIE _ HANDLER = CookieManager . getDefault ( ) ; \n + private static final ResponseCache DEFAULT _ RESPONSE _ CACHE = ResponseCache . getDefault ( ) ; \n + private static final Authenticator DEFAULT _ AUTHENTICATOR = null ; / / No Authenticator . getDefault ( ) . \n + \n - ProxySelector . setDefault ( null ) ; \n - CookieManager . setDefault ( null ) ; \n - ResponseCache . setDefault ( null ) ; \n - Authenticator . setDefault ( null ) ; \n + ProxySelector . setDefault ( DEFAULT _ PROXY _ SELECTOR ) ; \n + CookieManager . setDefault ( DEFAULT _ COOKIE _ HANDLER ) ; \n + ResponseCache . setDefault ( DEFAULT _ RESPONSE _ CACHE ) ; \n + Authenticator . setDefault ( DEFAULT _ AUTHENTICATOR ) ; \n,fix # 800 : NPE on proxySelector . select,2
"okhttp - urlconnection \ src \ main \ java \ com \ squareup \ okhttp \ internal \ huc \ HttpURLConnectionImpl . java \n - httpEngine = newHttpEngine ( method , null , null , null ) ; \n + / / If the user set content length to zero , we know there will not be a request body . \n + RetryableSink requestBody = doOutput & & fixedContentLength = = 0 ? Util . emptySink ( ) : null ; \n + httpEngine = newHttpEngine ( method , null , requestBody , null ) ; \n","In HttpURLConnection , pay attention when fixedContentLength is set to zero .",2
"mockwebserver \ src \ main \ java \ com \ squareup \ okhttp \ mockwebserver \ MockWebServer . java \n - | | request . startsWith ( "" DELETE "" ) \n - & & ! request . startsWith ( "" PATCH "" ) ) { \n + & & ! request . startsWith ( "" PATCH "" ) \n + & & ! request . startsWith ( "" DELETE "" ) ) { / / Permitted as spec is ambiguous . \n okhttp - tests \ src \ test \ java \ com \ squareup \ okhttp \ internal \ http \ URLConnectionTest . java \n - server . enqueue ( new MockResponse ( ) . setBody ( new byte [ ] { - 2 , - 1 } ) ) ; \n + server . enqueue ( new MockResponse ( ) . setBody ( new byte [ ] { - 2 , - 1 } ) ) ; \n - assertNull ( connection . getContent ( new Class [ ] { getClass ( ) } ) ) ; \n + assertNull ( connection . getContent ( new Class [ ] { getClass ( ) } ) ) ; \n + / * * \n + * The RFC is unclear in this regard as it only specifies that this should \n + * invalidate the cache entry ( if any ) . \n + * / \n + @ Test public void bodyPermittedOnDelete ( ) throws Exception { \n + server . enqueue ( new MockResponse ( ) ) ; \n + server . play ( ) ; \n + \n + HttpURLConnection connection = client . open ( server . getUrl ( "" / "" ) ) ; \n + connection . setRequestMethod ( "" DELETE "" ) ; \n + connection . setDoOutput ( true ) ; \n + connection . getOutputStream ( ) . write ( "" BODY "" . getBytes ( UTF _ 8 ) ) ; \n + assertEquals ( 200 , connection . getResponseCode ( ) ) ; \n + \n + RecordedRequest request = server . takeRequest ( ) ; \n + assertEquals ( "" DELETE "" , request . getMethod ( ) ) ; \n + assertEquals ( "" BODY "" , new String ( request . getBody ( ) , UTF _ 8 ) ) ; \n + } \n + \n okhttp \ src \ main \ java \ com \ squareup \ okhttp \ internal \ http \ HttpMethod . java \n - | | method . equals ( "" PATCH "" ) ; \n + | | method . equals ( "" PATCH "" ) \n + | | method . equals ( "" DELETE "" ) ; / / Permitted as spec is ambiguous . \n","fix # 605 : Allow DELETE Request Body , Ensure Sane Behavior .",2
"mockwebserver \ src \ main \ java \ com \ squareup \ okhttp \ mockwebserver \ MockWebServer . java \n + import okio . OkBuffer ; \n - byte [ ] body = response . getBody ( ) ; \n - boolean closeStreamAfterHeaders = body . length > 0 | | ! response . getPushPromises ( ) . isEmpty ( ) ; \n + OkBuffer body = new OkBuffer ( ) ; \n + if ( response . getBody ( ) ! = null ) { \n + body . write ( response . getBody ( ) ) ; \n + } \n + boolean closeStreamAfterHeaders = body . size ( ) > 0 | | ! response . getPushPromises ( ) . isEmpty ( ) ; \n - if ( body . length > 0 ) { \n + if ( body . size ( ) > 0 ) { \n - sink . write ( body ) ; \n + if ( response . getThrottleBytesPerPeriod ( ) = = Integer . MAX _ VALUE ) { \n + sink . write ( body , body . size ( ) ) ; \n + sink . flush ( ) ; \n + } else { \n + while ( body . size ( ) > 0 ) { \n + long toWrite = Math . min ( body . size ( ) , response . getThrottleBytesPerPeriod ( ) ) ; \n + sink . write ( body , toWrite ) ; \n + sink . flush ( ) ; \n + try { \n + long delayMs = response . getThrottleUnit ( ) . toMillis ( response . getThrottlePeriod ( ) ) ; \n + if ( delayMs ! = 0 ) Thread . sleep ( delayMs ) ; \n + } catch ( InterruptedException e ) { \n + throw new AssertionError ( ) ; \n + } \n + } \n + } \n",Update MWS to pay attention to throttling for SPDY streams .,2
"okhttp \ src \ main \ java \ com \ squareup \ okhttp \ OkHttpClient . java \n - import com . squareup . okhttp . internal . bytes . ByteString ; \n + import com . squareup . okhttp . internal . bytes . ByteString ; \n + import java . security . GeneralSecurityException ; \n - import javax . net . ssl . HttpsURLConnection ; \n + import javax . net . ssl . SSLContext ; \n - * < p > If unset , the { @ link HttpsURLConnection # getDefaultSSLSocketFactory ( ) \n - * system - wide default } SSL socket factory will be used . \n + * < p > If unset , a lazily created SSL socket factory will be used . \n - * < p > If unset , the { @ link HttpsURLConnection # getDefaultHostnameVerifier ( ) \n + * < p > If unset , the \n + * { @ link javax . net . ssl . HttpsURLConnection # getDefaultHostnameVerifier ( ) \n - result . sslSocketFactory = HttpsURLConnection . getDefaultSSLSocketFactory ( ) ; \n + result . sslSocketFactory = getDefaultSSLSocketFactory ( ) ; \n + / * * \n + * Java and Android programs default to using a single global SSL context , \n + * accessible to HTTP clients as { @ link SSLSocketFactory # getDefault ( ) } . If we \n + * used the shared SSL context , when OkHttp enables NPN for its SPDY - related \n + * stuff , it would also enable NPN for other usages , which might crash them \n + * because NPN is enabled when it isn ' t expected to be . \n + * < p > \n + * This code avoids that by defaulting to an OkHttp created SSL context . The \n + * significant drawback of this approach is that apps that customize the \n + * global SSL context will lose these customizations . \n + * / \n + private synchronized SSLSocketFactory getDefaultSSLSocketFactory ( ) { \n + if ( sslSocketFactory = = null ) { \n + try { \n + SSLContext sslContext = SSLContext . getInstance ( "" TLS "" ) ; \n + sslContext . init ( null , null , null ) ; \n + sslSocketFactory = sslContext . getSocketFactory ( ) ; \n + } catch ( GeneralSecurityException e ) { \n + throw new AssertionError ( ) ; / / The system has no TLS . Just give up . \n + } \n + } \n + return sslSocketFactory ; \n + } \n + \n",fix # 184 : OkHttp no longer uses default ssl context .,2
okhttp \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Huffman . java \n - / / FIXME \n,Remove FIXME from Huffman as it is good enough .,2
"okcurl \ src \ main \ java \ com \ squareup \ okhttp \ curl \ Main . java \n + @ Option ( name = { "" - X "" , "" - - request "" } , description = "" Specify request command to use "" , \n + allowedValues = { "" GET "" , "" HEAD "" } ) \n + public String method = "" GET "" ; \n + \n + request . method ( method , null ) ; \n","Add - X to okcurl , permitting HEAD requests .",2
"modules \ mapper - extras \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ SearchAsYouTypeFieldMapper . java \n - \n - @ Override \n - public Query existsQuery ( QueryShardContext context ) { \n - throw new UnsupportedOperationException ( ) ; \n - } \n modules \ mapper - extras \ src \ test \ java \ org \ elasticsearch \ index \ mapper \ SearchAsYouTypeFieldMapperTests . java \n + import org . apache . lucene . queryparser . classic . ParseException ; \n + import org . apache . lucene . search . NormsFieldExistsQuery ; \n + import org . elasticsearch . index . search . QueryStringQueryParser ; \n + public void testNestedExistsQuery ( ) throws IOException , ParseException { \n + MapperService ms = createMapperService ( mapping ( b - > { \n + b . startObject ( "" foo "" ) ; \n + { \n + b . field ( "" type "" , "" object "" ) ; \n + b . startObject ( "" properties "" ) ; \n + { \n + b . startObject ( "" bar "" ) ; \n + { \n + b . field ( "" type "" , "" search _ as _ you _ type "" ) ; \n + } \n + b . endObject ( ) ; \n + } \n + b . endObject ( ) ; \n + } \n + b . endObject ( ) ; \n + } ) ) ; \n + QueryShardContext qsc = createQueryShardContext ( ms ) ; \n + QueryStringQueryParser parser = new QueryStringQueryParser ( qsc , "" f "" ) ; \n + Query q = parser . parse ( "" foo : * "" ) ; \n + assertEquals ( new ConstantScoreQuery ( new BooleanQuery . Builder ( ) \n + . add ( new NormsFieldExistsQuery ( "" foo . bar "" ) , BooleanClause . Occur . SHOULD ) \n + . add ( new NormsFieldExistsQuery ( "" foo . bar . _ 3gram "" ) , BooleanClause . Occur . SHOULD ) \n + . add ( new NormsFieldExistsQuery ( "" foo . bar . _ 2gram "" ) , BooleanClause . Occur . SHOULD ) \n + . add ( new TermQuery ( new Term ( "" _ field _ names "" , "" foo . bar . _ index _ prefix "" ) ) , BooleanClause . Occur . SHOULD ) \n + . build ( ) ) , q ) ; \n + } \n + \n test \ framework \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ MapperServiceTestCase . java \n + when ( queryShardContext . getObjectMapper ( anyString ( ) ) ) . thenAnswer ( \n + inv - > mapperService . getObjectMapper ( inv . getArguments ( ) [ 0 ] . toString ( ) ) ) ; \n",Fix UOE when building exists query for nested search - as - you - type field ( # 64630 ) \n PrefixFieldType can use the default existsQuery ( ) implementation . \n Fixes # 64609,10
"server \ src \ test \ java \ org \ elasticsearch \ index \ mapper \ ObjectMapperTests . java \n + import org . elasticsearch . common . bytes . BytesReference ; \n - @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 64607 "" ) \n - merge ( mapperService , reason , topMapping ( b - > b . field ( "" dynamic "" , "" strict "" ) ) ) ; \n - assertEquals ( Dynamic . STRICT , mapperService . documentMapper ( ) . root ( ) . dynamic ( ) ) ; \n + / / Call mapperService . merge directly here , because we may randomly pick PREFLIGHT _ CHECK \n + / / as a merge reason , in which case the mapper does not get updated in - place . \n + mapper = mapperService . merge ( \n + "" _ doc "" , \n + new CompressedXContent ( BytesReference . bytes ( topMapping ( b - > b . field ( "" dynamic "" , "" strict "" ) ) ) ) , \n + reason ) ; \n + assertEquals ( Dynamic . STRICT , mapper . root ( ) . dynamic ( ) ) ; \n","Fix bug in ObjectMapperTests . testMerge ( ) ( # 64626 ) \n This test checks that the dynamic propertly on ObjectMappers can \n be updated through a merge . We need to directly retrieve the merged \n result by calling MapperService # merge , because if we randomly \n pick MergeReason . MAPPING _ UPDATE _ PREFLIGHT as the merge \n reason then the mappers do not get updated in - place within the \n MapperService .",10
"server \ src \ main \ java \ org \ elasticsearch \ common \ xcontent \ support \ XContentMapValues . java \n - values . add ( value ) ; \n + if ( index = = pathElements . length ) { \n + values . add ( value ) ; \n + } \n server \ src \ test \ java \ org \ elasticsearch \ common \ xcontent \ support \ XContentMapValuesTests . java \n + import org . hamcrest . Matchers ; \n + import static org . hamcrest . Matchers . contains ; \n + assertThat ( XContentMapValues . extractRawValues ( "" test . dummy "" , map ) , contains ( "" value "" ) ) ; \n + public void testExtractRawValueLeafOnly ( ) throws IOException { \n + Map < String , Object > map ; \n + XContentBuilder builder = XContentFactory . jsonBuilder ( ) . startObject ( ) \n + . startArray ( "" path1 "" ) . value ( 9 ) . startObject ( ) . field ( "" path2 "" , "" value "" ) . endObject ( ) . value ( 7 ) . endArray ( ) \n + . endObject ( ) ; \n + try ( XContentParser parser = createParser ( JsonXContent . jsonXContent , Strings . toString ( builder ) ) ) { \n + map = parser . map ( ) ; \n + } \n + assertThat ( XContentMapValues . extractRawValues ( "" path1 "" , map ) , contains ( 9 , 7 ) ) ; \n + assertThat ( XContentMapValues . extractRawValues ( "" path1 . path2 "" , map ) , Matchers . contains ( "" value "" ) ) ; \n + } \n + \n","Fix array handling in XContentMapValues . extractRawValues ( ) ( # 65193 ) \n When an array is encountered while following a path through the map , \n we should only add array values if we ' re at the final path . So following the \n path ` foo . bar . baz ` shouldn ' t add concrete values that sit in the array \n at ` foo . bar ` .",10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ SourceValueFetcher . java \n - return List . of ( ) ; \n + continue ; \n server \ src \ test \ java \ org \ elasticsearch \ search \ fetch \ subphase \ FieldFetcherTests . java \n + . startObject ( "" yet _ another _ field "" ) \n + . field ( "" type "" , "" keyword "" ) \n + . field ( "" copy _ to "" , "" field "" ) \n + . endObject ( ) \n","SourceValueFetcher should check all possible source fields ( # 65375 ) \n This commit fixes a bug where SourceValueFetcher was returning \n an empty set of values if any of its source fields were empty ; instead , \n we skip over the empty value and continue collecting from all other \n source fields .",10
server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ DocumentMapper . java \n - import org . elasticsearch . common . text . Text ; \n - private final Text typeText ; \n - this . typeText = new Text ( this . type ) ; \n - public Text typeText ( ) { \n - return this . typeText ; \n - } \n - \n,Remove unused typeText field from DocumentMapper ( # 67646 ),10
"server \ src \ main \ java \ org \ elasticsearch \ index \ search \ MatchQuery . java \n - import java . util . Set ; \n - Set < String > fields = context . simpleMatchToIndexNames ( fieldName ) ; \n - if ( fields . contains ( fieldName ) ) { \n - assert fields . size ( ) = = 1 ; \n - / / this field is a concrete field or an alias so we use the \n - / / field type name directly \n - fieldName = fieldType . name ( ) ; \n - } \n - final Term term = new Term ( fieldName , value . toString ( ) ) ; \n + final Term term = new Term ( fieldType . name ( ) , value . toString ( ) ) ; \n - return parseInternal ( type , fieldName , builder , value ) ; \n + return parseInternal ( type , fieldType . name ( ) , builder , value ) ; \n","Simplify field name lookup in MatchQuery ( # 67973 ) \n MatchQuery needs to resolve field aliases before it builds its internal \n queries . It currently checks for aliases by calling simpleMatchToFieldNames \n but this is in fact unnecessary , as getFieldType ( ) will already return a \n field type pointing at the concrete fields to be searched , so we can use \n the name of this resolved field type instead .",10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ KeywordFieldMapper . java \n + NamedAnalyzer quoteAnalyzer = Lucene . KEYWORD _ ANALYZER ; \n + searchAnalyzer = quoteAnalyzer = normalizer ; \n - } else { \n - searchAnalyzer = normalizer ; \n - return new KeywordFieldType ( buildFullName ( contentPath ) , fieldType , normalizer , searchAnalyzer , this ) ; \n + return new KeywordFieldType ( buildFullName ( contentPath ) , fieldType , normalizer , searchAnalyzer , quoteAnalyzer , this ) ; \n - NamedAnalyzer normalizer , NamedAnalyzer searchAnalyzer , Builder builder ) { \n + NamedAnalyzer normalizer , NamedAnalyzer searchAnalyzer , NamedAnalyzer quoteAnalyzer , \n + Builder builder ) { \n - new TextSearchInfo ( fieldType , builder . similarity . getValue ( ) , searchAnalyzer , searchAnalyzer ) , \n + new TextSearchInfo ( fieldType , builder . similarity . getValue ( ) , searchAnalyzer , quoteAnalyzer ) , \n server \ src \ test \ java \ org \ elasticsearch \ index \ mapper \ KeywordFieldMapperTests . java \n + Analyzer q = ft . getTextSearchInfo ( ) . getSearchQuoteAnalyzer ( ) ; \n + assertTokenStreamContents ( q . tokenStream ( "" "" , "" Hello World "" ) , new String [ ] { "" hello world "" } ) ; \n server \ src \ test \ java \ org \ elasticsearch \ index \ query \ QueryStringQueryBuilderTests . java \n + . startObject ( "" ww _ keyword "" ) \n + . field ( "" type "" , "" keyword "" ) \n + . field ( "" split _ queries _ on _ whitespace "" , true ) \n + . endObject ( ) \n + \n + public void testWhitespaceKeywordQueries ( ) throws IOException { \n + String query = "" \ "" query with spaces \ "" "" ; \n + QueryStringQueryBuilder b = new QueryStringQueryBuilder ( query ) ; \n + b . field ( "" ww _ keyword "" ) ; \n + Query q = b . doToQuery ( createSearchExecutionContext ( ) ) ; \n + assertEquals ( new TermQuery ( new Term ( "" ww _ keyword "" , "" query with spaces "" ) ) , q ) ; \n + } \n","Correctly set search quote analyzer for keyword fields ( # 68315 ) \n Keyword fields with split _ queries _ on _ whitespace = true were also setting \n whitespace analyzers to be used for quoted queries . Instead , keyword \n fields should always set their searchQuoteAnalyzer to be the same as the \n index - time normalizer . \n Fixes # 68313",10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ KeywordFieldMapper . java \n - import java . util . Objects ; \n - = Parameter . stringParam ( "" normalizer "" , false , m - > toType ( m ) . normalizerName , "" default "" ) ; \n + = Parameter . stringParam ( "" normalizer "" , false , m - > toType ( m ) . normalizerName , null ) . acceptsNull ( ) ; \n - if ( Objects . equals ( normalizerName , "" default "" ) = = false ) { \n + if ( normalizerName ! = null ) { \n server \ src \ test \ java \ org \ elasticsearch \ index \ mapper \ KeywordFieldMapperTests . java \n - Map . entry ( "" other _ lowercase "" , new NamedAnalyzer ( "" other _ lowercase "" , AnalyzerScope . INDEX , new LowercaseNormalizer ( ) ) ) \n + Map . entry ( "" other _ lowercase "" , new NamedAnalyzer ( "" other _ lowercase "" , AnalyzerScope . INDEX , new LowercaseNormalizer ( ) ) ) , \n + Map . entry ( "" default "" , new NamedAnalyzer ( "" default "" , AnalyzerScope . INDEX , new LowercaseNormalizer ( ) ) ) \n + public void testNormalizerNamedDefault ( ) throws IOException { \n + / / you can call a normalizer ' default ' but it won ' t be applied unless you specifically ask for it \n + DocumentMapper mapper = createDocumentMapper ( mapping ( b - > { \n + b . startObject ( "" field "" ) . field ( "" type "" , "" keyword "" ) . endObject ( ) ; \n + b . startObject ( "" field2 "" ) . field ( "" type "" , "" keyword "" ) . field ( "" normalizer "" , "" default "" ) . endObject ( ) ; \n + } ) ) ; \n + ParsedDocument doc = mapper . parse ( source ( b - > { \n + b . field ( "" field "" , "" FOO "" ) ; \n + b . field ( "" field2 "" , "" FOO "" ) ; \n + } ) ) ; \n + assertEquals ( new BytesRef ( "" FOO "" ) , doc . rootDoc ( ) . getField ( "" field "" ) . binaryValue ( ) ) ; \n + assertEquals ( new BytesRef ( "" foo "" ) , doc . rootDoc ( ) . getField ( "" field2 "" ) . binaryValue ( ) ) ; \n + } \n + \n","Don ' t use ' default ' as the default name for keyword normalizers ( # 68354 ) \n We previously used ' null ' as a placeholder for unconfigured normalizers \n on keywords . With recent refactoring , this was changed to ' default ' , but \n this causes problems for configurations that already have a custom \n normalizer called ' default ' , which now gets ignored . This commit changes \n the mapper back to using ' null ' as a default , and adds a test that you can \n add a normalizer called ' default ' that will be applied correctly .",10
rest - api - spec \ src \ main \ resources \ rest - api - spec \ test \ search \ 330 _ fetch _ fields . yml \n - - - \n - skip : \n - version : ' - 8 . 0 . 0 ' \n - reason : ' Added in 8 . 0 - change on backport ' \n + version : ' - 7 . 11 . 99 ' \n + reason : ' Behaviour changed in 7 . 12 ' \n - do : \n,Adjust YAML test skip value after backport ( # 69105 ) \n Relates to # 68738,10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ SourceValueFetcher . java \n - queue . addAll ( ( List < ? > ) value ) ; \n + for ( Object o : ( List < ? > ) value ) { \n + if ( o ! = null ) { \n + queue . add ( o ) ; \n + } \n + } \n server \ src \ test \ java \ org \ elasticsearch \ search \ fetch \ subphase \ FieldFetcherTests . java \n + public void testNullValues ( ) throws IOException { \n + MapperService mapperService = createMapperService ( ) ; \n + XContentBuilder source = XContentFactory . jsonBuilder ( ) . startObject ( ) \n + . startObject ( "" object "" ) . field ( "" field "" , "" value "" ) . endObject ( ) \n + . nullField ( "" object . field "" ) \n + . endObject ( ) ; \n + \n + Map < String , DocumentField > fields = fetchFields ( mapperService , source , "" * "" ) ; \n + assertThat ( fields . size ( ) , equalTo ( 1 ) ) ; \n + \n + DocumentField field = fields . get ( "" object . field "" ) ; \n + assertThat ( field . getValues ( ) . size ( ) , equalTo ( 1 ) ) ; \n + assertThat ( field . getValues ( ) , containsInAnyOrder ( "" value "" ) ) ; \n + \n + source = XContentFactory . jsonBuilder ( ) . startObject ( ) \n + . array ( "" nullable _ long _ field "" , 1 , 2 , 3 , null , 5 ) \n + . endObject ( ) ; \n + fields = fetchFields ( mapperService , source , "" * "" ) ; \n + assertThat ( fields . size ( ) , equalTo ( 1 ) ) ; \n + \n + field = fields . get ( "" nullable _ long _ field "" ) ; \n + assertThat ( field . getValues ( ) . size ( ) , equalTo ( 5 ) ) ; \n + assertThat ( field . getValues ( ) , containsInAnyOrder ( 1L , 2L , 3L , 5L , 42L ) ) ; \n + } \n + \n + . startObject ( "" nullable _ long _ field "" ) . field ( "" type "" , "" long "" ) . field ( "" null _ value "" , 42 ) . endObject ( ) \n","Correctly handle nulls when fetching multiple values from source ( # 69062 ) \n If a field contains a single null value that would have been substituted via \n a mapper ' s configured null _ value , then we return this configured value in \n that mapper ' s value fetcher . However , we also need to handle the case where \n the field contains an array , one of which is null . \n Fixes # 68979",10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ MapperService . java \n - public ObjectMapper getObjectMapper ( String name ) { \n - return this . mapper = = null ? null : this . mapper . mappers ( ) . objectMappers ( ) . get ( name ) ; \n - } \n - \n server \ src \ test \ java \ org \ elasticsearch \ index \ search \ NestedHelperTests . java \n - return new NestedHelper ( mapperService : : getObjectMapper , field - > mapperService . fieldType ( field ) ! = null ) ; \n + return new NestedHelper ( mapperService . mappingLookup ( ) . objectMappers ( ) : : get , field - > mapperService . fieldType ( field ) ! = null ) ; \n test \ framework \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ MapperServiceTestCase . java \n - inv - > mapperService . getObjectMapper ( inv . getArguments ( ) [ 0 ] . toString ( ) ) ) ; \n + inv - > mapperService . mappingLookup ( ) . objectMappers ( ) . get ( inv . getArguments ( ) [ 0 ] . toString ( ) ) ) ; \n","Remove MapperService . getObjectMapper ( ) ( # 68403 ) \n This is still used in a couple of tests , and can be replaced by \n mapperService . mappingLookup ( ) . objectMappers ( ) . get ( )",10
"server \ src \ test \ java \ org \ elasticsearch \ cluster \ metadata \ DateMathExpressionResolverTests . java \n + @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / pull / 66914 "" ) \n",Mute DateMathExpressionResolverTests # testExpression _ MixedArray ( # 66919 ),10
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ ParseContext . java \n + import org . apache . lucene . document . Field ; \n + import org . apache . lucene . index . IndexableField ; \n + import org . apache . lucene . util . BytesRef ; \n + import org . elasticsearch . common . time . DateFormatter ; \n + import org . elasticsearch . common . xcontent . XContentParser ; \n + import org . elasticsearch . index . IndexSettings ; \n + import org . elasticsearch . index . analysis . IndexAnalyzers ; \n + import org . elasticsearch . plugins . MapperPlugin ; \n + \n - import org . apache . lucene . document . Field ; \n - import org . apache . lucene . index . IndexableField ; \n - import org . apache . lucene . util . BytesRef ; \n - import org . elasticsearch . common . time . DateFormatter ; \n - import org . elasticsearch . common . xcontent . XContentParser ; \n - import org . elasticsearch . index . IndexSettings ; \n - import org . elasticsearch . index . analysis . IndexAnalyzers ; \n - import org . elasticsearch . plugins . MapperPlugin ; \n - \n - import com . carrotsearch . hppc . ObjectObjectHashMap ; \n - import com . carrotsearch . hppc . ObjectObjectMap ; \n - \n - private ObjectObjectMap < Object , IndexableField > keyedFields ; \n + private Map < Object , IndexableField > keyedFields ; \n - keyedFields = new ObjectObjectHashMap < > ( ) ; \n + keyedFields = new HashMap < > ( ) ; \n","Don ' t use hppc ObjectObjectMap in ParseContext . Document ( # 67250 ) \n HashMap works perfectly well here , no need to rely on a third - party \n implementation .",10
x - pack \ plugin \ sql \ qa \ server \ src \ main \ resources \ date . csv - spec \n - / / AwaitsFix https : / / github . com / elastic / elasticsearch / issues / 65336 \n - currentDateFilter - Ignore \n - SELECT first _ name FROM test _ emp WHERE hire _ date > CURRENT _ DATE ( ) - INTERVAL 35 YEARS ORDER BY first _ name ASC LIMIT 10 ; \n + currentDateFilter \n + SELECT first _ name FROM test _ emp WHERE hire _ date > CURRENT _ DATE ( ) - INTERVAL 45 YEARS ORDER BY first _ name ASC LIMIT 10 ; \n - - - - - - - - - - - - - - - - - \n,Extend the interval date comparison ( # 65348 ),30
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 67414 "" / * place a PR link here when committing bwc changes * / \n",Switch the bwc _ tests _ enabled setting ( # 67421 ),30
"build . gradle \n - boolean bwc _ tests _ enabled = false \n - String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 67414 "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = true \n + String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n qa \ mixed - cluster \ src \ test \ java \ org \ elasticsearch \ backwards \ SearchWithMinCompatibleSearchNodeIT . java \n - boolean shouldSetCcsMinimizeRoundtrips = randomBoolean ( ) ; \n - Request request = new Request ( "" POST "" , index + "" / _ search ? min _ compatible _ shard _ node = "" + version + \n - ( shouldSetCcsMinimizeRoundtrips ? "" & ccs _ minimize _ roundtrips = true "" : "" "" ) ) ; \n + Request request = new Request ( "" POST "" , index + "" / _ search ? min _ compatible _ shard _ node = "" + version \n + + "" & ccs _ minimize _ roundtrips = true "" ) ; \n - if ( bwcVersion . before ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( bwcVersion . before ( Version . V _ 7 _ 12 _ 0 ) ) { \n server \ src \ main \ java \ org \ elasticsearch \ ElasticsearchException . java \n - Version . V _ 8 _ 0 _ 0 ) ; \n + Version . V _ 7 _ 12 _ 0 ) ; \n server \ src \ main \ java \ org \ elasticsearch \ action \ search \ SearchRequest . java \n - if ( in . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( in . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n - if ( out . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( out . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n",Enable bwc tests after elastic # 67414 merge ( # 67430 ),30
"x - pack \ plugin \ sql \ src \ main \ java \ org \ elasticsearch \ xpack \ sql \ plugin \ TransportSqlQueryAction . java \n + import org . elasticsearch . xpack . sql . expression . literal . geo . GeoShape ; \n + import org . elasticsearch . xpack . sql . expression . literal . interval . Interval ; \n - import org . elasticsearch . xpack . sql . session . SqlConfiguration ; \n + import org . elasticsearch . xpack . sql . session . SqlConfiguration ; \n + import static org . elasticsearch . xpack . sql . proto . Mode . CLI ; \n - rowView . forEachColumn ( row : : add ) ; \n + rowView . forEachColumn ( r - > row . add ( value ( r , request . mode ( ) ) ) ) ; \n + \n + @ SuppressWarnings ( "" rawtypes "" ) \n + private static Object value ( Object r , Mode mode ) { \n + / * \n + * Intervals and GeoShape instances need to be serialized ( as in StreamInput / Ouput serialization ) as Strings \n + * since SqlQueryResponse creation doesn ' t have access to GeoShape nor Interval classes to make the decision \n + * so , we flatten them as Strings before being serialized . \n + * CLI gets a special treatment see { @ link org . elasticsearch . xpack . sql . action . SqlQueryResponse # value ( ) } \n + * / \n + if ( r instanceof GeoShape ) { \n + r = r . toString ( ) ; \n + } else if ( r instanceof Interval ) { \n + if ( mode = = CLI ) { \n + r = r . toString ( ) ; \n + } else { \n + r = ( ( Interval ) r ) . value ( ) ; \n + } \n + } \n + \n + return r ; \n + } \n",SQL : Serialize Intervals and GeoShapes as Strings ( # 68440 ),30
x - pack \ plugin \ sql \ qa \ mixed - node \ src \ test \ java \ org \ elasticsearch \ xpack \ sql \ qa \ mixed _ node \ SqlSearchIT . java \n - / / TODO : remove the 8 . 0 . 0 version check after the code reaches 7 . x as well \n - isBwcNodeBeforeFieldsApiInQL = newVersion = = Version . V _ 8 _ 0 _ 0 | | bwcVersion . before ( FIELDS _ API _ QL _ INTRODUCTION ) ; \n + isBwcNodeBeforeFieldsApiInQL = bwcVersion . before ( FIELDS _ API _ QL _ INTRODUCTION ) ; \n,"Remove the version 8 . 0 . 0 "" restriction "" ( # 68822 )",30
"x - pack \ plugin \ eql \ qa \ mixed - node \ src \ test \ java \ org \ elasticsearch \ xpack \ eql \ qa \ mixed _ node \ EqlSearchIT . java \n - request . setJsonEntity ( "" { \ "" query \ "" : \ "" "" + event + "" where true \ "" } "" ) ; \n + request . setJsonEntity ( "" { \ "" query \ "" : \ "" "" + event + "" where true \ "" , \ "" size \ "" : 15 } "" ) ; \n + StringBuilder builder = new StringBuilder ( ) ; \n - StringBuilder builder = new StringBuilder ( ) ; \n + builder . append ( "" { \ "" index \ "" : { \ "" _ id \ "" : "" + i + "" } } \ n "" ) ; \n - builder . append ( "" } "" ) ; \n + builder . append ( "" } \ n "" ) ; \n - \n - Request request = new Request ( "" PUT "" , index + "" / _ doc / "" + i ) ; \n - request . setJsonEntity ( builder . toString ( ) ) ; \n - assertOK ( client ( ) . performRequest ( request ) ) ; \n + Request request = new Request ( "" PUT "" , index + "" / _ bulk ? refresh "" ) ; \n + request . setJsonEntity ( builder . toString ( ) ) ; \n + assertOK ( client ( ) . performRequest ( request ) ) ; \n","Add "" size "" to the eql request ( # 68898 )",30
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ AlertDialogWrapper . java \n - public Builder alwaysCallMultiChoiceCallback ( ) { \n - builder . alwaysCallMultiChoiceCallback ( ) ; \n - return this ; \n - } \n - \n + builder . alwaysCallMultiChoiceCallback ( ) ; \n,"Revert "" # 303 - Setting alwaysCallMultiChoiceCallback would alter behaviour of the AlertDialogWrapper . Builder for existing users . So just add option to enable it instead . "" \n This reverts commit 01844e560db9be36987cd054a3664e3e42286ed5 .",31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ AlertDialogWrapper . java \n - builder . alwaysCallMultiChoiceCallback ( ) ; \n,"Revert "" # 303 - Stock AlertDialog calls the multi choice item clicked callback every time one is clicked . Therefore , make the AlertDialogWrapper work in the same way . "" \n This reverts commit b9c350a15123fed0069c59c417f620e299f472ef .",31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ MaterialDialog . java \n + private int lastDialogHeight ; \n + \n,"Revert "" # 272 - Removed variable that was left in by mistake . "" \n This reverts commit 73473f6915f22e63901f1d3e427a0054cdf3b25c .",31
"library \ src \ main \ res \ values \ dimens . xml \n + < ! - - \n + Applied to content scrollview / listview and customview , the spec calls for 16dp between the \n + bottom of the content and the top of the button bar , we split this between the two for \n + ease of layouts and adjustments . Likewise the spec implies 16dp between the title and \n + content and we split that as well . \n + \n + Splitting makes it easier to have consistent padding against the dividers . \n + - - > \n","Revert "" # 272 - Removed comment , that is no longer the case . "" \n This reverts commit 60fae71c22cf10226a127daab0f0e90c698a1f75 .",31
"library \ src \ main \ java \ com \ afollestad \ materialdialogs \ MaterialDialog . java \n - import android . support . annotation . DimenRes ; \n - if ( builder . limitIconToDefaultSize | | \n - DialogUtils . resolveBoolean ( mBuilder . context , R . attr . md _ icon _ limit _ icon _ to _ default _ size ) ) { \n + boolean limitIconToDefaultSize = DialogUtils . resolveBoolean ( mBuilder . context , R . attr . md _ icon _ limit _ icon _ to _ default _ size ) ; \n + if ( builder . limitIconToDefaultSize | | limitIconToDefaultSize ) { \n - public Builder maxIconSizeRes ( @ DimenRes int maxIconSizeRes ) { \n - return maxIconSize ( ( int ) this . context . getResources ( ) . getDimension ( maxIconSizeRes ) ) ; \n - } \n - \n","Revert "" Added maxIconSizeRes ( ) "" \n This reverts commit 56e654fd0b92b3abf104d2bc55b3f8550f28afc9 .",31
"library \ src \ main \ res \ values \ dimens . xml \n - < ! - - \n - Applied to content scrollview / listview and customview , the spec calls for 16dp between the \n - bottom of the content and the top of the button bar , we split this between the two for \n - ease of layouts and adjustments . Likewise the spec implies 16dp between the title and \n - content and we split that as well . \n - \n - Splitting makes it easier to have consistent padding against the dividers . \n - - - > \n","# 272 - Removed comment , that is no longer the case .",31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ MaterialDialog . java \n - private int lastDialogHeight ; \n - \n,# 272 - Removed variable that was left in by mistake .,31
"library \ src \ main \ java \ com \ afollestad \ materialdialogs \ AlertDialogWrapper . java \n - * @ param listener notified when an item on the list is clicked . The dialog will not be dismissed when an item is clicked . It will only be dismissed if clicked on a button , if no buttons are supplied it ' s up to the user to dismiss the dialog . * @ return \n + * @ param listener notified when an item on the list is clicked . The dialog will not be dismissed when an item is clicked . It will only be dismissed if clicked on a button , if no buttons are supplied it ' s up to the user to dismiss the dialog . * @ return \n - * @ param listener notified when an item on the list is clicked . The dialog will not be dismissed when an item is clicked . It will only be dismissed if clicked on a button , if no buttons are supplied it ' s up to the user to dismiss the dialog . * @ return \n + * @ param listener notified when an item on the list is clicked . The dialog will not be dismissed when an item is clicked . It will only be dismissed if clicked on a button , if no buttons are supplied it ' s up to the user to dismiss the dialog . * @ return \n + builder . alwaysCallMultiChoiceCallback ( ) ; \n","# 303 - Stock AlertDialog calls the multi choice item clicked callback every time one is clicked . Therefore , make the AlertDialogWrapper work in the same way .",31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ AlertDialogWrapper . java \n + public Builder alwaysCallMultiChoiceCallback ( ) { \n + builder . alwaysCallMultiChoiceCallback ( ) ; \n + return this ; \n + } \n + \n - builder . alwaysCallMultiChoiceCallback ( ) ; \n,# 303 - Setting alwaysCallMultiChoiceCallback would alter behaviour of the AlertDialogWrapper . Builder for existing users . So just add option to enable it instead .,31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ MaterialDialog . java \n + private int lastDialogHeight ; \n + \n,"Revert "" # 272 - Removed variable that was left in by mistake . "" \n This reverts commit c94321b326d7cb396a16c54fbe8e246e4c1ca024 .",31
"library \ src \ main \ res \ values \ dimens . xml \n + < ! - - \n + Applied to content scrollview / listview and customview , the spec calls for 16dp between the \n + bottom of the content and the top of the button bar , we split this between the two for \n + ease of layouts and adjustments . Likewise the spec implies 16dp between the title and \n + content and we split that as well . \n + \n + Splitting makes it easier to have consistent padding against the dividers . \n + - - > \n","Revert "" # 272 - Removed comment , that is no longer the case . "" \n This reverts commit 687dedbd51cc90144f9ca11f6bcd2ce0348057d9 .",31
library \ src \ main \ java \ com \ afollestad \ materialdialogs \ MaterialDialog . java \n - title ! = null & & ( items = = null | | items . length = = 0 ) & & customView = = null ) { \n + title ! = null & & ( items = = null | | items . length = = 0 ) & & \n + customView = = null & & adapter = = null ) { \n,Put back adapter = = null check .,31
server \ src \ main \ java \ org \ elasticsearch \ common \ compress \ DeflateCompressor . java \n - inflater . reset ( ) ; \n + } finally { \n + inflater . reset ( ) ; \n - final Deflater deflater = deflaterRef . get ( ) ; \n - deflater . reset ( ) ; \n + final Deflater deflater = deflaterRef . get ( ) ; \n + } finally { \n + deflater . reset ( ) ; \n,"Reset Deflater / Inflater after Use in DeflateCompressor ( # 65617 ) \n We should reset after use , not before reuse . Otherwise we keep the input buffers \n on these objects around for a long time and they can grow to O ( MB ) .",44
"x - pack \ plugin \ ccr \ src \ main \ java \ org \ elasticsearch \ xpack \ ccr \ action \ ShardFollowTasksExecutor . java \n + import org . elasticsearch . common . util . concurrent . EsRejectedExecutionException ; \n - threadPool . schedule ( ( ) - > nodeOperation ( task , params , state ) , params . getMaxRetryDelay ( ) , Ccr . CCR _ THREAD _ POOL _ NAME ) ; \n + try { \n + threadPool . schedule ( ( ) - > nodeOperation ( task , params , state ) , params . getMaxRetryDelay ( ) , Ccr . CCR _ THREAD _ POOL _ NAME ) ; \n + } catch ( EsRejectedExecutionException rex ) { \n + rex . addSuppressed ( e ) ; \n + shardFollowNodeTask . onFatalFailure ( rex ) ; \n + } \n",Handle RejectedExecutionException in ShardFollowTasksExecutor ( # 65648 ) \n Follow - up to # 65415 . We can ' t have this exception bubble up in an exception \n handler any longer due to the new assertion so we must handle it here .,44
server \ src \ main \ java \ org \ elasticsearch \ cluster \ InternalClusterInfoService . java \n + if ( storeStats = = null ) { \n + continue ; \n + } \n,Fix NPE in ClusterInfoService ( # 65654 ) \n Store stats can be ` null ` if e . g . the shard was already closed \n when the stats where retrieved . Don ' t record those shards in the \n sizes map to fix an NPE in this case .,44
"x - pack \ plugin \ ilm \ src \ main \ java \ org \ elasticsearch \ xpack \ ilm \ history \ ILMHistoryStore . java \n - logger . trace ( "" indexed [ { } ] items into ILM history index [ { } ] , items : { } "" , items , \n + logger . trace ( "" indexed [ { } ] items into ILM history index [ { } ] "" , items , \n - . collect ( Collectors . joining ( "" , "" ) ) , \n - request . requests ( ) . stream ( ) \n - . map ( dwr - > ( ( IndexRequest ) dwr ) . sourceAsMap ( ) ) \n - . map ( Objects : : toString ) \n",Fix NPE in ILMHistoryStore TRACE Loggging ( # 65651 ) \n We can ' t access thebulk request items after the bulk request was executed \n because we ` null ` them out . This code would always throw an NPE therefore \n and now started to trip assertions due to # 65415 .,44
"server \ src \ main \ java \ org \ elasticsearch \ repositories \ RepositoryData . java \n + final Map < String , String > stringDeduplicator = new HashMap < > ( ) ; \n - metaGenerations = parser . mapStrings ( ) ; \n + metaGenerations = parser . map ( HashMap : : new , p - > stringDeduplicator . computeIfAbsent ( p . text ( ) , Function . identity ( ) ) ) ; \n",Deduplicate Index Meta Generations when Deserializing ( # 65619 ) \n These strings are quite long individually and will be repeated \n potentially up to the number of snapshots in the repository times . \n Since these make up more than half of the size of the repository metadata \n and are likely the same for all snapshots the savings from deduplicating them \n can make up for more than half the size of ` RepositoryData ` easily in most real - world \n cases .,44
"docs \ reference \ slm \ apis \ slm - put . asciidoc \n + + \n + NOTE : The maximum number of snapshots in a repository should not exceed ` 200 ` . This ensures that the snapshot repository metadata does not \n + grow to a size which might destabilize the master node . If the ` max _ count ` setting is not set , this limit should be enforced by configuring \n + other retention rules such that the repository size does not exceed ` 200 ` snapshots . \n",Document Recommended Maximum Repository Size in SLM Docs ( # 64485 ) \n Just adding a short note on reasonable sizing limits .,44
"test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ rest \ ESRestTestCase . java \n - } ) ; \n + } , 30L , TimeUnit . SECONDS ) ; \n",Increase Timeout for Waiting on Tasks in REST Tests ( # 64707 ) \n 10s is pretty tight here considering that some x - pack related tests \n might have a running create - index tasks in the backgroud after a test \n that require multiple CS updates and can randomly take a few seconds on \n slow IO etc . \n closes # 64580,44
"server \ src \ main \ java \ org \ elasticsearch \ cluster \ node \ DiscoveryNode . java \n - import org . elasticsearch . common . util . set . Sets ; \n + import java . util . Collection ; \n - import java . util . HashSet ; \n + import java . util . TreeSet ; \n - import java . util . function . Predicate ; \n - / / verify that no node roles are being provided as attributes \n - Predicate < Map < String , String > > predicate = ( attrs ) - > { \n - boolean success = true ; \n - for ( final DiscoveryNodeRole role : DiscoveryNode . roleMap . values ( ) ) { \n - success & = attrs . containsKey ( role . roleName ( ) ) = = false ; \n - assert success : role . roleName ( ) ; \n - } \n - return success ; \n - } ; \n - assert predicate . test ( attributes ) : attributes ; \n - this . roles = roles . stream ( ) . collect ( Sets . toUnmodifiableSortedSet ( ) ) ; \n + assert DiscoveryNode . roleMap . values ( ) . stream ( ) . noneMatch ( role - > attributes . containsKey ( role . roleName ( ) ) ) : \n + "" Node roles must not be provided as attributes but saw attributes "" + attributes ; \n + this . roles = Collections . unmodifiableSortedSet ( new TreeSet < > ( roles ) ) ; \n - final Set < DiscoveryNodeRole > roles = new HashSet < > ( rolesSize ) ; \n + final SortedSet < DiscoveryNodeRole > roles = new TreeSet < > ( ) ; \n - this . roles = roles . stream ( ) . collect ( Sets . toUnmodifiableSortedSet ( ) ) ; \n + this . roles = Collections . unmodifiableSortedSet ( roles ) ; \n - public static Set < DiscoveryNodeRole > getPossibleRoles ( ) { \n - return Set . copyOf ( roleMap . values ( ) ) ; \n + public static Collection < DiscoveryNodeRole > getPossibleRoles ( ) { \n + return roleMap . values ( ) ; \n",CleanUp / SpeedUp some Spots in DiscoveryNode ( # 63229 ) \n Random things found while looking for a fix for 62840 . . . \n * Build sorted sets directly \n * Don ' t instantiate ` Predicate ` needlessly with assertions off,44
"server \ src \ main \ java \ org \ elasticsearch \ cluster \ routing \ allocation \ FailedShard . java \n - + failure = = null ? "" null "" : ExceptionsHelper . stackTrace ( failure ) + "" ] "" ; \n + + ( failure = = null ? "" null "" : ExceptionsHelper . stackTrace ( failure ) ) + "" ] "" ; \n","Fix NPE in toString of FailedShard ( # 64770 ) \n The concatenation took precedence over the null check , leading to an NPE \n because ` null ` was passed to ` ExceptionsHelper . stackTrace ( failure ) ) ` .",44
libs \ core \ src \ main \ java \ org \ elasticsearch \ common \ util \ concurrent \ AbstractRefCounted . java \n - public final void decRef ( ) { \n + public final boolean decRef ( ) { \n + return true ; \n - \n + return false ; \n libs \ core \ src \ main \ java \ org \ elasticsearch \ common \ util \ concurrent \ RefCounted . java \n + * \n + * @ return returns { @ code true } if the ref count dropped to 0 as a result of calling this method \n - void decRef ( ) ; \n - \n + boolean decRef ( ) ; \n server \ src \ main \ java \ org \ elasticsearch \ index \ store \ Store . java \n - public final void decRef ( ) { \n - refCounter . decRef ( ) ; \n + public final boolean decRef ( ) { \n + return refCounter . decRef ( ) ; \n x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ index \ store \ cache \ CacheFile . java \n + assert evicted . get ( ) ; \n - refCounter . decRef ( ) ; \n + decrementRefCount ( ) ; \n - refCounter . decRef ( ) ; \n + decrementRefCount ( ) ; \n - refCounter . decRef ( ) ; \n + decrementRefCount ( ) ; \n + private void decrementRefCount ( ) { \n + final boolean released = refCounter . decRef ( ) ; \n + assert released = = false | | Files . notExists ( file ) ; \n + } \n + \n - refCounter . decRef ( ) ; \n + decrementRefCount ( ) ; \n - assert evicted . get ( ) = = false | | refCounter . refCount ( ) ! = 0 | | Files . notExists ( file ) ; \n,Fix # invariant Assertion in CacheFile ( # 64180 ) \n Fix # invariant Assertion in CacheFile \n closes # 64141,44
x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ index \ store \ cache \ CacheFile . java \n - assert released = = false | | Files . notExists ( file ) ; \n + assert released = = false | | ( evicted . get ( ) & & Files . notExists ( file ) ) ; \n,Enhance CacheFile # invariant Assertion ( # 64272 ) \n Follow up to # 64180 tightening the assertion further .,44
"x - pack \ plugin \ searchable - snapshots \ src \ test \ java \ org \ elasticsearch \ index \ store \ cache \ CachedBlobContainerIndexInputTests . java \n + import java . util . concurrent . atomic . AtomicInteger ; \n + / / busy assert that closing of all streams happened because they are closed on background fetcher threads \n + assertBusy ( \n + ( ) - > assertEquals ( \n + "" All open streams should have been closed "" , \n + 0 , \n + ( ( CountingBlobContainer ) blobContainer ) . openStreams . get ( ) \n + ) \n + ) ; \n + private final AtomicInteger openStreams = new AtomicInteger ( 0 ) ; \n + \n - private long bytesRead = 0L ; \n + this . container . openStreams . incrementAndGet ( ) ; \n - bytesRead + = 1L ; \n + this . container . totalBytes . increment ( ) ; \n - bytesRead + = len ; \n + this . container . totalBytes . add ( len ) ; \n - in . close ( ) ; \n - this . container . totalBytes . add ( bytesRead ) ; \n + super . close ( ) ; \n + this . container . openStreams . decrementAndGet ( ) ; \n",Fix CachedBlobContainerIndexInputTests ( # 64239 ) \n Closing the input stream happens on a separate thread \n now that the ` CacheFile ` is implemented in a lock - free \n fashion . \n Closes # 64215,44
"server \ src \ main \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepository . java \n - "" repository by a process other than this cluster or an issue with the repository ' s underlying "" + \n - "" storage . The repository has been disabled to prevent corrupting its contents . To re - enable it "" + \n + "" repository by a process other than this cluster or an issue with the repository ' s underlying storage . "" + \n + "" The repository has been disabled to prevent corrupting its contents . To re - enable it "" + \n",Fix Typo in Repository Exception Message ( # 64412 ) \n Missing space fixed .,44
"server \ src \ main \ java \ org \ elasticsearch \ index \ snapshots \ IndexShardSnapshotStatus . java \n + import org . elasticsearch . snapshots . AbortedSnapshotException ; \n + \n + } else if ( isAborted ( ) ) { \n + throw new AbortedSnapshotException ( ) ; \n + assert false : "" Should not try to move stage [ "" + stage . get ( ) + "" ] to [ STARTED ] "" ; \n + } else if ( isAborted ( ) ) { \n + throw new AbortedSnapshotException ( ) ; \n + assert false : "" Should not try to move stage [ "" + stage . get ( ) + "" ] to [ FINALIZE ] "" ; \n + assert false : "" Should not try to move stage [ "" + stage . get ( ) + "" ] to [ DONE ] "" ; \n",Fix Needless WARN Logging during Snapshot ABORT ( # 65077 ) \n The fact that we run into ` ABORTED ` when moving from ` INIT ` to ` STARTED ` is not a bug \n since during a snapshot abort we might have concurrently moved the status to ` ABORTED ` \n due to a cluster state update . In this case we should throw ` AbortedSnapshotException ` \n so that upstream logic will avoid logging a warning for this expected exception .,44
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ snapshots \ SharedClusterSnapshotRestoreIT . java \n - clusterAdmin ( ) . prepareCreateSnapshot ( repo , snapshot ) \n - . setWaitForCompletion ( false ) \n - . execute ( ) ; \n + final ActionFuture < CreateSnapshotResponse > snapshotFuture = startFullSnapshot ( repo , snapshot ) ; \n + awaitNumberOfSnapshotsInProgress ( 1 ) ; \n - SnapshotInfo snapshotInfo = getSnapshot ( repo , snapshot ) ; \n + SnapshotInfo snapshotInfo = snapshotFuture . get ( ) . getSnapshotInfo ( ) ; \n","Fix testSnapshotCanceledOnRemovedShard ( # 65096 ) \n This test failed a couple of times recently when master CS application was slow . \n This is explained by the data node blocking before the master even gets around to applying \n the cluster state that contains the started snapshot , leading to all the logic around \n failing the shard to run too early . \n Also we shouldn ' t just fire off the create snapshot response in the background without making \n sure that it actually returns ( otherwise we may leak the in - progress snapshot for a tiny window of time \n when it was physically written to the repo but not yet removed from the cluster state and fail the repo \n cleanup after the test ) .",44
"server \ src \ main \ java \ org \ elasticsearch \ indices \ recovery \ PeerRecoveryTargetService . java \n - CancellableThreads cancellableThreads ; \n - cancellableThreads = recoveryTarget . cancellableThreads ( ) ; \n - RecoveryResponseHandler responseHandler = new RecoveryResponseHandler ( startRequest , timer ) ; \n - \n - try { \n - cancellableThreads . executeIO ( ( ) - > \n - / / we still execute under cancelableThreads here to ensure we interrupt any blocking call to the network if any \n - / / on the underlying transport . It ' s unclear if we need this here at all after moving to async execution but \n - / / the issues that a missing call to this could cause are sneaky and hard to debug . If we don ' t need it on this \n - / / call we can potentially remove it altogether which we should do it in a major release only with enough \n - / / time to test . This shoudl be done for 7 . 0 if possible \n - transportService . sendRequest ( startRequest . sourceNode ( ) , actionName , requestToSend , responseHandler ) \n - ) ; \n - } catch ( CancellableThreads . ExecutionCancelledException e ) { \n - logger . trace ( "" recovery cancelled "" , e ) ; \n - } catch ( Exception e ) { \n - responseHandler . onException ( e ) ; \n - } \n + transportService . sendRequest ( startRequest . sourceNode ( ) , actionName , requestToSend , \n + new RecoveryResponseHandler ( startRequest , timer ) ) ; \n - onException ( e ) ; \n - } \n - \n - private void onException ( Exception e ) { \n",Remove Redundant use of Cancellable Threads in PeerRecoveryTargetService ( # 65119 ) \n The transport request sending call is completely async and never throws at this point \n ( all exceptions are caught and passed to the transport handler ) making this use of cancellable \n threads redundant .,44
"docs \ reference \ index - modules \ allocation \ filtering . asciidoc \n - - - - - - - - - - - - - - - - - - - - - - - - \n - If you specify multiple filters , all conditions must be satisfied for shards to \n - be relocated . For example , to move the ` test ` index to ` big ` nodes in ` rack1 ` , \n - you could specify : \n + If you specify multiple filters the following conditions must be satisfied \n + simultaneously by a node in order for shards to be relocated to it : \n + \n + * If any ` require ` type conditions are specified , all of them must be satisfied \n + * If any ` exclude ` type conditions are specified , none of them may be satisfied \n + * If any ` include ` type conditions are specified , at least one of them must be \n + satisfied \n + \n + For example , to move the ` test ` index to ` big ` nodes in ` rack1 ` , you could \n + specify : \n - - - - - - - - - - - - - - - - - - - - - - - - \n - "" index . routing . allocation . include . size "" : "" big "" , \n - "" index . routing . allocation . include . rack "" : "" rack1 "" \n + "" index . routing . allocation . require . size "" : "" big "" , \n + "" index . routing . allocation . require . rack "" : "" rack1 "" \n - - - - - - - - - - - - - - - - - - - - - - - - \n",Fix Allocation ` include ` Filter Docs ( # 65202 ) \n Fix documentation to match actual behavior of ` include ` type filters . \n Closes # 65113,44
"server \ src \ main \ java \ org \ elasticsearch \ index \ translog \ Checkpoint . java \n - / / no need to force metadata , file size stays the same and we did the full fsync \n - / / when we first created the file , so the directory entry doesn ' t change as well \n - channel . force ( false ) ; \n + / / fsync with metadata as we use this method when creating the file \n + channel . force ( true ) ; \n server \ src \ main \ java \ org \ elasticsearch \ index \ translog \ Translog . java \n - IOUtils . fsync ( checkpointFile , false ) ; \n server \ src \ main \ java \ org \ elasticsearch \ index \ translog \ TranslogReader . java \n - \n - IOUtils . fsync ( checkpointFile , false ) ; \n server \ src \ main \ java \ org \ elasticsearch \ index \ translog \ TruncateTranslogAction . java \n - / / fsync with metadata here to make sure . \n - IOUtils . fsync ( filename , false ) ; \n",Remove Redundant Translog Fsync ( # 65121 ) \n All spots using this method would do a fsync with metadata afterwards \n so we might as well do a full fsync right away and save a redundant \n fsync + re - opening the file .,44
x - pack \ plugin \ sql \ qa \ server \ src \ main \ resources \ date . csv - spec \n - currentDateFilter \n + / / AwaitsFix https : / / github . com / elastic / elasticsearch / issues / 65336 \n + currentDateFilter - Ignore \n,Mute JdbcCsvSpecIT # testCurrentDateFilter ( # 65339 ) \n Muting for https : / / github . com / elastic / elasticsearch / issues / 65336,44
"x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ index \ store \ cache \ CacheFile . java \n - final boolean added = listeners . add ( listener ) ; \n - assert added : "" listener already exists "" + listener ; \n - if ( listeners . size ( ) = = 1 ) { \n + if ( listeners . isEmpty ( ) ) { \n + final boolean added = listeners . add ( listener ) ; \n + assert added : "" listener already exists "" + listener ; \n","Fix Broken Error Handling in CacheFile # acquire ( # 65342 ) \n If we fail to create the ` FileChannelReference ` ( e . g . because the directory it should be created in \n was deleted in a test ) we have to remove the listener from the ` listeners ` set to not trip internal \n consistency assertions . \n Relates # 65302 ( does not fix it though , but reduces noise from failures by removing secondary \n tripped assertions after the test fails )",44
"docs \ plugins \ repository - s3 . asciidoc \n - ` 1GB ` , ` 10MB ` , ` 5KB ` , ` 500B ` . Defaults to ` 1GB ` . \n + ` 1TB ` , ` 1GB ` , ` 10MB ` . Defaults to the maximum size of a blob in the S3 which is ` 5TB ` . \n plugins \ repository - s3 \ src \ main \ java \ org \ elasticsearch \ repositories \ s3 \ S3Repository . java \n - * Big files can be broken down into chunks during snapshotting if needed . Defaults to 1g . \n + * Big files can be broken down into chunks during snapshotting if needed . Defaults to 5tb . \n - static final Setting < ByteSizeValue > CHUNK _ SIZE _ SETTING = Setting . byteSizeSetting ( "" chunk _ size "" , new ByteSizeValue ( 1 , ByteSizeUnit . GB ) , \n - new ByteSizeValue ( 5 , ByteSizeUnit . MB ) , new ByteSizeValue ( 5 , ByteSizeUnit . TB ) ) ; \n + static final Setting < ByteSizeValue > CHUNK _ SIZE _ SETTING = Setting . byteSizeSetting ( "" chunk _ size "" , MAX _ FILE _ SIZE _ USING _ MULTIPART , \n + new ByteSizeValue ( 5 , ByteSizeUnit . MB ) , MAX _ FILE _ SIZE _ USING _ MULTIPART ) ; \n",Default S3 Chunk Size to 5TB ( # 64980 ) \n Just like we did for Azure and GCS we should just go with the \n maximum possible chunk size in S3 as well .,44
"server \ src \ main \ java \ org \ elasticsearch \ snapshots \ SnapshotsService . java \n - endingSnapshots . remove ( snapshot ) ; \n - completeListenersIgnoringException ( \n - snapshotCompletionListeners . remove ( snapshot ) , Tuple . tuple ( newRepoData , snapshotInfo ) ) ; \n + completeListenersIgnoringException ( endAndGetListenersToResolve ( snapshot ) , Tuple . tuple ( newRepoData , snapshotInfo ) ) ; \n + / * * \n + * Remove a snapshot from { @ link # endingSnapshots } set and return its completion listeners that must be resolved . \n + * / \n + private List < ActionListener < Tuple < RepositoryData , SnapshotInfo > > > endAndGetListenersToResolve ( Snapshot snapshot ) { \n + / / get listeners before removing from the ending snapshots set to not trip assertion in # assertConsistentWithClusterState that \n + / / makes sure we don ' t have listeners for snapshots that aren ' t tracked in any internal state of this class \n + final List < ActionListener < Tuple < RepositoryData , SnapshotInfo > > > listenersToComplete = snapshotCompletionListeners . remove ( snapshot ) ; \n + endingSnapshots . remove ( snapshot ) ; \n + return listenersToComplete ; \n + } \n + \n - endingSnapshots . remove ( snapshot ) ; \n - failListenersIgnoringException ( snapshotCompletionListeners . remove ( snapshot ) , e ) ; \n + failListenersIgnoringException ( endAndGetListenersToResolve ( snapshot ) , e ) ; \n","Adjust Cleanup Order of Internal State in SnapshotsService ( # 66225 ) \n In the assertion mentioned in the new comment we first get the ` endingSnapshots ` \n and then check that we don ' t have a listener that isn ' t referred to by it so we need \n to remove from the listers map before removing from ` endingSnapshots ` to avoid rare , random \n assertion tripping here with concurrent repository operations .",44
"x - pack \ plugin \ searchable - snapshots \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ SearchableSnapshotsRelocationIntegTests . java \n + import java . util . stream . Collectors ; \n - final List < RecoveryState > recoveryStates = getActiveRestores ( restoredIndex ) ; \n + final List < RecoveryState > recoveryStates = getActiveRelocations ( restoredIndex ) ; \n - assertBusy ( ( ) - > assertSame ( RecoveryState . Stage . TRANSLOG , getActiveRestores ( restoredIndex ) . get ( 0 ) . getStage ( ) ) ) ; \n + assertBusy ( ( ) - > assertSame ( RecoveryState . Stage . TRANSLOG , getActiveRelocations ( restoredIndex ) . get ( 0 ) . getStage ( ) ) ) ; \n - assertBusy ( ( ) - > assertThat ( getActiveRestores ( restoredIndex ) , Matchers . empty ( ) ) ) ; \n + assertBusy ( ( ) - > assertThat ( getActiveRelocations ( restoredIndex ) , Matchers . empty ( ) ) ) ; \n - private static List < RecoveryState > getActiveRestores ( String restoredIndex ) { \n + private static List < RecoveryState > getActiveRelocations ( String restoredIndex ) { \n - . get ( restoredIndex ) ; \n + . get ( restoredIndex ) \n + . stream ( ) \n + . filter ( recoveryState - > recoveryState . getSourceNode ( ) ! = null ) \n + . collect ( Collectors . toList ( ) ) ; \n","Fix SearchableSnapshotRelocationIntegTests ( # 66234 ) \n We must only check he running relocations here . Otherwise , \n a cache that is randomly sized too small for the prewarm on the \n initial primary will show up as another recovery ( because it ' ll be stuck on ` FINALIZE ` ) \n and break the assertions around only having a single recovery running .",44
"x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ cache \ PersistentCache . java \n + import java . util . Collections ; \n + import java . util . Set ; \n - for ( CacheIndexWriter writer : writers ) { \n - writer . prepareCommit ( ) ; \n - } \n - void prepareCommit ( ) throws IOException { \n - logger . debug ( "" preparing commit "" ) ; \n - final Map < String , String > commitData = new HashMap < > ( 1 ) ; \n - commitData . put ( NODE _ VERSION _ COMMIT _ KEY , Integer . toString ( Version . CURRENT . id ) ) ; \n - indexWriter . setLiveCommitData ( commitData . entrySet ( ) ) ; \n - indexWriter . prepareCommit ( ) ; \n - } \n + private static final Set < Map . Entry < String , String > > LUCENE _ COMMIT _ DATA = Collections . singletonMap ( \n + NODE _ VERSION _ COMMIT _ KEY , \n + Integer . toString ( Version . CURRENT . id ) \n + ) . entrySet ( ) ; \n + indexWriter . setLiveCommitData ( LUCENE _ COMMIT _ DATA ) ; \n x - pack \ plugin \ searchable - snapshots \ src \ test \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ cache \ PersistentCacheTests . java \n - writer . prepareCommit ( ) ; \n - if ( frequently ( ) ) { \n - writer . commit ( ) ; \n - commit = true ; \n - } \n + writer . commit ( ) ; \n + commit = true ; \n","Remove Lucene Precommit from PersistentCache ( # 66324 ) \n There is nothing gained from doing the precommit step explicitly here . \n Also , we can just reuse the same map entries statically .",44
x - pack \ plugin \ searchable - snapshots \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ SearchableSnapshotsRelocationIntegTests . java \n - . filter ( recoveryState - > recoveryState . getSourceNode ( ) ! = null ) \n + / / filter for relocations that are not in stage FINALIZE ( they could end up in this stage without progress for good if the \n + / / target node does not have enough cache space available to hold the primary completely \n + . filter ( recoveryState - > recoveryState . getSourceNode ( ) ! = null & & recoveryState . getStage ( ) ! = RecoveryState . Stage . FINALIZE ) \n,Fix SearchableSnapshot Relocation Test ( # 66322 ) \n Follow - up to # 66234 to also handle the case where the relocation target can ' t hold \n the full shard in its cache and gets stuck in ` FINALIZE ` for the relocation recovery \n entry .,44
"x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ SearchableSnapshotAllocator . java \n + import org . elasticsearch . action . FailedNodeException ; \n + for ( FailedNodeException entry : nodesCacheFilesMetadata . failures ( ) ) { \n + final DiscoveryNode dataNode = nodes . get ( entry . nodeId ( ) ) ; \n + logger . warn ( "" Failed fetching cache size from datanode "" , entry ) ; \n + res . put ( dataNode , new NodeCacheFilesMetadata ( dataNode , 0L ) ) ; \n + } \n - } , ( ) - > client . admin ( ) . cluster ( ) . prepareReroute ( ) . execute ( REROUTE _ LISTENER ) ) \n + } , ( ) - > { \n + if ( asyncFetch . data ( ) ! = null ) { \n + client . admin ( ) . cluster ( ) . prepareReroute ( ) . execute ( REROUTE _ LISTENER ) ; \n + } \n + } ) \n","Improve Error Handling in SearchableSnapshotAllocator ( # 66402 ) \n 1 . We shouldn ' t be triggering reroutes when we don ' t have all \n the data yet \n 2 . We must handle failure responses , otherwise we never trigger the reroute .",44
"x - pack \ plugin \ searchable - snapshots \ src \ main \ java \ org \ elasticsearch \ xpack \ searchablesnapshots \ action \ cache \ TransportSearchableSnapshotCacheStoresAction . java \n - public static final String ACTION _ NAME = "" cluster : admin / xpack / searchable _ snapshots / cache / store "" ; \n + public static final String ACTION _ NAME = "" internal : admin / xpack / searchable _ snapshots / cache / store "" ; \n x - pack \ plugin \ security \ qa \ operator - privileges - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ security \ operator \ Constants . java \n - "" cluster : admin / xpack / searchable _ snapshots / cache / store "" , \n + "" internal : admin / xpack / searchable _ snapshots / cache / store "" , \n",Make Searchable Snapshot Cache Stats Action Internal ( # 67416 ) \n Make searchable snapshot cache stats action internal to not trip \n authorization checks .,44
"server \ src \ main \ java \ org \ elasticsearch \ snapshots \ SnapshotsService . java \n - final Metadata . Builder metaBuilder = Metadata . builder ( repo . getSnapshotGlobalMetadata ( entry . source ( ) ) ) ; \n + final Metadata existing = repo . getSnapshotGlobalMetadata ( entry . source ( ) ) ; \n + final Metadata . Builder metaBuilder = Metadata . builder ( existing ) ; \n + final Set < Index > existingIndices = new HashSet < > ( ) ; \n - metaBuilder . put ( repo . getSnapshotIndexMetaData ( repositoryData , entry . source ( ) , index ) , false ) ; \n + final IndexMetadata indexMetadata = repo . getSnapshotIndexMetaData ( repositoryData , entry . source ( ) , index ) ; \n + existingIndices . add ( indexMetadata . getIndex ( ) ) ; \n + metaBuilder . put ( indexMetadata , false ) ; \n + / / remove those data streams from metadata for which we are missing indices \n + Map < String , DataStream > dataStreamsToCopy = new HashMap < > ( ) ; \n + for ( Map . Entry < String , DataStream > dataStreamEntry : existing . dataStreams ( ) . entrySet ( ) ) { \n + if ( existingIndices . containsAll ( dataStreamEntry . getValue ( ) . getIndices ( ) ) ) { \n + dataStreamsToCopy . put ( dataStreamEntry . getKey ( ) , dataStreamEntry . getValue ( ) ) ; \n + } \n + } \n + metaBuilder . dataStreams ( dataStreamsToCopy ) ; \n x - pack \ plugin \ data - streams \ src \ internalClusterTest \ java \ org \ elasticsearch \ datastreams \ DataStreamsSnapshotsIT . java \n + \n + public void testCloneSnapshotThatIncludesDataStream ( ) throws Exception { \n + final String sourceSnapshotName = "" snap - source "" ; \n + final String indexWithoutDataStream = "" test - idx - no - ds "" ; \n + createIndexWithContent ( indexWithoutDataStream ) ; \n + assertSuccessful ( \n + client . admin ( ) \n + . cluster ( ) \n + . prepareCreateSnapshot ( REPO , sourceSnapshotName ) \n + . setWaitForCompletion ( true ) \n + . setIndices ( "" ds "" , indexWithoutDataStream ) \n + . setIncludeGlobalState ( false ) \n + . execute ( ) \n + ) ; \n + assertAcked ( \n + client ( ) . admin ( ) \n + . cluster ( ) \n + . prepareCloneSnapshot ( REPO , sourceSnapshotName , "" target - snapshot - 1 "" ) \n + . setIndices ( indexWithoutDataStream ) \n + . get ( ) \n + ) ; \n + \n + } \n",Fix NPE in Cloning Snapshots that Include Datastreams ( # 67642 ) \n Fix ` Metadata ` by removing datastreams that are missing \n indices from the snapshot .,44
"server \ src \ main \ java \ org \ elasticsearch \ repositories \ RepositoryData . java \n + / / ensure we drained the stream completely \n + XContentParserUtils . ensureExpectedToken ( null , parser . nextToken ( ) , parser ) ; \n + \n",Make RepositoryData Parsing Stricter ( # 67699 ) \n We should not accept random bytes after the actual repository \n data bytes . Not validating for this was causing e . g . ` { } abc ` to be parsed \n as empty repository data instead of throwing . \n closes # 67696,44
"server \ src \ main \ java \ org \ elasticsearch \ indices \ recovery \ RecoverySettings . java \n - / / choose 512KB - 16B to ensure that the resulting byte [ ] is not a humongous allocation in G1 . \n - public static final ByteSizeValue DEFAULT _ CHUNK _ SIZE = new ByteSizeValue ( 512 * 1024 - 16 , ByteSizeUnit . BYTES ) ; \n + public static final ByteSizeValue DEFAULT _ CHUNK _ SIZE = new ByteSizeValue ( 512 , ByteSizeUnit . KB ) ; \n",Remove Recovery Chunk Size G1GC Workaround ( # 67348 ) \n We don ' t allocate new arrays for each chunk any longer ( see # 65921 ) \n so this workaround can go away ( if anything it now makes allignment a little worse ) .,44
server \ src \ main \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepository . java \n + / / double check the generation since we checked it outside the mutex in the caller and it could have changed by a \n + / / concurrent initialization of the repo metadata and just load repository normally in case we already finished the \n + / / initialization \n + if ( metadata . generation ( ) ! = RepositoryData . UNKNOWN _ REPO _ GEN ) { \n + getRepositoryData ( listener ) ; \n + return ; \n + } \n,Fix Rare Race in Repository Generation Initialization ( # 67713 ) \n Fixes extreme corner case in repository initialization .,44
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ snapshots \ CorruptedBlobStoreRepositoryIT . java \n - @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 67696 "" ) \n server \ src \ main \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepository . java \n - if ( bestEffortConsistency ) { \n + / / Don ' t deduplicate repo data loading if we don ' t have strong consistency guarantees between the repo and the cluster state \n + / / Also , if we are not caching repository data ( for tests ) we assume that the contents of the repository data at a given \n + / / generation may change \n + if ( bestEffortConsistency | | cacheRepositoryData = = false ) { \n","Don ' t Deduplicate RepositoryData Loading When Caching is Disabled ( # 68126 ) \n Deduplicating repository data loading when deactivating caching ( which is effectively a test only \n setting that allows us to change the repo data at a given generation in place ) . \n In the corner case of the result deduplicator not removing the request from the ` requests ` map \n quickly enough when we update the repository data in place this causes the old version to be loaded still , \n thus breaking repo corruption tests . \n Instead of complicating the tests , this commit just turns off deduplication if caching is off since \n its always on in production anyway . \n Closes # 67696",44
"server \ src \ main \ java \ org \ elasticsearch \ indices \ recovery \ RecoverySourceHandler . java \n + final ReleasableBytesReference content = new ReleasableBytesReference ( request . content , request ) ; \n - request . md , request . position , ReleasableBytesReference . wrap ( request . content ) , request . lastChunk , \n - translogOps . getAsInt ( ) , ActionListener . runBefore ( listener , request : : close ) ) ; \n + request . md , request . position , content , request . lastChunk , \n + translogOps . getAsInt ( ) , ActionListener . runBefore ( listener , content : : close ) ) ; \n","Properly Retain Buffer in RecoverySourceHandler ( # 68283 ) \n This only really applies to tests using the ` AsyncRecoveryTarget ` as far as I can see but \n be that as it may , we should properly handle the ref count on the content here and only \n release the buffer once it ' s released and not tie the bytes to the listener lifecycle . \n Otherwise the bytes can ' t be retained by the multi file writer when dealing with out of order \n writes and get released to early . \n Closes # 68280",44
"server \ src \ main \ java \ org \ elasticsearch \ snapshots \ RestoreService . java \n - final Metadata metadata = metadataBuilder . build ( ) ; \n + final Metadata metadata = metadataBuilder . dataStreams ( dataStreams ) . build ( ) ; \n x - pack \ plugin \ data - streams \ src \ internalClusterTest \ java \ org \ elasticsearch \ datastreams \ DataStreamsSnapshotsIT . java \n + public void testPartialRestoreSnapshotThatIncludesDataStream ( ) { \n + final String snapshot = "" test - snapshot "" ; \n + final String indexWithoutDataStream = "" test - idx - no - ds "" ; \n + createIndexWithContent ( indexWithoutDataStream ) ; \n + createFullSnapshot ( REPO , snapshot ) ; \n + assertAcked ( client . admin ( ) . indices ( ) . prepareDelete ( indexWithoutDataStream ) ) ; \n + RestoreInfo restoreInfo = client . admin ( ) \n + . cluster ( ) \n + . prepareRestoreSnapshot ( REPO , snapshot ) \n + . setIndices ( indexWithoutDataStream ) \n + . setWaitForCompletion ( true ) \n + . setRestoreGlobalState ( randomBoolean ( ) ) \n + . get ( ) \n + . getRestoreInfo ( ) ; \n + assertThat ( restoreInfo . failedShards ( ) , is ( 0 ) ) ; \n + assertThat ( restoreInfo . successfulShards ( ) , is ( 1 ) ) ; \n + } \n + \n",Fix Partial Restore Of Snapshot Including DataStream ( # 68365 ) \n We have to filter the intermediate metadata here so that indices \n and datastreams in it are consistent . Otherwise we throw an NPE \n in production when restoring global state but not all datastreams \n and trip an assertion in tests . \n Closes # 68357,44
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ action \ bulk \ BulkProcessorClusterSettingsIT . java \n + import org . elasticsearch . action . support . AutoCreateIndex ; \n + import org . elasticsearch . index . IndexNotFoundException ; \n + import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAcked ; \n + import static org . hamcrest . Matchers . instanceOf ; \n + "" and [ action . auto _ create _ index ] is [ false ] "" ) ) ; \n + \n + public void testIndexWithDisabledAutoCreateIndex ( ) { \n + assertAcked ( client ( ) . admin ( ) . cluster ( ) . prepareUpdateSettings ( ) . setTransientSettings ( Settings . builder ( ) \n + . put ( AutoCreateIndex . AUTO _ CREATE _ INDEX _ SETTING . getKey ( ) , randomFrom ( "" - * "" , "" + . * "" ) ) . build ( ) ) . get ( ) ) ; \n + final BulkItemResponse itemResponse = \n + client ( ) . prepareBulk ( ) . add ( client ( ) . prepareIndex ( "" test - index "" ) . setSource ( "" foo "" , "" bar "" ) ) . get ( ) . getItems ( ) [ 0 ] ; \n + assertThat ( itemResponse . getFailure ( ) . getCause ( ) , instanceOf ( IndexNotFoundException . class ) ) ; \n + } \n server \ src \ main \ java \ org \ elasticsearch \ action \ bulk \ TransportBulkAction . java \n - indicesThatCannotBeCreated . put ( index , ( IndexNotFoundException ) e ) ; \n + indicesThatCannotBeCreated . put ( index , ( IndexNotFoundException ) cause ) ; \n",Fix Incorrect Cast in Bulk Handler Failure Handling ( # 69773 ) \n We need to cast the cause and not the original exception here .,44
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 68986 "" / * place a PR link here when committing bwc changes * / \n",Disable BwC Tests for # 68986 ( # 68987 ) \n Disabling BwC tests so that # 68986 can be merged .,44
"build . gradle \n - boolean bwc _ tests _ enabled = false \n - String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 68986 "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = true \n + String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n server \ src \ main \ java \ org \ elasticsearch \ snapshots \ SnapshotsService . java \n - public static final Version CLUSTER _ UUID _ IN _ REPO _ DATA _ VERSION = Version . V _ 8 _ 0 _ 0 ; \n + public static final Version CLUSTER _ UUID _ IN _ REPO _ DATA _ VERSION = Version . V _ 7 _ 12 _ 0 ; \n",Reenable BwC Tests ( # 69002 ) \n Reenabling BwC tests now that # 68986 was merged .,44
"server \ src \ main \ java \ org \ elasticsearch \ bootstrap \ JNAFalloc . java \n - * System specific wrappers of the fallocate system call via JNA for Linux and OSX . \n + * System specific wrappers of the fallocate system call via JNA for Linux . \n + * TODO : look into adding native implementations for falloc equivalents for other platforms ( Windows ) to improve performance . \n - if ( Constants . MAC _ OS _ X ) { \n - return OSX . INSTANCE ; \n - } else if ( Constants . LINUX ) { \n + if ( Constants . LINUX ) { \n - private static class OSX extends JNAFalloc { \n - \n - static final OSX INSTANCE = new OSX ( ) ; \n - \n - static { \n - Native . register ( "" c "" ) ; \n - } \n - \n - @ Override \n - public int fallocate ( int fd , long offset , long length ) { \n - return posix _ fallocate ( fd , offset , length ) ; \n - } \n - \n - private static native int posix _ fallocate ( int fd , long offset , long length ) ; \n - } \n - \n",Remove POSIX Allocate JNA Call ( # 68891 ) \n This doesn ' t work on any modern day OSX so it ' s just \n logging noise for users trying out this functionality on their \n laptops .,44
"server \ src \ main \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepository . java \n - threadPool . generic ( ) . execute ( ( ) - > doGetRepositoryData ( \n + threadPool . generic ( ) . execute ( ActionRunnable . wrap ( \n - } ) , onFailure ) ) ) ; \n + } ) , onFailure ) , this : : doGetRepositoryData ) ) ; \n - } catch ( IOException ioe ) { \n + } catch ( Exception e ) { \n - new RepositoryException ( metadata . name ( ) , "" Could not determine repository generation from root blobs "" , ioe ) ) ; \n + new RepositoryException ( metadata . name ( ) , "" Could not determine repository generation from root blobs "" , e ) ) ; \n",Fix Leaking Listener in BlobStoreRepository ( # 69110 ) \n We have no guarantees that implementations won ' t throw a non - IO exception in this spot \n so we have to make sure to resolve the listener on any exception to not leak it .,44
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepositoryCleanupIT . java \n + import org . elasticsearch . ExceptionsHelper ; \n + import org . elasticsearch . action . ActionFuture ; \n + import org . elasticsearch . action . admin . cluster . repositories . cleanup . CleanupRepositoryResponse ; \n + import java . io . IOException ; \n + import static org . hamcrest . Matchers . instanceOf ; \n - startBlockedCleanup ( "" test - repo "" ) ; \n + final ActionFuture < CleanupRepositoryResponse > cleanupFuture = startBlockedCleanup ( "" test - repo "" ) ; \n + \n + cleanupFuture . get ( ) ; \n - final String masterNode = startBlockedCleanup ( "" test - repo "" ) ; \n + final ActionFuture < CleanupRepositoryResponse > cleanupFuture = startBlockedCleanup ( "" test - repo "" ) ; \n - unblockNode ( "" test - repo "" , masterNode ) ; \n + unblockNode ( "" test - repo "" , internalCluster ( ) . getMasterName ( ) ) ; \n + \n + final ExecutionException e = expectThrows ( ExecutionException . class , cleanupFuture : : get ) ; \n + final Throwable ioe = ExceptionsHelper . unwrap ( e , IOException . class ) ; \n + assertThat ( ioe , instanceOf ( IOException . class ) ) ; \n + assertThat ( ioe . getMessage ( ) , is ( "" exception after block "" ) ) ; \n - private String startBlockedCleanup ( String repoName ) throws Exception { \n + private ActionFuture < CleanupRepositoryResponse > startBlockedCleanup ( String repoName ) throws Exception { \n - client ( ) . admin ( ) . cluster ( ) . prepareCleanupRepository ( repoName ) . execute ( ) ; \n + / / running from a non - master client because shutting down a master while a request to it is pending might result in the future \n + / / never completing \n + final ActionFuture < CleanupRepositoryResponse > future = \n + internalCluster ( ) . nonMasterClient ( ) . admin ( ) . cluster ( ) . prepareCleanupRepository ( repoName ) . execute ( ) ; \n - return masterNode ; \n + return future ; \n","Fix BlobStoreRepositoryCleanupIT Leaking Futures ( # 69446 ) \n The problem with # 69434 was that during master failover \n the listener might get retried after the new master has \n already dropped the cleanup from the cluster state which \n then conflicts with the cleanup executed by the repo consistency \n checks after each test . \n To prevent running into this conflict , just wait for the future \n to actually return . \n Closes # 69434",44
x - pack \ plugin \ repository - encrypted \ src \ internalClusterTest \ java \ org \ elasticsearch \ repositories \ encrypted \ EncryptedRepositorySecretIntegTests . java \n - ensureStableCluster ( 2 ) ; \n + ensureGreen ( ) ; \n - ensureStableCluster ( 2 ) ; \n + ensureGreen ( ) ; \n,"Correctly Wait for Cluster State Recovery in Encrypted Repo Test ( # 69547 ) \n Waiting for a connected cluster is not enough , we must wait for green to ensure \n that state recovery has happened which causes the repository to be created . \n Closes # 67834",44
"libs \ nio \ src \ main \ java \ org \ elasticsearch \ nio \ Page . java \n - public Page ( ByteBuffer byteBuffer ) { \n - this ( byteBuffer , ( ) - > { } ) ; \n - } \n - \n + assert refCountedCloseable . refCount ( ) > 0 ; \n + assert refCountedCloseable . refCount ( ) > 0 ; \n x - pack \ plugin \ security \ src \ main \ java \ org \ elasticsearch \ xpack \ security \ transport \ nio \ SSLOutboundBuffer . java \n + import org . elasticsearch . ElasticsearchException ; \n + import org . elasticsearch . ExceptionsHelper ; \n - import java . util . function . BiConsumer ; \n - return buildNetworkFlushOperation ( ( r , e ) - > { } ) ; \n - } \n - \n - FlushOperation buildNetworkFlushOperation ( BiConsumer < Void , Exception > listener ) { \n - IOUtils . closeWhileHandlingException ( pagesToClose ) ; \n - listener . accept ( r , e ) ; \n + try { \n + IOUtils . close ( pagesToClose ) ; \n + } catch ( Exception ex ) { \n + if ( e ! = null ) { \n + ex . addSuppressed ( e ) ; \n + } \n + assert false : ex ; \n + throw new ElasticsearchException ( ex ) ; \n + } \n - IOUtils . closeWhileHandlingException ( currentPage ) ; \n - IOUtils . closeWhileHandlingException ( pages ) ; \n + Exception closeException = null ; \n + try { \n + IOUtils . close ( currentPage ) ; \n + } catch ( Exception e ) { \n + closeException = e ; \n + } \n + currentPage = null ; \n + Page p ; \n + while ( ( p = pages . pollFirst ( ) ) ! = null ) { \n + try { \n + p . close ( ) ; \n + } catch ( Exception ex ) { \n + closeException = ExceptionsHelper . useOrSuppress ( closeException , ex ) ; \n + } \n + } \n + if ( closeException ! = null ) { \n + assert false : closeException ; \n + throw new ElasticsearchException ( closeException ) ; \n + } \n",Add Ref Count Assertion to Page ( # 69599 ) \n Added this assertion to have an easier time debugging \n work on # 67502 and found that we were accessing ` refcount = = 0 ` \n bytes in the ` SSLOutboundBuffer ` so I fixed that buffer to not \n keep references to released pages .,44
"server \ src \ main \ java \ org \ elasticsearch \ action \ admin \ cluster \ snapshots \ restore \ TransportRestoreSnapshotAction . java \n - / / Using the generic instead of the snapshot threadpool here as the snapshot threadpool might be blocked on long running tasks \n - / / which would block the request from getting an error response because of the ongoing task \n - RestoreSnapshotRequest : : new , indexNameExpressionResolver , RestoreSnapshotResponse : : new , ThreadPool . Names . GENERIC ) ; \n + RestoreSnapshotRequest : : new , indexNameExpressionResolver , RestoreSnapshotResponse : : new , ThreadPool . Names . SAME ) ; \n server \ src \ main \ java \ org \ elasticsearch \ node \ Node . java \n - metadataCreateIndexService , indexMetadataVerifier , clusterService . getClusterSettings ( ) , shardLimitValidator ) ; \n - \n + metadataCreateIndexService , indexMetadataVerifier , shardLimitValidator ) ; \n server \ src \ main \ java \ org \ elasticsearch \ snapshots \ RestoreService . java \n - import org . elasticsearch . action . StepListener ; \n + import org . elasticsearch . action . support . ThreadedActionListener ; \n + import org . elasticsearch . threadpool . ThreadPool ; \n - IndexMetadataVerifier indexMetadataVerifier , ClusterSettings clusterSettings , \n - ShardLimitValidator shardLimitValidator ) { \n + IndexMetadataVerifier indexMetadataVerifier , ShardLimitValidator shardLimitValidator ) { \n - final StepListener < RepositoryData > repositoryDataListener = new StepListener < > ( ) ; \n - repository . getRepositoryData ( repositoryDataListener ) ; \n - repositoryDataListener . whenComplete ( repositoryData - > { \n + ActionListener < RepositoryData > repoDataListener = ActionListener . wrap ( repositoryData - > { \n - String renamedIndex , boolean partial ) { \n + String renamedIndex , boolean partial ) { \n + / / fork handling the above listener to the generic pool since it loads various pieces of metadata from the repository over a \n + / / longer period of time \n + repository . getRepositoryData ( new ThreadedActionListener < > ( logger , clusterService . getClusterApplierService ( ) . threadPool ( ) , \n + ThreadPool . Names . GENERIC , repoDataListener , false ) ) ; \n server \ src \ test \ java \ org \ elasticsearch \ snapshots \ SnapshotResiliencyTests . java \n - clusterSettings , \n","Fix Threading in Snapshot Restore ( # 68390 ) \n Same as # 68023 but even less likely ( couldn ' t really find a quick way \n to write a test for it for that reason ) . \n Fix is the same , fork off to the generic pool for listener handling . \n Also , this allows removing the forking in the transport action since we don ' t do any long \n runnning work on the calling thread any longer in the restore method .",44
"server \ src \ main \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepository . java \n - "" set safe repository generation [ "" + metadata . name ( ) + "" ] [ "" + repoData + "" ] "" , \n + "" set initial safe repository generation [ "" + metadata . name ( ) + "" ] [ "" + repoData . getGenId ( ) + "" ] "" , \n + logger . trace ( "" [ { } ] initialized repository generation in cluster state to [ { } ] "" , \n + metadata . name ( ) , repoData . getGenId ( ) ) ; \n + logger . trace ( "" [ { } ] called listeners after initializing repository to generation [ { } ] "" \n + , metadata . name ( ) , repoData . getGenId ( ) ) ; \n + logger . trace ( "" [ { } ] writing repository data on top of expected generation [ { } ] "" , metadata . name ( ) , expectedGen ) ; \n + logger . trace ( "" [ { } ] successfully set pending repository generation to [ { } ] "" , metadata . name ( ) , newGen ) ; \n + logger . trace ( "" [ { } ] successfully set safe repository generation to [ { } ] "" , metadata . name ( ) , newGen ) ; \n server \ src \ test \ java \ org \ elasticsearch \ repositories \ blobstore \ BlobStoreRepositoryTests . java \n - public void testRepositoryDataConcurrentModificationNotAllowed ( ) { \n + public void testRepositoryDataConcurrentModificationNotAllowed ( ) throws Exception { \n - final PlainActionFuture < RepositoryData > future = PlainActionFuture . newFuture ( ) ; \n - repository . writeIndexGen ( repositoryData , startingGeneration , Version . CURRENT , Function . identity ( ) , future ) ; \n + writeIndexGen ( repository , repositoryData , startingGeneration ) ; \n","Fix BlobStoreRepositoryTest Leaking a RepoData Write Operation ( # 68441 ) \n We were leaking a repo data write operation here by never waiting on the future . \n Since we normally don ' t invoke ` writeIndexGen ` manually there are no safety measures \n around removing the repository from the cluster state and adding it back with a different \n path concurrently , leading to a collision between repo generation CS updates since all tests \n use the same repository name . \n Fix the missing write and added some trace logging that was very helpful in tracking this down . \n Closes # 68437",44
"x - pack \ plugin \ ccr \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ ccr \ CcrRepositoryIT . java \n - import org . elasticsearch . action . admin . indices . forcemerge . ForceMergeResponse ; \n + import static org . elasticsearch . test . hamcrest . ElasticsearchAssertions . assertAllSuccessful ; \n - final ForceMergeResponse forceMergeResponse = leaderClient ( ) . admin ( ) . indices ( ) . prepareForceMerge ( leaderIndex ) \n - . setMaxNumSegments ( 1 ) \n - . setFlush ( true ) \n - . get ( ) ; \n - assertThat ( forceMergeResponse . getSuccessfulShards ( ) , equalTo ( numberOfShards ) ) ; \n - assertThat ( forceMergeResponse . getFailedShards ( ) , equalTo ( 0 ) ) ; \n + assertAllSuccessful ( leaderClient ( ) . admin ( ) . indices ( ) . prepareForceMerge ( leaderIndex ) \n + . setMaxNumSegments ( 1 ) \n + . setFlush ( true ) \n + . get ( ) ) ; \n + refresh ( leaderClient ( ) , leaderIndex ) ; \n",Safer Refresh of Index Stats in CCR IT ( # 66830 ) \n We should only force merge after we know that an index is green and refresh after \n forcemerge to ensure we get the latest stats in any case . \n closes # 64167,44
"plugins \ repository - s3 \ src \ main \ java \ org \ elasticsearch \ repositories \ s3 \ S3ClientSettings . java \n + static { \n + / / Make sure repository plugin class is loaded before this class is used to trigger static initializer for that class which applies \n + / / necessary Jackson workaround \n + try { \n + Class . forName ( "" org . elasticsearch . repositories . s3 . S3RepositoryPlugin "" ) ; \n + } catch ( ClassNotFoundException e ) { \n + throw new AssertionError ( e ) ; \n + } \n + } \n + \n","Fix S3ClientSettings Class Loading ( # 66886 ) \n This is motivated by the inability to run \n ` org . elasticsearch . repositories . encrypted . EncryptedS3BlobStoreRepositoryIntegTests ` \n in isolation without this workaround . The way integration tests load classes \n otherwise leads to a load order which doesn ' t load the plugin class first , \n thus fails to apply the jackson workaround before further S3 classes are loaded \n but depend on our Jackson workaround .",44
"x - pack \ plugin \ ccr \ src \ main \ java \ org \ elasticsearch \ xpack \ ccr \ repository \ CcrRepository . java \n - ListenerTimeouts . wrapWithTimeout ( threadPool , ActionListener . delegateFailure ( listener , ( l , r ) - > { \n - r . incRef ( ) ; \n - threadPool . generic ( ) . execute ( new ActionRunnable < > ( listener ) { \n - @ Override \n - protected void doRun ( ) throws Exception { \n - writeFileChunk ( request . md , r ) ; \n - listener . onResponse ( null ) ; \n - } \n - \n - @ Override \n - public void onAfter ( ) { \n - r . decRef ( ) ; \n - } \n - } ) ; \n - } ) , ccrSettings . getRecoveryActionTimeout ( ) , ThreadPool . Names . GENERIC , GetCcrRestoreFileChunkAction . NAME ) ) ; \n + ListenerTimeouts . wrapWithTimeout ( threadPool , new ActionListener < > ( ) { \n + @ Override \n + public void onResponse ( \n + GetCcrRestoreFileChunkAction . GetCcrRestoreFileChunkResponse getCcrRestoreFileChunkResponse ) { \n + getCcrRestoreFileChunkResponse . incRef ( ) ; \n + threadPool . generic ( ) . execute ( new ActionRunnable < > ( listener ) { \n + @ Override \n + protected void doRun ( ) throws Exception { \n + writeFileChunk ( request . md , getCcrRestoreFileChunkResponse ) ; \n + listener . onResponse ( null ) ; \n + } \n + \n + @ Override \n + public void onAfter ( ) { \n + getCcrRestoreFileChunkResponse . decRef ( ) ; \n + } \n + } ) ; \n + } \n + \n + @ Override \n + public void onFailure ( Exception e ) { \n + threadPool . generic ( ) . execute ( ( ) - > { \n + try { \n + listener . onFailure ( e ) ; \n + } catch ( Exception ex ) { \n + e . addSuppressed ( ex ) ; \n + logger . warn ( ( ) - > \n + new ParameterizedMessage ( "" failed to execute failure callback for chunk request "" ) , e ) ; \n + } \n + } ) ; \n + } \n + } , ccrSettings . getRecoveryActionTimeout ( ) , ThreadPool . Names . GENERIC , GetCcrRestoreFileChunkAction . NAME ) ) ; \n","Fix AutoFollowIT Failures from Transport Thread Assertion ( # 67115 ) \n We have to execute the failure callback on the generic pool as well , \n not just the ` onResponse ` since it blocks on a transport request so I refactored \n the listener accordingly . \n closes # 67106",44
"x - pack \ plugin \ searchable - snapshots \ src \ test \ java \ org \ elasticsearch \ index \ store \ cache \ SparseFileTrackerTests . java \n - long end = randomLongBetween ( length , length + 1000L ) ; \n + long end = randomLongBetween ( length + 1 , length + 1000L ) ; \n",Fix off by one Mistake in SparseFileTrackerTests ( # 68739 ) \n This was caused by # 68709 which turned the edge case of a \n range with start > end into a tripped assertion .,44
"x - pack \ plugin \ searchable - snapshots \ src \ test \ java \ org \ elasticsearch \ index \ store \ cache \ SparseFileTrackerTests . java \n - } else { \n - e = expectThrows ( \n - IllegalArgumentException . class , \n - ( ) - > sparseFileTracker . waitForRange ( ByteRange . of ( start , end ) , ByteRange . of ( start - 1L , end ) , listener ) \n - ) ; \n - assertThat ( \n - "" listener range start must not be smaller than zero "" , \n - e . getMessage ( ) , \n - containsString ( "" invalid range to listen to "" ) \n - ) ; \n - assertThat ( invoked . get ( ) , is ( false ) ) ; \n",Remove Dead Test Code Branch in SparseFileTrackerTests ( # 68801 ) \n This branch makes no sense and was failing for the ` start = = 0 ` case \n now that we assert that byte ranges are well formed .,44
server \ src \ main \ java \ org \ elasticsearch \ common \ bytes \ BytesArray . java \n + if ( from = = 0 & & this . length = = length ) { \n + return this ; \n + } \n server \ src \ main \ java \ org \ elasticsearch \ common \ bytes \ CompositeBytesReference . java \n + if ( from = = 0 & & this . length = = length ) { \n + return this ; \n + } \n server \ src \ main \ java \ org \ elasticsearch \ common \ bytes \ PagedBytesReference . java \n + if ( from = = 0 & & this . length = = length ) { \n + return this ; \n + } \n server \ src \ main \ java \ org \ elasticsearch \ common \ bytes \ ReleasableBytesReference . java \n + if ( from = = 0 & & length ( ) = = length ) { \n + return retain ( ) ; \n + } \n,"Avoid NOOP BytesReference Slices ( # 67330 ) \n We have a number of spots where the logic creates these noop slices \n and we can save a few objects here . \n Also , this makes debugging memory leaks around the page recycling \n a little easier which is how I found these .",44
"server \ src \ main \ java \ org \ elasticsearch \ common \ util \ SingleObjectCache . java \n - private Lock refreshLock = new ReentrantLock ( ) ; \n + private final Lock refreshLock = new ReentrantLock ( ) ; \n server \ src \ main \ java \ org \ elasticsearch \ monitor \ fs \ FsService . java \n + import java . io . UncheckedIOException ; \n - fsInfoSupplier = new FsInfoCache ( refreshInterval , initialValue , probe ) : : getOrRefresh ; \n + final FsInfoCache fsInfoCache = new FsInfoCache ( refreshInterval , initialValue , probe ) ; \n + fsInfoSupplier = ( ) - > { \n + try { \n + return fsInfoCache . getOrRefresh ( ) ; \n + } catch ( UncheckedIOException e ) { \n + logger . debug ( "" unexpected exception reading filesystem info "" , e ) ; \n + return null ; \n + } \n + } ; \n - return stats ( probe , initialValue ) ; \n + try { \n + return probe . stats ( initialValue ) ; \n + } catch ( IOException e ) { \n + throw new UncheckedIOException ( e ) ; \n + } \n",Fix Tripping Assertion in IndicesServiceCloseTests ( # 67336 ) \n We can ' t use a method that returns ` null ` as ` refresh ` implementation \n because that trips an assertion in ` SingleObjectCache ` so we must bubble \n up an exception and handle it upstream instead .,44
scripts \ dumpapp \n - process = None \n + \n + # Connect to the process passed in via - p . If that is not supplied fallback \n + # the process defined in STETHO _ PROCESS . If neither are defined throw . \n + process = os . environ . get ( ' STETHO _ PROCESS ' ) \n + \n + \n scripts \ stetho _ open . py \n - ' Use - p < process > to select one ' ) \n + ' Use - p < process > or the environment variable STETHO _ PROCESS to ' + \n + ' select one ' ) \n,Add support for STETHO _ PROCESS environment variable to dumpapp \n We want to be able to support passing the process via environment \n variable . This gets around having to create arbitrary wrapper scripts \n that just pass ` - p myprocess $ @ ` to dumpapp .,54
release . gradle \n - archives jarRelease \n,Remove creation of jars in output \n This diff removes creating jars in the ` installArchives ` and \n ` uploadArchives ` steps of ` gradlew ` . This is needed as this step causes \n the default packaging to be ` jar ` rather than ` aar ` .,54
"CHANGELOG . md \n + # # Version 1 . 4 . 0 \n + _ 2016 _ 09 _ 07 \n + \n + * * * Add UI Accessibility Properties to Styles tab * * \n + Added support for accessibility inspection , which allows users to select \n + a View and see whether or not it will be focusable by an Accessibility \n + Service , why it will or won ' t be focusable , the text description sent to \n + Accessibility Services , and any AccessibilityActions that are currently \n + available on the View . \n + \n + * Fix # 367 : Fixed SqliteDatabaseDriver with custom DatabaseFilesProvider \n + * Fix # 424 : Make aar be the default packaging in maven \n + \n",Update CHANGELOG . md to 1 . 4 . 0,54
README . md \n - compile ' com . facebook . stetho : stetho : 1 . 3 . 1 ' \n + compile ' com . facebook . stetho : stetho : 1 . 4 . 0 ' \n - < version > 1 . 3 . 1 < / version > \n + < version > 1 . 4 . 0 < / version > \n - compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 3 . 1 ' \n + compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 4 . 0 ' \n - compile ' com . facebook . stetho : stetho - urlconnection : 1 . 3 . 1 ' \n + compile ' com . facebook . stetho : stetho - urlconnection : 1 . 4 . 0 ' \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 3 . 1 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 0 ' \n gradle . properties \n - VERSION _ NAME = 1 . 3 . 2 - SNAPSHOT \n + VERSION _ NAME = 1 . 4 . 0 \n stetho - js - rhino \ README . md \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 3 . 1 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 0 ' \n - < version > 1 . 3 . 1 < / version > \n + < version > 1 . 4 . 0 < / version > \n,Bump to version 1 . 4 . 0,54
gradle . properties \n - VERSION _ NAME = 1 . 4 . 0 \n + VERSION _ NAME = 1 . 4 . 1 - SNAPSHOT \n,Update to 1 . 4 . 1 - SNAPSHOT,54
gradle . properties \n - VERSION _ NAME = 1 . 4 . 1 \n + VERSION _ NAME = 1 . 4 . 2 - SNAPSHOT \n,Update to 1 . 4 . 2 - SNAPSHOT,54
"stetho \ src \ main \ java \ com \ facebook \ stetho \ json \ ObjectMapper . java \n - "" Field : "" + field . getName ( ) + "" type "" + setValue . getClass ( ) . getName ( ) , \n + "" Field : "" + field . getName ( ) + "" type "" + ( setValue ! = null ? \n + setValue . getClass ( ) . getName ( ) \n + : "" null "" ) , \n",Fix NPE in ObjectMapper \n Fix NPE when an IllegalArgumentException is thrown from ` field . set ` . \n fixes # 447,54
stetho \ src \ main \ java \ com \ facebook \ stetho \ inspector \ database \ DefaultDatabaseFilesProvider . java \n - for ( String filename : mContext . databaseList ( ) ) { \n - databaseFiles . add ( new File ( filename ) ) ; \n + for ( String databaseName : mContext . databaseList ( ) ) { \n + databaseFiles . add ( mContext . getDatabasePath ( databaseName ) ) ; \n,Have DefaultDatabaseProvider return filename \n The API for ` DatabaseProvider ` is to return ` List < File > ` however the \n current implementation of ` DefaultDatabaseProvider ` returns a ` File ` \n that does not exist . We were able to get around this before due to the \n fact that the file was only used to call ` File # getName ( ) ` . \n In # 390 this was changed and the actual ` File ` object was used to open \n the database . \n This fixes # 431,54
CHANGELOG . md \n + # # Version 1 . 4 . 1 \n + _ 2016 _ 09 _ 13 _ \n + \n + * Fix # 432 Have DefaultDatabaseProvider return filename \n + \n + v1 . 4 . 0 exposed a long standing bug relating to loading databases . \n + \n + \n,Update CHANGELOG . md to 1 . 4 . 1,54
README . md \n - compile ' com . facebook . stetho : stetho : 1 . 4 . 0 ' \n + compile ' com . facebook . stetho : stetho : 1 . 4 . 1 ' \n - < version > 1 . 4 . 0 < / version > \n + < version > 1 . 4 . 1 < / version > \n - compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 4 . 0 ' \n + compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 4 . 1 ' \n - compile ' com . facebook . stetho : stetho - urlconnection : 1 . 4 . 0 ' \n + compile ' com . facebook . stetho : stetho - urlconnection : 1 . 4 . 1 ' \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 0 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 1 ' \n gradle . properties \n - VERSION _ NAME = 1 . 4 . 1 - SNAPSHOT \n + VERSION _ NAME = 1 . 4 . 1 \n stetho - js - rhino \ README . md \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 0 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 1 ' \n - < version > 1 . 4 . 0 < / version > \n + < version > 1 . 4 . 1 < / version > \n,Bump to version 1 . 4 . 1,54
"CHANGELOG . md \n + # # Version 1 . 4 . 2 \n + _ 2016 _ 12 _ 14 _ \n + \n + * * * Bug fixes * * \n + Fixes a few bugs in the Elements tab . \n + \n + * Fix # 381 : Fixes NPE while rotating the device with retained fragments . \n + * Fix # 447 : Support Instant Run in android studio , by fixing ObjectMapper \n + * Fix # 456 : Support ANDROID _ ADB _ SERVER _ PORT \n + * Fix # 454 : Upgrade to OkHttp 3 . 4 . 2 \n + * Fix # 449 : Make sure only unfocusable children ' s descriptions are being \n + co - opted by parents \n + \n + \n",Update CHANGELOG . md to 1 . 4 . 2,54
README . md \n - compile ' com . facebook . stetho : stetho : 1 . 4 . 1 ' \n + compile ' com . facebook . stetho : stetho : 1 . 4 . 2 ' \n - < version > 1 . 4 . 1 < / version > \n + < version > 1 . 4 . 2 < / version > \n - compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 4 . 1 ' \n + compile ' com . facebook . stetho : stetho - okhttp3 : 1 . 4 . 2 ' \n - compile ' com . facebook . stetho : stetho - urlconnection : 1 . 4 . 1 ' \n + compile ' com . facebook . stetho : stetho - urlconnection : 1 . 4 . 2 ' \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 1 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 2 ' \n gradle . properties \n - VERSION _ NAME = 1 . 4 . 2 - SNAPSHOT \n + VERSION _ NAME = 1 . 4 . 2 \n stetho - js - rhino \ README . md \n - compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 1 ' \n + compile ' com . facebook . stetho : stetho - js - rhino : 1 . 4 . 2 ' \n - < version > 1 . 4 . 1 < / version > \n + < version > 1 . 4 . 2 < / version > \n,Bump to version 1 . 4 . 2,54
gradle . properties \n - VERSION _ NAME = 1 . 4 . 2 \n + VERSION _ NAME = 1 . 4 . 3 - SNAPSHOT \n,Update to 1 . 4 . 3 - SNAPSHOT ( # 473 ),54
vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ core \ FrescoController2 . java \n + FrescoDrawable2 createDrawable ( ) ; \n + \n vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ core \ impl \ FrescoController2Impl . java \n + @ Override \n + public FrescoDrawable2 createDrawable ( ) { \n + return new FrescoDrawable2Impl ( ) ; \n + } \n + \n vito \ litho \ src \ main \ java \ com \ facebook \ fresco \ vito \ litho \ FrescoVitoImage2Spec . java \n - import com . facebook . fresco . vito . core . impl . FrescoDrawable2Impl ; \n - return new FrescoDrawable2Impl ( ) ; \n + return FrescoVitoProvider . getController ( ) . createDrawable ( ) ; \n vito \ view \ src \ main \ java \ com \ facebook \ fresco \ vito \ view \ VitoViewImpl2 . java \n - import com . facebook . fresco . vito . core . impl . FrescoDrawable2Impl ; \n - final FrescoDrawable2 frescoDrawable = new FrescoDrawable2Impl ( ) ; \n + final FrescoDrawable2 frescoDrawable = mController . createDrawable ( ) ; \n,Create a ` createDrawable ` method in FrescoController \n Reviewed By : oprisnik \n Differential Revision : D20742065 \n fbshipit - source - id : 47ebf260c58f5fb8ce91ae2085034aef3a0ec944,54
vito \ litho \ src \ main \ java \ com \ facebook \ fresco \ vito \ litho \ FrescoVitoImageSpec . java \n - import com . facebook . fresco . vito . provider . DefaultFrescoContext ; \n + import com . facebook . fresco . vito . provider . impl . DefaultFrescoContext ; \n rename from vito \ provider \ src \ main \ java \ com \ facebook \ fresco \ vito \ provider \ DefaultFrescoContext . java \n rename to vito \ provider \ src \ main \ java \ com \ facebook \ fresco \ vito \ provider \ impl \ DefaultFrescoContext . java \n - package com . facebook . fresco . vito . provider ; \n + package com . facebook . fresco . vito . provider . impl ; \n rename from vito \ provider \ src \ main \ java \ com \ facebook \ fresco \ vito \ provider \ DefaultFrescoVitoProvider . java \n rename to vito \ provider \ src \ main \ java \ com \ facebook \ fresco \ vito \ provider \ impl \ DefaultFrescoVitoProvider . java \n - package com . facebook . fresco . vito . provider ; \n + package com . facebook . fresco . vito . provider . impl ; \n + import com . facebook . fresco . vito . provider . FrescoVitoProvider ; \n,Create provider : interfaces \n Reviewed By : oprisnik \n Differential Revision : D20742067 \n fbshipit - source - id : de47c3f40961a244d4d3ad09f1c328f741629755,54
vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ core \ impl \ FrescoControllerImpl . java \n - import com . facebook . fresco . vito . listener . AutoPlayImageListener ; \n - import com . facebook . fresco . vito . listener . ForwardingImageListener ; \n + import com . facebook . fresco . vito . listener . impl . AutoPlayImageListener ; \n + import com . facebook . fresco . vito . listener . impl . ForwardingImageListener ; \n rename from vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ listener \ AutoPlayImageListener . java \n rename to vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ listener \ impl \ AutoPlayImageListener . java \n - package com . facebook . fresco . vito . listener ; \n + package com . facebook . fresco . vito . listener . impl ; \n + import com . facebook . fresco . vito . listener . BaseImageListener ; \n rename from vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ listener \ ForwardingImageListener . java \n rename to vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ listener \ impl \ ForwardingImageListener . java \n - package com . facebook . fresco . vito . listener ; \n + package com . facebook . fresco . vito . listener . impl ; \n + import com . facebook . fresco . vito . listener . ImageListener ; \n,Create vito / listener : interface \n Reviewed By : oprisnik \n Differential Revision : D20633944 \n fbshipit - source - id : fdd03987c699e867fd4299027eee49916855799f,54
"apex \ statsd \ framework \ Android . bp \n + "" / / packages / modules / StatsD / apex : _ _ subpackages _ _ "" , \n - impl _ library _ visibility : [ "" / / frameworks / base / apex / statsd / framework / test : _ _ subpackages _ _ "" ] , \n + impl _ library _ visibility : [ \n + "" / / frameworks / base / apex / statsd / framework / test : _ _ subpackages _ _ "" , \n + "" / / packages / modules / StatsD / apex / framework / test : _ _ subpackages _ _ "" , \n + ] , \n",Fix visibility rules for apex / statsd \n The / / frameworks / base / apex / statsd path is being migrated to \n / / packages / modules / StatsD / apex . \n BUG : 167962588 \n TEST : TH \n Change - Id : Ifee35a00de64e194abb80af5d85e34732244f509,55
core \ java \ android \ util \ EventLog . java \n - / / see system / core / liblog / include / log / log _ read . h \n + / / see system / logging / liblog / include / log / log _ read . h \n,Cleanup references to system / core / liblog - > system / logging / liblog \n BUG : 170387172 \n Test : TH \n Change - Id : Ifb2bd2c3db97c52baeac6f2e3643dabf6fcfde6e,55
"Android . bp \n + "" / / packages / modules / Connectivity / Tethering / tests / unit "" , \n core \ java \ android \ net \ TEST _ MAPPING \n - } \n + } \n packages \ Tethering \ common \ TetheringLib \ Android . bp \n - impl _ library _ visibility : [ "" / / frameworks / base / packages / Tethering : _ _ subpackages _ _ "" ] , \n + impl _ library _ visibility : [ \n + "" / / frameworks / base / packages / Tethering : _ _ subpackages _ _ "" , \n + "" / / packages / modules / Connectivity / Tethering : _ _ subpackages _ _ "" , \n + ] , \n packages \ Tethering \ tests \ Android . bp \n + "" / / packages / modules / Connectivity / Tethering / tests : _ _ subpackages _ _ "" , \n packages \ Tethering \ tests \ unit \ Android . bp \n + "" / / packages / modules / Connectivity / Tethering / tests / integration "" , \n services \ net \ Android . bp \n - visibility : [ "" / / frameworks / base / packages / Tethering "" ] , \n + visibility : [ \n + "" / / frameworks / base / packages / Tethering "" , \n + "" / / packages / modules / Connectivity / Tethering "" \n + ] , \n",Add visibility rules for packages / modules / Connectivity / Tethering \n BUG : 167962976 \n Test : TH \n Change - Id : Id28881b35cf24fc9517fa11af6d8e539ab244fa6,55
packages \ Tethering \ OWNERS \n - include platform / packages / modules / NetworkStack / : / OWNERS \n - markchien @ google . com \n + set noparent # while performing migration - b / 167962976 \n + baligh @ google . com \n,Add OWNERS block to prevent the tree from mooving during migration . \n BUG : 167962976 \n TEST : None . \n Change - Id : I49db5a11ee89645dac158ec3757180b2387e2d70,55
"new file \n cmds \ statsd \ src \ OWNERS \n + # Temporary OWNERS Block to assist with migration \n + # bug : 167962588 \n + per - file * atoms . proto = set noparent \n + per - file * atom _ field _ options . proto = set noparent \n + per - file * atoms . proto = baligh @ google . com , yro @ google . com , singhtejinder @ google . com , jeffreyhuang @ google . com \n + per - file * atom _ field _ options . proto = baligh @ google . com , yro @ google . com , singhtejinder @ google . com , jeffreyhuang @ google . com \n core \ proto \ OWNERS \n + \n + # Temporary Block to assist in migration \n + # Bug : 143080132 \n + per - file * enums . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * media _ output _ enum . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * networkcapabilities . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * data _ stall _ event . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * procstats _ enum . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * usb . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * network _ stack . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * tethering . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * dns _ resolver . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * device _ policy . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * launcher . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n + per - file * mediametrics . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n",Add OWNERS block to facilitate in migration \n BUG : 167962588 \n Test : TH \n Change - Id : Ia8cdeb0c2bd0e98d8d6b8a44f49d42ccd0d04908,55
cmds \ statsd \ OWNERS \n - jeffreyhuang @ google . com \n - joeo @ google . com \n - jtnguyen @ google . com \n - muhammadq @ google . com \n - ruchirr @ google . com \n - singhtejinder @ google . com \n - tsaichristine @ google . com \n - yaochen @ google . com \n - yro @ google . com \n + baligh @ google . com \n,Temporary apply OWNERS block for migration \n BUG : 167962588 \n TEST : TH \n Change - Id : Ia168658c499e19f99aac05cb379155669a3e1431,55
"deleted file \n cmds \ statsd \ src \ OWNERS \n - # Temporary OWNERS Block to assist with migration \n - # bug : 167962588 \n - per - file * atoms . proto = set noparent \n - per - file * atom _ field _ options . proto = set noparent \n - per - file * atoms . proto = baligh @ google . com , yro @ google . com , singhtejinder @ google . com , jeffreyhuang @ google . com \n - per - file * atom _ field _ options . proto = baligh @ google . com , yro @ google . com , singhtejinder @ google . com , jeffreyhuang @ google . com \n core \ proto \ OWNERS \n - \n - # Temporary Block to assist in migration \n - # Bug : 143080132 \n - per - file * enums . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * media _ output _ enum . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * networkcapabilities . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * data _ stall _ event . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * procstats _ enum . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * usb . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * network _ stack . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * tethering . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * dns _ resolver . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * device _ policy . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * launcher . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n - per - file * mediametrics . proto = baligh @ google . com , yro @ google . com , jeffreyhuang @ google . com \n","Revert "" Add OWNERS block to facilitate in migration "" \n This reverts commit 9e569671a3752c4edd95367f483355ad31fac8d4 . \n Reason for revert : atoms and associated protos have been migrated . Removing migration block . \n Change - Id : Ia1e4a73001ebc9509b8550c7957135172ce8938d \n BUG : 167962588 \n Test : TH",55
"wifi \ Android . bp \n + "" / / packages / modules / Wifi / framework / tests "" , \n + "" / / packages / modules / Wifi / service / tests / wifitests : _ _ subpackages _ _ "" , \n + \n","Add visibility rule for migration . \n Add paths to visibility needed for tests . \n Soong allows specifying paths w / o validation .  Once the \n migration is complete , we can remove the old path in \n visibility rules . \n BUG : 137323948 \n Test : TH \n Change - Id : I81c053c79dd82d7059bc7fb67be82accc3254e97",55
"Android . bp \n - visibility : [ "" / / frameworks / opt / net / wifi / service "" ] , \n + visibility : [ \n + "" / / frameworks / opt / net / wifi / service "" , \n + "" / / packages / modules / Wifi / service "" , \n + ] , \n services \ net \ Android . bp \n + "" / / packages / modules / Wifi / service "" , \n + "" / / packages / modules / Wifi / service / tests / wifitests "" , \n",Adjust visibility rules for migration \n Adjusting visibility to accomodate migration of \n frameworks / opt / net / wifi to packages / modules / Wifi . \n BUG : 137323948 \n Test : TH \n Change - Id : Ib4c481f6e17507fb5a423be83e04f4cbebfd10f5,55
"apex \ permission \ framework \ Android . bp \n - impl _ library _ visibility : [ "" / / frameworks / base / apex / permission : _ _ subpackages _ _ "" ] , \n + impl _ library _ visibility : [ \n + "" / / frameworks / base / apex / permission : _ _ subpackages _ _ "" , \n + "" / / packages / modules / Permission : _ _ subpackages _ _ "" , \n + ] , \n apex \ permission \ service \ Android . bp \n + "" / / packages / modules / Permission / tests "" , \n","Add visibility for new location of permission apex . \n This is prep . work for f / b / apex / permission migraton to \n packages / modules / Permission . The Build System does not \n enforce location checks within visibility , which allows \n us to add the new location post migration and ensure \n migration process does not run into visibility related errors . \n BUG : 167963264 \n Test : TH \n Change - Id : I765b73bb8e0f377ef03805423807e720f1e90582",55
"apk \ build . gradle \n - compileSdkVersion 25 \n - buildToolsVersion "" 25 . 0 . 2 "" \n + compileSdkVersion rootProject . ext . compileSdkVersion \n + buildToolsVersion rootProject . ext . buildToolsVersion \n - minSdkVersion 21 \n + minSdkVersion rootProject . ext . minSdkVersion \n build . gradle \n + \n + ext { \n + compileSdkVersion = 25 \n + buildToolsVersion = "" 25 . 0 . 2 "" \n + minSdkVersion = 21 \n + targetSdkVersion = 23 \n + } \n lib \ build . gradle \n - compileSdkVersion 25 \n - buildToolsVersion "" 25 . 0 . 2 "" \n + compileSdkVersion rootProject . ext . compileSdkVersion \n + buildToolsVersion rootProject . ext . buildToolsVersion \n - minSdkVersion 21 \n + minSdkVersion rootProject . ext . minSdkVersion \n - targetSdkVersion 23 \n + targetSdkVersion rootProject . ext . targetSdkVersion \n - targetSdkVersion 22 \n + targetSdkVersion rootProject . ext . targetSdkVersion \n","Unify tools versions across modules \n Instead of declaring versions in each project \n they are now declared within the root project ' s \n ext extension and can be accessed like this \n "" rootProject . ext . value "" . \n Change - Id : If27985140810a102f2b2be4f96b1fa2e55adf954",60
"mobile \ src \ main \ AndroidManifest . xml \n - android : theme = "" @ style / AppTheme . Launcher "" / > \n + android : theme = "" @ style / AppTheme . Launcher "" > \n + < ! - - This will have to be placed wherever the activity - alias is pointing to . - - > \n + < intent - filter > \n + < action android : name = "" android . intent . action . MAIN "" / > \n + < category android : name = "" android . intent . category . LAUNCHER "" / > \n + < / intent - filter > \n + < ! - - URL handling and instant app auto - verification . - - > \n + < intent - filter android : autoVerify = "" true "" > \n + < action android : name = "" android . intent . action . VIEW "" / > \n + < category android : name = "" android . intent . category . BROWSABLE "" / > \n + < category android : name = "" android . intent . category . DEFAULT "" / > \n + < data android : scheme = "" http "" / > \n + < data android : scheme = "" https "" / > \n + < data android : host = "" events . google . com "" / > \n + < data android : path = "" / io "" / > \n + < data android : path = "" / io / "" / > \n + < data android : path = "" / io / schedule "" / > \n + < data android : path = "" / io / schedule / "" / > \n + < / intent - filter > \n + < meta - data \n + android : name = "" default - url "" \n + android : value = "" https : / / events . google . com / io "" / > \n + < / activity > \n",Add url handling \n We ' re handling events . google . com / io and / io / schedule . \n Future CLs may introdcue further URLs . \n The redundancy between activity - alias and activity \n intent filters originates in b / 67066937 . \n Bug : 127731374 \n Change - Id : I2f2375fa60fb79f89d8d5c413dddd500ef805de7,60
"build . gradle \n + instantAppsVersion = ' 1 . 1 . 0 ' \n mobile \ build . gradle \n + implementation "" com . google . android . instantapps : instantapps : $ rootProject . instantAppsVersion "" \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ FirebaseAnalyticsHelper . kt \n + import com . google . android . instantapps . InstantApps \n + private val FA _ DEPLOYMENT _ TYPE = "" app _ type "" \n + \n + private val STATUS _ INSTALLED = "" installed "" \n + private val STATUS _ INSTANT = "" instant "" \n + val isInstant = InstantApps . isInstantApp ( context ) \n + val deploymentType = if ( isInstant ) STATUS _ INSTANT else STATUS _ INSTALLED \n + firebaseAnalytics . setUserProperty ( FA _ DEPLOYMENT _ TYPE , deploymentType ) \n + \n - Timber . d ( "" Analytics initialized "" ) \n + Timber . d ( "" Analytics initialized , $ FA _ DEPLOYMENT _ TYPE : $ deploymentType "" ) \n",Add deployment type tracking \n * Introduce instant apps library to the project \n * Track whether the app is installed or instant \n Bug : 127731374 \n Change - Id : I0a18c7c24d6eba6bea6f7fbbff3d1a37595c5a59,60
"app \ src \ main \ java \ io \ plaidapp \ dagger \ HomeComponent . kt \n + import io . plaidapp . core . dagger . SharedPreferencesModule \n + fun sharedPreferencesModule ( module : SharedPreferencesModule ) : Builder \n app \ src \ main \ java \ io \ plaidapp \ dagger \ HomeModule . kt \n + import io . plaidapp . core . dagger . designernews . DesignerNewsDataModule \n + DesignerNewsDataModule : : class , \n - fun viewPreloadSizeProvider ( ) = ViewPreloadSizeProvider < Shot > ( ) \n + fun viewPreloadSizeProvider ( ) : ViewPreloadSizeProvider < Shot > = ViewPreloadSizeProvider ( ) \n - fun isPocketInstalled ( ) = PocketUtils . isPocketInstalled ( activity ) \n + fun isPocketInstalled ( ) : Boolean = PocketUtils . isPocketInstalled ( activity ) \n app \ src \ main \ java \ io \ plaidapp \ dagger \ Injector . kt \n + import io . plaidapp . core . dagger . SharedPreferencesModule \n + import io . plaidapp . core . designernews . data . login . LoginLocalDataSource \n + . sharedPreferencesModule ( \n + SharedPreferencesModule ( activity , LoginLocalDataSource . DESIGNER _ NEWS _ PREF ) \n + ) \n",Add shared preferences module explicitly \n This allows adding the preferences name .,60
rename from app \ src \ main \ java \ io \ plaidapp \ ui \ span \ TextColorSpan . java \n rename to base \ src \ main \ java \ io \ plaidapp \ base \ ui \ span \ TextColorSpan . java \n - package io . plaidapp . ui . span ; \n + package io . plaidapp . base . ui . span ; \n rename from app \ src \ main \ java \ io \ plaidapp \ ui \ widget \ CollapsingTitleLayout . java \n rename to base \ src \ main \ java \ io \ plaidapp \ base \ ui \ widget \ CollapsingTitleLayout . java \n - package io . plaidapp . ui . widget ; \n + package io . plaidapp . base . ui . widget ; \n - import io . plaidapp . R ; \n - import io . plaidapp . ui . span . TextColorSpan ; \n + import io . plaidapp . base . R ; \n + import io . plaidapp . base . ui . span . TextColorSpan ; \n - import io . plaidapp . util . CollapsingTextHelper ; \n + import io . plaidapp . base . util . CollapsingTextHelper ; \n rename from app \ src \ main \ java \ io \ plaidapp \ util \ CollapsingTextHelper . java \n rename to base \ src \ main \ java \ io \ plaidapp \ base \ util \ CollapsingTextHelper . java \n - package io . plaidapp . util ; \n + package io . plaidapp . base . util ; \n rename from app \ src \ main \ res \ values \ attrs _ plaid . xml \n rename to base \ src \ main \ res \ values \ attrs _ plaid . xml \n designernews \ src \ main \ java \ io \ plaidapp \ ui \ designernews \ story \ DesignerNewsStory . java \n - import io . plaidapp . ui . widget . CollapsingTitleLayout ; \n + import io . plaidapp . base . ui . widget . CollapsingTitleLayout ; \n designernews \ src \ main \ res \ layout \ activity _ designer _ news _ story . xml \n - < io . plaidapp . ui . widget . CollapsingTitleLayout \n + < io . plaidapp . base . ui . widget . CollapsingTitleLayout \n - < / io . plaidapp . ui . widget . CollapsingTitleLayout > \n + < / io . plaidapp . base . ui . widget . CollapsingTitleLayout > \n,CollapsingTitleLayout & supporting code - > base \n Classes moved to keep app lightweight and unify \n things in base that are being used in different \n feature modules .,60
"app \ src \ main \ res \ values \ styles . xml \n - < style name = "" TextAppearance . Filter "" parent = "" @ android : style / TextAppearance . Material . Title "" > \n - < item name = "" android : textSize "" > 16sp < / item > \n - < item name = "" android : textColor "" > @ color / filter _ text < / item > \n - < / style > \n - \n rename from app \ src \ main \ res \ animator \ filter _ active . xml \n rename to base \ src \ main \ res \ animator \ filter _ active . xml \n rename from app \ src \ main \ res \ color \ filter _ text . xml \n rename to base \ src \ main \ res \ color \ filter _ text . xml \n rename from base \ src \ main \ res \ drawable - v26 \ avd _ back _ to _ search . xml \n rename to base \ src \ main \ res \ drawable \ avd _ back _ to _ search . xml \n rename from app \ src \ main \ res \ drawable \ filter _ placeholder . xml \n rename to base \ src \ main \ res \ drawable \ filter _ placeholder . xml \n rename from app \ src \ main \ res \ drawable \ ic _ pocket . xml \n rename to base \ src \ main \ res \ drawable \ ic _ pocket . xml \n rename from search \ src \ main \ res \ drawable \ searchback _ back . xml \n rename to base \ src \ main \ res \ drawable \ searchback _ back . xml \n rename from search \ src \ main \ res \ drawable \ searchback _ search . xml \n rename to base \ src \ main \ res \ drawable \ searchback _ search . xml \n base \ src \ main \ res \ values \ styles . xml \n + < style name = "" TextAppearance . Filter "" parent = "" @ android : style / TextAppearance . Material . Title "" > \n + < item name = "" android : textSize "" > 16sp < / item > \n + < item name = "" android : textColor "" > @ color / filter _ text < / item > \n + < / style > \n + \n","Move colors , styles and drawables to base",60
"about \ build . gradle \n - proguardFiles getDefaultProguardFile ( ' proguard - android - optimize . txt ' ) , \n - ' proguard - rules . pro ' \n + proguardFiles ' proguard - rules . pro ' \n designernews \ build . gradle \n - proguardFiles getDefaultProguardFile ( ' proguard - android - optimize . txt ' ) , ' proguard - rules . pro ' \n + proguardFiles ' proguard - rules . pro ' \n dribbble \ build . gradle \n - proguardFiles getDefaultProguardFile ( ' proguard - android - optimize . txt ' ) , \n - ' proguard - rules . pro ' \n + proguardFiles ' proguard - rules . pro ' \n search \ build . gradle \n - proguardFiles getDefaultProguardFile ( ' proguard - android - optimize . txt ' ) , \n - ' proguard - rules . pro ' \n + proguardFiles ' proguard - rules . pro ' \n",Remove default proguard file from non - base modules,60
"app \ build . gradle \n - applicationId "" io . plaidapp "" \n + applicationId names . applicationId \n - \n - def filesAuthorityValue = applicationId + "" . shareprovider "" \n - buildConfigField "" String "" , "" FILES _ AUTHORITY "" , "" \ "" $ { filesAuthorityValue } \ "" "" \n - manifestPlaceholders + = [ \n - filesAuthority : filesAuthorityValue , \n - crashlyticsEnabled : false \n - ] \n + manifestPlaceholders + = [ \n + crashlyticsEnabled : false \n + ] \n build . gradle \n + ext . names = [ \n + ' applicationId ' : ' io . plaidapp ' \n + ] \n dribbble \ build . gradle \n - def filesAuthorityValue = applicationId + "" . shareprovider "" \n + def filesAuthorityValue = names . applicationId + "" . shareprovider "" \n",Address wrongly set filesAuthority \n Fixes # 348,60
"about \ src \ main \ AndroidManifest . xml \n - dist : onDemand = "" true "" \n + dist : onDemand = "" false "" \n dribbble \ src \ main \ AndroidManifest . xml \n - dist : onDemand = "" true "" \n + dist : onDemand = "" false "" \n search \ src \ main \ AndroidManifest . xml \n - dist : onDemand = "" true "" \n + dist : onDemand = "" false "" \n",Mark dynamic - feature modules as not on demand \n This will be changed once we use the Google PlayCore API .,60
"build . gradle \n + okioVersion = ' 1 . 14 . 0 ' \n shared \ build . gradle \n + / / Has to be replaced to avoid compile / runtime conflicts between okhttp and firestore \n + api "" com . squareup . okio : okio : $ rootProject . okioVersion "" \n",Force okio version explicitly \n This was a warning with 3 . 2 but will break the build with 3 . 3 and gradle \n 4 . 9 . \n Bug : 124097534 \n Change - Id : Iaa0659b8d0f4f4b1659d8440d063b9098acbeb95,60
"core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ dribbble \ DribbbleDataModule . kt \n + import retrofit2 . Converter \n - @ Provides fun provideShotsRepository ( \n + @ Provides \n + fun provideShotsRepository ( \n - @ Provides fun provideDribbbleSearchService ( ) : DribbbleSearchService = \n - provideRetrofit ( ) . create ( DribbbleSearchService : : class . java ) \n + @ Provides \n + fun provideDribbbleSearchService ( ) : DribbbleSearchService = \n + provideRetrofit ( \n + DribbbleSearchService . ENDPOINT , \n + provideDribbleSearchConverterFactory ( ) \n + ) \n + . create ( DribbbleSearchService : : class . java ) \n - @ Provides fun provideRetrofit ( ) : Retrofit { \n - return Retrofit . Builder ( ) \n - . baseUrl ( DribbbleSearchService . ENDPOINT ) \n - . addConverterFactory ( DribbbleSearchConverter . Factory ( ) ) \n + @ Provides \n + fun provideRetrofit ( \n + baseUrl : String , \n + factory : Converter . Factory \n + ) : Retrofit { \n + return provideRetrofitBuilder ( ) \n + . baseUrl ( baseUrl ) \n + . addConverterFactory ( factory ) \n - @ Provides fun provideLoggingInterceptor ( ) : HttpLoggingInterceptor { \n + @ Provides \n + fun provideRetrofitBuilder ( ) = Retrofit . Builder ( ) \n + \n + @ Provides \n + fun provideDribbleSearchConverterFactory ( ) = DribbbleSearchConverter . Factory ( ) \n + \n + @ Provides \n + fun provideLoggingInterceptor ( ) : HttpLoggingInterceptor { \n - @ Provides fun provideOkHttpClient ( loggingInterceptor : HttpLoggingInterceptor ) : OkHttpClient = \n + @ Provides \n + fun provideOkHttpClient ( loggingInterceptor : HttpLoggingInterceptor ) : OkHttpClient = \n",Clean up after dagger introduction \n Remove DribbbleInjection \n No more explicit DribbbleDataModule \n Some cleanup in FilterAdapter,60
"about \ src \ main \ java \ io \ plaidapp \ about \ ui \ AboutStyler . kt \n + import android . content . res . ColorStateList \n - import android . support . v4 . content . ContextCompat \n - import io . plaidapp . core . R as coreR \n + import android . support . v7 . content . res . AppCompatResources \n + import io . plaidapp . core . R as coreR \n - val linksColor = ContextCompat . getColorStateList ( activity , coreR . color . plaid _ links ) ! ! \n + val linksColor : ColorStateList = AppCompatResources . getColorStateList ( \n + activity , \n + coreR . color . plaid _ links \n + ) \n + \n",Remove nullability from linksColor \n This is done by using AppCompatResources instead of ColorCompat .,60
about \ src \ main \ java \ io \ plaidapp \ about \ dagger \ AboutActivityModule . kt \n - fun provideAboutStyler ( activity : AboutActivity ) = AboutStyler ( activity ) \n + fun provideAboutStyler ( ) = AboutStyler ( activity ) \n about \ src \ main \ java \ io \ plaidapp \ about \ dagger \ AboutComponent . kt \n + import dagger . BindsInstance \n - fun activity ( activity : AboutActivity ) \n + fun inject ( activity : AboutActivity ) \n + \n + @ Component . Builder \n + interface Builder { \n + \n + fun build ( ) : AboutComponent \n + \n + @ BindsInstance fun activity ( activity : AboutActivity ) : Builder \n + \n + fun aboutActivityModule ( module : AboutActivityModule ) : Builder \n + \n + fun markdownModule ( module : MarkdownModule ) : Builder \n + } \n about \ src \ main \ java \ io \ plaidapp \ about \ dagger \ Injector . kt \n + . activity ( this ) \n - . build ( ) . apply { \n - activity ( this @ inject ) \n - } \n + . build ( ) \n + . inject ( this ) \n about \ src \ main \ java \ io \ plaidapp \ about \ ui \ model \ AboutViewModelFactory . kt \n - import android . content . res . Resources \n - internal class AboutViewModelFactory @ Inject constructor ( \n - val resources : Resources \n - ) : ViewModelProvider . Factory { \n + internal class AboutViewModelFactory @ Inject constructor ( ) : ViewModelProvider . Factory { \n,Make AboutActivityModule stateless \n As per @ hzsweers ' suggestion at \n https : / / github . com / nickbutcher / plaid / pull / 461 # discussion _ r211067087,60
"build . gradle \n - ' crashlytics ' : ' 2 . 9 . 5 ' , \n + ' crashlytics ' : ' 2 . 9 . 6 ' , \n - ' firebase ' : ' 16 . 0 . 3 ' , \n + ' firebase ' : ' 16 . 0 . 5 ' , \n - ' kotlin ' : ' 1 . 3 . 0 ' , \n + ' kotlin ' : ' 1 . 3 . 10 ' , \n - classpath ' com . android . tools . build : gradle : 3 . 3 . 0 - beta02 ' \n + classpath ' com . android . tools . build : gradle : 3 . 4 . 0 - alpha05 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 10 . 2 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 0 - all . zip \n",Update to gradle 5 . 0 & AGP 3 . 4 . 0 - a5 \n Requires Android Studio 3 . 4 canary from now on .,60
"core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ CoreDataModule . kt \n - @ Provides \n - fun provideOkHttpClient ( builder : OkHttpClient . Builder ) : OkHttpClient = builder . build ( ) \n - \n core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ ProductHuntModule . kt \n - builder : OkHttpClient . Builder , \n + okHttpClientBuilder : OkHttpClient . Builder , \n - builder , \n + okHttpClientBuilder , \n - builder : OkHttpClient . Builder , \n + okHttpClientBuilder : OkHttpClient . Builder , \n - val client = builder \n + val client = okHttpClientBuilder \n core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ designernews \ DesignerNewsDataModule . kt \n + okHttpClientBuilder : OkHttpClient . Builder , \n - val client = OkHttpClient . Builder ( ) \n + val client = okHttpClientBuilder \n","Don ' t directly provide OkHttpClient via dagger \n To customize the connection , use OkHttpClient . Builder",60
"core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ dribbble \ DribbbleDataModule . kt \n - @ Provides \n - fun provideBaseUrl ( ) : String = DribbbleSearchService . ENDPOINT \n - \n - baseUrl : String , \n - . baseUrl ( baseUrl ) \n + . baseUrl ( DribbbleSearchService . ENDPOINT ) \n",Inline base url since it ' s only used in one place,60
"ar \ src \ main \ AndroidManifest . xml \n + < dist : fusing dist : include = "" true "" / > \n",Fix dynamic feature module declaration \n Change - Id : Ia1bc00280dd08644d65bec63d68bd09b84a6ac5b,60
"core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ ProductHuntModule . kt \n - import io . plaidapp . core . data . api . DenvelopingConverter \n + import io . plaidapp . core . data . api . DeEnvelopingConverter \n - denvelopingConverter : DenvelopingConverter , \n + deEnvelopingConverter : DeEnvelopingConverter , \n - denvelopingConverter , \n + deEnvelopingConverter , \n - @ Provides \n - fun provideDenvelopingConverter ( gson : Gson ) : DenvelopingConverter { \n - return DenvelopingConverter ( gson ) \n - } \n - \n - denvelopingConverter : DenvelopingConverter , \n + deEnvelopingConverter : DeEnvelopingConverter , \n - . addConverterFactory ( denvelopingConverter ) \n + . addConverterFactory ( deEnvelopingConverter ) \n core \ src \ main \ java \ io \ plaidapp \ core \ dagger \ designernews \ DesignerNewsDataModule . kt \n - import io . plaidapp . core . data . api . DenvelopingConverter \n + import io . plaidapp . core . data . api . DeEnvelopingConverter \n - . addConverterFactory ( DenvelopingConverter ( gson ) ) \n + . addConverterFactory ( DeEnvelopingConverter ( gson ) ) \n rename from core \ src \ main \ java \ io \ plaidapp \ core \ data \ api \ DenvelopingConverter . java \n rename to core \ src \ main \ java \ io \ plaidapp \ core \ data \ api \ DeEnvelopingConverter . java \n - \n - \n - import java . lang . annotation . Annotation ; \n - import java . lang . reflect . Type ; \n - \n + import javax . inject . Inject ; \n + import java . lang . annotation . Annotation ; \n + import java . lang . reflect . Type ; \n + \n - public class DenvelopingConverter extends Converter . Factory { \n + public class DeEnvelopingConverter extends Converter . Factory { \n - public DenvelopingConverter ( @ NonNull Gson gson ) { \n + @ Inject \n + public DeEnvelopingConverter ( @ NonNull Gson gson ) { \n designernews \ src \ main \ java \ io \ plaidapp \ designernews \ dagger \ DataModule . kt \n - import io . plaidapp . core . data . api . DenvelopingConverter \n + import io . plaidapp . core . data . api . DeEnvelopingConverter \n - . addConverterFactory ( DenvelopingConverter ( gson ) ) \n + . addConverterFactory ( DeEnvelopingConverter ( gson ) ) \n","Fix typo in DeEnvelopingConverter \n Also change the way it is injected , away from DataModule \n and into constructor injection .",60
"designernews \ src \ main \ java \ io \ plaidapp \ designernews \ dagger \ LoginComponent . kt \n + import io . plaidapp . core . dagger . CoreDataModule \n + import io . plaidapp . core . dagger . designernews . DesignerNewsDataModule \n - @ Component ( modules = [ LoginModule : : class ] ) \n + @ Component ( \n + modules = [ \n + CoreDataModule : : class , \n + DesignerNewsDataModule : : class , \n + SharedPreferencesModule : : class \n + ] \n + ) \n deleted file \n designernews \ src \ main \ java \ io \ plaidapp \ designernews \ dagger \ LoginModule . kt \n - / * \n - * Copyright 2018 Google , Inc . \n - * \n - * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - * you may not use this file except in compliance with the License . \n - * You may obtain a copy of the License at \n - * \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - * \n - * Unless required by applicable law or agreed to in writing , software \n - * distributed under the License is distributed on an "" AS IS "" BASIS , \n - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - * See the License for the specific language governing permissions and \n - * limitations under the License . \n - * / \n - \n - package io . plaidapp . designernews . dagger \n - \n - import dagger . Module \n - import io . plaidapp . core . dagger . CoreDataModule \n - import io . plaidapp . core . dagger . SharedPreferencesModule \n - import io . plaidapp . core . dagger . designernews . DesignerNewsDataModule \n - \n - / * * \n - * Dagger module for [ io . plaidapp . designernews . ui . login . LoginActivity ] . \n - * / \n - @ Module ( \n - includes = [ \n - CoreDataModule : : class , \n - DesignerNewsDataModule : : class , \n - SharedPreferencesModule : : class \n - ] \n - ) \n - class LoginModule \n",Remove LoginModule \n The module did not have any functions and was merely an introduction of \n unnecessary code .,60
"build . gradle \n - ' compileSdk ' : 28 , \n + ' compileSdk ' : 29 , \n - ' targetSdk ' : 28 , \n + ' targetSdk ' : 29 , \n - classpath ' com . android . tools . build : gradle : 3 . 6 . 0 - alpha12 ' \n + classpath ' com . android . tools . build : gradle : 3 . 6 . 0 - beta03 ' \n",Update sdk to 29 & tools to beta03,60
"buildSrc \ src \ main \ java \ Libs . kt \n + const val PLAYCORE _ KTX = "" com . google . android . play : core - ktx "" \n depconstraints \ build . gradle . kts \n + val playCore = "" 1 . 6 . 5 "" \n + api ( "" $ { Libs . PLAYCORE _ KTX } : $ playCore "" ) \n mobile \ build . gradle . kts \n + implementation ( Libs . PLAYCORE _ KTX ) \n",Introduce dependency on PlayCore \n Bug : 148216924 \n Bug : 148878698 \n Change - Id : I803453ce872ee0c403d81a0d44b76330afae2e36,60
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ di \ AppModule . kt \n - fun providesPreferenceStorage ( context : Context ) : PreferenceStorage = \n + fun providePreferenceStorage ( context : Context ) : PreferenceStorage = \n - fun providesWifiManager ( context : Context ) : WifiManager = \n + fun provideWifiManager ( context : Context ) : WifiManager = \n - fun providesConnectivityManager ( context : Context ) : ConnectivityManager = \n + fun provideConnectivityManager ( context : Context ) : ConnectivityManager = \n - fun providesClipboardManager ( context : Context ) : ClipboardManager = \n + fun provideClipboardManager ( context : Context ) : ClipboardManager = \n - fun providesMainThreadHandler ( ) : IOSchedHandler = IOSchedMainHandler ( ) \n + fun provideMainThreadHandler ( ) : IOSchedHandler = IOSchedMainHandler ( ) \n - fun providesAnalyticsHelper ( \n + fun provideAnalyticsHelper ( \n - fun providesAppDatabase ( context : Context ) : AppDatabase = AppDatabase . buildDatabase ( context ) \n + fun provideAppDatabase ( context : Context ) : AppDatabase = AppDatabase . buildDatabase ( context ) \n,Adjust provide function names to match convention \n Change - Id : If0059d67a17f0c37791c1764e1fb167a9f2c290d,60
"tools \ jdk \ java _ toolchain _ default . bzl \n - genclass = [ Label ( "" / / : GenClass "" , relative _ to _ caller _ repository = True ) ] , \n - header _ compiler = [ Label ( "" / / : TurbineDirect "" , relative _ to _ caller _ repository = True ) ] , \n - header _ compiler _ direct = [ Label ( "" / / : TurbineDirect "" , relative _ to _ caller _ repository = True ) ] , \n - ijar = [ Label ( "" / / : ijar "" , relative _ to _ caller _ repository = True ) ] , \n - javabuilder = [ Label ( "" / / : JavaBuilder "" , relative _ to _ caller _ repository = True ) ] , \n + genclass = [ Label ( "" / / : GenClass "" ) ] , \n + header _ compiler = [ Label ( "" / / : TurbineDirect "" ) ] , \n + header _ compiler _ direct = [ Label ( "" / / : TurbineDirect "" ) ] , \n + ijar = [ Label ( "" / / : ijar "" ) ] , \n + javabuilder = [ Label ( "" / / : JavaBuilder "" ) ] , \n - jacocorunner = Label ( "" / / : jacoco _ coverage _ runner _ filegroup "" , relative _ to _ caller _ repository = True ) , \n + jacocorunner = Label ( "" / / : jacoco _ coverage _ runner _ filegroup "" ) , \n - singlejar = [ Label ( "" / / : singlejar "" , relative _ to _ caller _ repository = True ) ] , \n + singlejar = [ Label ( "" / / : singlejar "" ) ] , \n","Remove relative _ to _ caller _ repository from java _ toolchain _ default . \n relative _ to _ caller _ repository is marked "" Deprecated . Do not use "" in the documentation . Moreover , this flag has the unpleasant effect of making the relative labels be interpreted relative to the main workspace not a remote java tools . \n Closes # 12387 . \n PiperOrigin - RevId : 340200201",63
"tools \ jdk \ default _ java _ toolchain . bzl \n - # In JDK9 we have seen a ~ 30 % slow down in JavaBuilder performance when using \n - # G1 collector and having compact strings enabled . \n - "" - XX : + UseParallelOldGC "" , \n + # Compact strings make JavaBuilder slightly slower . \n + turbine _ jvm _ opts = [ \n + # Turbine is not a worker and parallel GC is faster for short - lived programs . \n + "" - XX : + UseParallelOldGC "" , \n + ] , \n - # In JDK9 we have seen a ~ 30 % slow down in JavaBuilder performance when using \n - # G1 collector and having compact strings enabled . \n - "" - XX : + UseParallelOldGC "" , \n + # Compact strings make JavaBuilder slightly slower . \n + turbine _ jvm _ opts = [ \n + # Turbine is not a worker and parallel GC is faster for short - lived programs . \n + "" - XX : + UseParallelOldGC "" , \n + ] , \n","Allow G1 for javac workers . \n G1 has a smoother memory profile than parallelGC , which is desirable for workers \n that users run locally like javac . \n Unfortunately , completely getting rid of the parallelGC option regresses Java \n build performance . This is because Turbine does not run as a worker—see \n https : / / github . com / bazelbuild / bazel / issues / 8006—and G1 seems to do worse than \n parallelGC for short - lived programs . So , I simply moved the parallelGC option to \n the Turbine - specific jvm opts . \n I ran bazel - bench to test the performance this change building / / src : bazel _ nojdk : \n ` ` ` \n metric mean median stddev pval \n wall : 475 . 842s ( - 0 . 05 % ) 474 . 997s ( - 0 . 09 % ) 1 . 203s 0 . 00000 \n cpu : 73 . 063s ( - 2 . 28 % ) 72 . 980s ( - 2 . 21 % ) 1 . 499s 0 . 40000 \n system : 19 . 427s ( + 0 . 66 % ) 19 . 450s ( + 1 . 09 % ) 0 . 111s 0 . 40000 \n memory : 89 . 667MB ( - 0 . 74 % ) 90 . 000MB ( + 0 . 00 % ) 0 . 471MB 0 . 00000 \n ` ` ` \n Closes # 12598 . \n PiperOrigin - RevId : 345616260",63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ query2 \ query \ BlazeQueryEnvironment . java \n - Set < PathFragment > packages = CompactHashSet . create ( ) ; \n + Set < PackageIdentifier > packages = CompactHashSet . create ( ) ; \n - packages . add ( target . getLabel ( ) . getPackageFragment ( ) ) ; \n + packages . add ( target . getLabel ( ) . getPackageIdentifier ( ) ) ; \n - if ( ! packages . contains ( label . getPackageFragment ( ) ) ) { \n + if ( ! packages . contains ( label . getPackageIdentifier ( ) ) ) { \n src \ test \ shell \ integration \ bazel _ query _ test . sh \n + function test _ unnecessary _ external _ workspaces _ not _ loaded ( ) { \n + cat > WORKSPACE < < ' EOF ' \n + local _ repository ( \n + name = "" notthere "" , \n + path = "" / nope "" , \n + ) \n + EOF \n + cat > BUILD < < ' EOF ' \n + filegroup ( \n + name = "" something "" , \n + srcs = [ "" @ notthere "" ] , \n + ) \n + EOF \n + bazel query ' / / : * ' | | fail "" Expected success "" \n + } \n + \n",Fix the classic query package - loading cutoff optimization with external workspaces . \n A package ' s path fragment is not unambiguous when external workspaces are involved . \n Fixes https : / / github . com / bazelbuild / bazel / issues / 12497 . \n Closes # 12595 . \n PiperOrigin - RevId : 346048937,63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ analysis \ actions \ SymlinkTreeAction . java \n + import com . google . devtools . build . lib . collect . nestedset . NestedSet ; \n - import com . google . devtools . build . lib . collect . nestedset . Order ; \n + import com . google . devtools . build . lib . util . OS ; \n - skipRunfilesManifests & & enableRunfiles & & ( filesetRoot = = null ) \n - ? NestedSetBuilder . emptySet ( Order . STABLE _ ORDER ) \n - : NestedSetBuilder . create ( Order . STABLE _ ORDER , inputManifest ) , \n + computeInputs ( enableRunfiles , skipRunfilesManifests , runfiles , inputManifest ) , \n + private static NestedSet < Artifact > computeInputs ( \n + boolean enableRunfiles , \n + boolean skipRunfilesManifests , \n + Runfiles runfiles , \n + Artifact inputManifest ) { \n + NestedSetBuilder < Artifact > inputs = NestedSetBuilder . < Artifact > stableOrder ( ) ; \n + if ( ! skipRunfilesManifests | | ! enableRunfiles | | runfiles = = null ) { \n + inputs . add ( inputManifest ) ; \n + } \n + / / All current strategies ( in - process and build - runfiles - windows ) for \n + / / making symlink trees on Windows depend on the target files \n + / / existing , so directory or file links can be made as appropriate . \n + if ( enableRunfiles & & runfiles ! = null & & OS . getCurrent ( ) = = OS . WINDOWS ) { \n + inputs . addTransitive ( runfiles . getAllArtifacts ( ) ) ; \n + } \n + return inputs . build ( ) ; \n + } \n + \n","Windows : Make runfiles symlink tree actions depend on the runfiles artifacts . \n Windows distinguishes between symlinks to files and symlinks to directories . The \n code to create symlink trees on Windows thus inspects the targets of the links \n to learn what kind of symlink to make . Unfortunately , the symlinking code did \n not depend on the link targets actually being created . This race could lead to \n non - deterministic and non - functional symlink trees . \n Fix this problem by depending on runfiles artifacts in the SymtreeTreeAction \n when the host platform is Windows . \n It ' s certainly possible to avoid this os - dependent input dependency—by using \n in - memory Artifact state for the in - process implementation and extending the \n runfiles manifest format to indicate target type for build - runfiles - windows—but \n this commit is the most straightforward change that remediates the serious \n correctness issue represented by the previous state . \n This topic has a long history . When Windows runfiles trees were actually copies \n of artifacts , the "" symlink "" action obviously had to depend on the origin \n artifacts ( 41f4456ac2348bef66739194853a1ddadcbb887e ) . That code was removed in \n an interregnum period where runfiles trees weren ' t supported at all on Windows \n ( 0885abd851b17d19661dfbd5459a5b91feb45620 ) . However , the dependency was not \n added back when Windows symlinked runfiles trees support was finally added \n ( b592dbd46d5aae2977b11426850eecb89d94a6cb ) . \n Closes # 12018 . \n PiperOrigin - RevId : 330496487",63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ analysis \ starlark \ StarlarkRuleClassFunctions . java \n - getLocation ( ) , \n + definitionLocation , \n + "" analysis _ test _ transition transitions "" ) ; \n - getLocation ( ) , "" _ allowlist _ function _ transition attribute must be a label type "" ) ; \n + definitionLocation , \n + "" _ allowlist _ function _ transition attribute must be a label type "" ) ; \n - getLocation ( ) , \n + definitionLocation , \n - getLocation ( ) , \n + definitionLocation , \n + defaultLabel \n + "" ) does not have the expected value "" \n - getLocation ( ) , \n + definitionLocation , \n + "" ' _ allowlist _ function _ transition ' . See Starlark transitions documentation "" \n - getLocation ( ) , \n + definitionLocation , \n - throw new EvalException ( getLocation ( ) , ex ) ; \n + throw new EvalException ( definitionLocation , ex ) ; \n src \ test \ java \ com \ google \ devtools \ build \ lib \ starlark \ StarlarkRuleClassFunctionsTest . java \n - . matches ( "" Attribute r \ \ . x { 150 } ' s name is too long \ \ ( 150 > 128 \ \ ) "" ) ; \n + . matches ( "" : 2 : 9 : Attribute r \ \ . x { 150 } ' s name is too long \ \ ( 150 > 128 \ \ ) "" ) ; \n",Use definition location for StarlarkRuleFunction . export errors . \n StarlarkRuleFunction . getLocation ( ) always returns BUILTIN . \n Closes # 11915 . \n PiperOrigin - RevId : 326724815,63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ runtime \ commands \ InfoCommand . java \n - "" Blaze info does not support starlark options . Ignoring options : "" \n + "" info command does not support starlark options . Ignoring options : "" \n + removedStarlarkOptions ) ) ; \n",Remove a Blaze from warning . \n Closes # 12155 . \n PiperOrigin - RevId : 333295480,63
deleted file \n third _ party \ guava \ guava - 25 . 1 - jre . jar \n Binary files a / third _ party / guava / guava - 25 . 1 - jre . jar and / dev / null differ \n deleted file \n third _ party \ guava \ guava - testlib - 25 . 1 - jre . jar \n Binary files a / third _ party / guava / guava - testlib - 25 . 1 - jre . jar and / dev / null differ \n,Delete old guava jars . \n Closes https : / / github . com / bazelbuild / bazel / pull / 12280,63
"scripts \ bootstrap \ compile . sh \n - LIBRARY _ JARS = $ ( find $ ADDITIONAL _ JARS third _ party - name ' * . jar ' | grep - Fv JavaBuilder | grep - Fv third _ party / guava | grep - ve ' third _ party / grpc / grpc . * jar ' | tr "" \ n "" "" "" ) \n + LIBRARY _ JARS = $ ( find $ ADDITIONAL _ JARS third _ party - name ' * . jar ' | grep - Fv JavaBuilder | grep - Fv third _ party / guava / guava | grep - ve ' third _ party / grpc / grpc . * jar ' | tr "" \ n "" "" "" ) \n - GUAVA _ VERSION = 25 . 1 \n + GUAVA _ VERSION = 29 . 0 \n",Update bootstrap guava version to 29 . 0 . \n Closes # 12281 . \n PiperOrigin - RevId : 337496599,63
"src \ BUILD \n - cmd = "" zip - jX $ @ $ ( SRCS ) "" , \n + cmd = "" zip - qjX $ @ $ ( SRCS ) "" , \n",Quiet noise from the java tools zip genrule . \n Closes # 12293 . \n PiperOrigin - RevId : 337850339,63
"src \ java _ tools \ buildjar \ java \ com \ google \ devtools \ build \ buildjar \ BazelJavaBuilder . java \n - System . exit ( \n - builder . parseAndBuild ( \n - Arrays . asList ( args ) , \n - new PrintWriter ( new OutputStreamWriter ( System . err , Charset . defaultCharset ( ) ) ) ) ) ; \n + PrintWriter pw = \n + new PrintWriter ( new OutputStreamWriter ( System . err , Charset . defaultCharset ( ) ) ) ; \n + int returnCode ; \n + try { \n + returnCode = builder . parseAndBuild ( Arrays . asList ( args ) , pw ) ; \n + } finally { \n + pw . flush ( ) ; \n + } \n + System . exit ( returnCode ) ; \n","Flush err after completing standalone jar build request . \n Otherwise , diagnostics are eaten . \n Closes # 12268 . \n PiperOrigin - RevId : 338123554",63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ packages \ semantics \ BuildLanguageOptions . java \n - defaultValue = "" false "" , \n + defaultValue = "" true "" , \n - "" - incompatible _ linkopts _ to _ linklibs "" ; \n + "" + incompatible _ linkopts _ to _ linklibs "" ; \n src \ test \ shell \ bazel \ cc _ integration _ test . sh \n - bazel build / / foo \ \n + bazel build - - noincompatible _ linkopts _ to _ linklibs / / foo \ \n",Flip - - incompatible _ linkopts _ to _ linklibs . \n https : / / github . com / bazelbuild / bazel / issues / 10905 \n Closes # 12334 . \n PiperOrigin - RevId : 339056354,63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ starlarkbuildapi \ cpp \ CcModuleApi . java \n - doc = "" Creates a < code > LinkingContext < / code > . "" , \n + doc = "" Creates a < code > LinkerInput < / code > . "" , \n",Fix create _ linker _ input doc . \n Closes # 12355 . \n PiperOrigin - RevId : 339682648,63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ remote \ RemoteActionInputFetcher . java \n + import com . google . devtools . build . lib . actions . cache . VirtualActionInput . EmptyActionInput ; \n - VirtualActionInput virtualActionInput = ( VirtualActionInput ) input ; \n - Path outputPath = execRoot . getRelative ( virtualActionInput . getExecPath ( ) ) ; \n - SandboxHelpers . atomicallyWriteVirtualInput ( virtualActionInput , outputPath , "" . remote "" ) ; \n + if ( ! ( input instanceof EmptyActionInput ) ) { \n + VirtualActionInput virtualActionInput = ( VirtualActionInput ) input ; \n + Path outputPath = execRoot . getRelative ( virtualActionInput . getExecPath ( ) ) ; \n + SandboxHelpers . atomicallyWriteVirtualInput ( virtualActionInput , outputPath , "" . remote "" ) ; \n + } \n src \ test \ java \ com \ google \ devtools \ build \ lib \ remote \ RemoteActionInputFetcherTest . java \n + import com . google . devtools . build . lib . exec . SpawnInputExpander ; \n + Path dev = fs . getPath ( "" / dev "" ) ; \n + dev . createDirectory ( ) ; \n + dev . setWritable ( false ) ; \n + @ Test \n + public void testStagingEmptyVirtualActionInput ( ) throws Exception { \n + / / arrange \n + MetadataProvider metadataProvider = new StaticMetadataProvider ( new HashMap < > ( ) ) ; \n + RemoteCache remoteCache = newCache ( options , digestUtil , new HashMap < > ( ) ) ; \n + RemoteActionInputFetcher actionInputFetcher = \n + new RemoteActionInputFetcher ( remoteCache , execRoot , RequestMetadata . getDefaultInstance ( ) ) ; \n + \n + / / act \n + actionInputFetcher . prefetchFiles ( \n + ImmutableList . of ( SpawnInputExpander . EMPTY _ FILE ) , metadataProvider ) ; \n + \n + / / assert that nothing happened \n + assertThat ( actionInputFetcher . downloadedFiles ( ) ) . isEmpty ( ) ; \n + assertThat ( actionInputFetcher . downloadsInProgress ) . isEmpty ( ) ; \n + } \n + \n","Take no action to prefetch empty artifacts . \n Previously , Bazel would attempt to overwrite / dev / null . \n Closes # 12514 . \n PiperOrigin - RevId : 343824719",63
src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ java \ JavaLibrary . java \n - / / java _ library doesn ' t need to return JavaRunfilesProvider \n,Delete a final reference to JavaRunfilesProvider . \n Closes # 13066 . \n PiperOrigin - RevId : 358823509,63
"src \ main \ java \ com \ google \ devtools \ build \ lib \ exec \ SpawnLogContext . java \n + if ( input instanceof VirtualActionInput . EmptyActionInput ) { \n + continue ; \n + } \n src \ test \ shell \ bazel \ bazel _ execlog _ test . sh \n + function test _ empty _ file _ in _ runfiles ( ) { \n + mkdir d \n + touch d / main . py \n + cat > BUILD < < ' EOF ' \n + py _ binary ( \n + name = "" py _ tool "" , \n + main = "" d / main . py "" , \n + srcs = [ "" d / main . py "" ] , \n + ) \n + genrule ( \n + name = "" rule "" , \n + outs = [ "" out . txt "" ] , \n + tools = [ "" : py _ tool "" ] , \n + cmd = "" echo hello > $ ( location out . txt ) "" \n + ) \n + EOF \n + bazel build / / : rule - - experimental _ execution _ log _ file output 2 > & 1 > > $ TEST _ log | | fail "" could not build "" \n + [ [ - e output ] ] | | fail "" no output produced "" \n + } \n + \n",Ignore empty virtual artifacts when spawn - logging inputs . \n Fixes https : / / github . com / bazelbuild / bazel / issues / 12816 . \n Closes # 12819 . \n PiperOrigin - RevId : 355800567,63
"tools \ cpp \ unix _ cc _ configure . bzl \n - def _ find _ linker _ path ( repository _ ctx , cc , linker ) : \n + def _ find _ linker _ path ( repository _ ctx , cc , linker , is _ clang ) : \n + is _ clang : whether the compiler is known to be clang \n - # Some macos clang versions don ' t fail when setting - fuse - ld = gold , adding \n + # Some macOS clang versions don ' t fail when setting - fuse - ld = gold , adding \n + if not is _ clang : \n + return linker \n + \n - if flag . find ( "" - - enable - "" + linker ) > - 1 or flag . find ( "" - - with - plugin - ld "" ) > - 1 : \n - # skip build configuration options of gcc itself \n - # TODO ( hlopko ) : Add redhat - like worker on the CI ( # 9392 ) \n - continue \n - \n - # flag is ' - fuse - ld = gold ' for GCC or "" / usr / lib / ld . gold "" for Clang \n - # strip space , single quote , and double quotes \n - flag = flag . strip ( "" \ "" ' "" ) \n - # remove - fuse - ld = from GCC output so we have only the flag value part \n - flag = flag . replace ( "" - fuse - ld = "" , "" "" ) \n - return flag \n + # flag looks like "" / usr / lib / ld . gold "" . \n + return flag . strip ( "" \ "" ' "" ) \n - _ find _ linker _ path ( repository _ ctx , cc , "" lld "" ) or \n - _ find _ linker _ path ( repository _ ctx , cc , "" gold "" ) \n + _ find _ linker _ path ( repository _ ctx , cc , "" lld "" , is _ clang ) or \n + _ find _ linker _ path ( repository _ ctx , cc , "" gold "" , is _ clang ) \n","Bail out quickly from _ find _ gold _ linker _ path for GCC . \n GCC can ' t make use of an absolute gold path , so keep parsing specific to clang . This avoids silly problems like https : / / stackoverflow . com / questions / 65336037 / how - do - i - fix - a - bazel - build - error - in - tensorflow . \n Closes # 12729 . \n PiperOrigin - RevId : 356515434",63
"packages \ SettingsLib \ HelpUtils \ res \ values - ar \ strings . xml \n - < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" المساعدة والتعليقات "" < / string > \n + < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" المساعدة والملاحظات والآراء "" < / string > \n packages \ SettingsLib \ HelpUtils \ res \ values - es \ strings . xml \n - < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Ayuda y sugerencias "" < / string > \n + < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Ayuda y comentarios "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Idcecdf13bd946d505e9bdf5b934d7f7164b6b663,69
"packages \ SettingsLib \ SearchWidget \ res \ values - be \ strings . xml \n - < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Налады пошуку "" < / string > \n + < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Пошук налад "" < / string > \n packages \ SettingsLib \ SearchWidget \ res \ values - es - rUS \ strings . xml \n - < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Buscar en la configuración "" < / string > \n + < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Buscar configuraciones "" < / string > \n packages \ SettingsLib \ SearchWidget \ res \ values - fr - rCA \ strings . xml \n - < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Paramètres de recherche "" < / string > \n + < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" Rechercher dans les paramètres "" < / string > \n packages \ SettingsLib \ SearchWidget \ res \ values - hi \ strings . xml \n - < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" खोज की सेटिंग "" < / string > \n + < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" सेटिंग में खोजें "" < / string > \n packages \ SettingsLib \ SearchWidget \ res \ values - pa \ strings . xml \n - < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" ਖੋਜ ਸੈਟਿੰਗਾਂ "" < / string > \n + < string name = "" search _ menu "" msgid = "" 1914043873178389845 "" > "" ਸੈਟਿੰਗਾਂ ਵਿੱਚ ਖੋਜੋ "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I2d4513fe4279d504597bbcde3d658259264b6592,69
"packages \ overlays \ DisplayCutoutEmulationHoleOverlay \ res \ values - nl \ strings . xml \n - < string name = "" display _ cutout _ emulation _ overlay "" msgid = "" 7305489596221077240 "" > "" Punch Hole - cutout "" < / string > \n + < string name = "" display _ cutout _ emulation _ overlay "" msgid = "" 7305489596221077240 "" > "" Cameragat - cutout "" < / string > \n new file \n packages \ overlays \ DisplayCutoutEmulationHoleOverlay \ res \ values - ta \ strings . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" UTF - 8 "" ? > \n + < ! - - \n + ~ Copyright ( C ) 2020 The Android Open Source Project \n + ~ \n + ~ Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + ~ you may not use this file except in compliance with the License . \n + ~ You may obtain a copy of the License at \n + ~ \n + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + ~ \n + ~ Unless required by applicable law or agreed to in writing , software \n + ~ distributed under the License is distributed on an "" AS IS "" BASIS , \n + ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + ~ See the License for the specific language governing permissions and \n + ~ limitations under the License . \n + - - > \n + \n + < resources xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n + xmlns : xliff = "" urn : oasis : names : tc : xliff : document : 1 . 2 "" > \n + < string name = "" display _ cutout _ emulation _ overlay "" msgid = "" 7305489596221077240 "" > "" பஞ்ச் ஹோல் கட்அவுட் "" < / string > \n + < / resources > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I25ce3ce029fbbae4d511e0ed9a2e72f4717c0807,69
"packages \ SystemUI \ res \ values - ky - ldrtl \ strings . xml \n - < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" Колдонмолорду тез которуштуруу үчүн солго сүйрөңүз "" < / string > \n + < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" Колдонмолорду тез которуштуруу үчүн , солго сүйрөңүз "" < / string > \n packages \ SystemUI \ res \ values - ne - ldrtl \ strings . xml \n - < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" अनुप्रयोगहरू द्रुत गतिमा बदल्न बायाँतिर ड्र्याग गर्नुहोस् "" < / string > \n + < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" एपहरू द्रुत गतिमा बदल्न बायाँतिर ड्र्याग गर्नुहोस् "" < / string > \n packages \ SystemUI \ res \ values - pt - rPT - ldrtl \ strings . xml \n - < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" Arrastar para a esquerda para mudar rapidamente de aplicação "" < / string > \n + < string name = "" recents _ quick _ scrub _ onboarding "" msgid = "" 2452671841151577157 "" > "" Arrastar para a esquerda para mudar rapidamente de app "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I7869492af986dfc45138bee058954d5109c53087,69
"packages \ SystemUI \ res \ values - ar \ strings _ tv . xml \n - < string name = "" notification _ channel _ tv _ pip "" msgid = "" 844249465483874817 "" > "" صورة داخل صورة "" < / string > \n + < string name = "" notification _ channel _ tv _ pip "" msgid = "" 844249465483874817 "" > "" نافذة ضمن النافذة "" < / string > \n packages \ SystemUI \ res \ values - be \ strings _ tv . xml \n - < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" Ва ўвесь экран "" < / string > \n + < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" Поўнаэкранны рэжым "" < / string > \n packages \ SystemUI \ res \ values - ne \ strings _ tv . xml \n - < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" पूर्ण स्क्रिन "" < / string > \n + < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" फुल स्क्रिन "" < / string > \n packages \ SystemUI \ res \ values - te \ strings _ tv . xml \n - < string name = "" notification _ channel _ tv _ pip "" msgid = "" 844249465483874817 "" > "" చిత్రంలో చిత్రం "" < / string > \n + < string name = "" notification _ channel _ tv _ pip "" msgid = "" 844249465483874817 "" > "" పిక్చర్ - ఇన్ - పిక్చర్ "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I23b88c296c509967ddcb30371fa436803e5c5ac4,69
"packages \ SettingsLib \ res \ values - mn \ strings . xml \n - < string name = "" wifi _ disabled _ password _ failure "" msgid = "" 6892387079613226738 "" > "" Гэрчлэлийн асуудал "" < / string > \n + < string name = "" wifi _ disabled _ password _ failure "" msgid = "" 6892387079613226738 "" > "" Баталгаажуулалтын асуудал "" < / string > \n - < string name = "" user _ add _ user _ message _ long "" msgid = "" 1527434966294733380 "" > "" Та нэмэлт хэрэглэгч үүсгэх замаар бусад хүмүүстэй энэ төхөөрөмжийг хуваалцаж болно . Хэрэглэгч тус бүр апп , ханын цаас болон бусад зүйлээ өөрчлөх боломжтой хувийн орон зайтай байдаг . Түүнчлэн хэрэглэгч нь бүх хэрэглэгчид нөлөөлөх боломжтой Wi - Fi зэрэг төхөөрөмжийн тохиргоог өөрчлөх боломжтой . \ n \ nХэрэв та шинэ хэрэглэгч нэмэх бол тухайн хүн хувийн орон зайгаа бүрдүүлэх ёстой . \ n \ nХэрэглэгч бүр бусад бүх хэрэглэгчийн өмнөөс апп шинэчилж болно . Хүртээмжийн тохиргоо болон үйлчилгээг шинэ хэрэглэгчид шилжүүлэх боломжгүй байж болзошгүй . "" < / string > \n + < string name = "" user _ add _ user _ message _ long "" msgid = "" 1527434966294733380 "" > "" Та нэмэлт хэрэглэгч үүсгэх замаар бусад хүмүүстэй энэ төхөөрөмжийг хуваалцаж болно . Хэрэглэгч тус бүр апп , дэлгэцийн зураг болон бусад зүйлээ өөрчлөх боломжтой хувийн орон зайтай байдаг . Түүнчлэн хэрэглэгч нь бүх хэрэглэгчид нөлөөлөх боломжтой Wi - Fi зэрэг төхөөрөмжийн тохиргоог өөрчлөх боломжтой . \ n \ nХэрэв та шинэ хэрэглэгч нэмэх бол тухайн хүн хувийн орон зайгаа бүрдүүлэх ёстой . \ n \ nХэрэглэгч бүр бусад бүх хэрэглэгчийн өмнөөс апп шинэчилж болно . Хүртээмжийн тохиргоо болон үйлчилгээг шинэ хэрэглэгчид шилжүүлэх боломжгүй байж болзошгүй . "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I386b5ae57d12aa506287b53b11018a18d955d38a,69
"packages \ PrintSpooler \ res \ values - fr - rCA \ strings . xml \n + < item quantity = "" many "" > < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers found < / item > \n + < item quantity = "" many "" > Install to discover < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers < / item > \n packages \ PrintSpooler \ res \ values - fr \ strings . xml \n + < item quantity = "" many "" > < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers found < / item > \n + < item quantity = "" many "" > Install to discover < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers < / item > \n packages \ PrintSpooler \ res \ values - mk \ strings . xml \n - < string name = "" could _ not _ create _ file "" msgid = "" 3425025039427448443 "" > "" Не можеше да се создаде датотека "" < / string > \n + < string name = "" could _ not _ create _ file "" msgid = "" 3425025039427448443 "" > "" Не може да се создаде датотека "" < / string > \n - < string name = "" print _ write _ error _ message "" msgid = "" 5787642615179572543 "" > "" Не можеше да се напише во датотеката "" < / string > \n + < string name = "" print _ write _ error _ message "" msgid = "" 5787642615179572543 "" > "" Не може да се напише во датотеката "" < / string > \n packages \ PrintSpooler \ res \ values - mr \ strings . xml \n - < string name = "" could _ not _ create _ file "" msgid = "" 3425025039427448443 "" > "" फाईल तयार करणेे शक्य झाले नाही "" < / string > \n + < string name = "" could _ not _ create _ file "" msgid = "" 3425025039427448443 "" > "" फाइल तयार करणेे शक्य झाले नाही "" < / string > \n packages \ PrintSpooler \ res \ values - uz \ strings . xml \n - < item msgid = "" 3882302912790928315 "" > "" Yo‘q "" < / item > \n + < item msgid = "" 3882302912790928315 "" > "" Hech qanday "" < / item > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Ia3bb94a32d5771cdea8f7db17d480211a6b19c7a,69
"packages \ SoundPicker \ res \ values - kk \ strings . xml \n - < string name = "" add _ ringtone _ text "" msgid = "" 6642389991738337529 "" > "" Рингтон енгізу "" < / string > \n + < string name = "" add _ ringtone _ text "" msgid = "" 6642389991738337529 "" > "" Рингтон қосу "" < / string > \n packages \ SoundPicker \ res \ values - te \ strings . xml \n - < string name = "" notification _ sound _ default "" msgid = "" 8133121186242636840 "" > "" డిఫాల్ట్ నోటిఫికేషన్ ధ్వని "" < / string > \n - < string name = "" alarm _ sound _ default "" msgid = "" 4787646764557462649 "" > "" డిఫాల్ట్ అలారం ధ్వని "" < / string > \n + < string name = "" notification _ sound _ default "" msgid = "" 8133121186242636840 "" > "" నోటిఫికేషన్ ఆటోమేటిక్ సౌండ్ "" < / string > \n + < string name = "" alarm _ sound _ default "" msgid = "" 4787646764557462649 "" > "" అలారం ఆటోమేటిక్ సౌండ్ "" < / string > \n packages \ SoundPicker \ res \ values - uz \ strings . xml \n - < string name = "" add _ alarm _ text "" msgid = "" 3545497316166999225 "" > "" Signal qo‘shish "" < / string > \n - < string name = "" add _ notification _ text "" msgid = "" 4431129543300614788 "" > "" Bildirishnoma qo‘shish "" < / string > \n + < string name = "" add _ alarm _ text "" msgid = "" 3545497316166999225 "" > "" Signal kiritish "" < / string > \n + < string name = "" add _ notification _ text "" msgid = "" 4431129543300614788 "" > "" Bildirishnoma kiritish "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Id8abc8de6ceacef61c2bfcaa782578f58e65c3f9,69
"packages \ Shell \ res \ values - mk \ strings . xml \n - < string name = "" bugreport _ unreadable _ text "" msgid = "" 586517851044535486 "" > "" Датотеката со извештај за грешка не можеше да се прочита "" < / string > \n + < string name = "" bugreport _ unreadable _ text "" msgid = "" 586517851044535486 "" > "" Датотеката со извештај за грешка не може да се прочита "" < / string > \n packages \ Shell \ res \ values - mr \ strings . xml \n - < string name = "" bugreport _ unreadable _ text "" msgid = "" 586517851044535486 "" > "" बग रीपोर्ट फाईल वाचणे शक्य झाले नाही "" < / string > \n - < string name = "" bugreport _ add _ details _ to _ zip _ failed "" msgid = "" 1302931926486712371 "" > "" झिप फाईल मध्ये बग रीपोर्ट तपशील जोडणे शक्य झाले नाही "" < / string > \n + < string name = "" bugreport _ unreadable _ text "" msgid = "" 586517851044535486 "" > "" बग रीपोर्ट फाइल वाचणे शक्य झाले नाही "" < / string > \n + < string name = "" bugreport _ add _ details _ to _ zip _ failed "" msgid = "" 1302931926486712371 "" > "" झिप फाइल मध्ये बग रीपोर्ट तपशील जोडणे शक्य झाले नाही "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Id2c26adb70f2403ba0dfa3a0065be715825f9446,69
"packages \ SystemUI \ res \ values - be \ strings _ tv . xml \n - < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" Ва ўвесь экран "" < / string > \n + < string name = "" pip _ fullscreen "" msgid = "" 3877997489869475181 "" > "" Поўнаэкранны рэжым "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Ic063f3e903383708e3a80baa775902918b745729,69
"packages \ SettingsLib \ HelpUtils \ res \ values - ar \ strings . xml \n - < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" المساعدة والتعليقات "" < / string > \n + < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" المساعدة والملاحظات والآراء "" < / string > \n packages \ SettingsLib \ HelpUtils \ res \ values - es \ strings . xml \n - < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Ayuda y sugerencias "" < / string > \n + < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Ayuda y comentarios "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Ib0d95e6322e5f2cfbd63cabb37f45e2ee518d9de,69
"packages \ CarSystemUI \ res \ values - uz \ strings . xml \n - < string name = "" hvac _ min _ text "" msgid = "" 8167124789068494624 "" > "" Daq . "" < / string > \n + < string name = "" hvac _ min _ text "" msgid = "" 8167124789068494624 "" > "" Min "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I8c34d4e1656d948c367a5bedfce52e10026c9729,69
"packages \ PrintSpooler \ res \ values - fr - rCA \ strings . xml \n - < item quantity = "" many "" > < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers found < / item > \n - < item quantity = "" many "" > Install to discover < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers < / item > \n packages \ PrintSpooler \ res \ values - fr \ strings . xml \n - < item quantity = "" many "" > < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers found < / item > \n - < item quantity = "" many "" > Install to discover < xliff : g id = "" COUNT _ 1 "" > % 1 $ s < / xliff : g > printers < / item > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Ia93ade3e9cbbd9356ca42a5448022b70dc4b66b3,69
"packages \ SettingsLib \ HelpUtils \ res \ values - uz \ strings . xml \n - < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Yordam va fikr - mulohaza "" < / string > \n + < string name = "" help _ feedback _ label "" msgid = "" 7106780063063027882 "" > "" Yordam / fikr - mulohaza "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : I794414b55fdf3199567ae41122969e18615abbd0,69
"packages \ SettingsProvider \ res \ values - iw \ strings . xml \n - < string name = "" wifi _ softap _ config _ change "" msgid = "" 5688373762357941645 "" > "" ההגדרות של הנקודה לשיתוף אינטרנט השתנו "" < / string > \n + < string name = "" wifi _ softap _ config _ change "" msgid = "" 5688373762357941645 "" > "" ‏הגדרות נקודת האינטרנט ( hotspot ) השתנו "" < / string > \n",Import translations . DO NOT MERGE ANYWHERE \n Auto - generated - cl : translation import \n Change - Id : Ib708925798cc05fdd16ef5a7e21c763136dd5895,69
"src \ main \ java \ org \ junit \ internal \ runners \ JUnit38ClassRunner . java \n + import java . lang . annotation . Annotation ; \n + import java . lang . reflect . Method ; \n - return Description . createTestDescription ( tc . getClass ( ) , tc . getName ( ) ) ; \n + return Description . createTestDescription ( tc . getClass ( ) , tc . getName ( ) , \n + getAnnotations ( tc ) ) ; \n + / * * \n + * Get the annotations associated with given TestCase . \n + * @ param test \n + * @ return \n + * / \n + private static Annotation [ ] getAnnotations ( TestCase test ) { \n + try { \n + Method m = test . getClass ( ) . getDeclaredMethod ( test . getName ( ) ) ; \n + return m . getDeclaredAnnotations ( ) ; \n + } catch ( SecurityException e ) { \n + } catch ( NoSuchMethodException e ) { \n + } \n + return new Annotation [ 0 ] ; \n + } \n + \n",Collect annotations for JUnit3 tests . \n Necessary to support test filtering by annotation .,72
src \ test \ java \ org \ junit \ tests \ junit3compatibility \ JUnit38ClassRunnerTest . java \n - public static class RejectAllFilter extends Filter { \n + public static class RejectAllTestsFilter extends Filter { \n - if ( description . isTest ( ) ) { \n - return false ; \n - } \n - return true ; \n + return description . isSuite ( ) ; \n - runner . filter ( new RejectAllFilter ( ) ) ; \n + runner . filter ( new RejectAllTestsFilter ( ) ) ; \n,Fix code review comments : Rename to RejectAllTestsFilter and use description . isSuite ( ),72
src \ main \ java \ org \ junit \ internal \ runners \ JUnit38ClassRunner . java \n - Method m = test . getClass ( ) . getDeclaredMethod ( test . getName ( ) ) ; \n + Method m = test . getClass ( ) . getMethod ( test . getName ( ) ) ; \n src \ test \ java \ org \ junit \ tests \ junit3compatibility \ JUnit38ClassRunnerTest . java \n + public static class DerivedAnnotatedMethod extends JUnit3ClassWithAnnotatedMethod { \n + } \n + \n + assertAnnotationFiltering ( runner ) ; \n + } \n + \n + @ Test \n + public void getDescriptionWithAnnotationInSuper ( ) { \n + JUnit38ClassRunner runner = new JUnit38ClassRunner ( DerivedAnnotatedMethod . class ) ; \n + assertAnnotationFiltering ( runner ) ; \n + } \n + \n + private void assertAnnotationFiltering ( JUnit38ClassRunner runner ) { \n,Fix annotation collection from super classes of JUnit3 tests .,72
"src \ main \ java \ org \ junit \ internal \ runners \ JUnit38ClassRunner . java \n + if ( filtered . testCount ( ) = = 0 ) { \n + throw new NoTestsRemainException ( ) ; \n + } \n src \ test \ java \ org \ junit \ tests \ junit3compatibility \ JUnit38ClassRunnerTest . java \n + import org . junit . runner . manipulation . Filter ; \n + import org . junit . runner . manipulation . NoTestsRemainException ; \n + \n + public static class RejectAllFilter extends Filter { \n + @ Override \n + public boolean shouldRun ( Description description ) { \n + return false ; \n + } \n + \n + @ Override \n + public String describe ( ) { \n + return "" filter all "" ; \n + } \n + } \n + \n + / * * \n + * Test that NoTestsRemainException is thrown when all methods have been filtered . \n + * / \n + @ Test ( expected = NoTestsRemainException . class ) \n + public void filter _ noTestsRemain ( ) throws NoTestsRemainException { \n + JUnit38ClassRunner runner = new JUnit38ClassRunner ( OneTest . class ) ; \n + runner . filter ( new RejectAllFilter ( ) ) ; \n + } \n",Properly handle case where filter removes all JUnit3 tests in suite .,72
"src \ main \ java \ org \ junit \ internal \ runners \ JUnit38ClassRunner . java \n + if ( filtered . testCount ( ) = = 0 ) { \n + throw new NoTestsRemainException ( ) ; \n + } \n src \ test \ java \ org \ junit \ tests \ junit3compatibility \ JUnit38ClassRunnerTest . java \n + import org . junit . runner . manipulation . Filter ; \n + import org . junit . runner . manipulation . NoTestsRemainException ; \n + \n + public static class RejectAllFilter extends Filter { \n + @ Override \n + public boolean shouldRun ( Description description ) { \n + return false ; \n + } \n + \n + @ Override \n + public String describe ( ) { \n + return "" filter all "" ; \n + } \n + } \n + \n + / * * \n + * Test that NoTestsRemainException is thrown when description is returned when all methods \n + * have been filtered . \n + * / \n + @ Test ( expected = NoTestsRemainException . class ) \n + public void filter _ noTestsRemain ( ) throws NoTestsRemainException { \n + JUnit38ClassRunner runner = new JUnit38ClassRunner ( OneTest . class ) ; \n + runner . filter ( new RejectAllFilter ( ) ) ; \n + } \n",Properly handle case where filter removes all JUnit3 tests in suite .,72
src \ test \ java \ org \ junit \ tests \ junit3compatibility \ JUnit38ClassRunnerTest . java \n - return false ; \n + if ( description . isTest ( ) ) { \n + return false ; \n + } \n + return true ; \n,Change RejectAllTestsFilter to only reject atomic tests .,72
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ HttpClientUpgradeHandler . java \n - request . headers ( ) . set ( HttpHeaderNames . CONNECTION , builder . toString ( ) ) ; \n + request . headers ( ) . add ( HttpHeaderNames . CONNECTION , builder . toString ( ) ) ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpClientUpgradeHandlerTest . java \n + import java . util . List ; \n + \n + @ Test \n + public void dontStripConnectionHeaders ( ) { \n + HttpClientUpgradeHandler . SourceCodec sourceCodec = new FakeSourceCodec ( ) ; \n + HttpClientUpgradeHandler . UpgradeCodec upgradeCodec = new FakeUpgradeCodec ( ) ; \n + HttpClientUpgradeHandler handler = new HttpClientUpgradeHandler ( sourceCodec , upgradeCodec , 1024 ) ; \n + UserEventCatcher catcher = new UserEventCatcher ( ) ; \n + EmbeddedChannel channel = new EmbeddedChannel ( catcher ) ; \n + channel . pipeline ( ) . addFirst ( "" upgrade "" , handler ) ; \n + \n + DefaultFullHttpRequest request = new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . GET , "" netty . io "" ) ; \n + request . headers ( ) . add ( "" connection "" , "" extra "" ) ; \n + request . headers ( ) . add ( "" extra "" , "" value "" ) ; \n + assertTrue ( channel . writeOutbound ( request ) ) ; \n + FullHttpRequest readRequest = channel . readOutbound ( ) ; \n + \n + List < String > connectionHeaders = readRequest . headers ( ) . getAll ( "" connection "" ) ; \n + assertTrue ( connectionHeaders . contains ( "" extra "" ) ) ; \n + assertTrue ( readRequest . release ( ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n","Don ' t replace all ' connection ' headers when sending h2c upgrade request ( # 7824 ) \n Motivation : \n There may be meaningful ' connection ' headers that exist on a request \n that is used to attempt a HTTP / 1 . x upgrade request that will be \n clobbered . \n Modifications : \n HttpClientUpgradeHandler uses the ` HttpHeaders . add ` instead of \n ` HttpHeaders . set ` when adding the ' upgrade ' field . \n Result : \n Fixes # 7823 , existing ' connection ' headers are preserved .",76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n + } else { \n + / / Send any other frames down the pipeline \n + ctx . fireChannelRead ( frame ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecTest . java \n + @ Test \n + public void unhandledHttp2FramesShouldBePropagated ( ) { \n + ByteBuf content = UnpooledByteBufAllocator . DEFAULT . buffer ( 8 ) . writeLong ( 0 ) ; \n + Http2PingFrame decodedFrame = new DefaultHttp2PingFrame ( content ) ; \n + \n + codec . onHttp2Frame ( decodedFrame ) ; \n + Http2PingFrame receivedPing = parentChannel . readInbound ( ) ; \n + assertSame ( receivedPing , decodedFrame ) ; \n + assertTrue ( receivedPing . release ( ) ) ; \n + } \n + \n","Http2MultiplexCodec should propagate unhandled Http2Frames down the pipeline \n Motivation : \n Http2MultiplexCodec swallows Http2PingFrames without releasing the payload , resulting in a memory leak . \n Modification : \n Send unhandled frames down the pipeline for consumption / disposal by another InboundChannelHandler . \n Result : \n Fixes # 7607 .",76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2Connection . java \n + \n + / / If the stream is opened in a half - closed state , the headers must have either \n + / / been sent if this is a local stream , or received if it is a remote stream . \n + if ( state = = HALF _ CLOSED _ LOCAL ) { \n + headersSent ( / * isInformational * / false ) ; \n + } else if ( state = = HALF _ CLOSED _ REMOTE ) { \n + headersReceived ( / * isInformational * / false ) ; \n + } \n codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2Stream . java \n - * is { @ code true } and the stream is local . < / li > \n + * is { @ code true } and the stream is local . In this state , { @ link # isHeadersSent ( ) } is { @ code true } < / li > \n - * is { @ code true } and the stream is remote . < / li > \n + * is { @ code true } and the stream is remote . In this state , { @ link # isHeadersReceived ( ) } is { @ code true } < / li > \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2ConnectionTest . java \n + assertTrue ( stream . isHeadersReceived ( ) ) ; \n + assertTrue ( stream . isHeadersSent ( ) ) ; \n","Motivation : ( # 7848 ) \n It is possible to create streams in the half - closed state where the \n stream state doesn ' t reflect that the request headers have been sent by \n the client or the server hasn ' t received the request headers . This \n state isn ' t possible in the H2 spec as a half closed stream must have \n either received a full request or have received the headers from a \n pushed stream . In the current implementation , this can cause the stream \n created as part of an h2c upgrade request to be in this invalid state \n and result in the omission of RST frames as the client doesn ' t believe \n it has sent the request to begin with . \n Modification : \n The ` DefaultHttp2Connection . activate ` method checks the state and \n modifies the status of the request headers as appropriate . \n Result : \n Fixes # 7847 .",76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - / / Some transports like local and AIO does not allow the deregistration of \n - / / an open channel . Their doDeregister ( ) calls close ( ) . Consequently , \n - / / close ( ) calls deregister ( ) again - no need to fire channelUnregistered , so check \n - / / if it was registered . \n + / / The user can fire ` deregister ` events multiple times but we only want to fire the pipeline \n + / / event if the channel was actually registered . \n - } else { \n - promise . setFailure ( new IllegalStateException ( "" Not registered "" ) ) ; \n","Don ' t fail the deregistration promise in Http2MultiplexCodec \n Motivation : \n We deviate from the AbstractChannel implementation on deregistration by \n failing the provided promise if the channel is already deregistered . In \n contrast , AbstractChannel will always set the promise to successfully \n done . \n Modification : \n Change the \n Http2MultiplexCodec . DefaultHttp2StreamChannel . Http2ChannelUnsafe to \n always set the promise provided to deregister as done as is the \n case in AbstractChannel .",76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - promise . setFailure ( wrapStreamClosedError ( cause ) ) ; \n + promise . setFailure ( wrapStreamClosedError ( cause ) ) ; \n - promise . setFailure ( error ) ; \n - \n + promise . setFailure ( error ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecTest . java \n + import java . util . ArrayDeque ; \n + import java . util . Queue ; \n + import io . netty . util . ReferenceCountUtil ; \n + assertFalse ( channelActive . get ( ) ) ; \n + assertFalse ( channelActive . get ( ) ) ; \n + assertFalse ( childChannel . isActive ( ) ) ; \n + } \n + \n + @ Test \n + public void channelClosedWhenWriteFutureFails ( ) { \n + final Queue < ChannelPromise > writePromises = new ArrayDeque < ChannelPromise > ( ) ; \n + writer = new Writer ( ) { \n + @ Override \n + void write ( Object msg , ChannelPromise promise ) { \n + ReferenceCountUtil . release ( msg ) ; \n + writePromises . offer ( promise ) ; \n + } \n + } ; \n + \n + LastInboundHandler inboundHandler = streamActiveAndWriteHeaders ( inboundStream ) ; \n + Http2StreamChannel childChannel = ( Http2StreamChannel ) inboundHandler . channel ( ) ; \n + \n + assertTrue ( childChannel . isOpen ( ) ) ; \n + assertTrue ( childChannel . isActive ( ) ) ; \n + \n + final AtomicBoolean channelOpen = new AtomicBoolean ( true ) ; \n + final AtomicBoolean channelActive = new AtomicBoolean ( true ) ; \n + \n + ChannelFuture f = childChannel . writeAndFlush ( new DefaultHttp2HeadersFrame ( new DefaultHttp2Headers ( ) ) ) ; \n + assertFalse ( f . isDone ( ) ) ; \n + f . addListener ( new ChannelFutureListener ( ) { \n + @ Override \n + public void operationComplete ( ChannelFuture future ) throws Exception { \n + channelOpen . set ( future . channel ( ) . isOpen ( ) ) ; \n + channelActive . set ( future . channel ( ) . isActive ( ) ) ; \n + } \n + } ) ; \n + \n + ChannelPromise first = writePromises . poll ( ) ; \n + first . setFailure ( new ClosedChannelException ( ) ) ; \n + f . awaitUninterruptibly ( ) ; \n + \n + assertFalse ( channelOpen . get ( ) ) ; \n + assertFalse ( channelActive . get ( ) ) ; \n","Reorder channel state changes in Http2MultiplexCodec child channel \n Motivation : \n If a write fails for a Http2MultiplexChannel stream channel , the channel \n may be forcibly closed , but only after the promise has been failed . That \n means continuations attached to the promise may see the channel in an \n inconsistent state of still being open and active . \n Modifications : \n Move the satisfaction of the promise to after the channel cleanup logic \n runs . \n Result : \n Listeners attached to the future that resulted in a Failed write will \n see the stream channel in the correct state .",76
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2CodecUtil . java \n - private static final ByteBuf EMPTY _ PING = \n - unreleasableBuffer ( directBuffer ( PING _ FRAME _ PAYLOAD _ LENGTH ) . writeZero ( PING _ FRAME _ PAYLOAD _ LENGTH ) ) \n - . asReadOnly ( ) ; \n - / * * \n - * Returns a buffer filled with all zeros that is the appropriate length for a PING frame . \n - * / \n - public static ByteBuf emptyPingBuf ( ) { \n - / / Return a duplicate so that modifications to the reader index will not affect the original buffer . \n - return EMPTY _ PING . retainedDuplicate ( ) ; \n - } \n - \n,Remove dead code in Http2CodecUtil ( # 8009 ) \n Motivation : \n The ` ByteBuffer emptyPingBuf ( ) ` method of Http2CodecUtils is has been dead \n code since DefaultHttp2PingFrame switched from using a ByteBuf to represent \n the 8 octets to a long . \n Modifications : \n Remove the method and the unused static ByteBuf . \n Result : \n Less dead code . \n Fixes # 8002,76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2ConnectionDecoder . java \n - logger . info ( "" { } ignoring { } frame for stream { } { } "" , ctx . channel ( ) , frameName , \n + logger . info ( "" { } ignoring { } frame for stream { } "" , ctx . channel ( ) , frameName , \n",Remove uninterpolated ` { } ` in DefaultHttp2ConnectionDecoder log message ( # 8441 ) \n Motivation : \n There are log messages emitted from Http2ConnectionDecoder of the form \n ` ` ` \n INF i . n . h . c . h . DefaultHttp2ConnectionDecoder ignoring HEADERS frame for stream RST _ STREAM sent . { } \n ` ` ` \n Modifications : \n Remove the trailing ` { } ` in the log message that doesn ' t have a value . \n Result : \n Log messages no longer have a trailing ` { } ` .,76
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n + parentContext . release ( ) ; \n + private final ReferenceCountedOpenSslContext parentContext ; \n + / / Now that everything looks good and we ' re going to successfully return the \n + / / object so we need to retain a reference to the parent context . \n + parentContext = context ; \n + parentContext . retain ( ) ; \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngineTest . java \n + import io . netty . buffer . UnpooledByteBufAllocator ; \n + import static junit . framework . TestCase . * ; \n + \n + \n + @ Test \n + public void parentContextIsRetainedByChildEngines ( ) throws Exception { \n + SslContext clientSslCtx = SslContextBuilder . forClient ( ) \n + . trustManager ( InsecureTrustManagerFactory . INSTANCE ) \n + . sslProvider ( sslClientProvider ( ) ) \n + . protocols ( protocols ( ) ) \n + . ciphers ( ciphers ( ) ) \n + . build ( ) ; \n + \n + SSLEngine engine = clientSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + assertEquals ( ReferenceCountUtil . refCnt ( clientSslCtx ) , 2 ) ; \n + \n + cleanupClientSslContext ( clientSslCtx ) ; \n + assertEquals ( ReferenceCountUtil . refCnt ( clientSslCtx ) , 1 ) ; \n + \n + cleanupClientSslEngine ( engine ) ; \n + assertEquals ( ReferenceCountUtil . refCnt ( clientSslCtx ) , 0 ) ; \n + } \n","Reference - counted SslEngines retain a reference to their parent SslContext ( # 9626 ) \n Motivation : \n With the Netty ref - counted OpenSSL implementation the parent SslContext \n maintains state necessary for the SslEngine ' s it produces . However , it ' s \n possible for the parent context to be closed and release those resources \n before the child engines are finished which causes problems . \n Modification : \n Spawned ReferenceCountedOpenSslEngine ' s retain a reference to their \n parent ReferenceCountedOpenSslContext . \n Result : \n The lifetime of the shared data is extended to include the lifetime of \n the dependents .",76
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ AbstractHttp2StreamChannel . java \n - ( message = inboundBuffer . poll ( ) ) ! = null ) ; \n + inboundBuffer ! = null & & ( message = inboundBuffer . poll ( ) ) ! = null ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexTest . java \n + @ Test \n + public void channelReadShouldRespectAutoReadAndNotProduceNPE ( ) throws Exception { \n + LastInboundHandler inboundHandler = new LastInboundHandler ( ) ; \n + Http2StreamChannel childChannel = newInboundStream ( 3 , false , inboundHandler ) ; \n + assertTrue ( childChannel . config ( ) . isAutoRead ( ) ) ; \n + Http2HeadersFrame headersFrame = inboundHandler . readInbound ( ) ; \n + assertNotNull ( headersFrame ) ; \n + \n + childChannel . config ( ) . setAutoRead ( false ) ; \n + childChannel . pipeline ( ) . addFirst ( new ChannelInboundHandlerAdapter ( ) { \n + private int count ; \n + @ Override \n + public void channelRead ( ChannelHandlerContext ctx , Object msg ) throws Exception { \n + ctx . fireChannelRead ( msg ) ; \n + / / Close channel after 2 reads so there is still something in the inboundBuffer when the close happens . \n + if ( + + count = = 2 ) { \n + ctx . close ( ) ; \n + } \n + } \n + } ) ; \n + frameInboundWriter . writeInboundData ( childChannel . stream ( ) . id ( ) , bb ( "" hello world "" ) , 0 , false ) ; \n + Http2DataFrame dataFrame0 = inboundHandler . readInbound ( ) ; \n + assertNotNull ( dataFrame0 ) ; \n + release ( dataFrame0 ) ; \n + \n + frameInboundWriter . writeInboundData ( childChannel . stream ( ) . id ( ) , bb ( "" foo "" ) , 0 , false ) ; \n + frameInboundWriter . writeInboundData ( childChannel . stream ( ) . id ( ) , bb ( "" bar "" ) , 0 , false ) ; \n + frameInboundWriter . writeInboundData ( childChannel . stream ( ) . id ( ) , bb ( "" bar "" ) , 0 , false ) ; \n + \n + assertNull ( inboundHandler . readInbound ( ) ) ; \n + \n + childChannel . config ( ) . setAutoRead ( true ) ; \n + verifyFramesMultiplexedToCorrectChannel ( childChannel , inboundHandler , 3 ) ; \n + inboundHandler . checkException ( ) ; \n + } \n + \n",Fix an NPE in AbstractHttp2StreamChannel ( # 9379 ) \n Motivation : \n If a read triggers a AbstractHttp2StreamChannel to close we can \n get an NPE in the read loop . \n Modifications : \n Make sure that the inboundBuffer isn ' t null before attempting to \n continue the loop . \n Result : \n No NPE . \n Fixes # 9337,76
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamChannelBootstrap . java \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n,"Support cancellation in the Http2StreamChannelBootstrap ( # 9519 ) \n Motivation : \n Right now you can cancel the Future returned by \n ` Http2StreamChannelBootstrap . open ( ) ` and that will race with the \n registration of the stream channel with the event loop , potentially \n culminating in an ` IllegalStateException ` and potential resource leak . \n Modification : \n Ensure that the returned promise is uncancellable . \n Result : \n Should no longer see ` IllegalStateException ` s .",76
"buffer \ src \ main \ java \ io \ netty \ buffer \ PoolThreadCache . java \n + maxCachedBufferCapacity + "" ( expected : > = 0 ) "" ) ; \n - if ( freeSweepAllocationThreshold < 1 ) { \n - throw new IllegalArgumentException ( "" freeSweepAllocationThreshold : "" \n - + freeSweepAllocationThreshold + "" ( expected : > 0 ) "" ) ; \n - } \n + / / Only check freeSweepAllocationThreshold when there are caches in use . \n + if ( freeSweepAllocationThreshold < 1 ) { \n + throw new IllegalArgumentException ( "" freeSweepAllocationThreshold : "" \n + + freeSweepAllocationThreshold + "" ( expected : > 0 ) "" ) ; \n + } \n - if ( cacheSize > 0 ) { \n + if ( cacheSize > 0 & & numCaches > 0 ) { \n - if ( cacheSize > 0 ) { \n + if ( cacheSize > 0 & & maxCachedBufferCapacity > 0 ) { \n buffer \ src \ test \ java \ io \ netty \ buffer \ PooledByteBufAllocatorTest . java \n + @ Test \n + public void testWithoutUseCacheForAllThreads ( ) { \n + assertFalse ( Thread . currentThread ( ) instanceof FastThreadLocalThread ) ; \n + \n + PooledByteBufAllocator pool = new PooledByteBufAllocator ( \n + / * preferDirect = * / false , \n + / * nHeapArena = * / 1 , \n + / * nDirectArena = * / 1 , \n + / * pageSize = * / 8192 , \n + / * maxOrder = * / 11 , \n + / * tinyCacheSize = * / 0 , \n + / * smallCacheSize = * / 0 , \n + / * normalCacheSize = * / 0 , \n + / * useCacheForAllThreads = * / false ) ; \n + ByteBuf buf = pool . buffer ( 1 ) ; \n + buf . release ( ) ; \n + } \n + \n","Enable PooledByteBufAllocator to work , event without a cache \n Motivation : \n ` useCacheForAllThreads ` may be false which disables memory caching \n on non netty threads . Setting this argument or the system property \n makes it impossible to use ` PooledByteBufAllocator ` . \n Modifications : \n Delayed the check of ` freeSweepAllocationThreshold ` in \n ` PoolThreadCache ` to after it knows there will be any caches in \n use . Additionally , check if the caches will have any data in them \n ( rather than allocating a 0 - length array ) . \n A test case is also added that fails without this change . \n Results : \n Fixes # 7194",77
transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollEventLoopGroup . java \n - static { \n - / / Ensure JNI is initialized by the time this class is loaded by this time ! \n + { \n + / / Ensure JNI is initialized by the time this class is loaded . \n - Epoll . ensureAvailability ( ) ; \n - Epoll . ensureAvailability ( ) ; \n - Epoll . ensureAvailability ( ) ; \n - Epoll . ensureAvailability ( ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ KQueueEventLoopGroup . java \n - static { \n + { \n,"Unify { Epoll , KQueue } EventLoopGroup initialization . \n Motivation : \n ` Epoll . ensureAvailability ( ) ` is called multiple times , once in \n static initialization and in a couple of the constructors . This is \n redundant and confusing to read . \n Modifications : \n Move ` Epoll . ensureAvailability ( ) ` call into an instance initializer \n and remove all other references . This ensures that every EELG \n checks availability , while still delaying the check until \n construction . This pattern is used when there are multiple ctors , \n as in this class . \n Result : \n Easier to read code .",77
"transport \ src \ main \ java \ io \ netty \ channel \ DelegatingChannelPromiseNotifier . java \n - public ChannelPromise addListeners ( GenericFutureListener < ? extends Future < ? super Void > > [ ] listeners ) { \n + public ChannelPromise addListeners ( GenericFutureListener < ? extends Future < ? super Void > > . . . listeners ) { \n - public ChannelPromise removeListeners ( GenericFutureListener < ? extends Future < ? super Void > > [ ] listeners ) { \n + public ChannelPromise removeListeners ( GenericFutureListener < ? extends Future < ? super Void > > . . . listeners ) { \n new file \n transport \ src \ test \ java \ io \ netty \ channel \ DelegatingChannelPromiseNotifierTest . java \n + / * \n + * Copyright 2017 The Netty Project \n + * \n + * The Netty Project licenses this file to you under the Apache License , \n + * version 2 . 0 ( the "" License "" ) ; you may not use this file except in compliance \n + * with the License . You may obtain a copy of the License at : \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , WITHOUT \n + * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the \n + * License for the specific language governing permissions and limitations \n + * under the License . \n + * / \n + package io . netty . channel ; \n + \n + import io . netty . util . concurrent . Future ; \n + import io . netty . util . concurrent . GenericFutureListener ; \n + import org . junit . Test ; \n + import org . mockito . Mockito ; \n + \n + import static org . junit . Assert . * ; \n + \n + public class DelegatingChannelPromiseNotifierTest { \n + @ Test \n + public void varargsNotifiersAllowed ( ) { \n + ChannelPromise promise = Mockito . mock ( ChannelPromise . class ) ; \n + DelegatingChannelPromiseNotifier promiseNotifier = new DelegatingChannelPromiseNotifier ( promise ) ; \n + \n + GenericFutureListener < ? extends Future < ? super Void > > gfl = \n + ( GenericFutureListener < ? extends Future < ? super Void > > ) Mockito . mock ( GenericFutureListener . class ) ; \n + promiseNotifier . addListeners ( gfl ) ; \n + promiseNotifier . removeListeners ( gfl ) ; \n + \n + Mockito . verify ( promise ) . addListeners ( gfl ) ; \n + Mockito . verify ( promise ) . removeListeners ( gfl ) ; \n + } \n + } \n","Make DelegatingChannelPromiseNotifier use Vararg overload \n Motivation : \n ErrorProne complains that the array override doesn ' t match the \n vararg super call . See http : / / errorprone . info / bugpattern / Overrides \n Additionally , almost every other Future uses the vararg form , so \n it would be stylistically consistent to keep it that way . \n Modifications : \n Use vararg override . \n Result : \n Cleaner , less naggy code .",77
transport - native - epoll \ src \ main \ c \ netty _ epoll _ native . c \n - # ifndef NETTY _ NOT _ DYNAMIC \n + # ifndef NETTY _ BUILD _ STATIC \n - # endif / * NETTY _ NOT _ DYNAMIC * / \n + # endif / * NETTY _ BUILD _ STATIC * / \n + # ifndef NETTY _ BUILD _ STATIC \n + # endif / * NETTY _ BUILD _ STATIC * / \n + # ifndef NETTY _ BUILD _ STATIC \n + # endif / * NETTY _ BUILD _ STATIC * / \n transport - native - kqueue \ src \ main \ c \ netty _ kqueue _ native . c \n - # ifndef NETTY _ NOT _ DYNAMIC \n + # ifndef NETTY _ BUILD _ STATIC \n - # endif / * NETTY _ NOT _ DYNAMIC * / \n + # endif / * NETTY _ BUILD _ STATIC * / \n + # ifndef NETTY _ BUILD _ STATIC \n + # endif / * NETTY _ BUILD _ STATIC * / \n + # ifndef NETTY _ BUILD _ STATIC \n + # endif / * NETTY _ BUILD _ STATIC * / \n,"Do not define JNI _ OnLoad when not dynamic \n Motivation : \n Due to an oversight ( by myself ) , linking two JNI modules with \n duplicate symbols fails in linking . This only seems to happen \n some of the time ( the behavior seems to be different between GCC \n and Clang toolchains ) . For instance , including both netty tcnative \n and netty epoll fails to link because of duplicate JNI _ OnLoad \n symobols . \n Modification : \n Do not define the JNI _ OnLoad and JNI _ OnUnload symbols when \n compiling for static linkage , as indicated by the NETTY _ BUILD _ STATIC \n preprocessor define . They are never directly called when \n statically linked . \n Result : \n Able to statically compile epoll and tcnative code into a single \n binary .",77
codec \ src \ main \ java \ io \ netty \ handler \ codec \ protobuf \ ProtobufDecoderNano . java \n - MessageNano prototype = clazz . newInstance ( ) ; \n + MessageNano prototype = clazz . getConstructor ( ) . newInstance ( ) ; \n transport - udt \ src \ test \ java \ io \ netty \ test \ udt \ util \ CaliperRunner . java \n - final CaliperBench booter = klaz . newInstance ( ) ; \n + final CaliperBench booter = klaz . getConstructor ( ) . newInstance ( ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ ReflectiveChannelFactory . java \n - return clazz . newInstance ( ) ; \n + return clazz . getConstructor ( ) . newInstance ( ) ; \n,"Use Constructor for reflective class instantiation . \n Motivation : \n Calling ` newInstance ( ) ` on a Class object can bypass compile time \n checked Exception propagation . This is noted in Java Puzzlers , \n as well as in ErrorProne : \n http : / / errorprone . info / bugpattern / ClassNewInstance \n Modifications : \n Use the niladic constructor to create a new instance . \n Result : \n Compile time safety for checked exceptions",77
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ native . c \n - jint JNI _ OnLoad ( JavaVM * vm , void * reserved ) { \n + JNIEXPORT jint JNI _ OnLoad ( JavaVM * vm , void * reserved ) { \n - void JNI _ OnUnload ( JavaVM * vm , void * reserved ) { \n + JNIEXPORT void JNI _ OnUnload ( JavaVM * vm , void * reserved ) { \n transport - native - kqueue \ src \ main \ c \ netty _ kqueue _ native . c \n - jint JNI _ OnLoad ( JavaVM * vm , void * reserved ) { \n + JNIEXPORT jint JNI _ OnLoad ( JavaVM * vm , void * reserved ) { \n - void JNI _ OnUnload ( JavaVM * vm , void * reserved ) { \n + JNIEXPORT void JNI _ OnUnload ( JavaVM * vm , void * reserved ) { \n","Include JNIEXPORT on exported symbols \n Motivation : \n As noticed in https : / / stackoverflow . com / questions / 45700277 / \n compilation can fail if the definition of a method doesn ' t \n match the declaration . It ' s easy enough to add this in , and make \n it easy to compile . \n Modifications : \n Add JNIEXPORT to the entry points . \n * On Windows this adds : ` _ _ declspec ( dllexport ) ` \n * On Mac this adds : ` _ _ attribute _ _ ( ( visibility ( "" default "" ) ) ) ` \n * On Linux ( GCC 4 . 2 + ) this adds : ` _ _ attribute _ _ ( ( visibility ( "" default "" ) ) ) ` \n * On other it doesn ' t add anything . \n Result : \n Easier compilation",77
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + / * * \n + * Return the reason ( if any ) why { @ code sun . misc . Unsafe } was not available . \n + * / \n + public static Throwable getUnsafeUnavailabilityCause ( ) { \n + return PlatformDependent0 . getUnsafeUnavailabilityCause ( ) ; \n + } \n + \n - } catch ( Throwable ignored ) { \n + } catch ( Throwable t ) { \n + logger . trace ( "" Could not determine if Unsafe is available "" , t ) ; \n common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n + private static final Throwable UNSAFE _ UNAVAILABILITY _ CAUSE ; \n + Throwable unsafeUnavailabilityCause = null ; \n + unsafeUnavailabilityCause = new UnsupportedOperationException ( "" Unsafe explicitly disabled "" ) ; \n - if ( maybeUnsafe instanceof Exception ) { \n + if ( maybeUnsafe instanceof Throwable ) { \n - logger . debug ( "" sun . misc . Unsafe . theUnsafe : unavailable "" , ( Exception ) maybeUnsafe ) ; \n + unsafeUnavailabilityCause = ( Throwable ) maybeUnsafe ; \n + logger . debug ( "" sun . misc . Unsafe . theUnsafe : unavailable "" , ( Throwable ) maybeUnsafe ) ; \n + unsafeUnavailabilityCause = ( Throwable ) maybeException ; \n + unsafeUnavailabilityCause = ( Throwable ) maybeAddressField ; \n + unsafeUnavailabilityCause = new UnsupportedOperationException ( "" Unexpected unsafe . arrayIndexScale "" ) ; \n + UNSAFE _ UNAVAILABILITY _ CAUSE = unsafeUnavailabilityCause ; \n + static Throwable getUnsafeUnavailabilityCause ( ) { \n + return UNSAFE _ UNAVAILABILITY _ CAUSE ; \n + } \n + \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ Epoll . java \n - UNAVAILABILITY _ CAUSE = PlatformDependent . hasUnsafe ( ) ? null : \n - new IllegalStateException ( "" sun . misc . Unsafe not available "" ) ; \n + UNAVAILABILITY _ CAUSE = PlatformDependent . hasUnsafe ( ) \n + ? null \n + : new IllegalStateException ( \n + "" sun . misc . Unsafe not available "" , \n + PlatformDependent . getUnsafeUnavailabilityCause ( ) ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ KQueue . java \n - UNAVAILABILITY _ CAUSE = PlatformDependent . hasUnsafe ( ) ? null : \n - new IllegalStateException ( "" sun . misc . Unsafe not available "" ) ; \n + UNAVAILABILITY _ CAUSE = PlatformDependent . hasUnsafe ( ) \n + ? null \n + : new IllegalStateException ( \n + "" sun . misc . Unsafe not available "" , \n + PlatformDependent . getUnsafeUnavailabilityCause ( ) ) ; \n","Include more detail why Unsafe is not available \n Motivation : \n PD and PD0 Both try to find and use Unsafe . If unavailable , they \n try to log why and continue on . However , it is not always east to \n enable this logging . Chaining exceptions together is much easier \n to reach , and the original exception is relevant when Unsafe is \n needed . \n Modifications : \n * Make PD log why PD0 could not be loaded with a trace level log \n * Make PD0 remember why Unsafe wasn ' t available \n * Expose unavailability cause through PD for higher level use . \n * Make Epoll and KQueue include the reason when failing \n Result : \n Easier debugging in hard to reconfigure environments",77
"buffer \ src \ main \ java \ io \ netty \ buffer \ AbstractReferenceCountedByteBuf . java \n - private volatile int refCnt = 1 ; \n + private volatile int refCnt ; \n + refCntUpdater . set ( this , 1 ) ; \n - this . refCnt = refCnt ; \n + refCntUpdater . set ( this , refCnt ) ; \n common \ src \ main \ java \ io \ netty \ util \ AbstractReferenceCounted . java \n - this . refCnt = refCnt ; \n + refCntUpdater . set ( this , refCnt ) ; \n common \ src \ main \ java \ io \ netty \ util \ HashedWheelTimer . java \n - @ SuppressWarnings ( { "" unused "" , "" FieldMayBeFinal "" , "" RedundantFieldInitialization "" } ) \n - private volatile int workerState = WORKER _ STATE _ INIT ; / / 0 - init , 1 - started , 2 - shut down \n + @ SuppressWarnings ( { "" unused "" , "" FieldMayBeFinal "" } ) \n + private volatile int workerState ; / / 0 - init , 1 - started , 2 - shut down \n","Use threadsafe setter on Atomic Updaters \n Motivation : \n The documentation for field updates says : \n > Note that the guarantees of the { @ code compareAndSet } \n > method in this class are weaker than in other atomic classes . \n > Because this class cannot ensure that all uses of the field \n > are appropriate for purposes of atomic access , it can \n > guarantee atomicity only with respect to other invocations of \n > { @ code compareAndSet } and { @ code set } on the same updater . \n This implies that volatiles shouldn ' t use normal assignment ; the \n updater should set them . \n Modifications : \n Use setter for field updaters that make use of compareAndSet . \n Result : \n Concurrency compliant code",77
common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n + import static io . netty . util . internal . EmptyArrays . EMPTY _ OBJECTS ; \n - / / Should be power of two . \n - private final Deque < String > lastRecords = new ArrayDeque < String > ( ) ; \n + private final Deque < String > lastRecords ; \n + lastRecords = new ArrayDeque < String > ( ) ; \n + lastRecords = null ; \n - synchronized ( lastRecords ) { \n - array = lastRecords . toArray ( ) ; \n - removedRecords = this . removedRecords ; \n + if ( lastRecords ! = null ) { \n + synchronized ( lastRecords ) { \n + array = lastRecords . toArray ( ) ; \n + removedRecords = this . removedRecords ; \n + } \n + } else { \n + removedRecords = 0 ; \n + array = EMPTY _ OBJECTS ; \n,"Remove allocation from ResourceLeakDetector \n Motivation : \n RLD allocates an ArrayDeque in anticipation of recording access \n points . If the leak detection level is less than ADVANCED though , \n the dequeue is never used . Since SIMPLE is the default level , \n there is a minor perf win to not preemptively allocate it . \n This showed up in garbage profiling when creation a high number of \n buffers . \n Modifications : \n Only allocate the dequeue if it will be used . \n Result : \n Less garbage created .",77
buffer \ src \ main \ java \ io \ netty \ buffer \ PooledByteBufAllocator . java \n + / * * \n + * Default thread caching behavior - System Property : io . netty . allocator . useCacheForAllThreads - default true \n + * / \n + public static boolean defaultUseCacheForAllThreads ( ) { \n + return DEFAULT _ USE _ CACHE _ FOR _ ALL _ THREADS ; \n + } \n + \n + / * * \n + * Default prefer direct - System Property : io . netty . noPreferDirect - default false \n + * / \n + public static boolean defaultPreferDirect ( ) { \n + return PlatformDependent . directBufferPreferred ( ) ; \n + } \n + \n,"Expose all defaults on PooledByteBufAllocator \n Motivation : \n Most , but not all defaults are statically exposed on \n PooledByteBufAllocator . This makes it cumbersome to make a custom \n allocator where most of the defaults remain the same . \n Modification : \n Expose useCacheForAllThreads , and Direct preferred . The latter is \n needed because it is under the internal package , and public code \n should probably not depend on it . \n Result : \n More customizeable allocators",77
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n - import java . lang . ref . PhantomReference ; \n + import java . lang . ref . WeakReference ; \n - extends PhantomReference < Object > implements ResourceLeakTracker < T > , ResourceLeak { \n + extends WeakReference < Object > implements ResourceLeakTracker < T > , ResourceLeak { \n - / / be collected via the PhantomReference . \n + / / be collected via the WeakReference . \n","Use WeakReferences for Resource Leaks \n Motivation : \n Phantom references are for cleaning up resources that were \n forgotten , which means they keep their referent alive . This \n means garbage is kept around until the refqueue is drained , rather \n than when the reference is unreachable . \n Modification : \n Use Weak References instead of Phantoms \n Result : \n More punctual leak detection .",77
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ errors . c \n + static jint netty _ unix _ errors _ errnoENOENT ( JNIEnv * env , jclass clazz ) { \n + return ENOENT ; \n + } \n + \n + { "" errnoENOENT "" , "" ( ) I "" , ( void * ) netty _ unix _ errors _ errnoENOENT } , \n transport - native - unix - common \ src \ main \ java \ io \ netty \ channel \ unix \ Errors . java \n + import java . io . FileNotFoundException ; \n + public static final int ERRNO _ ENOENT _ NEGATIVE = - errnoENOENT ( ) ; \n + if ( err = = ERRNO _ ENOENT _ NEGATIVE ) { \n + throw new FileNotFoundException ( ) ; \n + } \n + if ( err = = ERRNO _ ENOENT _ NEGATIVE ) { \n + throw new FileNotFoundException ( ) ; \n + } \n transport - native - unix - common \ src \ main \ java \ io \ netty \ channel \ unix \ ErrorsStaticallyReferencedJniMethods . java \n + static native int errnoENOENT ( ) ; \n","Throw FileNotFoundException when connecting to a missing UDS path \n Motivation : \n Exception handling is nicer when a more specific Exception is thrown \n Modification : \n Add a static reference for ENOENT , and throw FNFE if it is returned \n Result : \n More precise exception handling",77
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n - boolean android ; \n - try { \n - Class . forName ( "" android . app . Application "" , false , getSystemClassLoader ( ) ) ; \n - android = true ; \n - } catch ( Throwable ignored ) { \n - / / Failed to load the class uniquely available in Android . \n - android = false ; \n - } \n + / / Idea : Sometimes java binaries include Android classes on the classpath , even if it isn ' t actually Android . \n + / / Rather than check if certain classes are present , just check the VM , which is tied to the JDK . \n + \n + / / Optional improvement : check if ` android . os . Build . VERSION ` is > = 24 . On later versions of Android , the \n + / / OpenJDK is used , which means ` Unsafe ` will actually work as expected . \n - if ( android ) { \n + / / Android sets this property to Dalvik , regardless of whether it actually is . \n + String vmName = SystemPropertyUtil . get ( "" java . vm . name "" ) ; \n + boolean isAndroid = vmName . equals ( "" Dalvik "" ) ; \n + if ( isAndroid ) { \n - return android ; \n + return isAndroid ; \n","To detect Android , check the VM property rather than the classpath \n Motivation : \n Some java binaries include android classes on their classpath , even \n if they aren ' t actually android . When this is true , ` Unsafe ` no \n longer works , disabling the Epoll functionality . A sample case is \n for binaries that use the j2objc library . \n Modifications : \n Check the ` java . vm . name ` instead of the classpath . Numerous \n Google - internal Android libraries / binaries check this property \n rather than the class path . \n It is believed this is safe and works with bother ART and Dalvik \n VMs , safe for Robolectric , and j2objc . \n Results : \n Unusually built java server binaries can still use Netty Epoll .",77
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2Headers . java \n - return contains ( name , value , caseInsensitive ? CASE _ INSENSITIVE _ HASHER : CASE _ SENSITIVE _ HASHER ) ; \n + return contains ( name , value , caseInsensitive ? CASE _ INSENSITIVE _ HASHER : CASE _ SENSITIVE _ HASHER ) ; \n codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ ReadOnlyHttp2Headers . java \n - final HashingStrategy < CharSequence > strategy = caseInsensitive ? CASE _ INSENSITIVE _ HASHER : CASE _ SENSITIVE _ HASHER ; \n + final HashingStrategy < CharSequence > strategy = \n + caseInsensitive ? CASE _ INSENSITIVE _ HASHER : CASE _ SENSITIVE _ HASHER ; \n - return contains ( name , nameHash , value , valueHash , strategy , pseudoHeaders ) \n - | | contains ( name , nameHash , value , valueHash , strategy , otherHeaders ) ; \n + return contains ( name , nameHash , value , valueHash , strategy , otherHeaders ) \n + | | contains ( name , nameHash , value , valueHash , strategy , pseudoHeaders ) ; \n","Swap header check in ReadOnlyHttp2Headers \n Motivation : \n Pseudo headers are checked less frequently than normal headers , so \n it is more efficient to check the latter first . \n Modifications : \n Swap the order of the check , and fix minor formatting \n Result : \n Possibly more efficient header checks",77
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - sslWrote = SSL . writeToSSL ( ssl , Buffer . address ( src ) + pos , len ) ; \n + sslWrote = SSL . writeToSSL ( ssl , bufferAddress ( src ) + pos , len ) ; \n - SSL . bioSetByteBuffer ( networkBIO , Buffer . address ( src ) + pos , len , false ) ; \n + SSL . bioSetByteBuffer ( networkBIO , bufferAddress ( src ) + pos , len , false ) ; \n - sslRead = SSL . readFromSSL ( ssl , Buffer . address ( dst ) + pos , dst . limit ( ) - pos ) ; \n + sslRead = SSL . readFromSSL ( ssl , bufferAddress ( dst ) + pos , dst . limit ( ) - pos ) ; \n - SSL . bioSetByteBuffer ( networkBIO , Buffer . address ( dst ) + dst . position ( ) , dst . remaining ( ) , \n + SSL . bioSetByteBuffer ( networkBIO , bufferAddress ( dst ) + dst . position ( ) , dst . remaining ( ) , \n + private static long bufferAddress ( ByteBuffer b ) { \n + assert b . isDirect ( ) ; \n + if ( PlatformDependent . hasUnsafe ( ) ) { \n + return PlatformDependent . directBufferAddress ( b ) ; \n + } \n + return Buffer . address ( b ) ; \n + } \n + \n","Get memory address from Unsafe for OpenSSL \n Motivation : \n Profiling tcnative SSL code showed a non trivial percentage ( 1 % ) \n of time spent in JNI code for InstaceOf . This turned out to be \n from ` Buffer . address ` which makes a JNI call , which safely checks \n on each call that The ByteBuffer is direct . \n Modification : \n Prefer using the address field of the pojo rather than looking it \n up with JNI . This is the same approach taken by the ` OpenSsl ` \n class . \n Result : \n Less JNI overhead",77
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n + outboundClosed = true ; \n + outboundClosed = true ; \n + engine . closeOutbound ( ) ; \n + \n - outboundClosed = true ; \n - engine . closeOutbound ( ) ; \n - \n,"Close SSLEngine when connection fails . \n Motivation : \n When using the JdkSslEngine , the ALPN class is used keep a reference \n to the engine . In the event that the TCP connection fails , the \n SSLEngine is not removed from the map , creating a memory leak . \n Modification : \n Always close the SSLEngine regardless of if the channel became \n active . Also , record the SSLEngine was closed in all places . \n Result : \n Fixes : https : / / github . com / grpc / grpc - java / issues / 3080",77
transport \ src \ main \ java \ io \ netty \ channel \ AbstractChannel . java \n - setStackTrace ( exception . getStackTrace ( ) ) ; \n - setStackTrace ( exception . getStackTrace ( ) ) ; \n - setStackTrace ( exception . getStackTrace ( ) ) ; \n,"Don ' t double record stacktrace in Annotated * Exception ( # 9117 ) \n Motivation : \n When initializing the AnnotatedSocketException in AbstractChannel , both \n the cause and the stack trace are set , leaving a trailing "" Caused By "" \n that is compressed when printing the trace . \n Modification : \n Don ' t include the stack trace in the exception , but leave it in the cause . \n Result : \n Clearer stack trace",77
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n + memset ( & interfaceAddr , 0 , sizeof ( interfaceAddr ) ) ; \n + \n + memset ( & groupAddr , 0 , sizeof ( groupAddr ) ) ; \n + memset ( & interfaceAddr , 0 , sizeof ( interfaceAddr ) ) ; \n + \n + memset ( & groupAddr , 0 , sizeof ( groupAddr ) ) ; \n + memset ( & sourceAddr , 0 , sizeof ( sourceAddr ) ) ; \n + memset ( & interfaceAddr , 0 , sizeof ( interfaceAddr ) ) ; \n + \n + memset ( & groupAddr , 0 , sizeof ( groupAddr ) ) ; \n + memset ( & interfaceAddr , 0 , sizeof ( interfaceAddr ) ) ; \n + \n + memset ( & groupAddr , 0 , sizeof ( groupAddr ) ) ; \n + memset ( & sourceAddr , 0 , sizeof ( sourceAddr ) ) ; \n + memset ( & interfaceAddr , 0 , sizeof ( interfaceAddr ) ) ; \n + \n + \n + memset ( & addr , 0 , sizeof ( addr ) ) ; \n + \n","Unconditionally initialize sockaddrs in epoll linuxsocket ( # 9299 ) \n Motivation : \n Compiling with - Werror , - Wuninitialized complains about the sockaddrs being uninitialized . \n I believe this is because the init function netty _ unix _ socket _ initSockaddr is in a \n separate compilation unit . Since this code isn ' t on the criticial path , it ' s easy \n to just memset the variables rather than suppress the warning . \n Modification : \n Always clear the sockaddrs , even if they will be initialized later . \n Result : \n Able to compile with warnings turned on",77
"transport \ src \ main \ java \ io \ netty \ channel \ ChannelHandlerMask . java \n + import io . netty . util . internal . logging . InternalLogger ; \n + import io . netty . util . internal . logging . InternalLoggerFactory ; \n + import java . lang . reflect . Method ; \n + private static final InternalLogger logger = InternalLoggerFactory . getInstance ( ChannelHandlerMask . class ) ; \n - return handlerType . getMethod ( methodName , paramTypes ) . isAnnotationPresent ( Skip . class ) ; \n + Method m ; \n + try { \n + m = handlerType . getMethod ( methodName , paramTypes ) ; \n + } catch ( NoSuchMethodException e ) { \n + logger . debug ( \n + "" Class { } missing method { } , assume we can not skip execution "" , handlerType , methodName , e ) ; \n + return false ; \n + } \n + return m . isAnnotationPresent ( Skip . class ) ; \n","Handle missing methods on ChannelHandlerMask ( # 9221 ) \n Motivation : \n When Netty is run through ProGuard , seemingly unused methods are removed . This breaks reflection , making the Handler skipping throw a reflective error . \n Modification : \n If a method is seemingly absent , just disable the optimization . \n Result : \n Dealing with ProGuard sucks infinitesimally less .",77
"imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ HttpUrlConnectionNetworkFetcher . java \n + import javax . annotation . Nullable ; \n + @ Nullable private String mUserAgent ; \n - this ( RealtimeSinceBootClock . get ( ) ) ; \n + this ( null , RealtimeSinceBootClock . get ( ) ) ; \n - this ( RealtimeSinceBootClock . get ( ) ) ; \n + this ( null , RealtimeSinceBootClock . get ( ) ) ; \n + mHttpConnectionTimeout = httpConnectionTimeout ; \n + } \n + \n + public HttpUrlConnectionNetworkFetcher ( String userAgent , int httpConnectionTimeout ) { \n + this ( userAgent , RealtimeSinceBootClock . get ( ) ) ; \n - HttpUrlConnectionNetworkFetcher ( MonotonicClock monotonicClock ) { \n + HttpUrlConnectionNetworkFetcher ( @ Nullable String userAgent , MonotonicClock monotonicClock ) { \n + mUserAgent = userAgent ; \n + if ( mUserAgent ! = null ) { \n + connection . setRequestProperty ( "" User - Agent "" , mUserAgent ) ; \n + } \n imagepipeline \ src \ test \ java \ com \ facebook \ imagepipeline \ producers \ HttpUrlConnectionNetworkFetcherTest . java \n + import static org . mockito . Matchers . eq ; \n - mFetcher = new HttpUrlConnectionNetworkFetcher ( mock ( MonotonicClock . class ) ) ; \n + mFetcher = new HttpUrlConnectionNetworkFetcher ( "" user - agent - blabla "" , mock ( MonotonicClock . class ) ) ; \n + @ Test \n + public void testUserAgent ( ) throws Exception { \n + HttpURLConnection mockConnection = mockSuccessWithStream ( mock ( InputStream . class ) ) ; \n + \n + runFetch ( ) ; \n + \n + verify ( mockConnection ) . setRequestProperty ( eq ( "" User - Agent "" ) , eq ( "" user - agent - blabla "" ) ) ; \n + } \n + \n",Support customizing the User - Agent that HttpUrlConnectionNetworkFetcher uses \n Reviewed By : lsaddan \n Differential Revision : D20184661 \n fbshipit - source - id : 888fb5b8067c84c7f56938b9bb1f14fbd86e1fe1,78
imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ PriorityNetworkFetcher . java \n - static { \n - FLog . setMinimumLoggingLevel ( FLog . VERBOSE ) ; \n - } \n - \n,Remove accidental FLog . setMinimumLoggingLevel \n Differential Revision : D19722469 \n fbshipit - source - id : 3732abf9145448c13c0254b96e0e38316f7e9951,78
"drawee \ src \ main \ java \ com \ facebook \ drawee \ debug \ DebugControllerOverlayDrawable . java \n + private int mOverlayColor = Color . TRANSPARENT ; \n + / * * Pass a semi - transparency color ( e . g . , 0x66RRGGBB ) to give the overlay a color shade . * / \n + public void setOverlayColor ( int overlayColor ) { \n + this . mOverlayColor = overlayColor ; \n + } \n + \n + / / Draw overlay \n + mPaint . setStyle ( Paint . Style . FILL ) ; \n + mPaint . setColor ( mOverlayColor ) ; \n + canvas . drawRect ( bounds . left , bounds . top , bounds . right , bounds . bottom , mPaint ) ; \n + \n",Support color shades for the debug overlay \n Reviewed By : oprisnik \n Differential Revision : D21277921 \n fbshipit - source - id : c47d6ec56cdcb741db0449492d7309d930aaa985,78
"imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ HttpUrlConnectionNetworkFetcher . java \n + @ Nullable private final Map < String , String > mRequestHeaders ; \n - this ( null , RealtimeSinceBootClock . get ( ) ) ; \n + this ( null , null , RealtimeSinceBootClock . get ( ) ) ; \n - this ( null , RealtimeSinceBootClock . get ( ) ) ; \n + this ( null , null , RealtimeSinceBootClock . get ( ) ) ; \n - this ( userAgent , RealtimeSinceBootClock . get ( ) ) ; \n + this ( userAgent , null , RealtimeSinceBootClock . get ( ) ) ; \n + mHttpConnectionTimeout = httpConnectionTimeout ; \n + } \n + \n + public HttpUrlConnectionNetworkFetcher ( \n + String userAgent , @ Nullable Map < String , String > requestHeaders , int httpConnectionTimeout ) { \n + this ( userAgent , requestHeaders , RealtimeSinceBootClock . get ( ) ) ; \n - HttpUrlConnectionNetworkFetcher ( @ Nullable String userAgent , MonotonicClock monotonicClock ) { \n + HttpUrlConnectionNetworkFetcher ( \n + @ Nullable String userAgent , \n + @ Nullable Map < String , String > requestHeaders , \n + MonotonicClock monotonicClock ) { \n + mRequestHeaders = requestHeaders ; \n + if ( mRequestHeaders ! = null ) { \n + for ( Map . Entry < String , String > entry : mRequestHeaders . entrySet ( ) ) { \n + connection . setRequestProperty ( entry . getKey ( ) , entry . getValue ( ) ) ; \n + } \n + } \n imagepipeline \ src \ test \ java \ com \ facebook \ imagepipeline \ producers \ HttpUrlConnectionNetworkFetcherTest . java \n - mFetcher = new HttpUrlConnectionNetworkFetcher ( "" user - agent - blabla "" , mock ( MonotonicClock . class ) ) ; \n + mFetcher = \n + new HttpUrlConnectionNetworkFetcher ( "" user - agent - blabla "" , null , mock ( MonotonicClock . class ) ) ; \n",HttpUrlConnectionNetworkFetcher : specify arbitrary request headers \n Reviewed By : hvu \n Differential Revision : D22289847 \n fbshipit - source - id : 940fe452789dee6722cf25ddf8cd7f5ce7557059,78
imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ PriorityNetworkFetcher . java \n - @ VisibleForTesting \n - static class PriorityFetchState < FETCH _ STATE extends FetchState > extends FetchState { \n - final FETCH _ STATE delegatedState ; \n + public static class PriorityFetchState < FETCH _ STATE extends FetchState > extends FetchState { \n + public final FETCH _ STATE delegatedState ; \n,PriorityNetworkFetcher to work with LiteNetworkFetchProducer \n Reviewed By : yanivsb \n Differential Revision : D20288148 \n fbshipit - source - id : e2d3e0ab2e0590680ab8245614968ad8b70fdd07,78
imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ NetworkFetchProducer . java \n - private final PooledByteBufferFactory mPooledByteBufferFactory ; \n + protected final PooledByteBufferFactory mPooledByteBufferFactory ; \n,"Output pool is now created in the producer , not the fetcher \n Differential Revision : D23581465 \n fbshipit - source - id : a027c58db5c4aac21ae98a79b88b16a7162863b3",78
"vito \ core \ src \ main \ java \ com \ facebook \ fresco \ vito \ core \ impl \ debug \ DebugOverlayDrawable . java \n + import android . graphics . Color ; \n + import androidx . annotation . ColorInt ; \n + private @ ColorInt int mBackgroundColor = Color . TRANSPARENT ; \n + / / Draw overlay \n + mPaint . setStyle ( Paint . Style . FILL ) ; \n + mPaint . setColor ( mBackgroundColor ) ; \n + canvas . drawRect ( bounds . left , bounds . top , bounds . right , bounds . bottom , mPaint ) ; \n + \n + public void setBackgroundColor ( @ ColorInt int color ) { \n + mBackgroundColor = color ; \n + } \n + \n",Support background color in the debug overlay \n Reviewed By : oprisnik \n Differential Revision : D25423302 \n fbshipit - source - id : 78b3ea7cc91a20b2e117a9f8006c2a60ce2c5071,78
"imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ PriorityNetworkFetcher . java \n - if ( infiniteRetries ) { \n + if ( infiniteRetries \n + & & ! ( throwable instanceof PriorityNetworkFetcher . NonrecoverableException ) ) { \n + / * * \n + * The delegate fetcher may pass an instance of this exception to its callback ' s onFailure to \n + * signal to a PriorityNetworkFetcher that it shouldn ' t retry that request . \n + * \n + * < p > This is useful for e . g . , requests that fail due to HTTP 403 : there ' s no point in retrying \n + * them , usually . \n + * / \n + public static class NonrecoverableException extends Throwable { \n + public NonrecoverableException ( @ androidx . annotation . Nullable String message ) { \n + super ( message ) ; \n + } \n + } \n + \n imagepipeline \ src \ test \ java \ com \ facebook \ imagepipeline \ producers \ PriorityNetworkFetcherTest . java \n + / * * Scenario : an image fetch fails with a non - recoverable exception . Don ' t requeue it . * / \n + @ Test \n + public void testInfiniteRetries _ dontRetryNonrecoverableException ( ) { \n + RecordingNetworkFetcher recordingNetworkFetcher = new RecordingNetworkFetcher ( ) ; \n + \n + / / Max hi - pri : 1 , max low - pri : 0 \n + PriorityNetworkFetcher < FetchState > fetcher = \n + new PriorityNetworkFetcher < > ( recordingNetworkFetcher , false , 1 , 0 , true , true ) ; \n + \n + PriorityFetchState < FetchState > hipri1 = fetch ( fetcher , "" hipri1 "" , callback , true ) ; \n + \n + assertThat ( fetcher . getCurrentlyFetching ( ) ) . containsExactly ( hipri1 ) ; \n + assertThat ( fetcher . getHiPriQueue ( ) ) . isEmpty ( ) ; \n + assertThat ( fetcher . getLowPriQueue ( ) ) . isEmpty ( ) ; \n + \n + / / Simulate a failure in hipri1 . \n + getOnlyElement ( recordingNetworkFetcher . callbacks . get ( hipri1 . delegatedState ) ) \n + . onFailure ( new PriorityNetworkFetcher . NonrecoverableException ( "" HTTP 403 "" ) ) ; \n + \n + assertThat ( fetcher . getCurrentlyFetching ( ) ) . isEmpty ( ) ; \n + assertThat ( fetcher . getHiPriQueue ( ) ) . isEmpty ( ) ; \n + assertThat ( fetcher . getLowPriQueue ( ) ) . isEmpty ( ) ; \n + \n + assertThat ( hipri1 . requeueCount ) . isEqualTo ( 0 ) ; \n + } \n + \n",Don ' t retry certain errors indefinitely \n Differential Revision : D25378921 \n fbshipit - source - id : b9a985d4ece55fe60a59f64b9072eb6cfabbd5ed,78
"src \ main \ java \ com \ google \ devtools \ build \ lib \ remote \ util \ BUILD \n + "" / / third _ party : flogger "" , \n src \ main \ java \ com \ google \ devtools \ build \ lib \ remote \ util \ NetworkTime . java \n + import com . google . common . flogger . GoogleLogger ; \n + private static final GoogleLogger logger = GoogleLogger . forEnclosingClass ( ) ; \n + \n + / * * \n + * This method must not throw any exceptions . Doing so will cause the wrapped call to \n + * silently hang indefinitely : https : / / github . com / grpc / grpc - java / pull / 6107 \n + * / \n - networkTime . stop ( ) ; \n + / / There is a risk that networkTime . stop ( ) would throw a IllegalStateException : if \n + / / networkTime . outstanding is overflowed , wallTime . stop ( ) will be called even it ' s \n + / / already stopped . \n + try { \n + networkTime . stop ( ) ; \n + } catch ( RuntimeException e ) { \n + logger . atWarning ( ) . withCause ( e ) . log ( "" Failed to stop networkTime "" ) ; \n + } \n",Ensure NetworkTime never throw exceptions inside onClose \n Failed doing so will cause gRPC hanging forever . This could be one of causes that leads to # 11782 . \n Closes # 12422 . \n PiperOrigin - RevId : 340995977,81
"src \ main \ java \ com \ google \ devtools \ build \ lib \ remote \ RemoteModule . java \n - boolean enableGrpcCache = GrpcCacheClient . isRemoteCacheOptions ( remoteOptions ) ; \n + / / If - - remote _ cache is empty but - - remote _ executor is not , endpoint for cache should be the one \n + / / for execution . \n + if ( enableRemoteExecution & & Strings . isNullOrEmpty ( remoteOptions . remoteCache ) ) { \n + remoteOptions . remoteCache = remoteOptions . remoteExecutor ; \n + } \n + boolean enableGrpcCache = GrpcCacheClient . isRemoteCacheOptions ( remoteOptions ) ; \n - if ( Strings . isNullOrEmpty ( remoteOptions . remoteCache ) \n - | | remoteOptions . remoteCache . equals ( remoteOptions . remoteExecutor ) ) { \n + if ( remoteOptions . remoteCache . equals ( remoteOptions . remoteExecutor ) ) { \n",Set - - remote _ cache to - - remote _ executor if it is empty . \n Fixes # 11913 \n Closes # 11998 . \n PiperOrigin - RevId : 328487098,81
". bazelci \ postsubmit . yml \n - "" / / src : bazel _ jdk _ minimal "" \n - build \n + kythe _ ubuntu2004 : \n + shell _ commands : \n + - sed - i . bak - e ' s / ^ # android _ sdk _ repository / android _ sdk _ repository / ' \n + - e ' s / ^ # android _ ndk _ repository / android _ ndk _ repository / ' WORKSPACE \n + - rm - f WORKSPACE . bak \n + index _ flags : \n + - "" - - define = kythe _ corpus = github . com / bazelbuild / bazel "" \n + index _ targets _ query : "" kind ( \ "" cc _ ( binary | library | test | proto _ library ) rule \ "" , . . . ) union kind ( \ "" java _ ( binary | import | library | plugin | test | proto _ library ) rule \ "" , . . . ) union kind ( \ "" proto _ library rule \ "" , . . . ) "" \n + index _ upload _ policy : Always \n + index _ upload _ gcs : True \n",Add task ` kythe _ ubuntu2004 ` to ` postsubmit . yml ` \n Add task ` kythe _ ubuntu2004 ` to generate indexing files with Kythe and upload to GCS automatically . \n Must be merged after https : / / github . com / bazelbuild / continuous - integration / commit / 7bb698c41cd6159475154e74c5fab3a38b6106b5 landed . \n Closes # 12011 . \n PiperOrigin - RevId : 329437289,81
"src \ main \ java \ com \ google \ devtools \ build \ lib \ remote \ GrpcCacheClient . java \n + import build . bazel . remote . execution . v2 . RequestMetadata ; \n + \n + RequestMetadata requestMetadata = TracingMetadataUtils . fromCurrentContext ( ) ; \n - TracingMetadataUtils . fromCurrentContext ( ) . getActionId ( ) , \n + requestMetadata . getActionId ( ) , \n",Fixed a bug that could fail the build if unable to findMissingBlobs . \n Closes # 12369 . \n PiperOrigin - RevId : 339427586,81
"third _ party \ BUILD \n - srcjar = "" javax _ annotations / javax . activation - api - 1 . 2 . 0 - sources . jar "" , \n + srcjar = "" javax _ activation / javax . activation - api - 1 . 2 . 0 - sources . jar "" , \n",Fix typo in srcjar of / / third _ party : javax _ activation,81
"BUILD \n - value : "" n1 - highcpu - 32 "" \n + value : "" e2 - highcpu - 32 "" \n","Change gceMachineType of highcpu platform from n1 - highcpu - 32 to e2 - highcpu - 32 \n Since the worker pools are migrated from n1 machines to e2 . \n Fixes ` FAILED _ PRECONDITION : there are no bots capable of executing the action , requested action properties : gceMachineType = n1 - highcpu - 32 , OSFamily = Linux ` errors in Bazel CI . \n Closes # 13087 . \n PiperOrigin - RevId : 358772910",81
src \ jvm \ clojure \ lang \ Agent . java \n - nested . set ( PersistentVector . EMPTY ) ; \n + nested . set ( null ) ; / / allow errorHandler to send \n,Allows agent error - handler to send successfully . Refs # 390 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,84
"src \ clj \ clojure \ core . clj \n - ( . a ( dispatch ( binding - conveyor - fn f ) args false ) ) ) \n + ( binding [ * agent * a ] \n + ( . dispatch a ( binding - conveyor - fn f ) args false ) ) ) \n - ( . a ( dispatch ( binding - conveyor - fn f ) args true ) ) ) \n + ( binding [ * agent * a ] \n + ( . dispatch a ( binding - conveyor - fn f ) args true ) ) ) \n src \ jvm \ clojure \ lang \ Agent . java \n - Var . pushThreadBindings ( RT . map ( RT . AGENT , action . agent ) ) ; \n - Var . popThreadBindings ( ) ; \n test \ clojure \ test _ clojure \ agents . clj \n + ( deftest earmuff - agent - bound \n + ( let [ a ( agent 1 ) ] \n + ( send a ( fn [ _ ] * agent * ) ) \n + ( await a ) \n + ( is ( = a @ a ) ) ) ) \n + \n",Restore * agent * binding in agent action . CLJ - 672 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,84
test \ clojure \ test _ clojure \ agents . clj \n + ( let [ target - agent ( agent : before - error ) \n + handler ( fn [ agt err ] \n + ( send target - agent ( constantly : sent - after - error ) ) ) \n + failing - agent ( agent nil : error - handler handler ) ] \n + ( send failing - agent ( fn [ _ ] ( throw ( RuntimeException . ) ) ) ) \n + ( await - for 1000 failing - agent ) \n + ( is ( = : sent - after - error @ target - agent ) ) ) ) \n + \n + ( deftest can - send - to - self - from - error - handler - before - popping - action - that - caused - error \n,extra test for send from agent error \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,84
"src \ clj \ clojure \ repl . clj \n + ; ; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n + ; ; Handle Ctrl - C keystrokes \n + \n + ( defn thread - stopper \n + "" Returns a function that takes one arg and uses that as an exception message \n + to stop the given thread . Defaults to the current thread "" \n + ( [ ] ( thread - stopper ( Thread / currentThread ) ) ) \n + ( [ thread ] ( fn [ msg ] ( . stop thread ( Error . msg ) ) ) ) ) \n + \n + ( defn set - break - handler ! \n + "" Register INT signal handler . After calling this , Ctrl - C will cause \n + the given function f to be called with a single argument , the signal . \n + Uses thread - stopper if no function given . "" \n + ( [ ] ( set - break - handler ! ( thread - stopper ) ) ) \n + ( [ f ] \n + ( sun . misc . Signal / handle \n + ( sun . misc . Signal . "" INT "" ) \n + ( proxy [ sun . misc . SignalHandler ] [ ] \n + ( handle [ signal ] \n + ( f ( str "" - - caught signal "" signal ) ) ) ) ) ) ) \n","Add set - break - handler ! and thread - stopper , refs CLJ - 460 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >",84
"src \ jvm \ clojure \ lang \ ASeq . java \n - public abstract class ASeq extends Obj implements ISeq , List , Serializable { \n + public abstract class ASeq extends Obj implements ISeq , Sequential , List , Serializable { \n src \ jvm \ clojure \ lang \ IChunkedSeq . java \n - public interface IChunkedSeq extends ISeq { \n + public interface IChunkedSeq extends ISeq , Sequential { \n src \ jvm \ clojure \ lang \ ISeq . java \n - public interface ISeq extends IPersistentCollection , Sequential { \n + public interface ISeq extends IPersistentCollection { \n src \ jvm \ clojure \ lang \ IndexedSeq . java \n - public interface IndexedSeq extends ISeq , Counted { \n + public interface IndexedSeq extends ISeq , Sequential , Counted { \n src \ jvm \ clojure \ lang \ LazySeq . java \n - public final class LazySeq extends Obj implements ISeq , List { \n + public final class LazySeq extends Obj implements ISeq , Sequential , List { \n","Remove Sequential from ISeq ' s implements list CLJ - 741 \n Also add Sequential to the implements lists of : \n ASeq , IChunkedSeq , IndexedSeq , and LazySeq \n Signed - off - by : Stuart Halloway < stu @ Orolo - 2 . local > \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >",84
src \ clj \ clojure \ core . clj \n - ( if ( seq ? f ) \n - ` ( ~ ( first f ) ~ gx ~ @ ( next f ) ) \n - ` ( ~ f ~ gx ) ) ) \n + ( with - meta \n + ( if ( seq ? f ) \n + ` ( ~ ( first f ) ~ gx ~ @ ( next f ) ) \n + ` ( ~ f ~ gx ) ) \n + ( meta f ) ) ) \n,CLJ - 2184 propagate metadata in doto forms \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,84
app \ build . gradle \n - compile ' com . android . support : design : 22 . 2 . 0 ' \n - compile ' com . android . support : appcompat - v7 : 22 . 2 . 0 ' \n - compile ' com . android . support : cardview - v7 : 22 . 2 . 0 ' \n - compile ' com . android . support : recyclerview - v7 : 22 . 2 . 0 ' \n + compile ' com . android . support : design : 22 . 2 . 1 ' \n + compile ' com . android . support : appcompat - v7 : 22 . 2 . 1 ' \n + compile ' com . android . support : cardview - v7 : 22 . 2 . 1 ' \n + compile ' com . android . support : recyclerview - v7 : 22 . 2 . 1 ' \n,Update to support library 22 . 2 . 1,86
"app \ build . gradle \n - compile ' com . android . support : design : 23 . 0 . 1 ' \n - compile ' com . android . support : appcompat - v7 : 23 . 0 . 1 ' \n - compile ' com . android . support : cardview - v7 : 23 . 0 . 1 ' \n - compile ' com . android . support : recyclerview - v7 : 23 . 0 . 1 ' \n + compile ' com . android . support : design : 23 . 1 . 0 ' \n + compile ' com . android . support : cardview - v7 : 23 . 1 . 0 ' \n app \ src \ main \ res \ layout \ include _ list _ viewpager . xml \n - app : layout _ scrollFlags = "" scroll | enterAlways "" / > \n + app : layout _ scrollFlags = "" scroll | enterAlways | snap "" / > \n",Update to v23 . 1 . 0 and use the snap scroll flag,86
"app \ build . gradle \n - buildToolsVersion "" 23 . 0 . 1 "" \n + buildToolsVersion "" 23 . 0 . 3 "" \n - compile ' com . android . support : design : 23 . 1 . 1 ' \n - compile ' com . android . support : cardview - v7 : 23 . 1 . 1 ' \n + compile ' com . android . support : design : 23 . 3 . 0 ' \n + compile ' com . android . support : cardview - v7 : 23 . 3 . 0 ' \n build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 2 . 3 ' \n + classpath ' com . android . tools . build : gradle : 2 . 1 . 0 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Wed Apr 10 15 : 27 : 10 PDT 2013 \n + # Thu May 05 12 : 46 : 14 BST 2016 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 2 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 10 - all . zip \n",Update to support lib 23 . 3 . 0,86
"android \ build . gradle \n - compileSdkVersion 23 \n - buildToolsVersion "" 23 . 0 . 1 "" \n + compileSdkVersion 25 \n + buildToolsVersion "" 25 . 0 . 2 "" \n build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 3 ' \n gradle . properties \n - android _ support _ lib _ version = 23 . 4 . 0 \n - google _ play _ services _ client _ library _ version = 8 . 4 . 0 \n + android _ support _ lib _ version = 25 . 1 . 0 \n + google _ play _ services _ client _ library _ version = 9 . 8 . 0 \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + # Gradle configuraton \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + # Increase max heap to 2GB to allow in - process dex - ing \n + org . gradle . jvmargs = - Xmx2048M \n third _ party \ volley \ build . gradle \n - buildscript { \n - repositories { \n - mavenCentral ( ) \n - } \n - dependencies { \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n - } \n - } \n - \n - apply plugin : ' android - library ' \n + apply plugin : ' com . android . library ' \n",Gradle build improvements \n - Updated Support Lib and Play Services \n dependencies . \n - Increased max heap size to allow in - process \n dex - ing . \n Change - Id : I07fea9129a17afd11e2769e10e43a171a51ebfb2,86
"android \ build . gradle \n - compileSdkVersion 23 \n - buildToolsVersion "" 23 . 0 . 1 "" \n + compileSdkVersion 25 \n + buildToolsVersion "" 25 . 0 . 2 "" \n build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 3 ' \n gradle . properties \n - android _ support _ lib _ version = 23 . 4 . 0 \n - google _ play _ services _ client _ library _ version = 8 . 4 . 0 \n + android _ support _ lib _ version = 25 . 1 . 0 \n + google _ play _ services _ client _ library _ version = 9 . 8 . 0 \n third _ party \ volley \ build . gradle \n - buildscript { \n - repositories { \n - mavenCentral ( ) \n - } \n - dependencies { \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n - } \n - } \n - \n - apply plugin : ' android - library ' \n + apply plugin : ' com . android . library ' \n",build . gradle improvements \n Also updated Support Lib and Play Services \n dependencies . \n Change - Id : If3956c880bf79281853193771c2b799ac0a7d6e1,86
"android \ build . gradle \n - compileSdkVersion 25 \n - buildToolsVersion "" 25 . 0 . 2 "" \n + compileSdkVersion 23 \n + buildToolsVersion "" 23 . 0 . 1 "" \n build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 3 ' \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n gradle . properties \n - android _ support _ lib _ version = 25 . 1 . 0 \n - google _ play _ services _ client _ library _ version = 9 . 8 . 0 \n + android _ support _ lib _ version = 23 . 4 . 0 \n + google _ play _ services _ client _ library _ version = 8 . 4 . 0 \n third _ party \ volley \ build . gradle \n - apply plugin : ' com . android . library ' \n + buildscript { \n + repositories { \n + mavenCentral ( ) \n + } \n + dependencies { \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 1 ' \n + } \n + } \n + \n + apply plugin : ' android - library ' \n","Revert "" build . gradle improvements "" \n This reverts commit aae74a4f156a360a2bacd1328dc37064c2351396 . \n Change - Id : Ic37484bd2ee9bbd8e7e4b3e6ebb6fbfdb5522bc0",86
"android \ src \ debug \ res \ values \ placeholder _ strings . xml \n - < string name = "" placeholder _ session _ start _ time "" translatable = "" false "" > 10 : 00am < / string > \n + < string name = "" placeholder _ session _ start _ time "" translatable = "" false "" > 10 AM < / string > \n android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ MyScheduleDayAdapter . java \n - return true ; \n + return false ; \n - return true ; \n + return false ; \n - clearClickable ( startTime ) ; \n - \n - \n - final long now = TimeUtils . getCurrentTime ( view . getContext ( ) ) ; \n - boolean isPastDuringConference = item . endTime < = now \n - & & now < Config . CONFERENCE _ END _ MILLIS ; \n - \n - if ( isPastDuringConference ) { \n - startTime . setTextColor ( mHourColorPast ) ; \n - } else { \n - startTime . setTextColor ( mHourColorDefault ) ; \n - } \n - \n - setUriClickable ( view , ScheduleContract . Sessions \n - . buildUnscheduledSessionsInInterval ( item . startTime , item . endTime ) , false ) ; \n android \ src \ main \ res \ layout \ my _ schedule _ time _ separator _ item . xml \n - - > \n - < FrameLayout \n + < TextView \n + android : id = "" @ + id / start _ time "" \n - android : foreground = "" ? android : selectableItemBackground "" \n - android : importantForAccessibility = "" yes "" > \n + android : padding = "" @ dimen / keyline _ 1 "" \n + android : textAppearance = "" @ style / TextAppearance . AppCompat . Title "" \n + tools : text = "" @ string / placeholder _ session _ start _ time "" / > \n - < TextView \n - android : id = "" @ + id / start _ time "" \n - android : layout _ width = "" match _ parent "" \n - android : layout _ height = "" wrap _ content "" \n - android : gravity = "" center _ vertical "" \n - android : padding = "" @ dimen / keyline _ 1 "" \n - android : textAppearance = "" @ style / TextAppearance . AppCompat . Headline "" \n - tools : text = "" @ string / placeholder _ session _ start _ time "" / > \n - \n - < / FrameLayout > \n",Stop making timeslot items clickable \n BUG : 35302846 \n Change - Id : Ib3cc0b72f8d5153d778036afa1dc9cb423e20431,86
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ model \ ScheduleItemHelper . java \n + \n + public static boolean sameStartTime ( ScheduleItem block1 , ScheduleItem block2 , \n + boolean useOverlap ) { \n + return Math . abs ( block1 . startTime - block2 . startTime ) < = ( useOverlap ? ALLOWED _ OVERLAP : 0 ) ; \n + } \n android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ MyScheduleDayAdapter . java \n + import com . google . samples . apps . iosched . model . ScheduleItemHelper ; \n - if ( prev = = null | | prev . startTime ! = item . startTime ) { \n + if ( prev = = null | | ! ScheduleItemHelper . sameStartTime ( prev , item , true ) ) { \n + new Date ( item . startTime ) ) ; \n",Support ' similar time ' items in slots \n This CL basically makes us more resilient to \n start times which are off by < = 5m . \n BUG : 35302898 \n Change - Id : I81d9204f0a03bbd978e0563179b943a03f491bf1,86
android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ model \ ScheduleHelper . java \n - final boolean attendeeAtVenue = SettingsUtils . isAttendeeAtVenue ( mContext ) ; \n - \n - / / Hide BREAK blocks to remote attendees ( b / 14666391 ) : \n - if ( item . type = = ScheduleItem . BREAK & & ! attendeeAtVenue ) { \n - continue ; \n - } \n,Show all events to all attendees \n Regardless of whether attending or not . \n BUG : 35255546 \n Change - Id : I8dd7a85cd889482c65458e7b193c3807d978931f,86
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ MyScheduleDayAdapter . java \n + import java . util . Arrays ; \n + private static final long [ ] ID _ ARRAY = new long [ 4 ] ; \n + \n - ScheduleItem item = mItems . get ( position ) ; \n - if ( item . sessionId ! = null ) { \n - return item . sessionId . hashCode ( ) ; \n - } \n - / / Must be a time separator so just use the startTime \n - return item . startTime ; \n + final ScheduleItem item = mItems . get ( position ) ; \n + \n + / / This code may look complex but its pretty simple . We need to use stable ids so that \n + / / any user interaction animations are run correctly ( such as ripples ) . This means that \n + / / we need to generate a stable id . Not all items have sessionIds so we generate one \n + / / using the sessionId , title , start time and end time . \n + final long [ ] array = ID _ ARRAY ; \n + array [ 0 ] = TextUtils . isEmpty ( item . sessionId ) ? 0 : item . sessionId . hashCode ( ) ; \n + array [ 1 ] = TextUtils . isEmpty ( item . title ) ? 0 : item . title . hashCode ( ) ; \n + array [ 2 ] = item . startTime ; \n + array [ 3 ] = item . endTime ; \n + \n + return Arrays . hashCode ( array ) ; \n","Fix RecyclerView not re - binding views \n Happens because we now use stable ids , but the \n ids we provide are not stable . This CL fixes \n it by generating IDs from more data points . \n BUG : 35789131 \n Change - Id : I237be66b883ed96cda3f4c1a02032962ec7051ab",86
extras \ docker \ Dockerfile \n - ENV ANDROID _ SDK _ DATE 20170131 \n + ENV ANDROID _ SDK _ DATE 20170206 \n gradle . properties \n - android _ support _ lib _ version = 25 . 1 . 0 \n + android _ support _ lib _ version = 25 . 1 . 1 \n,Update to support lib 25 . 1 . 1 \n Change - Id : I89ce583e6689ce75067812403fff56105ace62b8,86
"apk \ build . gradle \n - \n + applicationIdSuffix "" . mapeditor "" \n + qualityassuranceCompile ' com . squareup . leakcanary : leakcanary - android - no - op : 1 . 5 ' \n apk \ src \ androidTest \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ StubMyScheduleModel . java \n - if ( mScheduleData . containsKey ( dayId ) ) { \n + if ( mScheduleData . indexOfKey ( dayId ) > = 0 ) { \n apk \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ MyScheduleModel . java \n - import android . util . SparseArray ; \n + import android . support . v4 . util . SparseArrayCompat ; \n - private final SparseArray < List < ScheduleItem > > mScheduleData = new SparseArray < > ( ) ; \n + @ VisibleForTesting \n + final SparseArrayCompat < List < ScheduleItem > > mScheduleData = new SparseArrayCompat < > ( ) ; \n",Fix build and unit tests \n Change - Id : I9a5beedea0b6ca68561a93d726d0758f3bf4c817,86
"android \ src \ main \ res \ values \ colors . xml \n - < color name = "" theme _ primary "" > # FF26C6DA < / color > \n - < color name = "" theme _ primary _ dark "" > # 00BCD4 < / color > \n + < color name = "" theme _ primary "" > # 4C6AF2 < / color > \n + < color name = "" theme _ primary _ dark "" > # 3C53BB < / color > \n",Re - apply primary color change \n Must have been wiped out in the recent \n lint fixes . \n Change - Id : I3b627c89192f01b577431ee244b115a378806f9c,86
"new file \n lib \ src \ main \ res \ values - h400dp \ styles . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < ! - - \n + Copyright 2017 Google Inc . All rights reserved . \n + \n + Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + you may not use this file except in compliance with the License . \n + You may obtain a copy of the License at \n + \n + http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + \n + Unless required by applicable law or agreed to in writing , software \n + distributed under the License is distributed on an "" AS IS "" BASIS , \n + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + See the License for the specific language governing permissions and \n + limitations under the License . \n + - - > \n + < resources xmlns : tools = "" http : / / schemas . android . com / tools "" > \n + \n + < ! - - Schedule - - > \n + < style name = "" Theme . IOSched . Schedule "" parent = "" @ style / Theme . IOSched . Immersive "" / > \n + \n + < / resources > \n lib \ src \ main \ res \ values \ styles . xml \n - < style name = "" Theme . IOSched . Schedule "" parent = "" @ style / Theme . IOSched . Immersive "" / > \n + < style name = "" Theme . IOSched . Schedule "" parent = "" @ style / Theme . IOSched "" / > \n",Fix status bar background color on landscape \n Change - Id : I9c5ad0acbdf795bebbaf5f8403f6054578636e67,86
build . gradle \n - google ( ) \n + maven { url ' https : / / maven . google . com ' } \n + jcenter ( ) \n - classpath ' com . android . tools . build : gradle : 3 . 0 . 0 - alpha5 ' \n + classpath ' com . android . tools . build : gradle : 3 . 0 . 0 - alpha6 ' \n,Update Gradle plugin to 3 . 0 . 0 - alpha6,86
"mobile \ src \ main \ res \ layout - land \ include _ schedule _ appbar . xml \n - android : layout _ height = "" match _ parent "" \n + android : layout _ height = "" wrap _ content "" \n + android : layout _ gravity = "" center _ vertical "" \n","Fix schedule indicator vertical alignment \n Now centered vertically , previously it visually \n aligned to the top \n Change - Id : I58a89e0bd184c78691c7d3febc7070df87a008b6",86
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ StatusBarScrimBehavior . kt \n - import androidx . core . view . children \n + / / Return false so that the child is laid out by the parent \n + return false \n + } \n - / / Find a AppBarLayout sibling and copy it ' s elevation \n - val appBarLayout = parent . children . first { it is AppBarLayout } \n - ( appBarLayout as ? AppBarLayout ) ? . let { \n - child . elevation = appBarLayout . elevation \n + override fun layoutDependsOn ( \n + parent : CoordinatorLayout , \n + child : View , \n + dependency : View \n + ) : Boolean { \n + if ( dependency is AppBarLayout ) { \n + / / Jump the drawable state in case the elevation is animating \n + dependency . jumpDrawablesToCurrentState ( ) \n + / / Copy over the elevation value \n + child . elevation = dependency . elevation \n + return true \n + return false \n + } \n - / / Return false so that the child is laid out by the parent \n + override fun onDependentViewChanged ( \n + parent : CoordinatorLayout , \n + child : View , \n + dependency : View \n + ) : Boolean { \n + child . elevation = dependency . elevation \n mobile \ src \ main \ res \ layout \ fragment _ info . xml \n - app : layout _ scrollFlags = "" scroll | snap | exitUntilCollapsed "" \n + app : layout _ scrollFlags = "" scroll | enterAlways | snap "" \n - android : layout _ height = "" ? actionBarSize "" / > \n + android : layout _ height = "" wrap _ content "" / > \n + < ! - - A view to draw above the AppBarLayout to mimic the status bar - - > \n + < View \n + android : layout _ width = "" match _ parent "" \n + android : layout _ height = "" 0dp "" \n + android : background = "" ? attr / colorSurface "" \n + android : fitsSystemWindows = "" true "" \n + app : layout _ behavior = "" com . google . samples . apps . iosched . util . StatusBarScrimBehavior "" / > \n + \n + \n","Fix InfoFragment app bar \n It now scrolls correctly , and thus has elevation . \n Required some changes to StatusBarScrimBehavior so \n that it depends on AppBarLayouts , and update its \n elevation automatically to match . \n Change - Id : Ib2f267508a537d163ad49bc5baabba246fcdb5e0",86
"mobile \ src \ main \ res \ drawable \ info _ transport _ footer . xml \n - < path \n - android : fillColor = "" # FFFEFE "" \n - android : pathData = "" M0 , 0H512V288H0z "" / > \n - android : strokeColor = "" # E9E9E9 "" \n + android : strokeColor = "" ? attr / colorControlLight "" \n",Remove white background from Info / Transport footer \n Now looks much better using dark theme \n Change - Id : I13b717386e5b46e535129c20737f247902a4e68c,86
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ SectionHeader . kt \n - data class SectionHeader ( @ StringRes val titleId : Int ) \n + data class SectionHeader ( \n + @ StringRes val titleId : Int , \n + val useHorizontalPadding : Boolean = true \n + ) \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ filters \ ScheduleFilterAdapter . kt \n - newList . add ( SectionHeader ( category . labelResId ) ) \n + newList + = SectionHeader ( \n + titleId = category . labelResId , \n + useHorizontalPadding = false \n + ) \n mobile \ src \ main \ res \ layout \ fragment _ schedule _ filter . xml \n - android : padding = "" @ dimen / margin _ normal "" \n + android : paddingHorizontal = "" @ dimen / margin _ normal "" \n + android : paddingVertical = "" @ dimen / spacing _ normal "" \n + app : layoutManager = "" GridLayoutManager "" \n - app : layoutManager = "" GridLayoutManager "" \n mobile \ src \ main \ res \ layout \ item _ generic _ section _ header . xml \n - android : paddingLeft = "" @ dimen / margin _ normal "" \n - android : paddingRight = "" @ dimen / margin _ normal "" \n + android : paddingLeft = "" @ { sectionHeader . useHorizontalPadding ? @ dimen / margin _ normal : 0 } "" \n + android : paddingRight = "" @ { sectionHeader . useHorizontalPadding ? @ dimen / margin _ normal : 0 } "" \n","Tighten up schedule filter UI \n - Make section headers align to the keyline \n - Reduce vertical padding , it ' s not needed now that \n the chips contain their own padding \n Change - Id : I3e5586fd3ec389cd575939de4a48c348ab930934",86
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ MainActivity . kt \n - import androidx . core . os . BuildCompat \n - if ( drawer . isDrawerOpen ( navigation ) ) { \n - var closeDrawerOnBack = true \n - if ( BuildCompat . isAtLeastQ ( ) ) { \n - closeDrawerOnBack = shouldCloseDrawerFromBackPress ( drawer ) \n - } \n - if ( closeDrawerOnBack ) { \n - closeDrawer ( ) \n - } \n + / * * \n + * If the drawer is open , the behavior changes based on the API level . \n + * When gesture nav is enabled ( Q + ) , we want back to exit when the drawer is open . \n + * When button navigation is enabled ( on Q or pre - Q ) we want to close the drawer on back . \n + * / \n + if ( drawer . isDrawerOpen ( navigation ) & & shouldCloseDrawerFromBackPress ( drawer ) ) { \n + closeDrawer ( ) \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ widget \ IoschedDrawerLayout . kt \n + override fun setDrawerLockMode ( lockMode : Int , edgeGravity : Int ) { \n + super . setDrawerLockMode ( lockMode , edgeGravity ) \n + updateGestureExclusion ( ) \n + } \n + \n - if ( hasClosedDrawer ( Gravity . LEFT ) ) { \n - / / We have a closed drawer on the left , add an exclusion rect so that the user \n - / / can swipe it open \n + if ( getDrawerLockMode ( Gravity . LEFT ) ! = DrawerLayout . LOCK _ MODE _ LOCKED _ CLOSED & & \n + hasClosedDrawer ( Gravity . LEFT ) ) { \n + / / We have a non - locked closed drawer on the left , add an exclusion rect so \n + / / that the user can swipe it open \n - if ( hasClosedDrawer ( Gravity . RIGHT ) ) { \n - / / We have a closed drawer on the right , add an exclusion rect so that the user \n - / / can swipe it open \n + if ( getDrawerLockMode ( Gravity . RIGHT ) ! = DrawerLayout . LOCK _ MODE _ LOCKED _ CLOSED & & \n + hasClosedDrawer ( Gravity . RIGHT ) ) { \n + / / We have a non - locked closed drawer on the right , add an exclusion rect so \n + / / that the user can swipe it open \n",Fix back handling when using gesture nav \n Two issues fixed in this CL : \n - Back when the drawer is open does not actually \n invoke super . onBackPressed ( ) . \n - Disable drawer gesture exclusion logic for locked \n drawers . This enables back to work correctly on the \n detail screens . \n Change - Id : Ic598239458806ffdd63a73495cbc373a751a4be4,86
"build . gradle \n - appcompatVersion = ' 1 . 1 . 0 - alpha03 ' \n + appcompatVersion = ' 1 . 1 . 0 - beta01 ' \n + activityVersion = ' 1 . 0 . 0 - beta01 ' \n - coreVersion = ' 1 . 2 . 0 - alpha01 ' \n + coreVersion = ' 1 . 2 . 0 - alpha02 ' \n - drawerLayoutVersion = ' 1 . 1 . 0 - alpha01 ' \n + drawerLayoutVersion = ' 1 . 1 . 0 - alpha02 ' \n + fragmentVersion = "" 1 . 1 . 0 - beta01 "" \n - lifecycleVersion = ' 2 . 1 . 0 - alpha03 ' \n + lifecycleVersion = ' 2 . 1 . 0 - beta01 ' \n - materialVersion = ' 1 . 1 . 0 - alpha05 ' \n + materialVersion = ' 1 . 1 . 0 - alpha07 ' \n - roomVersion = ' 2 . 1 . 0 - alpha06 ' \n + roomVersion = ' 2 . 1 . 0 ' \n mobile \ build . gradle \n + implementation "" androidx . activity : activity - ktx : $ rootProject . activityVersion "" \n + implementation "" androidx . fragment : fragment - ktx : $ rootProject . fragmentVersion "" \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ map \ MapFragment . kt \n - import androidx . activity . OnBackPressedCallback \n + import androidx . activity . addCallback \n - requireActivity ( ) . addOnBackPressedCallback ( this , OnBackPressedCallback { onBackPressed ( ) } ) \n + requireActivity ( ) . onBackPressedDispatcher . addCallback ( this ) { \n + onBackPressed ( ) \n + } \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleFragment . kt \n - import androidx . activity . OnBackPressedCallback \n + import androidx . activity . addCallback \n - requireActivity ( ) . addOnBackPressedCallback ( this , OnBackPressedCallback { onBackPressed ( ) } ) \n + requireActivity ( ) . onBackPressedDispatcher . addCallback ( this ) { \n + onBackPressed ( ) \n + } \n",Update various AndroidX alpha / beta dependencies \n Change - Id : I21b3cf2d824dfede933639e3e8bae228814e7195,86
"CHANGES \n - Added Debug3dRenderer see https : / / github . com / libgdx / libgdx / pull / 3953 \n - API Change : moved shape builder logic out of MeshBuilder , see : https : / / github . com / libgdx / libgdx / pull / 3996 \n - API Change : Table reset now calls clearChildren , not clear . \n + - Fixed crashes in AndroidMusic . java when isPlaying is called . Errors are now logged only rather than crashing the app . \n - Added TextureArray wrapper see https : / / github . com / libgdx / libgdx / pull / 3807 \n",Changes file updated ( AndroidMusic . java fix ) .,90
"gdx \ src \ com \ badlogic \ gdx \ utils \ ObjectSet . java \n - if ( tableSize > 1 < < 30 ) throw new IllegalArgumentException ( "" The required capacity is too large : "" + capacity ) ; \n + / / Note : 0x40000000 is "" 1 < < 30 "" but crashes under certain circumstances - see : https : / / github . com / libgdx / libgdx / issues / 4065 \n + if ( tableSize > 0x40000000 ) throw new IllegalArgumentException ( "" The required capacity is too large : "" + capacity ) ; \n","Bugfix for crashes under Windows / Linux when "" 1 < < 30 "" didn ' t properly initalize .",90
"gdx \ src \ com \ badlogic \ gdx \ utils \ ObjectSet . java \n - / / Note : 0x40000000 is "" 1 < < 30 "" but crashes under certain circumstances - see : https : / / github . com / libgdx / libgdx / issues / 4065 \n - if ( tableSize > 0x40000000 ) throw new IllegalArgumentException ( "" The required capacity is too large : "" + capacity ) ; \n + if ( tableSize > 1 < < 30 ) throw new IllegalArgumentException ( "" The required capacity is too large : "" + capacity ) ; \n","Revert "" Bugfix for crashes under Windows / Linux when "" 1 < < 30 "" didn ' t properly initalize . "" \n This reverts commit 36dc9706821e4d0867c376cb0a669e5405504210 .",90
"extensions \ gdx - setup \ src \ com \ badlogic \ gdx \ setup \ DependencyBank . java \n - static String moeVersion = "" 1 . 5 . 1 "" ; \n + static String moeVersion = "" 1 . 4 . 0 "" ; \n - static String moePluginImport = "" org . multi - os - engine . community : moe - gradle : "" + moeVersion ; \n + static String moePluginImport = "" org . multi - os - engine : moe - gradle : "" + moeVersion ; \n extensions \ gdx - setup \ src \ com \ badlogic \ gdx \ setup \ GdxSetup . java \n - if ( builder . modules . contains ( ProjectType . IOSMOE ) ) { \n - Executor . execute ( new File ( outputDir ) , "" gradlew . bat "" , "" gradlew "" , "" moeUpdateXcodeSettings "" + parseGradleArgs ( builder . modules , gradleArgs ) , callback ) ; \n - } \n - \n","Revert "" Makes ios - moe generated by gdx - setup . jar work ( # 6016 ) "" ( # 6143 ) \n This reverts commit 90d903a1c0f879da71d7fb3edbb6f8157031a7e6 .",90
"CHANGES \n - Update to LWJGL 3 . 2 . 3 \n - API Change : Table # getRow now returns - 1 when over the table but not over a row ( used to return the last row ) . \n - API Change : Tree # addToTree and # removeFromTree now have an "" int actorIndex "" parameter . \n - \n + - Fixed AndroidInput crashes due to missing array resize ( pressure array ) . \n - API Addition : Allow target display for maximization LWJGL3 backend \n - API Addition : Accelerometer support on GWT \n backends \ gdx - backend - android \ src \ com \ badlogic \ gdx \ backends \ android \ AndroidInput . java \n - import java . util . ArrayList ; \n - import java . util . Arrays ; \n - import java . util . List ; \n - \n - import android . service . wallpaper . WallpaperService . Engine ; \n - import android . view . WindowManager ; \n + import android . view . WindowManager ; \n - \n - import com . badlogic . gdx . Input . TextInputListener ; \n - import com . badlogic . gdx . backends . android . AndroidLiveWallpaperService . AndroidWallpaperEngine ; \n + import java . util . ArrayList ; \n + import java . util . Arrays ; \n + import java . util . List ; \n + \n + pressure = resize ( pressure ) ; \n + private float [ ] resize ( float [ ] orig ) { \n + float [ ] tmp = new float [ orig . length + 2 ] ; \n + System . arraycopy ( orig , 0 , tmp , 0 , orig . length ) ; \n + return tmp ; \n + } \n + \n",Fixed AndroidInput crashes due to missing array resize ( pressure array ) .,90
gdx \ src \ com \ badlogic \ gdx \ graphics \ glutils \ InstanceBufferObjectSubData . java \n + import java . nio . Buffer ; \n,Missing java . nio . Buffer import added .,90
"src \ main \ java \ io \ vertx \ core \ impl \ launcher \ commands \ Watcher . java \n - addFileToWatch ( roots ) ; \n + addFilesToWatchedList ( roots ) ; \n - private void addFileToWatch ( List < File > roots ) { \n - roots . forEach ( this : : addFileToWatch ) ; \n + private void addFilesToWatchedList ( List < File > roots ) { \n + roots . forEach ( this : : addFileToWatchedList ) ; \n - private void addFileToWatch ( File file ) { \n + private void addFileToWatchedList ( File file ) { \n - addFileToWatch ( child ) ; \n + addFileToWatchedList ( child ) ; \n + / * * \n + * Checks whether or not a change has occurred in one of the watched file that match one of the given include pattern \n + * . Are detected : new files , modified file and deleted files . File modification is detected using \n + * { @ link File # lastModified ( ) } , so the behavior depends on the file system precision . \n + * \n + * @ return { @ code true } if a change occurred requiring the redeployment . \n + * / \n - addFileToWatch ( newFile ) ; \n + addFileToWatchedList ( newFile ) ; \n","Integrate reviews and add javadoc . \n I ' ve made the method name a bit more explicit , and explain how the change detection is done . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >",97
src \ main \ asciidoc \ java \ override \ dependencies . adoc \n - < version > 3 . 3 . 0 < / version > \n + < version > 3 . 3 . 1 - SNAPSHOT < / version > \n - - - - \n - - - - \n - compile io . vertx : vertx - core : 3 . 3 . 0 \n + compile io . vertx : vertx - core : 3 . 3 . 1 - SNAPSHOT \n - - - - \n src \ main \ asciidoc \ java \ shareddata . adoc \n + IMPORTANT : The behavior of the distributed data structure depends of the cluster manager you use . Backup \n + ( replication ) and behavior when a network partition is faced are defined by the cluster manager and its \n + configuration . Refer to the cluster manager documentation as well as to the underlying framework manual . \n + \n src \ main \ java \ io \ vertx \ core \ shareddata \ AsyncMap . java \n - * Like { @ link # put } but specifying a timeout . If the value cannot be put within the timeout a \n - * failure will be passed to the handler \n + * Like { @ link # put } but specifying a time to live for the entry . Entry will expire and get evicted after the \n + * ttl . \n - * Link { @ link # putIfAbsent } but specifying a timeout . If the value cannot be put within the timeout a \n - * failure will be passed to the handler \n + * Link { @ link # putIfAbsent } but specifying a time to live for the entry . Entry will expire and get evicted \n + * after the ttl . \n src \ main \ java \ io \ vertx \ core \ shareddata \ package - info . java \n + * IMPORTANT : The behavior of the distributed data structure depends of the cluster manager you use . Backup \n + * ( replication ) and behavior when a network partition is faced are defined by the cluster manager and its \n + * configuration . Refer to the cluster manager documentation as well as to the underlying framework manual . \n + * \n,Address comments from # 1320 : \n * add a note about the behavior of distributed data structure \n * fix mistake in the AsyncMap javadoc \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
src \ main \ asciidoc \ java \ shareddata . adoc \n - IMPORTANT : The behavior of the distributed data structure depends of the cluster manager you use . Backup \n + IMPORTANT : The behavior of the distributed data structure depends on the cluster manager you use . Backup \n src \ main \ java \ io \ vertx \ core \ shareddata \ package - info . java \n - * IMPORTANT : The behavior of the distributed data structure depends of the cluster manager you use . Backup \n + * IMPORTANT : The behavior of the distributed data structure depends on the cluster manager you use . Backup \n,Fix typo \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
src \ test \ java \ io \ vertx \ core \ logging \ Log4J2LogDelegateTest . java \n - import static junit . framework . Assert . assertTrue ; \n + import static org . junit . Assert . assertTrue ; \n,Replace a deprecated package import . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ test \ java \ io \ vertx \ core \ impl \ launcher \ commands \ StartStopListCommandsTest . java \n + if ( ExecUtils . isWindows ( ) ) { \n + / / Test skipped on windows , because on windows we do not check whether or not the pid exists . \n + return ; \n + } \n",Skip the test with an unknown pid on windows . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ java \ io \ vertx \ core \ impl \ VertxImpl . java \n - completionHandler . handle ( Future . failedFuture ( "" Vert . x closed "" ) ) ; \n + if ( completionHandler ! = null ) { \n + / / The completionHandler may be null , we should check before calling it . \n + completionHandler . handle ( Future . failedFuture ( "" Vert . x closed "" ) ) ; \n + } \n src \ test \ java \ io \ vertx \ test \ core \ VerticleFactoryTest . java \n + @ Test \n + public void testDeploymentOnClosedVertxWithCompletionHandler ( ) { \n + TestVerticle verticle = new TestVerticle ( ) ; \n + vertx . close ( done - > { \n + vertx . deployVerticle ( verticle , ar - > { \n + assertFalse ( ar . succeeded ( ) ) ; \n + testComplete ( ) ; \n + } ) ; \n + } ) ; \n + await ( ) ; \n + } \n + \n + @ Test \n + public void testDeploymentOnClosedVertxWithoutCompletionHandler ( ) { \n + TestVerticle verticle = new TestVerticle ( ) ; \n + vertx . close ( done - > { \n + vertx . deployVerticle ( verticle ) ; \n + testComplete ( ) ; \n + } ) ; \n + await ( ) ; \n + } \n + \n + \n",Fix issue # 1383 - check that the completion handler is not null before calling it upon failed verticle deployment \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ java \ io \ vertx \ core \ impl \ VertxImpl . java \n - / / The completionHandler may be null , we should check before calling it . \n",Remove comment \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ java \ io \ vertx \ core \ Launcher . java \n - * \n + * \n + * @ param config the read config , empty if none are provided . \n + * \n + * @ param options the configured Vert . x options . Modify them to customize the Vert . x instance . \n + * \n + * @ param vertx the created Vert . x instance \n + * \n + * @ param deploymentOptions the current deployment options . Modify them to customize the deployment . \n + * \n + * @ param vertx the vert . x instance \n + * @ param mainVerticle the verticle \n + * @ param deploymentOptions the verticle deployment options \n + * @ param cause the cause of the failure \n src \ main \ java \ io \ vertx \ core \ impl \ launcher \ VertxLifecycleHooks . java \n - * @ param config the json config file passed via - conf on the command line \n + * @ param config the json config file passed via - conf on the command line , an empty json object is not set . \n",Extend javadoc \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
src \ main \ java \ io \ vertx \ core \ impl \ launcher \ commands \ BareCommand . java \n + beforeStartingVertx ( options ) ; \n - beforeStartingVertx ( options ) ; \n - beforeStartingVertx ( options ) ; \n src \ main \ java \ io \ vertx \ core \ impl \ launcher \ commands \ RunCommand . java \n - * @ return whether the { @ code cluster } option or the { @ code ha } option are enabled . \n + * @ return whether the { @ code cluster } option or the { @ code ha } option are enabled . Also { @ code true } when a custom \n + * launcher modifies the Vert . x options to set ` clustered ` to { @ code true } \n - return cluster | | ha ; \n + return cluster | | ha | | ( options ! = null & & options . isClustered ( ) ) ; \n,Allow custom launchers to configure whether or not the created vert . x should be clustered . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
src \ main \ java \ io \ vertx \ core \ impl \ launcher \ commands \ RunCommand . java \n + if ( conf = = null ) { \n + conf = new JsonObject ( ) ; \n + } \n,"Don ' t call the ` afterConfigParsed ` callback with ` null ` , create an empty JSON object instead . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >",97
"src \ main \ java \ io \ vertx \ core \ json \ Json . java \n - throw new DecodeException ( "" Failed to decode : "" + e . getMessage ( ) ) ; \n + throw new DecodeException ( "" Failed to decode : "" + e . getMessage ( ) ) ; \n - throw new DecodeException ( "" Failed to decode : "" + e . getMessage ( ) , e ) ; \n + throw new DecodeException ( "" Failed to decode : "" + e . getMessage ( ) , e ) ; \n",Fix https : / / github . com / vert - x3 / issues / issues / 267 \n Add a space between the ` : ` and the exception message . \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ java \ io \ vertx \ core \ impl \ launcher \ commands \ BareCommand . java \n - System . out . println ( "" Shutdown hook ! "" + vertx ) ; \n",Remove trace \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ test \ java \ io \ vertx \ core \ impl \ launcher \ LauncherExtensibilityTest . java \n - BareCommand . getTerminationRunnable ( vertx , LoggerFactory . getLogger ( "" foo "" ) , ( ) - > { \n - asv . set ( true ) ; \n - } ) . run ( ) ; \n + BareCommand . getTerminationRunnable ( vertx , LoggerFactory . getLogger ( "" foo "" ) , ( ) - > asv . set ( true ) ) . run ( ) ; \n + assertThat ( bsv . get ( ) ) . isTrue ( ) ; \n",Check that bsv has been set to true \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ asciidoc \ java \ index . adoc \n - This way avoids leaks ( as the process is restarted ) . \n + This avoids leaks , as the process is restarted . \n - or ` grunt ` to update your resources . Don ' t forget that passing parameter to your application requires the \n + or ` grunt ` to update your resources . Don ' t forget that passing parameters to your application requires the \n src \ main \ java \ io \ vertx \ core \ package - info . java \n - * This way avoids leaks ( as the process is restarted ) . \n + * This avoids leaks , as the process is restarted . \n - * or ` grunt ` to update your resources . Don ' t forget that passing parameter to your application requires the \n + * or ` grunt ` to update your resources . Don ' t forget that passing parameters to your application requires the \n",Apply @ jponge’s reviews \n Signed - off - by : Clement Escoffier < clement . escoffier @ gmail . com >,97
"src \ main \ java \ io \ vertx \ core \ impl \ DeploymentManager . java \n + / * * \n + * < strong > IMPORTANT < / strong > - Isolation groups are not supported on Java 9 + because the application classloader is not \n + * an URLClassLoader anymore . Thus we can ' t extract the list of jars to configure the IsolatedClassLoader . \n + * \n + * / \n + / / IMPORTANT - Isolation groups are not supported on Java 9 + , because the system classloader is not an URLClassLoader \n + / / anymore . Thus we can ' t extract the paths from the classpath and isolate the loading . \n",Add a comment in the method about https : / / github . com / eclipse / vert . x / issues / 2278 . \n Unfortunately IsolationGroup won ' t be supported for Java 9 + until the mechanism is rewritten in a compatible way .,97
travis \ build . sh \n - # browse to the android project \n + # Browse to the android project \n - # build a specific gradle task \n - . / gradlew assembleRelease \n + # This will run our linters etc . \n + # NOTE : check depends on assembleDebug \n + . / gradlew check \n,[ android ] Require check be run in travis build,101
android \ PhysicalWeb \ app \ build . gradle \n - compileSdkVersion 22 \n + compileSdkVersion 21 \n - targetSdkVersion 22 \n + targetSdkVersion 21 \n + / / We ' ll get to fixing the icon later \n + / / Travis requires an older api at the moment \n + disable ' OldTargetApi ' \n,[ android ] Go back to sdk 21 \n This will fix our Travis build since Travis doesn ' t have 22 at the \n moment .,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n + mNotificationManager . cancelAll ( ) ; \n,"[ android ] Cancel prev . notifications on new scan \n This restores previous behavior and fixes a bug . Currently , if \n a user encounters 2 + URLs and then later encounters exactly 1 URL , \n two notifications are displayed . If we kill all the notifications \n at the beginning of a scan , we remove the risk of this happening .",101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n + import java . util . HashSet ; \n + private static final int NOTIFICATION _ VISIBILITY = NotificationCompat . VISIBILITY _ PUBLIC ; \n + private HashSet < String > mPublicUrls ; \n + mPublicUrls = new HashSet < > ( ) ; \n + mPublicUrls . add ( url ) ; \n + if ( android . os . Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . LOLLIPOP ) { \n + if ( mPublicUrls . contains ( url ) ) { \n + builder . setVisibility ( NOTIFICATION _ VISIBILITY ) ; \n + } \n + } \n - Notification notification = builder . setSmallIcon ( R . drawable . ic _ notification ) \n + builder . setSmallIcon ( R . drawable . ic _ notification ) \n - . setContentIntent ( pendingIntent ) \n - . build ( ) ; \n + . setContentIntent ( pendingIntent ) ; \n + if ( android . os . Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . LOLLIPOP ) { \n + builder . setVisibility ( NOTIFICATION _ VISIBILITY ) ; \n + } \n + Notification notification = builder . build ( ) ; \n,"Make all UriBeacon notifications public on Lollipop \n There doesn ' t seem to be any reason why public beacons would give \n anything other than public notifications . This change makes beacons \n publicly visible on the Android 5 . 0 lock screen when the user has \n "" hide sensitive notification content "" selected . \n However , this change keeps urls discovered through mdns or ssdp as \n private .",101
"android \ PhysicalWeb \ app \ src \ main \ AndroidManifest . xml \n + < uses - permission android : name = "" android . permission . RECEIVE _ BOOT _ COMPLETED "" / > \n + < receiver \n + android : name = "" . AutostartUriBeaconDiscoveryServiceReceiver "" > \n + < intent - filter > \n + < action android : name = "" android . intent . action . BOOT _ COMPLETED "" / > \n + < / intent - filter > \n + < / receiver > \n + \n new file \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ AutostartUriBeaconDiscoveryServiceReceiver . java \n + / * \n + * Copyright 2015 Google Inc . All rights reserved . \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * / \n + \n + package org . physical _ web . physicalweb ; \n + \n + import android . content . BroadcastReceiver ; \n + import android . content . Context ; \n + import android . content . Intent ; \n + import android . content . SharedPreferences ; \n + \n + / * * \n + * This receiver starts the UriBeaconDiscoveryService \n + * / \n + public class AutostartUriBeaconDiscoveryServiceReceiver extends BroadcastReceiver { \n + public void onReceive ( Context context , Intent intent ) { \n + String preferences _ key = context . getString ( R . string . physical _ web _ preference _ file _ name ) ; \n + SharedPreferences sharedPreferences = \n + context . getSharedPreferences ( preferences _ key , Context . MODE _ PRIVATE ) ; \n + if ( sharedPreferences . getBoolean ( context . getString ( R . string . user _ opted _ in _ flag ) , false ) ) { \n + Intent newIntent = new Intent ( context , UriBeaconDiscoveryService . class ) ; \n + context . startService ( newIntent ) ; \n + } \n + } \n + } \n","Ensure the discovery service starts at boot \n Previously , a user would have to reopen the application after rebooting \n in order to start the discovery service again . This starts it \n automatically if they have opted in .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n - MetadataResolver . UrlMetadata urlMetadata _ firstBeacon = mUrlToUrlMetadata . get ( url ) ; \n - if ( urlMetadata _ firstBeacon ! = null ) { \n - String title = mUrlToUrlMetadata . get ( url ) . title ; \n - String description = mUrlToUrlMetadata . get ( url ) . description ; \n - Bitmap icon = mUrlToUrlMetadata . get ( url ) . icon ; \n - remoteViews . setImageViewBitmap ( R . id . icon _ firstBeacon , icon ) ; \n - remoteViews . setTextViewText ( R . id . title _ firstBeacon , title ) ; \n - remoteViews . setTextViewText ( R . id . url _ firstBeacon , url ) ; \n - remoteViews . setTextViewText ( R . id . description _ firstBeacon , description ) ; \n + MetadataResolver . UrlMetadata urlMetadata = mUrlToUrlMetadata . get ( url ) ; \n + if ( urlMetadata ! = null ) { \n + remoteViews . setImageViewBitmap ( R . id . icon _ firstBeacon , urlMetadata . icon ) ; \n + remoteViews . setTextViewText ( R . id . title _ firstBeacon , urlMetadata . title ) ; \n + remoteViews . setTextViewText ( R . id . url _ firstBeacon , urlMetadata . siteUrl ) ; \n + remoteViews . setTextViewText ( R . id . description _ firstBeacon , urlMetadata . description ) ; \n - MetadataResolver . UrlMetadata urlMetadata _ secondBeacon = mUrlToUrlMetadata . get ( url ) ; \n - if ( urlMetadata _ secondBeacon ! = null ) { \n - String title = mUrlToUrlMetadata . get ( url ) . title ; \n - String description = mUrlToUrlMetadata . get ( url ) . description ; \n - Bitmap icon = mUrlToUrlMetadata . get ( url ) . icon ; \n - remoteViews . setImageViewBitmap ( R . id . icon _ secondBeacon , icon ) ; \n - remoteViews . setTextViewText ( R . id . title _ secondBeacon , title ) ; \n - remoteViews . setTextViewText ( R . id . url _ secondBeacon , url ) ; \n - remoteViews . setTextViewText ( R . id . description _ secondBeacon , description ) ; \n + MetadataResolver . UrlMetadata urlMetadata = mUrlToUrlMetadata . get ( url ) ; \n + if ( urlMetadata ! = null ) { \n + remoteViews . setImageViewBitmap ( R . id . icon _ secondBeacon , urlMetadata . icon ) ; \n + remoteViews . setTextViewText ( R . id . title _ secondBeacon , urlMetadata . title ) ; \n + remoteViews . setTextViewText ( R . id . url _ secondBeacon , urlMetadata . siteUrl ) ; \n + remoteViews . setTextViewText ( R . id . description _ secondBeacon , urlMetadata . description ) ; \n","Use full siteUrl to update summary notification \n The summary notification was being updated with short urls , depending \n on what was provided by the beacon . This change ensures that they use \n the full siteUrl provided by the metadata service .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MdnsPwoDiscoverer . java \n + if ( toRestart ) { \n + toRestart = false ; \n + startScan ( ) ; \n + } \n + private boolean toRestart ; \n + toRestart = false ; \n - mNsdManager . discoverServices ( MDNS _ SERVICE _ TYPE , NsdManager . PROTOCOL _ DNS _ SD , mDiscoveryListener ) ; \n + mNsdManager . discoverServices ( MDNS _ SERVICE _ TYPE , NsdManager . PROTOCOL _ DNS _ SD , mDiscoveryListener ) ; \n - mNsdManager . stopServiceDiscovery ( mDiscoveryListener ) ; \n + mNsdManager . stopServiceDiscovery ( mDiscoveryListener ) ; \n + } \n + \n + @ Override \n + public synchronized void restartScan ( ) { \n + toRestart = true ; \n + stopScan ( ) ; \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoverer . java \n + public void restartScan ( ) { \n + stopScan ( ) ; \n + startScan ( ) ; \n + } \n + \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n + mPwoResponseCallbacks . add ( pwoResponseCallback ) ; \n + } else { \n + / / If the client isn ' t requesting cached PWOs , let ' s restart the scanners so that those \n + / / scanners that only discover a PWO once ( and not repeatedly ) will have an opportunity \n + / / to report all results . \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . restartScan ( ) ; \n + } \n - mPwoResponseCallbacks . add ( pwoResponseCallback ) ; \n","[ android ] Restart scanners on refresh \n This fixes a bug with refreshing mdns results , since mdns results \n are typically only found once in a scan , and not frequently like ble \n results .",101
android \ PhysicalWeb \ app \ build . gradle \n + \n - compile files ( ' libs / google - api - client - 1 . 19 . 0 . jar ' ) \n - compile files ( ' libs / google - http - client - 1 . 19 . 0 . jar ' ) \n - compile files ( ' libs / google - api - services - urlshortener - v1 - rev33 - 1 . 19 . 0 . jar ' ) \n - compile files ( ' libs / google - http - client - android - 1 . 19 . 0 . jar ' ) \n + compile ' com . google . api - client : google - api - client : 1 . 19 . 0 ' \n + compile ' com . google . apis : google - api - services - urlshortener : v1 - rev33 - 1 . 19 . 0 ' \n + compile ' com . google . http - client : google - http - client : 1 . 19 . 0 ' \n + compile ' com . google . http - client : google - http - client - android : 1 . 19 . 0 ' \n deleted file \n android \ PhysicalWeb \ app \ libs \ google - api - client - 1 . 19 . 0 . jar \n Binary files a / android / PhysicalWeb / app / libs / google - api - client - 1 . 19 . 0 . jar and / dev / null differ \n deleted file \n android \ PhysicalWeb \ app \ libs \ google - api - services - urlshortener - v1 - rev33 - 1 . 19 . 0 . jar \n Binary files a / android / PhysicalWeb / app / libs / google - api - services - urlshortener - v1 - rev33 - 1 . 19 . 0 . jar and / dev / null differ \n deleted file \n android \ PhysicalWeb \ app \ libs \ google - http - client - 1 . 19 . 0 . jar \n Binary files a / android / PhysicalWeb / app / libs / google - http - client - 1 . 19 . 0 . jar and / dev / null differ \n deleted file \n android \ PhysicalWeb \ app \ libs \ google - http - client - android - 1 . 19 . 0 . jar \n Binary files a / android / PhysicalWeb / app / libs / google - http - client - android - 1 . 19 . 0 . jar and / dev / null differ \n,Use maven to fetch our . jar libraries . \n This change removes the . jar files from our source tree and fetches \n them via maven .,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + view . findViewById ( R . id . metadata _ debug _ container ) . setVisibility ( View . VISIBLE ) ; \n + view . findViewById ( R . id . metadata _ debug _ container ) . setVisibility ( View . GONE ) ; \n + \n + PwsClient . UrlMetadata metadata = mUrlToUrlMetadata . get ( url ) ; \n + if ( metadata ! = null ) { \n + float rank = metadata . rank ; \n + String rankString = getString ( R . string . metadata _ debug _ rank _ prefix ) + rank ; \n + TextView rankView = ( TextView ) view . findViewById ( R . id . metadata _ debug _ rank ) ; \n + rankView . setText ( rankString ) ; \n + } \n android \ PhysicalWeb \ app \ src \ main \ res \ layout \ list _ item _ nearby _ beacon . xml \n - < / LinearLayout > \n + < LinearLayout \n + android : layout _ width = "" match _ parent "" \n + android : layout _ height = "" wrap _ content "" \n + android : orientation = "" horizontal "" \n + android : id = "" @ + id / metadata _ debug _ container "" \n + android : visibility = "" gone "" > \n + \n + < TextView \n + android : layout _ width = "" wrap _ content "" \n + android : layout _ height = "" match _ parent "" \n + android : layout _ weight = "" 1 "" \n + android : textSize = "" 16sp "" \n + android : textColor = "" # bbbbbb "" \n + android : id = "" @ + id / metadata _ debug _ rank "" / > \n + < / LinearLayout > \n + \n + < / LinearLayout > \n android \ PhysicalWeb \ app \ src \ main \ res \ values \ strings . xml \n + < string name = "" metadata _ debug _ rank _ prefix "" > rank : < / string > \n",[ android ] Add a metadata debug view,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n - private static final int NOTIFICATION _ PRIORITY = NotificationCompat . PRIORITY _ LOW ; \n + private static final int NOTIFICATION _ PRIORITY = NotificationCompat . PRIORITY _ MIN ; \n,[ android ] Change notify priority from low to min \n This takes the notification off the lockscreen and off the status bar . \n They become discoverable only on expanding the notification shade . \n More info : \n http : / / developer . android . com / design / patterns / notifications . html,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + PwsClient . getInstance ( getActivity ( ) ) . useDevEndpoint ( ) ; \n + PwsClient . getInstance ( getActivity ( ) ) . useProdEndpoint ( ) ; \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwsClient . java \n - / / private static final String DEV _ URL = "" https : / / url - caster - dev . appspot . com "" ; \n + private static final String DEV _ URL = "" https : / / url - caster - dev . appspot . com "" ; \n + private String mEndpointUrl ; \n + mEndpointUrl = PROD _ URL ; \n + public void useProdEndpoint ( ) { \n + mEndpointUrl = PROD _ URL ; \n + } \n + \n + public void useDevEndpoint ( ) { \n + mEndpointUrl = DEV _ URL ; \n + } \n + \n",[ android ] Use PWS dev server in debug mode,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + import android . util . Log ; \n - mNearbyDeviceAdapter . sortDevices ( ) ; \n + mNearbyDeviceAdapter . sortUrls ( ) ; \n - String url = mNearbyDeviceAdapter . getUrlForListItem ( position ) ; \n + String url = mNearbyDeviceAdapter . getItem ( position ) ; \n - mNearbyDeviceAdapter . sortDevices ( ) ; \n + mNearbyDeviceAdapter . sortUrls ( ) ; \n - private List < String > mSortedDevices ; \n + private List < String > mSortedUrls ; \n - mSortedDevices = new ArrayList < > ( ) ; \n + mSortedUrls = new ArrayList < > ( ) ; \n - return mSortedDevices . size ( ) ; \n + return mSortedUrls . size ( ) ; \n - return mSortedDevices . get ( i ) ; \n + return mSortedUrls . get ( i ) ; \n - String url = getUrlForListItem ( i ) ; \n + String url = getItem ( i ) ; \n - public String getUrlForListItem ( int i ) { \n - String address = getItem ( i ) ; \n - for ( String url : mUrlToDeviceAddress . keySet ( ) ) { \n - if ( mUrlToDeviceAddress . get ( url ) . equals ( address ) ) { \n - return url ; \n - } \n - } \n - return null ; \n - } \n - \n - public void sortDevices ( ) { \n - mSortedDevices = new ArrayList < > ( mUrlToDeviceAddress . values ( ) ) ; \n - Collections . sort ( mSortedDevices , new MetadataComparator ( mUrlToUrlMetadata ) ) ; \n + public void sortUrls ( ) { \n + Log . d ( TAG , "" Sorting urls "" ) ; \n + mSortedUrls = new ArrayList < > ( mUrlToDeviceAddress . keySet ( ) ) ; \n + Collections . sort ( mSortedUrls , new MetadataComparator ( mUrlToUrlMetadata ) ) ; \n - mSortedDevices . clear ( ) ; \n + mSortedUrls . clear ( ) ; \n","[ android ] Fix sorting bug \n We had been using device addresses to do metadata lookups where urls \n were the expected key . As one might expect , this led to arbitrarily \n sorted values .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ AboutFragment . java \n - webView . getSettings ( ) . setRenderPriority ( WebSettings . RenderPriority . HIGH ) ; \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ OobActivity . java \n - webView . getSettings ( ) . setRenderPriority ( WebSettings . RenderPriority . HIGH ) ; \n - } \n + } \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwsClient . java \n - import java . util . Collection ; \n - Request request = new JsonObjectRequest ( \n + JsonObjectRequest request = new JsonObjectRequest ( \n - Request request = createUrlMetadataRequest ( jsonObj , false , resolveScanCallback ) ; \n + JsonObjectRequest request = createUrlMetadataRequest ( jsonObj , false , resolveScanCallback ) ; \n - Request request = createUrlMetadataRequest ( null , true , resolveScanCallback ) ; \n + JsonObjectRequest request = createUrlMetadataRequest ( null , true , resolveScanCallback ) ; \n - private Request createUrlMetadataRequest ( \n + private JsonObjectRequest createUrlMetadataRequest ( \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n + @ SuppressWarnings ( "" deprecation "" ) \n + / / NOTE : use powerManager . isInteractive ( ) when minsdk > = 20 \n android \ PhysicalWeb \ build . gradle \n + gradle . projectsEvaluated { \n + tasks . withType ( JavaCompile ) { \n + options . compilerArgs < < "" - Xlint : unchecked "" < < "" - Xlint : deprecation "" \n + } \n + } \n","[ android ] Fix unchecked ops and deprecations \n Additionally , add checks for these things to build . gradle .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - Log . d ( TAG , url + "" Metadata not null1 "" ) ; \n - / / TODO : urlTextView . setText ( urlMetadata . displayUrl ) ; \n - urlTextView . setText ( url ) ; \n + urlTextView . setText ( urlMetadata . displayUrl ) ; \n - Log . d ( TAG , url + "" Metadata null1 "" ) ; \n - Log . d ( TAG , url + "" Metadata not null2 "" ) ; \n + new DecimalFormat ( "" # # . # # "" ) . format ( rank ) ; \n",[ android ] Cleanup errs from debug output change,101
"android \ PhysicalWeb \ app \ build . gradle \n - versionCode 12 \n - versionName "" 0 . 1 . 853 "" \n + versionCode 13 \n + versionName "" 0 . 1 . 854 "" \n",[ android ] Bump version for new release,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - + new DecimalFormat ( "" # # . # # s "" ) . format ( pwsTripTime ) + "" "" + url ; \n + + new DecimalFormat ( "" # # . # # s "" ) . format ( pwsTripTime ) ; \n",[ android ] Remove unhelpful url from debug display,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + mNearbyDeviceAdapter . notifyDataSetChanged ( ) ; \n,[ android ] Update UI when emptying metadata queue \n The whole intend of queueing up metadata before emptying into in the \n adapter is so that we can control when the information is displayed . \n This is a partial fix for issue # 445,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n - . setServiceData ( UriBeacon . URI _ SERVICE _ UUID , \n - new byte [ ] { } , \n - new byte [ ] { } ) \n + . setServiceUuid ( UriBeacon . URI _ SERVICE _ UUID ) \n - . setServiceData ( UriBeacon . TEST _ SERVICE _ UUID , \n - new byte [ ] { } , \n - new byte [ ] { } ) \n + . setServiceUuid ( UriBeacon . TEST _ SERVICE _ UUID ) \n","[ android ] Use setServiceUuid to build scan filter \n Not only is this simpler , but this ensures that other mask values , etc . \n are set to null and not an empty byte array . This ensures that all the \n appropriate beacons show up and fixes a bug that hid some in the \n surfaced notifications .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ UriBeaconDiscoveryService . java \n + import java . util . Date ; \n + private long mScanStartTime ; \n - mCanUpdateNotifications = false ; \n - mHandler . postDelayed ( mNotificationUpdateGateTimeout , NOTIFICATION _ UPDATE _ GATE _ DURATION ) ; \n - startSearchingForUriBeacons ( ) ; \n - mMdnsUrlDiscoverer . startScanning ( ) ; \n - mSsdpUrlDiscoverer . startScanning ( ) ; \n + startSearchingForPwos ( ) ; \n - mHandler . removeCallbacks ( mNotificationUpdateGateTimeout ) ; \n - stopSearchingForUriBeacons ( ) ; \n - mMdnsUrlDiscoverer . stopScanning ( ) ; \n - mSsdpUrlDiscoverer . stopScanning ( ) ; \n + stopSearchingForPwos ( ) ; \n + private void startSearchingForPwos ( ) { \n + mScanStartTime = new Date ( ) . getTime ( ) ; \n + mCanUpdateNotifications = false ; \n + mHandler . postDelayed ( mNotificationUpdateGateTimeout , NOTIFICATION _ UPDATE _ GATE _ DURATION ) ; \n + startSearchingForUriBeacons ( ) ; \n + mMdnsUrlDiscoverer . startScanning ( ) ; \n + mSsdpUrlDiscoverer . startScanning ( ) ; \n + } \n + \n + private void stopSearchingForPwos ( ) { \n + mHandler . removeCallbacks ( mNotificationUpdateGateTimeout ) ; \n + stopSearchingForUriBeacons ( ) ; \n + mMdnsUrlDiscoverer . stopScanning ( ) ; \n + mSsdpUrlDiscoverer . stopScanning ( ) ; \n + } \n + \n - mCanUpdateNotifications = false ; \n - mHandler . postDelayed ( mNotificationUpdateGateTimeout , NOTIFICATION _ UPDATE _ GATE _ DURATION ) ; \n - startSearchingForUriBeacons ( ) ; \n - mMdnsUrlDiscoverer . startScanning ( ) ; \n - mSsdpUrlDiscoverer . startScanning ( ) ; \n + startSearchingForPwos ( ) ; \n - mHandler . removeCallbacks ( mNotificationUpdateGateTimeout ) ; \n - stopSearchingForUriBeacons ( ) ; \n - mMdnsUrlDiscoverer . stopScanning ( ) ; \n - mSsdpUrlDiscoverer . stopScanning ( ) ; \n + stopSearchingForPwos ( ) ; \n",[ android ] Consolidate start / stop code in service,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MdnsUrlDiscoverer . java \n + isRunning = true ; \n + isRunning = false ; \n + private boolean isRunning ; \n + isRunning = false ; \n - public void startScanning ( ) { \n + public synchronized void startScanning ( ) { \n + if ( isRunning ) { \n + return ; \n + } \n - public void stopScanning ( ) { \n + public synchronized void stopScanning ( ) { \n + if ( ! isRunning ) { \n + return ; \n + } \n - } \n + } \n,[ android ] Safe start / stop mdns discovery \n The NsdManager likes to complain if we start or stop it while it is \n already in the desired state . This change turns our \n start / stopScanning methods into safe methods that check the state of \n the scanner before performing the operation .,101
"new file \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoverer . java \n + / * \n + * Copyright 2015 Google Inc . All rights reserved . \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * / \n + \n + package org . physical _ web . physicalweb ; \n + \n + import java . util . Date ; \n + \n + abstract class PwoDiscoverer { \n + \n + private PwoDiscoveryCallback mPwoDiscoveryCallback ; \n + private long mScanStartTime ; \n + \n + public abstract void startScanImpl ( ) ; \n + public abstract void stopScanImpl ( ) ; \n + \n + public void startScan ( ) { \n + mScanStartTime = new Date ( ) . getTime ( ) ; \n + startScanImpl ( ) ; \n + } \n + \n + public void stopScan ( ) { \n + stopScanImpl ( ) ; \n + } \n + \n + public void setCallback ( PwoDiscoveryCallback pwoDiscoveryCallback ) { \n + mPwoDiscoveryCallback = pwoDiscoveryCallback ; \n + } \n + \n + protected PwoMetadata createPwoMetadata ( String url ) { \n + PwoMetadata pwoMetadata = new PwoMetadata ( url , new Date ( ) . getTime ( ) - mScanStartTime ) ; \n + return pwoMetadata ; \n + } \n + \n + protected void reportPwo ( PwoMetadata pwoMetadata ) { \n + mPwoDiscoveryCallback . onPwoDiscovered ( pwoMetadata ) ; \n + } \n + \n + public interface PwoDiscoveryCallback { \n + public void onPwoDiscovered ( PwoMetadata pwoMetadata ) ; \n + } \n + } \n",[ android ] Add a PwoDiscoverer class \n This class is designed to provide a standard interface to all classes \n that discover Physical Web Objects and provide some common \n functionality .,101
"rename from android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MdnsUrlDiscoverer . java \n rename to android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MdnsPwoDiscoverer . java \n - class MdnsUrlDiscoverer { \n + class MdnsPwoDiscoverer extends PwoDiscoverer { \n - private static final String TAG = "" MdnsUrlDiscoverer "" ; \n + private static final String TAG = "" MdnsPwoDiscoverer "" ; \n - mMdnsUrlDiscovererCallback . onMdnsUrlFound ( name ) ; \n + PwoMetadata pwoMetadata = createPwoMetadata ( name ) ; \n + pwoMetadata . isPublic = false ; \n + reportPwo ( pwoMetadata ) ; \n - private MdnsUrlDiscovererCallback mMdnsUrlDiscovererCallback ; \n - public MdnsUrlDiscoverer ( Context context , MdnsUrlDiscovererCallback mdnsUrlDiscovererCallback ) { \n - mMdnsUrlDiscovererCallback = mdnsUrlDiscovererCallback ; \n + public MdnsPwoDiscoverer ( Context context ) { \n - public synchronized void startScanning ( ) { \n + @ Override \n + public synchronized void startScanImpl ( ) { \n - public synchronized void stopScanning ( ) { \n + @ Override \n + public synchronized void stopScanImpl ( ) { \n - \n - public interface MdnsUrlDiscovererCallback { \n - public void onMdnsUrlFound ( String url ) ; \n - } \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - MdnsUrlDiscoverer . MdnsUrlDiscovererCallback , \n - private MdnsUrlDiscoverer mMdnsUrlDiscoverer ; \n - for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n - pwoDiscoverer . setCallback ( this ) ; \n - } \n - mMdnsUrlDiscoverer = new MdnsUrlDiscoverer ( getActivity ( ) , NearbyBeaconsFragment . this ) ; \n + mPwoDiscoverers . add ( new MdnsPwoDiscoverer ( getActivity ( ) ) ) ; \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . setCallback ( this ) ; \n + } \n - mMdnsUrlDiscoverer . stopScanning ( ) ; \n - mMdnsUrlDiscoverer . startScanning ( ) ; \n - @ Override \n - public void onMdnsUrlFound ( String url ) { \n - onLanUrlFound ( url ) ; \n - } \n - \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n - MdnsUrlDiscoverer . MdnsUrlDiscovererCallback , \n - private MdnsUrlDiscoverer mMdnsUrlDiscoverer ; \n + mPwoDiscoverers . add ( new MdnsPwoDiscoverer ( this ) ) ; \n - mMdnsUrlDiscoverer = new MdnsUrlDiscoverer ( this , this ) ; \n - @ Override \n - public void onMdnsUrlFound ( String url ) { \n - onLanUrlFound ( url ) ; \n - } \n - \n - mMdnsUrlDiscoverer . startScanning ( ) ; \n - mMdnsUrlDiscoverer . stopScanning ( ) ; \n",[ android ] Convert mdns discoverer to PwoDiscoverer \n This change turns the old MdnsUrlDiscoverer class into a \n MdnsPwoDiscoverer class .,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + PwoDiscoverer . PwoDiscoveryCallback , \n + private List < PwoDiscoverer > mPwoDiscoverers ; \n + mPwoDiscoverers = new ArrayList < > ( ) ; \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . setCallback ( this ) ; \n + } \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . stopScan ( ) ; \n + } \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . startScan ( ) ; \n + } \n + @ Override \n + public void onPwoDiscovered ( PwoMetadata pwoMetadata ) { \n + if ( pwoMetadata . hasBleMetadata ( ) ) { \n + BleMetadata bleMetadata = pwoMetadata . bleMetadata ; \n + mNearbyDeviceAdapter . updateItem ( pwoMetadata . url , bleMetadata . deviceAddress , bleMetadata . rssi , \n + bleMetadata . txPower ) ; \n + } \n + \n + if ( ! mUrlToPwoMetadata . containsKey ( pwoMetadata . url ) ) { \n + mUrlToPwoMetadata . put ( pwoMetadata . url , pwoMetadata ) ; \n + PwsClient . getInstance ( getActivity ( ) ) . findUrlMetadata ( pwoMetadata , this , TAG ) ; \n + mPwoMetadataQueue . add ( pwoMetadata ) ; \n + if ( mSecondScanComplete ) { \n + emptyPwoMetadataQueue ( ) ; \n + } \n + } \n + } \n + \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n + import org . physical _ web . physicalweb . PwoMetadata . BleMetadata ; \n + PwoDiscoverer . PwoDiscoveryCallback , \n + private List < PwoDiscoverer > mPwoDiscoverers ; \n + mPwoDiscoverers = new ArrayList < > ( ) ; \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . setCallback ( this ) ; \n + } \n + @ Override \n + public void onPwoDiscovered ( PwoMetadata pwoMetadata ) { \n + if ( pwoMetadata . hasBleMetadata ( ) ) { \n + BleMetadata bleMetadata = pwoMetadata . bleMetadata ; \n + mRegionResolver . onUpdate ( bleMetadata . deviceAddress , bleMetadata . rssi , bleMetadata . txPower ) ; \n + } \n + \n + if ( ! mUrlToPwoMetadata . containsKey ( pwoMetadata . url ) ) { \n + mUrlToPwoMetadata . put ( pwoMetadata . url , pwoMetadata ) ; \n + PwsClient . getInstance ( this ) . findUrlMetadata ( pwoMetadata , this , TAG ) ; \n + } \n + } \n + \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . startScan ( ) ; \n + } \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . stopScan ( ) ; \n + } \n","[ android ] Use the new PwoDiscoverer class \n Although no class actually extends this class yet , this change places \n a list of discovery services into our service and fragment so that it \n can be populated with discoverers at a later time .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MdnsUrlDiscoverer . java \n - isRunning = true ; \n + mState = State . STARTED ; \n - isRunning = false ; \n + mState = State . STOPPED ; \n - private boolean isRunning ; \n + private enum State { \n + STOPPED , \n + WAITING , \n + STARTED , \n + } \n + private State mState ; \n - isRunning = false ; \n + mState = State . STOPPED ; \n - if ( isRunning ) { \n + if ( mState ! = State . STOPPED ) { \n + mState = State . WAITING ; \n - if ( ! isRunning ) { \n + if ( mState ! = State . STARTED ) { \n + mState = State . WAITING ; \n","[ android ] Further fortify mdns start / stop \n The mdns scan start / stop still isn ' t robust enough . The reason seems to be \n that while we are waiting on a response , client code can call start / stop a \n second time and the NsdManager doesn ' t like that .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + private boolean mRequestCachedPwos ; \n - public void onServiceConnected ( ComponentName className , IBinder service ) { \n + public synchronized void onServiceConnected ( ComponentName className , IBinder service ) { \n - mDiscoveryService . requestPwoMetadata ( NearbyBeaconsFragment . this ) ; \n - startScanningDisplay ( mDiscoveryService . getScanStartTime ( ) ) ; \n + mDiscoveryService . requestPwoMetadata ( NearbyBeaconsFragment . this , mRequestCachedPwos ) ; \n + startScanningDisplay ( mRequestCachedPwos ? mDiscoveryService . getScanStartTime ( ) \n + : new Date ( ) . getTime ( ) ) ; \n - public void onServiceDisconnected ( ComponentName className ) { \n + public synchronized void onServiceDisconnected ( ComponentName className ) { \n - public void connect ( ) { \n + public synchronized void connect ( boolean requestCachedPwos ) { \n + mRequestCachedPwos = requestCachedPwos ; \n - public void disconnect ( ) { \n + public synchronized void disconnect ( ) { \n - mDiscoveryServiceConnection . connect ( ) ; \n + mDiscoveryServiceConnection . connect ( true ) ; \n - / / Kill the service to force a refresh \n + / / Reconnect to the service \n - Intent intent = new Intent ( getActivity ( ) , PwoDiscoveryService . class ) ; \n - getActivity ( ) . stopService ( intent ) ; \n - \n - / / Connect to the service \n - mDiscoveryServiceConnection . connect ( ) ; \n + mDiscoveryServiceConnection . connect ( false ) ; \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n - public void requestPwoMetadata ( PwoResponseCallback pwoResponseCallback ) { \n - for ( PwoMetadata pwoMetadata : mUrlToPwoMetadata . values ( ) ) { \n - pwoResponseCallback . onPwoDiscovered ( pwoMetadata ) ; \n + public void requestPwoMetadata ( PwoResponseCallback pwoResponseCallback , \n + boolean requestCachedPwos ) { \n + if ( requestCachedPwos ) { \n + for ( PwoMetadata pwoMetadata : mUrlToPwoMetadata . values ( ) ) { \n + pwoResponseCallback . onPwoDiscovered ( pwoMetadata ) ; \n + } \n",[ android ] Refresh without killing DiscoveryService \n This change will also prepare us for when the service chaches \n PwoMetadata objects because at that point merely killing the \n service won ' t be enough to force a refresh .,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ BeaconConfigFragment . java \n - \n - @ Override \n - public void onUrlMetadataIconReceived ( PwoMetadata pwoMetadata ) { \n - } \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n + @ Override \n + public void onUrlMetadataIconError ( PwoMetadata pwoMetadata ) { \n + } \n + \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n + PwsClient . DownloadIconCallback , \n - PwsClient . ResolveScanCallback { \n + PwsClient . ResolveScanCallback , \n + PwsClient . DownloadIconCallback { \n + if ( ! pwoMetadata . urlMetadata . iconUrl . isEmpty ( ) ) { \n + PwsClient . getInstance ( this ) . downloadIcon ( pwoMetadata , this ) ; \n + } \n + @ Override \n + public void onUrlMetadataIconError ( PwoMetadata pwoMetadata ) { \n + for ( PwoResponseCallback pwoResponseCallback : mPwoResponseCallbacks ) { \n + pwoResponseCallback . onUrlMetadataIconError ( pwoMetadata ) ; \n + } \n + } \n + \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwsClient . java \n + } \n + \n + public interface DownloadIconCallback { \n + public void onUrlMetadataIconError ( PwoMetadata pwoMetadata ) ; \n - \n - if ( ! urlMetadata . iconUrl . isEmpty ( ) ) { \n - downloadIcon ( pwoMetadata , resolveScanCallback ) ; \n - } \n - * @ param urlMetadata The metadata for the given url \n + * @ param pwoMetadata contains the relevant UrlMetadata \n - private void downloadIcon ( final PwoMetadata pwoMetadata , \n - final ResolveScanCallback resolveScanCallback ) { \n + public void downloadIcon ( final PwoMetadata pwoMetadata , \n + final DownloadIconCallback downloadIconCallback ) { \n - ImageRequest imageRequest = new ImageRequest ( urlMetadata . iconUrl , \n - new Response . Listener < Bitmap > ( ) { \n + Response . Listener < Bitmap > responseListener = new Response . Listener < Bitmap > ( ) { \n - resolveScanCallback . onUrlMetadataIconReceived ( pwoMetadata ) ; \n + downloadIconCallback . onUrlMetadataIconReceived ( pwoMetadata ) ; \n - } , 0 , 0 , null , null ) ; \n + } ; \n + Response . ErrorListener errorListener = new Response . ErrorListener ( ) { \n + @ Override \n + public void onErrorResponse ( VolleyError error ) { \n + downloadIconCallback . onUrlMetadataIconError ( pwoMetadata ) ; \n + } \n + } ; \n + ImageRequest imageRequest = new ImageRequest ( urlMetadata . iconUrl , responseListener , 0 , 0 , null , \n + errorListener ) ; \n","[ android ] Require explicit call to DL favicon \n This is desirable for three reasons : \n 1 . These are independent features of the PWS , the calls should be made \n distinct \n 2 . The BeaconConfigFragment doesn ' t use the icon , so we shouldn ' t \n download it \n 3 . When we start caching PWOs in the discovery service , we ' ll need to \n fetch icons if we already have the url metadata , but no icon .",101
"android \ PhysicalWeb \ app \ src \ main \ res \ layout \ activity _ oob . xml \n - android : paddingLeft = "" 16dp "" \n - android : paddingRight = "" 16dp "" \n + android : paddingStart = "" 16dp "" \n + android : paddingEnd = "" 16dp "" \n android \ PhysicalWeb \ app \ src \ main \ res \ layout \ fragment _ beacon _ config . xml \n - android : paddingLeft = "" 16dp "" \n - android : paddingRight = "" 16dp "" \n + android : paddingStart = "" 16dp "" \n + android : paddingEnd = "" 16dp "" \n - android : paddingLeft = "" 20dp "" \n - android : paddingRight = "" 20dp "" \n + android : paddingStart = "" 20dp "" \n + android : paddingEnd = "" 20dp "" \n - android : paddingLeft = "" 10dp "" \n - android : paddingRight = "" 10dp "" \n + android : paddingStart = "" 10dp "" \n + android : paddingEnd = "" 10dp "" \n - android : paddingLeft = "" 10dp "" \n - android : paddingRight = "" 10dp "" \n + android : paddingStart = "" 10dp "" \n + android : paddingEnd = "" 10dp "" \n - android : paddingLeft = "" 10dp "" \n - android : paddingRight = "" 10dp "" \n + android : paddingStart = "" 10dp "" \n + android : paddingEnd = "" 10dp "" \n android \ PhysicalWeb \ app \ src \ main \ res \ layout \ list _ item _ nearby _ beacon . xml \n - android : paddingLeft = "" 18dp "" \n - android : paddingRight = "" 18dp "" \n + android : paddingStart = "" 18dp "" \n + android : paddingEnd = "" 18dp "" \n",[ android ] Use start / end instead of begin / end \n start / end is considered better because it enables bidi support .,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - private List < PwoDiscoverer > mPwoDiscoverers ; \n - mPwoDiscoverers = new ArrayList < > ( ) ; \n - mPwoDiscoverers . add ( new MdnsPwoDiscoverer ( getActivity ( ) ) ) ; \n - mPwoDiscoverers . add ( new SsdpPwoDiscoverer ( getActivity ( ) ) ) ; \n - mPwoDiscoverers . add ( new BlePwoDiscoverer ( getActivity ( ) ) ) ; \n - for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n - pwoDiscoverer . setCallback ( this ) ; \n - } \n - \n,[ android ] Remove pwo discoverers from fragment \n These are only needed in the discovery service .,101
"android \ PhysicalWeb \ app \ src \ main \ res \ values \ strings . xml \n - < string name = "" main _ prefs _ key "" > org . physical _ web . physicalweb . MAIN _ PREFS < / string > \n + < string name = "" main _ prefs _ key "" > physical _ web _ preferences < / string > \n + < ! - - The following is a more appropriate name , but would require special code to migrate users - - > \n + < ! - - string name = "" main _ prefs _ key "" > org . physical _ web . physicalweb . MAIN _ PREFS < / string - - > \n",[ android ] Restore old preference file name \n This will prevent users from having to accept the terms in the Oob \n activity twice .,101
"android \ PhysicalWeb \ . gitignore \n + # Keystore files for signing \n + * . jks \n + * . keystore \n + \n - local . properties \n + local . properties \n + signing . properties \n android \ PhysicalWeb \ app \ build . gradle \n + \n + \n + if ( new File ( "" signing . properties "" ) . exists ( ) ) { \n + Properties signingProperties = new Properties ( ) \n + signingProperties . load ( new FileInputStream ( new File ( ' signing . properties ' ) ) ) \n + \n + signingConfigs { \n + release { \n + storeFile new File ( signingProperties [ ' storeFile ' ] ) \n + storePassword signingProperties [ ' storePassword ' ] \n + keyAlias signingProperties [ ' keyAlias ' ] \n + keyPassword signingProperties [ ' keyPassword ' ] \n + } \n + } \n + \n + buildTypes { \n + release { \n + signingConfig signingConfigs . release \n + } \n + } \n + } \n","Read signing configuration from signing . gradle \n Instead of manually pasting configuration values into gradle or \n studio on each release , this lets the developer keep a \n signing . properties file with the necessary information .",101
"android \ PhysicalWeb \ app \ build . gradle \n - targetSdkVersion 21 \n + targetSdkVersion 22 \n - versionName "" 0 . 1 . 851 "" \n + versionName "" 0 . 1 . 852 "" \n",Bump the version number to 0 . 1 . 852 for Android \n This also bumps the target SDK to 22 .,101
"android \ PhysicalWeb \ app \ build . gradle \n - versionCode 11 \n - versionName "" 0 . 1 . 852 "" \n + versionCode 12 \n + versionName "" 0 . 1 . 853 "" \n",Bump Android version name to 0 . 1 . 853,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n + PwoMetadata storedPwoMetadata = mUrlToPwoMetadata . get ( pwoMetadata . url ) ; \n + if ( storedPwoMetadata = = null ) { \n + mUrlToPwoMetadata . put ( pwoMetadata . url , pwoMetadata ) ; \n + PwsClient . getInstance ( this ) . findUrlMetadata ( pwoMetadata , this , TAG ) ; \n + storedPwoMetadata = pwoMetadata ; \n + } \n + \n - pwoResponseCallback . onPwoDiscovered ( pwoMetadata ) ; \n + pwoResponseCallback . onPwoDiscovered ( storedPwoMetadata ) ; \n - \n - if ( ! mUrlToPwoMetadata . containsKey ( pwoMetadata . url ) ) { \n - mUrlToPwoMetadata . put ( pwoMetadata . url , pwoMetadata ) ; \n - PwsClient . getInstance ( this ) . findUrlMetadata ( pwoMetadata , this , TAG ) ; \n - } \n","[ android ] Returned stored PwoMetadata to clients \n Currently , when the Fragment refreshes , we hand it newly discovered \n PwoMetadata objects . However , because the service ( typically ) already \n has the UrlMetadata and the icon , this can prevent the fragment from \n being subscribed to the UrlMetadata on refresh . Instead of giving the \n client the newly discovered PwoMetadata objects , we give it the stored \n one that matches the url of the newly discovered one .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - PwsClient . getInstance ( getActivity ( ) ) . findUrlMetadata ( pwoMetadata , this , TAG ) ; \n","[ android ] Do not fetch urlMetadata in fragment \n The service is supposed to be handling this . Additionally , it creates \n warring fetches that end up confusing things and images don ' t download .",101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwoDiscoveryService . java \n - } \n - @ Override \n - @ SuppressWarnings ( "" deprecation "" ) \n - public int onStartCommand ( Intent intent , int flags , int startId ) { \n - startSearchingForPwos ( ) ; \n - / / make sure the service keeps running \n - return START _ STICKY ; \n + mScanStartTime = new Date ( ) . getTime ( ) ; \n + mHandler . postDelayed ( mFirstScanTimeout , FIRST _ SCAN _ TIME _ MILLIS ) ; \n + mHandler . postDelayed ( mSecondScanTimeout , SECOND _ SCAN _ TIME _ MILLIS ) ; \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . startScan ( ) ; \n + } \n - stopSearchingForPwos ( ) ; \n + mHandler . removeCallbacks ( mFirstScanTimeout ) ; \n + mHandler . removeCallbacks ( mSecondScanTimeout ) ; \n + for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n + pwoDiscoverer . stopScan ( ) ; \n + } \n + \n - private void startSearchingForPwos ( ) { \n - if ( mScanStartTime ! = 0 ) { \n - return ; \n - } \n - \n - mScanStartTime = new Date ( ) . getTime ( ) ; \n - mHandler . postDelayed ( mFirstScanTimeout , FIRST _ SCAN _ TIME _ MILLIS ) ; \n - mHandler . postDelayed ( mSecondScanTimeout , SECOND _ SCAN _ TIME _ MILLIS ) ; \n - for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n - pwoDiscoverer . startScan ( ) ; \n - } \n - } \n - \n - private void stopSearchingForPwos ( ) { \n - mHandler . removeCallbacks ( mFirstScanTimeout ) ; \n - mHandler . removeCallbacks ( mSecondScanTimeout ) ; \n - for ( PwoDiscoverer pwoDiscoverer : mPwoDiscoverers ) { \n - pwoDiscoverer . stopScan ( ) ; \n - } \n - } \n - \n","[ android ] Handle scanning startup in onCreate \n onStartService isn ' t the place to do this since we only want to start \n scanning once . The android docs seem to indicate that onCreate doesn ' t \n have to be merely used for variable instantiation , but can also start \n threads as shown in one of their own examples . \n http : / / developer . android . com / guide / components / services . html",101
java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ UrlDeviceJsonSerializer . java \n - T deserialize ( JSONObject jsonObject ) ; \n + UrlDevice deserialize ( JSONObject jsonObject ) ; \n,"Deserialize to UrlDevice , not to specific subclass \n The UrlDeviceJsonSerializer is designed to serialize a specific \n subclass of UrlDevice and de serialize a specific subclass of \n UrlDevice . We should not dictate what it deserializes to , only what \n it deserializes from . This will allow updated versions of clients to \n transition between subclasses of UrlDevice .",101
"java \ libs \ config \ checkstyle \ checkstyle . xml \n + ANNOTATION CHECKS \n + \n + - - > \n + \n + < module name = "" MissingOverride "" / > \n + \n + < ! - - \n + \n - - > \n java \ libs \ src \ test \ java \ org \ physical _ web \ collection \ PhysicalWebCollectionTest . java \n + @ SuppressWarnings ( "" PMD . AvoidDuplicateLiterals "" ) \n",Suppress duplicate literals in PWC test \n This gets travis gree again .,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ BeaconConfigFragment . java \n - / / Shorten the url if necessary \n - if ( ! hasValidUrlLength ( url ) | | ! isAsciiUrl ( url ) ) { \n - PwsClient . getInstance ( getActivity ( ) ) . shortenUrl ( url , urlSetter , TAG ) ; \n - } else { \n + \n + if ( hasValidUrlLength ( url ) & & isAsciiUrl ( url ) ) { \n + / / Set the url if we can \n + } else { \n + / / Shorten the url if necessary \n + PwsClient . getInstance ( getActivity ( ) ) . shortenUrl ( url , urlSetter , TAG ) ; \n",Order conditional positively in beacon config \n This is a simple readability cleanup that reverses a set of \n if / else blocks so that the condition can be stated positively .,101
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ AutostartPwoDiscoveryServiceReceiver . java \n - String preferencesKey = context . getString ( R . string . physical _ web _ preference _ file _ name ) ; \n + String preferencesKey = context . getString ( R . string . main _ prefs _ key ) ; \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ MainActivity . java \n - SharedPreferences sharedPreferences = getSharedPreferences ( "" physical _ web _ preferences "" , \n + String preferencesKey = getString ( R . string . main _ prefs _ key ) ; \n + SharedPreferences sharedPreferences = getSharedPreferences ( preferencesKey , \n android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ OobActivity . java \n - String fileName = getString ( R . string . physical _ web _ preference _ file _ name ) ; \n - SharedPreferences sharedPreferences = getSharedPreferences ( fileName , Context . MODE _ PRIVATE ) ; \n + String preferencesKey = getString ( R . string . main _ prefs _ key ) ; \n + SharedPreferences sharedPreferences = getSharedPreferences ( preferencesKey , \n + Context . MODE _ PRIVATE ) ; \n android \ PhysicalWeb \ app \ src \ main \ res \ values \ strings . xml \n - < string name = "" physical _ web _ preference _ file _ name "" > physical _ web _ preferences < / string > \n + < string name = "" main _ prefs _ key "" > org . physical _ web . physicalweb . MAIN _ PREFS < / string > \n","[ android ] Use a scoped preference file name \n "" "" "" \n When naming your shared preference files , you should use a name that ' s \n uniquely identifiable to your app , such as \n "" com . example . myapp . PREFERENCE _ FILE _ KEY "" \n "" "" "" \n http : / / developer . android . com / training / basics / data - storage / shared - preferences . html",101
"android \ PhysicalWeb \ app \ src \ main \ AndroidManifest . xml \n + < uses - permission android : name = "" android . permission . ACCESS _ COARSE _ LOCATION "" / > \n",Add location permission \n This allows to do scanning on screen wakeup on M .,101
"android \ PhysicalWeb \ app \ build . gradle \n + compile ( project ( ' : libs ' ) ) { \n + exclude group : ' org . json ' , module : ' json ' \n + } \n + \n android \ PhysicalWeb \ settings . gradle \n - include ' : app ' \n + include ' : app ' , ' : libs ' \n + \n + project ( ' : libs ' ) . projectDir = new File ( ' . . / . . / java / libs ' ) \n java \ libs \ build . gradle \n - reportsDir = file ( "" $ project . buildDir / reports / findbugs "" ) \n - excludeFilter = file ( "" $ project . rootDir / config / findbugs / exclude - filter . xml "" ) \n + reportsDir = new File ( buildDir , "" reports / findbugs "" ) \n + excludeFilter = new File ( projectDir , "" config / findbugs / exclude - filter . xml "" ) \n - configProperties . checkstyleSuppressionsPath = file ( "" $ project . rootDir / config / checkstyle / suppressions . xml "" ) \n + configProperties . checkstyleSuppressionsPath = \n + new File ( projectDir , "" config / checkstyle / suppressions . xml "" ) \n - ruleSetFiles = files ( "" $ { project . rootDir } / config / pmd / pmd - ruleset . xml "" ) \n + ruleSetFiles = files ( new File ( projectDir , "" config / pmd / pmd - ruleset . xml "" ) ) \n - reportsDir = file ( "" $ project . buildDir / reports / findbugs "" ) \n + reportsDir = new File ( buildDir , "" reports / findbugs "" ) \n",Build collection lib along with the Android app,101
"java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ PhysicalWebCollection . java \n - mPwsClient . resolve ( newUrls , augmentedCallback ) ; \n + if ( newUrls . size ( ) > 0 ) { \n + mPwsClient . resolve ( newUrls , augmentedCallback ) ; \n + } \n","Don ' t send empty requests to PWS \n If there are no new URLs to get metadata for , don ' t send a request \n to PWS .",101
rename from java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ http \ JsonObjectRequest . java \n rename to java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ JsonObjectRequest . java \n - package org . physical _ web . collection . http ; \n + package org . physical _ web . collection ; \n - public class JsonObjectRequest extends Request < JSONObject > { \n + class JsonObjectRequest extends Request < JSONObject > { \n java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ PwsClient . java \n - import org . physical _ web . collection . http . JsonObjectRequest ; \n - import org . physical _ web . collection . http . Request ; \n - \n rename from java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ http \ Request . java \n rename to java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ Request . java \n - package org . physical _ web . collection . http ; \n + package org . physical _ web . collection ; \n - public abstract class Request < T > extends Thread { \n + abstract class Request < T > extends Thread { \n java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ Utils . java \n - public class Utils { \n + class Utils { \n,Make http classes package private \n There are several classe that don ' t need to be exposed to developers . \n This change makes them package private .,101
"web - service \ tests . py \n + import signal \n + import sys \n - ] , bufsize = 1 , stderr = subprocess . PIPE ) \n + ] , bufsize = 1 , stderr = subprocess . PIPE , preexec _ fn = os . setsid ) \n - for line in iter ( server . stderr . readline , b ' ' ) : \n + while True : \n + line = server . stderr . readline ( ) \n + if ' Unable to bind ' in line : \n + print ' Rogue server already running . ' \n + return 1 \n - server . kill ( ) \n + os . killpg ( os . getpgid ( server . pid ) , signal . SIGINT ) \n + server . wait ( ) \n",[ PWS ] Start / stop auto test server more reliably,101
"java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ PhysicalWebCollection . java \n + / * * \n + * Return the top - ranked PwPair for a given group ID . \n + * @ return a PwPair . \n + * / \n + public PwPair getTopRankedPwPairByGroupId ( String groupId ) { \n + for ( PwPair pwPair : getGroupedPwPairsSortedByRank ( ) ) { \n + if ( pwPair . getPwsResult ( ) . getGroupId ( ) . equals ( groupId ) ) { \n + return pwPair ; \n + } \n + } \n + return null ; \n + } \n + \n java \ libs \ src \ test \ java \ org \ physical _ web \ collection \ PhysicalWebCollectionTest . java \n + \n + @ Test \n + public void getTopRankedPwPairByGroupIdWorks ( ) { \n + PhysicalWebCollection physicalWebCollection = new PhysicalWebCollection ( ) ; \n + addRankedDeviceAndMetadata ( physicalWebCollection , ID1 , URL1 , GROUP _ ID1 , . 1 ) ; / / Group 1 \n + addRankedDeviceAndMetadata ( physicalWebCollection , ID2 , URL2 , GROUP _ ID1 , . 2 ) ; / / Better rank \n + addRankedDeviceAndMetadata ( physicalWebCollection , ID1 , URL1 , GROUP _ ID2 , . 3 ) ; / / Group 2 \n + assertNull ( physicalWebCollection . getTopRankedPwPairByGroupId ( "" notagroup "" ) ) ; \n + PwPair pwPair = physicalWebCollection . getTopRankedPwPairByGroupId ( GROUP _ ID1 ) ; \n + assertNotNull ( pwPair ) ; \n + assertEquals ( ID2 , pwPair . getUrlDevice ( ) . getId ( ) ) ; \n + } \n",Add a helper method to grab a top pair for a group,101
"java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ PhysicalWebCollection . java \n - private static final String DEFAULT _ PWS _ ENDPOINT = "" https : / / url - caster . appspot . com "" ; \n - mPwsClient = new PwsClient ( DEFAULT _ PWS _ ENDPOINT ) ; \n + mPwsClient = new PwsClient ( ) ; \n java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ PwsClient . java \n + private static final String DEFAULT _ PWS _ ENDPOINT = "" https : / / url - caster . appspot . com "" ; \n + / * * \n + * Construct a PwsClient . \n + * / \n + public PwsClient ( ) { \n + this ( DEFAULT _ PWS _ ENDPOINT ) ; \n + } \n + \n",Construct PWS client with default endpoint \n This lets client code construct a PwsClient without any arguments .,101
java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ JsonObjectRequest . java \n + urlConnection . setDoOutput ( true ) ; \n java \ libs \ src \ main \ java \ org \ physical _ web \ collection \ Request . java \n - urlConnection . setDoOutput ( true ) ; \n,Allow request subclasses to setDoOutput \n This will prevent us from making POST requests with the BitmapRequest \n class .,101
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ SettingsFragment . java \n + import android . preference . PreferenceGroup ; \n + private PreferenceGroup mCustomEndpointCategory ; \n + mCustomEndpointCategory = \n + ( PreferenceGroup ) findPreference ( getString ( R . string . custom _ pws _ endpoint _ key ) ) ; \n + updatePwsPreference ( ) ; \n + updatePwsPreference ( ) ; \n - if ( entry ! = null & & entry . equals ( getString ( R . string . custom _ pws ) ) ) { \n + if ( entry = = null ) { \n + return ; \n + } \n + \n + if ( entry . equals ( getString ( R . string . custom _ pws ) ) ) { \n - EditTextPreference customPwsUrlPreference = ( EditTextPreference ) findPreference ( \n - getString ( R . string . custom _ pws _ url _ key ) ) ; \n - ListPreference customPwsVersionPreference = ( ListPreference ) findPreference ( \n - getString ( R . string . custom _ pws _ version _ key ) ) ; \n - EditTextPreference customPwsApiKeyPreference = ( EditTextPreference ) findPreference ( \n - getString ( R . string . custom _ pws _ api _ key _ key ) ) ; \n + EditTextPreference customPwsUrlPreference = \n + ( EditTextPreference ) mCustomEndpointCategory . findPreference ( \n + getString ( R . string . custom _ pws _ url _ key ) ) ; \n + ListPreference customPwsVersionPreference = \n + ( ListPreference ) mCustomEndpointCategory . findPreference ( \n + getString ( R . string . custom _ pws _ version _ key ) ) ; \n + EditTextPreference customPwsApiKeyPreference = \n + ( EditTextPreference ) mCustomEndpointCategory . findPreference ( \n + getString ( R . string . custom _ pws _ api _ key _ key ) ) ; \n + getPreferenceScreen ( ) . addPreference ( mCustomEndpointCategory ) ; \n + } else { \n + getPreferenceScreen ( ) . removePreference ( mCustomEndpointCategory ) ; \n,"Hide custom PWS settings when not in use \n When the user is not using a custom PWS , the custom PWS settings are \n visible ; confusing ! This change hides those settings when not in use .",101
"new file \n rxandroid \ src \ main \ java \ rx \ android \ lifecycle \ LifecycleEvent . java \n + / * * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * / \n + \n + package rx . android . lifecycle ; \n + \n + / * * \n + * Lifecycle events that can be emitted by Activities or Fragments . \n + * / \n + public enum LifecycleEvent { \n + \n + ATTACH , \n + CREATE , \n + CREATE _ VIEW , \n + START , \n + RESUME , \n + PAUSE , \n + STOP , \n + DESTROY _ VIEW , \n + DESTROY , \n + DETACH \n + \n + } \n",Added LifecycleEvent enum \n Can be used for all the major Activity and Fragment events .,109
"rxandroid - framework \ build . gradle \n - buildscript { \n - repositories { jcenter ( ) } \n - dependencies { \n - classpath ' com . netflix . nebula : gradle - rxjava - project - plugin : 1 . 12 . + ' \n - classpath ' com . netflix . nebula : gradle - extra - configurations - plugin : 1 . 12 . + ' \n - } \n - } \n - \n - apply plugin : ' rxjava - project ' \n - apply plugin : ' provided - base ' \n - \n - dependencies { \n - compile "" io . reactivex : rxjava : $ rxJavaVersion "" \n - provided ' com . google . android : android : 4 . 0 . 1 . 2 ' \n - provided ' com . google . android : support - v4 : r7 ' \n - \n - / / testing \n - testCompile ' junit : junit - dep : 4 . 11 ' \n - testCompile ' org . mockito : mockito - core : 1 . 10 . 8 ' \n - testCompile ( ' org . robolectric : robolectric : 2 . 4 ' ) { \n - exclude group : ' com . android . support ' \n - } \n - } \n + / / Multi - module modules aren ' t really supported \n + version = rootProject . version \n + \n + dependencies { \n + compile ( project ( "" : rxandroid "" ) ) \n + } \n","Fixed broken builds in IntelliJ \n To be honest , not even sure how it was building command - line , but now \n it ' s no longer double - including all its funky dependencies .",109
"sample - app \ build . gradle \n + \n + lintOptions { \n + lintConfig file ( ' lint . xml ' ) \n + } \n new file \n sample - app \ lint . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" UTF - 8 "" ? > \n + < lint > \n + < ! - - \n + Since this is just a sample app , there are a number of minor \n + lint checks that really don ' t matter . \n + - - > \n + \n + < issue id = "" IconMissingDensityFolder "" severity = "" ignore "" / > \n + < issue id = "" HardcodedText "" severity = "" ignore "" / > \n + < / lint > \n",Ignore lint warnings that don ' t matter for sample apps,109
"gradle . properties \n - VERSION _ NAME = 1 . 0 - SNAPSHOT \n + VERSION _ NAME = 1 . 0 \n rxandroid \ build . gradle \n - version = VERSION _ NAME \n + \n + / / Both the artifactory and bintray plugins depend on this singular \n + / / global ` version ` variable . As such , we need to configure it based \n + / / on which task we ' re running . \n + / / \n + / / The solution here is brittle ; it just checks whether ' bintrayUpload ' \n + / / was called for execution , otherwise it assumes SNAPSHOT . If we \n + / / were to wait until the task graph was built , we ' d be too late \n + / / ( the plugins would already have used ` version ` ) . \n + boolean isReleaseBuild = gradle . startParameter . taskNames . contains ( ' bintrayUpload ' ) \n + version = isReleaseBuild ? VERSION _ NAME : "" $ VERSION _ NAME - SNAPSHOT "" \n + logger . info ( "" RxAndroid using version = $ project . version "" ) \n",Switch ` version ` based on tasks called,109
gradle . properties \n - VERSION _ NAME = 1 . 0 \n + VERSION _ NAME = 1 . 0 . 0 - rc1 \n rxandroid \ build . gradle \n + publish = true \n + \n,Automatically publish bintray releases \n Bumped version to 1 . 0 . 0 - rc1 ( for testing auto - publishing ) .,109
"gradle \ buildViaTravis . sh \n - . / gradlew - PbintrayUser = "" $ { bintrayUser } "" - PbintrayKey = "" $ { bintrayKey } "" - PsonatypeUsername = "" $ { sonatypeUsername } "" - PsonatypePassword = "" $ { sonatypePassword } "" build artifactoryPublish - - stacktrace \n + . / gradlew - PbintrayUser = "" $ { bintrayUser } "" - PbintrayKey = "" $ { bintrayKey } "" - PsonatypeUsername = "" $ { sonatypeUsername } "" - PsonatypePassword = "" $ { sonatypePassword } "" build artifactoryPublish - - stacktrace - - info \n - . / gradlew - PbintrayUser = "" $ { bintrayUser } "" - PbintrayKey = "" $ { bintrayKey } "" - PsonatypeUsername = "" $ { sonatypeUsername } "" - PsonatypePassword = "" $ { sonatypePassword } "" build bintrayUpload - - stacktrace \n + . / gradlew - PbintrayUser = "" $ { bintrayUser } "" - PbintrayKey = "" $ { bintrayKey } "" - PsonatypeUsername = "" $ { sonatypeUsername } "" - PsonatypePassword = "" $ { sonatypePassword } "" build bintrayUpload - - stacktrace - - info \n",Added - - info to snapshot / release builds \n Then we might actually know what ' s going on when it ' s publishing !,109
gradle . properties \n - VERSION _ NAME = 1 . 0 . 0 - rc1 \n + VERSION _ NAME = 1 . 0 . 0 \n,Bump to version 1 . 0 . 0,109
rxandroid \ src \ main \ java \ rx \ android \ schedulers \ HandlerScheduler . java \n + if ( compositeSubscription . isUnsubscribed ( ) ) { \n + return Subscriptions . unsubscribed ( ) ; \n + } \n + \n rxandroid \ src \ test \ java \ rx \ android \ schedulers \ HandlerSchedulerTest . java \n - import java . util . concurrent . atomic . AtomicReference ; \n - import rx . android . plugins . RxAndroidPluginsTest ; \n + import java . util . concurrent . atomic . AtomicBoolean ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n + import static org . junit . Assert . assertTrue ; \n + \n + @ Test \n + public void shouldNotScheduleAfterUnsubscribe ( ) { \n + Scheduler scheduler = HandlerScheduler . from ( new Handler ( ) ) ; \n + Worker inner = scheduler . createWorker ( ) ; \n + inner . unsubscribe ( ) ; \n + \n + / / Assert that work scheduled after unsubscribe ( ) is never called \n + final AtomicBoolean neverCalled = new AtomicBoolean ( true ) ; \n + inner . schedule ( new Action0 ( ) { \n + @ Override \n + public void call ( ) { \n + neverCalled . set ( false ) ; \n + } \n + } ) ; \n + assertTrue ( neverCalled . get ( ) ) ; \n + } \n,Check isUnsubscribed ( ) before scheduling more work,109
"rxandroid \ src \ main \ java \ rx \ android \ schedulers \ HandlerScheduler . java \n + scheduledAction . addParent ( compositeSubscription ) ; \n + compositeSubscription . add ( scheduledAction ) ; \n + \n + handler . postDelayed ( scheduledAction , unit . toMillis ( delayTime ) ) ; \n + \n - scheduledAction . addParent ( compositeSubscription ) ; \n - compositeSubscription . add ( scheduledAction ) ; \n - \n - handler . postDelayed ( scheduledAction , unit . toMillis ( delayTime ) ) ; \n rxandroid \ src \ test \ java \ rx \ android \ schedulers \ HandlerSchedulerTest . java \n + import java . util . concurrent . TimeUnit ; \n + \n + @ Test \n + public void shouldNotScheduleAfterUnsubscribeRaceCondition ( ) { \n + Scheduler scheduler = HandlerScheduler . from ( new Handler ( ) ) ; \n + final Scheduler . Worker inner = scheduler . createWorker ( ) ; \n + \n + RxAndroidPlugins . getInstance ( ) . registerSchedulersHook ( new RxAndroidSchedulersHook ( ) { \n + @ Override public Action0 onSchedule ( Action0 action ) { \n + / / Purposefully unsubscribe in an asinine point , \n + / / after the normal isUnsubscribed ( ) check \n + inner . unsubscribe ( ) ; \n + return super . onSchedule ( action ) ; \n + } \n + } ) ; \n + \n + final AtomicBoolean neverCalled = new AtomicBoolean ( true ) ; \n + inner . schedule ( new Action0 ( ) { \n + @ Override \n + public void call ( ) { \n + neverCalled . set ( false ) ; \n + } \n + } , 1 , TimeUnit . MILLISECONDS ) ; \n + \n + Robolectric . runUiThreadTasksIncludingDelayedTasks ( ) ; \n + \n + assertTrue ( neverCalled . get ( ) ) ; \n + } \n",Fixed race condition between unsubscribe ( ) and postDelayed ( ) \n We now guarantee that removeCallbacks ( ) is called * after * the message \n is posted to the Handler . That way there ' s no possibility of \n removeCallbacks ( ) being called before the message is posted ( thus \n causing the message to occur anyways ) .,109
retrofit - adapters \ rxjava \ src \ main \ java \ retrofit \ RxJavaCallAdapterFactory . java \n - subscriber . onError ( t ) ; \n + if ( ! subscriber . isUnsubscribed ( ) ) { \n + subscriber . onError ( t ) ; \n + } \n - subscriber . onCompleted ( ) ; \n + if ( ! subscriber . isUnsubscribed ( ) ) { \n + subscriber . onCompleted ( ) ; \n + } \n,Added extra caution before calling onError / onCompleted \n The chances are low ( but not zero ) of an unsubscription between onNext ( ) and \n the terminal event .,109
"retrofit - adapters \ rxjava \ src \ main \ java \ retrofit \ RxJavaCallAdapterFactory . java \n - call . enqueue ( new Callback < T > ( ) { \n - @ Override public void onResponse ( Response < T > response , Retrofit retrofit ) { \n - if ( subscriber . isUnsubscribed ( ) ) { \n - return ; \n - } \n - try { \n - subscriber . onNext ( response ) ; \n - } catch ( Throwable t ) { \n - if ( ! subscriber . isUnsubscribed ( ) ) { \n - subscriber . onError ( t ) ; \n - } \n - return ; \n - } \n - if ( ! subscriber . isUnsubscribed ( ) ) { \n - subscriber . onCompleted ( ) ; \n - } \n - } \n + if ( subscriber . isUnsubscribed ( ) ) { \n + return ; \n + } \n - @ Override public void onFailure ( Throwable t ) { \n - if ( subscriber . isUnsubscribed ( ) ) { \n - return ; \n - } \n + try { \n + Response < T > response = call . execute ( ) ; \n + if ( ! subscriber . isUnsubscribed ( ) ) { \n + subscriber . onNext ( response ) ; \n + } \n + } catch ( Throwable t ) { \n + if ( ! subscriber . isUnsubscribed ( ) ) { \n - } ) ; \n + return ; \n + } \n + \n + if ( ! subscriber . isUnsubscribed ( ) ) { \n + subscriber . onCompleted ( ) ; \n + } \n","Use execute ( ) instead of enqueue ( ) in Rx adapter \n Retrofit should leave threading up to the Scheduler used to invoke call ( ) . \n Otherwise , there can be two types of unwanted behavior : \n 1 . It can execute on another Thread when sync behavior is desired . \n 2 . It uses unnecessary extra Threads even when already called on a Scheduler .",109
leakcanary - android \ consumer - proguard - rules . pro \n - keep class org . eclipse . mat . * * { * ; } \n - keep class com . squareup . leakcanary . * * { * ; } \n + \n + # Marshmallow removed Notification . setLatestEventInfo ( ) \n + - dontwarn android . app . Notification \n,"Add proguard rule for android . app . Notification \n Marshmallow removed Notification . setLatestEventInfo ( ) . LeakCanary uses it , \n but only pre - Marshmallow . This rule should prevent proguard from complaining .",109
leakcanary - android \ src \ main \ java \ com \ squareup \ leakcanary \ AndroidExcludedRefs . java \n + import static android . os . Build . VERSION _ CODES . N ; \n - SPELL _ CHECKER _ SESSION ( SDK _ INT > = JELLY _ BEAN & & SDK _ INT < = LOLLIPOP _ MR1 ) { \n + SPELL _ CHECKER _ SESSION ( ( SDK _ INT > = JELLY _ BEAN & & SDK _ INT < = LOLLIPOP _ MR1 ) | | SDK _ INT > = N ) { \n,"Exclude SpellChecker check on N + \n The bug seems to have returned , exactly as it was from before .",109
"picasso \ src \ main \ java \ com \ squareup \ picasso \ Dispatcher . java \n - boolean hasConnectivity = networkInfo ! = null & & networkInfo . isConnected ( ) ; \n - boolean shouldRetryHunter = hunter . shouldRetry ( airplaneMode , networkInfo ) ; \n - boolean supportsReplay = hunter . supportsReplay ( ) ; \n - \n - if ( ! shouldRetryHunter ) { \n - / / Mark for replay only if we observe network info changes and support replay . \n - boolean willReplay = scansNetworkChanges & & supportsReplay ; \n - performError ( hunter , willReplay ) ; \n - if ( willReplay ) { \n - markForReplay ( hunter ) ; \n - } \n - return ; \n - } \n - \n - / / If we don ' t scan for network changes ( missing permission ) or if we have connectivity , retry . \n - if ( ! scansNetworkChanges | | hasConnectivity ) { \n + if ( hunter . shouldRetry ( airplaneMode , networkInfo ) ) { \n - return ; \n - } \n - \n - performError ( hunter , supportsReplay ) ; \n - \n - if ( supportsReplay ) { \n - markForReplay ( hunter ) ; \n + } else { \n + / / Mark for replay only if we observe network info changes and support replay . \n + boolean willReplay = scansNetworkChanges & & hunter . supportsReplay ( ) ; \n + performError ( hunter , willReplay ) ; \n + if ( willReplay ) { \n + markForReplay ( hunter ) ; \n + } \n picasso \ src \ test \ java \ com \ squareup \ picasso \ DispatcherTest . java \n - @ Test public void performRetryMarksForReplayIfSupportsReplayAndNoConnectivity ( ) { \n - NetworkInfo networkInfo = mockNetworkInfo ( false ) ; \n + @ Test public void performRetryMarksForReplayIfSupportsReplayAndShouldNotRetry ( ) { \n - when ( hunter . shouldRetry ( anyBoolean ( ) , any ( NetworkInfo . class ) ) ) . thenReturn ( true ) ; \n + when ( hunter . shouldRetry ( anyBoolean ( ) , any ( NetworkInfo . class ) ) ) . thenReturn ( false ) ; \n - when ( connectivityManager . getActiveNetworkInfo ( ) ) . thenReturn ( networkInfo ) ; \n - @ Test public void performRetryRetriesIfHasConnectivity ( ) { \n - NetworkInfo networkInfo = mockNetworkInfo ( true ) ; \n + @ Test public void performRetryRetriesIfShouldRetry ( ) { \n - when ( connectivityManager . getActiveNetworkInfo ( ) ) . thenReturn ( networkInfo ) ; \n","Retry requests even when there is no connectivity \n BitmapHunter was intended to eventually retry using NetworkPolicy . OFFLINE \n if there were enough failed retries . However , the code was ( at \n some point ) changed so that it would not retry if you had no connectivity . \n These two behaviors were at odds , so I changed it back to depending \n solely on BitmapHunter . shouldRetry ( ) .",109
hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - private class MetricsPollerThreadFactory implements ThreadFactory { \n + private static class MetricsPollerThreadFactory implements ThreadFactory { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixRollingNumber . java \n - / * package * / class BucketCircularArray implements Iterable < Bucket > { \n + / * package * / static class BucketCircularArray implements Iterable < Bucket > { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixRollingPercentile . java \n - / * package for testing * / class BucketCircularArray implements Iterable < Bucket > { \n + / * package for testing * / static class BucketCircularArray implements Iterable < Bucket > { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixTimer . java \n - private class TimerReference extends SoftReference < TimerListener > { \n + private static class TimerReference extends SoftReference < TimerListener > { \n,"make inner classes static where possible , and remove outer class reference",118
hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ requests \ stream \ HystrixRequestEventsJsonStream . java \n - if ( ! eventType . equals ( HystrixEventType . COLLAPSED ) ) { \n + if ( eventType ! = HystrixEventType . COLLAPSED ) { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - if ( properties . executionIsolationStrategy ( ) . get ( ) . equals ( ExecutionIsolationStrategy . THREAD ) ) { \n + if ( properties . executionIsolationStrategy ( ) . get ( ) = = ExecutionIsolationStrategy . THREAD ) { \n - return properties . executionIsolationThreadInterruptOnTimeout ( ) . get ( ) & & _ cmd . isCommandTimedOut . get ( ) . equals ( TimedOutStatus . TIMED _ OUT ) ; \n + return properties . executionIsolationThreadInterruptOnTimeout ( ) . get ( ) & & _ cmd . isCommandTimedOut . get ( ) = = TimedOutStatus . TIMED _ OUT ; \n - if ( properties . executionIsolationStrategy ( ) . get ( ) . equals ( ExecutionIsolationStrategy . SEMAPHORE ) ) { \n + if ( properties . executionIsolationStrategy ( ) . get ( ) = = ExecutionIsolationStrategy . SEMAPHORE ) { \n - return commandState . get ( ) . equals ( CommandState . TERMINAL ) ; \n + return commandState . get ( ) = = CommandState . TERMINAL ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HystrixCommandExecutionStarted . java \n - return isolationStrategy . equals ( HystrixCommandProperties . ExecutionIsolationStrategy . THREAD ) ; \n + return isolationStrategy = = HystrixCommandProperties . ExecutionIsolationStrategy . THREAD ; \n,"compare enums with = = , avoid chances of NPE",118
hystrix - contrib \ hystrix - javanica \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ javanica \ cache \ CacheInvocationContext . java \n - Annotation [ ] [ ] parametersAnnotations = method . getParameterAnnotations ( ) ; \n + Annotation [ ] [ ] parametersAnnotations = method . getParameterAnnotations ( ) ; \n,"no need to fetch the method ' s parameter annotations , if there aren ' t any .",118
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HystrixRequestEvents . java \n - HystrixCollapserKey collapserKey = execution . getOriginatingCollapserKey ( ) ; \n - int collapserBatchCount = execution . getNumberCollapsed ( ) ; \n,remove dead code around fetching execution collapse info,118
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ collapser \ RequestCollapserFactory . java \n - defaultNameCache . clear ( ) ; \n - \n - / / this is a micro - optimization but saves about 1 - 2microseconds ( on 2011 MacBook Pro ) \n - / / on the repetitive string processing that will occur on the same classes over and over again \n - @ SuppressWarnings ( "" rawtypes "" ) \n - private static ConcurrentHashMap < Class < ? extends HystrixCollapser > , String > defaultNameCache = new ConcurrentHashMap < Class < ? extends HystrixCollapser > , String > ( ) ; \n - \n",remove dead field defaultNameCache \n resolves GitHub Issue # 1220,118
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCollapserKey . java \n - \n + \n + @ Override \n + public String toString ( ) { \n + return name ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandKey . java \n - \n + \n + @ Override \n + public String toString ( ) { \n + return name ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolKey . java \n - \n + \n + @ Override \n + public String toString ( ) { \n + return name ; \n + } \n,add toString ( ) s to help when debugging custom HystrixPropertiesStrategy classes,118
"hystrix - contrib \ hystrix - clj \ src \ test \ clojure \ com \ netflix \ hystrix \ core _ test . clj \n - ( : import [ com . netflix . hystrix HystrixExecutable ] \n + ( : import [ com . netflix . hystrix Hystrix HystrixExecutable ] \n + ; reset hystrix after each execution , for consistency and sanity \n + ( defn reset - fixture \n + [ f ] \n + ( try \n + ( f ) \n + ( finally \n + ( Hystrix / reset ) ) ) ) \n + \n + ( use - fixtures : once reset - fixture ) \n + \n","Reset Hystrix after tests have run . \n Without the resets , running the tests more than once will fail due to \n collapser instance caching behind the scenes .",120
"hystrix - contrib \ hystrix - clj \ build . gradle \n - classpath ' clojuresque : clojuresque : 1 . 5 . 4 ' \n + classpath ' clojuresque : clojuresque : 1 . 5 . 8 ' \n hystrix - contrib \ hystrix - clj \ src \ test \ clojure \ com \ netflix \ hystrix \ core _ test . clj \n - ; In the end , reset Hystrix so that Clojuresque will exit after running tests . \n - ( defn hystrix - reset - fixture \n - [ f ] \n - ( try \n - ( f ) \n - ( finally \n - ( com . netflix . hystrix . Hystrix / reset ) ) ) ) \n - \n - ( use - fixtures : once hystrix - reset - fixture ) \n - \n",Update clojuresque and remove test shutdown hack . \n Clojuresque 1 . 5 . 8 addresses the issue with Clojure tests never \n finishing . Now it does an explicit System . exit ( ) to ensure the tests \n finish even if there are threads hanging around .,120
"hystrix - contrib \ hystrix - clj \ src \ main \ clojure \ com \ netflix \ hystrix \ core . clj \n - ( ns ^ { : doc \n + ( ns com . netflix . hystrix . core \n - \n - "" } \n - com . netflix . hystrix . core \n + "" \n",Move ns docstring from meta to docstring position .,120
"language - adaptors \ rxjava - clojure \ src \ main \ clojure \ rx \ lang \ clojure \ core . clj \n - merge next nth partition reduce reductions \n + merge next nth partition - all reduce reductions \n - ; TODO partition . Use window \n + ( defn ^ Observable partition - all \n + "" Returns an Observable of Observables of n items each , at offsets step \n + apart . If step is not supplied , defaults to n , i . e . the partitions \n + do not overlap . May include partitions with fewer than n items at the end . \n + \n + See : \n + clojure . core / partition - all \n + rx . Observable / window \n + "" \n + ( [ n ^ Observable xs ] ( . window xs ( int n ) ) ) \n + ( [ n step ^ Observable xs ] ( . window xs ( int n ) ( int step ) ) ) ) \n language - adaptors \ rxjava - clojure \ src \ test \ clojure \ rx \ lang \ clojure \ core _ test . clj \n + ( deftest test - partition - all \n + ( are [ input - size part - size step ] ( = ( - > > ( range input - size ) \n + ( partition - all part - size step ) ) \n + ( - > > ( range input - size ) \n + ( rx / seq - > o ) \n + ( rx / partition - all part - size step ) \n + ( rx / map # ( rx / into [ ] % ) ) \n + ( rx / concat * ) \n + ( b / into [ ] ) ) ) \n + 0 1 1 \n + 10 2 2 \n + 10 3 2 \n + 15 30 4 ) \n + \n + ( are [ input - size part - size ] ( = ( - > > ( range input - size ) \n + ( partition - all part - size ) ) \n + ( - > > ( range input - size ) \n + ( rx / seq - > o ) \n + ( rx / partition - all part - size ) \n + ( rx / map # ( rx / into [ ] % ) ) \n + ( rx / concat * ) \n + ( b / into [ ] ) ) ) \n + 0 1 \n + 10 2 \n + 10 3 \n + 15 30 ) ) \n + \n","Implemented partition - all \n There isn ' t really an rxjava impl equivalent to clojure . core / partition , \n so it ' s omitted .",120
"language - adaptors \ rxjava - clojure \ src \ main \ clojure \ rx \ lang \ clojure \ core . clj \n - "" "" \n + "" Experimental , subject to change or deletion . "" \n - "" Returns a new implementation of rx . Observable $ Operator that calls the given \n + "" Experimental , subject to change or deletion . \n + \n + Returns a new implementation of rx . Observable $ Operator that calls the given \n + "" Subscribe to the given observable . \n + \n + on - X - action is a normal clojure function . \n + \n + See : \n + rx . Observable / subscribe \n + "" \n + "" Synchronize execution . \n + \n + See : \n + rx . Observable / synchronize \n + "" \n",Updates from @ mbossenbroek ' s feedback .,120
"language - adaptors \ rxjava - clojure \ src \ main \ clojure \ rx \ lang \ clojure \ core . clj \n - ( key - fn x ) and the val is an Observable of ( val - fn x ) for each key . If val - fn is \n - omitted , it defaults to identity . \n + ( key - fn x ) and the val is an Observable of x for each key . \n - ( map ( fn [ ^ GroupedObservable go ] \n - ( clojure . lang . MapEntry . ( . getKey go ) go ) ) ) ) ) \n - ( [ key - fn val - fn ^ Observable xs ] \n - ; TODO reinstate once this is implemented \n - ; see https : / / github . com / Netflix / RxJava / commit / 02ccc4d727a9297f14219549208757c6e0efce2a \n - ( throw ( UnsupportedOperationException . "" groupBy with val - fn is currently unimplemented in RxJava "" ) ) \n - ( - > > ( . groupBy xs \n - ( iop / fn * key - fn ) \n - ( iop / fn * val - fn ) ) \n",Remove val - fn version of group - by,120
"language - adaptors \ rxjava - clojure \ src \ main \ clojure \ rx \ lang \ clojure \ core . clj \n - ( if xs \n - ( Observable / from ^ Iterable xs ) \n + ( if - let [ s ( clojure . core / seq xs ) ] \n + ( Observable / from ^ Iterable s ) \n language - adaptors \ rxjava - clojure \ src \ test \ clojure \ rx \ lang \ clojure \ core _ test . clj \n + ( is ( = [ \ a \ b \ c ] ( b / into [ ] ( rx / seq - > o "" abc "" ) ) ) ) \n",seq - > o should seq - ify arg,120
"language - adaptors \ rxjava - clojure \ README . md \n + # # Using Observable / create \n + As of 0 . 17 , ` rx . Observable / create ` takes an implementation of ` rx . Observable $ OnSubscribe ` which is basically an alias for ` rx . util . functions . Action1 ` that takes an ` rx . Subscriber ` as its argument . Thus , you can just use ` rx / action ` when creating new observables : \n + \n + ` ` ` clojure \n + ; A simple observable that emits 0 . . 9 taking unsubscribe into account \n + ( Observable / create ( rx / action [ ^ rx . Subscriber s ] \n + ( loop [ i 0 ] \n + ( when ( and ( < i 10 ) ( . isUnsubscribed s ) ) \n + ( . onNext s i ) \n + ( recur ( inc i ) ) ) ) \n + ( . onCompleted s ) ) ) \n + ` ` ` \n + \n language - adaptors \ rxjava - clojure \ src \ main \ clojure \ rx \ lang \ clojure \ interop . clj \n + ; TODO remove this when OnSubscriberFunc is removed \n + ; OnSubscribe is just an Action1 , so add it to the list of implemented interfaces \n + ; so an action cab be used with Observable / create \n + ~ @ ( if ( and ( = prefix "" rx . util . functions . Action "" ) \n + ( some # { 1 } arities ) ) \n + ` ( rx . Observable $ OnSubscribe ) ) \n + \n - by delegating to the given function . \n + by delegating to the given function . Also implements rx . Observable $ OnSubscribe which \n + is just an Action1 . \n language - adaptors \ rxjava - clojure \ src \ test \ clojure \ rx \ lang \ clojure \ interop _ test . clj \n + ( is ( instance ? rx . Observable $ OnSubscribe a ) ) \n - ( testing "" can create an observable "" \n + ( testing "" can create an observable with old style fn "" \n + ( testing "" can create an observable with new - style action "" \n + ( is ( = 99 \n + ( - > ( Observable / create ( rx / action [ ^ rx . Subscriber s ] \n + ( when - not ( . isUnsubscribed s ) \n + ( . onNext s 99 ) ) \n + ( . onCompleted s ) ) ) \n + . toBlockingObservable \n + . single ) ) ) ) \n",Make rx / action implement new OnSubscribe interface,120
hystrix - contrib \ hystrix - clj \ src \ main \ clojure \ com \ netflix \ hystrix \ core . clj \n - ( assoc m : arglists ` ( list ( quote ~ params ) ) ) \n + ( assoc m : arglists ( list ' quote ` ( ~ params ) ) ) \n,"Fix generated arglists \n This is a fix for issue # 831 ( https : / / github . com / Netflix / Hystrix / issues / 831 ) which \n is a blocker for http : / / dev . clojure . org / jira / browse / CLJ - 1232 . Instead of generating \n : arglists as ( list ( quote [ . . ] ) * ) , generate ( quote ( [ . . ] * ) ) . Tests still \n pass and ( doc command ) works as intended . I have not directly tested \n this with Clojure patched with CLJ - 1232 .",120
"src \ main \ java \ org \ junit \ experimental \ max \ MaxCore . java \n - / / TODO ( Feb 23 , 2009 10 : 14 : 05 PM ) : publicized for squeeze \n - / / TODO ( Feb 23 , 2009 10 : 42 : 05 PM ) : V \n - public Request constructLeafRequest ( List < Description > leaves ) { \n + private Request constructLeafRequest ( List < Description > leaves ) { \n - / / TODO ( Feb 23 , 2009 11 : 17 : 01 PM ) : V \n - public Runner buildRunner ( Description each ) { \n + private Runner buildRunner ( Description each ) { \n - try { \n - / / TODO ( Nov 18 , 2008 2 : 18 : 28 PM ) : move to Suite \n - return new Suite ( null , new Class < ? > [ 0 ] ) ; \n - } catch ( InitializationError e ) { \n - / / TODO Auto - generated catch block \n - e . printStackTrace ( ) ; \n - } \n + return Suite . emptySuite ( ) ; \n src \ main \ java \ org \ junit \ runners \ Suite . java \n + public static Runner emptySuite ( ) { \n + try { \n + return new Suite ( ( RunnerBuilder ) null , new Class < ? > [ 0 ] ) ; \n + } catch ( InitializationError e ) { \n + throw new RuntimeException ( "" This shouldn ' t be possible "" ) ; \n + } \n + } \n + \n",Move emptySuite method to Suite \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
"src \ main \ java \ org \ junit \ experimental \ max \ MaxCore . java \n - / / TODO ( Nov 18 , 2008 2 : 04 : 09 PM ) : add a check if building a runner is possible \n - / / TODO ( Feb 23 , 2009 10 : 40 : 23 PM ) : V \n - public List < Description > findLeaves ( Request request ) { \n + private List < Description > findLeaves ( Request request ) { \n - / / TODO ( Feb 23 , 2009 10 : 50 : 48 PM ) : V \n - public void findLeaves ( Description description , List < Description > results ) { \n + private void findLeaves ( Description description , List < Description > results ) { \n",TODO clean - up \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
"src \ main \ java \ org \ junit \ experimental \ max \ MaxHistory . java \n - import java . io . FileNotFoundException ; \n - \n - \n - private static MaxHistory readHistory ( File storedResults ) throws CouldNotReadCoreException { \n - / / TODO : rule of three \n - / / TODO : Really ? \n - ObjectInputStream stream ; \n - FileInputStream file = null ; \n - try { \n - file = new FileInputStream ( storedResults ) ; \n - } catch ( FileNotFoundException e ) { \n - throw new CouldNotReadCoreException ( e ) ; \n - } \n + \n + private static MaxHistory readHistory ( File storedResults ) \n + throws CouldNotReadCoreException { \n + FileInputStream file = new FileInputStream ( storedResults ) ; \n - stream = new ObjectInputStream ( file ) ; \n - } catch ( IOException e ) { \n - throw new CouldNotReadCoreException ( e ) ; \n - } \n - try { \n - return ( MaxHistory ) stream . readObject ( ) ; \n - } catch ( Exception e ) { \n - throw new CouldNotReadCoreException ( e ) ; / / TODO think about what we can do better here \n - } finally { \n + ObjectInputStream stream = new ObjectInputStream ( file ) ; \n + return ( MaxHistory ) stream . readObject ( ) ; \n + } finally { \n - } catch ( IOException e ) { \n - throw new CouldNotReadCoreException ( e ) ; \n - } \n - } finally { \n - try { \n + } finally { \n - } catch ( IOException e ) { \n - / / TODO can ' t imagine what ' s gone wrong here , but who cares ? \n + } catch ( Exception e ) { \n + throw new CouldNotReadCoreException ( e ) ; \n + \n - / / possible time \n + / / possible time \n - \n + \n - int result = getFailure ( o2 ) . compareTo ( getFailure ( o1 ) ) ; \n - return result ! = 0 \n - ? result \n - / / Then shorter tests first \n - : getTestDuration ( o1 ) . compareTo ( getTestDuration ( o2 ) ) ; \n + int result = getFailure ( o2 ) . compareTo ( getFailure ( o1 ) ) ; \n + return result ! = 0 ? result \n + / / Then shorter tests first \n + : getTestDuration ( o1 ) . compareTo ( getTestDuration ( o2 ) ) ; \n - \n + \n - if ( result = = null ) \n + if ( result = = null ) \n - \n",Clean up exceptions in readHistory \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
"src \ main \ java \ org \ junit \ experimental \ max \ MaxHistory . java \n - / / TODO ( Feb 23 , 2009 10 : 41 : 36 PM ) : V \n src \ main \ java \ org \ junit \ internal \ ComparisonCriteria . java \n + / * * \n + * Defines criteria for finding two items "" equal enough "" . Concrete subclasses \n + * may demand exact equality , or , for example , equality within a given delta . \n + * / \n - \n + \n - * Asserts that two arrays are equal . If they are not , an \n - * { @ link AssertionError } is thrown with the given message . If \n - * < code > expecteds < / code > and < code > actuals < / code > are < code > null < / code > , \n - * they are considered equal . \n + * Asserts that two arrays are equal , according to the criteria defined by \n + * the concrete subclass . If they are not , an { @ link AssertionError } is \n + * thrown with the given message . If < code > expecteds < / code > and \n + * < code > actuals < / code > are < code > null < / code > , they are considered equal . \n - * the identifying message for the { @ link AssertionError } ( < code > null < / code > \n - * okay ) \n + * the identifying message for the { @ link AssertionError } ( \n + * < code > null < / code > okay ) \n - * @ param criteria TODO \n - public void arrayEquals ( String message , Object expecteds , \n - Object actuals ) throws ArrayComparisonFailure { \n - / / TODO : DUP above \n - / / TODO ( Sep 8 , 2008 4 : 32 : 50 PM ) : Test that this fails sometimes \n - / / TODO ( Sep 8 , 2008 4 : 33 : 04 PM ) : Update javadoc \n - \n + public void arrayEquals ( String message , Object expecteds , Object actuals ) \n + throws ArrayComparisonFailure { \n - \n - int expectedsLength = Assert . assertArraysAreSameLength ( expecteds , actuals , \n - header ) ; \n + \n + int expectedsLength = Assert . assertArraysAreSameLength ( expecteds , \n + actuals , header ) ; \n - \n + \n src \ main \ java \ org \ junit \ internal \ ExactComparisonCriteria . java \n - / / TODO ( Apr 29 , 2009 4 : 17 : 49 PM ) : where should this live ? \n",Clean up TODOs in ComparisonCriteria and subclasses \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
". settings \ org . eclipse . jdt . core . prefs \n - # Fri Jul 17 17 : 27 : 50 EDT 2009 \n + # Mon Jul 27 22 : 30 : 22 EDT 2009 \n - org . eclipse . jdt . core . compiler . problem . missingJavadocComments = warning \n + org . eclipse . jdt . core . compiler . problem . missingJavadocComments = ignore \n new file \n src \ main \ java \ CategoryTest . java \n + import static org . junit . Assert . fail ; \n + import org . junit . rules . MethodRule ; \n + import org . junit . rules . Timeout ; \n + import org . junit . runner . RunWith ; \n + import org . junit . runners . Suite ; \n + import org . junit . runners . Suite . SuiteClasses ; \n + \n + \n + public class CategoryTest { \n + public static class A { \n + public void a ( ) { \n + / / pass \n + } \n + \n + @ Category ( SlowTests . class ) \n + public void b ( ) { \n + fail ( ) ; \n + } \n + } \n + \n + @ Category ( SlowTests . class ) \n + public static class B { \n + public void c ( ) { \n + \n + } \n + } \n + \n + public static class C { \n + public void d ( ) { \n + \n + } \n + } \n + \n + @ RunWith ( Suite . class ) \n + @ SuiteClasses ( { A . class , B . class , C . class } ) \n + public static class AbcTest { \n + enum JUnitCategories { \n + INTEGRATION , UNIT , GOOD , BAD ; \n + } \n + \n + enum GoogleCategories extends JUnitCategories { \n + SMALL , MEDIUM , LARGE , ENORMOUS ; \n + } \n + \n + @ SuiteRule public Filter filter = new CategoryFilter ( Category . class , SLOW ) ; \n + @ SuiteRule public Filter decimator = new RandomFilter ( 0 . 1 ) ; \n + \n + @ SuiteRule public SuiteRule globalTimeout = GlobalTimeout . createTimeoutOnEachMethod ( 1000 ) ; \n + \n + public static MethodRule GOOGLE _ DEFAULT _ TIMEOUT = new Timeout ( 1000 ) ; \n + \n + SuiteRule \n + @ SuiteRule public MethodRule timeout = new Timeout ( 1000 ) ; \n + \n + @ SuiteRule public MethodRuleDistributor timeoutDistributer = \n + new MethodRuleDistributor ( new Timeout ( 1000 ) ) ; \n + } \n + } \n",Here ' s what categories would look like,131
new file \n . gitignore \n + MaxCore . ser \n + bin \n,Added . gitignore \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
"src \ main \ java \ org \ junit \ runner \ Result . java \n - private boolean fIgnoredDuringExecution = false ; \n - \n - if ( ! fIgnoredDuringExecution ) \n - fCount + + ; \n - fIgnoredDuringExecution = false ; \n + fCount + + ; \n - fIgnoredDuringExecution = true ; \n src \ test \ java \ org \ junit \ tests \ running \ methods \ TestMethodTest . java \n + assertEquals ( 1 , result . getRunCount ( ) ) ; \n",Removed misguided fIgnoredDuringRun flag \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
acknowledgements . txt \n - Amanda Robinson : Fixed overly permissive @ DataPoint processing . \n + Amanda Robinson : Fixed overly permissive @ DataPoint processing . \n + \n + 2009 Feb 9 \n + Mark Shapiro : Discovered bug in test counting after an ignored method ( 2106324 ) \n,Added Mark Shapiro to acknowledgements \n Signed - off - by : Kent Beck < kent @ threeriversinstitute . org >,131
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ turbomodule \ core \ jni \ ReactCommon \ OnLoad . cpp \n - # include < fb / xplat _ init . h > \n - return facebook : : xplat : : initialize ( vm , [ ] { \n + return facebook : : jni : : initialize ( vm , [ ] { \n",Remove fb / xplat _ init dependency \n Summary : \n This diff removes the fb / xplat _ init dependency from fabric onLoad class \n This is necessary to make RM compile in OSS \n changelog : [ Internal ] Internal \n Reviewed By : RSNara \n Differential Revision : D22875531 \n fbshipit - source - id : cc4cd2af875fe7eadfb3a8f4a9f16acf5fa415d8,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ OnLoad . cpp \n - # include < fb / xplat _ init . h > \n - return facebook : : xplat : : initialize ( vm , [ ] { \n + return facebook : : jni : : initialize ( vm , [ ] { \n",Remove fb / xplat _ init dependency \n Summary : \n This diff removes the fb / xplat _ init dependency from fabric onLoad class \n This is necessary to make fabric compile in OSS \n changelog : [ Internal ] Internal \n Reviewed By : RSNara \n Differential Revision : D22874850 \n fbshipit - source - id : 0c61a366e09ab072215ba2fe651f96ef4c2e455a,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ views \ view \ ReactViewBackgroundDrawable . java \n - / * Used for rounded border and rounded background * / \n - private @ Nullable PathEffect mPathEffectForBorderStyle ; \n - mPathEffectForBorderStyle = \n + / / Used for rounded border and rounded background \n + PathEffect mPathEffectForBorderStyle = \n,EZ refactor in ReactViewBackgroundDrawable \n Summary : \n EZ refactor in ReactViewBackgroundDrawable to remove an unnecessary class variable \n changelog : [ internal ] Internal \n Reviewed By : RSNara \n Differential Revision : D22874851 \n fbshipit - source - id : 16808809b196cba0dab5c9972359d7786939a7ce,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ config \ ReactFeatureFlags . java \n + \n + / * * Enable caching of Spannable objects using equality of ReadableNativeMaps * / \n + public static boolean enableSpannableCacheByReadableNativeMapEquality = true ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ views \ text \ BUCK \n + react _ native _ target ( "" java / com / facebook / react / config : config "" ) , \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ views \ text \ TextLayoutManager . java \n + import com . facebook . react . bridge . ReadableNativeMap ; \n + import com . facebook . react . config . ReactFeatureFlags ; \n + private static final LruCache < ReadableNativeMap , Spannable > sSpannableCacheV2 = \n + new LruCache < > ( spannableCacheSize ) ; \n - String attributedStringPayload = attributedString . toString ( ) ; \n - synchronized ( sSpannableCacheLock ) { \n - preparedSpannableText = sSpannableCache . get ( attributedStringPayload ) ; \n - / / TODO : T31905686 implement proper equality of attributedStrings \n - if ( preparedSpannableText ! = null ) { \n - return preparedSpannableText ; \n + String attributedStringPayload = "" "" ; \n + \n + boolean cacheByReadableNativeMap = \n + ReactFeatureFlags . enableSpannableCacheByReadableNativeMapEquality ; \n + / / TODO : T74600554 Cleanup this experiment once positive impact is confirmed in production \n + if ( cacheByReadableNativeMap ) { \n + synchronized ( sSpannableCacheLock ) { \n + preparedSpannableText = sSpannableCacheV2 . get ( ( ReadableNativeMap ) attributedString ) ; \n + if ( preparedSpannableText ! = null ) { \n + return preparedSpannableText ; \n + } \n + } \n + } else { \n + attributedStringPayload = attributedString . toString ( ) ; \n + synchronized ( sSpannableCacheLock ) { \n + preparedSpannableText = sSpannableCache . get ( attributedStringPayload ) ; \n + if ( preparedSpannableText ! = null ) { \n + return preparedSpannableText ; \n + } \n - synchronized ( sSpannableCacheLock ) { \n - sSpannableCache . put ( attributedStringPayload , preparedSpannableText ) ; \n + \n + if ( cacheByReadableNativeMap ) { \n + synchronized ( sSpannableCacheLock ) { \n + sSpannableCacheV2 . put ( ( ReadableNativeMap ) attributedString , preparedSpannableText ) ; \n + } \n + } else { \n + synchronized ( sSpannableCacheLock ) { \n + sSpannableCache . put ( attributedStringPayload , preparedSpannableText ) ; \n + } \n","Refactor caching of Spannable objects instide TextLayoutManager \n Summary : \n This diff optimizes the caching of Spannable objects managed by the TextLayoutManager class . \n Previously , these objects were cached using unsing a String representation of the RedableMap ( creating this string adds a non trivial cost ) , this diff improves the caching performance relying on the equals / hashcode methods of the ReadableNativeMap class \n I created a MC just to have a killswitch \n Motivation : I was analysing another bug and I found this non performant code \n changelog : [ internal ] internal \n Reviewed By : shergin \n Differential Revision : D23429365 \n fbshipit - source - id : 59e5ad0b1b95da992ac393aecfe029da68a8df97",133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricUIManager . java \n - if ( shouldSchedule & & mountItem ! = null ) { \n + if ( shouldSchedule ) { \n,remove unnecessary check \n Summary : \n EZ check to remove unnecessary check \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25315988 \n fbshipit - source - id : a635ce9fd7ad50109bee55f82ccf3556cc7a4b0d,133
"Libraries \ Image \ ImageViewNativeComponent . js \n + internal _ analyticTag : true , \n",Add internal _ analyticTag into RCTImageView JS view configs \n Summary : \n this diff fixes the next error : \n ` ` ` \n ' RCTImageView ' has a view config that does not match native . ' validAttributes ' is missing : internal _ analyticTag \n in RCTImageView ( at Image . ios . js : 149 ) \n in ImageAnalyticsTagContext . Consumer ( at Image . ios . js : 146 ) \n in Image ( at TintedIcon . js : 55 ) \n in TintedIcon ( at TetraIcon . js : 98 ) \n in TetraIcon ( at FDSCheckbox . js : 67 ) \n in FDSCheckbox ( at TetraListCell . js : 820 ) \n in TetraAddOnSecondary ( at TetraListCell . js : 576 ) \n in TetraPressable ( at TetraListCell . js : 603 ) \n in TetraListCell ( created by TetraListCell ) \n in TetraListCell ( at RNInternalSettingsUnit . js : 35 ) \n in TetraList ( at RNInternalSettingsUnit . js : 32 ) \n in RNInternalSettingsUnit ( at RNInternalSettingsDeveloperModeUnit . new . js : 73 ) \n in RNInternalSettingsDeveloperModeUnit ( at RNInternalSettingsSurface . js : 79 ) \n in RNInternalSettingsSurface ( at withDefaultErrorBoundary . js : 30 ) \n in DefaultError ( React . lazy ( RNInternalSettingsSurfaceForFacebook ) ) ( at renderApplication . js : 47 ) \n ` ` ` \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D25313414 \n fbshipit - source - id : ab951d25ac6a80809a2977c80ff059f667cc5595,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactInstanceManager . java \n + import android . view . ViewGroup ; \n + @ ThreadConfined ( UI ) \n + UiThreadUtil . assertOnUiThread ( ) ; \n - reactRoot . getRootViewGroup ( ) . removeAllViews ( ) ; \n - reactRoot . getRootViewGroup ( ) . setId ( View . NO _ ID ) ; \n + ViewGroup rootViewGroup = reactRoot . getRootViewGroup ( ) ; \n + rootViewGroup . removeAllViews ( ) ; \n + rootViewGroup . setId ( View . NO _ ID ) ; \n + @ ThreadConfined ( UI ) \n,Add annotations and thread safety checks in the initialization / teardown methods of ReactInstanceManager \n Summary : \n Add annotations and thread safety checks in the initialization / teardown methods of ReactInstanceManager \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D25321380 \n fbshipit - source - id : 113a7c224ae04009cda9e15676208abcef6af211,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer \n + $ ( call import - module , react / renderer / mapbuffer ) \n new file \n ReactCommon \ react \ renderer \ mapbuffer \ Android . mk \n + # Copyright ( c ) Facebook , Inc . and its affiliates . \n + # \n + # This source code is licensed under the MIT license found in the \n + # LICENSE file in the root directory of this source tree . \n + \n + LOCAL _ PATH : = $ ( call my - dir ) \n + \n + include $ ( CLEAR _ VARS ) \n + \n + LOCAL _ MODULE : = react _ render _ mapbuffer \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SRC _ FILES : = $ ( wildcard $ ( LOCAL _ PATH ) / * . cpp ) \n + \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SHARED _ LIBRARIES : = libreact _ utils \n + \n + LOCAL _ CFLAGS : = \ \n + - DLOG _ TAG = \ "" Fabric \ "" \n + \n + LOCAL _ CFLAGS + = - fexceptions - frtti - std = c + + 14 - Wall \n + \n + include $ ( BUILD _ SHARED _ LIBRARY ) \n + \n + $ ( call import - module , react / utils ) \n",Make react / renderer / mapbuffer module to compile in OSS \n Summary : \n This diff extends the react / renderer / mapbuffer module to compile in OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D22908221 \n fbshipit - source - id : d2a6da04ea73efc35e862839563262d4e89a2c56,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core \n + $ ( call import - module , react / renderer / core ) \n new file \n ReactCommon \ react \ renderer \ core \ Android . mk \n + # Copyright ( c ) Facebook , Inc . and its affiliates . \n + # \n + # This source code is licensed under the MIT license found in the \n + # LICENSE file in the root directory of this source tree . \n + \n + LOCAL _ PATH : = $ ( call my - dir ) \n + \n + include $ ( CLEAR _ VARS ) \n + \n + LOCAL _ MODULE : = react _ render _ core \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SRC _ FILES : = $ ( wildcard $ ( LOCAL _ PATH ) / * . cpp ) \n + \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libjsi libfolly _ futures libreact _ utils libreact _ render _ debug libreact _ render _ graphics \n + \n + LOCAL _ CFLAGS : = \ \n + - DLOG _ TAG = \ "" Fabric \ "" \n + \n + LOCAL _ CFLAGS + = - fexceptions - frtti - std = c + + 14 - Wall \n + \n + include $ ( BUILD _ SHARED _ LIBRARY ) \n + \n + $ ( call import - module , folly ) \n + $ ( call import - module , jsi ) \n + $ ( call import - module , react / utils ) \n + $ ( call import - module , react / renderer / debug ) \n + $ ( call import - module , react / renderer / graphics ) \n",Make react / core module to compile in OSS \n Summary : \n Make react / core module to compile in OSS \n This is necessary to make fabric compile in OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D22908222 \n fbshipit - source - id : a37b87d02ecf77bb25693ce32cd0f3432be5daa7,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics \n + $ ( call import - module , react / renderer / graphics ) \n ReactCommon \ react \ renderer \ graphics \ Android . mk \n - LOCAL _ MODULE : = fabricgraphics \n + LOCAL _ MODULE : = react _ render _ graphics \n - LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / \n - LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / $ ( LOCAL _ PATH ) / platform / cxx / \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json \n + \n + LOCAL _ STATIC _ LIBRARIES : = \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / $ ( LOCAL _ PATH ) / platform / cxx / \n + \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / $ ( LOCAL _ PATH ) / platform / cxx / \n - DLOG _ TAG = \ "" Fabric \ "" \n - LOCAL _ STATIC _ LIBRARIES : = \n - \n - \n + \n + $ ( call import - module , folly ) \n",Make graphics module to compile in OSS \n Summary : \n This diff creates the Android . mk file for the fabric graphics module \n This is necessary to enable fabric in RN OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D22908219 \n fbshipit - source - id : 70ef1d06053b0ca07a71c0a2d36e4edd617b2a25,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug \n + # Fabric : \n + $ ( call import - module , react / utils ) \n + $ ( call import - module , react / renderer / debug ) \n + \n + \n new file \n ReactCommon \ react \ renderer \ debug \ Android . mk \n + # Copyright ( c ) Facebook , Inc . and its affiliates . \n + # \n + # This source code is licensed under the MIT license found in the \n + # LICENSE file in the root directory of this source tree . \n + \n + LOCAL _ PATH : = $ ( call my - dir ) \n + \n + include $ ( CLEAR _ VARS ) \n + \n + LOCAL _ MODULE : = react _ render _ debug \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SRC _ FILES : = $ ( wildcard $ ( LOCAL _ PATH ) / * . cpp ) \n + \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json \n + \n + LOCAL _ CFLAGS : = \ \n + - DLOG _ TAG = \ "" Fabric \ "" \n + \n + LOCAL _ CFLAGS + = - fexceptions - frtti - std = c + + 14 - Wall \n + \n + include $ ( BUILD _ SHARED _ LIBRARY ) \n + \n + $ ( call import - module , folly ) \n ReactCommon \ react \ utils \ Android . mk \n - LOCAL _ MODULE : = reactutils \n + LOCAL _ MODULE : = react _ utils \n",Create Android MK file for debug module \n Summary : \n This diff creates the Android . mk file for the fabric debug module \n This is necessary to enable fabric in RN OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D22908220 \n fbshipit - source - id : f970fa1d8534a6043f60f362740bfc3e5199b511,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry libreact _ render _ components _ view libreact _ render _ components _ view libreact _ render _ components _ unimplementedview libreact _ render _ components _ root libreact _ render _ components _ scrollview \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry libreact _ render _ components _ view libreact _ render _ components _ view libreact _ render _ components _ unimplementedview libreact _ render _ components _ root libreact _ render _ components _ scrollview libbetter \n + $ ( call import - module , better ) \n new file \n ReactCommon \ better \ Android . mk \n + # Copyright ( c ) Facebook , Inc . and its affiliates . \n + # \n + # This source code is licensed under the MIT license found in the \n + # LICENSE file in the root directory of this source tree . \n + \n + LOCAL _ PATH : = $ ( call my - dir ) \n + \n + include $ ( CLEAR _ VARS ) \n + \n + LOCAL _ MODULE : = better \n + \n + LOCAL _ SRC _ FILES : = $ ( wildcard $ ( LOCAL _ PATH ) / * . cpp ) \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / \n + \n + LOCAL _ CFLAGS : = \ \n + - DLOG _ TAG = \ "" Better \ "" \n + \n + LOCAL _ CFLAGS + = - fexceptions - frtti - std = c + + 14 - Wall \n + \n + LOCAL _ STATIC _ LIBRARIES : = \n + \n + LOCAL _ SHARED _ LIBRARIES : = glog \n + \n + include $ ( BUILD _ SHARED _ LIBRARY ) \n + \n + $ ( call import - module , glog ) \n",Extend ' better ' module to compile in OSS \n Summary : \n This diff extends the ' better ' module to compile in OSS \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D22918208 \n fbshipit - source - id : 11cf7c093bd1d50bbb53c6b6a740a3db41971fc0,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry libreact _ render _ view \n + $ ( call import - module , react / renderer / components / view ) \n ReactCommon \ react \ renderer \ components \ view \ Android . mk \n - LOCAL _ MODULE : = reactview \n + LOCAL _ MODULE : = react _ render _ view \n + LOCAL _ SHARED _ LIBRARIES : = libyoga glog libfolly _ json libglog _ init libreact _ render _ core libreact _ render _ debug libreact _ render _ graphics \n + \n + $ ( call import - module , glog ) \n + $ ( call import - module , folly ) \n + $ ( call import - module , fbgloginit ) \n + $ ( call import - module , react / renderer / core ) \n + $ ( call import - module , react / renderer / debug ) \n + $ ( call import - module , react / renderer / graphics ) \n + $ ( call import - module , yogajni ) \n",Extend react / renderer / component / view module to compile in OSS \n Summary : \n This diff extends react / renderer / component / view module to compile in OSS \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D22918210 \n fbshipit - source - id : b92e8701ac6ec93ba8f2cdbfdcc5e34cade0f218,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer \n + LOCAL _ SHARED _ LIBRARIES : = libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry \n + $ ( call import - module , react / renderer / componentregistry ) \n new file \n ReactCommon \ react \ renderer \ componentregistry \ Android . mk \n + # Copyright ( c ) Facebook , Inc . and its affiliates . \n + # \n + # This source code is licensed under the MIT license found in the \n + # LICENSE file in the root directory of this source tree . \n + \n + LOCAL _ PATH : = $ ( call my - dir ) \n + \n + include $ ( CLEAR _ VARS ) \n + \n + LOCAL _ MODULE : = react _ render _ componentregistry \n + \n + LOCAL _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SRC _ FILES : = $ ( wildcard $ ( LOCAL _ PATH ) / * . cpp ) \n + \n + LOCAL _ EXPORT _ C _ INCLUDES : = $ ( LOCAL _ PATH ) / . . / . . / . . / \n + \n + LOCAL _ SHARED _ LIBRARIES : = libjsi libfolly _ futures libfolly _ json libreact _ render _ core libreact _ render _ debug libreact _ utils libglog _ init \n + \n + LOCAL _ CFLAGS : = \ \n + - DLOG _ TAG = \ "" Fabric \ "" \n + \n + LOCAL _ CFLAGS + = - fexceptions - frtti - std = c + + 14 - Wall \n + \n + include $ ( BUILD _ SHARED _ LIBRARY ) \n + \n + $ ( call import - module , fbgloginit ) \n + $ ( call import - module , folly ) \n + $ ( call import - module , jsi ) \n + $ ( call import - module , react / renderer / core ) \n + $ ( call import - module , react / renderer / debug ) \n + $ ( call import - module , react / utils ) \n",Extend react / renderer / componentregistry module to compile in OSS \n Summary : \n This diff extends react / renderer / componentregistry module to compile in OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D22908223 \n fbshipit - source - id : 6cc053262fbe2bb0f631ac40cd57959267ae95fa,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ JBackgroundExecutor . cpp \n - > getMethod < void ( Runnable : : javaobject ) > ( "" queueRunnable "" ) ; \n - method ( self , static _ ref _ cast < Runnable > ( jrunnable ) . get ( ) ) ; \n + method ( self , static _ ref _ cast < Runnable : : javaobject > ( jrunnable ) . get ( ) ) ; \n ReactAndroid \ src \ main \ jni \ react \ jni \ JNativeRunnable . h \n - class Runnable : public JavaClass < Runnable > { \n + struct Runnable : public JavaClass < Runnable > { \n",Refactor Runnable C + + class to compile in OSS \n Summary : \n This diff refactors the class Runnable into a struct to make it work in OSS \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D22963704 \n fbshipit - source - id : 2212c8f1e4a62b2bcad5c061709e29b247454fc1,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ mounting \ MountingManager . java \n - import static com . facebook . infer . annotation . ThreadConfined . UI ; \n - @ ThreadConfined ( UI ) \n - public void addRootView ( int reactRootTag , @ NonNull View rootView ) { \n - if ( rootView . getId ( ) ! = View . NO _ ID ) { \n - FLog . e ( \n - TAG , \n - "" Trying to add RootTag to RootView that already has a tag : existing tag : [ % d ] new tag : [ % d ] "" , \n - rootView . getId ( ) , \n - reactRootTag ) ; \n - throw new IllegalViewOperationException ( \n - "" Trying to add a root view with an explicit id already set . React Native uses "" \n - + "" the id field to track react tags and will overwrite this field . If that is fine , "" \n - + "" explicitly overwrite the id field to View . NO _ ID before calling addRootView . "" ) ; \n - } \n - \n + @ AnyThread \n + public void addRootView ( final int reactRootTag , @ NonNull final View rootView ) { \n - rootView . setId ( reactRootTag ) ; \n + \n + UiThreadUtil . runOnUiThread ( \n + new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + if ( rootView . getId ( ) ! = View . NO _ ID ) { \n + FLog . e ( \n + TAG , \n + "" Trying to add RootTag to RootView that already has a tag : existing tag : [ % d ] new tag : [ % d ] "" , \n + rootView . getId ( ) , \n + reactRootTag ) ; \n + throw new IllegalViewOperationException ( \n + "" Trying to add a root view with an explicit id already set . React Native uses "" \n + + "" the id field to track react tags and will overwrite this field . If that is fine , "" \n + + "" explicitly overwrite the id field to View . NO _ ID before calling addRootView . "" ) ; \n + } \n + rootView . setId ( reactRootTag ) ; \n + } \n + } ) ; \n",Ensure ReactRootView . getId ( ) is accessed on the UIThread \n Summary : \n Ensure ReactRootView . getId ( ) is accessed on the UIThread \n changelog : [ internal ] intenral \n Reviewed By : JoshuaGross \n Differential Revision : D25321379 \n fbshipit - source - id : 889e59c655324352a7b9ac5bed769750786b8190,133
Libraries \ Components \ TextInput \ AndroidTextInputNativeComponent . js \n - import * as React from ' react ' ; \n,Remove unused dependency \n Summary : \n Remove unused dependency \n changelog : [ Internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D22470766 \n fbshipit - source - id : e49180d1a9eb01e8380fb2bde16b8d4378018693,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactInstanceManager . java \n + FLog . d ( ReactConstants . TAG , "" ReactInstanceManager has been destroyed "" ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ CatalystInstanceImpl . java \n - \n - UiThreadUtil . assertOnUiThread ( ) ; \n - \n","Refactor destruction of ReactInstanceManager during Memory Pressure in FB4A \n Summary : \n This diff refactors the destruction of the ReactInstanceManager when the app is experiencing low memory . \n As part of this refactor , I setup an experiment to understand at what level of memory pressure is convenient to destroy the RN bridge . \n The experiment is divided in six levels described in the following table : \n https : / / pxl . cl / 1dzx8 \n https : / / www . internalfb . com / intern / qe2 / fb4a _ react _ native _ memory / android _ fb4a _ instance _ unload _ pressure _ v2 / setup \n changelog : [ internal ] Internal \n Reviewed By : JoshuaGross \n Differential Revision : D22577553 \n fbshipit - source - id : 37f8f561099a1ba6239795f5907090ced3b5dd18",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ common \ LifecycleState . java \n - * Eventually , if necessary , it could contain something like : \n - * < p > BEFORE _ CREATE , CREATED , VIEW _ CREATED , STARTED , RESUMED \n + * < p > BEFORE _ CREATE is used before a ReactRootView is attached to ReactInstanceManager , or after all \n + * the ReactRootView has been detached from the ReactInstanceManager . \n + * \n + * < p > BEFORE _ RESUME is used after a ReactRootView is attached to ReactInstanceManager but before \n + * it ' s activity is resumed , or after its activity has been paused and before the ReactRootView has \n + * been detached from the ReactInstanceManager . \n + * \n + * < p > RESUMED is used when a ReactRootView is rendered on the screen and the user can interact with \n + * it . \n","Update InitialLifeCycleState used when initializing RN in FB4A \n Summary : \n This diff changes the InitialLifeCycleState used when initializing RN in FB4A from BEFORE _ RESUME to BEFORE _ CREATE . \n The value of this field is used during the teardown of RN to determine if RN is actually running or not \n The intention of this change is to represent the right behavior of RN during initialization , also this will allow RN to be turn down in case of memory pressure when the bridge has been initialized but before the user has navigated to a RN screen ( preloading ) \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D22577555 \n fbshipit - source - id : e54ef596cfe4429745611fe6022eb000051a93d0",133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ events \ EventDispatcherImpl . java \n + import java . util . concurrent . CopyOnWriteArrayList ; \n - private final ArrayList < EventDispatcherListener > mListeners = new ArrayList < > ( ) ; \n + private final CopyOnWriteArrayList < EventDispatcherListener > mListeners = \n + new CopyOnWriteArrayList < > ( ) ; \n,"Fix ConcurrentModificationException while registering events \n Summary : \n This diff fixes a ConcurrentModificationException that is thrown when registering events in React Native . \n This bug was introduced by D22483508 ( https : / / github . com / facebook / react - native / commit / 80f13412e548c8666b6ad770e6d3d5c54a717bc2 ) , before event listeners were registered in the NativeModule Thread , now they are registered in the UI Thread . \n As part of this diff I change the type of mListeners variable to use CopyOnWriteArrayList instead of ArrayList because this variable is accessed from different threads . This will prevent the exception to happen , but additionally we need to verify if the change of threading made in D22483508 ( https : / / github . com / facebook / react - native / commit / 80f13412e548c8666b6ad770e6d3d5c54a717bc2 ) will cause any other issue ( e . g . events not being delivered becuase the listeners are registered too late in the UI Thread ) \n changelog : [ Internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D22599747 \n fbshipit - source - id : 5c5e46710c4a559badbd713f536e6e6e464fda23",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ BUCK \n + react _ native _ dep ( "" libraries / fbcore / src / main / java / com / facebook / common / logging : logging "" ) , \n + react _ native _ target ( "" java / com / facebook / react / common : common "" ) , \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ DisplayMetricsHolder . java \n + import com . facebook . common . logging . FLog ; \n + import com . facebook . react . common . ReactConstants ; \n - throw new RuntimeException ( "" Error getting real dimensions for API level < 17 "" , e ) ; \n + / / this may not be 100 % accurate , but it ' s all we ' ve got \n + screenDisplayMetrics . widthPixels = display . getWidth ( ) ; \n + screenDisplayMetrics . heightPixels = display . getHeight ( ) ; \n + FLog . e ( \n + ReactConstants . TAG , \n + "" Unable to access getRawHeight and getRawWidth to get real dimensions . "" , \n + e ) ; \n",Fix NoSuchMethodException when calling DisplayMetricsHolder . initDisplayMetrics in Android API level < = 16 \n Summary : \n This diff fixex a NoSuchMethodException when calling DisplayMetricsHolder . initDisplayMetrics in Android API level < = 16 . \n changelog : [ Android ] [ Fixed ] Fix NoSuchMethodException when calling DisplayMetricsHolder . initDisplayMetrics in Android API level < = 16 \n Reviewed By : fkgozali \n Differential Revision : D22630603 \n fbshipit - source - id : d2a95445beb5745a89ee1eefdf0d24ce3e0b8893,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ views \ view \ ReactViewBackgroundDrawable . java \n + import static android . os . Build . VERSION _ CODES . KITKAT ; \n + \n + import android . annotation . TargetApi ; \n + @ TargetApi ( KITKAT ) \n,Fix render of ARTShape using null paths \n Summary : \n This diff fixes the rendering of ART Shapes that uses null paths \n changelog : [ internal ] internal fix \n Reviewed By : JoshuaGross \n Differential Revision : D22780163 \n fbshipit - source - id : 2aded726ad47fce243ec1c28fbd4c39dd71820ef,133
RNTester \ android \ app \ build . gradle \n - minSdkVersion 18 \n + minSdkVersion 19 \n ReactAndroid \ build . gradle \n - } \n + } \n - / / after which the base path will be null \n + / / after which the base path will be null \n - minSdkVersion ( 16 ) \n + minSdkVersion ( 19 ) \n,Upgrade react - native - github Android to support API level 19 + \n Summary : \n This diff upgrades react - native - github Android to support API level 19 + \n changelog : [ Android ] [ Deprecated ] Deprecate support of Android API levels 16 to 18 . The new minSDK version will be 19 + moving forward \n Reviewed By : JoshuaGross \n Differential Revision : D22734208 \n fbshipit - source - id : b052721c8cfb44f8d74cf4bbb5b7a769e544d1d9,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ modules \ accessibilityinfo \ AccessibilityInfoModule . java \n + @ TargetApi ( Build . VERSION _ CODES . KITKAT ) \n - Build . VERSION . SDK _ INT < Build . VERSION _ CODES . JELLY _ BEAN _ MR1 \n - ? null \n - : Settings . Global . getString ( \n - mContentResolver , Settings . Global . TRANSITION _ ANIMATION _ SCALE ) ; \n + Settings . Global . getString ( mContentResolver , Settings . Global . TRANSITION _ ANIMATION _ SCALE ) ; \n + @ TargetApi ( Build . VERSION _ CODES . KITKAT ) \n - if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . KITKAT ) { \n - mAccessibilityManager . addTouchExplorationStateChangeListener ( \n - mTouchExplorationStateChangeListener ) ; \n - } \n + mAccessibilityManager . addTouchExplorationStateChangeListener ( \n + mTouchExplorationStateChangeListener ) ; \n + @ TargetApi ( Build . VERSION _ CODES . KITKAT ) \n - if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . KITKAT ) { \n - mAccessibilityManager . removeTouchExplorationStateChangeListener ( \n - mTouchExplorationStateChangeListener ) ; \n - } \n + mAccessibilityManager . removeTouchExplorationStateChangeListener ( \n + mTouchExplorationStateChangeListener ) ; \n - if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . JELLY _ BEAN _ MR1 ) { \n - mContentResolver . unregisterContentObserver ( animationScaleObserver ) ; \n - } \n + mContentResolver . unregisterContentObserver ( animationScaleObserver ) ; \n",Cleanup unsed code on AccessibilityInfoModule \n Summary : \n This diff cleansup unused code on AccessibilityInfoModule class \n changelog : [ Android ] [ Deprecated ] Remove code used by deprecated Android API levels \n Reviewed By : JoshuaGross \n Differential Revision : D22771912 \n fbshipit - source - id : f32808fa93f75c10324e8875b85fe4e541b284b8,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ queue \ ReactQueueConfigurationSpec . java \n - Build . VERSION . SDK _ INT < 21 \n + Build . VERSION . SDK _ INT < Build . VERSION _ CODES . LOLLIPOP \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ modules \ network \ ForwardingCookieHandler . java \n - / / As CookieManager was synchronous before API 21 this class emulates the async behavior on < 21 . \n - private static final boolean USES _ LEGACY _ STORE = Build . VERSION . SDK _ INT < 21 ; \n + / / As CookieManager was synchronous before API 21 this class emulates the async behavior on < 21 . \n + private static final boolean USES _ LEGACY _ STORE = \n + Build . VERSION . SDK _ INT < Build . VERSION _ CODES . LOLLIPOP ; \n + @ TargetApi ( Build . VERSION _ CODES . LOLLIPOP ) \n - @ TargetApi ( 21 ) \n + @ TargetApi ( Build . VERSION _ CODES . LOLLIPOP ) \n - @ TargetApi ( 21 ) \n + @ TargetApi ( Build . VERSION _ CODES . LOLLIPOP ) \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ modules \ network \ OkHttpClientProvider . java \n - } catch ( Exception exc ) { \n - FLog . e ( "" OkHttpClientProvider "" , "" Error while enabling TLS 1 . 2 "" , exc ) ; \n + } catch ( Exception ex ) { \n + FLog . e ( "" OkHttpClientProvider "" , "" Error while enabling TLS 1 . 2 "" , ex ) ; \n","Cleanup ForwardingCookieHandler class \n Summary : \n This diff cleansup the class ForwardingCookieHandler , refactoring constants and adding annotations to avoid lint errors \n changelog : [ Internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D22771914 \n fbshipit - source - id : 4fdff2df5ea103f93519c2f4504288202114b1fc",133
template \ android \ build . gradle \n - minSdkVersion = 16 \n + minSdkVersion = 19 \n,Upgrade minsdkversion of RN OSS template to API level 19 \n Summary : \n This diff updates the minsdkversion of RN OSS template to API level 19 \n changelog : [ Android ] [ Deprecated ] Deprecate support of Android API levels 16 to 18 . The new minSDK version will be 19 + moving forward \n Reviewed By : JoshuaGross \n Differential Revision : D22874852 \n fbshipit - source - id : 1df98e422dc9debd40ab2021aafc7b165312d14b,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ config \ ReactFeatureFlags . java \n + \n + / * * Enables Static ViewConfig in RN Android native code . * / \n + public static boolean enableExperimentalStaticViewConfigs = false ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n + import com . facebook . react . config . ReactFeatureFlags ; \n + / / TODO T81145457 - Implement pre - initialization of ViewManagers in Fabric Android \n + if ( ReactFeatureFlags . enableExperimentalStaticViewConfigs ) { \n + preInitializeViewManagers ( viewManagerNames ) ; \n + / / When Static view configs are enabled it is not necessary to pre - compute the constants for \n + / / viewManagers , although the pre - initialization of viewManager objects is still necessary \n + / / for performance reasons . \n + return ; \n + } \n + \n + private void preInitializeViewManagers ( List < String > viewManagerNames ) { \n + for ( String viewManagerName : viewManagerNames ) { \n + mUIImplementation . resolveViewManager ( viewManagerName ) ; \n + } \n + } \n + \n",Prevent initialization of constants for view managers for users with static view config enabled \n Summary : \n This diff prevents the pre - calculation of ViewManager ' s constants for users with static view config enabled . \n We still load viewManager classes and create viewManger objects for perf reasons \n Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D25414068 \n fbshipit - source - id : a91f6113e35b42625c03d13bd67b63e3f9f75098,133
"packages \ react - native - codegen \ DEFS . bzl \n + copy _ generated _ cxx _ files = "" copy _ generated _ cxx _ files - { } "" . format ( name ) \n + zip _ generated _ cxx _ files = "" zip _ generated _ cxx _ files - { } "" . format ( name ) \n + fb _ native . genrule ( \n + name = copy _ generated _ cxx _ files , \n + cmd = "" mkdir $ OUT & & find $ ( location : { } ) - name ' * . cpp ' - o - name ' * . h ' - exec cp { { } } $ OUT \ \ ; "" . format ( generate _ fixtures _ rule _ name ) , \n + out = "" cxx "" , \n + labels = [ "" codegen _ rule "" ] , \n + ) \n + \n + fb _ native . zip _ file ( \n + name = zip _ generated _ cxx _ files , \n + srcs = [ "" : { } "" . format ( copy _ generated _ cxx _ files ) ] , \n + out = "" { } . src . zip "" . format ( zip _ generated _ cxx _ files ) , \n + visibility = [ "" PUBLIC "" ] , \n + labels = [ "" codegen _ rule "" ] , \n + ) \n + \n + rn _ android _ library ( \n + name = "" generated _ components _ cxx - { } "" . format ( name ) , \n + srcs = [ \n + "" : { } "" . format ( zip _ generated _ cxx _ files ) , \n + ] , \n + labels = [ "" codegen _ rule "" ] , \n + visibility = [ "" PUBLIC "" ] , \n + deps = [ \n + react _ native _ dep ( "" third - party / android / androidx : annotation "" ) , \n + react _ native _ target ( "" java / com / facebook / react / bridge : bridge "" ) , \n + react _ native _ target ( "" java / com / facebook / react / common : common "" ) , \n + react _ native _ target ( "" java / com / facebook / react / turbomodule / core : core "" ) , \n + react _ native _ target ( "" java / com / facebook / react / uimanager : uimanager "" ) , \n + ] , \n + ) \n + \n",Create buck target to copy C + + files into OSS \n Summary : \n This new buck target will execute the code gen and copy C + + files to the output directory . This will be used to integrate these files into RN Tester \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23115538 \n fbshipit - source - id : de4135be697c36cd559edf416986299511c31744,133
"ReactCommon \ react \ renderer \ imagemanager \ BUCK \n + exported _ headers = subdir _ glob ( \n + [ \n + ( "" "" , "" * . h "" ) , \n + ( "" platform / cxx "" , "" * * / * . h "" ) , \n + ] , \n + prefix = "" react / renderer / imagemanager "" , \n + ) , \n",Fix codegen for CXX build \n Summary : \n Fabric codegen is failing with running without specifying a specific platform . This diff fixes that . \n Steps to reproduce : \n ` ` ` \n buck build / / xplat / js / react - native - github : generated _ components - rncore - - show - output \n ` ` ` \n Error : \n ` ` ` \n # include < react / renderer / imagemanager / primitives . h > \n ^ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n 1 error generated . \n ` ` ` \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23114403 \n fbshipit - source - id : 50210e74f2a99ae5a77087988c3323bdacf04128,133
"RNTester \ android \ app \ build . gradle \n - * / / Enable react - native - codegen during build time . \n - * enableCodegen : true , \n - * \n - enableCodegen : System . getenv ( ' USE _ CODEGEN ' ) , \n - enableFabric : System . getenv ( "" USE _ FABRIC "" ) ? : false , \n + enableFabric : ( System . getenv ( ' USE _ FABRIC ' ) ? : ' 0 ' ) . toBoolean ( ) , \n ReactAndroid \ build . gradle \n - / / USE _ FABRIC = false will build RN excluding fabric \n - / / USE _ FABRIC = true will build RN including fabric \n - def enableFabric = System . getenv ( "" USE _ FABRIC "" ) ? : "" false "" \n + / / USE _ FABRIC = 0 will build RN excluding fabric \n + / / USE _ FABRIC = 1 will build RN including fabric \n + def enableFabric = ( System . getenv ( ' USE _ FABRIC ' ) ? : ' 0 ' ) . toBoolean ( ) \n",Unify type and values of USE _ FABRIC env variable with USE _ CODEGEN \n Summary : \n This diff unifies the type and value of USE _ FABRIC env variable exposed in Gradle with the USE _ CODEGEN env variable \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23145658 \n fbshipit - source - id : 9575f6b50c7a977254e364037d1417b3b1cdb607,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ ViewManager . java \n + / * * \n + * Returns a { @ link Map < String , String > } representing the native props of the view manager . The \n + * Map contains the names ( key ) and types ( value ) of the ViewManager ' s props . \n + * / \n",Build RN Tester with fabric enabled in sandcastle \n Summary : \n This diff extends test - react - native - oss - android - legocastle to test the build of RNTester with fabric enabled in Sandcastle \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23141524 \n fbshipit - source - id : 396dae1c0a23ce03db1053de1627eacb09a6df94,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ BUCK \n + # TODO T71316899 : Extract CoreComponentsRegistry out of this module \n + # The following dependencies are required by CoreComponentsRegistry \n + "" / / xplat / js / react - native - github : generated _ components - rncore "" , \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ CoreComponentsRegistry . cpp \n + # include < react / renderer / components / rncore / ComponentDescriptors . h > \n + \n + / / TODO T69453179 : Codegen this file \n + \n - > createComponentDescriptorRegistry ( \n + \n + auto mutableRegistry = \n + std : : const _ pointer _ cast < ComponentDescriptorRegistry > ( registry ) ; \n + mutableRegistry - > setFallbackComponentDescriptor ( \n + std : : make _ shared < UnimplementedNativeViewComponentDescriptor > ( \n + ComponentDescriptorParameters { \n + eventDispatcher , contextContainer , nullptr } ) ) ; \n + \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ shell \ BUCK \n + react _ native _ target ( "" java / com / facebook / react / views / unimplementedview : unimplementedview "" ) , \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ shell \ MainReactPackage . java \n + import com . facebook . react . views . unimplementedview . ReactUnimplementedViewManager ; \n + viewManagers . add ( new ReactUnimplementedViewManager ( ) ) ; \n + \n",Integrate UnimplementedView into RNTester OSS \n Summary : \n This diff integrates and render UnimplementedView into RNTester OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23170052 \n fbshipit - source - id : 9306311d114c280fdeeb20d545ef244369040e96,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ BUCK \n + react _ native _ xplat _ target ( "" react / renderer / components / textinput : androidtextinput "" ) , \n ReactCommon \ react \ renderer \ components \ textinput \ BUCK \n - ( "" androidtextinput "" , "" * . h "" ) , \n + ( "" androidtextinput / react / renderer / components / androidtextinput "" , "" * . h "" ) , \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputComponentDescriptor . h \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputComponentDescriptor . h \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputEventEmitter . cpp \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputEventEmitter . cpp \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputEventEmitter . h \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputEventEmitter . h \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputProps . cpp \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputProps . cpp \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputProps . h \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputProps . h \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputShadowNode . cpp \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputShadowNode . cpp \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputShadowNode . h \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputShadowNode . h \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputState . cpp \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputState . cpp \n rename from ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ AndroidTextInputState . h \n rename to ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputState . h \n",Update directory hierarchy of AndroidTextInput C + + files \n Summary : \n This diff updates the directory hierarchy of AndroidTextInput C + + files to be compatible with Android OSS build system \n changelog : [ internal ] Internal \n Reviewed By : PeteTheHeat \n Differential Revision : D23179390 \n fbshipit - source - id : 1c52e4f882853799a58d44876cadd392b4a35050,133
"ReactCommon \ react \ renderer \ components \ slider \ BUCK \n - ( "" platform / android "" , "" * . h "" ) , \n + ( "" platform / android / react / renderer / components / slider "" , "" * . h "" ) , \n - [ "" platform / android / * . h "" ] , \n + [ "" platform / android / react / renderer / components / slider / * . h "" ] , \n - [ "" platform / android / * . cpp "" ] , \n + [ "" platform / android / react / renderer / components / slider / * . cpp "" ] , \n rename from ReactCommon \ react \ renderer \ components \ slider \ platform \ android \ SliderMeasurementsManager . cpp \n rename to ReactCommon \ react \ renderer \ components \ slider \ platform \ android \ react \ renderer \ components \ slider \ SliderMeasurementsManager . cpp \n rename from ReactCommon \ react \ renderer \ components \ slider \ platform \ android \ SliderMeasurementsManager . h \n rename to ReactCommon \ react \ renderer \ components \ slider \ platform \ android \ react \ renderer \ components \ slider \ SliderMeasurementsManager . h \n",Move Android Slider C + + files to make them compatible with RN Tester OSS build \n Summary : \n This diff moves Android Slider C + + files to make them compatible with RN Tester OSS build \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D23227862 \n fbshipit - source - id : 7a5ed1bdc03cbe715467eddd4aad9af82761d4f0,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ CoreComponentsRegistry . cpp \n + providerRegistry - > add ( concreteComponentDescriptorProvider < \n + ActivityIndicatorViewComponentDescriptor > ( ) ) ; \n,Integrate Activity Indicator into RN Tester Android OSS app \n Summary : \n This diff integrates Activity Indicator into RN Tester Android OSS app \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23198641 \n fbshipit - source - id : 93614a3f856b4fc162d4618b168d9c82d18a91eb,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ CoreComponentsRegistry . cpp \n + providerRegistry - > add ( concreteComponentDescriptorProvider < \n + AndroidDrawerLayoutComponentDescriptor > ( ) ) ; \n,Integrate AndroidDrawerLayout component into RN Tester Android OSS APP \n Summary : \n This diff registers the AndroidDrawerLayout component into RN Tester Android OSS APP \n Changelog : [ internal ] \n Reviewed By : fkgozali \n Differential Revision : D23198359 \n fbshipit - source - id : 4033c7e968a993a7f8fcaa3f57e7dd78bf84fe57,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ CoreComponentsRegistry . cpp \n + # include < react / renderer / components / scrollview / ScrollViewComponentDescriptor . h > \n + providerRegistry - > add ( \n + concreteComponentDescriptorProvider < ScrollViewComponentDescriptor > ( ) ) ; \n,Integrate ScrollView in RN Tester Android OSS APP \n Summary : \n This diff integrates ScrollView in RN Tester Android OSS APP \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23179883 \n fbshipit - source - id : 8e892ae613a1f44c8d6cfb837bfdbc0771a89176,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ CoreComponentsRegistry . cpp \n + providerRegistry - > add ( concreteComponentDescriptorProvider < \n + AndroidSwipeRefreshLayoutComponentDescriptor > ( ) ) ; \n,Integrate AndroidSwipeRefreshLayout into RN Tester Android OSS app \n Summary : \n This diff integrates AndroidSwipeRefreshLayout into RN Tester Android OSS app \n Changelog : [ Internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23227855 \n fbshipit - source - id : 52bb457d655500b60614dfa3512b5173516f8483,133
"ReactCommon \ react \ renderer \ components \ switch \ BUCK \n - [ "" * * / * . cpp "" ] , \n + [ "" androidswitch / react / renderer / components / androidswitch / * . cpp "" ] , \n - [ "" * * / * . h "" ] , \n + [ "" androidswitch / react / renderer / components / androidswitch / * . h "" ] , \n - ( "" androidswitch "" , "" * . h "" ) , \n + ( "" androidswitch / react / renderer / components / androidswitch "" , "" * . h "" ) , \n rename from ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ AndroidSwitchComponentDescriptor . h \n rename to ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ react \ renderer \ components \ androidswitch \ AndroidSwitchComponentDescriptor . h \n rename from ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ AndroidSwitchMeasurementsManager . cpp \n rename to ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ react \ renderer \ components \ androidswitch \ AndroidSwitchMeasurementsManager . cpp \n rename from ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ AndroidSwitchMeasurementsManager . h \n rename to ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ react \ renderer \ components \ androidswitch \ AndroidSwitchMeasurementsManager . h \n rename from ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ AndroidSwitchShadowNode . cpp \n rename to ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ react \ renderer \ components \ androidswitch \ AndroidSwitchShadowNode . cpp \n rename from ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ AndroidSwitchShadowNode . h \n rename to ReactCommon \ react \ renderer \ components \ switch \ androidswitch \ react \ renderer \ components \ androidswitch \ AndroidSwitchShadowNode . h \n",Move AndroidSwitch C + + files to make them compatible with RN OSS Build \n Summary : \n This diff moves AndroidSwitch C + + files to make them compatible with RN OSS Build \n Changelog : [ Internal ] internal \n Reviewed By : PeteTheHeat \n Differential Revision : D23227861 \n fbshipit - source - id : 8f23c2eb266a47cb9af82f4159f64b987c14141b,133
"ReactCommon \ react \ renderer \ components \ textinput \ androidtextinput \ react \ renderer \ components \ androidtextinput \ AndroidTextInputState . cpp \n - if ( mostRecentEventCount ! = 0 ) { \n - newState [ "" attributedString "" ] = toDynamic ( attributedString ) ; \n - newState [ "" hash "" ] = newState [ "" attributedString "" ] [ "" hash "" ] ; \n - } \n + newState [ "" attributedString "" ] = toDynamic ( attributedString ) ; \n + newState [ "" hash "" ] = newState [ "" attributedString "" ] [ "" hash "" ] ; \n","Fix initial render of RN Android TextInput \n Summary : \n This diff fixes the initial render of RN Android TextInput . The problem was that "" attributedString "" was not serialized until an event was sent from native side . \n Changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D23383969 \n fbshipit - source - id : 86601434b1fbaa9f712bdb79b013a1d004bc55a4",133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n + * \n + * @ deprecated This method will not be supported by the new architecture of react native . \n + @ Deprecated \n,"Introduce TransparentImmersiveReactActivity in FB4A \n Summary : \n This diff creates the new TransparentImmersiveReactActivity in FB4A , the intention is to help integrate TransparentReactActivity with Fb4A \n Changelog : [ Deprecated ] [ Android ] Deprecated method UIManagerModule . getUIImplementation . This method will not be part of the new architecture of React Native . \n Reviewed By : stashuk \n Differential Revision : D23324543 \n fbshipit - source - id : 35395fe410790a9611a4637361b888678eb0a836",133
"Libraries \ Components \ TextInput \ AndroidTextInputViewConfig . js \n + topBlur : { \n + phasedRegistrationNames : { \n + bubbled : ' onBlur ' , \n + captured : ' onBlurCapture ' , \n + } , \n + } , \n + topEndEditing : { \n + phasedRegistrationNames : { \n + bubbled : ' onEndEditing ' , \n + captured : ' onEndEditingCapture ' , \n + } , \n + } , \n + topFocus : { \n + phasedRegistrationNames : { \n + bubbled : ' onFocus ' , \n + captured : ' onFocusCapture ' , \n + } , \n + } , \n + topKeyPress : { \n + phasedRegistrationNames : { \n + bubbled : ' onKeyPress ' , \n + captured : ' onKeyPressCapture ' , \n + } , \n + } , \n + topSubmitEditing : { \n + phasedRegistrationNames : { \n + bubbled : ' onSubmitEditing ' , \n + captured : ' onSubmitEditingCapture ' , \n + } , \n + } , \n","Fix inconsistency on AndroidTextInput view configs \n Summary : \n BubblingEventTypes are inconsistent between AndroidTextInputViewConfig . js and ReactTextInputManager . java , this diff fixes this inconsistency \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D22470096 \n fbshipit - source - id : 3940dcc0ae67a42ac070c06ec2d54bc365eab6b7",133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerHelper . java \n - @ Nullable \n - UIManager uiManager = \n - context . getJSIModule ( JSIModuleType . UIManager ) ! = null \n - ? ( UIManager ) context . getJSIModule ( JSIModuleType . UIManager ) \n - : null ; \n + @ Nullable UIManager uiManager = ( UIManager ) context . getJSIModule ( JSIModuleType . UIManager ) ; \n,"Remove double lookup of UIManager \n Summary : \n Remove double lookup of UIManager , cast of null returns null . \n changelog : [ internal ] \n Reviewed By : ejanzer \n Differential Revision : D25453878 \n fbshipit - source - id : c727c15fa787981eb5bf02006184e14cfab319c6",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactRootView . java \n - import com . facebook . react . uimanager . UIManagerModule ; \n - UIManagerModule uiManager = reactContext . getNativeModule ( UIManagerModule . class ) ; \n + UIManager uiManager = UIManagerHelper . getUIManager ( reactContext , getUIManagerType ( ) ) ; \n - UIManagerModule uiManager = reactContext . getNativeModule ( UIManagerModule . class ) ; \n + UIManager uiManager = UIManagerHelper . getUIManager ( reactContext , getUIManagerType ( ) ) ; \n",Prevent ReactRootView to load UIManagerModule when running with Fabric Enabled \n Summary : \n Prevent ReactRootView to load UIManagerModule when running with Fabric Enabled \n changelog : [ Internal ] \n Reviewed By : ejanzer \n Differential Revision : D25453879 \n fbshipit - source - id : 98e88db17a86ae60e14efb070df9b2da082ae127,133
"RNTester \ android \ app \ build . gradle \n + fabric { \n + / / TODO T71370706 - Create a different dimension to build fabric \n + dimension "" vm "" \n + } \n + fabricDebugImplementation { } \n + fabricReleaseImplementation { } \n + fabricDebugImplementation files ( hermesPath + "" hermes - debug . aar "" ) \n + fabricReleaseImplementation files ( hermesPath + "" hermes - release . aar "" ) \n","Create Fabric flavor into RN Tester build system \n Summary : \n This diff adds a new flavor into the RN Tester gradle system . \n The "" fabric "" flavor is going to be used in the future to : \n - determine if Fabric should be enabled or not ( at runtime ) \n - include or exclude fabric C + + code at compile time \n I decided to temporarily reuse the "" vm "" dimension in order to reduce friction while I ' m still iterating on the implementation . \n If I created another dimension , then it will force developers to compile RN tester using two flavors : \n ` ` ` \n . / gradlew : RNTester : android : app : installHermesFabricDebug \n ` ` ` \n I ' m planning to refactor this in the near future ( T71370706 ) \n changelog : [ Internal ] Internal \n Reviewed By : JoshuaGross \n Differential Revision : D23012445 \n fbshipit - source - id : 1ea6a707ea2bfaca1be567f43b08860407124c17",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ ComponentFactory . java \n + @ DoNotStrip \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ CoreComponentsRegistry . java \n + import com . facebook . jni . HybridData ; \n - import com . facebook . soloader . SoLoader ; \n + \n - SoLoader . loadLibrary ( "" fabricjni "" ) ; \n + FabricSoLoader . staticInit ( ) ; \n + @ DoNotStrip \n + private static native HybridData initHybrid ( ) ; \n + \n + @ DoNotStrip \n + @ DoNotStrip \n",Fix NoSuchMethodError in CoreComponentsRegistry class \n Summary : \n This diff fixes a NoSuchMethodError in CoreComponentsRegistry class . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D23043627 \n fbshipit - source - id : bd87ba560cc57ca345bf694b457be09097c433fe,133
"ReactAndroid \ build . gradle \n - ndk { \n - moduleName ( "" reactnativejni "" ) \n - } \n - \n",Remove ndk . moduleName from build . gradle \n Summary : \n This diff removes the ndk . moduleName configuration from build . gradle . This seems to be unnecessary \n The motivation is to reduce confusion and extra configuration that is not being used by the build system \n changelog : [ internal ] internal change to cleanup ndk configuration in gradle \n Reviewed By : fkgozali \n Differential Revision : D23068404 \n fbshipit - source - id : 07bb68906286531efaa9dc0036704c4b3ee1faf5,133
"RNTester \ android \ app \ build . gradle \n + * / / Enable Fabric at build time and runtime . \n + * enableFabric : true , \n + * \n + enableFabric : System . getenv ( "" USE _ FABRIC "" ) ? : false , \n + / * * \n + * Build and enable Fabric in RN Tester app . \n + * / \n + def enableFabric = project . ext . react . enableFabric \n + \n - fabric { \n - / / TODO T71370706 - Create a different dimension to build fabric \n - dimension "" vm "" \n - } \n + buildConfigField ( "" boolean "" , "" ENABLE _ FABRIC "" , "" $ enableFabric "" ) \n - fabricDebugImplementation { } \n - fabricReleaseImplementation { } \n - fabricDebugImplementation files ( hermesPath + "" hermes - debug . aar "" ) \n - fabricReleaseImplementation files ( hermesPath + "" hermes - release . aar "" ) \n RNTester \ android \ app \ src \ main \ java \ com \ facebook \ react \ uiapp \ RNTesterApplication . java \n - import static com . facebook . react . uiapp . BuildConfig . FLAVOR ; \n + import static com . facebook . react . uiapp . BuildConfig . ENABLE _ FABRIC ; \n - static final boolean IS _ FABRIC _ ENABLED = FLAVOR . contains ( "" fabric "" ) ; \n + static final boolean IS _ FABRIC _ ENABLED = ENABLE _ FABRIC ; \n","Replace ' Fabric ' flavor by environment variable \n Summary : \n This diff deletes the Fabric flavour from RNTester gradle configuration , replacing this by the ENV VAR : USE _ FABRIC \n - When USE _ FABRIC is set to "" true "" , gradle will build Fabric C + + code it will enable Fabric in RN Tester \n - When USE _ FABRIC is set to "" false "" , gradle WON ' T build Fabric C + + code it will disable Fabric in RN Tester \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D23085883 \n fbshipit - source - id : 2324f4a2cea4073b45b15805e69828d5dd70b365",133
"ReactAndroid \ build . gradle \n + / / The ' USE _ FABRIC ' environment variable will build Fabric C + + code into the bundle \n + / / USE _ FABRIC = false will build RN excluding fabric \n + / / USE _ FABRIC = true will build RN including fabric \n + def enableFabric = System . getenv ( "" USE _ FABRIC "" ) ? : "" false "" \n + \n + "" BUILD _ FABRIC = $ enableFabric "" , \n ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libreactnativeutilsjni libfolly _ json libfb libfbjni libglog _ init libyoga libfabricjni \n + LOCAL _ SHARED _ LIBRARIES : = libreactnativeutilsjni libfolly _ json libfb libfbjni libglog _ init libyoga \n - include $ ( REACT _ SRC _ DIR ) / fabric / jni / Android . mk \n + \n + ifeq ( $ ( BUILD _ FABRIC ) , true ) \n + include $ ( REACT _ SRC _ DIR ) / fabric / jni / Android . mk \n + endif \n",Exclude Fabric from RN OSS by default \n Summary : \n This diff adds a new mechanism to enable or disable the build of Fabric in RN OSS \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D23084586 \n fbshipit - source - id : b7b0b842486392ec4ccb91ad1e6441ba3a1f48b2,133
"ReactAndroid \ src \ main \ jni \ react \ jni \ Android . mk \n - LOCAL _ SHARED _ LIBRARIES : = libreactnativeutilsjni libfolly _ json libfb libfbjni libglog _ init libyoga libreact _ utils libreact _ render _ debug libreact _ render _ graphics libreact _ render _ core libreact _ render _ mapbuffer react _ render _ componentregistry libreact _ render _ components _ view libreact _ render _ components _ view libreact _ render _ components _ unimplementedview libreact _ render _ components _ root libreact _ render _ components _ scrollview libbetter libreact _ render _ attributedstring libreact _ render _ uimanager libreact _ render _ templateprocessor libreact _ render _ scheduler libreact _ render _ animations libreact _ render _ imagemanager libreact _ render _ textlayoutmanager libfabricjni \n + LOCAL _ SHARED _ LIBRARIES : = libreactnativeutilsjni libfolly _ json libfb libfbjni libglog _ init libyoga libfabricjni \n - # Fabric dependencies : \n - $ ( call import - module , react / utils ) \n - $ ( call import - module , react / renderer / animations ) \n - $ ( call import - module , react / renderer / attributedstring ) \n - $ ( call import - module , react / renderer / componentregistry ) \n - $ ( call import - module , react / renderer / core ) \n - $ ( call import - module , react / renderer / components / root ) \n - $ ( call import - module , react / renderer / components / scrollview ) \n - $ ( call import - module , react / renderer / components / unimplementedview ) \n - $ ( call import - module , react / renderer / components / view ) \n - $ ( call import - module , react / renderer / debug ) \n - $ ( call import - module , react / renderer / graphics ) \n - $ ( call import - module , react / renderer / imagemanager ) \n - $ ( call import - module , react / renderer / mapbuffer ) \n - $ ( call import - module , react / renderer / mounting ) \n - $ ( call import - module , react / renderer / scheduler ) \n - $ ( call import - module , react / renderer / templateprocessor ) \n - $ ( call import - module , react / renderer / textlayoutmanager ) \n - $ ( call import - module , react / renderer / uimanager ) \n - \n",Simplify reactnativejni Android . mk file \n Summary : \n This diff removes unnecessary shared library dependencies from reactnativejni module \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D23080052 \n fbshipit - source - id : b914a5a6d5d8d6ab93ee903820dbb779e6817312,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactRootView . java \n + import androidx . annotation . UiThread ; \n + @ UiThread \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricUIManager . java \n - Point viewportOffset = ReactRootView . getViewportOffset ( rootView ) ; \n + / / If startSurface is executed in the UIThread then , it uses the ViewportOffset from the View , \n + / / Otherwise Fabric relies on calling { @ link Binding # setConstraints } method to update the \n + / / ViewportOffset during measurement or onLayout . \n + @ SuppressLint ( "" WrongThread "" ) \n + Point viewportOffset = \n + UiThreadUtil . isOnUiThread ( ) ? ReactRootView . getViewportOffset ( rootView ) : new Point ( 0 , 0 ) ; \n",Fix race condition in FabricUIManager . StartSurface method \n Summary : \n This diff fixes a race condition in the execution of FabricUIManager . StartSurface method . \n The rootcause is that startSurface is executing getViewportOffset from a background thread . \n changelog : [ internal ] \n Reviewed By : shergin \n Differential Revision : D25617154 \n fbshipit - source - id : 9351201088164e74bb0b9454e30651e1de0da912,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ events \ EventDispatcherImpl . java \n - import java . util . List ; \n - private final List < BatchEventDispatchedListener > mPostEventDispatchListeners = new ArrayList < > ( ) ; \n + private final CopyOnWriteArrayList < BatchEventDispatchedListener > mPostEventDispatchListeners = \n + new CopyOnWriteArrayList < > ( ) ; \n,"Fix racecondition in registration of event listeners \n Summary : \n This diff fixes a racecondition in registration of event listeners . \n mPostEventDispatchListeners is accessed from different threads , most of the times this variable is used to executed the listeners . It is only written during initialization and turn down of the renderer . \n changelog : [ internal ] \n Reviewed By : PeteTheHeat \n Differential Revision : D25667988 \n fbshipit - source - id : 1bf95f5193d55a737bad9403206cc3320185b8cb",133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n + import androidx . annotation . NonNull ; \n - public String getName ( ) { \n + public @ NonNull String getName ( ) { \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ ViewManager . java \n - * @ param stateWrapper \n,Remove deleted parameter from javadoc \n Summary : \n ez javadoc \n changelog : [ internal ] \n Reviewed By : fkgozali \n Differential Revision : D25468185 \n fbshipit - source - id : bba614df552b3c8431e77aaa51a29e08fae5ea7f,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricJSIModuleProvider . java \n - import com . facebook . infer . annotation . Assertions ; \n - import com . facebook . react . uimanager . UIManagerModule ; \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n + @ NonNull private final ViewManagerRegistry mViewManagerRegistry ; \n - @ NonNull ReactNativeConfig config ) { \n + @ NonNull ReactNativeConfig config , \n + @ NonNull ViewManagerRegistry viewManagerRegistry ) { \n + mViewManagerRegistry = viewManagerRegistry ; \n - UIManagerModule nativeModule = \n - Assertions . assertNotNull ( mReactApplicationContext . getNativeModule ( UIManagerModule . class ) ) ; \n - EventDispatcher eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + EventDispatcher eventDispatcher = new EventDispatcherImpl ( mReactApplicationContext ) ; \n - mReactApplicationContext , \n - nativeModule . getViewManagerRegistry _ DO _ NOT _ USE ( ) , \n - eventDispatcher , \n - eventBeatManager ) ; \n + mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n packages \ rn - tester \ android \ app \ src \ main \ java \ com \ facebook \ react \ uiapp \ RNTesterApplication . java \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + final ReactInstanceManager reactInstanceManager = getReactInstanceManager ( ) ; \n + \n + ViewManagerRegistry viewManagerRegistry = \n + new ViewManagerRegistry ( \n + reactInstanceManager . getOrCreateViewManagers ( \n + reactApplicationContext ) ) ; \n + \n - } ) ; \n + } , \n + viewManagerRegistry ) ; \n",Refactor initialization of Fabric to avoid loading UIManagerModule \n Summary : \n This diff refactors the intialization of Fabric in order to avoid loading UIManagerModule as part of the creation of FabricJSIModuleProvider . \n One caveat is that now we are not taking into consideration the flag mLazyViewManagersEnabled \n https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / react - native - github / ReactAndroid / src / main / java / com / facebook / react / CoreModulesPackage . java ? commit = 4fb6c5ae79bb8e78e852a811128f03cf6fbed9aa & lines = 177 \n As a side effect of this diff view managers will be initialized twice if the user has fabric and paper enabled \n changelog : [ internal ] internal \n Reviewed By : shergin \n Differential Revision : D25468183 \n fbshipit - source - id : 78d8069007c5a98f9a6825eaa0c174603c8b9b4f,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ UIManager . java \n + import java . util . List ; \n + \n + / * * \n + * Helper method to pre - initialize view managers . When using Native ViewConfigs this method will \n + * also pre - compute the constants for a view manager . The purpose is to ensure that we don ' t block \n + * for getting the constants for view managers during initial rendering of a surface . \n + * \n + * @ deprecated this method will be removed in the future \n + * @ param viewManagerNames { @ link List < String > } names of ViewManagers \n + * / \n + @ Deprecated \n + void preInitializeViewManagers ( List < String > viewManagerNames ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricUIManager . java \n + @ Override \n + public void preInitializeViewManagers ( List < String > viewManagerNames ) { \n + for ( String viewManagerName : viewManagerNames ) { \n + mMountingManager . initializeViewManager ( viewManagerName ) ; \n + } \n + } \n + \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ mounting \ MountingManager . java \n + public void initializeViewManager ( String componentName ) { \n + mViewManagerRegistry . get ( componentName ) ; \n + } \n + \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n - * @ deprecated this method will not be available in FabricUIManager class . \n + * @ deprecated this method will be removed in the future \n - public void preComputeConstantsForViewManager ( List < String > viewManagerNames ) { \n - / / TODO T81145457 - Implement pre - initialization of ViewManagers in Fabric Android \n + @ Override \n + public void preInitializeViewManagers ( List < String > viewManagerNames ) { \n - preInitializeViewManagers ( viewManagerNames ) ; \n + for ( String viewManagerName : viewManagerNames ) { \n + mUIImplementation . resolveViewManager ( viewManagerName ) ; \n + } \n - private void preInitializeViewManagers ( List < String > viewManagerNames ) { \n - for ( String viewManagerName : viewManagerNames ) { \n - mUIImplementation . resolveViewManager ( viewManagerName ) ; \n - } \n - } \n - \n,Refactor preComputeConstantsForViewManager to avoid loading UIManagerModule in Fabric \n Summary : \n This method refactors the preComputeConstantsForViewManager to avoid loading UIManagerModule when using Fabric + Static View configs \n changelog : [ internal ] internal \n Reviewed By : shergin \n Differential Revision : D25468182 \n fbshipit - source - id : e95b0e7d013e832792fb77fc0b6e5705d7f04868,133
"ReactCommon \ react \ renderer \ mapbuffer \ BUCK \n - prefix = "" react "" , \n + prefix = "" react / renderer / mapbuffer "" , \n + react _ native _ xplat _ target ( "" react / renderer / mapbuffer : mapbuffer "" ) , \n ReactCommon \ react \ renderer \ mapbuffer \ MapBuffer . cpp \n + int MapBuffer : : getSize ( ) { \n + return 0 ; \n + } \n + \n ReactCommon \ react \ renderer \ mapbuffer \ MapBuffer . h \n + \n + int getSize ( ) ; \n ReactCommon \ react \ renderer \ mapbuffer \ tests \ MapBufferTest . cpp \n + # include < assert . h > \n + # include < react / renderer / mapbuffer / MapBuffer . h > \n - TEST ( MapBufferTest , testSomething ) { \n - / / TODO \n + using namespace facebook : : react ; \n + \n + / / Dummy test to create setup of tests \n + TEST ( MapBufferTest , testMapCreation ) { \n + auto buffer = MapBuffer ( ) ; \n + assert ( buffer . getSize ( ) = = 0 ) ; \n",Setup test infra into mapBuffer project \n Summary : \n Setup test infra into mapBuffer project \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25733949 \n fbshipit - source - id : bcfc89d87e28dc5a6ed28bc6b56893aa6f191e71,133
ReactAndroid \ src \ main \ jni \ react \ jni \ ReadableNativeMap . cpp \n - for ( auto & pair : pairs ) { \n - keys _ . value ( ) . push _ back ( pair . first . asString ( ) ) ; \n - } \n - jint size = keys _ . value ( ) . size ( ) ; \n + jint size = map _ . size ( ) ; \n - for ( jint ii = 0 ; ii < size ; ii + + ) { \n - ( * jarray ) [ ii ] = make _ jstring ( keys _ . value ( ) [ ii ] . getString ( ) ) ; \n + jint i = 0 ; \n + for ( auto & pair : pairs ) { \n + auto value = pair . first . asString ( ) ; \n + keys _ . value ( ) . push _ back ( value ) ; \n + ( * jarray ) [ i + + ] = make _ jstring ( value ) ; \n + \n,Micro - optimization in ReadableNativeMaps \n Summary : \n This is just a micro - optimization in ReadableNativeMaps . It wont change much in perf . . \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25733948 \n fbshipit - source - id : b01109acdf5b2eb532801469ef5cb845010c6ed0,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricJSIModuleProvider . java \n + import static com . facebook . react . config . ReactFeatureFlags . enableExperimentalStaticViewConfigs ; \n + \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n + @ NonNull private final ViewManagerRegistry mViewManagerRegistry ; \n - @ NonNull ReactNativeConfig config ) { \n + @ NonNull ReactNativeConfig config , \n + @ NonNull ViewManagerRegistry viewManagerRegistry ) { \n + mViewManagerRegistry = viewManagerRegistry ; \n - UIManagerModule nativeModule = \n - Assertions . assertNotNull ( mReactApplicationContext . getNativeModule ( UIManagerModule . class ) ) ; \n - EventDispatcher eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + EventDispatcher eventDispatcher = getEventDispatcher ( ) ; \n - mReactApplicationContext , \n - nativeModule . getViewManagerRegistry _ DO _ NOT _ USE ( ) , \n - eventDispatcher , \n - eventBeatManager ) ; \n + mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n + private EventDispatcher getEventDispatcher ( ) { \n + EventDispatcher eventDispatcher ; \n + if ( enableExperimentalStaticViewConfigs ) { \n + eventDispatcher = new EventDispatcherImpl ( mReactApplicationContext ) ; \n + } else { \n + UIManagerModule nativeModule = \n + Assertions . assertNotNull ( mReactApplicationContext . getNativeModule ( UIManagerModule . class ) ) ; \n + eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + } \n + return eventDispatcher ; \n + } \n + \n packages \ rn - tester \ android \ app \ src \ main \ java \ com \ facebook \ react \ uiapp \ RNTesterApplication . java \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + final ReactInstanceManager reactInstanceManager = getReactInstanceManager ( ) ; \n + \n + ViewManagerRegistry viewManagerRegistry = \n + new ViewManagerRegistry ( \n + reactInstanceManager . getOrCreateViewManagers ( \n + reactApplicationContext ) ) ; \n + \n - } ) ; \n + } , \n + viewManagerRegistry ) ; \n","Refactor initialization of Fabric to avoid loading UIManagerModule \n Summary : \n This diff refactors the intialization of Fabric in order to avoid loading UIManagerModule as part of the creation of FabricJSIModuleProvider . \n One caveat is that now we are not taking into consideration the flag mLazyViewManagersEnabled \n master / xplat / js / react - native - github / ReactAndroid / src / main / java / com / facebook / react / CoreModulesPackage . java177 \n if ( mLazyViewManagersEnabled ) { \n As a side effect of this diff view managers will be initialized twice if the user has fabric and paper enabled \n This diff was originally backed out in D25739854 ( https : / / github . com / facebook / react - native / commit / 4984c1e525e310f15c7d89230fdb2fa8fea91f05 ) because it produced a couple of bugs : \n https : / / fb . workplace . com / groups / rn . support / permalink / 4917641074951135 / \n https : / / fb . workplace . com / groups / rn . support / permalink / 4918163014898941 / \n These bugs are fixed by D25667987 ( https : / / github . com / facebook / react - native / commit / 2e631471092090e743245377742166ecae1d7e26 ) . \n This diff was reverted a couple of times because of the change in the registration of eventDispatcher . That ' s why I ' m gating that behavior change as part of the "" StaticViewConfig "" QE . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D25858934 \n fbshipit - source - id : a632799ccac728d4efca44ee685519713b4a7cbb",133
"Libraries \ Components \ RefreshControl \ AndroidSwipeRefreshLayoutNativeComponent . js \n - * \n - * This type isn ' t currently accurate . It really is specific numbers \n - * hard coded in the Android platform . \n - * \n - * Also , 1 isn ' t actually a safe default . We are able to set this here \n - * because native code isn ' t currently consuming the generated artifact . \n - * This will end up being \n - * size ? : WithDefault < ' default ' | ' large ' , ' default ' > , \n - size ? : WithDefault < Int32 , 1 > , \n + size ? : WithDefault < ' default ' | ' large ' , ' default ' > , \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ views \ swiperefresh \ SwipeRefreshLayoutManager . java \n - @ Override \n + @ Override \n + public void setSize ( ReactSwipeRefreshLayout view , String size ) { \n + if ( size = = null | | size . equals ( "" default "" ) ) { \n + view . setSize ( SwipeRefreshLayout . DEFAULT ) ; \n + } else if ( size . equals ( "" large "" ) ) { \n + view . setSize ( SwipeRefreshLayout . LARGE ) ; \n + } else { \n + throw new IllegalArgumentException ( "" Size must be ' default ' or ' large ' , received : "" + size ) ; \n + } \n + } \n + \n - final String sizeStr = size . asString ( ) ; \n - if ( sizeStr . equals ( "" default "" ) ) { \n - view . setSize ( SwipeRefreshLayout . DEFAULT ) ; \n - } else if ( sizeStr . equals ( "" large "" ) ) { \n - view . setSize ( SwipeRefreshLayout . LARGE ) ; \n - } else { \n - throw new IllegalArgumentException ( \n - "" Size must be ' default ' or ' large ' , received : "" + sizeStr ) ; \n - } \n + setSize ( view , size . asString ( ) ) ; \n","Change type of SwipeRefreshLayoutManager . size prop from Int to String \n Summary : \n This diff changes the type of the SwipeRefreshLayoutManager . size prop from Int to String in Fabric . \n The current implementation of this prop allows JS developers to use "" int "" type when fabric is enables and "" int or string "" types when using Fabric is disabled . \n Since long term we want to only support "" string "" type for this prop , I ' m changing the type of the prop to be String . \n After my diff Fabric will start supporting only "" string "" types , non fabric screens will keep supporting "" int or string "" values . \n * * Will this break production ? * * \n No , because there are no usages of RefreshControl . Size prop in fbsource \n * * What about if someone start using this prop next week ? * * \n IMO It ' s very unlikely because of the nature of this prop , I will be monitoring next week and if there ' s an usage it will be detected by flow when trying to land D25933457 . \n Changelog : [ Android ] [ Changed ] - RefreshControl . size prop changed its type to string , the valid values are : ' default ' and ' large ' \n Reviewed By : JoshuaGross \n Differential Revision : D25933458 \n fbshipit - source - id : 55067d7405b063f1e8d9bb7a5fd7731f5f168960",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerHelper . java \n - return getEventDispatcher ( context , getUIManagerType ( reactTag ) ) ; \n + EventDispatcher eventDispatcher = getEventDispatcher ( context , getUIManagerType ( reactTag ) ) ; \n + if ( eventDispatcher = = null ) { \n + ReactSoftException . logSoftException ( \n + "" UIManagerHelper "" , \n + new IllegalStateException ( "" Cannot get EventDispatcher for reactTag "" + reactTag ) ) ; \n + } \n + return eventDispatcher ; \n + ReactSoftException . logSoftException ( \n + "" UIManagerHelper "" , \n + new ReactNoCrashSoftException ( \n + "" Unable to find UIManager for UIManagerType "" + uiManagerType ) ) ; \n",Add logging to analyze Bug in BottomSheetRootViewGroup \n Summary : \n This diff adds logs and soft errors to analyze task T83470429 \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26032513 \n fbshipit - source - id : e6ee3f8a6ac942e794439396e1a9f7d6157d20a5,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n - int uiManagerType = ViewUtil . getUIManagerType ( tag ) ; \n - if ( uiManagerType = = FABRIC ) { \n - UIManager fabricUIManager = \n - UIManagerHelper . getUIManager ( getReactApplicationContext ( ) , uiManagerType ) ; \n - if ( fabricUIManager ! = null ) { \n - fabricUIManager . synchronouslyUpdateViewOnUIThread ( tag , props ) ; \n - } \n - } else { \n - mUIImplementation . synchronouslyUpdateViewOnUIThread ( tag , new ReactStylesDiffMap ( props ) ) ; \n - } \n + mUIImplementation . synchronouslyUpdateViewOnUIThread ( tag , new ReactStylesDiffMap ( props ) ) ; \n - int uiManagerType = ViewUtil . getUIManagerType ( tag ) ; \n - if ( uiManagerType = = FABRIC ) { \n - ReactApplicationContext reactApplicationContext = getReactApplicationContext ( ) ; \n - if ( reactApplicationContext . hasActiveCatalystInstance ( ) ) { \n - final UIManager fabricUIManager = \n - UIManagerHelper . getUIManager ( reactApplicationContext , uiManagerType ) ; \n - if ( fabricUIManager ! = null ) { \n - reactApplicationContext . runOnUiQueueThread ( \n - new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - fabricUIManager . synchronouslyUpdateViewOnUIThread ( tag , props ) ; \n - } \n - } ) ; \n - } \n - } \n - } else { \n - mUIImplementation . updateView ( tag , className , props ) ; \n - } \n + mUIImplementation . updateView ( tag , className , props ) ; \n","Remove usage of FabricUIManager Module related to NativeDriverAnimations \n Summary : \n This diff removes references to FabricUIManager from UIManagerModule , these callsited were originally used for NativeAnimatedDriver , but they are not used anymore \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross , shergin \n Differential Revision : D26035388 \n fbshipit - source - id : d4825af17f6948d922c42670f2c7b02498c12039",133
"Libraries \ Components \ RefreshControl \ AndroidSwipeRefreshLayoutNativeComponent . js \n - * Size of the refresh indicator , see RefreshControl . SIZE . \n + * Size of the refresh indicator . \n Libraries \ Components \ RefreshControl \ RefreshControl . js \n - let RefreshLayoutConsts : any ; \n - if ( Platform . OS = = = ' android ' ) { \n - const AndroidSwipeRefreshLayout = require ( ' . . / . . / ReactNative / UIManager ' ) . getViewManagerConfig ( \n - ' AndroidSwipeRefreshLayout ' , \n - ) ; \n - RefreshLayoutConsts = AndroidSwipeRefreshLayout \n - ? AndroidSwipeRefreshLayout . Constants \n - : { SIZE : { } } ; \n - } else { \n - RefreshLayoutConsts = { SIZE : { } } ; \n - } \n - \n - * Size of the refresh indicator , see RefreshControl . SIZE . \n + * Size of the refresh indicator . \n - size ? : ? ( \n - | typeof RefreshLayoutConsts . SIZE . DEFAULT \n - | typeof RefreshLayoutConsts . SIZE . LARGE \n - ) , \n + size ? : ? ( ' default ' | ' large ' ) , \n - static SIZE : any = RefreshLayoutConsts . SIZE ; \n - \n","Change flow types of RefreshControl . size prop \n Summary : \n This diff changes the flow types of RefreshControl . size prop from ' int ' to string ' . For more context see previous diff of the stack . \n This diff will be landed as soon as the native release containing D25933458 ( https : / / github . com / facebook / react - native / commit / 65975dd28de0a7b8b8c4eef6479bf7eee5fcfb93 ) goes to production . \n It ' s important to clarify that there are currently no usages of this prop in production \n Changelog : [ Android ] [ Changed ] - RefreshControl . size prop changed its type to string , the valid values are : ' default ' and ' large ' \n Reviewed By : JoshuaGross \n Differential Revision : D25933457 \n fbshipit - source - id : 2f34566f2f8a097e6d40f63c09ecb3ada2fd8409",133
Libraries \ Text \ TextNativeComponent . js \n - ! global . RN $ Bridgeless & & \n - UIManager . getViewManagerConfig ( ' RCTVirtualText ' ) = = null \n + ! global . RN $ Bridgeless & & ! UIManager . hasViewManagerConfig ( ' RCTVirtualText ' ) \n,"Avoid retrieving view configs on Text component \n Summary : \n This diff avoids retrieving view configs on Text component when static view configs are enabled \n changelog : [ interrnal ] \n Reviewed By : JoshuaGross , sammy - SC \n Differential Revision : D25577278 \n fbshipit - source - id : 674b8067cea13d284848e35dabaf26cd1bea4e27",133
"Libraries \ Components \ TextInput \ AndroidTextInputNativeComponent . js \n - const ReactNativeViewConfigRegistry = require ( ' . . / . . / Renderer / shims / ReactNativeViewConfigRegistry ' ) ; \n + import * as NativeComponentRegistry from ' . . / . . / NativeComponent / NativeComponentRegistry ' ; \n - let AndroidTextInputNativeComponent ; \n - if ( global . RN $ Bridgeless ) { \n - ReactNativeViewConfigRegistry . register ( ' AndroidTextInput ' , ( ) = > { \n - return AndroidTextInputViewConfig ; \n - } ) ; \n - AndroidTextInputNativeComponent = ' AndroidTextInput ' ; \n - } else { \n - AndroidTextInputNativeComponent = requireNativeComponent < NativeProps > ( \n - ' AndroidTextInput ' , \n - ) ; \n - } \n + let AndroidTextInputNativeComponent = NativeComponentRegistry . get < NativeProps > ( \n + ' AndroidTextInput ' , \n + ( ) = > AndroidTextInputViewConfig , \n + ) ; \n Libraries \ Components \ TextInput \ AndroidTextInputViewConfig . js \n - import { type ViewConfig } from ' . . / . . / Renderer / shims / ReactNativeTypes ' ; \n + import { type PartialViewConfig } from ' react - native / Libraries / Renderer / shims / ReactNativeTypes ' ; \n + adjustsFontSizeToFit : true , \n + minimumFontScale : true , \n + autoFocus : true , \n - color : true , \n + color : { process : require ( ' . . / . . / StyleSheet / processColor ' ) } , \n - module . exports = ( AndroidTextInputViewConfig : ViewConfig ) ; \n + module . exports = ( AndroidTextInputViewConfig : PartialViewConfig ) ; \n",Add supoprt for Text Input view configs \n Summary : \n This diff adds TextInput in the list of components that support static view configs \n changelog : [ internal ] \n Reviewed By : yungsters \n Differential Revision : D26040854 \n fbshipit - source - id : d6b5d3a78ef4657acf3f2c4ebe527ad4ca40bcb5,133
"Libraries \ ReactNative \ DummyUIManager . js \n + hasViewManagerConfig : ( viewManagerName : string ) : boolean = > { \n + return viewManagerName = = = ' RCTVirtualText ' ; \n + } , \n Libraries \ ReactNative \ PaperUIManager . js \n + hasViewManagerConfig ( viewManagerName : string ) : boolean { \n + return getViewManagerConfig ( viewManagerName ) ! = null ; \n + } , \n Libraries \ ReactNative \ UIManager . js \n + getViewManagerConfig : ( viewManagerName : string ) = > Object ; \n + + hasViewManagerConfig : ( viewManagerName : string ) = > boolean ; \n + createView : ( \n Libraries \ ReactNative \ UIManagerProperties . js \n + ' hasViewManagerConfig ' , \n Libraries \ Utilities \ deprecatedPropType . js \n - const UIManager = require ( ' . . / ReactNative / UIManager ' ) ; \n + import UIManager from ' . . / ReactNative / UIManager ' ; \n - ! UIManager . getViewManagerConfig ( componentName ) & & \n + UIManager . hasViewManagerConfig ( componentName ) & & \n jest \ setup . js \n + hasViewManagerConfig : jest . fn ( name = > { \n + return true ; \n + } ) , \n","Avoid the call to getViewManagerConfig on deprecatedPropType method \n Summary : \n This diff removes the call to UIManager . getViewManagerConfig into the deprecatedPropType method when static view configs are enabled \n This was necessary to avoid innecessary calls to UIManager . getViewManagerConfig and to avoid loading UIManagerModule classes when static view configs are enabled \n changelog : [ internal ] internal \n Reviewed By : fkgozali , yungsters \n Differential Revision : D26040855 \n fbshipit - source - id : 82cad9f4abe9898e781fd989ebaa03497dad926b",133
"Libraries \ ReactNative \ UIManager . js \n + import UIManagerInjection from ' . / UIManagerInjection ' ; \n - : require ( ' . / PaperUIManager ' ) ; \n + : UIManagerInjection . unstable _ UIManager = = null \n + ? require ( ' . / PaperUIManager ' ) \n + : UIManagerInjection . unstable _ UIManager ; \n new file \n Libraries \ ReactNative \ UIManagerInjection . js \n + / * * \n + * Copyright ( c ) Facebook , Inc . and its affiliates . \n + * \n + * This source code is licensed under the MIT license found in the \n + * LICENSE file in the root directory of this source tree . \n + * \n + * @ flow \n + * @ format \n + * / \n + \n + ' use strict ' ; \n + \n + export default { \n + unstable _ UIManager : ( null : ? any ) , \n + } ; \n",Refactor StaticViewConfigsPaperUIManager to avoid loading NativeUIManager . js \n Summary : \n This diff refactors the StaticViewConfigsPaperUIManager to avoid loading NativeUIManager . \n This is part of a experiment to prevent loading UIManagerModule class in native . \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25630215 \n fbshipit - source - id : 40d6f3b36ad4c3377820b1dcf0bd949db063d899,133
ReactAndroid \ build . gradle \n - compileSdkVersion 29 \n + compileSdkVersion 30 \n template \ android \ build . gradle \n - compileSdkVersion = 29 \n - targetSdkVersion = 29 \n + compileSdkVersion = 30 \n + targetSdkVersion = 30 \n,Bump Android compileSdkVersion and targetSdkVersion to 30 \n Summary : \n Bump Android compileSdkVersion and targetSdkVersion to 30 \n changelog : [ Android ] [ Changed ] Bump Android compileSdkVersion and targetSdkVersion from 29 to 30 \n Reviewed By : JoshuaGross \n Differential Revision : D26445966 \n fbshipit - source - id : 54c7b2dfff88cf2405fd66b3440a03f11de2304f,133
ReactAndroid \ build . gradle \n - compileSdkVersion 30 \n + compileSdkVersion 29 \n template \ android \ build . gradle \n - compileSdkVersion = 30 \n - targetSdkVersion = 30 \n + compileSdkVersion = 29 \n + targetSdkVersion = 29 \n,Revert D26445966 : Bump Android compileSdkVersion and targetSdkVersion to 30 \n Differential Revision : \n D26445966 ( https : / / github . com / facebook / react - native / commit / c7efd5b369aa7605a1017791440735ab72bc9fa8 ) \n Original commit changeset : 54c7b2dfff88 \n fbshipit - source - id : 91bf5564ed01f77d0837a090c941d65ad8d376a5,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactInstanceManager . java \n - if ( ReactFeatureFlags . enableStartSurfaceRaceConditionFix ) { \n - reactRoot . getState ( ) . compareAndSet ( ReactRoot . STATE _ STARTED , ReactRoot . STATE _ STOPPED ) ; \n - } \n + reactRoot . getState ( ) . compareAndSet ( ReactRoot . STATE _ STARTED , ReactRoot . STATE _ STOPPED ) ; \n - if ( ReactFeatureFlags . enableStartSurfaceRaceConditionFix ) { \n - if ( mAttachedReactRoots . add ( reactRoot ) ) { \n - clearReactRoot ( reactRoot ) ; \n - } \n - } else { \n - mAttachedReactRoots . add ( reactRoot ) ; \n + if ( mAttachedReactRoots . add ( reactRoot ) ) { \n - if ( ! ReactFeatureFlags . enableStartSurfaceRaceConditionFix \n - | | reactRoot . getState ( ) . compareAndSet ( ReactRoot . STATE _ STOPPED , ReactRoot . STATE _ STARTED ) ) { \n + if ( reactRoot . getState ( ) . compareAndSet ( ReactRoot . STATE _ STOPPED , ReactRoot . STATE _ STARTED ) ) { \n - if ( ! ReactFeatureFlags . enableStartSurfaceRaceConditionFix \n - | | reactRoot \n - . getState ( ) \n - . compareAndSet ( ReactRoot . STATE _ STOPPED , ReactRoot . STATE _ STARTED ) ) { \n + if ( reactRoot . getState ( ) . compareAndSet ( ReactRoot . STATE _ STOPPED , ReactRoot . STATE _ STARTED ) ) { \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ config \ ReactFeatureFlags . java \n - / * * \n - * Fixes race - condition in the initialization of RN surface . TODO T78832286 : remove this flag once \n - * we verify the fix is correct in production \n - * / \n - public static boolean enableStartSurfaceRaceConditionFix = false ; \n - \n","Release fix for race condition on startSurface \n Summary : \n This bug doesn ' t reproduce anymore in v301 + . MC has been enabled since december \n https : / / www . internalfb . com / intern / logview / details / facebook _ android _ javascripterrors / 419f8892e7b1a02f205810219ddfc299 / trends ? selected - logview - tab = All % 20Traces & drillstate = { % 22start % 22 : % 22Thu , % 2028 % 20Jan % 202021 % 2000 : 59 : 54 % 20 - 0800 % 22 , % 22end % 22 : % 22Thu , % 2011 % 20Feb % 202021 % 2000 : 59 : 54 % 20 - 0800 % 22 , % 22constraints % 22 : [ { % 22col % 22 : % 22mid % 22 , % 22op % 22 : % 22 = = % 22 , % 22vals % 22 : [ % 22419f8892e7b1a02f205810219ddfc299 % 22 ] } ] , % 22context % 22 : % 22facebook _ android _ javascripterrors % 22 , % 22metric % 22 : % 22count % 22 } \n changelog : [ internal ] internal \n Reviewed By : ShikaSD \n Differential Revision : D26398484 \n fbshipit - source - id : ca85ca211f1a38aa2691f150956a27c878d243bc",133
"Libraries \ ReactNative \ PaperUIManager . js \n - \n - if ( viewManagerConfigs [ viewManagerName ] = = = undefined ) { \n - console . warn ( \n - ' Error : Unable to find getConstantsForViewManager for viewManager : ' + \n - viewManagerName + \n - ' . ' , \n - ) ; \n - } \n - } else { \n - console . warn ( \n - ' Error : Unable to find viewManagerConfigs for viewManager : ' + \n - viewManagerName + \n - ' using lazyLoadView . ' , \n - ) ; \n","Remove log in PaperUIManager \n Summary : \n Removing log in PaperUIManager since this is logging warn messages for "" Text "" components \n changelog : [ internal ] internal \n Differential Revision : D26315745 \n fbshipit - source - id : 8871148b0fc1791e1723962f1f2477cd5e0c562d",133
"Libraries \ NativeComponent \ NativeComponentRegistry . js \n + \n + / * * \n + * Unstable API . Do not use ! \n + * \n + * This method returns if there is a StaticViewConfig registered for the \n + * component name received as a parameter . \n + * / \n + export function unstable _ hasStaticViewConfig ( name : string ) : boolean { \n + const { native } = getRuntimeConfig ? . ( name ) ? ? { \n + native : true , \n + } ; \n + return ! native ; \n + } \n","Fix rendering of Text and TextInlineViews in Fabric + StaticViewConfigs enabled \n Summary : \n This diff fixes the render of Text and TextInlineViews when using Fabric + StaticViewConfigs enabled \n Similar to Bridgeless mode , we want TextNativeComponent to render "" createReactNativeComponentClass ( ' RCTVirtualText . . . "" instead of NativeText . \n https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / react - native - github / Libraries / Text / TextNativeComponent . js ? commit = f044696a1a273dec1fac227898f5603682d4b19d & lines = 59 \n UIManager . hasViewManagerConfig returns false for all components when using StaticViewConfigs enabled . \n I ' m changing this method to return true when the component is supported by static view configs : \n https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / RKJSModules / EntryPoints / Fb4aBundle . js ? commit = 4661488cc6aab5078dc6b2afcbb0624e887346d5 & lines = 81 - 94 \n This is correct because hasViewManagerConfig is a new method that ' s used ONLY in two callsites : \n https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / react - native - github / Libraries / Text / TextNativeComponent . js ? lines = 59 \n https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / react - native - github / Libraries / Utilities / deprecatedPropType . js ? lines = 24 \n Although , this can fail if "" hasViewManagerConfig "" is started to be used as "" feature detection "" ( see next diffs of the stack ) \n I ' m open to other suggestions ( please comment in the diff \n My current plan is : \n - Land this diff ( or similar ) to unblock static view configs experiment next week \n - Include all codeGenNativeComponents into the list of static view configs \n - Migrate callsites of getViewManagerConfig ( ) - > hasNativeConfig ( ) ( only for components that have static view configs ) \n - Think / Discuss / Plan long term plan about feature detection \n changelog : [ internal ] internal \n Reviewed By : yungsters \n Differential Revision : D26427140 \n fbshipit - source - id : ce8bf00d6c9793ad17bdc65eb8476aaab63db066",133
ReactCommon \ react \ renderer \ textlayoutmanager \ TextMeasureCache . h \n - rhs . layoutConstraints . maximumSize . width ; \n + rhs . layoutConstraints . maximumSize . width & & \n + lhs . layoutConstraints . maximumSize . height = = \n + rhs . layoutConstraints . maximumSize . height ; \n,"Fix incorrect Height in Text components \n Summary : \n This diff fixes a bug in the calculation of layout for text components \n The rootcause of the bug is that fabric is not taking into consideration height constraints as part of the cache for text measurments . \n The title text was being measured with a specific height constraint ( 22px ) at the begining of the render , later there was a re - measure for the same Text component with a different height constraint , but fabric was reusing the result of the first calculation instead of re - measuring the text . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26676716 \n fbshipit - source - id : 3e769e0ca35b3e363b96d3a6d1626a091eaad908",133
". circleci \ config . yml \n - ANDROID _ HOME : "" C : \ \ Android \ \ android - sdk "" \n - ANDROID _ NDK : "" C : \ \ Android \ \ android - sdk \ \ ndk \ \ 20 . 1 . 5948944 "" \n - - ANDROID _ BUILD _ VERSION : 28 \n + - ANDROID _ BUILD _ VERSION : 30 \n - ANDROID _ TOOLS _ VERSION : 29 . 0 . 3 \n - GRADLE _ OPTS : - Dorg . gradle . daemon = false \n - NDK _ VERSION : 20 . 1 . 5948944 \n ReactAndroid \ build . gradle \n - compileSdkVersion 29 \n + compileSdkVersion 30 \n template \ android \ build . gradle \n - compileSdkVersion = 29 \n - targetSdkVersion = 29 \n + compileSdkVersion = 30 \n + targetSdkVersion = 30 \n",Bump Android compileSdkVersion and targetSdkVersion to 30 \n Summary : \n Bump Android compileSdkVersion and targetSdkVersion to 30 \n changelog : [ Android ] [ Changed ] Bump Android compileSdkVersion and targetSdkVersion from 29 to 30 \n Reviewed By : ShikaSD \n Differential Revision : D26470604 \n fbshipit - source - id : ffd490f6e547d16f9832ec46cf7bd2c0689aba96,133
". circleci \ config . yml \n - ANDROID _ HOME : "" C : \ \ Android \ \ android - sdk "" \n - ANDROID _ NDK : "" C : \ \ Android \ \ android - sdk \ \ ndk \ \ 20 . 1 . 5948944 "" \n - - ANDROID _ BUILD _ VERSION : 30 \n + - ANDROID _ BUILD _ VERSION : 28 \n - ANDROID _ TOOLS _ VERSION : 29 . 0 . 3 \n - GRADLE _ OPTS : - Dorg . gradle . daemon = false \n - NDK _ VERSION : 20 . 1 . 5948944 \n ReactAndroid \ build . gradle \n - compileSdkVersion 30 \n + compileSdkVersion 29 \n template \ android \ build . gradle \n - compileSdkVersion = 30 \n - targetSdkVersion = 30 \n + compileSdkVersion = 29 \n + targetSdkVersion = 29 \n",Revert D26470604 : Bump Android compileSdkVersion and targetSdkVersion to 30 \n Differential Revision : \n D26470604 ( https : / / github . com / facebook / react - native / commit / 55c8833817c3e9cf9882a712c8b9946a262df231 ) \n Original commit changeset : ffd490f6e547 \n fbshipit - source - id : 71926781696ab7b7fb2b109198a8d02c3286b05f,133
"ReactCommon \ react \ nativemodule \ core \ platform \ android \ ReactCommon \ JavaTurboModule . cpp \n - instance _ = instance _ , \n + instance _ = jni : : make _ weak ( instance _ ) , \n + auto instance = instance _ . lockLocal ( ) ; \n + if ( ! instance ) { \n + return ; \n + } \n - env - > CallVoidMethodA ( instance _ . get ( ) , methodID , jargs . data ( ) ) ; \n + env - > CallVoidMethodA ( instance . get ( ) , methodID , jargs . data ( ) ) ; \n - instance _ = instance _ , \n + instance _ = jni : : make _ weak ( instance _ ) , \n + auto instance = instance _ . lockLocal ( ) ; \n + \n + if ( ! instance ) { \n + return ; \n + } \n - env - > CallVoidMethodA ( instance _ . get ( ) , methodID , jargs . data ( ) ) ; \n + env - > CallVoidMethodA ( instance . get ( ) , methodID , jargs . data ( ) ) ; \n",Remove strong reference from TM infra \n Summary : \n This diff refactor strong references on TM infra to use weak references and avoid leaking objects \n changelog : [ internal ] internal \n Reviewed By : RSNara \n Differential Revision : D26229814 \n fbshipit - source - id : d4a327dba227378d23764433d5917eb4378a4453,133
"Libraries \ ReactNative \ PaperUIManager . js \n + \n + if ( viewManagerConfigs [ viewManagerName ] = = = undefined ) { \n + console . warn ( \n + ' Error : Unable to find getConstantsForViewManager for viewManager : ' + \n + viewManagerName + \n + ' . ' , \n + ) ; \n + } \n + } else { \n + console . warn ( \n + ' Error : Unable to find viewManagerConfigs for viewManager : ' + \n + viewManagerName + \n + ' using lazyLoadView . ' , \n + ) ; \n","Add logs in the getViewManagerConfig \n Summary : \n This diff adds error logs when the method getViewManagerConfig ( ) can ' t find a ViewConfig associated to a view manager \n changelog : [ inernal ] internal \n Reviewed By : JoshuaGross , ShikaSD \n Differential Revision : D26231245 \n fbshipit - source - id : d9252dcdcb84464d57342058a928881ebbb1b68c",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ mounting \ MountingManager . java \n - themedReactContext , propsDiffMap , stateWrapper , mJSResponderHandler ) ; \n + reactTag , themedReactContext , propsDiffMap , stateWrapper , mJSResponderHandler ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ NativeViewHierarchyManager . java \n - View view = viewManager . createView ( themedContext , null , null , mJSResponderHandler ) ; \n + View view = viewManager . createView ( tag , themedContext , null , null , mJSResponderHandler ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ ViewManager . java \n - / * * Creates a view and installs event emitters on it . * / \n - private final @ NonNull T createView ( \n - @ NonNull ThemedReactContext reactContext , JSResponderHandler jsResponderHandler ) { \n - return createView ( reactContext , null , null , jsResponderHandler ) ; \n - } \n - \n + int reactTag , \n - T view = createViewInstance ( reactContext , props , stateWrapper ) ; \n + T view = createViewInstance ( reactTag , reactContext , props , stateWrapper ) ; \n - * @ param reactContext \n + * @ param reactTag reactTag that should be set as ID of the view instance \n + * @ param reactContext ReactContext used to initialize view instance \n + * @ param initialProps initial props for the view instance \n + * @ param stateWrapper initial state for the view instance \n + int reactTag , \n + view . setId ( reactTag ) ; \n ReactAndroid \ src \ test \ java \ com \ facebook \ react \ uimanager \ SimpleViewPropertyTest . java \n + private static int sViewTag = 2 ; \n + \n - View view = mManager . createView ( mThemedContext , buildStyles ( ) , null , new JSResponderHandler ( ) ) ; \n + View view = \n + mManager . createView ( \n + sViewTag , mThemedContext , buildStyles ( ) , null , new JSResponderHandler ( ) ) ; \n - View view = mManager . createView ( mThemedContext , buildStyles ( ) , null , new JSResponderHandler ( ) ) ; \n + View view = \n + mManager . createView ( \n + sViewTag , mThemedContext , buildStyles ( ) , null , new JSResponderHandler ( ) ) ; \n","Refactor creation of views in Fabric Android \n Summary : \n This diff refactors the createViewInstance method in order to ensure that viewID is set before props are updated in the view . \n This is necessary because there are components that deliver events at the same time their props are set . This means that some components might not have their viewId set correctly when events are delivered . \n Since viewId is used to determine if a view belongs to Fabric or Paper , there are cases when the events are not delivered to the right renderer \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25667987 \n fbshipit - source - id : 4acfa8f80d66e9e59514354481957d7d3b571248",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricJSIModuleProvider . java \n - import com . facebook . infer . annotation . Assertions ; \n - import com . facebook . react . uimanager . UIManagerModule ; \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n + @ NonNull private final ViewManagerRegistry mViewManagerRegistry ; \n - @ NonNull ReactNativeConfig config ) { \n + @ NonNull ReactNativeConfig config , \n + @ NonNull ViewManagerRegistry viewManagerRegistry ) { \n + mViewManagerRegistry = viewManagerRegistry ; \n - UIManagerModule nativeModule = \n - Assertions . assertNotNull ( mReactApplicationContext . getNativeModule ( UIManagerModule . class ) ) ; \n - EventDispatcher eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + EventDispatcher eventDispatcher = new EventDispatcherImpl ( mReactApplicationContext ) ; \n - mReactApplicationContext , \n - nativeModule . getViewManagerRegistry _ DO _ NOT _ USE ( ) , \n - eventDispatcher , \n - eventBeatManager ) ; \n + mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n packages \ rn - tester \ android \ app \ src \ main \ java \ com \ facebook \ react \ uiapp \ RNTesterApplication . java \n + import com . facebook . react . uimanager . ViewManagerRegistry ; \n + final ReactInstanceManager reactInstanceManager = getReactInstanceManager ( ) ; \n + \n + ViewManagerRegistry viewManagerRegistry = \n + new ViewManagerRegistry ( \n + reactInstanceManager . getOrCreateViewManagers ( \n + reactApplicationContext ) ) ; \n + \n - } ) ; \n + } , \n + viewManagerRegistry ) ; \n",Refactor initialization of Fabric to avoid loading UIManagerModule \n Summary : \n This diff refactors the intialization of Fabric in order to avoid loading UIManagerModule as part of the creation of FabricJSIModuleProvider . \n One caveat is that now we are not taking into consideration the flag mLazyViewManagersEnabled \n ` ` ` \n master / xplat / js / react - native - github / ReactAndroid / src / main / java / com / facebook / react / CoreModulesPackage . java177 \n if ( mLazyViewManagersEnabled ) { \n ` ` ` \n As a side effect of this diff view managers will be initialized twice if the user has fabric and paper enabled \n This diff was originally backed out in D25739854 ( https : / / github . com / facebook / react - native / commit / 4984c1e525e310f15c7d89230fdb2fa8fea91f05 ) because it produced a couple of bugs : \n - https : / / fb . workplace . com / groups / rn . support / permalink / 4917641074951135 / \n - https : / / fb . workplace . com / groups / rn . support / permalink / 4918163014898941 / \n These bugs are fixed by D25667987 ( https : / / github . com / facebook / react - native / commit / 2e631471092090e743245377742166ecae1d7e26 ) . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D25746024 \n fbshipit - source - id : 3d12d29973a12b1edfea75f4dd954790f835e9bd,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricJSIModuleProvider . java \n + import com . facebook . infer . annotation . Assertions ; \n - import com . facebook . react . uimanager . ViewManagerRegistry ; \n + import com . facebook . react . uimanager . UIManagerModule ; \n - import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n - @ NonNull private final ViewManagerRegistry mViewManagerRegistry ; \n - @ NonNull ReactNativeConfig config , \n - @ NonNull ViewManagerRegistry viewManagerRegistry ) { \n + @ NonNull ReactNativeConfig config ) { \n - mViewManagerRegistry = viewManagerRegistry ; \n - EventDispatcher eventDispatcher = new EventDispatcherImpl ( mReactApplicationContext ) ; \n + UIManagerModule nativeModule = \n + Assertions . assertNotNull ( mReactApplicationContext . getNativeModule ( UIManagerModule . class ) ) ; \n + EventDispatcher eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n - mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n + mReactApplicationContext , \n + nativeModule . getViewManagerRegistry _ DO _ NOT _ USE ( ) , \n + eventDispatcher , \n + eventBeatManager ) ; \n packages \ rn - tester \ android \ app \ src \ main \ java \ com \ facebook \ react \ uiapp \ RNTesterApplication . java \n - import com . facebook . react . uimanager . ViewManagerRegistry ; \n - final ReactInstanceManager reactInstanceManager = getReactInstanceManager ( ) ; \n - \n - ViewManagerRegistry viewManagerRegistry = \n - new ViewManagerRegistry ( \n - reactInstanceManager . getOrCreateViewManagers ( \n - reactApplicationContext ) ) ; \n - \n - } , \n - viewManagerRegistry ) ; \n + } ) ; \n",Revert D25746024 : Refactor initialization of Fabric to avoid loading UIManagerModule \n Differential Revision : \n D25746024 ( https : / / github . com / facebook / react - native / commit / d3a3ce857ef5a54e7014e06af194b596ec18a03e ) \n Original commit changeset : 3d12d29973a1 \n fbshipit - source - id : 67a7f045e5c6b1bc0201ad58b569fc870c3a89f9,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ JSIModuleRegistry . java \n + import com . facebook . react . config . ReactFeatureFlags ; \n - mModules . clear ( ) ; \n + if ( ReactFeatureFlags . enableReactContextCleanupFix ) { \n + mModules . clear ( ) ; \n + } \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ NativeModuleRegistry . java \n + import com . facebook . react . config . ReactFeatureFlags ; \n - mModules . clear ( ) ; \n + if ( ReactFeatureFlags . enableReactContextCleanupFix ) { \n + mModules . clear ( ) ; \n + } \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ ReactContext . java \n + import com . facebook . react . config . ReactFeatureFlags ; \n + if ( ReactFeatureFlags . enableReactContextCleanupFix ) { \n + mLifecycleEventListeners . clear ( ) ; \n + mActivityEventListeners . clear ( ) ; \n + mWindowFocusEventListeners . clear ( ) ; \n + } \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ config \ ReactFeatureFlags . java \n + \n + / * * Enables a more aggressive cleanup during destruction of ReactContext * / \n + public static boolean enableReactContextCleanupFix = false ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n - getReactApplicationContext ( ) . removeLifecycleEventListener ( this ) ; \n - getReactApplicationContext ( ) . unregisterComponentCallbacks ( mMemoryTrimCallback ) ; \n + ReactApplicationContext reactApplicationContext = getReactApplicationContext ( ) ; \n + if ( ReactFeatureFlags . enableReactContextCleanupFix ) { \n + reactApplicationContext . removeLifecycleEventListener ( this ) ; \n + } \n + reactApplicationContext . unregisterComponentCallbacks ( mMemoryTrimCallback ) ; \n,Clean listeners during destroy of ReactContext \n Summary : \n This diff cleans listeners on the destruction of the ReactContext . \n changelog : [ inernal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26259929 \n fbshipit - source - id : 1843cabdac2fa3e67dcc890afd923b82472d8f66,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ JSIModuleRegistry . java \n + mModules . clear ( ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ bridge \ NativeModuleRegistry . java \n + mModules . clear ( ) ; \n,Clear internal maps of NativeModuleRegistry during turn down of the bridge \n Summary : \n This diff clears the internal maps of NativeModuleRegistry during turn down of the bridge . \n This is necessary for a proper cleanup of these modules . \n changelog : [ internal ] internal \n Reviewed By : ShikaSD \n Differential Revision : D26239303 \n fbshipit - source - id : 6e98e5db60a4f54d02e99b03339b03c17ecc183d,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerModule . java \n + getReactApplicationContext ( ) . removeLifecycleEventListener ( this ) ; \n,Unregister UIManagerModule from LifecycleEventListener \n Summary : \n This diff unregisters the UIManagerModule from LifecycleEventListener during turn down of the bridge . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26239156 \n fbshipit - source - id : b230949228c6e580cca088c395b970a3cff94839,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ ReactInstanceManager . java \n + if ( ReactFeatureFlags . enableExperimentalStaticViewConfigs ) { \n + catalystInstance . setGlobalVariable ( "" _ _ fbStaticViewConfig "" , "" true "" ) ; \n + } \n",Configure MC before the JS Bundle is loaded \n Summary : \n This diff setup a global variable to control the staticViewConfig experiment before the bundle is loaded . \n This global variable only has a meaning when RN uses a Bridge \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D26237670 \n fbshipit - source - id : 25ae63f36fba9c1e640ab2e70de88b71452ad8e6,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricJSIModuleProvider . java \n - import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n - EventDispatcher eventDispatcher = getEventDispatcher ( ) ; \n - FabricUIManager fabricUIManager = \n - new FabricUIManager ( \n - mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n - Systrace . endSection ( Systrace . TRACE _ TAG _ REACT _ JAVA _ BRIDGE ) ; \n - return fabricUIManager ; \n - } \n - \n - private EventDispatcher getEventDispatcher ( ) { \n - EventDispatcher eventDispatcher ; \n + FabricUIManager fabricUIManager ; \n - eventDispatcher = new EventDispatcherImpl ( mReactApplicationContext ) ; \n + fabricUIManager = \n + new FabricUIManager ( mReactApplicationContext , mViewManagerRegistry , eventBeatManager ) ; \n + / / TODO T83943316 : Remove this code once StaticViewConfigs are enabled by default \n - eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + EventDispatcher eventDispatcher = nativeModule . getEventDispatcher ( ) ; \n + fabricUIManager = \n + new FabricUIManager ( \n + mReactApplicationContext , mViewManagerRegistry , eventDispatcher , eventBeatManager ) ; \n - return eventDispatcher ; \n + Systrace . endSection ( Systrace . TRACE _ TAG _ REACT _ JAVA _ BRIDGE ) ; \n + return fabricUIManager ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ FabricUIManager . java \n + import com . facebook . react . uimanager . events . EventDispatcherImpl ; \n + / / TODO T83943316 : Delete this variable once StaticViewConfigs are enabled by default \n + private volatile boolean mShouldDeallocateEventDispatcher = false ; \n + \n + / / TODO T83943316 : Deprecate and delete this constructor once StaticViewConfigs are enabled by \n + / / default \n + mShouldDeallocateEventDispatcher = false ; \n + mEventBeatManager = eventBeatManager ; \n + mReactApplicationContext . addLifecycleEventListener ( this ) ; \n + } \n + \n + public FabricUIManager ( \n + ReactApplicationContext reactContext , \n + ViewManagerRegistry viewManagerRegistry , \n + EventBeatManager eventBeatManager ) { \n + mDispatchUIFrameCallback = new DispatchUIFrameCallback ( reactContext ) ; \n + mReactApplicationContext = reactContext ; \n + mMountingManager = new MountingManager ( viewManagerRegistry ) ; \n + mEventDispatcher = new EventDispatcherImpl ( reactContext ) ; \n + mShouldDeallocateEventDispatcher = true ; \n + \n + / / When using ReactFeatureFlags . enableExperimentalStaticViewConfigs enabled , FabriUIManager is \n + / / responsible for initializing and deallocating EventDispatcher . \n + / / TODO T83943316 : Remove this IF once StaticViewConfigs are enabled by default \n + if ( mShouldDeallocateEventDispatcher ) { \n + mEventDispatcher . onCatalystInstanceDestroyed ( ) ; \n + } \n",Deallocate EventDispatcher in FabricUIManager when StaticViewConfigs are enabled \n Summary : \n This diff refactor the initialization and deallocation of EventDispatcher in FabricUIManager when StaticViewConfigs are enabled . \n The goal of this diff is to make sure that the EventDispatcher is deallocated correctly when using StaticViewConfigs \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D26166413 \n fbshipit - source - id : e5bdad7ba923edc677c6b73f3a4d1271941f41cc,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ BUCK \n - "" - Wall "" , \n - "" - std = gnu + + 1y "" , \n + "" - std = c + + 14 "" , \n + "" - Wall "" , \n",Update C + + flags in Fabric Android \n Summary : \n Update C + + flags in Fabric Android \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26297398 \n fbshipit - source - id : d4603ee848abee98977ac9e21505547d9a867e21,133
ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ Binding . java \n - / / TODO ( T67721598 ) Remove the jsContext param once we ' ve migrated to using RuntimeExecutor \n,Remove out of date TODO \n Summary : \n Remove out of data TODO \n changelog : [ internal ] internal \n Reviewed By : PeteTheHeat \n Differential Revision : D26144400 \n fbshipit - source - id : c5a97ce98cd7251e40adc15c16fceed4b9c76f81,133
"ReactCommon \ react \ renderer \ components \ view \ YogaLayoutableShadowNode . cpp \n - LOG ( INFO ) < < "" RNYogaLogger "" < < buffer . data ( ) ; \n + LOG ( ERROR ) < < "" RNYogaLogger "" < < buffer . data ( ) ; \n",Increase severity for yoga logs \n Summary : \n This diff increases the severity for yoga logs to match all other logs in Fabric \n changelog : [ internal ] internal \n Differential Revision : D26315760 \n fbshipit - source - id : 1de3c23513ad8ce1630e3d0e3576f60608aac7de,133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ fabric \ jni \ Binding . cpp \n + # include < cfenv > \n + # include < cmath > \n + \n + static inline float scale ( Float value , Float pointScaleFactor ) { \n + std : : feclearexcept ( FE _ ALL _ EXCEPT ) ; \n + float result = value * pointScaleFactor ; \n + if ( std : : fetestexcept ( FE _ OVERFLOW ) ) { \n + LOG ( ERROR ) < < "" Binding : : scale - FE _ OVERFLOW - value : "" < < value \n + < < "" pointScaleFactor : "" < < pointScaleFactor \n + < < "" result : "" < < result ; \n + } \n + if ( std : : fetestexcept ( FE _ UNDERFLOW ) ) { \n + LOG ( ERROR ) < < "" Binding : : scale - FE _ UNDERFLOW - value : "" < < value \n + < < "" pointScaleFactor : "" < < pointScaleFactor \n + < < "" result : "" < < result ; \n + } \n + return result ; \n + } \n + \n - int left = floor ( contentInsets . left * pointScaleFactor ) ; \n - int top = floor ( contentInsets . top * pointScaleFactor ) ; \n - int right = floor ( contentInsets . right * pointScaleFactor ) ; \n - int bottom = floor ( contentInsets . bottom * pointScaleFactor ) ; \n + int left = floor ( scale ( contentInsets . left , pointScaleFactor ) ) ; \n + int top = floor ( scale ( contentInsets . top , pointScaleFactor ) ) ; \n + int right = floor ( scale ( contentInsets . right , pointScaleFactor ) ) ; \n + int bottom = floor ( scale ( contentInsets . bottom , pointScaleFactor ) ) ; \n - int x = round ( frame . origin . x * pointScaleFactor ) ; \n - int y = round ( frame . origin . y * pointScaleFactor ) ; \n - int w = round ( frame . size . width * pointScaleFactor ) ; \n - int h = round ( frame . size . height * pointScaleFactor ) ; \n + int x = round ( scale ( frame . origin . x , pointScaleFactor ) ) ; \n + int y = round ( scale ( frame . origin . y , pointScaleFactor ) ) ; \n + int w = round ( scale ( frame . size . width , pointScaleFactor ) ) ; \n + int h = round ( scale ( frame . size . height , pointScaleFactor ) ) ; \n","Add debug logs to check for overflow \n Summary : \n In this diff I ' m adding debug assertions to verify that there are no overflows when muptiplying layout metrics by the pointScaleFactor \n Ideally these should crash the app , but I ' m trying to be conservative . \n changelog : [ internal ] internal \n Reviewed By : JoshuaGross \n Differential Revision : D26297396 \n fbshipit - source - id : 068c60f4d89ea9cfd04a2e2174da2043ae150928",133
"ReactAndroid \ src \ main \ java \ com \ facebook \ react \ uimanager \ UIManagerHelper . java \n - return uiManager = = null ? null : ( EventDispatcher ) uiManager . getEventDispatcher ( ) ; \n + if ( uiManager = = null ) { \n + return null ; \n + } \n + EventDispatcher eventDispatcher = ( EventDispatcher ) uiManager . getEventDispatcher ( ) ; \n + if ( eventDispatcher = = null ) { \n + ReactSoftException . logSoftException ( \n + "" UIManagerHelper "" , \n + new IllegalStateException ( \n + "" Cannot get EventDispatcher for UIManagerType "" + uiManagerType ) ) ; \n + } \n + return eventDispatcher ; \n","Log SoftError when there is not EventDispatcher associated to UIManager \n Summary : \n This diff logs a SoftError when there is not EventDispatcher associated to UIManager \n The app will crash in Debug mode , this will not affect production users \n changelog : [ internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D25859546 \n fbshipit - source - id : 8045bcd67f613ea6286f30fe6f3c66113c700b0b",133
"packages \ rn - tester \ js \ RNTesterAppShared . js \n - const DisplayIfVisible = ( { isVisible , children } ) = > ( \n - < View style = { [ styles . container , ! isVisible & & styles . hidden ] } > \n - { children } \n - < / View > \n - ) ; \n + const DisplayIfVisible = ( { isVisible , children } ) = > \n + isVisible ? ( \n + < View style = { [ styles . container , ! isVisible & & styles . hidden ] } > \n + { children } \n + < / View > \n + ) : null ; \n",Prevent creating non visibile view in RNTester \n Summary : \n Small refactor to prevent creating non visibile view in RNTester \n changelog : [ internal ] internal \n Reviewed By : fkgozali \n Differential Revision : D25869868 \n fbshipit - source - id : 4873bf5f9de99612806df2d02adb73d21d3185db,133
"build . gradle \n - kotlin _ coroutines = ' 1 . 1 . 0 ' \n - materialVersion = ' 1 . 0 . 0 ' \n + kotlin _ coroutines _ version = ' 1 . 1 . 0 ' \n common \ build . gradle \n - api "" org . jetbrains . kotlinx : kotlinx - coroutines - core : $ kotlin _ coroutines "" \n - api "" org . jetbrains . kotlinx : kotlinx - coroutines - android : $ kotlin _ coroutines "" \n + api "" org . jetbrains . kotlinx : kotlinx - coroutines - core : $ kotlin _ coroutines _ version "" \n + api "" org . jetbrains . kotlinx : kotlinx - coroutines - android : $ kotlin _ coroutines _ version "" \n","Rename version variable to be consistent , remove unused materialVersion",145
"common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + \n + / / If playback is paused we remove the foreground state which allows the \n + / / notification to be dismissed . An alternative would be to provide a "" close "" \n + / / button in the notification which stops playback and clears the notification . \n + if ( playbackState = = Player . STATE _ READY ) { \n + if ( ! playWhenReady ) stopForeground ( false ) \n + } \n",Allow notification to be dismissed when playback is paused . Fixes # 360,145
build . gradle \n - glide _ version = ' 4 . 9 . 0 ' \n + glide _ version = ' 4 . 11 . 0 ' \n,Fix # 352 . Bump glide version to 4 . 11 . Fixes exif error on app startup,145
"common \ src \ main \ java \ com \ example \ android \ uamp \ common \ MusicServiceConnection . kt \n - nowPlaying . postValue ( metadata ? : NOTHING _ PLAYING ) \n + if ( metadata = = null | | \n + metadata . getString ( MediaMetadataCompat . METADATA _ KEY _ MEDIA _ ID ) = = null ) { \n + nowPlaying . postValue ( NOTHING _ PLAYING ) \n + } else { \n + nowPlaying . postValue ( metadata ) \n + } \n common \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ MediaMetadataCompatExt . kt \n + / / TODO : The fact that this method returns a String and not a String ? is convenient , however , it \n + / / masks a problem : getString ( METADATA _ KEY _ MEDIA _ ID ) can return null values . It may be better to \n + / / return a String ? here and have the caller handle null unless we can guarantee that \n + / / MediaMetadataCompat always has a value for METADATA _ KEY _ MEDIA _ ID . \n",Add check for null media id in the nowPlaying field . Fixes # 316 .,145
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ UampNotificationManager . kt \n - import kotlinx . coroutines . * \n + import kotlinx . coroutines . CoroutineScope \n + import kotlinx . coroutines . Dispatchers \n + import kotlinx . coroutines . SupervisorJob \n + import kotlinx . coroutines . launch \n + import kotlinx . coroutines . withContext \n,Stop Android Studio from using import . *,145
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n - import android . util . Log \n + private val playerListener = PlayerEventListener ( ) \n + \n - addListener ( PlayerEventListener ( ) ) \n + addListener ( playerListener ) \n + \n + / / Free ExoPlayer resources . \n + exoPlayer . removeListener ( playerListener ) \n + exoPlayer . release ( ) \n,Remove player listener and release ExoPlayer during destroy,145
"common \ src \ main \ java \ com \ example \ android \ uamp \ media \ PackageValidator . kt \n + import androidx . core . app . NotificationManagerCompat \n - * This last permission can be specifically granted to apps , and , in addition to \n - * allowing them to retrieve notifications , it also allows them to connect to an \n - * active [ MediaSessionCompat ] . \n - * As with the above , it ' s not required to allow apps holding this permission to \n - * connect to your [ MediaBrowserServiceCompat ] , but it does allow easy comparability \n + * If the calling app has a notification listener it is able to retrieve notifications \n + * and can connect to an active [ MediaSessionCompat ] . \n + * \n + * It ' s not required to allow apps with a notification listener to \n + * connect to your [ MediaBrowserServiceCompat ] , but it does allow easy compatibility \n - callerPackageInfo . permissions . contains ( BIND _ NOTIFICATION _ LISTENER _ SERVICE ) - > true \n - / / If none of the pervious checks succeeded , then the caller is unrecognized . \n + NotificationManagerCompat . getEnabledListenerPackages ( this . context ) \n + . contains ( callerPackageInfo . packageName ) - > true \n + \n + / / If none of the previous checks succeeded , then the caller is unrecognized . \n",Change to allow apps which have a notification listener to control UAMP . Fixes # 417,145
"app \ src \ main \ java \ com \ example \ android \ uamp \ cast \ UampCastOptionsProvider . kt \n - import com . google . android . gms . cast . CastMediaControlIntent . DEFAULT _ MEDIA _ RECEIVER _ APPLICATION _ ID \n + import com . google . android . exoplayer2 . ext . cast . DefaultCastOptionsProvider . APP _ ID _ DEFAULT _ RECEIVER _ WITH _ DRM \n - / / Use the Default Media Receiver . \n - / / See : https : / / developers . google . com / cast / docs / caf _ receiver # default _ media _ receiver . \n - / / If your content is DRM protected you can use the ExoPlayer default receiver app id \n - / / which has a value of "" A12D4273 "" \n - . setReceiverApplicationId ( DEFAULT _ MEDIA _ RECEIVER _ APPLICATION _ ID ) \n + / / Use the Default Media Receiver with DRM support . \n + . setReceiverApplicationId ( APP _ ID _ DEFAULT _ RECEIVER _ WITH _ DRM ) \n",Change to ExoPlayer ' s Default Media Reciever with DRM support,145
"common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n - * Create a CastPlayer to handle communication with a Cast session . \n + * If Cast is available , create a CastPlayer to handle communication with a Cast session . \n - private val castPlayer : CastPlayer by lazy { \n - CastPlayer ( CastContext . getSharedInstance ( this ) ) . apply { \n - setSessionAvailabilityListener ( UampCastSessionAvailabilityListener ( ) ) \n - addListener ( playerListener ) \n + private val castPlayer : CastPlayer ? by lazy { \n + try { \n + val castContext = CastContext . getSharedInstance ( this ) \n + CastPlayer ( castContext ) . apply { \n + setSessionAvailabilityListener ( UampCastSessionAvailabilityListener ( ) ) \n + addListener ( playerListener ) \n + } \n + } catch ( e : Exception ) { \n + / / We wouldn ' t normally catch the generic ` Exception ` however \n + / / calling ` CastContext . getSharedInstance ` can throw various exceptions , all of which \n + / / indicate that Cast is unavailable . \n + / / Related internal bug b / 68009560 . \n + Log . i ( TAG , "" Cast is not available on this device . "" + \n + "" Exception thrown when attempting to obtain CastContext . "" + e . message ) \n + null \n - newPlayer = if ( castPlayer . isCastSessionAvailable ) castPlayer else exoPlayer \n + newPlayer = if ( castPlayer ? . isCastSessionAvailable = = true ) castPlayer ! ! else exoPlayer \n - castPlayer . loadItems ( \n + castPlayer ! ! . loadItems ( \n - switchToPlayer ( currentPlayer , castPlayer ) \n + switchToPlayer ( currentPlayer , castPlayer ! ! ) \n",Make CastPlayer nullable for platforms which don ' t support Cast . Fixes # 412,145
"app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemAdapter . kt \n + . placeholder ( R . drawable . default _ art ) \n common \ src \ main \ java \ com \ example \ android \ uamp \ media \ library \ AlbumArtContentProvider . kt \n - import android . util . Log \n - import kotlinx . coroutines . Dispatchers \n - import kotlinx . coroutines . GlobalScope \n - import kotlinx . coroutines . launch \n - val file = File ( context . cacheDir , uri . path ) \n - return if ( ! file . exists ( ) ) { \n - GlobalScope . launch ( Dispatchers . IO ) { \n - / / Use Glide to download the album art \n - val cacheFile = Glide . with ( context ) \n - . asFile ( ) \n - . load ( remoteUri ) \n - . submit ( ) \n - . get ( ) \n - \n - / / Rename the file Glide created to match our own scheme . \n - cacheFile . renameTo ( file ) \n - \n - / / Notify the caller that the artwork has been updated . \n - context . contentResolver . notifyChange ( uri , null ) \n - } \n - \n - / / Provide placeholder art until the correct art can be downloaded . \n - context . assets . openFd ( "" default _ art . png "" ) . parcelFileDescriptor \n - } else { \n - ParcelFileDescriptor . open ( file , ParcelFileDescriptor . MODE _ READ _ ONLY ) \n + var file = File ( context . cacheDir , uri . path ) \n + \n + if ( ! file . exists ( ) ) { \n + / / Use Glide to download the album art . \n + val cacheFile = Glide . with ( context ) \n + . asFile ( ) \n + . load ( remoteUri ) \n + . submit ( ) \n + . get ( ) \n + \n + / / Rename the file Glide created to match our own scheme . \n + cacheFile . renameTo ( file ) \n + \n + file = cacheFile \n + return ParcelFileDescriptor . open ( file , ParcelFileDescriptor . MODE _ READ _ ONLY ) \n",Make ContentProvider block while downloading album art . Add placeholder image when downloading,145
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ library \ AlbumArtContentProvider . kt \n + / / The amount of time to wait for the album art file to download before timing out . \n + const val DOWNLOAD _ TIMEOUT _ SECONDS = 30L \n + \n - \n - const val DOWNLOAD _ TIMEOUT _ SECONDS = 30L \n,Move const to top of file and add comment,145
"modules \ core \ src \ retrofit \ core \ ErrorResponse . java \n - * @ param title a few words for a dialog title or heading , or null . \n - * @ param message a sentence or two with a more detailed , user friendly \n - * message , or null . \n + * @ param title a few words for a dialog title or heading , or null . \n + * @ param message a sentence or two with a more detailed , user friendly \n + * message , or null . \n + \n + @ Override public String toString ( ) { \n + return getClass ( ) . getSimpleName ( ) + "" [ "" \n + + "" title = "" + title \n + + "" , message = "" + message + "" ] "" ; \n + } \n",added toString ( ) to ErrorResponse . java,158
revision . properties \n - retrofit . revision = 0 . 1 - SNAPSHOT \n + retrofit . revision = 0 . 2 - SNAPSHOT \n,bumped revision to 0 . 2 - SNAPSHOT,158
"build . xml \n - The Retrofit version number , becomes part of the JAR file names . \n - - > \n - < property name = "" retrofit . revision "" value = "" 0 . 1 "" / > \n + < property file = "" revision . properties "" / > \n new file \n revision . properties \n + retrofit . revision = 0 . 1 - SNAPSHOT \n + \n",put the revision into a properties file ; included the SNAPSHOT tag,158
"modules \ io \ src - tests \ retrofit \ io \ TypedFileTest . java \n + import java . io . FileOutputStream ; \n + import java . io . IOException ; \n + \n + public void testLength ( ) throws IOException { \n + File tempFile = File . createTempFile ( "" foo "" , "" . tmp "" ) ; \n + try { \n + TypedFile typedFile = new TypedFile ( tempFile , MimeType . PNG ) ; \n + assertEquals ( "" length "" , 0 , typedFile . length ( ) ) ; \n + \n + writeToFile ( tempFile , new byte [ ] { 0 , 1 , 2 , 3 , 4 } ) ; \n + \n + assertEquals ( "" file length "" , 5 , tempFile . length ( ) ) ; \n + assertEquals ( "" typed file length "" , 5 , typedFile . length ( ) ) ; \n + \n + } finally { \n + / / noinspection ResultOfMethodCallIgnored \n + tempFile . delete ( ) ; \n + } \n + } \n + \n + private void writeToFile ( File file , byte [ ] data ) throws IOException { \n + FileOutputStream fos = new FileOutputStream ( file ) ; \n + try { \n + fos . write ( data ) ; \n + } finally { \n + fos . close ( ) ; \n + } \n + } \n modules \ io \ src \ retrofit \ io \ AbstractTypedBytes . java \n - private final int length ; \n - public AbstractTypedBytes ( MimeType mimeType , int length ) { \n - this . length = length ; \n + public AbstractTypedBytes ( MimeType mimeType ) { \n - public int length ( ) { \n - return length ; \n - } \n + / * * Returns the length in bytes . * / \n + public abstract int length ( ) ; \n modules \ io \ src \ retrofit \ io \ TypedByteArray . java \n - super ( mimeType , bytes . length ) ; \n + super ( mimeType ) ; \n + @ Override public int length ( ) { \n + return bytes . length ; \n + } \n + \n modules \ io \ src \ retrofit \ io \ TypedFile . java \n - super ( mimeType , ( int ) file . length ( ) ) ; \n + super ( mimeType ) ; \n + \n + @ Override public int length ( ) { \n + return ( int ) file . length ( ) ; \n + } \n",TypedFile gets its length from the underlying file now,158
revision . properties \n - retrofit . revision = 0 . 3 - SNAPSHOT \n + retrofit . revision = 0 . 4 - SNAPSHOT \n,bumped version from 0 . 3 - SNAPSHOT to 0 . 4 - SNAPSHOT,158
". idea \ inspectionProfiles \ Project _ Default . xml \n + < option name = "" IGNORE _ POINT _ TO _ ITSELF "" value = "" false "" / > \n . idea \ misc . xml \n + < component name = "" EntryPointsManager "" > \n + < entry _ points version = "" 2 . 0 "" / > \n + < / component > \n modules \ io \ src \ retrofit \ io \ ByteSinks . java \n - import java . io . OutputStream ; \n - final OutputStream out = new FileOutputStream ( file ) ; \n + final FileOutputStream out = new FileOutputStream ( file ) ; \n + out . getFD ( ) . sync ( ) ; \n modules \ io \ src \ retrofit \ io \ Files . java \n + out . getFD ( ) . sync ( ) ; \n",Ensure ByteSinks and Files use FileDescriptor . sync ( ),158
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ fragment \ UserListFragment . java \n - \n + this . rl _ progress . setVisibility ( View . VISIBLE ) ; \n + this . getActivity ( ) . setProgressBarIndeterminateVisibility ( true ) ; \n - \n + this . rl _ progress . setVisibility ( View . GONE ) ; \n + this . getActivity ( ) . setProgressBarIndeterminateVisibility ( false ) ; \n - \n + this . rl _ retry . setVisibility ( View . VISIBLE ) ; \n - \n + this . rl _ retry . setVisibility ( View . GONE ) ; \n,Added logic to show / hide loading and retry views .,165
"new file \n presentation \ src \ main \ res \ drawable \ selector _ item _ user . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < selector xmlns : android = "" http : / / schemas . android . com / apk / res / android "" > \n + < item android : drawable = "" @ android : color / holo _ blue _ light "" android : state _ focused = "" true "" / > \n + < item android : drawable = "" @ android : color / holo _ blue _ light "" android : state _ pressed = "" true "" / > \n + < item android : drawable = "" @ android : color / holo _ blue _ light "" android : state _ selected = "" true "" / > \n + < item android : drawable = "" @ android : color / background _ light "" / > \n + < / selector > \n presentation \ src \ main \ res \ layout \ fragment _ user _ list . xml \n - android : clickable = "" true "" \n - android : focusable = "" true "" \n - android : focusableInTouchMode = "" true "" \n presentation \ src \ main \ res \ layout \ row _ user . xml \n + android : background = "" @ drawable / selector _ item _ user "" \n",Add selector for user item in RecyclerView .,165
build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 0 . 0 - rc2 ' \n + classpath ' com . android . tools . build : gradle : 1 . 0 . 0 ' \n data \ build . gradle \n + versionCode 1 \n + } \n + \n + compileOptions { \n + sourceCompatibility JavaVersion . VERSION _ 1 _ 7 \n + targetCompatibility JavaVersion . VERSION _ 1 _ 7 \n domain \ build . gradle \n + sourceCompatibility = 1 . 7 \n + targetCompatibility = 1 . 7 \n + \n presentation \ build . gradle \n + compileOptions { \n + sourceCompatibility JavaVersion . VERSION _ 1 _ 7 \n + targetCompatibility JavaVersion . VERSION _ 1 _ 7 \n + } \n + \n,Add java 7 source and target compatibility .,165
"presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ adapter \ UsersAdapter . java \n - int count = 0 ; \n - if ( this . usersCollection ! = null & & ! this . usersCollection . isEmpty ( ) ) { \n - count = this . usersCollection . size ( ) ; \n - } \n - return count ; \n + return ( this . usersCollection ! = null ) ? this . usersCollection . size ( ) : 0 ; \n - throw new IllegalArgumentException ( "" The track list cannot be null "" ) ; \n + throw new IllegalArgumentException ( "" The list cannot be null "" ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ fragment \ UserListFragment . java \n - if ( this . rv _ users ! = null ) { \n - this . rv _ users . setLayoutManager ( usersLayoutManager ) ; \n - } \n + this . rv _ users . setLayoutManager ( usersLayoutManager ) ; \n - if ( this . userListPresenter ! = null ) { \n - this . userListPresenter . initialize ( ) ; \n - } \n + this . userListPresenter . initialize ( ) ; \n",Remove unnecessary defensive code . Minor refactor .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ activity \ UserListActivity . java \n - import com . fernandocejas . android10 . sample . presentation . navigation . Navigator ; \n - \n - this . initialize ( ) ; \n - \n - / * * \n - * Initializes activity ' s private members . \n - * / \n - private void initialize ( ) { \n - / / This initialization should be avoided by using a dependency injection framework . \n - / / But this is an example and for testing purpose . \n - this . navigator = new Navigator ( ) ; \n - } \n,Remove unused initialization code from user list activity .,165
data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ entity \ mapper \ UserEntityDataMapper . java \n - List < User > userList = new ArrayList < User > ( 20 ) ; \n + List < User > userList = new ArrayList < > ( 20 ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ mapper \ UserModelDataMapper . java \n - userModelsCollection = new ArrayList < UserModel > ( ) ; \n + userModelsCollection = new ArrayList < > ( ) ; \n,Get rid of unneeded type on data mappers .,165
data \ build . gradle \n + exclude ' LICENSE . txt ' \n,Exclude LICENSE . txt in packaging options .,165
"build . gradle \n + ext { \n + androidBuildToolsVersion = "" 21 . 1 . 2 "" \n + androidMinSdkVersion = 15 \n + androidTargetSdkVersion = 19 \n + androidCompileSdkVersion = 19 \n + androidApplicationId = ' com . fernandocejas . android10 . sample . presentation ' \n + androidVersionCode = 1 \n + androidVersionName = "" 1 . 0 "" \n + androidTestInstrumentationRunner = "" com . google . android . apps . common . testing . testrunner . GoogleInstrumentationTestRunner "" \n + } \n data \ build . gradle \n - compileSdkVersion 19 \n - buildToolsVersion ' 21 . 0 . 2 ' \n + def globalConfiguration = rootProject . extensions . getByName ( "" ext "" ) \n + \n + compileSdkVersion globalConfiguration . getAt ( "" androidCompileSdkVersion "" ) \n + buildToolsVersion globalConfiguration . getAt ( "" androidBuildToolsVersion "" ) \n - minSdkVersion 15 \n - targetSdkVersion 19 \n - versionCode 1 \n + minSdkVersion globalConfiguration . getAt ( "" androidMinSdkVersion "" ) \n + targetSdkVersion globalConfiguration . getAt ( "" androidTargetSdkVersion "" ) \n + versionCode globalConfiguration . getAt ( "" androidVersionCode "" ) \n presentation \ build . gradle \n - compileSdkVersion 19 \n - buildToolsVersion ' 21 . 0 . 2 ' \n + def globalConfiguration = rootProject . extensions . getByName ( "" ext "" ) \n + \n + compileSdkVersion globalConfiguration . getAt ( "" androidCompileSdkVersion "" ) \n + buildToolsVersion globalConfiguration . getAt ( "" androidBuildToolsVersion "" ) \n - applicationId "" com . fernandocejas . android10 . sample . presentation "" \n - minSdkVersion 15 \n - targetSdkVersion 19 \n - versionCode 1 \n - versionName "" 1 . 0 "" \n - testInstrumentationRunner "" com . google . android . apps . common . testing . testrunner . GoogleInstrumentationTestRunner "" \n + minSdkVersion globalConfiguration . getAt ( "" androidMinSdkVersion "" ) \n + targetSdkVersion globalConfiguration . getAt ( "" androidTargetSdkVersion "" ) \n + applicationId globalConfiguration . getAt ( "" androidApplicationId "" ) \n + versionCode globalConfiguration . getAt ( "" androidVersionCode "" ) \n + versionName globalConfiguration . getAt ( "" androidVersionName "" ) \n + testInstrumentationRunner globalConfiguration . getAt ( "" androidTestInstrumentationRunner "" ) \n",Add global variables for multi project configuration .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserDetailsPresenter . java \n + import javax . inject . Inject ; \n + import javax . inject . Singleton ; \n + @ Singleton \n + @ Inject \n,Add injectable constructor to user details presenter .,165
data \ build . gradle \n - compile ( ' com . google . code . gson : gson : 2 . 2 . 4 ' ) \n + compile ( ' com . google . code . gson : gson : 2 . 3 ' ) \n,Bump gson to version 2 . 3 on data layer .,165
"build . gradle \n - androidTestInstrumentationRunner = "" com . google . android . apps . common . testing . testrunner . GoogleInstrumentationTestRunner "" \n + testInstrumentationRunner = "" android . support . test . runner . AndroidJUnitRunner "" \n presentation \ build . gradle \n - testInstrumentationRunner globalConfiguration . getAt ( "" androidTestInstrumentationRunner "" ) \n + testInstrumentationRunner globalConfiguration . getAt ( "" testInstrumentationRunner "" ) \n - / / compile this only for testing . I had to use a workaround for using Espresso ( it is not in the \n - / / maven central repository ) : since both Mockito and Espresso use ' hamcrest ' I had to remove them \n - / / on the mockito library : "" zip - d mockito . jar org / hamcrest / * "" \n + / / Workaround for using Espresso since both Mockito and Espresso use ' hamcrest ' \n + / / I had to remove them on the mockito library : "" zip - d mockito . jar org / hamcrest / * "" \n + androidTestCompile ' com . android . support . test . espresso : espresso - core : 2 . 0 ' \n + androidTestCompile ' com . android . support . test : testing - support - lib : 0 . 1 ' \n presentation \ src \ androidTest \ java \ com \ fernandocejas \ android10 \ sample \ test \ view \ activity \ UserDetailsActivityTest . java \n - import static com . google . android . apps . common . testing . ui . espresso . Espresso . onView ; \n - import static com . google . android . apps . common . testing . ui . espresso . assertion . ViewAssertions . matches ; \n - import static com . google . android . apps . common . testing . ui . espresso . matcher . ViewMatchers . isDisplayed ; \n - import static com . google . android . apps . common . testing . ui . espresso . matcher . ViewMatchers . withId ; \n - import static com . google . android . apps . common . testing . ui . espresso . matcher . ViewMatchers . withText ; \n + import static android . support . test . espresso . Espresso . onView ; \n + import static android . support . test . espresso . assertion . ViewAssertions . matches ; \n + import static android . support . test . espresso . matcher . ViewMatchers . isDisplayed ; \n + import static android . support . test . espresso . matcher . ViewMatchers . withId ; \n + import static android . support . test . espresso . matcher . ViewMatchers . withText ; \n deleted file \n presentation \ testLibs \ espresso - 1 . 1 - bundled . jar \n Binary files a / presentation / testLibs / espresso - 1 . 1 - bundled . jar and / dev / null differ \n",Bump to espresso 2 . 0 . Fix failing tests .,165
"presentation \ build . gradle \n - / / Workaround for using Espresso since both Mockito and Espresso use ' hamcrest ' \n - / / I had to remove them on the mockito library : "" zip - d mockito . jar org / hamcrest / * "" \n - androidTestCompile fileTree ( dir : ' testLibs ' , include : ' * . jar ' ) \n + androidTestCompile ' org . mockito : mockito - core : 1 . 9 . 5 ' \n + androidTestCompile ' com . google . dexmaker : dexmaker : 1 . 0 ' \n + androidTestCompile ' com . google . dexmaker : dexmaker - mockito : 1 . 0 ' \n deleted file \n presentation \ testLibs \ dexmaker - 1 . 0 . jar \n Binary files a / presentation / testLibs / dexmaker - 1 . 0 . jar and / dev / null differ \n deleted file \n presentation \ testLibs \ dexmaker - mockito - 1 . 0 . jar \n Binary files a / presentation / testLibs / dexmaker - mockito - 1 . 0 . jar and / dev / null differ \n deleted file \n presentation \ testLibs \ mockito - all - 1 . 9 . 5 . jar \n Binary files a / presentation / testLibs / mockito - all - 1 . 9 . 5 . jar and / dev / null differ \n",Remove testing static libs and add dependencies on build . gradle file .,165
build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 0 . 0 ' \n + classpath ' com . android . tools . build : gradle : 1 . 0 . 1 ' \n,Bump android build tools to 1 . 0 . 1 .,165
new file \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ AndroidApplication . java \n + / * * \n + * Copyright ( C ) 2015 android10 . org . All rights reserved . \n + * @ author Fernando Cejas ( the android10 coder ) \n + * / \n + package com . fernandocejas . android10 . sample . presentation ; \n + \n + import android . app . Application ; \n + \n + / * * \n + * Android Main Application \n + * / \n + public class AndroidApplication extends Application { \n + \n + @ Override public void onCreate ( ) { \n + super . onCreate ( ) ; \n + } \n + } \n new file \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ PresentationModule . java \n + / * * \n + * Copyright ( C ) 2015 android10 . org . All rights reserved . \n + * @ author Fernando Cejas ( the android10 coder ) \n + * / \n + package com . fernandocejas . android10 . sample . presentation ; \n + \n + import dagger . Module ; \n + \n + / * * \n + * Dagger module that provides Presentation layer dependencies . \n + * / \n + @ Module \n + public class PresentationModule { \n + } \n,Add android application class and presentation module .,165
presentation \ build . gradle \n + provided ' org . glassfish : javax . annotation : 10 . 0 - b28 ' \n + \n,Added missing annotation dependency needed by dagger .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ AndroidApplication . java \n + private ApplicationComponent applicationComponent ; \n + \n + \n + this . applicationComponent = Dagger _ ApplicationComponent . builder ( ) \n + . applicationModule ( new ApplicationModule ( this ) ) \n + . build ( ) ; \n + this . applicationComponent . injectApplication ( this ) ; \n + } \n + \n + ApplicationComponent getApplicationComponent ( ) { \n + return applicationComponent ; \n new file \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ ApplicationComponent . java \n + / * * \n + * Copyright ( C ) 2015 android10 . org . All rights reserved . \n + * @ author Fernando Cejas ( the android10 coder ) \n + * / \n + package com . fernandocejas . android10 . sample . presentation ; \n + \n + import dagger . Component ; \n + \n + @ Component ( modules = ApplicationModule . class ) \n + interface ApplicationComponent { \n + AndroidApplication injectApplication ( AndroidApplication androidApplication ) ; \n + } \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ ApplicationModule . java \n + import android . app . Application ; \n + import dagger . Provides ; \n - * Dagger module that provides Presentation layer dependencies . \n + * Dagger module that provides objects which will live during the application lifecycle . \n + \n + private final Application application ; \n + \n + ApplicationModule ( Application application ) { \n + this . application = application ; \n + } \n + \n + @ Provides Application application ( ) { \n + return this . application ; \n + } \n,Add application component for dependency injection with dagger .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ AndroidApplication . java \n - this . applicationComponent . injectApplication ( this ) ; \n + this . applicationComponent . inject ( this ) ; \n - ApplicationComponent getApplicationComponent ( ) { \n + public ApplicationComponent getComponent ( ) { \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ ApplicationComponent . java \n - AndroidApplication injectApplication ( AndroidApplication androidApplication ) ; \n + AndroidApplication inject ( AndroidApplication androidApplication ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ ApplicationModule . java \n - public class ApplicationModule { \n + final class ApplicationModule { \n - @ Provides Application application ( ) { \n + @ Provides Application provideApplication ( ) { \n,Add application dependency injector component and module .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ modules \ ApplicationModule . java \n + import android . content . Context ; \n + import android . view . LayoutInflater ; \n - @ Provides Application provideApplication ( ) { \n + @ Provides Context provideApplicationContext ( ) { \n + \n + @ Provides LayoutInflater provideLayoutInflater ( ) { \n + return LayoutInflater . from ( this . application ) ; \n + } \n,Add provide context and layout inflater to Application Module .,165
build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 0 . 1 ' \n + classpath ' com . android . tools . build : gradle : 1 . 1 . 2 ' \n data - test \ build . gradle \n - testCompile files ( dataLayer . plugins . findPlugin ( ' com . android . library ' ) . getBootClasspath ( ) ) \n + testCompile files ( dataLayer . android . bootClasspath ) \n,Update latest android build tools . Fix broken robolectric tests .,165
build . gradle \n - androidTargetSdkVersion = 19 \n - androidCompileSdkVersion = 19 \n + androidTargetSdkVersion = 21 \n + androidCompileSdkVersion = 21 \n,Add compile version api level 21 Lollipop .,165
presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ HasComponent . java \n + / * * \n + * Interface representing a contract for clients that contains a component for dependency injection . \n + * / \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ components \ UserComponent . java \n + / * * \n + * A scope { @ link com . fernandocejas . android10 . sample . presentation . internal . di . PerActivity } component . \n + * Injects user specific Fragments . \n + * / \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ modules \ UserModule . java \n + / * * \n + * Dagger module that provides user related collaborators . \n + * / \n,Add documentation to dependency injection components and modules .,165
"build . gradle \n - task wrapper ( type : Wrapper ) { \n - description ' Creates the gradle wrapper . ' \n - gradleVersion ' 2 . 2 . 1 ' \n - } \n - \n + \n + task wrapper ( type : Wrapper ) { \n + description ' Creates the gradle wrapper . ' \n + gradleVersion ' 2 . 2 . 1 ' \n + } \n + \n + task runAcceptanceTests ( dependsOn : [ ' : presentation : connectedAndroidTest ' ] ) { \n + description ' Run application acceptance tests . ' \n + } \n + \n + task runUnitTests ( dependsOn : [ ' : domain : test ' , ' : data - test : test ' ] ) { \n + description ' Run unit tests for both domain and data layers . ' \n + } \n + \n",Add tasks for executing unit and acceptance tests .,165
"build . gradle \n + mavenCentral ( ) \n - classpath ' com . android . tools . build : gradle : 1 . 2 . 3 ' \n + classpath ' com . android . tools . build : gradle : 1 . 3 . 1 ' \n + classpath "" com . fernandocejas . frodo : frodo - plugin : 0 . 8 . 1 "" \n data \ build . gradle \n - repositories { \n - mavenCentral ( ) \n - } \n - \n + apply plugin : ' com . fernandocejas . frodo ' \n + defaultPublishConfig "" debug "" \n + \n data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ net \ RestApiImpl . java \n + import com . fernandocejas . frodo . annotation . RxLogObservable ; \n + @ RxLogObservable \n + @ RxLogObservable \n presentation \ build . gradle \n + apply plugin : ' com . fernandocejas . frodo ' \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserDetailsPresenter . java \n + import com . fernandocejas . frodo . annotation . RxLogSubscriber ; \n + @ RxLogSubscriber \n",Enable frodo on presentation and data layer .,165
data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ entity \ mapper \ UserEntityJsonMapper . java \n + import javax . inject . Inject ; \n + import javax . inject . Singleton ; \n + @ Singleton \n + @ Inject \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ modules \ ApplicationModule . java \n + import com . fernandocejas . android10 . sample . data . executor . JobExecutor ; \n + import com . fernandocejas . android10 . sample . domain . executor . PostExecutionThread ; \n + import com . fernandocejas . android10 . sample . domain . executor . ThreadExecutor ; \n + import com . fernandocejas . android10 . sample . presentation . UIThread ; \n + import javax . inject . Singleton ; \n - @ Provides Context provideApplicationContext ( ) { \n + @ Provides @ Singleton Context provideApplicationContext ( ) { \n - @ Provides LayoutInflater provideLayoutInflater ( ) { \n + @ Provides @ Singleton LayoutInflater provideLayoutInflater ( ) { \n + \n + @ Provides @ Singleton ThreadExecutor provideThreadExecutor ( JobExecutor jobExecutor ) { \n + return jobExecutor ; \n + } \n + \n + @ Provides @ Singleton PostExecutionThread providePostExecutionThread ( UIThread uiThread ) { \n + return uiThread ; \n + } \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ modules \ UserModule . java \n - import com . fernandocejas . android10 . sample . data . executor . JobExecutor ; \n - import com . fernandocejas . android10 . sample . domain . executor . PostExecutionThread ; \n - import com . fernandocejas . android10 . sample . domain . executor . ThreadExecutor ; \n - import com . fernandocejas . android10 . sample . presentation . UIThread ; \n - @ Provides @ Singleton ThreadExecutor provideThreadExecutor ( JobExecutor jobExecutor ) { \n - return jobExecutor ; \n - } \n - \n - @ Provides @ Singleton PostExecutionThread providePostExecutionThread ( UIThread uiThread ) { \n - return uiThread ; \n - } \n - \n,Refactor user module to include user related injections .,165
"build . gradle \n - classpath "" com . fernandocejas . frodo : frodo - plugin : 0 . 8 . 1 "" \n + classpath "" com . fernandocejas . frodo : frodo - plugin : 0 . 8 . 2 "" \n data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ net \ RestApiImpl . java \n + import static com . fernandocejas . frodo . annotation . RxLogObservable . Scope . SCHEDULERS ; \n + \n - @ RxLogObservable \n + @ RxLogObservable ( SCHEDULERS ) \n - @ RxLogObservable \n + @ RxLogObservable ( SCHEDULERS ) \n",Update frodo to version 0 . 8 . 2 .,165
buildsystem \ dependencies . gradle \n - rxJavaVersion = ' 1 . 0 . 9 ' \n + rxJavaVersion = ' 1 . 0 . 12 ' \n,Bump rxJava version to 1 . 0 . 12,165
build . gradle \n + testApplicationId = ' com . fernandocejas . android10 . sample . presentation . test ' \n - gradleVersion ' 2 . 2 . 1 ' \n + gradleVersion ' 2 . 4 ' \n gradle \ wrapper \ gradle - wrapper . jar \n Binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ \n gradle \ wrapper \ gradle - wrapper . properties \n - # Fri May 08 21 : 09 : 40 CEST 2015 \n + # Sun Jun 21 00 : 56 : 58 CEST 2015 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 2 . 1 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 4 - bin . zip \n,Bump gradle wrapper version to 2 . 4,165
"new file \n buildsystem \ debug . keystore \n Binary files / dev / null and b / buildsystem / debug . keystore differ \n domain \ build . gradle \n + / / noinspection GroovyUnusedAssignment \n + / / noinspection GroovyUnusedAssignment \n presentation \ build . gradle \n + testApplicationId globalConfiguration . getAt ( "" testApplicationId "" ) \n + \n + signingConfigs { \n + debug { \n + storeFile file ( ' . . / buildsystem / debug . keystore ' ) \n + storePassword ' android ' \n + keyAlias ' androiddebugkey ' \n + keyPassword ' android ' \n + } \n + } \n + \n + buildTypes { \n + debug { \n + signingConfig signingConfigs . debug \n + } \n + } \n",Attach debug . keystore and setup build . gradle to use this configuration .,165
"buildsystem \ dependencies . gradle \n - androidBuildToolsVersion = ' 22 . 0 . 1 ' \n + androidBuildToolsVersion = "" 21 . 1 . 2 "" \n","Revert "" Bump android build tool version . "" \n This reverts commit d26d47f438c90ce15e57a18f3793a1fd04202204 .",165
. travis . yml \n - android - 19 \n - . / gradlew build \n + . / gradlew build - x lint \n data \ build . gradle \n - abortOnError false ; \n + quiet true \n + abortOnError false \n + ignoreWarnings true \n presentation \ build . gradle \n - abortOnError false ; \n + quiet true \n + abortOnError false \n + ignoreWarnings true \n,Disable lint due to retrolambda bug when compiling lint tasks .,165
"build . gradle \n - apply from : ' buildsrc / dependencies . gradle ' \n + apply from : ' buildsystem / ci . gradle ' \n + apply from : ' buildsystem / dependencies . gradle ' \n new file \n buildsystem \ ci . gradle \n + def ciServer = ' TRAVIS ' \n + def executingOnCI = "" true "" . equals ( System . getenv ( ciServer ) ) \n + \n + / / Since for CI we always do full clean builds , we don ' t want to pre - dex \n + / / See http : / / tools . android . com / tech - docs / new - build - system / tips \n + subprojects { \n + project . plugins . whenPluginAdded { plugin - > \n + if ( ' com . android . build . gradle . AppPlugin ' . equals ( plugin . class . name ) | | \n + ' com . android . build . gradle . LibraryPlugin ' . equals ( plugin . class . name ) ) { \n + project . android . dexOptions . preDexLibraries = ! executingOnCI \n + } \n + } \n + } \n rename from buildsrc \ dependencies . gradle \n rename to buildsystem \ dependencies . gradle \n",Disable pre design on continuos integration environment . Minor refactor .,165
buildsystem \ dependencies . gradle \n - maven { url ' https : / / oss . sonatype . org / content / repositories / snapshots ' } \n - daggerVersion = ' 2 . 0 - SNAPSHOT ' \n + daggerVersion = ' 2 . 0 ' \n,Update dagger2 dependency to use stable version .,165
"buildsystem \ dependencies . gradle \n - javaxAnnotationVersion = ' 10 . 0 - b28 ' \n + javaxAnnotationVersion = ' 1 . 0 ' \n - javaxAnnotation : "" org . glassfish : javax . annotation : $ { javaxAnnotationVersion } "" , \n + javaxAnnotation : "" javax . annotation : jsr250 - api : $ { javaxAnnotationVersion } "" , \n - javaxAnnotation : "" org . glassfish : javax . annotation : $ { javaxAnnotationVersion } "" , \n + javaxAnnotation : "" javax . annotation : jsr250 - api : $ { javaxAnnotationVersion } "" , \n - javaxAnnotation : "" org . glassfish : javax . annotation : $ { javaxAnnotationVersion } "" , \n + javaxAnnotation : "" javax . annotation : jsr250 - api : $ { javaxAnnotationVersion } "" , \n",Use javax . annotation instead of org . glassfish ones .,165
buildsystem \ dependencies . gradle \n - rxAndroidVersion = ' 0 . 24 . 0 ' \n + rxAndroidVersion = ' 0 . 25 . 0 ' \n - okHttpVersion = ' 2 . 3 . 0 ' \n + okHttpVersion = ' 2 . 5 . 0 ' \n,Bump both rxAndroid and httpok to latest version,165
"build . gradle \n - gradleVersion ' 2 . 6 ' \n + gradleVersion ' 2 . 8 ' \n - task runDataUnitTests ( dependsOn : [ ' : data : cleanTestDebug ' , ' : data : testDebug ' ] ) { \n + task runDataUnitTests ( dependsOn : [ ' : data : cleanTestDebugUnitTest ' , ' : data : testDebugUnitTest ' ] ) { \n buildsystem \ dependencies . gradle \n - androidBuildToolsVersion = "" 21 . 1 . 2 "" \n + androidBuildToolsVersion = "" 23 . 0 . 1 "" \n - } \n + } \n gradle \ wrapper \ gradle - wrapper . jar \n Binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ \n gradle \ wrapper \ gradle - wrapper . properties \n - # Mon Aug 31 10 : 46 : 18 CEST 2015 \n + # Tue Nov 17 23 : 40 : 11 CET 2015 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 6 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 8 - bin . zip \n",Bump gradle and android build tools version . Fix data layer unit test task name .,165
buildsystem \ dependencies . gradle \n - recyclerViewVersion = ' 22 . 2 . 0 ' \n + recyclerViewVersion = ' 23 . 0 . 1 ' \n - androidAnnotationsVersion = ' 22 . 2 . 0 ' \n + androidAnnotationsVersion = ' 23 . 0 . 1 ' \n,Bump android libraries : RecyclerView and AndroidAnnotations .,165
buildsystem \ dependencies . gradle \n - recyclerViewVersion = ' 23 . 0 . 1 ' \n + recyclerViewVersion = ' 21 . 0 . 3 ' \n - androidAnnotationsVersion = ' 23 . 0 . 1 ' \n + androidAnnotationsVersion = ' 21 . 0 . 3 ' \n,Rollback dependencies bump due to CI server not finding them .,165
"domain \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserDetailsUseCaseImpl . java \n - if ( userRepository = = null | | threadExecutor = = null | | postExecutionThread = = null ) { \n - throw new IllegalArgumentException ( "" Constructor parameters cannot be null ! ! ! "" ) ; \n - } \n domain \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserListUseCaseImpl . java \n - if ( userRepository = = null | | threadExecutor = = null | | postExecutionThread = = null ) { \n - throw new IllegalArgumentException ( "" Constructor parameters cannot be null ! ! ! "" ) ; \n - } \n domain \ src \ test \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserDetailsUseCaseTest . java \n - \n - @ Test ( expected = IllegalArgumentException . class ) \n - public void testExecuteUserCaseNullParameter ( ) { \n - getUserDetailsUseCase . execute ( FAKE _ USER _ ID , null ) ; \n - } \n domain \ src \ test \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserListUseCaseTest . java \n - \n - @ Test ( expected = IllegalArgumentException . class ) \n - public void testExecuteUserListUseCaseNullParameter ( ) { \n - getUserListUseCase . execute ( null ) ; \n - } \n",Remove null checks in constructor . Get rid of unuseful tests .,165
"data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ cache \ FileManager . java \n - import java . io . FileNotFoundException ; \n - } catch ( FileNotFoundException e ) { \n - e . printStackTrace ( ) ; \n - } finally { \n - \n - } catch ( FileNotFoundException e ) { \n - e . printStackTrace ( ) ; \n - public void clearDirectory ( File directory ) { \n + public boolean clearDirectory ( File directory ) { \n + boolean result = false ; \n - file . delete ( ) ; \n + result = file . delete ( ) ; \n + return result ; \n data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ exception \ RepositoryErrorBundle . java \n + import com . fernandocejas . frodo . core . strings . Strings ; \n - String message = "" "" ; \n + String message = Strings . EMPTY ; \n - this . exception . getMessage ( ) ; \n + message = this . exception . getMessage ( ) ; \n",Collapse exceptions and assigned error Message on RepositoryErrorBundle class .,165
data \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ data \ net \ RestApiImpl . java \n - import static com . fernandocejas . frodo . annotation . RxLogObservable . Scope . SCHEDULERS ; \n - \n - @ RxLogObservable ( SCHEDULERS ) \n + @ RxLogObservable \n - @ RxLogObservable ( SCHEDULERS ) \n + @ RxLogObservable \n,Remove frodo annotation scope due to a bug with the library .,165
"build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 3 . 1 ' \n + classpath ' com . android . tools . build : gradle : 1 . 5 . 0 ' \n - gradleVersion ' 2 . 8 ' \n + gradleVersion ' 2 . 10 ' \n gradle \ wrapper \ gradle - wrapper . jar \n Binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ \n gradle \ wrapper \ gradle - wrapper . properties \n - # Tue Nov 17 23 : 40 : 11 CET 2015 \n + # Tue Jan 19 23 : 59 : 31 CET 2016 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 8 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 10 - bin . zip \n gradlew \n - # For Cygwin , ensure paths are in UNIX format before anything is touched . \n - if $ cygwin ; then \n - [ - n "" $ JAVA _ HOME "" ] & & JAVA _ HOME = ` cygpath - - unix "" $ JAVA _ HOME "" ` \n - fi \n - \n - cd "" ` dirname \ "" $ PRG \ "" ` / "" > & - \n + cd "" ` dirname \ "" $ PRG \ "" ` / "" > / dev / null \n - cd "" $ SAVED "" > & - \n + cd "" $ SAVED "" > / dev / null \n + JAVACMD = ` cygpath - - unix "" $ JAVACMD "" ` \n",Bump android build tools and gradle versions .,165
"presentation \ src \ androidTest \ java \ com \ fernandocejas \ android10 \ sample \ test \ presenter \ UserDetailsPresenterTest . java \n - given ( mockUserDetailsView . getContext ( ) ) . willReturn ( mockContext ) ; \n + given ( mockUserDetailsView . context ( ) ) . willReturn ( mockContext ) ; \n presentation \ src \ androidTest \ java \ com \ fernandocejas \ android10 \ sample \ test \ presenter \ UserListPresenterTest . java \n - given ( mockUserListView . getContext ( ) ) . willReturn ( mockContext ) ; \n + given ( mockUserListView . context ( ) ) . willReturn ( mockContext ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserDetailsPresenter . java \n - String errorMessage = ErrorMessageFactory . create ( this . viewDetailsView . getContext ( ) , \n + String errorMessage = ErrorMessageFactory . create ( this . viewDetailsView . context ( ) , \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserListPresenter . java \n - String errorMessage = ErrorMessageFactory . create ( this . viewListView . getContext ( ) , \n + String errorMessage = ErrorMessageFactory . create ( this . viewListView . context ( ) , \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ LoadDataView . java \n - Context getContext ( ) ; \n + Context context ( ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ fragment \ UserDetailsFragment . java \n - @ Override public Context getContext ( ) { \n + @ Override public Context context ( ) { \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ fragment \ UserListFragment . java \n - @ Override public Context getContext ( ) { \n + @ Override public Context context ( ) { \n",Rename context ( ) method due to existent similar one in android api 23 .,165
presentation \ build . gradle \n - debugCompile developmentDependencies . leakCanary \n + / / Development \n + compile developmentDependencies . leakCanary \n,Fix broken build due to leak canary .,165
presentation \ src \ androidTest \ java \ com \ fernandocejas \ android10 \ sample \ test \ presenter \ UserDetailsPresenterTest . java \n - userDetailsPresenter . initialize ( FAKE _ USER _ ID ) ; \n + userDetailsPresenter . initialize ( ) ; \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserDetailsPresenter . java \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - / * * id used to retrieve user details * / \n - private int userId ; \n - \n - public void initialize ( int userId ) { \n - this . userId = userId ; \n + public void initialize ( ) { \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ view \ fragment \ UserDetailsFragment . java \n - this . userDetailsPresenter . initialize ( this . userId ) ; \n + this . userDetailsPresenter . initialize ( ) ; \n - this . userDetailsPresenter . initialize ( this . userId ) ; \n + this . userDetailsPresenter . initialize ( ) ; \n,Remove unused userId injected by dependency injector through module creation .,165
"build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 5 . 0 ' \n + classpath ' com . android . tools . build : gradle : 2 . 1 . 0 ' \n - classpath "" com . fernandocejas . frodo : frodo - plugin : 0 . 8 . 1 "" \n + classpath "" com . fernandocejas . frodo : frodo - plugin : 0 . 8 . 3 "" \n - gradleVersion ' 2 . 10 ' \n + gradleVersion ' 2 . 12 ' \n",Bump Android build tools and frodo versions .,165
. travis . yml \n - - build - tools - 23 . 0 . 1 \n - - android - 21 \n + - tools \n + - platform - tools \n + - tools \n + - build - tools - 24 . 0 . 1 \n + - android - 23 \n + - extra - google - m2repository \n + - extra - android - m2repository \n + \n + licenses : \n + - ' android - sdk - preview - license - . + ' \n + - ' android - sdk - license - . + ' \n + - ' google - gdk - license - . + ' \n,Setup travis to run with build tools 24,165
"domain \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserDetails . java \n + public static final String NAME = "" userDetails "" ; \n + \n domain \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ domain \ interactor \ GetUserList . java \n + public static final String NAME = "" userList "" ; \n + \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ internal \ di \ modules \ UserModule . java \n - @ Provides @ PerActivity @ Named ( "" userList "" ) UseCase provideGetUserListUseCase ( \n + @ Provides @ PerActivity @ Named ( GetUserList . NAME ) UseCase provideGetUserListUseCase ( \n - @ Provides @ PerActivity @ Named ( "" userDetails "" ) UseCase provideGetUserDetailsUseCase ( \n + @ Provides @ PerActivity @ Named ( GetUserDetails . NAME ) UseCase provideGetUserDetailsUseCase ( \n - } \n + } \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserDetailsPresenter . java \n + import com . fernandocejas . android10 . sample . domain . interactor . GetUserDetails ; \n - public UserDetailsPresenter ( @ Named ( "" userDetails "" ) UseCase getUserDetailsUseCase , \n + public UserDetailsPresenter ( @ Named ( GetUserDetails . NAME ) UseCase getUserDetailsUseCase , \n presentation \ src \ main \ java \ com \ fernandocejas \ android10 \ sample \ presentation \ presenter \ UserListPresenter . java \n + import com . fernandocejas . android10 . sample . domain . interactor . GetUserList ; \n - public UserListPresenter ( @ Named ( "" userList "" ) UseCase getUserListUserCase , \n + public UserListPresenter ( @ Named ( GetUserList . NAME ) UseCase getUserListUserCase , \n",Refactor UserModule to use constant for injection rather than string literals .,165
"CHANGELOG . md \n + * Fixed "" Read - only file system "" exception when compacting Realm file on external storage ( # 4140 ) . \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmTests . java \n + @ Test \n + public void compactRealm _ onExternalStorage ( ) { \n + final File externalFilesDir = context . getExternalFilesDir ( null ) ; \n + final RealmConfiguration config = new RealmConfiguration . Builder ( ) \n + . directory ( externalFilesDir ) \n + . name ( "" external . realm "" ) \n + . build ( ) ; \n + Realm . deleteRealm ( config ) ; \n + Realm realm = Realm . getInstance ( config ) ; \n + realm . close ( ) ; \n + assertTrue ( Realm . compactRealm ( config ) ) ; \n + realm = Realm . getInstance ( config ) ; \n + realm . close ( ) ; \n + Realm . deleteRealm ( config ) ; \n + } \n + \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ internal _ SharedRealm . cpp \n + # include < realm / group _ shared _ options . hpp > \n - realm : : set _ temporary _ directory ( std : : string ( path ) ) ; / / throws \n + SharedGroupOptions : : set _ sys _ tmp _ dir ( std : : string ( path ) ) ; / / throws \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit 9a8520da95fc2505c1634d6d801f12ea73109cac \n + Subproject commit 48853a33f61447f8d4b502660c114e5bf7076a6f \n",Fix compacting on external storage \n Fix # 4140 . \n Update Object Store to 37a2ba42b .,174
realm \ realm - annotations - processor \ src \ main \ java \ io \ realm \ processor \ RealmProcessor . java \n - private int round ; \n + private int round = - 1 ; \n - RealmVersionChecker updateChecker = RealmVersionChecker . getInstance ( processingEnv ) ; \n - updateChecker . executeRealmVersionUpdate ( ) ; \n + RealmVersionChecker . getInstance ( processingEnv ) . executeRealmVersionUpdate ( ) ; \n,Resume sending update messages ( # 4419 ) \n Fixes # 4418,174
"realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ AuthTests . java \n + \n + / / verify that multiple users can be logged in at the same time \n + @ Test \n + public void multipleUsersCanBeLoggedInSimultaneously ( ) { \n + final String password = "" password "" ; \n + final SyncUser [ ] users = new SyncUser [ 3 ] ; \n + \n + for ( int i = 0 ; i < users . length ; i + + ) { \n + SyncCredentials credentials = SyncCredentials . usernamePassword ( UUID . randomUUID ( ) . toString ( ) , password , \n + true ) ; \n + users [ i ] = SyncUser . login ( credentials , Constants . AUTH _ URL ) ; \n + } \n + \n + for ( int i = 0 ; i < users . length ; i + + ) { \n + assertTrue ( users [ i ] . isValid ( ) ) ; \n + } \n + \n + for ( int i = 0 ; i < users . length ; i + + ) { \n + users [ i ] . logout ( ) ; \n + } \n + \n + for ( int i = 0 ; i < users . length ; i + + ) { \n + assertFalse ( users [ i ] . isValid ( ) ) ; \n + } \n + } \n + \n + / / verify that a single user can be logged out and back in . \n + @ Test \n + public void singleUserCanBeLoggedInAndOutRepeatedly ( ) { \n + final String username = UUID . randomUUID ( ) . toString ( ) ; \n + final String password = "" password "" ; \n + \n + / / register the user the first time \n + SyncCredentials credentials = SyncCredentials . usernamePassword ( username , password , true ) ; \n + \n + SyncUser user = SyncUser . login ( credentials , Constants . AUTH _ URL ) ; \n + assertTrue ( user . isValid ( ) ) ; \n + user . logout ( ) ; \n + assertFalse ( user . isValid ( ) ) ; \n + \n + / / on subsequent logins , the user is already registered . \n + credentials = credentials = SyncCredentials . usernamePassword ( username , password , false ) ; \n + for ( int i = 0 ; i < 3 ; i + + ) { \n + user = SyncUser . login ( credentials , Constants . AUTH _ URL ) ; \n + assertTrue ( user . isValid ( ) ) ; \n + user . logout ( ) ; \n + assertFalse ( user . isValid ( ) ) ; \n + } \n + } \n",Extend test to verify that logging out one user allows another to log in ( # 4893 ) \n * Add test to verify that multiple users can be logged in at the same time \n * Add test to verify that a user can be logged out and then logged back in again,174
"realm - transformer \ src \ main \ groovy \ io \ realm \ transformer \ RealmTransformer . groovy \n + def targetSdk = project ? . android ? . defaultConfig ? . targetSdkVersion ? . mApiLevel as String ; \n + def minSdk = project ? . android ? . defaultConfig ? . minSdkVersion ? . mApiLevel as String ; \n + \n - def analytics = new RealmAnalytics ( packages as Set , containsKotlin , sync ) \n + def analytics = new RealmAnalytics ( packages as Set , containsKotlin , sync , targetSdk , minSdk ) \n realm - transformer \ src \ main \ java \ io \ realm \ transformer \ RealmAnalytics . java \n + "" \ "" Realm Version \ "" : \ "" % REALM _ VERSION % \ "" , \ n "" \n + "" \ "" Host OS Type \ "" : \ "" % OS _ TYPE % \ "" , \ n "" \n + "" \ "" Host OS Version \ "" : \ "" % OS _ VERSION % \ "" , \ n "" \n - + "" \ "" Target OS Type \ "" : \ "" android \ "" \ n "" \n + + "" \ "" Target OS Type \ "" : \ "" android \ "" , \ n "" \n + + "" \ "" Target OS Version \ "" : \ "" % TARGET _ SDK % \ "" , \ n "" \n + + "" \ "" Target OS Minimum Version \ "" : \ "" % MIN _ SDK % \ "" \ n "" \n + "" } \ n "" \n + "" } "" ; \n + private String targetSdk ; \n + private String minSdk ; \n - public RealmAnalytics ( Set < String > packages , boolean usesKotlin , boolean usesSync ) { \n + public RealmAnalytics ( Set < String > packages , boolean usesKotlin , boolean usesSync , String targetSdk , String minSdk ) { \n + this . targetSdk = targetSdk ; \n + this . minSdk = minSdk ; \n - . replaceAll ( "" % OS _ VERSION % "" , System . getProperty ( "" os . version "" ) ) ; \n + . replaceAll ( "" % OS _ VERSION % "" , System . getProperty ( "" os . version "" ) ) \n + . replaceAll ( "" % TARGET _ SDK % "" , targetSdk ) \n + . replaceAll ( "" % MIN _ SDK % "" , minSdk ) ; \n",Add minVersion and targetVersion to metrics collected by the Realm Tranformer ( # 4143 ) \n Fixes # 206,174
"realm \ realm - annotations - processor \ src \ main \ java \ io \ realm \ processor \ RealmProcessor . java \n + import javax . annotation . processing . SupportedOptions ; \n + @ SupportedOptions ( value = { "" realm . suppressWarnings "" } ) \n + \n realm \ realm - annotations - processor \ src \ main \ java \ io \ realm \ processor \ RealmProxyClassGenerator . java \n + private static final String OPTION _ SUPPRESS _ WARNINGS = "" realm . suppressWarnings "" ; \n + private final boolean suppressWarnings ; \n + \n + / / See the configuration for the debug build type , \n + / / in the realm - library project , for an example of how to set this flag . \n + this . suppressWarnings = ! "" false "" . equalsIgnoreCase ( processingEnvironment . getOptions ( ) . get ( OPTION _ SUPPRESS _ WARNINGS ) ) ; \n - writer . beginType ( \n + if ( suppressWarnings ) { \n + writer . emitAnnotation ( "" SuppressWarnings ( \ "" all \ "" ) "" ) ; \n + } \n + writer \n + . beginType ( \n realm \ realm - annotations - processor \ src \ test \ resources \ io \ realm \ AllTypesRealmProxy . java \n + @ SuppressWarnings ( "" all "" ) \n realm \ realm - annotations - processor \ src \ test \ resources \ io \ realm \ BooleansRealmProxy . java \n + @ SuppressWarnings ( "" all "" ) \n realm \ realm - annotations - processor \ src \ test \ resources \ io \ realm \ NullTypesRealmProxy . java \n + @ SuppressWarnings ( "" all "" ) \n realm \ realm - annotations - processor \ src \ test \ resources \ io \ realm \ SimpleRealmProxy . java \n + @ SuppressWarnings ( "" all "" ) \n realm \ realm - library \ build . gradle \n + \n + buildTypes { \n + debug { \n + javaCompileOptions { \n + annotationProcessorOptions { \n + arguments + = [ ' realm . suppressWarnings ' : ' false ' ] \n + } \n + } \n + } \n + } \n",Suppress warnings in generated code . ( # 4779 ) \n * Suppress warnings in generated code . \n * Add compile time flag controlling the SuppressWarnings annotation on generated classes,174
"CHANGELOG . md \n + * Added support for new data type ` MutableRealmIntegers ` . The new type behaves almost exactly as a reference to a Long ( mutable nullable , etc ) but supports ` increment ` and ` decrement ` methods , which implement a Conflict Free Replicated Data Type , whose value will converge even when changed across distributed devices with poor connections . ( # 4266 ) \n",Add MutableRealmIntegers to the CHANGELOG . ( # 5033 ) \n * Add MutableRealmIntegers to the CHANGELOG .,174
"android \ PhysicalWeb \ app \ src \ main \ res \ values \ strings . xml \n - < string name = "" config _ searching _ for _ beacons _ text "" > Searching . . . < / string > \n + < string name = "" config _ searching _ for _ beacons _ text "" > Searching… < / string > \n - < string name = "" empty _ nearby _ devices _ list _ text "" > Searching . . . < / string > \n + < string name = "" empty _ nearby _ devices _ list _ text "" > Searching… < / string > \n","Replace "" . . . "" with ellipsis character .",181
"android \ PhysicalWeb \ app \ src \ main \ res \ layout \ list _ item _ nearby _ device . xml \n - android : layout _ width = "" fill _ parent "" \n + android : layout _ width = "" 0dp "" \n - android : layout _ weight = "" 1 "" > \n + android : layout _ weight = "" 11 "" > \n - android : layout _ width = "" match _ parent "" \n + android : layout _ width = "" 0dp "" \n - android : layout _ weight = "" 11 "" \n + android : layout _ weight = "" 1 "" \n",Changed layout _ width . No need to calculate the width if you ' re using weight . Also swapped weights to represent the correct weight .,181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ Device . java \n - initializeUrl ( ) ; \n - } \n - \n - private void initializeUrl ( ) { \n - if ( mUriBeacon = = null ) { \n - return ; \n - } \n,"Deleted initializeUrl method , which didn ' t really do anything .",181
"android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ BeaconConfigFragment . java \n - View view = inflater . inflate ( R . layout . fragment _ beacon _ config , container , false ) ; \n - return view ; \n + return inflater . inflate ( R . layout . fragment _ beacon _ config , container , false ) ; \n",No need no initialize the view before returning,181
"android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ UrlShortener . java \n - Urlshortener . Builder builder = new Urlshortener . Builder ( httpTransport , jsonFactory , null ) ; \n - builder . setApplicationName ( "" PhysicalWeb "" ) ; \n - builder . setUrlshortenerRequestInitializer ( urlshortenerRequestInitializer ) . build ( ) ; \n - Urlshortener urlshortener = builder . build ( ) ; \n + Urlshortener urlshortener = new Urlshortener . Builder ( httpTransport , jsonFactory , null ) \n + . setApplicationName ( "" PhysicalWeb "" ) \n + . setUrlshortenerRequestInitializer ( urlshortenerRequestInitializer ) \n + . build ( ) ; \n","build ( ) was being called twice . Instead of initializing the builder , it now declares and initializes the Urlshortener directly .",181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ NearbyDevicesFragment . java \n - @ Override \n - public void onCreate ( Bundle savedInstanceState ) { \n - super . onCreate ( savedInstanceState ) ; \n - } \n - \n,No need to override the onCreate if it only calls super . onCreate,181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ NearbyDevicesFragment . java \n - int txPowerLevel = uriBeacon . getTxPowerLevel ( ) ; \n + int txPowerLevel = uriBeacon . getTxPowerLevel ( ) ; \n,"Moved getTxPowerLevel ( ) inside if statement , else it would throw nullPointerException if uriBeacon was null",181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ UriBeaconDiscoveryService . java \n + unregisterReceiver ( mScreenStateBroadcastReceiver ) ; \n,Got rid of ' service leaked intent error ',181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ UriBeaconDiscoveryService . java \n - unregisterReceiver ( mScreenStateBroadcastReceiver ) ; \n + unregisterReceiver ( mScreenStateBroadcastReceiver ) ; \n,Fixed issue where the service would try to stop the scanner after the service had been unregistered,181
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - private ImageView mScanningImageView ; \n - mScanningImageView = ( ImageView ) rootView . findViewById ( R . id . imageView _ nearbyBeaconsScanning ) ; \n - mScanningImageView . setBackgroundResource ( R . drawable . scanning _ animation ) ; \n - mScanningAnimationDrawable = ( AnimationDrawable ) mScanningImageView . getBackground ( ) ; \n + TextView tv = ( TextView ) rootView . findViewById ( R . id . textView _ nearbyBeaconsScanning ) ; \n + / / Get the top drawable \n + mScanningAnimationDrawable = ( AnimationDrawable ) tv . getCompoundDrawables ( ) [ 1 ] ; \n android \ PhysicalWeb \ app \ src \ main \ res \ layout \ fragment _ nearby _ beacons . xml \n - < LinearLayout \n - android : orientation = "" vertical "" \n - android : layout _ width = "" match _ parent "" \n - android : layout _ height = "" match _ parent "" \n - android : id = "" @ android : id / empty "" \n - android : paddingLeft = "" 16dp "" \n - android : paddingRight = "" 16dp "" \n - android : paddingBottom = "" 100dp "" \n - android : gravity = "" center "" > \n - \n - < ImageView \n + < TextView \n - android : gravity = "" center "" \n - android : contentDescription = "" @ string / desc _ searching _ beacons "" \n - android : id = "" @ + id / imageView _ nearbyBeaconsScanning "" / > \n - \n - < TextView \n - android : layout _ width = "" match _ parent "" \n - android : layout _ height = "" wrap _ content "" \n - android : gravity = "" center _ horizontal "" \n - android : paddingTop = "" 16dp "" / > \n - \n - < / LinearLayout > \n + android : drawableTop = "" @ drawable / scanning _ animation "" \n + android : layout _ centerInParent = "" true "" \n + android : id = "" @ + id / textView _ nearbyBeaconsScanning "" android : gravity = "" center _ horizontal "" / > \n",Replaced the LinearLayout in Nearby Devices with a compound drawable,181
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ AboutFragment . java \n - private WebView mWebView ; \n - \n - mWebView = ( WebView ) getActivity ( ) . findViewById ( R . id . about _ webview ) ; \n - mWebView . getSettings ( ) . setJavaScriptEnabled ( true ) ; \n - mWebView . getSettings ( ) . setRenderPriority ( WebSettings . RenderPriority . HIGH ) ; \n - mWebView . setWebViewClient ( new WebViewClient ( ) ) ; \n - mWebView . loadUrl ( getString ( R . string . url _ getting _ started ) ) ; \n + WebView webView = ( WebView ) getActivity ( ) . findViewById ( R . id . about _ webview ) ; \n + webView . getSettings ( ) . setJavaScriptEnabled ( true ) ; \n + webView . getSettings ( ) . setRenderPriority ( WebSettings . RenderPriority . HIGH ) ; \n + webView . setWebViewClient ( new WebViewClient ( ) ) ; \n + webView . loadUrl ( getString ( R . string . url _ getting _ started ) ) ; \n,No need to make a class variable since it ' s never used outside a function,181
android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ BeaconConfigHelper . java \n - import android . os . Handler ; \n - private Handler mBackgroundHandler ; \n - mBackgroundHandler = new Handler ( ) ; \n,Removed ' Handler ' that was never used,181
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ NearbyBeaconsFragment . java \n - TextView tv = ( TextView ) rootView . findViewById ( R . id . textView _ nearbyBeaconsScanning ) ; \n + TextView tv = ( TextView ) rootView . findViewById ( android . R . id . empty ) ; \n android \ PhysicalWeb \ app \ src \ main \ res \ layout \ fragment _ nearby _ beacons . xml \n - android : id = "" @ + id / textView _ nearbyBeaconsScanning "" \n + android : id = "" @ id / android : empty "" \n",Fixed animation would show when list had only one item,181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ DeviceDiscoveryService . java \n - int scanMode = ScanSettings . SCAN _ MODE _ LOW _ POWER ; \n - \n - . setScanMode ( scanMode ) \n + . setScanMode ( ScanSettings . SCAN _ MODE _ LOW _ POWER ) \n,Deleted initialization of scan mode . Only used once so no need to make a new variable for it .,181
android \ PhysicalWeb \ app \ src \ main \ java \ physical _ web \ org \ physicalweb \ DeviceDiscoveryService . java \n - ScanFilter . Builder builder = new ScanFilter . Builder ( ) \n + ScanFilter filter = new ScanFilter . Builder ( ) \n - new byte [ ] { } ) ; \n - filters . add ( builder . build ( ) ) ; \n + new byte [ ] { } ) \n + . build ( ) ; \n + \n + filters . add ( filter ) ; \n,Initialize the filter directly instead of initializing the builder first .,181
"android \ PhysicalWeb \ app \ build . gradle \n - buildToolsVersion "" 21 . 0 . 2 "" \n + buildToolsVersion "" 21 . 1 . 2 "" \n - compile ' com . android . support : appcompat - v7 : 21 . 0 . 0 ' \n + compile ' com . android . support : appcompat - v7 : 21 . 0 . 3 ' \n android \ PhysicalWeb \ build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 0 . 0 - rc4 ' \n + classpath ' com . android . tools . build : gradle : 1 . 0 . 0 ' \n","Updated support library , gradle , and build tools",181
guava \ src \ com \ google \ common \ collect \ Streams . java \n - return boxedLast . isPresent ( ) ? OptionalInt . of ( boxedLast . get ( ) ) : OptionalInt . empty ( ) ; \n + return boxedLast . map ( OptionalInt : : of ) . orElseGet ( OptionalInt : : empty ) ; \n - return boxedLast . isPresent ( ) ? OptionalLong . of ( boxedLast . get ( ) ) : OptionalLong . empty ( ) ; \n + return boxedLast . map ( OptionalLong : : of ) . orElseGet ( OptionalLong : : empty ) ; \n - return boxedLast . isPresent ( ) ? OptionalDouble . of ( boxedLast . get ( ) ) : OptionalDouble . empty ( ) ; \n + return boxedLast . map ( OptionalDouble : : of ) . orElseGet ( OptionalDouble : : empty ) ; \n,Internal change \n RELNOTES = n / a \n PiperOrigin - RevId : 349578051,182
android \ pom . xml \n - < version > 3 . 0 . 0 - M2 < / version > \n + < version > 3 . 0 . 0 - M3 < / version > \n pom . xml \n - < version > 3 . 0 . 0 - M2 < / version > \n + < version > 3 . 0 . 0 - M3 < / version > \n,update enforcer - rule \n RELNOTES = n / a \n PiperOrigin - RevId : 360178627,182
android \ pom . xml \n - < version > 4 . 13 . 1 < / version > \n + < version > 4 . 13 . 2 < / version > \n pom . xml \n - < version > 4 . 13 . 1 < / version > \n + < version > 4 . 13 . 2 < / version > \n,update JUnit \n RELNOTES = n / a \n PiperOrigin - RevId : 360183244,182
android \ pom . xml \n - < version > 2 . 4 . 0 < / version > \n + < version > 2 . 5 . 1 < / version > \n pom . xml \n - < version > 2 . 4 . 0 < / version > \n + < version > 2 . 5 . 1 < / version > \n,This is causing upper bounds errors in google - http - java - client \n RELNOTES = update error prone annotations \n PiperOrigin - RevId : 358467773,182
"android \ guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - private static void log ( Throwable throwable ) { \n + private void log ( Throwable throwable ) { \n - : "" Got more than one input Future failure . Logging failures after the first "" ; \n + : "" An additional input failed after the first . Logging it after adding the first "" \n + + "" failure as a suppressed exception . "" ; \n guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - private static void log ( Throwable throwable ) { \n + private void log ( Throwable throwable ) { \n - : "" Got more than one input Future failure . Logging failures after the first "" ; \n + : "" An additional input failed after the first . Logging it after adding the first "" \n + + "" failure as a suppressed exception . "" ; \n",Internal change . \n RELNOTES = n / a \n PiperOrigin - RevId : 359800508,182
"android \ guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - private void log ( Throwable throwable ) { \n + private static void log ( Throwable throwable ) { \n - : "" An additional input failed after the first . Logging it after adding the first "" \n - + "" failure as a suppressed exception . "" ; \n + : "" Got more than one input Future failure . Logging failures after the first "" ; \n guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - private void log ( Throwable throwable ) { \n + private static void log ( Throwable throwable ) { \n - : "" An additional input failed after the first . Logging it after adding the first "" \n - + "" failure as a suppressed exception . "" ; \n + : "" Got more than one input Future failure . Logging failures after the first "" ; \n",Internal change . \n PiperOrigin - RevId : 359827899,182
"android \ guava \ src \ com \ google \ common \ collect \ ImmutableSortedMap . java \n - * Returns an immutable map containing the given entries , with keys sorted by the provided \n - * comparator . \n + * Returns an immutable map containing the given entries , with keys sorted by their natural \n + * ordering . \n guava \ src \ com \ google \ common \ collect \ ImmutableSortedMap . java \n - * Returns an immutable map containing the given entries , with keys sorted by the provided \n - * comparator . \n + * Returns an immutable map containing the given entries , with keys sorted by their natural \n + * ordering . \n","Fix a comment to reflect that the ImmutableSortedMap copyOf method uses the natural ordering of the keys , rather than a provided comparator . \n PiperOrigin - RevId : 350137044",182
"x - pack \ plugin \ transform \ src \ test \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ TransformIndexerStateTests . java \n + import org . elasticsearch . threadpool . ScalingExecutorBuilder ; \n + private String executorName ; \n - threadPool = new TestThreadPool ( ThreadPool . Names . GENERIC ) ; \n + / / we need "" generic "" as part of the name , because it is asserted \n + executorName = ThreadPool . Names . GENERIC + "" - "" + getTestName ( ) ; \n + threadPool = new TestThreadPool ( executorName , new ScalingExecutorBuilder ( executorName , 4 , 10 , TimeValue . timeValueSeconds ( 30 ) ) ) ; \n - ThreadPool . Names . GENERIC , \n + executorName , \n - ThreadPool . Names . GENERIC , \n + executorName , \n - ThreadPool . Names . GENERIC , \n + executorName , \n - ThreadPool . Names . GENERIC , \n + executorName , \n - ThreadPool . Names . GENERIC , \n + executorName , \n - ThreadPool . Names . GENERIC , \n + executorName , \n - threadPool . executor ( ThreadPool . Names . GENERIC ) . execute ( ( ) - > { \n + threadPool . executor ( executorName ) . execute ( ( ) - > { \n",[ Transform ] Use test threadpool to avoid conflict with other tests ( # 65721 ) \n use a test threadpool instead of the generic threadpool in test \n fixes # 65542,192
"x - pack \ plugin \ transform \ qa \ single - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ TransformUsageIT . java \n - / / temporary debug logs for https : / / github . com / elastic / elasticsearch / issues / 52931 \n - logger . info ( "" test _ usage / _ stats response : [ { } ] "" , stats ) ; \n - / / temporary debug logs for https : / / github . com / elastic / elasticsearch / issues / 52931 \n - logger . info ( "" test _ usage _ continuous / _ stats response : [ { } ] "" , stats ) ; \n - / / the trigger count can be higher if the scheduler kicked before usage has been called , therefore check for gte \n + / / the trigger count can be off : e . g . if the scheduler kicked in before usage has been called , \n + / / or if the scheduler triggered later , but state hasn ' t been persisted ( by design ) \n + / / however , we know that as we have 2 transforms , the trigger count must be greater or equal to 2 \n - greaterThanOrEqualTo ( expectedStats . get ( statName ) . doubleValue ( ) ) \n + greaterThanOrEqualTo ( 2 . 0 ) \n","[ Transform ] fix intermittent test _ usage failure ( # 65742 ) \n relax test for trigger count , it might have been incremented but not persisted \n fixes # 52931",192
"x - pack \ plugin \ transform \ src \ main \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ pivot \ TransformAggregations . java \n - WEIGHTED _ AVG ( "" weighted _ avg "" , DYNAMIC ) , \n + WEIGHTED _ AVG ( "" weighted _ avg "" , DOUBLE ) , \n x - pack \ plugin \ transform \ src \ test \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ pivot \ TransformAggregationsTests . java \n - assertEquals ( "" _ dynamic "" , TransformAggregations . resolveTargetMapping ( "" weighted _ avg "" , null ) ) ; \n - assertEquals ( "" _ dynamic "" , TransformAggregations . resolveTargetMapping ( "" weighted _ avg "" , "" double "" ) ) ; \n + assertEquals ( "" double "" , TransformAggregations . resolveTargetMapping ( "" weighted _ avg "" , null ) ) ; \n + assertEquals ( "" double "" , TransformAggregations . resolveTargetMapping ( "" weighted _ avg "" , "" double "" ) ) ; \n + assertEquals ( "" double "" , TransformAggregations . resolveTargetMapping ( "" weighted _ avg "" , "" int "" ) ) ; \n","[ Transform ] weighted avg should map to double ( # 64586 ) \n weighted avg like avg returns always a double value , this changes changes the output mapping from \n dynamic to double",192
"docs \ reference \ rest - api \ common - parms . asciidoc \n + * < < search - aggregations - metrics - median - absolute - deviation - aggregation , Median absolute deviation > > \n x - pack \ plugin \ transform \ qa \ single - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ TransformPivotRestIT . java \n + "" \ "" avg \ "" : { "" \n + "" \ "" field \ "" : \ "" stars \ "" "" \n + "" } } , "" \n + + "" \ "" variability _ rating \ "" : { "" \n + + "" \ "" median _ absolute _ deviation \ "" : { "" \n + + "" \ "" field \ "" : \ "" stars \ "" "" \n + + "" } } , "" \n + "" \ "" sum _ rating \ "" : { "" \n + "" \ "" sum \ "" : { "" \n + "" \ "" field \ "" : \ "" stars \ "" "" \n + actual = ( Number ) ( ( List < ? > ) XContentMapValues . extractValue ( "" hits . hits . _ source . variability _ rating "" , searchResult ) ) . get ( 0 ) ; \n + assertEquals ( 0 . 0 , actual . doubleValue ( ) , 0 . 000001 ) ; \n x - pack \ plugin \ transform \ src \ main \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ pivot \ TransformAggregations . java \n - "" median _ absolute _ deviation "" , \n + MEDIAN _ ABSOLUTE _ DEVIATION ( "" median _ absolute _ deviation "" , DOUBLE ) , \n x - pack \ plugin \ transform \ src \ test \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ pivot \ TransformAggregationsTests . java \n + / / median _ absolute _ deviation \n + assertEquals ( "" double "" , TransformAggregations . resolveTargetMapping ( "" median _ absolute _ deviation "" , "" int "" ) ) ; \n + assertEquals ( "" double "" , TransformAggregations . resolveTargetMapping ( "" median _ absolute _ deviation "" , "" double "" ) ) ; \n + \n",[ Transform ] add support for median absolute deviation ( # 64634 ) \n add median _ absolute _ deviation to the list of supported aggs in transform,192
"x - pack \ plugin \ transform \ qa \ single - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ continuous \ DateHistogramGroupByOtherTimeFieldIT . java \n - is ( lessThanOrEqualTo ( 1 ) ) \n + is ( lessThanOrEqualTo ( 2 ) ) \n x - pack \ plugin \ transform \ qa \ single - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ continuous \ TransformContinuousIT . java \n + import java . util . concurrent . TimeUnit ; \n - . format ( runDate . minusSeconds ( randomIntBetween ( 0 , 5 ) ) . plusNanos ( randomIntBetween ( 0 , 999999 ) ) ) ; \n + . format ( runDate . minusSeconds ( randomIntBetween ( 0 , 2 ) ) . plusNanos ( randomIntBetween ( 0 , 999999 ) ) ) ; \n - } ) ; \n + } , 20 , TimeUnit . SECONDS ) ; \n",[ Transform ] Improve DateHistogramGroupByOtherTimeFieldIT robustness ( # 64780 ) \n Increase the timeout when waiting for the next checkpoint . \n fixes # 64192,192
"x - pack \ plugin \ transform \ qa \ multi - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ TransformIT . java \n + String transformId = "" transform - crud "" ; \n - TransformConfig config = createTransformConfig ( "" transform - crud "" , groups , aggs , "" reviews - by - user - business - day "" , indexName ) ; \n + TransformConfig config = createTransformConfig ( transformId , groups , aggs , "" reviews - by - user - business - day "" , indexName ) ; \n + String transformId = "" transform - continuous - crud "" ; \n - "" transform - crud "" , \n + transformId , \n + String transformId = "" transform - continuous - crud - throttled "" ; \n + \n - "" transform - crud "" , \n + transformId , \n x - pack \ plugin \ transform \ qa \ multi - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ TransformIntegTestCase . java \n + long totalSleepTime = 0 ; \n - Thread . sleep ( 5 * ( 1 + totalRetries - retries ) ) ; \n + \n + / / wait between some ms max 5s , between a check , \n + / / with 10 retries the total retry should not be longer than 10s \n + final long sleepTime = 5 * Math . round ( ( Math . min ( Math . pow ( 2 , 1 + totalRetries - retries ) , 1000 ) ) ) ; \n + totalSleepTime + = sleepTime ; \n + Thread . sleep ( sleepTime ) ; \n - throw lastConflict ; \n + throw new AssertionError ( "" startTransformWithRetryOnConflict timed out after "" + totalSleepTime + "" ms "" , lastConflict ) ; \n","[ Transform ] Further increase the timeout and improve message for testStopWaitForCheckpoint ( # 64865 ) \n improve timeout when starting a transform with retry , improve transform \n ids in tests to avoid clashes in logs \n fixes # 63365",192
"x - pack \ plugin \ transform \ qa \ single - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ TransformUsageIT . java \n - "" Incorrect stat "" + statName , \n + "" Incorrect stat "" + statName + "" , got : "" + statsMap . get ( "" transform "" ) , \n - "" Incorrect stat "" + statName , \n + "" Incorrect stat "" + statName + "" , got : "" + statsMap . get ( "" transform "" ) , \n",[ Transform ] add more debug logging in testUsage IT ( # 65296 ) \n log the full usage response on failure ( individual counts are logged already ) \n relates # 52931,192
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 67779 "" / * place a PR link here when committing bwc changes * / \n",[ Transform ] disable BWC for backport of last _ search _ time ( # 67807 ) \n backport PR : # 67779,192
"build . gradle \n - boolean bwc _ tests _ enabled = false \n - String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 67779 "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = true \n + String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n x - pack \ plugin \ core \ src \ main \ java \ org \ elasticsearch \ xpack \ core \ transform \ transforms \ TransformCheckpointingInfo . java \n - if ( in . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { / / todo : V _ 7 _ 12 _ 0 \n + if ( in . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n - if ( out . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { / / todo : V _ 7 _ 12 _ 0 \n + if ( out . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n",[ Transform ] finalize backport of last _ search _ time ( # 67808 ) \n adjusts the version after the backport of # 66718 and re - enables BWC,192
"x - pack \ plugin \ src \ test \ resources \ rest - api - spec \ test \ transform \ transforms _ cat _ apis . yml \n - - - \n + - skip : \n + version : "" all "" \n + reason : "" Awaits fix : https : / / github . com / elastic / elasticsearch / issues / 68350 "" \n - do : \n","mute cat transform stats with batch transform yaml tests , tracked in # 68350",192
"test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ ESSingleNodeTestCase . java \n + import org . elasticsearch . test . rest . ESRestTestCase ; \n + ensureNoInitializingShards ( ) ; \n - \n + \n + / * * \n + * waits until all shard initialization is completed . \n + * \n + * inspired by { @ link ESRestTestCase } \n + * \n + * @ throws IOException \n + * / \n + protected void ensureNoInitializingShards ( ) throws IOException { \n + ClusterHealthResponse actionGet = client ( ) . admin ( ) \n + . cluster ( ) \n + . health ( Requests . clusterHealthRequest ( "" _ all "" ) . waitForNoInitializingShards ( true ) ) \n + . actionGet ( ) ; \n + \n + assertFalse ( "" timed out waiting for shards to initialize "" , actionGet . isTimedOut ( ) ) ; \n + } \n + \n","[ CI ] wait for initializing shards on teardown in ESSingleNodeTestCase ( # 69186 ) \n ensure shards aren ' t initializing at test teardown , so indexes that are initializing are not missed \n for deletion . \n fixes # 69057",192
"x - pack \ plugin \ transform \ src \ main \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ TransformIndexer . java \n + / * \n + * ignore if indexer thread is shutting down ( after finishing a checkpoint ) \n + * shutting down means : \n + * - indexer has finished a checkpoint and called onFinish \n + * - indexer state has changed from indexing to started \n + * - state persistence has been called but has _ not _ returned yet \n + * \n + * If we trigger the indexer in this situation the 2nd indexer thread might \n + * try to save state at the same time , causing a version conflict \n + * see gh # 67121 \n + * / \n + if ( indexerThreadShuttingDown ) { \n + logger . debug ( "" [ { } ] indexer thread is shutting down . Ignoring trigger . "" , getJobId ( ) ) ; \n + return false ; \n + } \n + \n","[ Transfrom ] prevent concurrent state persistence when indexer gets triggered during shutdown ( # 69551 ) \n the latest state , during the 2 stages a new run might get triggered and \n run into a race condition where a new state persists runs while the old \n has not finished yet . This change prevents the trigger if the indexer is \n in the described intermediate state \n fixes # 67121",192
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 68814 "" / * place a PR link here when committing bwc changes * / \n",[ Transform ] disable BWC for backport of # 68814 ( # 68883 ) \n disable BWC for the purpose of backporting # 68814,192
"x - pack \ plugin \ transform \ src \ test \ java \ org \ elasticsearch \ xpack \ transform \ transforms \ TransformIndexerTests . java \n + import static org . hamcrest . Matchers . oneOf ; \n - assertEquals ( indexer . getState ( ) , IndexerState . INDEXING ) ; \n + assertThat ( indexer . getState ( ) , oneOf ( IndexerState . INDEXING , IndexerState . STARTED ) ) ; \n",[ Transform ] make testRetentionPolicyExecution more robust ( # 68887 ) \n relax test of the state in case the indexer threads runs quicker than expected .,192
media \ java \ android \ media \ tv \ tuner \ Tuner . java \n + releaseAll ( ) ; \n - releaseAll ( ) ; \n,Change resource claim to sync to avoid resource conflict \n bug : 174544018 \n Test : manual \n Change - Id : Ib2688da2a85cdad896f9f2814828ce7659c8a695 \n Merged - In : Ib2688da2a85cdad896f9f2814828ce7659c8a695,196
"media \ java \ android \ media \ tv \ tuner \ Tuner . java \n + import java . lang . ref . WeakReference ; \n - private Map < Integer , Descrambler > mDescramblers = new HashMap < > ( ) ; \n - private List < Filter > mFilters = new ArrayList < > ( ) ; \n + private Map < Integer , WeakReference < Descrambler > > mDescramblers = new HashMap < > ( ) ; \n + private List < WeakReference < Filter > > mFilters = new ArrayList < WeakReference < Filter > > ( ) ; \n - if ( ! mDescramblers . isEmpty ( ) ) { \n - for ( Map . Entry < Integer , Descrambler > d : mDescramblers . entrySet ( ) ) { \n - d . getValue ( ) . close ( ) ; \n - mTunerResourceManager . releaseDescrambler ( d . getKey ( ) , mClientId ) ; \n + synchronized ( mDescramblers ) { \n + if ( ! mDescramblers . isEmpty ( ) ) { \n + for ( Map . Entry < Integer , WeakReference < Descrambler > > d : mDescramblers . entrySet ( ) ) { \n + Descrambler descrambler = d . getValue ( ) . get ( ) ; \n + if ( descrambler ! = null ) { \n + descrambler . close ( ) ; \n + } \n + mTunerResourceManager . releaseDescrambler ( d . getKey ( ) , mClientId ) ; \n + } \n + mDescramblers . clear ( ) ; \n - mDescramblers . clear ( ) ; \n - if ( ! mFilters . isEmpty ( ) ) { \n - for ( Filter f : mFilters ) { \n - f . close ( ) ; \n + synchronized ( mFilters ) { \n + if ( ! mFilters . isEmpty ( ) ) { \n + for ( WeakReference < Filter > weakFilter : mFilters ) { \n + Filter filter = weakFilter . get ( ) ; \n + if ( filter ! = null ) { \n + filter . close ( ) ; \n + } \n + } \n + mFilters . clear ( ) ; \n - mFilters . clear ( ) ; \n - mFilters . add ( filter ) ; \n + synchronized ( mFilters ) { \n + WeakReference < Filter > weakFilter = new WeakReference < Filter > ( filter ) ; \n + mFilters . add ( weakFilter ) ; \n + } \n - mDescramblers . put ( handle , descrambler ) ; \n + synchronized ( mDescramblers ) { \n + WeakReference weakDescrambler = new WeakReference < Descrambler > ( descrambler ) ; \n + mDescramblers . put ( handle , weakDescrambler ) ; \n + } \n",Add thread protection for Filter / Descrambler table \n Use weak reference in the tables to allow objects released by caller \n bug : 174685399 \n bug : 174711353 \n Test : manual \n Change - Id : I760d0a77ad9efe2709a14f0fb8a669f8f16652e1 \n Merged - In : I760d0a77ad9efe2709a14f0fb8a669f8f16652e1,196
"media \ jni \ android _ media _ tv _ Tuner . cpp \n - env - > GetLongField ( settings , env - > GetFieldID ( clazz , "" mFec "" , "" J "" ) ) ) ; \n + env - > GetLongField ( settings , env - > GetFieldID ( clazz , "" mInnerFec "" , "" J "" ) ) ) ; \n - env - > GetByteField ( settings , env - > GetFieldID ( clazz , "" mAnnex "" , "" B "" ) ) ) ; \n + env - > GetIntField ( settings , env - > GetFieldID ( clazz , "" mAnnex "" , "" I "" ) ) ) ; \n",Fix typo to get correct innerFec and Annex for cable signal \n bug : 165808730 \n Test : manual \n Change - Id : I9213246c87512480cb08ab10b102b26f9fd9f681 \n Merged - In : I9213246c87512480cb08ab10b102b26f9fd9f681,196
"media \ jni \ android _ media _ tv _ Tuner . cpp \n - mediaEvent . avDataId , dataLength , obj ) ; \n + mediaEvent . avDataId , dataLength + offset , obj ) ; \n",add offset to calculate buffer size \n bug : 160886488 \n Test : Manual \n Change - Id : I6890b02c0f5a5732f1302348d7bff773dac1401f \n Merged - In : I6890b02c0f5a5732f1302348d7bff773dac1401f,196
media \ jni \ android _ media _ tv _ Tuner . cpp \n + if ( event - > mLinearBlockObj ! = NULL ) { \n + JNIEnv * env = android : : AndroidRuntime : : getJNIEnv ( ) ; \n + env - > DeleteWeakGlobalRef ( event - > mLinearBlockObj ) ; \n + event - > mLinearBlockObj = NULL ; \n + } \n + \n + LnbCallback : : ~ LnbCallback ( ) { \n + JNIEnv * env = AndroidRuntime : : getJNIEnv ( ) ; \n + env - > DeleteWeakGlobalRef ( mLnb ) ; \n + mLnb = NULL ; \n + } \n + \n + mLinearBlockObj = NULL ; \n - return mLinearBlockObj ; \n + return linearBlock ; \n media \ jni \ android _ media _ tv _ Tuner . h \n + ~ LnbCallback ( ) ; \n,free weakref to linearblock when it is destroy \n bug : 168331789 \n Test : Manual \n Change - Id : Iee1b2618bd5c970b728dbc0301b84ff43debde58 \n Merged - In : Iee1b2618bd5c970b728dbc0301b84ff43debde58,196
"media \ java \ android \ media \ tv \ tuner \ Tuner . java \n + private Boolean mIsSharedFrontend = false ; \n - mFrontendHandle = tuner . mFrontendHandle ; \n - mFrontend = nativeOpenFrontendByHandle ( mFrontendHandle ) ; \n + synchronized ( mIsSharedFrontend ) { \n + mFrontendHandle = tuner . mFrontendHandle ; \n + mFrontend = tuner . mFrontend ; \n + mIsSharedFrontend = true ; \n + } \n - int res = nativeCloseFrontend ( mFrontendHandle ) ; \n - if ( res ! = Tuner . RESULT _ SUCCESS ) { \n - TunerUtils . throwExceptionForResult ( res , "" failed to close frontend "" ) ; \n + synchronized ( mIsSharedFrontend ) { \n + if ( ! mIsSharedFrontend ) { \n + int res = nativeCloseFrontend ( mFrontendHandle ) ; \n + if ( res ! = Tuner . RESULT _ SUCCESS ) { \n + TunerUtils . throwExceptionForResult ( res , "" failed to close frontend "" ) ; \n + } \n + } \n + mIsSharedFrontend = false ; \n - FrameworkStatsLog . TV _ TUNER _ STATE _ CHANGED _ _ STATE _ _ UNKNOWN ) ; \n + FrameworkStatsLog . TV _ TUNER _ STATE _ CHANGED _ _ STATE _ _ UNKNOWN ) ; \n",Don ' t open frontend device if it ' s a shared frontend \n bug : 175255961 \n Test : manual \n Change - Id : Ib8c9704ebd1c518a84b8526172ca2fe3d087db87 \n Merged - In : Ib8c9704ebd1c518a84b8526172ca2fe3d087db87,196
"media \ java \ android \ media \ tv \ tuner \ Tuner . java \n - if ( mScanCallback ! = null | | mScanCallbackExecutor ! = null ) { \n + / * * \n + * Scan can be called again for blink scan if scanCallback and executor are same as before . \n + * / \n + if ( ( ( mScanCallback ! = null ) & & ( mScanCallback ! = scanCallback ) ) \n + | | ( ( mScanCallbackExecutor ! = null ) & & ( mScanCallbackExecutor ! = executor ) ) ) { \n - "" Scan already in progress . stopScan must be called before a new scan can be "" \n - + "" started . "" ) ; \n + "" Different Scan session already in progress . stopScan must be called "" \n + + "" before a new scan session can be "" + "" started . "" ) ; \n",Support blink scan \n Allow scan again if callback and executor are same as before . \n bug : 173239634 \n Test : atest - c TunerTest \n Change - Id : Iec5ba453b3d3d40c0d96fda5c7288b79898d9aea \n Merged - In : Iec5ba453b3d3d40c0d96fda5c7288b79898d9aea,196
media \ java \ android \ media \ tv \ TvInputHardwareInfo . java \n - return new Builder ( ) \n + Builder newBuilder = new Builder ( ) \n - . hdmiPortId ( mHdmiPortId ) \n + if ( mType = = TV _ INPUT _ TYPE _ HDMI ) { \n + newBuilder . hdmiPortId ( mHdmiPortId ) ; \n + } \n + return newBuilder ; \n,Don ' t set hdmiPortId for non HDMI device . \n bug : 142698113 \n Test : Manaul \n Change - Id : I2876dacb07e4ebb4ed43c5e95b14ab84c8d935cb,196
"media \ java \ android \ media \ tv \ tuner \ frontend \ FrontendInfo . java \n + / / if max Frequency is negative , we set it as max value of the Integer . \n + if ( maxFrequency < 0 ) { \n + maxFrequency = Integer . MAX _ VALUE ; \n + } \n",Set max frequency as Max _ Value of integer if it ' s negative . \n bug : 176097540 \n Test : Manual \n Change - Id : I17cdd3b2861415b4812694d79aa97f3e7463e12a,196
"media \ jni \ android _ media _ tv _ Tuner . cpp \n - void DestroyCallback ( const C2Buffer * / * buf * / , void * arg ) { \n + void DestroyCallback ( const C2Buffer * buf , void * arg ) { \n + android : : Mutex : : Autolock autoLock ( event - > mLock ) ; \n + event - > decStrong ( buf ) ; \n + incStrong ( pC2Buffer . get ( ) ) ; \n + android : : Mutex : : Autolock autoLock ( mediaEventSp - > mLock ) ; \n",Fix race condition in linearblock release between TIS and MediaCodec \n Bug : 177247275 \n Test : Manual \n Change - Id : I13f924adc3586607eb3a60d184e7786536c7b788 \n Merged - In : I13f924adc3586607eb3a60d184e7786536c7b788,196
dubbo - plugin \ dubbo - qos \ src \ main \ java \ com \ alibaba \ dubbo \ qos \ command \ impl \ Ls . java \n - result . append ( listProvier ( ) ) ; \n + result . append ( listProvider ( ) ) ; \n - public String listProvier ( ) { \n + public String listProvider ( ) { \n,"Merge pull request # 1391 , fix typo of method name in qos module .",199
"new file \n . codecov . yml \n + ignore : \n + - "" dubbo - demo / . * "" \n",Exclude dubbo - demo when calc coverage ( # 1561 ),199
". codecov . yml \n + coverage : \n + status : \n + # pull - requests only \n + patch : \n + default : \n + threshold : 0 . 1 % \n - "" dubbo - demo / . * "" \n",Add pull request coverage check and set threshold as 0 . 1 % ( # 1678 ),199
"dubbo - remoting \ dubbo - remoting - zookeeper \ src \ main \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ curator \ CuratorZookeeperClient . java \n + import org . apache . dubbo . common . Constants ; \n + int timeout = url . getParameter ( Constants . TIMEOUT _ KEY , 5000 ) ; \n - . connectionTimeoutMs ( 5000 ) ; \n + . connectionTimeoutMs ( timeout ) ; \n dubbo - remoting \ dubbo - remoting - zookeeper \ src \ main \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ zkclient \ ZkclientZookeeperClient . java \n + import org . apache . dubbo . common . Constants ; \n - client = new ZkClientWrapper ( url . getBackupAddress ( ) , 30000 ) ; \n + long timeout = url . getParameter ( Constants . TIMEOUT _ KEY , 30000L ) ; \n + client = new ZkClientWrapper ( url . getBackupAddress ( ) , timeout ) ; \n",add timeout config to zookeeper client ( # 2217 ),199
. travis . yml \n + - oraclejdk9 \n - oraclejdk8 \n - openjdk7 \n - travis _ wait 30 mvn clean package \n - - travis _ wait 30 mvn cobertura : cobertura \n - bash < ( curl - s https : / / codecov . io / bash ) \n dubbo - common \ src \ main \ java \ com \ alibaba \ dubbo \ common \ utils \ ReflectUtils . java \n + if ( field . isSynthetic ( ) ) { \n + continue ; \n + } \n pom . xml \n - < maven _ cobertura _ version > 2 . 7 < / maven _ cobertura _ version > \n + < maven _ jacoco _ version > 0 . 8 . 1 < / maven _ jacoco _ version > \n - < maven _ cobertura _ version > 2 . 7 < / maven _ cobertura _ version > \n - < argLine > $ { argline } < / argLine > \n + < argLine > $ { argline } $ { jacocoArgLine } < / argLine > \n - < groupId > org . codehaus . mojo < / groupId > \n - < artifactId > cobertura - maven - plugin < / artifactId > \n - < version > $ { maven _ cobertura _ version } < / version > \n - < configuration > \n - < formats > \n - < format > html < / format > \n - < format > xml < / format > \n - < / formats > \n - < check / > \n - < / configuration > \n + < groupId > org . jacoco < / groupId > \n + < artifactId > jacoco - maven - plugin < / artifactId > \n + < version > $ { maven _ jacoco _ version } < / version > \n + < executions > \n + < execution > \n + < id > jacoco - initialize < / id > \n + < goals > \n + < goal > prepare - agent < / goal > \n + < / goals > \n + < configuration > \n + < propertyName > jacocoArgLine < / propertyName > \n + < / configuration > \n + < / execution > \n + < execution > \n + < id > jacoco - site < / id > \n + < phase > package < / phase > \n + < goals > \n + < goal > report < / goal > \n + < / goals > \n + < / execution > \n + < / executions > \n,Use jacoco instead of cobertura for coverage rate collectiong ( # 1575 ),199
pom . xml \n - < id > jacoco - site < / id > \n - < phase > package < / phase > \n + < id > report - aggregate < / id > \n + < phase > verify < / phase > \n - < goal > report < / goal > \n + < goal > report - aggregate < / goal > \n,combine test coverage report ( # 2643 ),199
pom . xml \n - < argline > - server - Xms256m - Xmx512m - XX : PermSize = 64m - XX : MaxPermSize = 128m - Dfile . encoding = UTF - 8 \n + < argline > - server - Xms256m - Xmx512m - Dfile . encoding = UTF - 8 \n - Djava . net . preferIPv4Stack = true - XX : MetaspaceSize = 64m - XX : MaxMetaspaceSize = 128m \n - < profile > \n - < id > test < / id > \n - < activation > \n - < file > \n - < missing > . project < / missing > \n - < / file > \n - < / activation > \n - < modules > \n - < module > dubbo - test < / module > \n - < / modules > \n - < / profile > \n,polish pom . xml ( remove test profile and jvm permSize args ) ( # 3407 ),199
dubbo - all \ pom . xml \n + < dependency > \n + < groupId > org . apache . dubbo < / groupId > \n + < artifactId > dubbo - registry - nacos < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n + < include > org . apache . dubbo : dubbo - registry - nacos < / include > \n,include nacos in dubbo - all ( # 3968 ),199
pom . xml \n + < maven _ enforce _ version > 3 . 0 . 0 - M2 < / maven _ enforce _ version > \n + < profile > \n + < id > snapshot - ci - deploy < / id > \n + < build > \n + < plugins > \n + < plugin > \n + < groupId > org . apache . maven . plugins < / groupId > \n + < artifactId > maven - enforcer - plugin < / artifactId > \n + < version > $ { maven _ enforce _ version } < / version > \n + < executions > \n + < execution > \n + < id > enforce - no - releases < / id > \n + < goals > \n + < goal > enforce < / goal > \n + < / goals > \n + < configuration > \n + < rules > \n + < requireSnapshotVersion > \n + < message > No Releases Allowed ! < / message > \n + < failWhenParentIsRelease > false < / failWhenParentIsRelease > \n + < / requireSnapshotVersion > \n + < / rules > \n + < fail > true < / fail > \n + < / configuration > \n + < / execution > \n + < / executions > \n + < / plugin > \n + < / plugins > \n + < / build > \n + < / profile > \n,[ CI ] add snapshot deploy check ( # 4157 ),199
dubbo - all \ pom . xml \n - < include > org . apache . dubbo : dubbo - serialization - googlePb < / include > \n + < include > org . apache . dubbo : dubbo - serialization - protobuf - json < / include > \n,"[ Dubbo - 4355 ] Fix dubbo . jar do not contain "" serialization - protobuf - json "" module issue ( # 4356 ) ( # 4364 ) \n * include protobuf - json jar to dubbo",199
dubbo - all \ pom . xml \n - < include > org . apache . dubbo : dubbo - serialization - googlePb < / include > \n + < include > org . apache . dubbo : dubbo - serialization - protobuf - json < / include > \n,"[ Dubbo - 4355 ] Fix dubbo . jar do not contain "" serialization - protobuf - json "" module issue ( # 4356 ) ( # 4364 ) \n * include protobuf - json jar to dubbo",199
"codestyle \ checkstyle . xml \n + < module name = "" RedundantImport "" / > \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ AbstractInterfaceConfig . java \n - import org . apache . dubbo . common . utils . CollectionUtils ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ ServiceConfig . java \n - import org . apache . dubbo . common . utils . CollectionUtils ; \n",Add checkstyle rule for redundant import ( # 3444 ) \n * add checkstyle for redundant import and fix all issue in repo \n * fix git diff issue,199
pom . xml \n + < exclude > . github / * * < / exclude > \n,exclude . github folder for rat - plugin ( # 5165 ),199
"dubbo - plugin \ dubbo - qos \ src \ test \ java \ org \ apache \ dubbo \ qos \ command \ util \ CommandHelperTest . java \n - \n - \n + import org . apache . dubbo . qos . command . impl . Version ; \n - assertThat ( classes , containsInAnyOrder ( GreetingCommand . class , Help . class , Ls . class , Offline . class , Online . class , Quit . class , Ready . class ) ) ; \n + assertThat ( classes , \n + containsInAnyOrder ( GreetingCommand . class , Help . class , Ls . class , Offline . class , Online . class , Quit . class , \n + Ready . class , Version . class ) ) ; \n",fix unit test for qos module ( # 5962 ),199
"dubbo - plugin \ dubbo - qos \ src \ main \ java \ org \ apache \ dubbo \ qos \ legacy \ CountTelnetHandler . java \n - List < String > row = new ArrayList < String > ( ) ; \n - row . add ( m . getName ( ) ) ; \n - row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n - row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n - row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n - row . add ( String . valueOf ( count . getSucceededAverageElapsed ( ) ) + "" ms "" ) ; \n - row . add ( String . valueOf ( count . getSucceededMaxElapsed ( ) ) + "" ms "" ) ; \n - table . add ( row ) ; \n + table . add ( createRow ( m . getName ( ) , count ) ) ; \n - List < String > row = new ArrayList < String > ( ) ; \n - row . add ( method ) ; \n - row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n - row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n - row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n - row . add ( String . valueOf ( count . getSucceededAverageElapsed ( ) ) + "" ms "" ) ; \n - row . add ( String . valueOf ( count . getSucceededMaxElapsed ( ) ) + "" ms "" ) ; \n - table . add ( row ) ; \n + table . add ( createRow ( method , count ) ) ; \n + private List < String > createRow ( String methodName , RpcStatus count ) { \n + List < String > row = new ArrayList < String > ( ) ; \n + row . add ( methodName ) ; \n + row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n + row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n + row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n + row . add ( count . getSucceededAverageElapsed ( ) + "" ms "" ) ; \n + row . add ( count . getSucceededMaxElapsed ( ) + "" ms "" ) ; \n + return row ; \n + } \n",extracting duplicate code in CountTelnetHandler ( # 5824 ),199
"dubbo - plugin \ dubbo - qos \ src \ main \ java \ org \ apache \ dubbo \ qos \ legacy \ CountTelnetHandler . java \n - List < String > row = new ArrayList < String > ( ) ; \n - row . add ( m . getName ( ) ) ; \n - row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n - row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n - row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n - row . add ( String . valueOf ( count . getSucceededAverageElapsed ( ) ) + "" ms "" ) ; \n - row . add ( String . valueOf ( count . getSucceededMaxElapsed ( ) ) + "" ms "" ) ; \n - table . add ( row ) ; \n + table . add ( createRow ( m . getName ( ) , count ) ) ; \n - List < String > row = new ArrayList < String > ( ) ; \n - row . add ( method ) ; \n - row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n - row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n - row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n - row . add ( String . valueOf ( count . getSucceededAverageElapsed ( ) ) + "" ms "" ) ; \n - row . add ( String . valueOf ( count . getSucceededMaxElapsed ( ) ) + "" ms "" ) ; \n - table . add ( row ) ; \n + table . add ( createRow ( method , count ) ) ; \n + private List < String > createRow ( String methodName , RpcStatus count ) { \n + List < String > row = new ArrayList < String > ( ) ; \n + row . add ( methodName ) ; \n + row . add ( String . valueOf ( count . getTotal ( ) ) ) ; \n + row . add ( String . valueOf ( count . getFailed ( ) ) ) ; \n + row . add ( String . valueOf ( count . getActive ( ) ) ) ; \n + row . add ( count . getSucceededAverageElapsed ( ) + "" ms "" ) ; \n + row . add ( count . getSucceededMaxElapsed ( ) + "" ms "" ) ; \n + return row ; \n + } \n",extracting duplicate code in CountTelnetHandler ( # 5824 ),199
Jenkinsfile \n - timeout ( 35 ) { \n + timeout ( 40 ) { \n - sh ' . / mvnw clean package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n + sh ' . / mvnw clean source : jar javadoc : jar package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n,[ CI ] add source and javadoc jar to snapshot,199
Jenkinsfile \n - timeout ( 35 ) { \n + timeout ( 40 ) { \n - sh ' . / mvnw clean package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n + sh ' . / mvnw clean source : jar javadoc : jar package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n,[ CI ] add source and javadoc jar to snapshot,199
Jenkinsfile \n - sh ' . / mvnw clean source : jar javadoc : jar package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n + sh ' . / mvnw clean package deploy - pl dubbo - dependencies - bom & & . / mvnw clean source : jar javadoc : jar package deploy - DskipTests = true ' \n,[ CI ] fix source jar upload issue for snapshot,199
Jenkinsfile \n - sh ' . / mvnw clean source : jar javadoc : jar package deploy - pl dubbo - dependencies - bom & & . / mvnw clean package deploy - DskipTests = true ' \n + sh ' . / mvnw clean package deploy - pl dubbo - dependencies - bom & & . / mvnw clean source : jar javadoc : jar package deploy - DskipTests = true ' \n,[ CI ] fix source jar upload issue for snapshot,199
"dubbo - remoting \ dubbo - remoting - zookeeper \ src \ main \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ support \ AbstractZookeeperTransporter . java \n + import org . apache . dubbo . common . utils . StringUtils ; \n + / / address format : { [ username : password @ ] address } \n - \n + \n + String authPrefix = null ; \n + if ( StringUtils . isNotEmpty ( url . getUsername ( ) ) ) { \n + StringBuilder buf = new StringBuilder ( ) ; \n + buf . append ( url . getUsername ( ) ) ; \n + if ( StringUtils . isNotEmpty ( url . getPassword ( ) ) ) { \n + buf . append ( "" : "" ) ; \n + buf . append ( url . getPassword ( ) ) ; \n + } \n + buf . append ( "" @ "" ) ; \n + authPrefix = buf . toString ( ) ; \n + } \n + \n + if ( StringUtils . isNotEmpty ( authPrefix ) ) { \n + List < String > authedAddressList = new ArrayList < > ( addressList . size ( ) ) ; \n + for ( String addr : addressList ) { \n + authedAddressList . add ( authPrefix + addr ) ; \n + } \n + return authedAddressList ; \n + } \n + \n + \n dubbo - remoting \ dubbo - remoting - zookeeper \ src \ test \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ support \ AbstractZookeeperTransporterTest . java \n + \n + @ Test \n + public void testSameHostWithDifferentUser ( ) throws Exception { \n + int zkPort1 = NetUtils . getAvailablePort ( ) ; \n + int zkPort2 = NetUtils . getAvailablePort ( ) ; \n + try ( TestingServer zkServer1 = new TestingServer ( zkPort1 , true ) ) { \n + try ( TestingServer zkServer2 = new TestingServer ( zkPort2 , true ) ) { \n + URL url1 = URL . valueOf ( "" zookeeper : / / us1 : pw1 @ 127 . 0 . 0 . 1 : "" + zkPort1 + "" / path1 "" ) ; \n + URL url2 = URL . valueOf ( "" zookeeper : / / us2 : pw2 @ 127 . 0 . 0 . 1 : "" + zkPort1 + "" / path2 "" ) ; \n + \n + ZookeeperClient client1 = abstractZookeeperTransporter . connect ( url1 ) ; \n + ZookeeperClient client2 = abstractZookeeperTransporter . connect ( url2 ) ; \n + \n + assertThat ( client1 , not ( client2 ) ) ; \n + } \n + } \n + } \n",[ Dubbo - 4991 ] Fix zk client create logic ( # 5139 ) \n fix # 4991,199
dubbo - dependencies - bom \ pom . xml \n - < revision > 2 . 7 . 8 < / revision > \n + < revision > 2 . 7 . 9 - SNAPSHOT < / revision > \n dubbo - dependencies \ dubbo - dependencies - zookeeper \ pom . xml \n - < revision > 2 . 7 . 8 < / revision > \n + < revision > 2 . 7 . 9 - SNAPSHOT < / revision > \n,update all version to 2 . 7 . 9 - SNAPSHOT ( # 6531 ),199
server \ src \ main \ java \ org \ elasticsearch \ cluster \ metadata \ ComposableIndexTemplate . java \n - private static final Version ALLOW _ AUTO _ CREATE _ VERSION = Version . V _ 8 _ 0 _ 0 ; \n + private static final Version ALLOW _ AUTO _ CREATE _ VERSION = Version . V _ 7 _ 11 _ 0 ; \n,Fix ALLOW _ AUTO _ CREATE _ VERSION after backport ( # 64670 ) \n Fixes the serialization version after backport of # 64208,208
"rest - api - spec \ src \ main \ resources \ rest - api - spec \ test \ search . aggregation \ 20 _ terms . yml \n - - - \n - skip : \n - version : "" - 7 . 99 . 99 "" \n - reason : broken in 7 . 9 . 1 , not yet backported \n + version : "" - 7 . 9 . 2 "" \n + reason : broken in 7 . 9 . 1 , was fixed in 7 . 9 . 2 \n - do : \n - - - \n - skip : \n - version : "" - 7 . 99 . 99 "" \n - reason : "" https : / / github . com / elastic / elasticsearch / issues / 66876 "" \n + version : "" - 7 . 11 . 2 "" \n + reason : "" It was fixed in 7 . 11 . 2 "" \n - do : \n",Update rest tests skip version after backport ( # 69216 ) \n Updates versions after fix backports \n Relates to # 66876 and # 62130,208
"docs \ reference \ aggregations \ bucket \ multi - terms - aggregation . asciidoc \n + The multi _ term aggregations are the most useful when you need to sort by a number of document or a metric aggregation on a composite \n + key and get top N results . If sorting is not required and all values are expected to be retrieved using nested terms aggregation or \n + < < search - aggregations - bucket - composite - aggregation , ` composite aggregations ` > > will be a faster and more memory efficient solution . \n + \n",Clarify the intended use case for multi _ terms aggs ( # 69397 ) \n This PR clarifies when multi _ terms aggs should be used instead of composite \n aggs or nested term aggs . \n Relates to # 65623,208
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 68490 "" / * place a PR link here when committing bwc changes * / \n","Disable BWC tests for backport of changes in values source ( # 68528 ) \n In # 68490 we changed values source config serialization , which \n it is used in almost all aggregations . \n Relates to # 68490",208
"build . gradle \n - bwc _ tests _ enabled = false \n - bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / issues / 66772 "" \n + bwc _ tests _ enabled = true \n + bwc _ tests _ disabled _ issue = "" "" \n server \ src \ main \ java \ org \ elasticsearch \ search \ aggregations \ support \ MultiValuesSourceFieldConfig . java \n - if ( in . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( in . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n - if ( out . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( out . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n",Re - enable BWC tests after backport of changes in values source ( # 68534 ) \n Relates to # 68490,208
"rest - api - spec \ src \ main \ resources \ rest - api - spec \ test \ search . aggregation \ 20 _ terms . yml \n - - - \n - skip : \n - version : "" 7 . 99 . 99 - "" \n + version : "" - 7 . 99 . 99 "" \n - do : \n","Mute "" order by sub agg containing nested "" test correctly ( # 68879 ) \n Fat - fingered the skip statement in this one . \n Relates to # 66876",208
libraries \ stdlib \ jvm \ runtime \ kotlin \ jvm \ annotations \ JvmPlatformAnnotations . kt \n - @ Retention ( AnnotationRetention . BINARY ) \n + @ Retention ( AnnotationRetention . RUNTIME ) \n,Value classes : Raise retention of @ JvmInline to RUNTIME \n so it will be visible by reflection,213
compiler \ psi \ src \ org \ jetbrains \ kotlin \ psi \ stubs \ KotlinStubVersions . kt \n - const val SOURCE _ STUB _ VERSION = 138 \n + const val SOURCE _ STUB _ VERSION = 139 \n,Value classes : Increase stub version due to changes in the parser,213
"compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ codegen \ ExpressionCodegen . kt \n + import org . jetbrains . kotlin . backend . jvm . ir . erasedUpperBound \n + import org . jetbrains . kotlin . builtins . StandardNames \n + unboxResultIfNeeded ( expression ) \n + / / We do not mangle functions if Result is the only parameter of the function , \n + / / thus , if the function overrides generic parameter , its argument is boxed and there is no \n + / / bridge to unbox it . Instead , we unbox it in the non - mangled function manually . \n + private fun unboxResultIfNeeded ( arg : IrGetValue ) { \n + if ( arg . type . erasedUpperBound . fqNameWhenAvailable ! = StandardNames . RESULT _ FQ _ NAME ) return \n + if ( irFunction ! is IrSimpleFunction ) return \n + \n + val index = ( arg . symbol as ? IrValueParameterSymbol ) ? . owner ? . index ? : return \n + val genericOrAnyOverride = irFunction . overriddenSymbols . any { \n + val overriddenParam = if ( index < 0 ) it . owner . dispatchReceiverParameter ! ! else it . owner . valueParameters [ index ] \n + overriddenParam . type . erasedUpperBound . fqNameWhenAvailable ! = StandardNames . RESULT _ FQ _ NAME \n + } | | irFunction . parentAsClass . origin = = JvmLoweredDeclarationOrigin . LAMBDA _ IMPL \n + if ( ! genericOrAnyOverride ) return \n + \n + StackValue . unboxInlineClass ( OBJECT _ TYPE , arg . type . toIrBasedKotlinType ( ) , mv ) \n + } \n + \n compiler \ testData \ codegen \ box \ inlineClasses \ unboxGenericParameter \ funInterface \ result . kt \n - / / IGNORE _ BACKEND : JVM _ IR \n - / / IGNORE _ BACKEND _ FIR : JVM _ IR \n compiler \ testData \ codegen \ box \ inlineClasses \ unboxGenericParameter \ lambda \ result . kt \n - / / IGNORE _ BACKEND : JVM _ IR \n - / / IGNORE _ BACKEND _ FIR : JVM _ IR \n compiler \ testData \ codegen \ box \ inlineClasses \ unboxGenericParameter \ objectLiteral \ result . kt \n - / / IGNORE _ BACKEND : JVM _ IR \n - / / IGNORE _ BACKEND _ FIR : JVM _ IR \n",JVM _ IR : Unbox argument of type kotlin . Result \n if the argument has different type in parent : either generic or Any . \n # KT - 41163 Fixed \n # KT - 43536 Fixed,213
"compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ codegen \ MethodSignatureMapper . kt \n - isBoxMethodForInlineClass ( function ) | | forceFoxedReturnTypeOnOverride ( function ) | | forceBoxedReturnTypeOnDefaultImplFun ( function ) \n + isBoxMethodForInlineClass ( function ) | | forceFoxedReturnTypeOnOverride ( function ) | | forceBoxedReturnTypeOnDefaultImplFun ( function ) | | \n + function . isFromJava ( ) & & function . returnType . isInlined ( ) \n - typeMapper . mapType ( type , TypeMappingMode . DEFAULT , sw ) \n + if ( type . isInlined ( ) & & declaration . isFromJava ( ) ) { \n + typeMapper . mapType ( type , TypeMappingMode . GENERIC _ ARGUMENT , sw ) \n + } else { \n + typeMapper . mapType ( type , TypeMappingMode . DEFAULT , sw ) \n + } \n compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ lower \ inlineclasses \ MemoizedInlineClassReplacements . kt \n - it is IrSimpleFunction & & ( it . hasMangledParameters | | mangleReturnTypes & & it . hasMangledReturnType ) - > \n + it is IrSimpleFunction & & ! it . isFromJava ( ) & & ( it . hasMangledParameters | | mangleReturnTypes & & it . hasMangledReturnType ) - > \n","IC Mangling : Do not mangle functions with inline classes from Java \n in JVM _ IR BE . Map types to boxed variants , when mapping signatures . \n # KT - 26445",213
"compiler \ testData \ codegen \ box \ polymorphicSignature \ invokeExactWithInlineClass . kt \n - val r1 = mh . invokeExact ( Z ( "" OK "" ) ) as String \n - if ( r1 ! = "" OK "" ) return "" Fail r1 : $ r1 "" \n - \n - return mh . invokeExact ( "" OK "" ) as String \n + return try { \n + mh . invokeExact ( Z ( "" OK "" ) ) \n + "" FAIL "" \n + } catch ( ignored : java . lang . invoke . WrongMethodTypeException ) { \n + "" OK "" \n + } \n",IC Mangling : Change test since we pass boxed inline class to java method \n # KT - 28214,213
compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ codegen \ ExpressionCodegen . kt \n + import org . jetbrains . kotlin . backend . jvm . ir . isFromJava \n - val fieldType = callee . type . asmType \n + val calleeIrType = if ( callee . isFromJava ( ) & & callee . type . isInlined ( ) ) callee . type . makeNullable ( ) else callee . type \n + val fieldType = calleeIrType . asmType \n,IC Mangling : Use correct java field type if the type is inline class \n in JVM _ IR BE . \n # KT - 26445,213
"core \ metadata . jvm \ src \ org \ jetbrains \ kotlin \ metadata \ jvm \ deserialization \ JvmMetadataVersion . kt \n - val INSTANCE = JvmMetadataVersion ( 1 , 4 , 1 ) \n + val INSTANCE = JvmMetadataVersion ( 1 , 4 , 2 ) \n",Value classes : Increase JVM metadata version to distinguish \n between inline and value classes .,213
"core \ descriptors \ src \ org \ jetbrains \ kotlin \ renderer \ DescriptorRenderer . kt \n - FUN ( true ) \n + FUN ( true ) , \n + VALUE ( true ) \n core \ descriptors \ src \ org \ jetbrains \ kotlin \ renderer \ DescriptorRendererImpl . kt \n + renderModifier ( builder , DescriptorRendererModifier . VALUE in modifiers & & klass . isValue , "" value "" ) \n",Value classes : Render ' value ' before class,213
"compiler \ frontend \ src \ org \ jetbrains \ kotlin \ diagnostics \ rendering \ DefaultErrorMessages . java \n - MAP . put ( INLINE _ CLASS _ CONSTRUCTOR _ NOT _ FINAL _ READ _ ONLY _ PARAMETER , "" Inline class primary constructor must have only final read - only ( val ) property parameter "" ) ; \n + MAP . put ( INLINE _ CLASS _ CONSTRUCTOR _ NOT _ FINAL _ READ _ ONLY _ PARAMETER , "" Value class primary constructor must have only final read - only ( val ) property parameter "" ) ; \n",Value classes : Change relevant diagnostic to say ' value class ' \n instead of ' inline class ',213
compiler \ psi \ src \ org \ jetbrains \ kotlin \ psi \ stubs \ KotlinStubVersions . kt \n - private const val BINARY _ STUB _ VERSION = 73 \n + private const val BINARY _ STUB _ VERSION = 74 \n,Value Classes : Increase BINARY _ STUB _ VERSION after decompiler changes,213
"compiler \ backend \ src \ org \ jetbrains \ kotlin \ codegen \ inline \ InlineCodegen . kt \n + import org . jetbrains . kotlin . config . JVMConfigurationKeys \n - val asmMethod = if ( callDefault ) \n - state . typeMapper . mapDefaultMethod ( functionDescriptor , sourceCompiler . contextKind ) \n - else \n - mangleSuspendInlineFunctionAsmMethodIfNeeded ( functionDescriptor , jvmSignature . asmMethod ) \n + var asmMethod = mapMethod ( callDefault ) \n + if ( asmMethod . name . contains ( "" - "" ) & & \n + ! state . configuration . getBoolean ( JVMConfigurationKeys . USE _ OLD _ INLINE _ CLASSES _ MANGLING _ SCHEME ) & & \n + classFileContainsMethod ( functionDescriptor , state , asmMethod ) = = false \n + ) { \n + state . typeMapper . useOldManglingRulesForFunctionAcceptingInlineClass = true \n + asmMethod = mapMethod ( callDefault ) \n + state . typeMapper . useOldManglingRulesForFunctionAcceptingInlineClass = false \n + } \n + private fun mapMethod ( callDefault : Boolean ) : Method = \n + if ( callDefault ) state . typeMapper . mapDefaultMethod ( functionDescriptor , sourceCompiler . contextKind ) \n + else mangleSuspendInlineFunctionAsmMethodIfNeeded ( functionDescriptor , jvmSignature . asmMethod ) \n + \n compiler \ testData \ codegen \ box \ inlineClasses \ multifileClass . kt \n - / / IGNORE _ BACKEND : JVM \n",IC Mangling : correctly mangle inline default functions \n # KT - 43682 Fixed,213
"compiler \ testData \ codegen \ box \ coroutines \ featureIntersection \ funInterface . kt \n - / / TARGET _ BACKEND : JVM \n - / / IGNORE _ BACKEND : JVM \n + / / IGNORE _ BACKEND : JVM , JS _ IR \n + / / IGNORE _ LIGHT _ ANALYSIS \n + / / LANGUAGE : + SuspendFunctionsInFunInterfaces , + JvmIrEnabledByDefault \n - @ Suppress ( "" FUN _ INTERFACE _ WITH _ SUSPEND _ FUNCTION "" ) \n js \ js . tests \ tests - gen \ org \ jetbrains \ kotlin \ js \ test \ es6 \ semantics \ IrJsCodegenBoxES6TestGenerated . java \n + @ TestMetadata ( "" funInterface . kt "" ) \n + public void testFunInterface ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / coroutines / featureIntersection / funInterface . kt "" ) ; \n + } \n + \n js \ js . tests \ tests - gen \ org \ jetbrains \ kotlin \ js \ test \ ir \ semantics \ IrJsCodegenBoxTestGenerated . java \n + @ TestMetadata ( "" funInterface . kt "" ) \n + public void testFunInterface ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / coroutines / featureIntersection / funInterface . kt "" ) ; \n + } \n + \n js \ js . tests \ tests - gen \ org \ jetbrains \ kotlin \ js \ test \ semantics \ JsCodegenBoxTestGenerated . java \n + @ TestMetadata ( "" funInterface . kt "" ) \n + public void testFunInterface ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / coroutines / featureIntersection / funInterface . kt "" ) ; \n + } \n + \n",Minor . Change test to use the feature instead of suppressing error,213
"compiler \ testData \ codegen \ box \ compileKotlinAgainstKotlin \ inlineClassesOldMangling . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ coroutines \ featureIntersection \ callableReference \ lambdaParameterUsed . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ coroutines \ featureIntersection \ defaultExpect . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ coroutines \ nonLocalReturn . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ coroutines \ varSpilling \ safeCallElvis . kt \n - r . startCoroutine ( t , Continuation ( EmptyCoroutineContext ) { } ) \n + r . startCoroutine ( t , Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ inlineClasses \ jvm8DefaultInterfaceMethods \ jvmDefaultSuspend . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ box \ valueClasses \ jvmInline . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n compiler \ testData \ codegen \ boxInline \ suspend \ debugMetadataCrossinline . kt \n - c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { } ) \n + c . startCoroutine ( Continuation ( EmptyCoroutineContext ) { \n + it . getOrThrow ( ) \n + } ) \n",Minor . Throw exceptions in test coroutine builders,213
"compiler \ frontend \ src \ org \ jetbrains \ kotlin \ diagnostics \ Errors . java \n - DiagnosticFactory0 < PsiElement > RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS = DiagnosticFactory0 . create ( WARNING ) ; \n + DiagnosticFactory0 < PsiElement > RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS = DiagnosticFactory0 . create ( ERROR ) ; \n compiler \ testData \ codegen \ box \ inlineClasses \ interfaceDelegation \ memberExtVarDelegationWithInlineClassParameterTypes . kt \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n compiler \ testData \ codegen \ box \ reflection \ call \ inlineClasses \ nonOverridingVarOfInlineClass . kt \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n compiler \ testData \ codegen \ box \ reflection \ call \ inlineClasses \ overridingVarOfInlineClass . kt \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n compiler \ testData \ codegen \ box \ reflection \ call \ inlineClasses \ properties . kt \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n compiler \ testData \ codegen \ box \ reflection \ callBy \ inlineClassMembers . kt \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n + @ Suppress ( "" RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS "" ) \n",Raise RESERVED _ VAR _ PROPERTY _ OF _ VALUE _ CLASS to error,213
"compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ codegen \ ExpressionCodegen . kt \n - if ( ! arg . type . isInlined ( ) ) return \n + if ( ! arg . type . erasedUpperBound . isInline ) return \n + if ( arg . type . isNullable ( ) & & arg . type . makeNotNull ( ) . unboxInlineClass ( ) . isNullable ( ) ) return \n compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ codegen \ MethodSignatureMapper . kt \n - return type . isInlined ( ) & & ! type . isMappedToPrimitive \n + return type . erasedUpperBound . isInline & & ! type . isMappedToPrimitive \n compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ lower \ InlineCallableReferenceToLambda . kt \n + const val STUB _ FOR _ INLINING = "" stub _ for _ inlining "" \n + \n - name = Name . identifier ( "" stub _ for _ inlining "" ) \n + name = Name . identifier ( STUB _ FOR _ INLINING ) \n compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ lower \ inlineclasses \ InlineClassAbi . kt \n + import org . jetbrains . kotlin . backend . jvm . lower . STUB _ FOR _ INLINING \n - get ( ) = origin = = IrDeclarationOrigin . LOCAL _ FUNCTION _ FOR _ LAMBDA & & name . asString ( ) . contains ( "" \ $ stub _ for _ inlining "" ) \n + get ( ) = origin = = IrDeclarationOrigin . LOCAL _ FUNCTION _ FOR _ LAMBDA & & name . asString ( ) . contains ( "" \ $ $ STUB _ FOR _ INLINING "" ) \n - get ( ) = isInlined ( ) & & \n + get ( ) = erasedUpperBound . isInline & & \n compiler \ testData \ codegen \ box \ inlineClasses \ callableReferences \ let \ result . kt \n + / / IGNORE _ BACKEND : WASM \n",Use erased upper bound instead of checking for inline type,213
"idea \ src \ org \ jetbrains \ kotlin \ idea \ quickfix \ InlineClassDeprecatedFix . kt \n + import org . jetbrains . kotlin . idea . project . TargetPlatformDetector \n + import org . jetbrains . kotlin . platform . jvm . isJvm \n - private val text = KotlinBundle . message ( "" replace . with . 0 "" , "" @ JvmInline value "" ) \n + private val text = KotlinBundle . message ( \n + "" replace . with . 0 "" , \n + ( if ( TargetPlatformDetector . getPlatform ( element . containingKtFile ) . isJvm ( ) ) "" @ JvmInline "" else "" "" ) + "" value "" \n + ) \n - element ? . addAnnotation ( JVM _ INLINE _ ANNOTATION _ FQ _ NAME ) \n + if ( TargetPlatformDetector . getPlatform ( file ) . isJvm ( ) ) { \n + element ? . addAnnotation ( JVM _ INLINE _ ANNOTATION _ FQ _ NAME ) \n + } \n new file \n idea \ testData \ quickfix \ inlineClass \ inlineClassDeprecated _ js . kt \n + / / "" Replace with ' value ' "" "" true "" \n + / / JS \n + \n + < caret > inline class IC ( val i : Int ) \n new file \n idea \ testData \ quickfix \ inlineClass \ inlineClassDeprecated _ js . kt . after \n + / / "" Replace with ' value ' "" "" true "" \n + / / JS \n + \n + value class IC ( val i : Int ) \n idea \ tests \ org \ jetbrains \ kotlin \ idea \ quickfix \ QuickFixTestGenerated . java \n + \n + @ TestMetadata ( "" inlineClassDeprecated _ js . kt "" ) \n + public void testInlineClassDeprecated _ js ( ) throws Exception { \n + runTest ( "" idea / testData / quickfix / inlineClass / inlineClassDeprecated _ js . kt "" ) ; \n + } \n",Do not add @ JvmInline annotation on JS and Native,213
"tools \ jdk \ BUILD . java _ tools \n - values = { "" cpu "" : "" k8 "" } , \n - ) \n - \n - config _ setting ( \n - name = "" darwin "" , \n - values = { "" cpu "" : "" darwin "" } , \n + constraint _ values = [ "" @ platforms / / os : linux "" , "" @ platforms / / cpu : x86 _ 64 "" ] , \n - values = { "" cpu "" : "" darwin _ x86 _ 64 "" } , \n + constraint _ values = [ "" @ platforms / / os : macos "" , "" @ platforms / / cpu : x86 _ 64 "" ] , \n - values = { "" cpu "" : "" darwin _ arm64 "" } , \n + constraint _ values = [ "" @ platforms / / os : macos "" , "" @ platforms / / cpu : arm64 "" ] , \n - values = { "" cpu "" : "" darwin _ arm64e "" } , \n + constraint _ values = [ "" @ platforms / / os : macos "" , "" @ platforms / / cpu : arm64e "" ] , \n - values = { "" cpu "" : "" x64 _ windows "" } , \n + constraint _ values = [ "" @ platforms / / os : windows "" ] , \n - values = { "" cpu "" : "" freebsd "" } , \n + constraint _ values = [ "" @ platforms / / os : freebsd "" ] , \n - values = { "" cpu "" : "" openbsd "" } , \n + constraint _ values = [ "" @ platforms / / os : openbsd "" ] , \n - "" : darwin "" : "" java _ tools / src / tools / singlejar / singlejar _ local "" , \n - "" : darwin "" : "" : ijar _ prebuilt _ binary "" , \n","Use selects based on constraint _ values in java _ tools . \n This makes them consistent with platformization which works on OS and CPU constraints from @ platforms . \n Flag - - cpu = darwin maps on Bazel to macos + x86 _ 64 , internally - - cpu = darwin _ x86 _ 64 is used . With platforms , those become a single config _ setting . \n I didn ' t combine together other darwin config _ settings ( dropping cpu ) , because of possible combination macos + ppc . \n Closes # 12410 . \n PiperOrigin - RevId : 340636557",220
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ java \ JavaCompilationHelper . java \n + return ; \n src \ test \ shell \ bazel \ bazel _ java _ test _ defaults . sh \n + function test _ tools _ jdk _ toolchain _ nojacocorunner ( ) { \n + mkdir - p java / main \n + cat > java / main / BUILD < < EOF \n + java _ binary ( \n + name = ' JavaBinary ' , \n + srcs = [ ' JavaBinary . java ' ] , \n + main _ class = ' JavaBinary ' , \n + ) \n + load ( \n + "" @ bazel _ tools / / tools / jdk : default _ java _ toolchain . bzl "" , \n + "" default _ java _ toolchain "" , \n + ) \n + default _ java _ toolchain ( \n + name = "" default _ toolchain "" , \n + jacocorunner = None , \n + visibility = [ "" / / visibility : public "" ] , \n + ) \n + EOF \n + \n + cat > java / main / JavaBinary . java < < EOF \n + public class JavaBinary { \n + public static void main ( String [ ] args ) { \n + System . out . println ( "" Successfully executed JavaBinary ! "" ) ; \n + } \n + } \n + EOF \n + bazel coverage java / main : JavaBinary \ \n + - - java _ toolchain = / / java / main : default _ toolchain \ \n + - - javabase = @ bazel _ tools / / tools / jdk : remote _ jdk11 \ \n + - - verbose _ failures - s & > "" $ { TEST _ log } "" \ \n + & & fail "" Coverage succeeded even when jacocorunner not set "" \n + expect _ log "" jacocorunner not set in java _ toolchain : "" \n + } \n + \n",Fix NPE when coveragerunner is not set on the toolchain . \n Fixes https : / / github . com / bazelbuild / bazel / issues / 12619 \n Closes # 12625 . \n PiperOrigin - RevId : 345638551,220
"third _ party \ java \ jacoco \ BUILD \n + load ( "" / / src : release _ archive . bzl "" , "" release _ archive "" ) \n - genrule ( \n + release _ archive ( \n - outs = [ "" jacoco _ jars . zip "" ] , \n - cmd = "" $ ( location / / src : zip _ files ) third _ party / java / jacoco $ @ $ ( SRCS ) "" , \n - output _ to _ bindir = 1 , \n - tools = [ "" / / src : zip _ files "" ] , \n + package _ dir = "" java _ tools / third _ party / java / jacoco "" , \n + visibility = [ "" / / visibility : public "" ] , \n third _ party \ java \ proguard \ BUILD \n + load ( "" / / src : release _ archive . bzl "" , "" release _ archive "" ) \n + \n - genrule ( \n + release _ archive ( \n - outs = [ "" proguard . zip "" ] , \n - cmd = "" $ ( location / / src : zip _ files ) third _ party / java / proguard $ @ $ ( SRCS ) "" , \n - tools = [ "" / / src : zip _ files "" ] , \n + package _ dir = "" java _ tools / third _ party / java / proguard "" , \n","Use release _ archive to create java _ tools ' zips . \n Github part of https : / / github . com / bazelbuild / bazel / pull / 12615 \n Partial commit for third _ party / * , see # 12628 . \n Signed - off - by : Philipp Wollermann < philwo @ google . com >",220
src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ android \ AndroidSdkBaseRule . java \n - import com . google . devtools . build . lib . analysis . config . HostTransition ; \n + import com . google . devtools . build . lib . analysis . config . ExecutionTransitionFactory ; \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n - . cfg ( HostTransition . createFactory ( ) ) \n + . cfg ( ExecutionTransitionFactory . create ( ) ) \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ android \ AndroidBinaryTest . java \n - . isEqualTo ( jkrunchyExecutable . getExecPathString ( ) ) ; \n + . endsWith ( jkrunchyExecutable . getOutputDirRelativePathString ( ) ) ; \n,Change host transitions to exec transition in android sdk . \n Closes # 12220 . \n PiperOrigin - RevId : 335633528,220
src \ test \ shell \ bazel \ bazel _ java _ tools _ test . sh \n - # TODO ( ilist ) : reenable after jacocoagent is patched \n - function disable _ java _ tools _ has _ jacocoagent ( ) { \n + function test _ java _ tools _ has _ jacocoagent ( ) { \n - # TODO ( ilist ) : reenable after proguard is patched \n - function disable _ java _ tools _ has _ proguard ( ) { \n + function test _ java _ tools _ has _ proguard ( ) { \n,Use release _ archive to create java _ tools ' zips ( reenabling tests ) . \n This is third part of https : / / github . com / bazelbuild / bazel / pull / 12615 \n Second part was https : / / github . com / bazelbuild / bazel / pull / 12628 \n Closes # 12646 . \n PiperOrigin - RevId : 346074973,220
"src \ conditions \ BUILD \n + config _ setting ( \n + name = "" windows _ msvc "" , \n + values = { "" cpu "" : "" x64 _ windows _ msvc "" } , \n + visibility = [ "" / / visibility : public "" ] , \n + ) \n + \n","Add windows _ msvc back to conditions . \n This is partial revert of 6d637f4165445a0d6644f6e6f8a61b3f1de208d8 . \n windows _ msvc condition is used downstream by tensorflow via ruy . \n The culprit line is in https : / / github . com / google / ruy / blob / master / ruy / build _ defs . bzl # L60 ( and # L67 , # L77 ) . \n Closes # 12661 . \n PiperOrigin - RevId : 346353748",220
"third _ party \ BUILD \n - "" / / src / conditions : darwin _ x86 _ 64 "" : "" * . so * . dll "" , \n","Use constraints in global conditions instead of configuration flags ( third _ party / BUILD ) . \n This is part of https : / / github . com / bazelbuild / bazel / pull / 12427 , that \n changes third _ party / BUILD file . \n Partial commit for third _ party / * , see # 12435 . \n Signed - off - by : Philipp Wollermann < philwo @ google . com >",220
"src \ upload _ all _ java _ tools . sh \n - bazel test - - verbose _ failures - - test _ output = all - - nocache _ test _ results \ \n - / / src / test / shell / bazel : bazel _ java _ test _ local _ java _ tools _ jdk $ { java _ version } \ \n - - - define = LOCAL _ JAVA _ TOOLS _ ZIP _ URL = "" $ { file _ url } "" \n + \n + # Skip for now , as the test is broken on Windows . \n + # See https : / / github . com / bazelbuild / bazel / issues / 12244 for details \n + if not "" $ is _ windows "" ; then \n + bazel test - - verbose _ failures - - test _ output = all - - nocache _ test _ results \ \n + / / src / test / shell / bazel : bazel _ java _ test _ local _ java _ tools _ jdk $ { java _ version } \ \n + - - define = LOCAL _ JAVA _ TOOLS _ ZIP _ URL = "" $ { file _ url } "" \n + fi \n - - java _ tools _ zip src / java _ tools _ java $ { java _ version } . zip \ \n","Remove bazel _ java _ test _ local _ java _ tools _ jdkXX test from upload _ all _ java _ tools . sh… \n The tests don ' t pass on Windows , because of an outdated CI setup , see https : / / github . com / bazelbuild / bazel / issues / 12244 , because of Windows path limit . Removing the tests to be able make a release . Similar tests are already executed on the main branch . \n Closes # 12300 . \n PiperOrigin - RevId : 337851055",220
"tools \ jdk \ java _ toolchain _ default . bzl \n - genclass = [ "" : GenClass "" ] , \n - header _ compiler = [ "" : TurbineDirect "" ] , \n - header _ compiler _ direct = [ "" : TurbineDirect "" ] , \n - ijar = [ "" : ijar "" ] , \n - javabuilder = [ "" : JavaBuilder "" ] , \n + genclass = [ Label ( "" / / : GenClass "" , relative _ to _ caller _ repository = True ) ] , \n + header _ compiler = [ Label ( "" / / : TurbineDirect "" , relative _ to _ caller _ repository = True ) ] , \n + header _ compiler _ direct = [ Label ( "" / / : TurbineDirect "" , relative _ to _ caller _ repository = True ) ] , \n + ijar = [ Label ( "" / / : ijar "" , relative _ to _ caller _ repository = True ) ] , \n + javabuilder = [ Label ( "" / / : JavaBuilder "" , relative _ to _ caller _ repository = True ) ] , \n - jacocorunner = "" : jacoco _ coverage _ runner _ filegroup "" , \n + jacocorunner = Label ( "" / / : jacoco _ coverage _ runner _ filegroup "" , relative _ to _ caller _ repository = True ) , \n - singlejar = [ "" : singlejar "" ] , \n + singlejar = [ Label ( "" / / : singlejar "" , relative _ to _ caller _ repository = True ) ] , \n",Use relative labels in java _ toolchain _ default . bzl \n This way the . bzl file can be used from other WORKSPACES to define new toolchains . \n Closes # 12332 . \n PiperOrigin - RevId : 338485397,220
"src \ BUILD \n - "" / / third _ party / jarjar : jarjar _ command _ deploy . jar "" , \n - "" / / third _ party / jarjar : srcs "" , \n src \ test \ shell \ bazel \ bazel _ java _ tools _ dist _ test . sh \n - function test _ java _ tools _ has _ jarjar ( ) { \n - expect _ path _ in _ java _ tools "" third _ party / jarjar "" \n - expect _ path _ in _ java _ tools "" third _ party / jarjar / java / com / tonicsystems / jarjar "" \n - } \n - \n src \ test \ shell \ bazel \ bazel _ java _ tools _ test . sh \n - function test _ java _ tools _ has _ jarjar ( ) { \n - expect _ path _ in _ java _ tools "" java _ tools / jarjar _ command _ deploy . jar "" \n - } \n - \n tools \ jdk \ BUILD \n - remote _ java _ tools _ java _ import ( \n - name = "" JarJar "" , \n - target = "" : JarJar "" , \n - ) \n - \n tools \ jdk \ BUILD . java _ tools \n - filegroup ( \n - name = "" JarJar "" , \n - srcs = [ "" java _ tools / jarjar _ command _ deploy . jar "" ] , \n - ) \n - \n - cc _ library ( \n - name = "" lib - util "" , \n - srcs = [ "" java _ tools / src / main / native / windows / util . cc "" ] , \n - hdrs = [ "" java _ tools / src / main / native / windows / util . h "" ] , \n - strip _ include _ prefix = "" java _ tools "" , \n - ) \n - \n","Remove jarjar from java _ tools . \n Jarjar is an advanced processor of jar files . It can rename classes consistently within a . jar file . It is used in Jacoco deployment , renaming package of ' asm ' dependency in the Jacoco deployment jar . This is done so that ' asm ' does not clash with another version of asm that might be used in the target being "" code coveraged "" . \n After the deployment of java _ tools , jarjar is not used by Bazel itself . There might be downstream projects using jarjar from java _ tools . However it is a much better idea to remove jarjar from java _ tools interface , and that downstream projects depend on it directly . \n Closes # 12491 . \n PiperOrigin - RevId : 342819568",220
"src \ test \ shell \ bazel \ bazel _ java _ tools _ dist _ test . sh \n - # TOODO ( iirina ) : Re - enable this and update jacoco version after # 8376 is merged . \n - function DISABLED _ test _ java _ tools _ has _ jacocoagent ( ) { \n - expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . agent - 0 . 7 . 5 . 201505241946 - src . jar "" \n - expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . core - 0 . 7 . 5 . 201505241946 - src . jar "" \n - expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . report - 0 . 7 . 5 . 201505241946 - src . jar "" \n - expect _ path _ in _ java _ tools "" third _ party / asm / asm - analysis - 7 . 0 - sources . jar "" \n - expect _ path _ in _ java _ tools "" third _ party / asm / asm - commons - 7 . 0 - sources . jar "" \n - expect _ path _ in _ java _ tools "" third _ party / asm / asm - 7 . 0 - sources . jar "" \n + function test _ java _ tools _ has _ jacocoagent ( ) { \n + expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . agent - 0 . 8 . 3 - sources . jar "" \n + expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . core - 0 . 8 . 3 - sources . jar "" \n + expect _ path _ in _ java _ tools "" third _ party / java / jacoco / org . jacoco . report - 0 . 8 . 3 - sources . jar "" \n + expect _ path _ in _ java _ tools "" third _ party / asm / asm - analysis - 8 . 0 - sources . jar "" \n + expect _ path _ in _ java _ tools "" third _ party / asm / asm - commons - 8 . 0 - sources . jar "" \n + expect _ path _ in _ java _ tools "" third _ party / asm / asm - 8 . 0 - sources . jar "" \n",Reenabled jacoco agent test . \n Closes # 12492 . \n PiperOrigin - RevId : 342861728,220
"third _ party \ java \ jacoco \ BUILD \n - load ( "" / / tools / distributions : distribution _ rules . bzl "" , "" distrib _ java _ import "" , "" distrib _ jar _ filegroup "" ) \n + load ( "" / / tools / distributions : distribution _ rules . bzl "" , "" distrib _ jar _ filegroup "" , "" distrib _ java _ import "" ) \n - [ "" * - src . jar "" ] , \n + [ "" * - sources . jar "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n + enable _ distributions = [ "" debian "" ] , \n - enable _ distributions = [ "" debian "" ] , \n - jars = [ "" jacocoagent - % s . jar "" % VERSION ] , \n + jars = [ "" jacocoagent - % s . jar "" % VERSION ] , \n - jars = [ "" jacocoagent - % s . jar "" % VERSION ] , \n + jars = [ "" jacocoagent - % s . jar "" % VERSION ] , \n","Fix packing jacoco sources . \n Partial commit for third _ party / * , see # 12500 . \n Signed - off - by : Philipp Wollermann < philwo @ google . com >",220
"src \ BUILD \n - "" / / third _ party / jarjar : embedded _ build _ and _ license "" , \n src \ create _ embedded _ tools . py \n - ( ' * jarjar _ command _ deploy . jar ' , \n - lambda x : ' tools / jdk / jarjar _ command _ deploy . jar ' ) , \n - ( ' * third _ party / jarjar / BUILD . tools ' , lambda x : ' third _ party / jarjar / BUILD ' ) , \n - ( ' * third _ party / jarjar / LICENSE ' , lambda x : ' third _ party / jarjar / LICENSE ' ) , \n src \ test \ java \ com \ google \ devtools \ build \ lib \ analysis \ mock \ BazelAnalysisMock . java \n - . add ( "" sh _ binary ( name = ' jarjar _ bin ' , srcs = [ ' empty . sh ' ] ) "" ) \n tools \ android \ BUILD . tools \n - alias ( \n - name = "" jarjar _ bin "" , \n - actual = "" / / third _ party / java / jarjar : jarjar _ bin "" , \n - ) \n - \n",Remove jarjar distribution . \n Jarjar was removed from java _ tools already ( https : / / github . com / bazelbuild / bazel / pull / 12491 ) . This is cleanup of other dependencies . \n Closes # 12506 . \n PiperOrigin - RevId : 344071950,220
"third _ party \ jarjar \ BUILD \n - filegroup ( \n - name = "" embedded _ build _ and _ license "" , \n - srcs = [ \n - "" BUILD . tools "" , \n - "" LICENSE "" , \n - ] , \n - ) \n - \n deleted file \n third _ party \ jarjar \ BUILD . tools \n - package ( default _ visibility = [ "" / / visibility : public "" ] ) \n - \n - licenses ( [ "" notice "" ] ) # Apache 2 . 0 \n - \n - load ( \n - "" / / tools / jdk : remote _ java _ tools _ aliases . bzl "" , \n - "" remote _ java _ tools _ java _ import "" , \n - ) \n - \n - remote _ java _ tools _ java _ import ( \n - name = "" jarjar _ import "" , \n - target = "" : JarJar "" , \n - ) \n - \n - java _ binary ( \n - name = "" jarjar _ bin "" , \n - main _ class = "" com . tonicsystems . jarjar . Main "" , \n - runtime _ deps = [ "" : jarjar _ import "" ] , \n - ) \n","Remove jarjar distribution . \n This is part of the PR https : / / github . com / bazelbuild / bazel / pull / 12506 that only affect github files . \n Partial commit for third _ party / * , see # 12555 . \n Signed - off - by : Philipp Wollermann < philwo @ google . com >",220
"third _ party \ ijar \ BUILD \n + srcs = [ \n + "" : ijar _ srcs _ zip "" , \n + "" : ijar _ deploy _ zip "" , \n + "" / / src : zlib _ zip "" , \n + "" / / src / main / cpp / util : cpp _ util _ with _ deps _ zip "" , \n + ] , \n + outs = [ "" ijar _ with _ deps . zip "" ] , \n + cmd = "" $ ( location / / src : merge _ zip _ files ) - $ @ $ ( SRCS ) "" , \n + tools = [ "" / / src : merge _ zip _ files "" ] , \n + visibility = [ "" / / visibility : public "" ] , \n + ) \n + \n + genrule ( \n + name = "" ijar _ transitive _ srcs _ zip "" , \n + genrule ( \n + name = "" ijar _ deploy _ zip "" , \n + srcs = [ \n + "" : ijar "" , \n + "" : zipper "" , \n + ] , \n + outs = [ "" ijar _ deploy . zip "" ] , \n + cmd = "" $ ( location / / src : zip _ files ) ijar $ @ $ ( SRCS ) "" , \n + tools = [ "" / / src : zip _ files "" ] , \n + visibility = [ "" / / visibility : public "" ] , \n + ) \n + \n - ) + [ \n - "" : ijar "" , \n - "" : zipper "" , \n - ] , \n + ) , \n",Separate ijar sources from deployment zip . \n This is a github only patch from PR # 12546 . Needs to go in first . \n Closes # 12556 . \n Signed - off - by : Philipp Wollermann < philwo @ google . com >,220
"tools \ jdk \ default _ java _ toolchain . bzl \n - ijar = [ "" @ remote _ java _ tools / / : ijar _ cc _ binary "" ] , \n - singlejar = [ "" @ remote _ java _ tools / / : singlejar _ cc _ bin "" ] , \n + ijar = [ "" @ bazel _ tools / / tools / jdk : ijar _ prebuilt _ binary "" ] , \n + singlejar = [ "" @ bazel _ tools / / tools / jdk : prebuilt _ singlejar "" ] , \n - ijar = [ "" @ bazel _ tools / / tools / jdk : ijar _ prebuilt _ binary "" ] , \n - singlejar = [ "" @ bazel _ tools / / tools / jdk : prebuilt _ singlejar "" ] , \n + ijar = [ "" @ remote _ java _ tools / / : ijar _ cc _ binary "" ] , \n + singlejar = [ "" @ remote _ java _ tools / / : singlejar _ cc _ bin "" ] , \n",Fix mixup of prebuilt and nonprebuilt toolchain . \n Closes # 12724 . \n PiperOrigin - RevId : 348065963,220
"src \ main \ java \ com \ google \ devtools \ build \ lib \ analysis \ PlatformOptions . java \n - defaultValue = "" false "" , \n + defaultValue = "" true "" , \n","Flip incompatible _ use _ toolchain _ resolution _ for _ java _ rules flag . \n RELNOTES [ INC ] : flipped incompatible _ use _ toolchain _ resolution _ for _ java _ rules , see # 7849 \n Closes # 12812 . \n PiperOrigin - RevId : 351593322",220
"distdir _ deps . bzl \n - "" archive "" : "" java _ tools _ linux - v11 . 0 . zip "" , \n + "" archive "" : "" java _ tools _ linux - v11 . 1 . zip "" , \n - "" archive "" : "" java _ tools _ windows - v11 . 0 . zip "" , \n + "" archive "" : "" java _ tools _ windows - v11 . 1 . zip "" , \n - "" archive "" : "" java _ tools _ darwin - v11 . 0 . zip "" , \n + "" archive "" : "" java _ tools _ darwin - v11 . 1 . zip "" , \n",Fix version update of java _ tools to v11 . 1 . \n Closes # 12824 . \n PiperOrigin - RevId : 351786677,220
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ java \ JavaOptions . java \n + "" VM startup options of each java _ binary target . "" ) \n + @ Option ( \n + name = "" host _ jvmopt "" , \n + allowMultiple = true , \n + defaultValue = "" null "" , \n + documentationCategory = OptionDocumentationCategory . UNCATEGORIZED , \n + effectTags = { OptionEffectTag . UNKNOWN } , \n + help = \n + "" Additional options to pass to the Java VM when building tools that are executed during "" \n + + "" the build . These options will get added to the VM startup options of each "" \n + + "" java _ binary target . "" ) \n + public List < String > hostJvmOpts ; \n + \n - host . jvmOpts = ImmutableList . of ( "" - XX : ErrorFile = / dev / stderr "" ) ; \n + if ( hostJvmOpts = = null | | hostJvmOpts . isEmpty ( ) ) { \n + host . jvmOpts = ImmutableList . of ( "" - XX : ErrorFile = / dev / stderr "" ) ; \n + } else { \n + host . jvmOpts = hostJvmOpts ; \n + } \n",Add host _ jvmopt . \n Fixes https : / / github . com / bazelbuild / bazel / issues / 11893 \n Closes # 12822 . \n PiperOrigin - RevId : 352631243,220
"third _ party \ ijar \ ijar . cc \n + const char * DUMMY _ FILE = "" dummy "" ; \n + const size _ t DUMMY _ PATH _ LENGTH = strlen ( DUMMY _ FILE ) ; \n + / / The size of an output jar containing only an empty dummy file : \n + const size _ t JAR _ WITH _ DUMMY _ FILE _ SIZE = 98ull + 2 * DUMMY _ PATH _ LENGTH ; \n - u8 output _ length = \n - in - > CalculateOutputLength ( ) + \n + u8 output _ length = in - > CalculateOutputLength ( ) ; \n + if ( output _ length < JAR _ WITH _ DUMMY _ FILE _ SIZE ) { \n + output _ length = JAR _ WITH _ DUMMY _ FILE _ SIZE ; \n + } \n + output _ length + = \n + \n - out - > WriteEmptyFile ( "" dummy "" ) ; \n + out - > WriteEmptyFile ( DUMMY _ FILE ) ; \n","Fix ijar failing on empty jars . \n The problem happened when all the files are filtered out . In such case a dummy file is created , but it was not accounted for in the size estimation . \n Fixes https : / / github . com / bazelbuild / bazel / issues / 10162 \n Closes # 12893 . \n PiperOrigin - RevId : 353915969",220
"scripts \ bootstrap \ BUILD . bootstrap \n - singlejar = [ "" / / src / java _ tools / singlejar : bootstrap _ deploy . jar "" ] , \n + singlejar = [ "" / / src / tools / singlejar : singlejar "" ] , \n",Replace Java implementation of singlejar with CC implementation in bootstrap . \n Closes # 12784 . \n PiperOrigin - RevId : 350749515,220
"src \ test \ shell \ bazel \ bazel _ java _ test _ defaults . sh \n - java _ runtime = "" @ local _ jdk / / : jdk "" , \n tools \ jdk \ BUILD . tools \n + \n + java _ runtime _ version _ alias ( \n + name = "" jdk _ 8 "" , \n + runtime _ version = "" 8 "" , \n + selected _ java _ runtime = "" : legacy _ current _ java _ runtime "" , \n + visibility = [ "" / / visibility : public "" ] , \n + ) \n tools \ jdk \ default _ java _ toolchain . bzl \n - "" - Xbootclasspath / p : $ ( location @ bazel _ tools / / tools / jdk : javac _ jar ) "" , \n + "" - Xbootclasspath / p : $ ( location @ remote _ java _ tools / / : javac _ jar ) "" , \n + java _ runtime = "" @ bazel _ tools / / tools / jdk : jdk _ 8 "" , \n","Attach local JDK to JVM8 _ TOOLCHAIN _ CONFIGURATION . \n This is a partial revert of ec29e28a7f729c6a899ad0a75c770c4d174d78af . \n The commit support rules _ appengine usecase , which needs to supply additional parameters to a toolchain compiling with JDK8 . \n Previously the whole commit broke repos that are using bazel - toolchains . \n Caveat : the downstream still breaks rules _ appengine on Java 11 only system ( Ubuntu 18 . 04 ) . I believe this is correct behaviour , because rules _ appengine seem to support only Java 8 . \n Addresses issue : https : / / github . com / bazelbuild / rules _ appengine / issues / 119 \n Closes # 12789 . \n PiperOrigin - RevId : 350754300",220
"tools \ jdk \ BUILD \n + "" toolchain _ utils . bzl "" , \n new file \n tools \ jdk \ toolchain _ utils . bzl \n + # Copyright 2019 The Bazel Authors . All rights reserved . \n + # \n + # Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + # you may not use this file except in compliance with the License . \n + # You may obtain a copy of the License at \n + # \n + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + # \n + # Unless required by applicable law or agreed to in writing , software \n + # distributed under the License is distributed on an "" AS IS "" BASIS , \n + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + # See the License for the specific language governing permissions and \n + # limitations under the License . \n + \n + "" "" "" \n + Finds the Java toolchain . \n + \n + Returns the toolchain if enabled , and falls back to a toolchain constructed from \n + legacy toolchain selection . \n + "" "" "" \n + \n + def find _ java _ toolchain ( ctx , target ) : \n + "" "" "" \n + Finds the Java toolchain . \n + \n + If the Java toolchain is in use , returns it . Otherwise , returns a Java \n + toolchain derived from legacy toolchain selection . \n + \n + Args : \n + ctx : The rule context for which to find a toolchain . \n + target : A java _ toolchain target ( for legacy toolchain resolution ) . \n + \n + Returns : \n + A JavaToolchainInfo . \n + "" "" "" \n + \n + _ ignore = [ ctx ] \n + \n + return target [ java _ common . JavaToolchainInfo ] \n + \n + def find _ java _ runtime _ toolchain ( ctx , target ) : \n + "" "" "" \n + Finds the Java runtime . \n + \n + If the Java toolchain is in use , returns it . Otherwise , returns a Java \n + runtime derived from legacy toolchain selection . \n + \n + Args : \n + ctx : The rule context for which to find a toolchain . \n + target : A java _ runtime target ( for legacy toolchain resolution ) . \n + \n + Returns : \n + A JavaRuntimeInfo . \n + "" "" "" \n + \n + _ ignore = [ ctx ] \n + \n + return target [ java _ common . JavaRuntimeInfo ] \n",Undelete toolchain _ utils . bzl . \n This partially reverts https : / / github . com / bazelbuild / bazel / commit / 1cc4d89f3c1f0047151fe4472352737c58c3b4ed . \n There are downstream projects which depend on toolchain _ utils . bzl . \n Closes # 12802 . \n PiperOrigin - RevId : 351132017,220
"src \ test \ shell \ bazel \ bazel _ coverage _ java _ test . sh \n + load ( "" @ bazel _ tools / / tools / jdk : default _ java _ toolchain . bzl "" , "" default _ java _ toolchain "" ) \n + \n + \n + default _ java _ toolchain ( \n + name = "" custom _ toolchain "" \n + ) \n - assert _ coverage _ result "" $ expected _ result "" "" $ coverage _ file _ path "" \n + assert _ coverage _ result "" $ expected _ result "" "" $ coverage _ file _ path "" \n + \n + bazel coverage - - test _ output = all - - java _ toolchain = / / : custom _ toolchain / / : test & > $ TEST _ log | | fail "" Coverage with default _ java _ toolchain for / / : test failed "" \n + assert _ coverage _ result "" $ expected _ result "" "" $ coverage _ file _ path "" \n",Test coverage support when using default _ java _ toolchain . \n Issue https : / / github . com / bazelbuild / bazel / issues / 12793 \n Closes # 12805 . \n PiperOrigin - RevId : 351142251,220
"presto - geospatial - toolkit \ src \ test \ java \ com \ facebook \ presto \ geospatial \ serde \ TestGeometrySerialization . java \n - testSerialization ( "" POLYGON ( ( 0 0 , 0 1 , 1 1 , 1 0 , 0 0 ) ) "" ) ; \n + testCrossSerialization ( wkt ) ; \n + { \n + Geometry expected = createJtsGeometry ( wkt ) ; \n + Geometry actual = JtsGeometrySerde . deserialize ( JtsGeometrySerde . serialize ( expected ) ) ; \n + assertGeometryEquals ( actual , expected ) ; \n + } \n + \n + private static void testCrossSerialization ( String wkt ) \n - assertEquals ( jtsSerialized , esriSerialized ) ; \n - \n - Geometry jtsDeserialized = JtsGeometrySerde . deserialize ( jtsSerialized ) ; \n - assertGeometryEquals ( jtsDeserialized , jtsGeometry ) ; \n - OGCGeometry esriDeserialized = GeometrySerde . deserialize ( esriSerialized ) ; \n - assertGeometryEquals ( esriDeserialized , esriGeometry ) ; \n + OGCGeometry esriFromJts = GeometrySerde . deserialize ( jtsSerialized ) ; \n + Geometry jtsFromEsri = JtsGeometrySerde . deserialize ( esriSerialized ) ; \n + assertGeometryEquals ( esriFromJts , esriGeometry ) ; \n + assertGeometryEquals ( jtsFromEsri , jtsGeometry ) ; \n","Improve Geometry Serialization Tests \n 1 . Remove duplicate test case . \n 2 . Change serialization equality testing to be more semantic . \n JTS and ESRI have different orderings of their polygon loops \n ( clockwise and counter - clockwise ) which doesn ' t affect \n serialization / deserialization correctness , but does change the \n intermediate format . This changes the test to only care about \n the output .",227
pom . xml \n - < version > 1 . 15 . 0 < / version > \n + < version > 1 . 16 . 1 < / version > \n,Upgrade JTS to 1 . 16 . 1,227
"presto - geospatial \ src \ main \ java \ com \ facebook \ presto \ plugin \ geospatial \ GeoFunctions . java \n - if ( intersection . getXMin ( ) = = intersection . getXMax ( ) ) { \n - if ( intersection . getYMin ( ) = = intersection . getYMax ( ) ) { \n - return EsriGeometrySerde . serialize ( createFromEsriGeometry ( new Point ( intersection . getXMin ( ) , intersection . getXMax ( ) ) , null ) ) ; \n + if ( intersection . getXMin ( ) = = intersection . getXMax ( ) | | intersection . getYMin ( ) = = intersection . getYMax ( ) ) { \n + if ( intersection . getXMin ( ) = = intersection . getXMax ( ) & & intersection . getYMin ( ) = = intersection . getYMax ( ) ) { \n + return EsriGeometrySerde . serialize ( createFromEsriGeometry ( new Point ( intersection . getXMin ( ) , intersection . getYMin ( ) ) , null ) ) ; \n - return EsriGeometrySerde . serialize ( createFromEsriGeometry ( new Polyline ( new Point ( intersection . getXMin ( ) , intersection . getYMin ( ) ) , new Point ( intersection . getXMin ( ) , intersection . getYMax ( ) ) ) , null ) ) ; \n - } \n - \n - if ( intersection . getYMin ( ) = = intersection . getYMax ( ) ) { \n - return EsriGeometrySerde . serialize ( createFromEsriGeometry ( new Polyline ( new Point ( intersection . getXMin ( ) , intersection . getYMin ( ) ) , new Point ( intersection . getXMax ( ) , intersection . getYMin ( ) ) ) , null ) ) ; \n + return EsriGeometrySerde . serialize ( createFromEsriGeometry ( new Polyline ( new Point ( intersection . getXMin ( ) , intersection . getYMin ( ) ) , new Point ( intersection . getXMax ( ) , intersection . getYMax ( ) ) ) , null ) ) ; \n presto - geospatial \ src \ test \ java \ com \ facebook \ presto \ plugin \ geospatial \ TestGeoFunctions . java \n + assertEnvelopeIntersection ( "" POLYGON ( ( 0 0 , 0 5 , 5 5 , 5 0 , 0 0 ) ) "" , "" POLYGON ( ( 5 - 1 , 5 0 , 6 0 , 6 - 1 , 5 - 1 ) ) "" , "" POINT ( 5 0 ) "" ) ; \n","Fix incorrect intersection between two envelopes \n When two envelopes intersected at a single point , the intersection would \n be incorrectly calculated as ` POINT ( x , x ) ` instead of ` POINT ( x , y ) ` . \n This also simplifies the logic when two envelopes intersect in a line .",227
pom . xml \n - < dep . slice . version > 0 . 36 < / dep . slice . version > \n + < dep . slice . version > 0 . 38 < / dep . slice . version > \n presto - main \ src \ main \ java \ com \ facebook \ presto \ type \ setdigest \ SetDigest . java \n - import io . airlift . slice . Murmur3 ; \n + import io . airlift . slice . Murmur3Hash128 ; \n - addHash ( Murmur3 . hash64 ( value ) ) ; \n + addHash ( Murmur3Hash128 . hash64 ( value ) ) ; \n - addHash ( Murmur3 . hash64 ( value ) ) ; \n + addHash ( Murmur3Hash128 . hash64 ( value ) ) ; \n,Upgrade slice to 0 . 38 \n Previous version was 0 . 36 . There was one minor incompatibility .,227
"presto - geospatial - toolkit \ src \ main \ java \ com \ facebook \ presto \ geospatial \ GeometryType . java \n + / / LinearRings are a subclass of LineString \n + case "" LinearRing "" : \n presto - geospatial - toolkit \ src \ main \ java \ com \ facebook \ presto \ geospatial \ serde \ EsriGeometrySerde . java \n - case GEOMETRY _ COLLECTION : { \n + case GEOMETRY _ COLLECTION : \n - } \n - throw new IllegalArgumentException ( "" Unexpected type : "" + type ) ; \n + throw new IllegalArgumentException ( "" Unsupported geometry type : "" + type ) ; \n - throw new IllegalArgumentException ( "" Unexpected type : "" + type ) ; \n + throw new IllegalArgumentException ( "" Unsupported geometry type : "" + type ) ; \n presto - geospatial - toolkit \ src \ main \ java \ com \ facebook \ presto \ geospatial \ serde \ JtsGeometrySerde . java \n + import com . facebook . presto . geospatial . GeometryType ; \n + import static com . facebook . presto . geospatial . GeometryType . getForJtsGeometryType ; \n - throw new UnsupportedOperationException ( "" Unexpected type : "" + type ) ; \n + throw new IllegalArgumentException ( "" Unsupported geometry type : "" + type ) ; \n - switch ( geometry . getGeometryType ( ) ) { \n - case "" Point "" : \n + GeometryType type = getForJtsGeometryType ( geometry . getGeometryType ( ) ) ; \n + switch ( type ) { \n + case POINT : \n - case "" MultiPoint "" : \n + case MULTI _ POINT : \n - case "" LineString "" : \n - case "" LinearRing "" : \n - / / LinearRings are a subclass of LineString \n + case LINE _ STRING : \n - case "" MultiLineString "" : \n + case MULTI _ LINE _ STRING : \n - case "" Polygon "" : \n + case POLYGON : \n - case "" MultiPolygon "" : \n + case MULTI _ POLYGON : \n - case "" GeometryCollection "" : \n + case GEOMETRY _ COLLECTION : \n - throw new IllegalArgumentException ( "" Unsupported geometry type : "" + geometry . getGeometryType ( ) ) ; \n + throw new IllegalArgumentException ( "" Unsupported geometry type : "" + type ) ; \n - for ( Coordinate coordinate : geometry . getCoordinates ( ) ) { \n - writeCoordinate ( coordinate , output ) ; \n - } \n + writeCoordinates ( geometry . getCoordinates ( ) , output ) ; \n",Refactor case statement to use enums \n This is more consistent and safe .,227
"presto - geospatial - toolkit \ src \ main \ java \ com \ facebook \ presto \ geospatial \ GeometryUtils . java \n + import java . util . Optional ; \n - public static String getGeometryInvalidReason ( org . locationtech . jts . geom . Geometry geometry ) \n + public static Optional < String > getGeometryInvalidReason ( org . locationtech . jts . geom . Geometry geometry ) \n - return err . getMessage ( ) ; \n + return Optional . of ( err . getMessage ( ) ) ; \n - return format ( "" [ % s ] % s : ( % s % s ) "" , geometryType , errorDescription , nonSimpleLocation . getX ( ) , nonSimpleLocation . getY ( ) ) ; \n + return Optional . of ( format ( "" [ % s ] % s : ( % s % s ) "" , geometryType , errorDescription , nonSimpleLocation . getX ( ) , nonSimpleLocation . getY ( ) ) ) ; \n - return null ; \n + return Optional . empty ( ) ; \n presto - geospatial \ src \ main \ java \ com \ facebook \ presto \ plugin \ geospatial \ GeoFunctions . java \n + import io . airlift . slice . Slices ; \n - return utf8Slice ( getGeometryInvalidReason ( geometry ) ) ; \n + return getGeometryInvalidReason ( geometry ) . map ( Slices : : utf8Slice ) . orElse ( null ) ; \n presto - geospatial \ src \ test \ java \ com \ facebook \ presto \ plugin \ geospatial \ TestGeoFunctions . java \n + \n + / / valid geometries \n + assertInvalidReason ( "" POINT ( 1 2 ) "" , null ) ; \n + assertInvalidReason ( "" POLYGON ( ( 0 0 , 1 0 , 1 1 , 0 1 , 0 0 ) ) "" , null ) ; \n + assertInvalidReason ( "" GEOMETRYCOLLECTION ( MULTIPOINT ( 1 0 , 1 1 , 0 1 , 0 0 ) ) "" , null ) ; \n","Fix NPE in geometry _ invalid _ reason \n Embarrassingly , this method threw an NPE on valid geometries , which it \n was not supposed to . This commit uses Optional and adds a guard .",227
pom . xml \n - < version > 1 . 17 . 0 < / version > \n + < version > 1 . 18 . 0 < / version > \n - < version > 1 . 17 . 0 < / version > \n + < version > 1 . 18 . 0 < / version > \n,"Upgrade JTS to 1 . 18 . 0 \n Relevant parts : \n * Vastly improved overlay operations ( intersection , union , etc ) . This \n will allow us to use JTS operations ( currently using ESRI ) . \n + TopologicalExceptions have been mostly eliminated . \n + Performance is improved . For geometries that intersect in a small \n fraction of their area , performance is greatly improved . \n + More accurate in some cases . \n + https : / / locationtech . github . io / jts / javadoc / org / locationtech / jts / operation / overlayng / package - summary . html \n * Fix for ` buffer ` and ` DouglasPeuckerSimplifier ` : in some cases , the \n majority of the polygon would be dropped : \n + https : / / github . com / locationtech / jts / pull / 655 \n + https : / / github . com / locationtech / jts / issues / 498 \n * ` WKBWriter ` writes empty polygons in a fashion consistent with other \n libraries / tools . \n More details : https : / / github . com / locationtech / jts / releases / tag / jts - 1 . 18 . 0",227
"build . xml \n - < property name = "" version . num "" value = "" 1 . 2 . 0 "" / > \n + < property name = "" version . num "" value = "" 1 . 2 . 1 "" / > \n src \ com \ loopj \ android \ http \ AsyncHttpClient . java \n + HttpEntity entity = null ; \n + if ( params ! = null ) { \n + entity = params . getEntity ( ) ; \n + } \n + \n + post ( context , url , entity , null , responseHandler ) ; \n + } \n + \n + public void post ( Context context , String url , HttpEntity entity , String contentType , AsyncHttpResponseHandler responseHandler ) { \n - if ( params ! = null ) { \n - HttpEntity entity = params . getEntity ( ) ; \n - if ( entity ! = null ) { \n - post . setEntity ( entity ) ; \n - } \n + \n + if ( entity ! = null ) { \n + post . setEntity ( entity ) ; \n + } \n + \n + if ( contentType ! = null ) { \n + post . addHeader ( "" Content - Type "" , contentType ) ; \n",Support for alternative post entities other than key value pairs,231
"build . xml \n - < javac srcdir = "" src "" destdir = "" $ { classes . dir } "" classpathref = "" classpath "" / > \n + \n + < javac \n + srcdir = "" . "" \n + destdir = "" $ { classes . dir } "" \n + classpathref = "" classpath "" \n + debug = "" true "" \n + debuglevel = "" lines , source "" / > \n","Add line numbers to debug information , 25 % jar size increase : ( : ( but easier debugging : ) : )",231
"src \ com \ loopj \ android \ http \ PersistentCookieStore . java \n + / / Save cookie into local store , or remove if expired \n + if ( ! cookie . isExpired ( new Date ( ) ) ) { \n + cookies . put ( name , cookie ) ; \n + } else { \n + cookies . remove ( name ) ; \n + } \n + \n",Remove expired cookies ( thanks @ neromancer ),231
"src \ com \ loopj \ android \ http \ AsyncHttpClient . java \n + HttpConnectionParams . setConnectionTimeout ( httpParams , socketTimout ) ; \n",Add http timeout as well as socket timeout,231
"src \ com \ loopj \ android \ http \ JsonHttpResponseHandler . java \n + import android . os . Message ; \n + \n + protected static final int SUCCESS _ JSON _ MESSAGE = 100 ; \n + \n - protected void handleSuccessMessage ( String responseBody ) { \n - super . handleSuccessMessage ( responseBody ) ; \n + protected void handleMessage ( Message msg ) { \n + switch ( msg . what ) { \n + case SUCCESS _ JSON _ MESSAGE : \n + handleSuccessJsonMessage ( msg . obj ) ; \n + break ; \n + default : \n + super . handleMessage ( msg ) ; \n + } \n + } \n + \n + protected void handleSuccessJsonMessage ( Object jsonResponse ) { \n + if ( jsonResponse instanceof JSONObject ) { \n + onSuccess ( ( JSONObject ) jsonResponse ) ; \n + } else if ( jsonResponse instanceof JSONArray ) { \n + onSuccess ( ( JSONArray ) jsonResponse ) ; \n + } else { \n + onFailure ( new JSONException ( "" Unexpected type "" + jsonResponse . getClass ( ) . getName ( ) ) ) ; \n + } \n + } \n + @ Override \n + protected void sendSuccessMessage ( String responseBody ) { \n - if ( jsonResponse instanceof JSONObject ) { \n - onSuccess ( ( JSONObject ) jsonResponse ) ; \n - } else if ( jsonResponse instanceof JSONArray ) { \n - onSuccess ( ( JSONArray ) jsonResponse ) ; \n - } else { \n - throw new JSONException ( "" Unexpected type "" + jsonResponse . getClass ( ) . getName ( ) ) ; \n - } \n + sendMessage ( obtainMessage ( SUCCESS _ JSON _ MESSAGE , jsonResponse ) ) ; \n - onFailure ( e , responseBody ) ; \n + sendFailureMessage ( e , responseBody ) ; \n","Handle json parsing in the background thread , not the ui thread",231
"src \ com \ loopj \ android \ http \ JsonHttpResponseHandler . java \n + public void onFailure ( Throwable e , JSONObject errorResponse ) { } \n + public void onFailure ( Throwable e , JSONArray errorResponse ) { } \n + \n + \n + / / \n + / / Pre - processing of messages ( executes in background threadpool thread ) \n + / / \n + \n + @ Override \n + protected void sendSuccessMessage ( String responseBody ) { \n + try { \n + Object jsonResponse = parseResponse ( responseBody ) ; \n + sendMessage ( obtainMessage ( SUCCESS _ JSON _ MESSAGE , jsonResponse ) ) ; \n + } catch ( JSONException e ) { \n + sendFailureMessage ( e , responseBody ) ; \n + } \n + } \n + \n + \n + / / \n + / / Pre - processing of messages ( in original calling thread , typically the UI thread ) \n + / / \n - / / Utility methods \n - @ Override \n - protected void sendSuccessMessage ( String responseBody ) { \n - try { \n - Object jsonResponse = parseResponse ( responseBody ) ; \n - sendMessage ( obtainMessage ( SUCCESS _ JSON _ MESSAGE , jsonResponse ) ) ; \n - } catch ( JSONException e ) { \n - sendFailureMessage ( e , responseBody ) ; \n - } \n - } \n - \n - / * * \n - * Handle cases where a failure is returned as JSON \n - * / \n - public void onFailure ( Throwable e , JSONObject errorResponse ) { } \n - public void onFailure ( Throwable e , JSONArray errorResponse ) { } \n - \n",Move methods so they are consistent with asynchttpresponsehandler,231
"src \ com \ loopj \ android \ http \ RetryHandler . java \n - boolean retry ; \n + boolean retry = true ; \n - } else { \n + } \n + \n + if ( retry ) { \n - HttpUriRequest currentReq = ( HttpUriRequest ) context . getAttribute ( ExecutionContext . HTTP _ REQUEST ) ; \n + HttpUriRequest currentReq = ( HttpUriRequest ) context . getAttribute ( ExecutionContext . HTTP _ REQUEST ) ; \n - if ( ! requestType . equals ( "" POST "" ) ) { \n - retry = true ; \n - } else { \n - / / otherwise do not retry \n - retry = false ; \n - } \n + retry = ! requestType . equals ( "" POST "" ) ; \n","Don ' t retry non - idempotent requests , fixes # 108",231
"src \ com \ loopj \ android \ http \ JsonHttpResponseHandler . java \n - onFailure ( new JSONException ( "" Unexpected type "" + jsonResponse . getClass ( ) . getName ( ) ) ) ; \n + onFailure ( new JSONException ( "" Unexpected type "" + jsonResponse . getClass ( ) . getName ( ) ) , ( JSONObject ) null ) ; \n","Call ( arbitrary ) non - deprecated onFailure response in JsonHttpResponseHandler , fixes # 105",231
"examples \ TwitterRestClient . java \n - client . get ( getAbsoluteUrl ( url ) , params , responseHandler ) ; \n + client . post ( getAbsoluteUrl ( url ) , params , responseHandler ) ; \n",Fix type in TwitterRestClient . Fixes # 99,231
new file \n releases \ android - async - http - 1 . 2 . 0 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 2 . 0 . jar differ \n new file \n releases \ android - async - http - 1 . 2 . 1 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 2 . 1 . jar differ \n new file \n releases \ android - async - http - 1 . 3 . 0 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 3 . 0 . jar differ \n new file \n releases \ android - async - http - 1 . 3 . 1 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 3 . 1 . jar differ \n new file \n releases \ android - async - http - 1 . 3 . 2 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 3 . 2 . jar differ \n new file \n releases \ android - async - http - 1 . 4 . 0 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 4 . 0 . jar differ \n new file \n releases \ android - async - http - 1 . 4 . 1 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 4 . 1 . jar differ \n new file \n releases \ android - async - http - 1 . 4 . 2 . jar \n Binary files / dev / null and b / releases / android - async - http - 1 . 4 . 2 . jar differ \n,Add jar files to repo since github downloads is now dead ( RIP ),231
src \ com \ loopj \ android \ http \ PersistentCookieStore . java \n - / / Clear cookies from local store \n - cookies . clear ( ) ; \n - \n + \n + / / Clear cookies from local store \n + cookies . clear ( ) ; \n,Ensure cookies are deleted from prefs fixes # 214,231
new file \n android \ src \ main \ res \ drawable - xxhdpi \ map _ infowindow _ popup . 9 . png \n Binary files / dev / null and b / android / src / main / res / drawable - xxhdpi / map _ infowindow _ popup . 9 . png differ \n,Add xxhdpi info window asset . Fixes public issue 43 .,234
new file \n android \ debug . keystore \n Binary files / dev / null and b / android / debug . keystore differ \n,Re - adding debug . keystore . \n Change - Id : Iafafa5cd35039601ec5a2a252ea647ac708f0957,234
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ MapFragment . java \n + import com . google . android . gms . maps . model . LatLngBounds ; \n + \n + / * * \n + * Area covered by the venue . Determines if the venue is currently visible on screen . \n + * / \n + private static final LatLngBounds VENUE _ AREA = \n + new LatLngBounds ( new LatLng ( 37 . 423205 , - 122 . 081757 ) , \n + new LatLng ( 37 . 428479 , - 122 . 078109 ) ) ; \n - return mMap . getProjection ( ) . getVisibleRegion ( ) . latLngBounds . contains ( VENUE ) ; \n + LatLngBounds visibleBounds = mMap . getProjection ( ) . getVisibleRegion ( ) . latLngBounds ; \n + \n + return MapUtils . boundsIntersect ( visibleBounds , VENUE _ AREA ) ; \n android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ MapUtils . java \n + import com . google . android . gms . maps . model . LatLngBounds ; \n + \n + / * * \n + * Checks whether two LatLngBounds intersect . \n + * \n + * @ return true if the given bounds intersect . \n + * / \n + public static boolean boundsIntersect ( LatLngBounds first , LatLngBounds second ) { \n + / / First check if the latitudes are not intersecting . \n + if ( first . northeast . latitude < second . southwest . latitude | | \n + first . southwest . latitude > second . northeast . latitude ) { \n + return false ; \n + } \n + \n + / / Next , check if the longitudes are not intersecting . \n + if ( first . northeast . longitude < second . southwest . longitude | | \n + first . southwest . longitude > second . northeast . longitude ) { \n + return false ; \n + } \n + \n + / / Both latitude and longitude are intersecting . \n + return true ; \n + \n + } \n","Use area to check whether venue is displayed on screen . \n Instead of using a single LatLng position , compare the area of the venue \n ( a LatLngBounds ) to the visible region on screen . \n Bug : 28204026 \n Change - Id : I36ff92aec967bb4c572db4f4a85e154719e8bb0a",234
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ util \ SVGTileProvider . java \n - 41 . 185661155555536f , 99 . 26042152524433f , \n - 41 . 1888504888889f , 99 . 2603301865061f , \n - 41 . 1888504888889f , 99 . 26474027274617f \n - \n - / / TODO ( b / 27989561 ) : Update these values to match the new floor plan . \n - / * 40 . 95635986328125f , 98 . 94217824936158f , \n - 40 . 95730018615723f , 98 . 94123077396628f , \n - 40 . 95791244506836f , 98 . 94186019897214f \n - * / \n + 41 . 185890133333345f , 99 . 26028878054545f , / / NW \n + 41 . 188904099707f , 99 . 26028878054545f , / / NE \n + 41 . 188904099707f , 99 . 26489700767203f , / / SE \n",Fix misaligned map . \n Bug : 28283158 \n Change - Id : If6d4520a605d6d91bc321d1b2b0062c7025bac30,234
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ MapFragment . java \n - private static final float VENUE _ CAMERA _ ZOOM = 16 . 35f ; \n + private static final float VENUE _ CAMERA _ ZOOM = 17 . 7f ; \n + \n - new CameraPosition . Builder ( ) . bearing ( 234 . 2f ) \n - . target ( new LatLng ( 37 . 426360f , - 122 . 079552f ) ) \n + new CameraPosition . Builder ( ) . bearing ( 334 . 04f ) \n + . target ( new LatLng ( 37 . 42574957397063f , - 122 . 0797488838434f ) ) \n",Update initial camera position on map . \n Camera now faces north and is centered on the venue at a higher \n zoom level . \n Change - Id : Ib4f8508ba48ebea09db16e4ca4cadc9166a10d8d,234
"android \ src \ main \ res \ layout \ map _ info _ bottom . xml \n + android : minHeight = "" @ dimen / map _ slideableinfo _ height _ titleonly "" \n android \ src \ main \ res \ values \ dimens . xml \n - < dimen name = "" map _ slideableinfo _ height _ titleonly "" > 56dp < / dimen > \n + < dimen name = "" map _ slideableinfo _ height _ titleonly "" > 80dp < / dimen > \n android \ src \ main \ res \ values \ styles . xml \n - < item name = "" android : singleLine "" > true < / item > \n",Enable multiple line titles on map . \n Bug : 28607076 \n Change - Id : Id6c5ed5fb705180c2ed89a3ec9092fadff69fa90,234
android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ MapFragment . java \n - ICON _ ACTIVE = BitmapDescriptorFactory . fromResource ( R . drawable . map _ marker _ selected ) ; \n - ICON _ NORMAL = \n - BitmapDescriptorFactory . fromResource ( R . drawable . map _ marker _ unselected ) ; \n - \n + \n + / / Initialise marker icons . \n + ICON _ ACTIVE = BitmapDescriptorFactory . fromResource ( R . drawable . map _ marker _ selected ) ; \n + ICON _ NORMAL = BitmapDescriptorFactory . fromResource ( R . drawable . map _ marker _ unselected ) ; \n + \n,Move marker icon initialisation to onMapReady . \n Fixes NPE in onCreate when BitmapDescriptor is initialised before GoogleMap is ready . \n Bug : 28619167 \n Change - Id : I774b8cfd956d6a3c53373f50c897ef315dff1330,234
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ MapFragment . java \n + addVenueMarker ( ) ; \n + \n + / / Move camera directly to the venue \n + centerOnVenue ( false ) ; \n + \n + loadMapData ( ) ; \n + \n + LOGD ( TAG , "" Map setup complete . "" ) ; \n + } \n + \n + / * * \n + * Loads markers and tiles from the content provider . \n + * \n + * @ see # mMarkerLoader \n + * @ see # mTileLoader \n + * / \n + private void loadMapData ( ) { \n - \n - setupMap ( true ) ; \n - \n - private void setupMap ( boolean resetCamera ) { \n - \n - / / Add a Marker for venue \n + private void addVenueMarker ( ) { \n - \n - if ( resetCamera ) { \n - / / Move camera directly to the venue \n - centerOnVenue ( false ) ; \n - } \n - \n - LOGD ( TAG , "" Map setup complete . "" ) ; \n - / / clear map reload all data \n + / / Clear the map , but don ' t reset the camera . \n - setupMap ( false ) ; \n + addVenueMarker ( ) ; \n",Always add venue marker before loading tiles and markers . \n Fix NPE after screen rotation . \n Bug : 28619661 \n Change - Id : Ieb8ba798eb81d73c0b74dbc92f9c83bd74cd0ddc,234
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ MapFragment . java \n + / * * \n + * Indicates if the venue is active and its markers and floor plan is being displayed . Set to \n + * false by default , as the venue marker is shown first . \n + * / \n + private boolean mVenueIsActive = false ; \n + \n + \n - if ( cameraPosition . zoom < MAX _ RENDERED _ ZOOMLEVEL | | ! isAtVenue ( ) ) { \n - onDefocusVenue ( ) ; \n - } else { \n + boolean isVenueInFocus = cameraPosition . zoom > = MAX _ RENDERED _ ZOOMLEVEL & & isVenueVisible ( ) ; \n + \n + / / Check if the camera is focused on the venue . Trigger a callback if the state has changed . \n + if ( isVenueInFocus & & ! mVenueIsActive ) { \n + mVenueIsActive = true ; \n + } else if ( ! isVenueInFocus & & mVenueIsActive ) { \n + onDefocusVenue ( ) ; \n + mVenueIsActive = false ; \n - * @ see # isAtVenue ( ) \n + * @ see # isVenueVisible ( ) \n - if ( isAtVenue ( ) ) { \n + if ( isVenueVisible ( ) ) { \n - public boolean isAtVenue ( ) { \n + public boolean isVenueVisible ( ) { \n",Improve detection when map is focused on the venue . \n Only trigger callbacks as the state changes and the venue comes into \n focus ( or goes out of focus ) . \n Change - Id : Ic217f086de97323c122bf6b2f65bae115f9860d8,234
"android \ src \ main \ res \ raw \ bootstrap _ data . json \n - "" lat "" : 37 . 423819 , \n - "" lng "" : - 122 . 079771 , \n + "" lat "" : 37 . 423868 , \n + "" lng "" : - 122 . 079754 , \n - "" lat "" : 37 . 423926 , \n - "" lng "" : - 122 . 078656 , \n + "" lat "" : 37 . 42382 , \n + "" lng "" : - 122 . 078723 , \n - "" lat "" : 37 . 425637 , \n - "" lng "" : - 122 . 079111 , \n + "" lat "" : 37 . 425685 , \n + "" lng "" : - 122 . 07909 , \n",Move restroom markers . \n Bug : 28464806 \n Change - Id : Ic62cec148c4c9e7708bc3e67eb0a892f00d854e3,234
"android \ src \ main \ res \ raw \ bootstrap _ data . json \n - "" title "" : "" Play & Studio "" , \n + "" title "" : "" Play & Android Studio "" , \n - "" title "" : "" Office Hours / Spaces "" , \n + "" title "" : "" Office Hours / Ask a Dev "" , \n",Update sandbox names for launch . \n Bug : 28464806 \n Change - Id : I4b0fca34625c8d70354e6a3c787267bd3f601dfa,234
"lib \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ map \ util \ MarkerLoadingTask . java \n + import java . util . Iterator ; \n + \n - Iterable < GeoJsonFeature > features = layer . getFeatures ( ) ; \n + \n + Iterator < GeoJsonFeature > iterator = layer . getFeatures ( ) . iterator ( ) ; \n - for ( GeoJsonFeature feature : features ) { \n + while ( iterator . hasNext ( ) ) { \n + GeoJsonFeature feature = iterator . next ( ) ; \n + \n - pointStyle . setVisible ( true ) ; \n - feature . setPointStyle ( pointStyle ) ; \n + \n + / / If the marker is invalid ( e . g . the icon does not exist ) , remove it from the map . \n + if ( pointStyle = = null ) { \n + iterator . remove ( ) ; \n + } else { \n + pointStyle . setVisible ( true ) ; \n + feature . setPointStyle ( pointStyle ) ; \n + } \n","Fix NPE when marker icon does not exist . \n Instead , hide the marker from the map . \n Bug : 37488027 \n Change - Id : I2f5363746a5c4cabe20ca2f04430919ee81b57a3",234
"lib \ src \ mapEditor \ java \ com \ google \ samples \ apps \ iosched \ map \ EditorMapFragment . java \n - @ Override \n - public void onInfoShowVenue ( ) { \n - } \n - \n lib \ src \ mapEditor \ java \ com \ google \ samples \ apps \ iosched \ map \ MapEditorActivity . java \n - @ Override \n - public void onInfoShowVenue ( ) { \n - showMessage ( "" Venue Marker "" ) ; \n - } \n - \n",Fix build for mapEditor build variant . \n Change - Id : I6503ac4ba766b9a91428142909c08f4d802c0155,234
"react . gradle \n - def extraArgs = config . extraPackagerArgs ? : [ ] ; \n + def extraArgs = [ ] \n - extraArgs = extraArgs . clone ( ) \n - extraArgs . add ( "" - - config "" ) ; \n - extraArgs . add ( bundleConfig ) ; \n + extraArgs . add ( "" - - config "" ) \n + extraArgs . add ( bundleConfig ) \n + } \n + \n + / / Hermes doesn ' t require JS minification . \n + if ( enableHermes & & ! devEnabled ) { \n + extraArgs . add ( "" - - minify "" ) \n + extraArgs . add ( "" false "" ) \n + } \n + \n + if ( config . extraPackagerArgs ) { \n + extraArgs . addAll ( config . extraPackagerArgs ) \n scripts \ react - native - xcode . sh \n + # Hermes doesn ' t require JS minification . \n + if [ [ $ USE _ HERMES = = true & & $ DEV = = false ] ] ; then \n + EXTRA _ ARGS = "" $ EXTRA _ ARGS - - minify false "" \n + fi \n + \n - - entry - file "" $ ENTRY _ FILE "" \ \n - "" $ HERMES _ CLI _ PATH "" - emit - binary $ EXTRA _ COMPILER _ ARGS - out "" $ DEST / main . jsbundle "" "" $ BUNDLE _ FILE "" \n + "" $ HERMES _ CLI _ PATH "" - emit - binary $ EXTRA _ COMPILER _ ARGS - out "" $ DEST / main . jsbundle "" "" $ BUNDLE _ FILE "" \n",Don ' t minify JS bundle by default when using hermes ( # 30496 ) \n Summary : \n Minification is not needed for hermes as it does all required optimisations on the bytecode . This is what facebook does internally for hermes bundles and I also validated by comparing the bytecode bundle size on a minified and non - minified bundle . \n # # Changelog \n [ General ] [ Changed ] - Don ' t minify JS bundle by default when using hermes \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30496 \n Test Plan : Verified that the JS bundled generated on Android and iOS when using hermes is not minified by checking the generated JS file manually . \n Reviewed By : rickhanlonii \n Differential Revision : D25235195 \n Pulled By : cpojer \n fbshipit - source - id : ad2131aab4dfd17ab53b6a5720ed0e2f1b09cca4,235
". circleci \ config . yml \n - restore _ cache : \n - v4 - yarn - cache - { { arch } } - { { checksum "" yarn . lock "" } } \n - - v4 - yarn - cache - { { arch } } \n - run : \n - restore _ cache : \n - v3 - buck - v2019 . 01 . 10 . 01 - { { checksum "" scripts / circleci / buck _ fetch . sh "" } } } \n - - v3 - buck - v2019 . 01 . 10 . 01 - \n - run : \n - restore _ cache : \n - - v3 - pods - { { . Environment . CIRCLE _ JOB } } - { { checksum "" packages / rn - tester / Podfile . lock . bak "" } } \n - - v3 - pods - { { . Environment . CIRCLE _ JOB } } - \n + # The committed lockfile is generated using USE _ FRAMEWORKS = 0 and USE _ HERMES = 0 so it could load an outdated cache if a change \n + # only affects the frameworks or hermes config . To help prevent this also cache based on the content of Podfile . \n + - v3 - pods - { { . Environment . CIRCLE _ JOB } } - { { checksum "" packages / rn - tester / Podfile . lock . bak "" } } - { { checksum "" packages / rn - tester / Podfile "" } } \n - steps : < < parameters . steps > > \n - save _ cache : \n - packages / rn - tester / Pods \n - key : v3 - pods - { { . Environment . CIRCLE _ JOB } } - { { checksum "" packages / rn - tester / Podfile . lock . bak "" } } \n + key : v3 - pods - { { . Environment . CIRCLE _ JOB } } - { { checksum "" packages / rn - tester / Podfile . lock . bak "" } } - { { checksum "" packages / rn - tester / Podfile "" } } \n - restore _ cache : \n - v1 - gradle - { { checksum "" ReactAndroid / build . gradle "" } } - { { checksum "" scripts / circleci / gradle _ download _ deps . sh "" } } \n - - v1 - gradle - \n - run : \n - restore _ cache : \n - v1 - win - yarn - cache - { { arch } } - { { checksum "" yarn . lock "" } } \n - - v1 - win - yarn - cache - { { arch } } - \n - run : \n","Make dependencies cache more reliable on CI ( # 30534 ) \n Summary : \n I was looking into why CI was failing and could not reproduce locally , also noticed the errors seemed to come from old version of files being used , for example a missing symbol added in a JSI commit ~ 1 month ago . I noticed that we were using multiple cache keys for a lot of deps in the following format : \n ` ` ` \n - v3 - pods - { { . Environment . CIRCLE _ JOB } } - { { checksum "" packages / rn - tester / Podfile . lock . bak "" } } \n - v3 - pods - { { . Environment . CIRCLE _ JOB } } - \n ` ` ` \n This means that if the cache doesn ' t exist for the checksum of the lockfile it will get one for any other checksum . This can lead to loading old version of files that cocoapod / yarn probably doesn ' t detect and keeps instead of getting the proper version . To make things worst it then caches the broken dep package after . \n This removes all of these key fallbacks and use the cache only if we have a perfect match . This should make CI more reliable and fix random breaks after updating deps / pod configs . \n # # Changelog \n [ Internal ] [ Fixed ] - Make dependencies cache more reliable on CI \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30534 \n Test Plan : \n - Check that tests now pass when cache is bypassed \n - Check that it still passes with cache \n - Hope the issue stops happening the next time someone updates deps : ) \n Reviewed By : fkgozali \n Differential Revision : D25326131 \n Pulled By : hramos \n fbshipit - source - id : f21cdfca7b2456ac0edbdcce3f9eb0a828a9b977",235
RNTester \ RNTester \ AppDelegate . mm \n + [ bridge setRCTTurboModuleRegistry : _ turboModuleManager ] ; \n,Fix RNTester TurboModules loading ( # 29538 ) \n Summary : \n It is now required to call RCTBridge . setRCTTurboModuleRegistry for turbo modules to work properly on iOS . \n # # Changelog \n [ Internal ] [ Fix ] - Fix RNTester TurboModules loading \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 29538 \n Test Plan : Tested that images in RNTester now loads properly and Redbox module missing warning are gone . \n Reviewed By : JoshuaGross \n Differential Revision : D22884163 \n Pulled By : fkgozali \n fbshipit - source - id : daf2fccdb518ec4a382b80b7f7b02004405a7564,235
"template \ ios \ Podfile \n - use _ react _ native ! ( : path = > config [ "" reactNativePath "" ] ) \n + use _ react _ native ! ( : path = > config [ : reactNativePath ] ) \n",Fix passing react native path in Podfile template ( # 29285 ) \n Summary : \n Since https : / / github . com / react - native - community / cli / commit / e949e234b03fb65f8e4ed2706dfaa745aa59a14f # diff - d1800049b92343288bcbc1c484575058 the RN cli script returns an object with ` : reactNativePath ` instead of just JSON . Not super familiar with how objects / JSON works in ruby but using this syntax instead works . \n # # Changelog \n [ Fixed ] [ iOS ] - Fix passing react native path in Podfile template \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 29285 \n Test Plan : Tested in a project inside a monorepo using the latest version of RN CLI that the proper react - native path is now passed . \n Reviewed By : fkgozali \n Differential Revision : D23941162 \n Pulled By : hramos \n fbshipit - source - id : 0115412ec6d6bca101612d760dfc00cf89d97f1e,235
"scripts \ react - native - xcode . sh \n - mv "" $ BUNDLE _ FILE "" "" $ DEST / "" \n + cp "" $ BUNDLE _ FILE "" "" $ DEST / "" \n","Make sure js bundle still exists at bundle - output path ( # 30149 ) \n Summary : \n Since changes to support hermes on iOS the js bundled is moved away from the location where it is generated when calling metro . This causes issues with the RN sentry integration since it relies on intercepting this path to find the bundle file after running react - native - xcode . sh . Seems kind of like a hacky way to get the bundle location , but let ' s avoid breaking it . \n https : / / github . com / getsentry / sentry - cli / blob / master / src / commands / react _ native _ xcode . rs \n # # Changelog \n [ iOS ] [ Fixed ] - Make sure js bundle still exists at bundle - output path \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30149 \n Test Plan : \n Checked that the bundle file exists both at bundle - output path and in the . app . \n Checked that the sentry release script works . \n Reviewed By : cpojer \n Differential Revision : D24480115 \n Pulled By : appden \n fbshipit - source - id : c01c80d47ed54319f97063ec635c021552a95c22",235
"ReactAndroid \ src \ main \ java \ com \ facebook \ hermes \ reactexecutor \ HermesExecutor . java \n - super ( \n - config = = null \n - ? initHybridDefaultConfig ( ) \n - : initHybrid ( config . heapSizeMB , config . es6Proxy ) ) ; \n + super ( config = = null ? initHybridDefaultConfig ( ) : initHybrid ( config . heapSizeMB ) ) ; \n - private static native HybridData initHybrid ( long heapSizeMB , boolean es6Proxy ) ; \n + private static native HybridData initHybrid ( long heapSizeMB ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ hermes \ reactexecutor \ OnLoad . cpp \n - static : : hermes : : vm : : RuntimeConfig makeRuntimeConfig ( \n - jlong heapSizeMB , \n - bool es6Proxy ) { \n + static : : hermes : : vm : : RuntimeConfig makeRuntimeConfig ( jlong heapSizeMB ) { \n - . withES6Proxy ( es6Proxy ) \n - static jni : : local _ ref < jhybriddata > \n - initHybrid ( jni : : alias _ ref < jclass > , jlong heapSizeMB , bool es6Proxy ) { \n + static jni : : local _ ref < jhybriddata > initHybrid ( \n + jni : : alias _ ref < jclass > , \n + jlong heapSizeMB ) { \n - auto runtimeConfig = makeRuntimeConfig ( heapSizeMB , es6Proxy ) ; \n + auto runtimeConfig = makeRuntimeConfig ( heapSizeMB ) ; \n ReactAndroid \ src \ main \ java \ com \ facebook \ hermes \ reactexecutor \ RuntimeConfig . java \n - public boolean es6Proxy ; \n",Use default for hermes es6 proxy enabled ( # 30142 ) \n Summary : \n Proxy is now enabled by default in hermes 0 . 7 ( https : / / github . com / facebook / hermes / releases / tag / v0 . 7 . 0 ) . However we currently disable it because of the config we pass . \n This removes the config so proxy is now enabled . \n # # Changelog \n [ Android ] [ Changed ] - Use default for hermes es6 proxy enabled \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30142 \n Test Plan : Tested that proxy is now enabled ( typeof Proxy ! = = ' undefined ' ) with hermes 0 . 7 . \n Reviewed By : cpojer \n Differential Revision : D24494182 \n Pulled By : mhorowitz \n fbshipit - source - id : 7f8a506e2c436f2f1611e183ca22d33dc763643c,235
"ReactAndroid \ Android - prebuilt . mk \n - REACT _ ANDROID _ DIR : = $ ( LOCAL _ PATH ) \n - # TODO : Find a better way without pointing to ReactAndroid / build dir . \n - REACT _ ANDROID _ BUILD _ DIR : = $ ( REACT _ ANDROID _ DIR ) / build \n - \n packages \ rn - tester \ android \ app \ build . gradle \n - "" REACT _ ANDROID _ DIR = $ reactAndroidProjectDir "" \n + "" REACT _ ANDROID _ DIR = $ reactAndroidProjectDir "" , \n + "" REACT _ ANDROID _ BUILD _ DIR = $ reactAndroidBuildDir "" \n",More reliable way to get ReactAndroid build dir in Android - prebuilt . mk ( # 30222 ) \n Summary : \n Pass the ReactAndroid project build directory as a variable to the ndk build so it can be used instead of assuming that the build directory is under ReactAndroid / build . \n # # Changelog \n [ Internal ] \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30222 \n Test Plan : Tested in an app with a custom build directory \n Reviewed By : yungsters \n Differential Revision : D24560643 \n Pulled By : fkgozali \n fbshipit - source - id : cc65a70582f546ca2e2ca9fb6a2ff03ea70ca9d8,235
"ReactAndroid \ build . gradle \n - reactNativeRootDir = file ( "" $ rootDir "" ) \n + reactNativeRootDir = file ( "" $ projectDir / . . "" ) \n",Use $ projectDir instead of $ rootDir for ReactAndroid codegen ( # 30220 ) \n Summary : \n When working with RN installed from npm and a regular project structure ` $ rootDir ` won ' t be at the react - native package root . Instead we can use ` $ projectRoot ` which will always be the ReactAndroid folder . \n # # Changelog \n [ Android ] [ Internal ] - Use $ projectDir instead of $ rootDir for ReactAndroid codegen \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30220 \n Test Plan : Test building an app with RN as a regular dep with codegen enabled \n Reviewed By : hramos \n Differential Revision : D24560634 \n Pulled By : fkgozali \n fbshipit - source - id : 434d32f37e6f9d48a8c562655ceff7249bd056ce,235
"packages \ react - native - codegen \ scripts \ oss \ build . sh \n - pushd "" $ THIS _ DIR / . . / . . "" > / dev / null \n + CODEGEN _ DIR = "" $ THIS _ DIR / . . / . . "" \n - yarn install 2 > > ( grep - v ' ^ warning ' 1 > & 2 ) \n - yarn run build \n + rm - rf "" $ { CODEGEN _ DIR : ? } / lib "" "" $ { CODEGEN _ DIR : ? } / node _ modules "" \n - popd > / dev / null \n + YARN _ BINARY = "" $ { YARN _ BINARY : - $ ( command - v yarn ) } "" \n + \n + if [ [ "" $ FBSOURCE _ ENV "" - eq "" 1 "" ] ] ; then \n + # Custom FB - specific setup \n + pushd "" $ CODEGEN _ DIR "" > / dev / null \n + \n + "" $ YARN _ BINARY "" install 2 > > ( grep - v ' ^ warning ' 1 > & 2 ) \n + # Note : Within FBSOURCE _ ENV , this has to explicitly run build . \n + "" $ YARN _ BINARY "" run build \n + \n + popd > / dev / null \n + else \n + # Run yarn install in a separate tmp dir to avoid conflict with the rest of the repo . \n + # Note : OSS - only . \n + TMP _ DIR = $ ( mktemp - d ) \n + \n + cp - R "" $ CODEGEN _ DIR / . "" "" $ TMP _ DIR "" \n + \n + pushd "" $ TMP _ DIR "" > / dev / null \n + \n + # Note : this automatically runs build as well . \n + "" $ YARN _ BINARY "" install 2 > > ( grep - v ' ^ warning ' 1 > & 2 ) \n + \n + popd > / dev / null \n + \n + mv "" $ TMP _ DIR / lib "" "" $ TMP _ DIR / node _ modules "" "" $ CODEGEN _ DIR "" \n + rm - rf "" $ TMP _ DIR "" \n + fi \n","Build rn - codegen in a temporary directory ( # 30292 ) \n Summary : \n When running yarn install from the codegen directory it will reinstall all dependencies for the react - native workspace inside the react - native package . In my case this caused issues with metro because it would now have 2 copies of it ( node _ modules / metro and node _ modules / react - native / node _ modules / metro ) . \n To avoid this copy the react - native - codegen source in a temporary directory and yarn install from there , then copy the built files back . \n # # Changelog \n [ Internal ] - Build rn - codegen in a temporary directory \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 30292 \n Test Plan : Tested the script in an app with codegen enabled . Fresh install with rn - codegen not built , made sure no extra modules are installed under node _ modules / react - native / node _ modules . \n Reviewed By : yungsters \n Differential Revision : D24893216 \n Pulled By : fkgozali \n fbshipit - source - id : 2c372b755632ea6f50ad5d4562248612b349a9a6",235
React \ Views \ RefreshControl \ RCTRefreshControl . m \n + - ( void ) didMoveToWindow \n + { \n + [ super didMoveToWindow ] ; \n + \n + / / Since iOS 14 there seems to be a bug where refresh control becomes \n + / / visible if the view gets removed from window then added back again . \n + / / Calling endRefreshing fixes the layout . \n + if ( ! _ currentRefreshingState ) { \n + [ super endRefreshing ] ; \n + } \n + } \n + \n - ( void ) beginRefreshingProgrammatically \n,"Fix RefreshControl layout when removed from window ( # 31024 ) \n Summary : \n Since iOS 14 refresh control is sometimes visible when it shouldn ' t . It seems to happen when it is removed and added back to the window . This repros easily when using react - native - screens with react - navigation tabs . Inactive tabs are detached from the window to save resources . \n Calling endRefreshing when refresh control is added to the window fixes the layout . It will also be called on first mount where it is not necessary , but should be a no - op and didn ' t cause any issues . I also decided to call it for all ios versions , although it is only needed on iOS 14 + to avoid forking behavior more . \n # # Changelog \n [ iOS ] [ Fixed ] - Fix RefreshControl layout when removed from window \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 31024 \n Test Plan : \n Before : \n https : / / user - images . githubusercontent . com / 2677334 / 108666197 - 93ea5a80 - 74a4 - 11eb - 839b - 8a4916967bf8 . mov \n After : \n https : / / user - images . githubusercontent . com / 2677334 / 108666223 - 9ea4ef80 - 74a4 - 11eb - 8489 - 4e5d257299c8 . mov \n Reviewed By : shergin \n Differential Revision : D26590759 \n Pulled By : PeteTheHeat \n fbshipit - source - id : b8c06068a24446b261cbeb88ff166289724031f1",235
React \ Base \ RCTConvert . h \n - # if TARGET _ OS _ IPHONE & & WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE \n + # if TARGET _ OS _ IPHONE \n + ( UIDataDetectorTypes ) UIDataDetectorTypes : ( id ) json ; \n - # if TARGET _ OS _ IPHONE & & WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE \n + # if TARGET _ OS _ IPHONE \n + ( WKDataDetectorTypes ) WKDataDetectorTypes : ( id ) json ; \n React \ Base \ RCTConvert . m \n - # if WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE \n - # endif / / WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE \n React \ Base \ RCTDefines . h \n - \n - / * * \n - * Check if WebKit iOS 10 . 0 APIs are available . \n - * / \n - # define WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE _ _ has _ include ( < WebKit / WKAudiovisualMediaTypes . h > ) \n,Delete WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE \n Summary : \n Changelog : \n [ Internal ] [ Removed ] - Delete WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE because React Native doesn ' t support iOS 9 and WEBKIT _ IOS _ 10 _ APIS _ AVAILABLE would always be true . \n Reviewed By : PeteTheHeat \n Differential Revision : D22768504 \n fbshipit - source - id : 76dbf967260b26ee6c0a45d8ae099f137a3a4ec7,248
"React \ Fabric \ RCTSurfacePresenter . mm \n + \n + [ [ NSNotificationCenter defaultCenter ] addObserver : self \n + selector : @ selector ( _ handleContentSizeCategoryDidChangeNotification : ) \n + name : UIContentSizeCategoryDidChangeNotification \n + object : nil ] ; \n + - ( void ) _ handleContentSizeCategoryDidChangeNotification : ( NSNotification * ) notification \n + { \n + RCTScheduler * scheduler = [ self _ scheduler ] ; \n + \n + [ _ surfaceRegistry enumerateWithBlock : ^ ( NSEnumerator < RCTFabricSurface * > * enumerator ) { \n + for ( RCTFabricSurface * surface in enumerator ) { \n + LayoutContext layoutContext = RCTGetLayoutContext ( ) ; \n + \n + LayoutConstraints layoutConstraints = RCTGetLayoutConstraintsForSize ( surface . minimumSize , surface . maximumSize ) ; \n + \n + [ scheduler constraintSurfaceLayoutWithLayoutConstraints : layoutConstraints \n + layoutContext : layoutContext \n + surfaceId : surface . rootTag ] ; \n + } \n + } ] ; \n + } \n + \n - ( void ) schedulerDidFinishTransaction : ( MountingCoordinator : : Shared const & ) mountingCoordinator \n","Add UIContentSizeCategoryDidChangeNotification to re - render text \n Summary : \n Changelog : \n [ Internal ] - Add UIContentSizeCategoryDidChangeNotification to re - render text \n We don ' t need to restart the app to re - render text now , but we still need to swipe the screen or click on buttons to force to refresh . We may address this in the future . \n Reviewed By : PeteTheHeat \n Differential Revision : D22867293 \n fbshipit - source - id : 4747a45adc2bdc638cf7ef9c07a9484e48600583",248
"React \ Fabric \ Mounting \ ComponentViews \ View \ RCTViewComponentView . mm \n + - ( NSString * ) accessibilityValue \n + { \n + auto const & props = * std : : static _ pointer _ cast < ViewProps const > ( _ props ) ; \n + \n + / / Handle states which haven ' t already been handled . \n + if ( props . accessibilityState . checked = = AccessibilityState : : Checked ) { \n + return @ "" checked "" ; \n + } \n + if ( props . accessibilityState . checked = = AccessibilityState : : Unchecked ) { \n + return @ "" unchecked "" ; \n + } \n + if ( props . accessibilityState . checked = = AccessibilityState : : Mixed ) { \n + return @ "" mixed "" ; \n + } \n + if ( props . accessibilityState . expanded ) { \n + return @ "" expanded "" ; \n + } \n + if ( props . accessibilityState . busy ) { \n + return @ "" busy "" ; \n + } \n + \n + return nil ; \n + } \n + \n - ( NSArray < UIAccessibilityCustomAction * > * ) accessibilityCustomActions \n ReactCommon \ react \ renderer \ components \ view \ AccessibilityPrimitives . h \n - enum { Unchecked , Checked , Mixed } checked { Unchecked } ; \n + enum { Unchecked , Checked , Mixed , None } checked { None } ; \n ReactCommon \ react \ renderer \ components \ view \ accessibilityPropsConversions . h \n + } else { \n + result . checked = AccessibilityState : : None ; \n + } else { \n + result . checked = AccessibilityState : : None ; \n","Update accessibilityState prop \n Summary : \n Changelog : \n [ Internal ] - Add default value for accessibilityState "" checked "" and handle unhandled states . \n It is also work for the case that accessibilityRole = "" switch "" and accessibilityState is set . \n Reviewed By : sammy - SC \n Differential Revision : D22914427 \n fbshipit - source - id : 4767a21f3bd109019b57bc09918758a38fbdea93",248
"React \ Fabric \ Mounting \ ComponentViews \ View \ RCTViewComponentView . mm \n + / / Handle Switch . \n + if ( ( self . accessibilityTraits & AccessibilityTraitSwitch ) = = AccessibilityTraitSwitch ) { \n + if ( props . accessibilityState . checked = = AccessibilityState : : Checked ) { \n + return @ "" 1 "" ; \n + } else if ( props . accessibilityState . checked = = AccessibilityState : : Unchecked ) { \n + return @ "" 0 "" ; \n + } \n + } \n + \n React \ Fabric \ RCTConversions . h \n + UIAccessibilityTraits const AccessibilityTraitSwitch = 0x20000000000001 ; \n + \n + if ( ( accessibilityTraits & AccessibilityTraits : : Switch ) ! = AccessibilityTraits : : None ) { \n + result | = AccessibilityTraitSwitch ; \n + } \n ReactCommon \ react \ renderer \ components \ view \ AccessibilityPrimitives . h \n + Switch = ( 1 < < 16 ) , \n ReactCommon \ react \ renderer \ components \ view \ accessibilityPropsConversions . h \n - \n + if ( string = = "" switch "" ) { \n + result = AccessibilityTraits : : Switch ; \n + return ; \n + } \n","Add support for accessibilityRole = "" switch "" \n Summary : \n Changelog : \n [ Internal ] - Add support for accessibilityRole = "" switch "" \n Reviewed By : sammy - SC \n Differential Revision : D22906500 \n fbshipit - source - id : 81dfbfd56a24c89ffedc0fde5a63f7bdeed0c5db",248
"ReactCommon \ fabric \ components \ view \ ViewShadowNode . cpp \n - isColorMeaningful ( viewProps . shadowColor ) ; \n + isColorMeaningful ( viewProps . shadowColor ) | | \n + viewProps . importantForAccessibility ! = ImportantForAccessibility : : Auto ; \n ReactCommon \ fabric \ components \ view \ accessibility \ AccessibilityPrimitives . h \n + enum class ImportantForAccessibility { \n + Auto , \n + Yes , \n + No , \n + NoHideDescendants , \n + } ; \n + \n ReactCommon \ fabric \ components \ view \ accessibility \ AccessibilityProps . cpp \n + importantForAccessibility ( convertRawProp ( \n + rawProps , \n + "" importantForAccessibility "" , \n + sourceProps . importantForAccessibility , \n + ImportantForAccessibility : : Auto ) ) , \n ReactCommon \ fabric \ components \ view \ accessibility \ AccessibilityProps . h \n + ImportantForAccessibility importantForAccessibility { \n + ImportantForAccessibility : : Auto } ; \n ReactCommon \ fabric \ components \ view \ accessibility \ accessibilityPropsConversions . h \n + inline std : : string toString ( \n + const ImportantForAccessibility & importantForAccessibility ) { \n + switch ( importantForAccessibility ) { \n + case ImportantForAccessibility : : Auto : \n + return "" auto "" ; \n + case ImportantForAccessibility : : Yes : \n + return "" yes "" ; \n + case ImportantForAccessibility : : No : \n + return "" no "" ; \n + case ImportantForAccessibility : : NoHideDescendants : \n + return "" no - hide - descendants "" ; \n + } \n + } \n + \n + inline void fromRawValue ( \n + const RawValue & value , \n + ImportantForAccessibility & result ) { \n + auto string = ( std : : string ) value ; \n + if ( string = = "" auto "" ) { \n + result = ImportantForAccessibility : : Auto ; \n + return ; \n + } \n + if ( string = = "" yes "" ) { \n + result = ImportantForAccessibility : : Yes ; \n + return ; \n + } \n + if ( string = = "" no "" ) { \n + result = ImportantForAccessibility : : No ; \n + return ; \n + } \n + if ( string = = "" no - hide - descendants "" ) { \n + result = ImportantForAccessibility : : NoHideDescendants ; \n + return ; \n + } \n + abort ( ) ; \n + } \n + \n",Add ` importantForAccessibility ` to ` AccessibilityProps ` and wire with ` FormsStakingContext ` \n Summary : \n Changelog : \n [ iOS ] [ Added ] - Add ` importantForAccessibility ` to ` AccessibilityProps ` \n Reviewed By : shergin \n Differential Revision : D22490327 \n fbshipit - source - id : aec7ff64ea6ddfe29bad085b87d09906fa8ee029,248
"React \ Fabric \ Mounting \ ComponentViews \ Text \ RCTParagraphComponentAccessibilityProvider . mm \n - firstElement . accessibilityHint = @ "" Links and buttons are found , swipe right to move to them . "" ; \n + firstElement . accessibilityHint = @ "" Links and buttons are found , swipe to move to them . "" ; \n - ? @ "" One link found , swipe right to move to the link . "" \n - : [ NSString stringWithFormat : @ "" % ld links found , swipe right to move to the first link . "" , ( long ) numberOfLinks ] ; \n + ? @ "" One link found , swipe to move to the link . "" \n + : [ NSString stringWithFormat : @ "" % ld links found , swipe to move to the first link . "" , ( long ) numberOfLinks ] ; \n - ? @ "" One button found , swipe right to move to the button . "" \n - : [ NSString \n - stringWithFormat : @ "" % ld buttons found , swipe right to move to the first button . "" , ( long ) numberOfButtons ] ; \n + ? @ "" One button found , swipe to move to the button . "" \n + : [ NSString stringWithFormat : @ "" % ld buttons found , swipe to move to the first button . "" , ( long ) numberOfButtons ] ; \n",Reword the guide words \n Summary : \n Changelog : \n [ Internal ] - Reword the guide words to make it more generic . \n Considering the case that some languages are RTL so swiping right cannot guarantee to move to the link . iOS can handle the order of the words and accessibilityElements according to the language . But the accessibilityHint we hardcoded would be an issue . So we decided to reword it to be more generic . \n Reviewed By : PeteTheHeat \n Differential Revision : D22422498 \n fbshipit - source - id : 175711317961663d0b0b47e04d2ab600f63446fe,248
"React \ Fabric \ Mounting \ ComponentViews \ Text \ RCTParagraphComponentAccessibilityProvider . mm \n + if ( ! [ value isEqualToString : @ "" button "" ] & & ! [ value isEqualToString : @ "" link "" ] ) { \n + return ; \n + } \n","Add a condition to exclude accessibilityRole that not currently used \n Summary : \n Changelog : \n [ Internal ] - Add an condition to exclude accessibilityRole that not currently used \n Since I ' ve added all the possible values in accessibilityRole enum , it is necessary to gate what needs to be an accessibilityElement . SO I add a condition to exclude accessibilityRole that not currently used . \n Reviewed By : shergin \n Differential Revision : D22559136 \n fbshipit - source - id : 910d59132984872b5a9816b8e390117b7b1e2e71",248
ReactCommon \ fabric \ components \ text \ rawtext \ RawTextProps . h \n - const std : : string text { } ; \n + std : : string text { } ; \n,Remove const from text in RawTextProps \n Summary : \n Changelog : \n [ Internal ] - Remove const from text in RawTextProps \n Reviewed By : shergin \n Differential Revision : D22607120 \n fbshipit - source - id : 18f7ab716342c3e5a8e469b12c5437a617be8583,248
"React \ Tests \ Text \ RCTParagraphComponentViewTests . mm \n + - ( void ) testAttributedString \n + { \n + ParagraphShadowNode : : ConcreteState : : Shared _ stateA = stateWithShadowNode ( ParagrahShadowNodeA _ ) ; \n + RCTParagraphComponentView * paragraphComponentViewA = [ [ RCTParagraphComponentView alloc ] init ] ; \n + [ paragraphComponentViewA updateState : _ stateA oldState : nil ] ; \n + \n + ParagraphShadowNode : : ConcreteState : : Shared _ stateB = stateWithShadowNode ( ParagrahShadowNodeB _ ) ; \n + RCTParagraphComponentView * paragraphComponentViewB = [ [ RCTParagraphComponentView alloc ] init ] ; \n + [ paragraphComponentViewB updateState : _ stateB oldState : nil ] ; \n + \n + ParagraphShadowNode : : ConcreteState : : Shared _ stateC = stateWithShadowNode ( ParagrahShadowNodeC _ ) ; \n + RCTParagraphComponentView * paragraphComponentViewC = [ [ RCTParagraphComponentView alloc ] init ] ; \n + [ paragraphComponentViewC updateState : _ stateC oldState : nil ] ; \n + \n + / / Check the correctness of attributedString \n + XCTAssert ( [ [ paragraphComponentViewA . attributedText string ] \n + isEqual : @ "" Please check out facebook and instagram for a full description . "" ] ) ; \n + XCTAssertEqual ( _ stateA - > getData ( ) . attributedString . getFragments ( ) . size ( ) , 5 ) ; \n + \n + XCTAssert ( [ [ paragraphComponentViewB . attributedText string ] \n + isEqual : \n + @ "" Lorem ipsum dolor sit amet , consectetur adipiscing elit . Maecenas ut risus et sapien bibendum volutpat . Nulla facilisi . Cras imperdiet gravida tincidunt . In tempor , tellus et vestibulum venenatis , lorem nunc eleifend lectus , a consectetur magna augue at arcu . "" ] ) ; \n + XCTAssertEqual ( _ stateB - > getData ( ) . attributedString . getFragments ( ) . size ( ) , 2 ) ; \n + \n + XCTAssert ( [ [ paragraphComponentViewC . attributedText string ] \n + isEqual : \n + @ "" Lorem ipsum dolor sit amet , consectetur adipiscing elit . Maecenas ut risus et sapien bibendum volutpat . Nulla facilisi . Cras imperdiet gravida tincidunt . In tempor , tellus et vestibulum venenatis , lorem nunc eleifend lectus , a consectetur magna augue at arcu . See Less "" ] ) ; \n + XCTAssertEqual ( _ stateC - > getData ( ) . attributedString . getFragments ( ) . size ( ) , 3 ) ; \n + } \n + \n + # pragma mark - Accessibility \n + \n - ( void ) testAccessibilityMultipleLinks \n",Write tests to cover additional features in RCTParagraphComponentView \n Summary : \n Changelog : \n [ Internal ] - Add additional tests to cover other features in RCTParagraphComponentView . \n I mainly test the correctness of attributedString and fragments in the RCTParagraphComponentView . \n Reviewed By : shergin \n Differential Revision : D22668022 \n fbshipit - source - id : 6879eb6b6a6ace9e6e05f1486d4e4034ebfd73bc,248
"ReactCommon \ fabric \ components \ view \ accessibility \ AccessibilityPrimitives . h \n + enum { Unchecked , Checked , Mixed } checked { Unchecked } ; \n + bool busy { false } ; \n + bool expanded { false } ; \n - return lhs . disabled = = rhs . disabled & & lhs . selected = = rhs . selected ; \n + return lhs . disabled = = rhs . disabled & & lhs . selected = = rhs . selected & & \n + lhs . checked = = rhs . checked & & lhs . busy = = rhs . busy & & \n + lhs . expanded = = rhs . expanded ; \n ReactCommon \ fabric \ components \ view \ accessibility \ accessibilityPropsConversions . h \n + auto checked = map . find ( "" checked "" ) ; \n + if ( checked ! = map . end ( ) ) { \n + if ( checked - > second . hasType < std : : string > ( ) ) { \n + if ( ( std : : string ) checked - > second = = "" mixed "" ) { \n + result . checked = AccessibilityState : : Mixed ; \n + } \n + } else if ( checked - > second . hasType < bool > ( ) ) { \n + if ( ( bool ) checked - > second = = true ) { \n + result . checked = AccessibilityState : : Checked ; \n + } else { \n + result . checked = AccessibilityState : : Unchecked ; \n + } \n + } \n + } \n + auto busy = map . find ( "" busy "" ) ; \n + if ( busy ! = map . end ( ) ) { \n + fromRawValue ( busy - > second , result . busy ) ; \n + } \n + auto expanded = map . find ( "" expanded "" ) ; \n + if ( expanded ! = map . end ( ) ) { \n + fromRawValue ( expanded - > second , result . expanded ) ; \n + } \n","Add full support for AccessibilityState prop \n Summary : \n Changelog : [ Fabric ] [ iOS ] Add full support for AccessibilityState \n Since the AccessibilityState checked , busy or expanded only exist in Android and they don ' t have corresponding AccessibilityTrait to set , so we could just ignore the implementation in RCTViewComponentView . mm . What I did is to update the AccessibilityState values in AccessibilityPrimitives . h and accessibilityPropsConversions . h in order to enable further implementation in Android . \n Reviewed By : shergin \n Differential Revision : D22807584 \n fbshipit - source - id : f3ef048055d11314bc833357d8ca061e0fe219a4",248
"React \ Fabric \ Mounting \ ComponentViews \ Text \ RCTParagraphComponentAccessibilityProvider . mm \n - firstElement . accessibilityFrameInContainerSpace = _ view . bounds ; \n + firstElement . accessibilityFrame = UIAccessibilityConvertFrameToScreenCoordinates ( _ view . bounds , _ view ) ; \n - element . accessibilityFrameInContainerSpace = fragmentRect ; \n + element . accessibilityFrame = \n + UIAccessibilityConvertFrameToScreenCoordinates ( fragmentRect , self - > _ view ) ; \n","Fix the frame issue for truncated text \n Summary : \n Changelog : \n [ Internal ] - Fix the frame issue for truncated text . \n When double tapping to expand / truncate the text , the rect of the element always moves to the top and then come back to the original place . . This seems because after truncating / expanding the text , the view would re - render and the container would be destroyed . I used the API accessibilityFrameInContainerSpace to set the frame before . And the frame was not updated properly . Converting the bound to the screen coordinates and set accessibilityFrame directly fixed it . \n Reviewed By : PeteTheHeat \n Differential Revision : D23040295 \n fbshipit - source - id : 1b449c39c79007d5321ff7b565c170f6d3fab8a4",248
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - final String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + final String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 65927 "" / * place a PR link here when committing bwc changes * / \n server \ src \ main \ java \ org \ elasticsearch \ search \ internal \ ShardSearchRequest . java \n - if ( in . getVersion ( ) . before ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( in . getVersion ( ) . before ( Version . V _ 7 _ 11 _ 0 ) ) { \n - if ( asKey = = false & & out . getVersion ( ) . before ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( asKey = = false & & out . getVersion ( ) . before ( Version . V _ 7 _ 11 _ 0 ) ) { \n",Adapt version after backport ( # 65934 ) \n This commit adapts the version check for # 65706 in preparation of the backport in # 65927 . \n The bwc tests are also disabled to not fail the build before # 65927 gets merged .,250
"build . gradle \n - boolean bwc _ tests _ enabled = false \n - final String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 65927 "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = true \n + final String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n server \ src \ main \ java \ org \ elasticsearch \ search \ internal \ ShardSearchRequest . java \n - shardIndex = in . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ? in . readVInt ( ) : - 1 ; \n + shardIndex = in . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 11 _ 0 ) ? in . readVInt ( ) : - 1 ; \n - if ( out . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( out . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 11 _ 0 ) ) { \n",Reenable bwc tests after backport ( # 65954 ) \n reenable bwc tests after backport,250
"x - pack \ plugin \ eql \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ eql \ action \ AsyncEqlSearchActionIT . java \n + . setKeepAlive ( TimeValue . timeValueMinutes ( 10 ) ) \n + . setKeepAlive ( TimeValue . timeValueMinutes ( 10 ) ) \n - \n x - pack \ plugin \ eql \ src \ main \ java \ org \ elasticsearch \ xpack \ eql \ plugin \ TransportEqlAsyncGetResultAction . java \n - return new AsyncResultsService < > ( store , true , EqlSearchTask . class , \n + return new AsyncResultsService < > ( store , false , EqlSearchTask . class , \n","Fix "" resource not found "" exception on existing EQL async search ( # 65167 ) \n This change fixes the initialization of the async results service \n for the EQL get async action . The boolean that differentiates EQL \n from normal _ async _ search request is set incorrectly , which results \n in errors ( 404 ) when extending the keep alive of a running EQL search . \n Fixes # 65108",250
"server \ src \ main \ java \ org \ elasticsearch \ index \ query \ TermsSetQueryBuilder . java \n - private final IndexNumericFieldData field ; \n + private final String fieldName ; \n + private final IndexNumericFieldData fieldData ; \n - FieldValuesSource ( IndexNumericFieldData field ) { \n - this . field = field ; \n + FieldValuesSource ( IndexNumericFieldData fieldData ) { \n + this . fieldData = fieldData ; \n + this . fieldName = fieldData . getFieldName ( ) ; \n - return Objects . equals ( field , that . field ) ; \n + return Objects . equals ( fieldName , that . fieldName ) ; \n - return "" long ( "" + field + "" ) "" ; \n + return "" long ( "" + fieldName + "" ) "" ; \n - return Objects . hash ( field ) ; \n + return Objects . hash ( fieldName ) ; \n - SortedNumericDocValues values = field . load ( ctx ) . getLongValues ( ) ; \n + SortedNumericDocValues values = fieldData . load ( ctx ) . getLongValues ( ) ; \n server \ src \ test \ java \ org \ elasticsearch \ index \ query \ TermsSetQueryBuilderTests . java \n - @ Override \n - protected boolean builderGeneratesCacheableQueries ( ) { \n - return false ; \n - } \n server \ src \ test \ java \ org \ elasticsearch \ index \ query \ WrapperQueryBuilderTests . java \n + @ Override \n + protected boolean builderGeneratesCacheableQueries ( ) { \n + return false ; \n + } \n + \n test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ AbstractQueryTestCase . java \n + assertEquals ( "" two equivalent query builders lead to different lucene queries hashcode "" , \n + secondLuceneQuery . hashCode ( ) , firstLuceneQuery . hashCode ( ) ) ; \n - rewrite ( secondLuceneQuery ) , rewrite ( firstLuceneQuery ) ) ; \n + rewrite ( secondLuceneQuery ) , rewrite ( firstLuceneQuery ) ) ; \n",Fix cacheability of custom LongValuesSource in TermsSetQueryBuilder ( # 65367 ) \n This change fixes the equals and hashCode methods of the custom FieldValuesSource \n that is used internally to extract the value from a doc value field . \n Using the field data instance to check equality prevented the query to be cached in \n previous versions . Switching to the field name should make the query eligible for \n caching again .,250
"server \ src \ main \ java \ org \ elasticsearch \ index \ mapper \ AbstractPointGeometryFieldMapper . java \n - return Collections . emptyList ( ) ; \n - } \n - else { \n + return null ; \n + } else { \n server \ src \ test \ java \ org \ elasticsearch \ index \ mapper \ GeoPointFieldMapperTests . java \n - DocumentMapper mapper = createDocumentMapper ( fieldMapping ( b - > b . field ( "" type "" , "" geo _ point "" ) . field ( "" null _ value "" , "" 1 , 2 "" ) ) ) ; \n + DocumentMapper mapper = createDocumentMapper ( \n + fieldMapping ( b - > b . field ( "" type "" , "" geo _ point "" ) ) \n + ) ; \n + ParsedDocument doc = mapper . parse ( source ( b - > b . nullField ( "" field "" ) ) ) ; \n + assertThat ( doc . rootDoc ( ) . getField ( "" field "" ) , nullValue ( ) ) ; \n + assertThat ( doc . rootDoc ( ) . getFields ( FieldNamesFieldMapper . NAME ) . length , equalTo ( 0 ) ) ; \n + \n + mapper = createDocumentMapper ( \n + fieldMapping ( b - > b . field ( "" type "" , "" geo _ point "" ) . field ( "" doc _ values "" , false ) ) \n + ) ; \n + fieldMapper = mapper . mappers ( ) . getMapper ( "" field "" ) ; \n + assertThat ( fieldMapper , instanceOf ( GeoPointFieldMapper . class ) ) ; \n + \n + doc = mapper . parse ( source ( b - > b . nullField ( "" field "" ) ) ) ; \n + assertThat ( doc . rootDoc ( ) . getField ( "" field "" ) , nullValue ( ) ) ; \n + assertThat ( doc . rootDoc ( ) . getFields ( FieldNamesFieldMapper . NAME ) . length , equalTo ( 0 ) ) ; \n + \n + mapper = createDocumentMapper ( \n + fieldMapping ( b - > b . field ( "" type "" , "" geo _ point "" ) . field ( "" null _ value "" , "" 1 , 2 "" ) ) \n + ) ; \n + fieldMapper = mapper . mappers ( ) . getMapper ( "" field "" ) ; \n + assertThat ( fieldMapper , instanceOf ( GeoPointFieldMapper . class ) ) ; \n + \n - ParsedDocument doc = mapper . parse ( source ( b - > b . nullField ( "" field "" ) ) ) ; \n + doc = mapper . parse ( source ( b - > b . nullField ( "" field "" ) ) ) ; \n",Fix handling of null values in geo _ point ( # 65307 ) \n A bug was introduced in 7 . 10 that causes explicit ` null ` values to be indexed in the _ field _ names \n field . This change fixes this bug for newly ingested data but ` null ` values ingested with 7 . 10 will \n continue to match ` exists ` query so a reindex is required . \n Fixes # 65306,250
"x - pack \ plugin \ transform \ qa \ multi - node - tests \ src \ javaRestTest \ java \ org \ elasticsearch \ xpack \ transform \ integration \ continuous \ TransformContinuousIT . java \n + @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 66410 "" ) \n",[ CI ] Mute TransformContinuousIT . testContinousEvents ( # 66438 ) \n Relates # 66410,250
"build . gradle \n - boolean bwc _ tests _ enabled = true \n - String bwc _ tests _ disabled _ issue = "" "" / * place a PR link here when committing bwc changes * / \n + boolean bwc _ tests _ enabled = false \n + String bwc _ tests _ disabled _ issue = "" https : / / github . com / elastic / elasticsearch / pull / 67629 "" / * place a PR link here when committing bwc changes * / \n server \ src \ main \ java \ org \ elasticsearch \ index \ query \ TermsQueryBuilder . java \n - private static final Version VERSION _ STORE _ VALUES _ AS _ BYTES _ REFERENCE = Version . V _ 8 _ 0 _ 0 ; \n + private static final Version VERSION _ STORE _ VALUES _ AS _ BYTES _ REFERENCE = Version . V _ 7 _ 12 _ 0 ; \n",Adapt version check after backport ( # 67632 ) \n This change disables the backward compatibility tests until # 67629 is merged .,250
"x - pack \ plugin \ async - search \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ search \ AsyncSearchActionIT . java \n - import org . elasticsearch . action . ActionRequestValidationException ; \n - SubmitAsyncSearchRequest newReq = new SubmitAsyncSearchRequest ( indexName ) { \n - @ Override \n - public ActionRequestValidationException validate ( ) { \n - return null ; / / to use a small keep _ alive \n - } \n - } ; \n + SubmitAsyncSearchRequest newReq = new SubmitAsyncSearchRequest ( indexName ) ; \n - newReq . setWaitForCompletionTimeout ( TimeValue . timeValueMillis ( 1 ) ) . setKeepAlive ( TimeValue . timeValueSeconds ( 5 ) ) ; \n + newReq . setWaitForCompletionTimeout ( TimeValue . timeValueMillis ( 1 ) ) . setKeepAlive ( TimeValue . timeValueSeconds ( 1 ) ) ; \n x - pack \ plugin \ async - search \ src \ test \ java \ org \ elasticsearch \ xpack \ search \ SubmitAsyncSearchRequestTests . java \n - req . setKeepAlive ( TimeValue . timeValueSeconds ( randomIntBetween ( 1 , 59 ) ) ) ; \n + req . setKeepAlive ( TimeValue . timeValueMillis ( randomIntBetween ( 1 , 999 ) ) ) ; \n x - pack \ plugin \ core \ src \ main \ java \ org \ elasticsearch \ xpack \ core \ search \ action \ SubmitAsyncSearchRequest . java \n - public static long MIN _ KEEP _ ALIVE = TimeValue . timeValueMinutes ( 1 ) . millis ( ) ; \n + public static long MIN _ KEEP _ ALIVE = TimeValue . timeValueSeconds ( 1 ) . millis ( ) ; \n - addValidationError ( "" [ keep _ alive ] must be greater than 1 minute , got : "" + keepAlive . toString ( ) , validationException ) ; \n + addValidationError ( "" [ keep _ alive ] must be greater or equals than 1 second , got : "" + \n + keepAlive . toString ( ) , validationException ) ; \n",Async search keep alive validation ( # 67981 ) \n This commit changes the minimum value for the keep _ alive option of async searches to 1s . \n Closes # 67974,250
"x - pack \ plugin \ async - search \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ search \ AsyncSearchActionIT . java \n - import java . util . Collections ; \n - import java . util . concurrent . CountDownLatch ; \n - \n - @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 63948 "" ) \n - public void testRetryVersionConflict ( ) throws Exception { \n - SubmitAsyncSearchRequest request = new SubmitAsyncSearchRequest ( indexName ) ; \n - request . setWaitForCompletionTimeout ( TimeValue . timeValueMinutes ( 10 ) ) ; \n - request . setKeepOnCompletion ( true ) ; \n - AsyncSearchResponse response = submitAsyncSearch ( request ) ; \n - assertNotNull ( response . getSearchResponse ( ) ) ; \n - assertFalse ( response . isRunning ( ) ) ; \n - \n - List < Thread > threads = new ArrayList < > ( ) ; \n - CountDownLatch latch = new CountDownLatch ( 1 ) ; \n - List < Exception > exceptions = Collections . synchronizedList ( new ArrayList < > ( ) ) ; \n - for ( int i = 0 ; i < 2 ; i + + ) { \n - Runnable runnable = ( ) - > { \n - for ( int j = 0 ; j < 10 ; j + + ) { \n - try { \n - latch . await ( ) ; \n - getAsyncSearch ( response . getId ( ) , TimeValue . timeValueMinutes ( 10 ) ) ; \n - } catch ( Exception exc ) { \n - exceptions . add ( exc ) ; \n - } \n - } \n - } ; \n - Thread thread = new Thread ( runnable ) ; \n - thread . start ( ) ; \n - threads . add ( thread ) ; \n - } \n - latch . countDown ( ) ; \n - for ( Thread thread : threads ) { \n - thread . join ( ) ; \n - } \n - assertTrue ( exceptions . toString ( ) , exceptions . isEmpty ( ) ) ; \n - } \n",Remove flaky test for async search ( # 67982 ) \n This change removes a test that tries to simulate failures when indexing the response of an async search request . \n The test is flaky and doesn ' t simulate the errors correctly so it was disabled . This change removes it entirely \n since it doesn ' t add any value . \n Closes # 63948,250
"server \ src \ main \ java \ org \ elasticsearch \ search \ aggregations \ bucket \ terms \ StringTermsAggregatorFromFilters . java \n + if ( b . getDocCount ( ) < bucketCountThresholds . getShardMinDocCount ( ) ) { \n + continue ; \n + } \n + if ( b . getDocCount ( ) < bucketCountThresholds . getShardMinDocCount ( ) ) { \n + continue ; \n + } \n server \ src \ test \ java \ org \ elasticsearch \ search \ aggregations \ bucket \ terms \ TermsAggregatorTests . java \n + import java . util . Arrays ; \n + public void testStringShardMinDocCount ( ) throws IOException { \n + MappedFieldType fieldType = new KeywordFieldMapper . KeywordFieldType ( "" string "" , true , true , null ) ; \n + for ( TermsAggregatorFactory . ExecutionMode executionMode : TermsAggregatorFactory . ExecutionMode . values ( ) ) { \n + TermsAggregationBuilder aggregationBuilder = new TermsAggregationBuilder ( "" _ name "" ) \n + . field ( "" string "" ) \n + . executionHint ( executionMode . toString ( ) ) \n + . size ( 2 ) \n + . minDocCount ( 2 ) \n + . shardMinDocCount ( 2 ) \n + . order ( BucketOrder . key ( true ) ) ; \n + testCase ( aggregationBuilder , new MatchAllDocsQuery ( ) , iw - > { \n + / / force single shard / segment \n + iw . addDocuments ( Arrays . asList ( \n + doc ( fieldType , "" a "" , "" b "" ) , \n + doc ( fieldType , "" "" , "" c "" , "" d "" ) , \n + doc ( fieldType , "" b "" , "" d "" ) , \n + doc ( fieldType , "" b "" ) ) ) ; \n + } , ( InternalTerms < ? , ? > result ) - > { \n + assertEquals ( 2 , result . getBuckets ( ) . size ( ) ) ; \n + assertEquals ( "" b "" , result . getBuckets ( ) . get ( 0 ) . getKeyAsString ( ) ) ; \n + assertEquals ( 3L , result . getBuckets ( ) . get ( 0 ) . getDocCount ( ) ) ; \n + assertEquals ( "" d "" , result . getBuckets ( ) . get ( 1 ) . getKeyAsString ( ) ) ; \n + assertEquals ( 2L , result . getBuckets ( ) . get ( 1 ) . getDocCount ( ) ) ; \n + } , fieldType ) ; \n + } \n + } \n + \n",Terms aggs that run as filters ignore shard _ min _ doc _ count ( # 69323 ) \n This change handles ` shard _ min _ doc _ count ` for terms aggregation that run as filters . \n Closes # 69312,250
server \ src \ main \ java \ org \ elasticsearch \ search \ query \ QueryPhase . java \n + import org . elasticsearch . search . sort . FieldSortBuilder ; \n - if ( SortField . FIELD _ DOC . equals ( sField ) = = false ) return null ; \n - } else { \n + if ( SortField . FIELD _ DOC . equals ( sField ) = = false ) { \n + return null ; \n + } \n + } else if ( FieldSortBuilder . SHARD _ DOC _ FIELD _ NAME . equals ( sFieldName ) = = false ) { \n - if ( searchExecutionContext . getFieldType ( sFieldName ) = = null ) return null ; / / could be _ script sort that uses _ score \n + if ( searchExecutionContext . getFieldType ( sFieldName ) = = null ) { \n + return null ; / / could be _ script sort that uses _ score \n + } \n,Handle _ shard _ doc field for sort optimization ( # 69321 ) \n This commit ensures that the automatic tiebreaker ` _ shard _ doc ` does \n not disable sort optimization . \n Relates # 56828,250
"server \ src \ main \ java \ org \ elasticsearch \ common \ lucene \ search \ XMoreLikeThis . java \n - / * \n - * Copyright Elasticsearch B . V . and / or licensed to Elasticsearch B . V . under one \n - * or more contributor license agreements . Licensed under the Elastic License \n - * 2 . 0 and the Server Side Public License , v 1 ; you may not use this file except \n - * in compliance with , at your election , the Elastic License 2 . 0 or the Server \n - * Side Public License , v 1 . \n - * / \n - \n - / * \n - * Copyright 2004 - 2005 The Apache Software Foundation . \n - * \n - * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - * you may not use this file except in compliance with the License . \n - * You may obtain a copy of the License at \n + / * @ notice \n + * Licensed to the Apache Software Foundation ( ASF ) under one or more \n + * contributor license agreements . See the NOTICE file distributed with \n + * this work for additional information regarding copyright ownership . \n + * The ASF licenses this file to You under the Apache License , Version 2 . 0 \n + * ( the "" License "" ) ; you may not use this file except in compliance with \n + * the License . You may obtain a copy of the License at \n + * \n + * Modifications copyright ( C ) 2020 Elasticsearch B . V . \n + \n",Fix license for XMoreLikeThis ( # 68851 ),250
"server \ src \ main \ java \ org \ elasticsearch \ search \ sort \ ShardDocSortField . java \n - final DocComparator delegate = new DocComparator ( numHits , false , sortPos ) ; \n + final DocComparator delegate = new DocComparator ( numHits , getReverse ( ) , sortPos ) ; \n",Fix descending _ shard _ doc sort ( # 67239 ),250
"new file \n sample \ src \ main \ java \ uk \ co \ senab \ photoview \ sample \ HackyDrawerLayout . java \n + package uk . co . senab . photoview . sample ; \n + \n + import android . content . Context ; \n + import android . support . v4 . widget . DrawerLayout ; \n + import android . view . MotionEvent ; \n + \n + / * * \n + * Hacky fix for Issue # 4 and \n + * http : / / code . google . com / p / android / issues / detail ? id = 18990 \n + * < p / > \n + * ScaleGestureDetector seems to mess up the touch events , which means that \n + * ViewGroups which make use of onInterceptTouchEvent throw a lot of \n + * IllegalArgumentException : pointerIndex out of range . \n + * < p / > \n + * There ' s not much I can do in my code for now , but we can mask the result by \n + * just catching the problem and ignoring it . \n + * Created by John on 10 / 1 / 15 . \n + * / \n + public class HackyDrawerLayout extends DrawerLayout { \n + \n + public HackyDrawerLayout ( Context context ) { \n + super ( context ) ; \n + } \n + \n + @ Override \n + public boolean onInterceptTouchEvent ( MotionEvent ev ) { \n + try { \n + return super . onInterceptTouchEvent ( ev ) ; \n + } catch ( IllegalArgumentException e ) { \n + e . printStackTrace ( ) ; \n + return false ; \n + } \n + } \n + } \n",Create HackyDrawerLayout to demonstrate a fix for the onInterceptTouchEvent bug,254
library \ src \ main \ java \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n - if ( getScale ( ) < mMaxScale | | scaleFactor < 1f ) { \n + if ( ( getScale ( ) < mMaxScale | | scaleFactor < 1f ) & & ( getScale ( ) > mMinScale | | scaleFactor > 1f ) ) { \n,Clamp the min scale of the PhotoView the same way we are clamping the max scale so that we do not allow the user to continue to zoom the image out .,254
"build . gradle \n - mavenCentral ( ) \n + jcenter ( ) \n - classpath ' com . android . tools . build : gradle : 1 . 1 . 0 ' \n + classpath ' com . android . tools . build : gradle : 1 . 3 . 0 ' \n - version = VERSION _ NAME \n - group = GROUP \n - mavenCentral ( ) \n - } \n - \n - tasks . withType ( JavaCompile ) { \n - options . encoding = "" UTF - 8 "" \n - options . compilerArgs < < "" - Xlint : unchecked "" \n + jcenter ( ) \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 3 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 4 - all . zip \n library \ build . gradle \n - compile "" com . android . support : support - v4 : 22 . 0 . 0 "" \n + compile "" com . android . support : support - v4 : 23 . 0 . 1 "" \n - compileSdkVersion 22 \n - buildToolsVersion ' 22 . 0 . 1 ' \n + compileSdkVersion 23 \n + buildToolsVersion ' 23 . 0 . 1 ' \n - targetSdkVersion 22 \n + targetSdkVersion 23 \n library \ src \ main \ AndroidManifest . xml \n - < manifest xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n - package = "" uk . co . senab . photoview "" \n - android : versionCode = "" 122 "" \n - android : versionName = "" 1 . 2 . 2 - SHAPSHOT "" > \n + < manifest package = "" uk . co . senab . photoview "" > \n sample \ build . gradle \n - compileSdkVersion 22 \n - buildToolsVersion ' 22 . 0 . 1 ' \n + compileSdkVersion 23 \n + buildToolsVersion ' 23 . 0 . 1 ' \n - targetSdkVersion 22 \n + targetSdkVersion 23 \n","Update gradle , the support library , and project SDK",254
". travis . yml \n - jdk : openjdk7 \n + - platform - tools \n + - tools \n + \n + # The BuildTools version used by your project \n - build - tools - 23 . 0 . 1 \n - - extra - android - support \n - - extra - android - m2repository \n + \n + # The SDK version used to compile your project \n - android - 23 \n - licenses : \n - - ' . + ' \n - script : \n - - . / gradlew clean assemble check \n - branches : \n - only : \n - - master \n - - dev \n + \n + # Additional components \n + - extra - android - m2repository \n + \n + before _ script : \n + - chmod + x gradlew \n + \n + script : "" . / gradlew build "" \n README . md \n - Branch * * Dev * * : [ ! [ Build Status ] ( https : / / travis - ci . org / chrisbanes / PhotoView . png ? branch = dev ) ] ( https : / / travis - ci . org / chrisbanes / PhotoView ) \n + Branch * * Develop * * : [ ! [ Build Status ] ( https : / / travis - ci . org / chrisbanes / PhotoView . png ? branch = develop ) ] ( https : / / travis - ci . org / chrisbanes / PhotoView ) \n - PhotoView aims to help produce an easily usable implementation of a zooming Android ImageView . It is currently being used in [ photup ] ( https : / / play . google . com / store / apps / details ? id = uk . co . senab . photup ) . \n + PhotoView aims to help produce an easily usable implementation of a zooming Android ImageView . \n - Out of the box zooming , using multi - touch and double - tap . \n - Development happens in * * dev * * branch of this repository , and Pull Requests should be filled against that branch . \n + Development happens in * * develop * * branch of this repository , and Pull Requests should be filled against that branch . \n",Remove reference to photup in README since the app is no longer available . Rename development branch to ` develop ` to match Git flow .,254
"library \ src \ main \ java \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n - "" The ImageView ' s ScaleType has been changed since attaching a PhotoViewAttacher "" ) ; \n + "" The ImageView ' s ScaleType has been changed since attaching a PhotoViewAttacher . You should call setScaleType on the PhotoViewAttacher instead of on the ImageView "" ) ; \n",More clear messaging for if the user calls setScaleType on view directly,254
okhttp \ src \ main \ java \ okhttp3 \ OkHttpClient . java \n + / * * Sets the response cache to be used to read and write cached responses . * / \n,Add javadoc for cache call in the builder,254
"realm - annotations \ src \ main \ java \ io \ realm \ annotations \ RealmModule . java \n - * By default a Realm can stores all classes extending RealmObject in a project . However , if you want to restrict a \n - * Realm to only contain a subset of classes or want to share them between a library project and an app project you must \n + * By default a Realm can store all classes extending RealmObject in a project . However , if you want to restrict a \n + * Realm to only contain a subset of classes or want to share them between a library project and an app project , you must \n",Grammer for RealmModule docs ( # 4652 ),254
photoview \ src \ main \ java \ com \ github \ chrisbanes \ photoview \ PhotoView . java \n - attacher . update ( ) ; \n + if ( attacher ! = null ) { \n + attacher . update ( ) ; \n + } \n - attacher . update ( ) ; \n + if ( attacher ! = null ) { \n + attacher . update ( ) ; \n + } \n - attacher . update ( ) ; \n + if ( attacher ! = null ) { \n + attacher . update ( ) ; \n + } \n,Check existence of attacher when setting an image,254
"retrofit - adapters \ guava \ README . md \n - An ` Adapter ` for adapting [ Guava ] [ 1 ] types . \n + An ` Adapter ` for adapting [ Guava ] [ 1 ] ` ListenableFuture ` . \n retrofit - adapters \ java8 \ README . md \n - An ` Adapter ` for adapting [ Java8 ] [ 1 ] types . \n + An ` Adapter ` for adapting [ Java8 ] [ 1 ] ` CompletableFuture ` . \n retrofit - adapters \ rxjava \ README . md \n + Available types : \n + \n + * ` Observable < T > ` , ` Observable < Response < T > > ` , and ` Observable < Result < T > > ` where ` T ` is the body type . \n + * ` Single < T > ` , ` Single < Response < T > > ` , and ` Single < Result < T > > ` where ` T ` is the body type . \n + * ` Completable ` where response bodies are discarded . \n - - - - - - - - \n retrofit - adapters \ rxjava2 \ README . md \n + Available types : \n + \n + * ` Observable < T > ` , ` Observable < Response < T > > ` , and ` Observable < Result < T > > ` where ` T ` is the body type . \n + * ` Flowable < T > ` , ` Flowable < Response < T > > ` and ` Flowable < Result < T > > ` where ` T ` is the body type . \n + * ` Single < T > ` , ` Single < Response < T > > ` , and ` Single < Result < T > > ` where ` T ` is the body type . \n + * ` Maybe < T > ` , ` Maybe < Response < T > > ` , and ` Maybe < Result < T > > ` where ` T ` is the body type . \n + * ` Completable ` where response bodies are discarded . \n - - - - - - - - \n",Explain which types are supported for each adapter,254
photoview \ src \ main \ java \ com \ github \ chrisbanes \ photoview \ PhotoGestureDetector . java \n - if ( null ! = mVelocityTracker ) { \n + if ( mVelocityTracker ! = null ) { \n - if ( null ! = mVelocityTracker ) { \n + if ( mVelocityTracker ! = null ) { \n - if ( null ! = mVelocityTracker ) { \n + if ( mVelocityTracker ! = null ) { \n - if ( null ! = mVelocityTracker ) { \n + if ( mVelocityTracker ! = null ) { \n - if ( null ! = mVelocityTracker ) { \n + if ( mVelocityTracker ! = null ) { \n photoview \ src \ main \ java \ com \ github \ chrisbanes \ photoview \ PhotoViewAttacher . java \n - if ( null ! = mLongClickListener ) { \n + if ( mLongClickListener ! = null ) { \n - if ( null ! = displayRect ) { \n + if ( displayRect ! = null ) { \n - if ( null ! = parent ) { \n + if ( parent ! = null ) { \n - if ( null ! = parent ) { \n + if ( parent ! = null ) { \n - if ( null ! = mScaleChangeListener ) { \n + if ( mScaleChangeListener ! = null ) { \n - ViewParent parent = v . getParent ( ) ; \n + ViewParent parent = v . getParent ( ) ; \n - if ( null ! = rect ) { \n + if ( rect ! = null ) { \n - if ( null ! = mScaleDragDetector ) { \n + if ( mScaleDragDetector ! = null ) { \n - if ( null ! = mGestureDetector & & mGestureDetector . onTouchEvent ( ev ) ) { \n + if ( mGestureDetector ! = null & & mGestureDetector . onTouchEvent ( ev ) ) { \n - if ( null ! = mCurrentFlingRunnable ) { \n + if ( mCurrentFlingRunnable ! = null ) { \n - if ( null ! = d ) { \n + if ( d ! = null ) { \n - if ( null ! = displayRect ) { \n + if ( displayRect ! = null ) { \n - if ( null = = rect ) { \n + if ( rect = = null ) { \n sample \ src \ main \ java \ com \ github \ chrisbanes \ photoview \ sample \ SimpleSampleActivity . java \n - assert null ! = zoomToggle ; \n - \n - if ( null ! = mCurrentToast ) { \n + if ( mCurrentToast ! = null ) { \n,Update code style of null / nonnull checks,254
okhttp \ src \ main \ java \ okhttp3 \ Cache . java \n + / * * \n + * Create a cache of at most { @ code maxSize } bytes in { @ code directory } . \n + * / \n + / * * Max size of the cache ( in bytes ) . * / \n,Add some docs for Cache class ( # 4375 ) \n * Add some docs for cache \n * Correction to size getter \n * Update based on feedback,254
"retrofit \ src \ main \ java \ retrofit2 \ Response . java \n + checkNotNull ( body , "" body = = null "" ) ; \n + . body ( new OkHttpCall . NoContentResponseBody ( body . contentType ( ) , body . contentLength ( ) ) ) \n retrofit \ src \ test \ java \ retrofit2 \ ResponseTest . java \n + import okhttp3 . MediaType ; \n - ResponseBody errorBody = ResponseBody . create ( null , "" Broken ! "" ) ; \n + MediaType plainText = MediaType . get ( "" text / plain ; charset = utf - 8 "" ) ; \n + ResponseBody errorBody = ResponseBody . create ( plainText , "" Broken ! "" ) ; \n + assertThat ( response . raw ( ) . body ( ) . contentType ( ) ) . isEqualTo ( plainText ) ; \n + assertThat ( response . raw ( ) . body ( ) . contentLength ( ) ) . isEqualTo ( 7 ) ; \n + try { \n + response . raw ( ) . body ( ) . source ( ) ; \n + fail ( ) ; \n + } catch ( IllegalStateException expected ) { \n + } \n",Fix missing body in raw response for error \n ( cherry picked from commit 06978ccd683d9cb604769f0da3c64ad7d0a688a1 ),254
"retrofit \ src \ main \ java \ retrofit2 \ Response . java \n + checkNotNull ( body , "" body = = null "" ) ; \n + . body ( new OkHttpCall . NoContentResponseBody ( body . contentType ( ) , body . contentLength ( ) ) ) \n retrofit \ src \ test \ java \ retrofit2 \ ResponseTest . java \n + import okhttp3 . MediaType ; \n - ResponseBody errorBody = ResponseBody . create ( null , "" Broken ! "" ) ; \n + MediaType plainText = MediaType . get ( "" text / plain ; charset = utf - 8 "" ) ; \n + ResponseBody errorBody = ResponseBody . create ( plainText , "" Broken ! "" ) ; \n + assertThat ( response . raw ( ) . body ( ) . contentType ( ) ) . isEqualTo ( plainText ) ; \n + assertThat ( response . raw ( ) . body ( ) . contentLength ( ) ) . isEqualTo ( 7 ) ; \n + try { \n + response . raw ( ) . body ( ) . source ( ) ; \n + fail ( ) ; \n + } catch ( IllegalStateException expected ) { \n + } \n",Fix missing body in raw response for error,254
README . md \n - [ okhttp proguard ] : https : / / square . github . io / okhttp / # r8 - proguard \n + [ okhttp proguard ] : https : / / square . github . io / okhttp / r8 _ proguard / \n,Fix broken r8 / proguard link for OkHttp \n The link was just taking you to the top of the OkHttp page instead of the R8 / ProGuard section,254
"guava \ src \ com \ google \ common \ math \ LinearTransformation . java \n - return String . format ( "" NaN "" ) ; \n + return "" NaN "" ; \n",Remove redundant String . format call \n Fixes # 2584 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 134682786,259
"guava \ src \ com \ google \ common \ collect \ ArrayTable . java \n - / / Can change to use varargs in JDK 1 . 6 if we want \n - V [ ] [ ] copy = \n - ( V [ ] [ ] ) Array . newInstance ( valueClass , new int [ ] { rowList . size ( ) , columnList . size ( ) } ) ; \n + V [ ] [ ] copy = ( V [ ] [ ] ) Array . newInstance ( valueClass , rowList . size ( ) , columnList . size ( ) ) ; \n guava \ src \ com \ google \ common \ collect \ RegularImmutableSortedMultiset . java \n - RegularImmutableSortedSet < E > subElementSet = \n - ( RegularImmutableSortedSet < E > ) elementSet . getSubSet ( from , to ) ; \n + RegularImmutableSortedSet < E > subElementSet = elementSet . getSubSet ( from , to ) ; \n guava \ src \ com \ google \ common \ collect \ RegularImmutableSortedSet . java \n - return this . containsAll ( that ) ; \n + return containsAll ( that ) ; \n guava \ src \ com \ google \ common \ hash \ BloomFilter . java \n - IOException ioException = \n - new IOException ( \n - "" Unable to deserialize BloomFilter from InputStream . "" \n - + "" strategyOrdinal : "" \n - + strategyOrdinal \n - + "" numHashFunctions : "" \n - + numHashFunctions \n - + "" dataLength : "" \n - + dataLength ) ; \n - ioException . initCause ( e ) ; \n - throw ioException ; \n + String message = \n + "" Unable to deserialize BloomFilter from InputStream . "" \n + + "" strategyOrdinal : "" \n + + strategyOrdinal \n + + "" numHashFunctions : "" \n + + numHashFunctions \n + + "" dataLength : "" \n + + dataLength ; \n + throw new IOException ( message , e ) ; \n","Apply IntelliJ - suggested language feature migrations . \n All code which initializes an IOException with a cause exception now uses the appropriate constructor ( which was introduced in Java 6 ) , rather than initCause . Since Guava now depends on Java 6 , this is a safe change to make . \n Fixes # 2581 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 134684204",259
"guava \ src \ com \ google \ common \ base \ CaseFormat . java \n - : new StringBuilder ( word . length ( ) ) \n - . append ( Ascii . toUpperCase ( word . charAt ( 0 ) ) ) \n - . append ( Ascii . toLowerCase ( word . substring ( 1 ) ) ) \n - . toString ( ) ; \n + : Ascii . toUpperCase ( word . charAt ( 0 ) ) + Ascii . toLowerCase ( word . substring ( 1 ) ) ; \n guava \ src \ com \ google \ common \ collect \ GeneralRange . java \n - return new StringBuilder ( ) \n - . append ( comparator ) \n - . append ( "" : "" ) \n - . append ( lowerBoundType = = CLOSED ? ' [ ' : ' ( ' ) \n - . append ( hasLowerBound ? lowerEndpoint : "" - \ u221e "" ) \n - . append ( ' , ' ) \n - . append ( hasUpperBound ? upperEndpoint : "" \ u221e "" ) \n - . append ( upperBoundType = = CLOSED ? ' ] ' : ' ) ' ) \n - . toString ( ) ; \n + return comparator \n + + "" : "" \n + + ( lowerBoundType = = CLOSED ? ' [ ' : ' ( ' ) \n + + ( hasLowerBound ? lowerEndpoint : "" - \ u221e "" ) \n + + ' , ' \n + + ( hasUpperBound ? upperEndpoint : "" \ u221e "" ) \n + + ( upperBoundType = = CLOSED ? ' ] ' : ' ) ' ) ; \n guava \ src \ com \ google \ common \ collect \ SingletonImmutableList . java \n - String elementToString = element . toString ( ) ; \n - return new StringBuilder ( elementToString . length ( ) + 2 ) \n - . append ( ' [ ' ) \n - . append ( elementToString ) \n - . append ( ' ] ' ) \n - . toString ( ) ; \n + return ' [ ' + element . toString ( ) + ' ] ' ; \n guava \ src \ com \ google \ common \ collect \ SingletonImmutableSet . java \n - String elementToString = element . toString ( ) ; \n - return new StringBuilder ( elementToString . length ( ) + 2 ) \n - . append ( ' [ ' ) \n - . append ( elementToString ) \n - . append ( ' ] ' ) \n - . toString ( ) ; \n + return ' [ ' + element . toString ( ) + ' ] ' ; \n",Replace unnecessary StringBuilder calls with String concat \n Fixes # 2582 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 134687034,259
guava \ src \ com \ google \ common \ collect \ Collections2 . java \n - import static com . google . common . base . Predicates . in ; \n guava \ src \ com \ google \ common \ collect \ ImmutableSortedMap . java \n - import com . google . common . collect . ImmutableMap . Builder ; \n,Remove unused imports \n Fixes # 2583 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 134687038,259
"guava - tests \ test \ com \ google \ common \ base \ SplitterTest . java \n + @ GwtIncompatible / / java . util . regex . Pattern \n + public void testPatternSplitWordBoundary _ singleCharInput ( ) { \n + String string = "" f "" ; \n + Iterable < String > words = Splitter . on ( Pattern . compile ( "" \ \ b "" ) ) . split ( string ) ; \n + assertThat ( words ) . containsExactly ( "" f "" ) . inOrder ( ) ; \n + } \n + \n + @ AndroidIncompatible / / Apparently Gingerbread ' s regex API is buggy . \n + @ GwtIncompatible / / java . util . regex . Pattern \n + public void testPatternSplitWordBoundary _ singleWordInput ( ) { \n + String string = "" foo "" ; \n + Iterable < String > words = Splitter . on ( Pattern . compile ( "" \ \ b "" ) ) . split ( string ) ; \n + assertThat ( words ) . containsExactly ( "" foo "" ) . inOrder ( ) ; \n + } \n + \n guava \ src \ com \ google \ common \ base \ Splitter . java \n - if ( offset > = toSplit . length ( ) ) { \n + if ( offset > toSplit . length ( ) ) { \n","Fix # 1190 \n Before this fix , splitting a single character input string with a \n Splitter . onPattern instance created with a zero - width regex pattern , \n would have caused the input string to be dropped from the output , \n resulting in an empty iterable being returned rather than a single \n element one . \n This fix ensures that the input passes through untouched . \n For example , whereas before in this code snippet , ' words ' would have \n been initialized as an empty iterable . . . \n String string = "" f "" ; \n Iterable < String > words = \n Splitter . on ( Pattern . compile ( "" \ \ b "" ) ) . split ( string ) ; \n / / words is empty ! \n Fixes # 2615 , # 2086 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 137723825",259
guava \ src \ com \ google \ common \ collect \ ImmutableMapKeySet . java \n - import com . google . common . collect . ImmutableSet . Indexed ; \n guava \ src \ com \ google \ common \ collect \ Maps . java \n - import com . google . common . collect . Sets . ImprovedAbstractSet ; \n guava \ src \ com \ google \ common \ collect \ SingletonImmutableSet . java \n - import static com . google . common . base . Preconditions . checkNotNull ; \n - \n guava \ src \ com \ google \ common \ collect \ StandardTable . java \n - import com . google . common . collect . Table . Cell ; \n,Remove unused imports . \n Fixes # 2697 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 143186380,259
guava \ src \ com \ google \ common \ collect \ Maps . java \n - import com . google . common . collect . Maps . IteratorBasedAbstractMap ; \n - import com . google . common . collect . Maps . ViewCachingAbstractMap ; \n,Remove more unused imports . \n Fixes # 2698 \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 143270574,259
"android \ guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n - * < p > For example , to test { @ link java . util . ArrayList # iterator ( ) ArrayList . iterator ( ) } : \n + * < p > For example , to test { @ link java . util . Collections # unmodifiableList ( java . util . List ) \n + * Collections . unmodifiableList } ' s iterator : \n - * new ArrayList < > ( Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n + * Collections . unmodifiableList ( \n + * Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n - * IteratorFeature . MODIFIABLE , \n + * IteratorFeature . UNMODIFIABLE , \n - * KnownOrder . KNOWN _ ORDER ) { \n + * IteratorTester . KnownOrder . KNOWN _ ORDER ) { \n + * < p > < b > Note < / b > : It is necessary to use { @ code IteratorTester . KnownOrder } as shown above , rather \n + * than { @ code KnownOrder } directly , because otherwise the code is not compilable . \n + * \n guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n - * < p > For example , to test { @ link java . util . ArrayList # iterator ( ) ArrayList . iterator ( ) } : \n + * < p > For example , to test { @ link java . util . Collections # unmodifiableList ( java . util . List ) \n + * Collections . unmodifiableList } ' s iterator : \n - * new ArrayList < > ( Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n + * Collections . unmodifiableList ( \n + * Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n - * IteratorFeature . MODIFIABLE , \n + * IteratorFeature . UNMODIFIABLE , \n - * KnownOrder . KNOWN _ ORDER ) { \n + * IteratorTester . KnownOrder . KNOWN _ ORDER ) { \n + * < p > < b > Note < / b > : It is necessary to use { @ code IteratorTester . KnownOrder } as shown above , rather \n + * than { @ code KnownOrder } directly , because otherwise the code is not compilable . \n + * \n","Fix example in documentation for ` IteratorTester ` \n I made a mistake and accidentally included an example that does not \n compile . Specifically , importing ` KnownOrder ` as - is does not compile ; \n instead one needs to import ` IteratorTester . KnownOrder ` . See # 5254 for \n more information . \n I also changed the example to use ` Collections # unmodifiableList ` \n rather than ` ArrayList ` because ` ArrayList # iterator ` does not satisfy \n all the requirements of ` IteratorFeature # MODIFIABLE ` . \n Fixes # 5276 \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 336911192",259
"android \ guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n + * < p > The value you pass to the parameter { @ code steps } should be greater than the length of your \n + * iterator , so that this class can check that your iterator behaves correctly when it is exhausted . \n + * \n - * 5 , \n + * 6 , \n - * than { @ code KnownOrder } directly , because otherwise the code is not compilable . \n + * than { @ code KnownOrder } directly , because otherwise the code cannot be compiled . \n guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n + * < p > The value you pass to the parameter { @ code steps } should be greater than the length of your \n + * iterator , so that this class can check that your iterator behaves correctly when it is exhausted . \n + * \n - * 5 , \n + * 6 , \n - * than { @ code KnownOrder } directly , because otherwise the code is not compilable . \n + * than { @ code KnownOrder } directly , because otherwise the code cannot be compiled . \n","Update IteratorTester example with a greater "" steps "" value \n This allows IteratorTester to check the edge case that when an iterator has been exhausted ( that is , "" next "" has been called repeatedly until "" hasNext "" returns false ) then calling "" next "" on the iterator again exhibits the same behavior as the user ' s chosen "" known good "" reference implementation . \n Fixes # 5281 \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 337541752",259
"android \ guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n + * < p > For example , to test { @ link java . util . ArrayList # iterator ( ) ArrayList . iterator ( ) } : \n + * \n + * < pre > { @ code \n + * List < String > expectedElements = \n + * Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ; \n + * List < String > actualElements = \n + * new ArrayList < > ( Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n + * IteratorTester < String > iteratorTester = \n + * new IteratorTester < String > ( \n + * 5 , \n + * IteratorFeature . MODIFIABLE , \n + * expectedElements , \n + * KnownOrder . KNOWN _ ORDER ) { \n + * @ Override \n + * protected Iterator < String > newTargetIterator ( ) { \n + * return actualElements . iterator ( ) ; \n + * } \n + * } ; \n + * iteratorTester . test ( ) ; \n + * iteratorTester . testForEachRemaining ( ) ; \n + * } < / pre > \n + * \n guava - testlib \ src \ com \ google \ common \ collect \ testing \ IteratorTester . java \n + * < p > For example , to test { @ link java . util . ArrayList # iterator ( ) ArrayList . iterator ( ) } : \n + * \n + * < pre > { @ code \n + * List < String > expectedElements = \n + * Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ; \n + * List < String > actualElements = \n + * new ArrayList < > ( Arrays . asList ( "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ) ) ; \n + * IteratorTester < String > iteratorTester = \n + * new IteratorTester < String > ( \n + * 5 , \n + * IteratorFeature . MODIFIABLE , \n + * expectedElements , \n + * KnownOrder . KNOWN _ ORDER ) { \n + * @ Override \n + * protected Iterator < String > newTargetIterator ( ) { \n + * return actualElements . iterator ( ) ; \n + * } \n + * } ; \n + * iteratorTester . test ( ) ; \n + * iteratorTester . testForEachRemaining ( ) ; \n + * } < / pre > \n + * \n","Clarify how to use ` IteratorTester ` \n When using ` IteratorTester ` , IntelliJ IDEA automatically imports \n ` AbstractIteratorTester . KnownOrder ` . However ` AbstractIteratorTester ` \n is private , and it is not obvious that one was meant to import \n ` IteratorTester . KnownOrder ` instead . Therefore this commit updates the \n Javadoc to give an example of how to use the API properly . \n Fixes # 5272 \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 336716876",259
"src \ test \ java \ io \ vertx \ test \ core \ ClusteredEventBusStartFailureTest . java \n - String hostName = getClass ( ) . getSimpleName ( ) ; \n + String hostName = "" zoom . zoom . zen . tld "" ; \n",Fix ClusteredEventBusStartFailureTest \n On some networking configurations the CountDownLatch would expire . \n Using an improbable dotted hostname fixes the issue and makes the test pass .,277
NOTICE . md \n - * https : / / github . com / eclipse / vert . x \n + * https : / / github . com / eclipse - vertx / vert . x \n,Use the new https : / / github . com / eclipse - vertx / vert . x repositoy,277
"src \ test \ java \ io \ vertx \ core \ FutureTest . java \n - Thread thread = Thread . currentThread ( ) ; \n + Thread mainThread = Thread . currentThread ( ) ; \n - . thenAccept ( s - > { \n - assertEquals ( "" Yo "" , s ) ; \n - assertSame ( thread , Thread . currentThread ( ) ) ; \n + . thenAccept ( str - > { \n + assertEquals ( "" Yo "" , str ) ; \n + assertSame ( mainThread , Thread . currentThread ( ) ) ; \n - . whenComplete ( ( s , err ) - > { \n - assertNull ( s ) ; \n + . whenComplete ( ( str , err ) - > { \n + assertNull ( str ) ; \n - assertSame ( thread , Thread . currentThread ( ) ) ; \n + assertSame ( mainThread , Thread . currentThread ( ) ) ; \n + \n + @ Test \n + public void testToCompletionStageDelayedCompletion ( ) { \n + waitFor ( 2 ) ; \n + Thread mainThread = Thread . currentThread ( ) ; \n + Promise < String > willSucceed = Promise . promise ( ) ; \n + Promise < String > willFail = Promise . promise ( ) ; \n + \n + willSucceed . future ( ) . toCompletionStage ( ) . whenComplete ( ( str , err ) - > { \n + assertEquals ( "" Yo "" , str ) ; \n + assertNull ( err ) ; \n + assertNotSame ( mainThread , Thread . currentThread ( ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + willFail . future ( ) . toCompletionStage ( ) . whenComplete ( ( str , err ) - > { \n + assertNull ( str ) ; \n + assertTrue ( err instanceof RuntimeException ) ; \n + assertEquals ( "" Woops "" , err . getMessage ( ) ) ; \n + assertNotSame ( mainThread , Thread . currentThread ( ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + disableThreadChecks ( ) ; \n + new Thread ( ( ) - > willSucceed . complete ( "" Yo "" ) ) . start ( ) ; \n + new Thread ( ( ) - > willFail . fail ( new RuntimeException ( "" Woops "" ) ) ) . start ( ) ; \n + await ( 5 , SECONDS ) ; \n + } \n",CompletionStage delayed completion test \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
"src \ test \ java \ io \ vertx \ core \ FutureTest . java \n - import java . util . concurrent . CompletableFuture ; \n - import java . util . concurrent . CompletionStage ; \n - import java . util . concurrent . CountDownLatch ; \n - import java . util . concurrent . TimeUnit ; \n + import java . util . concurrent . * ; \n + \n + @ Test \n + public void testFromCompletionStageTrampolining ( ) { \n + waitFor ( 2 ) ; \n + disableThreadChecks ( ) ; \n + \n + AtomicReference < Thread > successSupplierThread = new AtomicReference < > ( ) ; \n + CompletableFuture < String > willSucceed = new CompletableFuture < > ( ) ; \n + \n + AtomicReference < Thread > failureSupplierThread = new AtomicReference < > ( ) ; \n + CompletableFuture < String > willFail = new CompletableFuture < > ( ) ; \n + \n + Future . from ( willSucceed ) . onSuccess ( str - > { \n + assertEquals ( "" Ok "" , str ) ; \n + assertSame ( successSupplierThread . get ( ) , Thread . currentThread ( ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + Future . from ( willFail ) . onFailure ( err - > { \n + assertTrue ( err instanceof RuntimeException ) ; \n + assertEquals ( "" Woops "" , err . getMessage ( ) ) ; \n + assertSame ( failureSupplierThread . get ( ) , Thread . currentThread ( ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + ForkJoinPool fjp = ForkJoinPool . commonPool ( ) ; \n + fjp . execute ( ( ) - > { \n + successSupplierThread . set ( Thread . currentThread ( ) ) ; \n + willSucceed . complete ( "" Ok "" ) ; \n + } ) ; \n + fjp . execute ( ( ) - > { \n + failureSupplierThread . set ( Thread . currentThread ( ) ) ; \n + willFail . completeExceptionally ( new RuntimeException ( "" Woops "" ) ) ; \n + } ) ; \n + \n + await ( 5 , SECONDS ) ; \n + } \n",Future from CompletionStage trampolining \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
"src \ test \ java \ io \ vertx \ core \ FutureTest . java \n + \n + @ Test \n + public void testFromCompletionStageWithContext ( ) { \n + waitFor ( 2 ) ; \n + Context context = vertx . getOrCreateContext ( ) ; \n + \n + AtomicReference < Thread > successSupplierThread = new AtomicReference < > ( ) ; \n + CompletableFuture < String > willSucceed = new CompletableFuture < > ( ) ; \n + \n + AtomicReference < Thread > failureSupplierThread = new AtomicReference < > ( ) ; \n + CompletableFuture < String > willFail = new CompletableFuture < > ( ) ; \n + \n + Future . from ( willSucceed , context ) . onSuccess ( str - > { \n + assertEquals ( "" Ok "" , str ) ; \n + assertNotSame ( successSupplierThread . get ( ) , Thread . currentThread ( ) ) ; \n + assertEquals ( context , vertx . getOrCreateContext ( ) ) ; \n + assertTrue ( Thread . currentThread ( ) . getName ( ) . startsWith ( "" vert . x - eventloop - thread "" ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + Future . from ( willFail , context ) . onFailure ( err - > { \n + assertTrue ( err instanceof RuntimeException ) ; \n + assertEquals ( "" Woops "" , err . getMessage ( ) ) ; \n + assertNotSame ( failureSupplierThread . get ( ) , Thread . currentThread ( ) ) ; \n + assertEquals ( context , vertx . getOrCreateContext ( ) ) ; \n + assertTrue ( Thread . currentThread ( ) . getName ( ) . startsWith ( "" vert . x - eventloop - thread "" ) ) ; \n + complete ( ) ; \n + } ) ; \n + \n + ForkJoinPool fjp = ForkJoinPool . commonPool ( ) ; \n + fjp . execute ( ( ) - > { \n + successSupplierThread . set ( Thread . currentThread ( ) ) ; \n + willSucceed . complete ( "" Ok "" ) ; \n + } ) ; \n + fjp . execute ( ( ) - > { \n + failureSupplierThread . set ( Thread . currentThread ( ) ) ; \n + willFail . completeExceptionally ( new RuntimeException ( "" Woops "" ) ) ; \n + } ) ; \n + \n + await ( 5 , SECONDS ) ; \n + } \n",Future from CompletionStage dispatch to Vert . x context \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
src \ main \ java \ io \ vertx \ core \ Future . java \n + / * * \n + * Bridges this Vert . x future to a { @ link CompletionStage } instance . \n + * < p > \n + * The { @ link CompletionStage } handling methods will be called from the thread that resolves this future . \n + * \n + * @ return a { @ link CompletionStage } that completes when this future resolves \n + * / \n + / * * \n + * Bridges a { @ link CompletionStage } object to a Vert . x future instance . \n + * < p > \n + * The Vert . x future handling methods will be called from the thread that completes { @ code completionStage } . \n + * \n + * @ param completionStage a completion stage \n + * @ param < T > the result type \n + * @ return a Vert . x future that resolves when { @ code completionStage } resolves \n + * / \n + / * * \n + * Bridges a { @ link CompletionStage } object to a Vert . x future instance . \n + * < p > \n + * The Vert . x future handling methods will be called from a thread attached to { @ code context } . \n + * \n + * @ param completionStage a completion stage \n + * @ param context a Vert . x context to dispatch to \n + * @ param < T > the result type \n + * @ return a Vert . x future that resolves when { @ code completionStage } resolves \n + * / \n,Javadocs \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
src \ main \ java \ io \ vertx \ core \ Future . java \n - * The Vert . x future handling methods will be called from a thread attached to { @ code context } . \n + * The Vert . x future handling methods will be called on the provided { @ code context } . \n,Update src / main / java / io / vertx / core / Future . java \n Co - Authored - By : Thomas Segismont < tsegismont @ gmail . com >,277
"src \ main \ asciidoc \ index . adoc \n + IMPORTANT : In most cases the variant with a ` CompletionStage ` and a ` Context ` is the one you will want to use to respect the Vert . x threading model , \n + since Vert . x ` Future ` are more likely to be used with Vert . x code , libraries and clients . \n + \n","Flag which "" from "" method to prefer \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >",277
"src \ main \ java \ examples \ CompletionStageInteropExamples . java \n + import java . util . UUID ; \n + private Future < String > storeInDb ( String key , String value ) { \n + return Future . succeededFuture ( "" Yo "" ) ; \n + } \n + \n + . flatMap ( str - > { \n + String key = UUID . randomUUID ( ) . toString ( ) ; \n + return storeInDb ( key , str ) ; \n + } ) \n","Improved "" from "" example with a flatMap \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >",277
"src \ main \ java \ io \ vertx \ core \ eventbus \ impl \ MessageConsumerImpl . java \n - Promise < Void > res = result ; \n + \n + Promise < Void > res = result ; / / Alias reference because result can become null when the onComplete callback executes \n - fut . onComplete ( ar - > { \n - res . tryFail ( "" blah "" ) ; \n - } ) ; \n + fut . onComplete ( ar - > res . tryFail ( "" blah "" ) ) ; \n + result = null ; \n src \ test \ java \ io \ vertx \ core \ eventbus \ EventBusFlowControlTest . java \n - import io . vertx . core . eventbus . DeliveryOptions ; \n - import io . vertx . core . eventbus . EventBus ; \n - import io . vertx . core . eventbus . MessageConsumer ; \n - import io . vertx . core . eventbus . MessageProducer ; \n + import io . vertx . core . streams . ReadStream ; \n - import java . util . concurrent . TimeUnit ; \n - consumer . handler ( msg - > { } ) ; \n + consumer . handler ( msg - > { \n + } ) ; \n + @ Test \n + public void testMessageConsumerUnregisterThenRegisterAgain ( ) { \n + String address = "" some - address "" ; \n + MessageConsumer < String > consumer = eb . consumer ( address ) ; \n + ReadStream < String > bodyStream = consumer . bodyStream ( ) ; \n + bodyStream . handler ( m1 - > { \n + assertEquals ( "" m1 "" , m1 ) ; \n + consumer . unregister ( ) ; \n + assertFalse ( "" Consumer is not registered "" , consumer . isRegistered ( ) ) ; \n + bodyStream . handler ( m2 - > { \n + assertEquals ( "" m2 "" , m2 ) ; \n + consumer . unregister ( ) ; \n + assertFalse ( "" Consumer is not registered "" , consumer . isRegistered ( ) ) ; \n + testComplete ( ) ; \n + } ) ; \n + assertTrue ( "" Consumer is registered "" , consumer . isRegistered ( ) ) ; \n + eb . send ( address , "" m2 "" ) ; \n + } ) ; \n + assertTrue ( "" Consumer is registered "" , consumer . isRegistered ( ) ) ; \n + eb . send ( address , "" m1 "" ) ; \n + await ( ) ; \n + } \n + \n",Bug when unregistering a message consumer and registering a handler again ( # 3343 ) \n * Reproducer for https : / / github . com / vert - x3 / vertx - rx / issues / 221 \n Signed - off - by : Julien Ponge < jponge @ redhat . com > \n * Test on the body stream \n Signed - off - by : Julien Ponge < jponge @ redhat . com > \n * Fix the unregister then set a new handler bug \n Signed - off - by : Julien Ponge < jponge @ redhat . com > \n * Further checks on the registration status \n Signed - off - by : Julien Ponge < jponge @ redhat . com >,277
"src \ test \ java \ io \ vertx \ core \ FutureTest . java \n - await ( 5 , SECONDS ) ; \n + await ( ) ; \n - await ( 5 , SECONDS ) ; \n + await ( ) ; \n - await ( 5 , SECONDS ) ; \n + await ( ) ; \n - await ( 5 , SECONDS ) ; \n + await ( ) ; \n",Just use await with default timeouts \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
"src \ main \ asciidoc \ index . adoc \n - - - - \n - We can conversely go from a ` CompletionStage ` to Vert . x ` Future ` using { @ link io . vertx . core . Future # from } . \n + We can conversely go from a ` CompletionStage ` to Vert . x ` Future ` using { @ link io . vertx . core . Future # fromCompletionStage } . \n src \ main \ java \ examples \ CompletionStageInteropExamples . java \n - Future . from ( completionStage , vertx . getOrCreateContext ( ) ) \n + Future . fromCompletionStage ( completionStage , vertx . getOrCreateContext ( ) ) \n src \ main \ java \ io \ vertx \ core \ Future . java \n - static < T > Future < T > from ( CompletionStage < T > completionStage ) { \n + static < T > Future < T > fromCompletionStage ( CompletionStage < T > completionStage ) { \n - static < T > Future < T > from ( CompletionStage < T > completionStage , Context context ) { \n + static < T > Future < T > fromCompletionStage ( CompletionStage < T > completionStage , Context context ) { \n src \ test \ java \ io \ vertx \ core \ FutureTest . java \n - import static java . util . concurrent . TimeUnit . SECONDS ; \n - \n - Future . from ( willSucceed ) . onSuccess ( str - > { \n + Future . fromCompletionStage ( willSucceed ) . onSuccess ( str - > { \n - Future . from ( willFail ) . onFailure ( err - > { \n + Future . fromCompletionStage ( willFail ) . onFailure ( err - > { \n - Future . from ( willSucceed , context ) . onSuccess ( str - > { \n + Future . fromCompletionStage ( willSucceed , context ) . onSuccess ( str - > { \n - Future . from ( willFail , context ) . onFailure ( err - > { \n + Future . fromCompletionStage ( willFail , context ) . onFailure ( err - > { \n",Rename from to fromCompletionStage \n Signed - off - by : Julien Ponge < julien . ponge @ gmail . com >,277
gradle \ buildscript . gradle \n - classpath ' gradle - release : gradle - release : 1 . 0pre ' \n + classpath ' gradle - release : gradle - release : 1 . 0 - SNAPSHOT ' \n gradle \ release . gradle \n - failOnCommitNeeded = false \n - failOnPublishNeeded = false \n - failOnUnversionedFiles = false \n - failOnUpdateNeeded = false \n + failOnCommitNeeded = true \n + failOnPublishNeeded = true \n + failOnUnversionedFiles = true \n + failOnUpdateNeeded = true \n + requireBranch = null \n,"Using custom build of release plugin , to support building from a branch",281
"build . gradle \n - group = ' com . netflix . osstemplate ' / / TEMPLATE : Set to organization of project \n + group = "" com . netflix . $ { githubProjectName } "" / / TEMPLATE : Set to organization of project \n",Make one less thing people have to change,281
"build . gradle \n - url "" https : / / github . com / Netflix / $ { rootProject . githubProjectName } "" \n - scm { \n - connection "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n - url "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n - developerConnection "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n - } \n - issueManagement { \n - system ' github ' \n - url ' https : / / github . com / Netflix / $ { rootProject . githubProjectName } / issues ' \n - } \n + url "" https : / / github . com / Netflix / $ { rootProject . githubProjectName } "" \n + scm { \n + connection "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n + url "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n + developerConnection "" scm : git : git @ github . com : Netflix / $ { rootProject . githubProjectName } . git "" \n + } \n + issueManagement { \n + system ' github ' \n + url ' https : / / github . com / Netflix / $ { rootProject . githubProjectName } / issues ' \n + } \n - testCompile ' org . mockito : mockito - core : 1 . 8 . 5 ' \n gradle \ maven . gradle \n - signing { \n - required { performingRelease & & gradle . taskGraph . hasTask ( "" uploadArchives "" ) } \n - sign configurations . archives \n + gradle . taskGraph . whenReady { taskGraph - > \n + if ( taskGraph . hasTask ( "" uploadMavenCentral "" ) ) { \n + signing { \n + required true \n + sign configurations . archives \n + } \n + } \n - task uploadArchives ( type : Upload ) { \n + task uploadMavenCentral ( type : Upload ) { \n - dependsOn signArchives \n + dependsOn ' signArchives ' \n",Avoid signatures in archives unless doing mavenCentral build,281
"gradle \ convention . gradle \n - classifier = ' sources ' \n - classifier = ' javadoc ' \n - / / Ensure output is on a new line \n - javadoc . doFirst { println "" "" } \n - \n + configurations . add ( ' sources ' ) \n + configurations . add ( ' javadoc ' ) \n - archives sourcesJar \n - archives javadocJar \n + sources ( sourcesJar ) { \n + type ' source ' \n + classifier ' sources ' \n + } \n + javadoc ( javadocJar ) { \n + type ' javadoc ' \n + classifier ' javadoc ' \n + } \n + \n + / / Ensure output is on a new line \n + javadoc . doFirst { println "" "" } \n + \n",Putting javadoc and sources into proper confs and setting types,281
"gradle \ convention . gradle \n + classifier ' sources ' \n + extension ' jar ' \n + classifier ' javadoc ' \n + extension ' jar ' \n + configurations . archives { \n + extendsFrom configurations . sources \n + extendsFrom configurations . javadoc \n + } \n + \n + / / When outputing to an Ivy repo , we want to use the proper type field \n + gradle . taskGraph . whenReady { \n + def isNotMaven = ! it . hasTask ( project . uploadMavenCentral ) \n + if ( isNotMaven ) { \n + def artifacts = project . configurations . sources . artifacts \n + def sourceArtifact = artifacts . iterator ( ) . next ( ) \n + sourceArtifact . type = ' sources ' \n + } \n + } \n - type ' source ' \n - classifier ' sources ' \n + / / Weird Gradle quirk where type will be used for the extension , but only for sources \n + type ' jar ' \n - classifier ' javadoc ' \n",Fixing issue when publishing source / javadoc to maven central,281
"gradle \ convention . gradle \n + configurations { \n + provided { \n + description = ' much like compile , but indicates you expect the JDK or a container to provide it . It is only available on the compilation classpath , and is not transitive . ' \n + transitive = false \n + visible = false \n + } \n + } \n + \n + project . sourceSets { \n + main . compileClasspath + = project . configurations . provided \n + main . runtimeClasspath - = project . configurations . provided \n + test . compileClasspath + = project . configurations . provided \n + test . runtimeClasspath + = project . configurations . provided \n + } \n",Adding provided scope \n Conflicts : \n gradle / convention . gradle,281
build . gradle \n - sourceSets { \n - test { \n - java { \n - srcDir ' src / main / java ' \n - } \n - } \n - } \n - / / Establish a provided scope \n - configurations { \n - provided { \n - description = ' Dependencies needed for compile but are provided at runtime or not needed ' \n - transitive = false \n - visible = false \n - } \n - compile . extendsFrom provided \n - } \n - sourceSets { \n - main . compileClasspath + = configurations . provided \n - main . runtimeClasspath - = configurations . provided \n - test . compileClasspath + = configurations . provided \n - } \n + sourceSets . test . java . srcDir ' src / main / java ' \n hystrix - contrib \ hystrix - metrics - event - stream \ build . gradle \n + provided ' junit : junit : 4 . 10 ' \n hystrix - examples \ build . gradle \n + provided ' junit : junit : 4 . 10 ' \n - } \n + } \n + \n,"Using gradle - template version of provided , fixing deps missing once provided was done \n Conflicts : \n hystrix - contrib / hystrix - metrics - event - stream / build . gradle",281
build . gradle \n - / / Establish a provided scope \n - configurations { \n - compile . extendsFrom provided \n + tasks . withType ( Javadoc ) . each { \n + it . classpath = sourceSets . main . compileClasspath \n - \n,"Use classpath , which is being changed by provided , instead of default",281
"hystrix - core \ build . gradle \n - javadoc { \n - / / the exclude isn ' t working , nor is there a subPackages options as docs suggest there should be \n - / / we do not want the com . netflix . hystrix . util package include \n - / / javadoc . exclude = [ ' * * / util / * * ' ] \n + javadoc { \n + / / the exclude isn ' t working , nor is there a subPackages options as docs suggest there should be \n + / / we do not want the com . netflix . hystrix . util package include \n + exclude ' * * / util / * * ' \n - javadoc . options . doclet = "" org . benjchristensen . doclet . DocletExclude "" \n - javadoc . options . docletpath = [ new File ( ' . / gradle / doclet - exclude . jar ' ) ] \n - javadoc . options . stylesheetFile = new File ( ' . / gradle / javadocStyleSheet . css ' ) \n - javadoc . options . windowTitle = "" Hystrix Javadoc 1 . 0 . x "" / / can this version come from a variable ? \n - / / The ' top ' option available on command - line appears to not exist via Gradle \n - / / javadoc . options . top = "" < h2 class = ' title ' > Hystrix : Latency and Fault Tolerance for Distributed Systems < / h2 > "" \n - } \n + options { \n + doclet = "" org . benjchristensen . doclet . DocletExclude "" \n + docletpath = [ rootProject . file ( ' . / gradle / doclet - exclude . jar ' ) ] \n + stylesheetFile = rootProject . file ( ' . / gradle / javadocStyleSheet . css ' ) \n + windowTitle = "" Hystrix Javadoc $ { project . version } "" \n + } \n + options . addStringOption ( ' top ' ) . value = ' < a href = "" https : / / github . com / Netflix / Hystrix "" > < img width = "" 92 "" height = "" 79 "" border = "" 0 "" align = "" left "" src = "" http : / / netflix . github . com / Hystrix / images / hystrix - logo - small . png "" > < / a > < h2 class = "" title "" style = "" padding - top : 40px "" > Hystrix : Latency and Fault Tolerance for Distributed Systems < / h2 > ' \n + } \n","NEBULA - 30 Fixing javadoc arguments . Using proper delegate in javadoc closure , add custom string option",281
"build . gradle \n + / / Prevent contrib project from being published \n + project ( ' hystrix - contrib ' ) . task ( ' uploadMavenCentral ' , overwrite : true ) { } \n",NEBULA - 28 Preventing contrib project from being uploaded,281
. gitignore \n + . m2 \n,NEBULA - 31 Ignore output from Gradle maven ant tasks,281
"gradle \ buildscript . gradle \n + classpath ' org . ajoberstar : gradle - git : 0 . 5 . 0 ' \n gradle \ convention . gradle \n - task aggregateJavadoc ( type : Javadoc ) { \n - description = ' Aggregate all subproject docs into a single docs directory ' \n - source subprojects . collect { project - > project . sourceSets . main . allJava } \n - classpath = files ( subprojects . collect { project - > project . sourceSets . main . compileClasspath } ) \n - destinationDir = new File ( projectDir , ' doc ' ) \n + apply plugin : ' github - pages ' / / Used to create publishGhPages task \n + \n + def docTasks = [ : ] \n + [ Javadoc , ScalaDoc , Groovydoc ] . each { Class docClass - > \n + def allSources = allprojects . tasks * . withType ( docClass ) . flatten ( ) * . source \n + if ( allSources ) { \n + def shortName = docClass . simpleName . toLowerCase ( ) \n + def docTask = task "" aggregate $ { shortName . capitalize ( ) } "" ( type : docClass , description : "" Aggregate subproject $ { shortName } s "" ) { \n + source = allSources \n + doFirst { \n + def classpaths = allprojects . findAll { it . plugins . hasPlugin ( JavaPlugin ) } . collect { it . sourceSets . main . compileClasspath } \n + classpath = files ( classpaths ) \n + } \n + } \n + docTasks [ shortName ] = docTask \n + processGhPages . dependsOn ( docTask ) \n + } \n + } \n + \n + githubPages { \n + repoUri = "" git @ github . com : quidryan / $ { rootProject . githubProjectName } . git "" \n + pages { \n + docTasks . each { shortName , docTask - > \n + from ( docTask . outputs . files ) { \n + into "" docs / $ { shortName } "" \n + } \n + } \n + } \n","Automatically aggregate and publish docs ( java , groovy , scala )",281
gradle \ release . gradle \n + task uploadMavenCentral ( dependsOn : subprojects . tasks . uploadMavenCentral ) \n,"Make uploadMavenCentral task , that encompasses other tasks",281
build . gradle \n - repositories { mavenRepo url : ' http : / / jcenter . bintray . com ' } \n + repositories { \n + mavenLocal ( ) \n + maven { url ' http : / / jcenter . bintray . com ' } \n + } \n - \n gradle \ buildscript . gradle \n - classpath ' nl . javadude . gradle . plugins : license - gradle - plugin : 0 . 6 . 0 ' \n + classpath ' nl . javadude . gradle . plugins : license - gradle - plugin : 0 . 6 . 1 ' \n gradle \ license . gradle \n + skipExistingHeaders true \n,Use newer version of license - gradle - plugin that fixes skipExistingHeaders field,281
build . gradle \n - repositories { mavenCentral ( ) } \n + repositories { mavenRepo url : ' http : / / jcenter . bintray . com ' } \n - repositories { mavenCentral ( ) } \n + repositories { mavenRepo url : ' http : / / jcenter . bintray . com ' } \n,Switching to bintray for dependencies ( same as Maven Central ),281
"gradle \ buildscript . gradle \n - classpath ' gradle - release : gradle - release : 1 . 1 . 4 ' \n + classpath ' gradle - release : gradle - release : 1 . 1 . 5 ' \n gradle \ convention . gradle \n - status = version . contains ( ' SNAPSHOT ' ) ? ' snapshot ' : status \n + / / GRADLE - 2087 workaround , perform after java plugin \n + status = project . hasProperty ( ' preferredStatus ' ) ? project . preferredStatus : ( version . contains ( ' SNAPSHOT ' ) ? ' snapshot ' : ' release ' ) \n gradle \ release . gradle \n - release . dependsOn ( forceCandidate ) \n + task forceRelease { \n + onlyIf { ! gradle . taskGraph . hasTask ( releaseCandidate ) } \n + doFirst { project . status = ' release ' } \n + } \n + release . dependsOn ( [ forceCandidate , forceRelease ] ) \n - / / Ensure upload happens before taggging but after all pre - checks \n - createReleaseTag . dependsOn ( [ uploadArtifactory , uploadMavenCentral ] ) \n + / / Ensure upload happens before taggging , hence upload failures will leave repo in a revertable state \n + preTagCommit . dependsOn ( [ uploadArtifactory , uploadMavenCentral ] ) \n + \n","Verify before we can ' t take it back , use preferredVersion variable",281
build . gradle \n + bintrayUpload . enabled = false \n,"rxproject isn ' t designed for multi - module projects , this change should avoid the unncessary publish of the root project",281
"presto - raptor \ src \ test \ java \ com \ facebook \ presto \ raptor \ integration \ TestRaptorIntegrationSmokeTest . java \n - assertUpdate ( "" CREATE TABLE test _ table _ stats ( x bigint ) WITH ( table _ supports _ delta _ delete = true ) "" ) ; \n + assertUpdate ( "" CREATE TABLE test _ table _ stats _ with _ delta _ delete ( x bigint ) WITH ( table _ supports _ delta _ delete = true ) "" ) ; \n - "" AND table _ name = ' test _ table _ stats ' "" ; \n + "" AND table _ name = ' test _ table _ stats _ with _ delta _ delete ' "" ; \n - assertUpdate ( "" INSERT INTO test _ table _ stats VALUES ( 1 ) , ( 2 ) , ( 3 ) , ( 4 ) "" , 4 ) ; \n + assertUpdate ( "" INSERT INTO test _ table _ stats _ with _ delta _ delete VALUES ( 1 ) , ( 2 ) , ( 3 ) , ( 4 ) "" , 4 ) ; \n - assertUpdate ( "" DELETE FROM test _ table _ stats WHERE x IN ( 2 , 4 ) "" , 2 ) ; \n + assertUpdate ( "" DELETE FROM test _ table _ stats _ with _ delta _ delete WHERE x IN ( 2 , 4 ) "" , 2 ) ; \n - assertUpdate ( "" ALTER TABLE test _ table _ stats ADD COLUMN y bigint "" ) ; \n + assertUpdate ( "" ALTER TABLE test _ table _ stats _ with _ delta _ delete ADD COLUMN y bigint "" ) ; \n - assertUpdate ( "" DROP TABLE test _ table _ stats "" ) ; \n + assertUpdate ( "" DROP TABLE test _ table _ stats _ with _ delta _ delete "" ) ; \n",Eliminate duplicate table name to avoid conflict in TestRaptorIntegrationSmokeTest,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ NodePartitioningManager . java \n - session . toConnectorSession ( ) , \n + session . toConnectorSession ( partitioningHandle . getConnectorId ( ) . get ( ) ) , \n",Fix null pointer when using ConnectorSession \n Using session . toConnectorSession ( ) causes FullConnectorSession \n to have properties as null,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n - createDynamicFilter ( node , context , partitionCount ) . ifPresent ( \n + createDynamicFilter ( buildSource , node , context , partitionCount ) . ifPresent ( \n - private Optional < LocalDynamicFilter > createDynamicFilter ( AbstractJoinNode node , LocalExecutionPlanContext context , int partitionCount ) \n + private Optional < LocalDynamicFilter > createDynamicFilter ( PhysicalOperation buildSource , AbstractJoinNode node , LocalExecutionPlanContext context , int partitionCount ) \n + checkState ( \n + buildSource . getPipelineExecutionStrategy ( ) ! = GROUPED _ EXECUTION , \n + "" Dynamic filtering cannot be used with grouped execution "" ) ; \n - Optional < LocalDynamicFilter > localDynamicFilter = createDynamicFilter ( node , context , partitionCount ) ; \n + Optional < LocalDynamicFilter > localDynamicFilter = createDynamicFilter ( buildSource , node , context , partitionCount ) ; \n",Add check that dynamic filtering is not enabled with grouped execution \n Dynamic filtering assumes that join build side is evaulated fixed \n ( task _ concurrency ) amount of times . This constraint is not satisfied \n when grouped execution is enabled . \n cherry - pick of : \n https : / / github . com / prestosql / presto / commit / 6782d7e0bbea34d6b89512a9391254fcf5a8e156 \n Co - Authored - By : Karol Sobczak < sopel39 @ users . noreply . github . com >,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ exchange \ LocalExchange . java \n - session . toConnectorSession ( ) , \n + session . toConnectorSession ( partitioning . getConnectorId ( ) . get ( ) ) , \n",Fix null pointer when creating ConnectorSession for LocalExchange,286
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveSplit . java \n - / / Use + 1 as secondary hash for now , would always get a diffrent position from the first hash . \n - / / When + 1 overflow , will circle back to starting point : Integer . MAX _ VALUE + 1 = = Integer . MIN _ VALUE \n + / / Use + 1 as secondary hash for now , would always get a different position from the first hash . \n + int size = sortedCandidates . size ( ) ; \n + int mod = path . hashCode ( ) % size ; \n + int position = mod < 0 ? mod + size : mod ; \n - sortedCandidates . get ( path . hashCode ( ) % sortedCandidates . size ( ) ) , \n - sortedCandidates . get ( ( path . hashCode ( ) + 1 ) % sortedCandidates . size ( ) ) ) ; \n + sortedCandidates . get ( position ) , \n + sortedCandidates . get ( ( position + 1 ) % size ) ) ; \n",Fix hash function for soft affnity in Hive,286
presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ BucketNodeMap . java \n + import java . util . List ; \n + public abstract boolean hasInitialMap ( ) ; \n + \n + \n + public abstract Optional < List < InternalNode > > getBucketToNode ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ FixedBucketNodeMap . java \n - public List < InternalNode > getBucketToNode ( ) \n + @ Override \n + public boolean hasInitialMap ( ) \n + { \n + return true ; \n + } \n + \n + @ Override \n + public Optional < List < InternalNode > > getBucketToNode ( ) \n - return bucketToNode ; \n + return Optional . of ( bucketToNode ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ SectionExecutionFactory . java \n - if ( ! bucketNodeMap . isDynamic ( ) ) { \n - stageNodeList = ( ( FixedBucketNodeMap ) bucketNodeMap ) . getBucketToNode ( ) . stream ( ) \n + if ( bucketNodeMap . hasInitialMap ( ) ) { \n + stageNodeList = bucketNodeMap . getBucketToNode ( ) . get ( ) . stream ( ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ group \ DynamicBucketNodeMap . java \n + import com . google . common . collect . ImmutableList ; \n + import org . checkerframework . checker . nullness . Opt ; \n + private final boolean hasInitialMap ; \n + hasInitialMap = false ; \n + this . hasInitialMap = true ; \n + \n + @ Override \n + public boolean hasInitialMap ( ) \n + { \n + return hasInitialMap ; \n + } \n + \n + @ Override \n + public Optional < List < InternalNode > > getBucketToNode ( ) \n + { \n + if ( bucketToNode . size ( ) = = 0 ) { \n + return Optional . empty ( ) ; \n + } \n + return Optional . of ( ImmutableList . copyOf ( bucketToNode . values ( ) ) ) ; \n + } \n,"Fix generated nodeList when using DynamicBucketNodeMap \n Instead of using random nodes for DynamicBucketNodeMap , \n when DynamicBucketNodeMap provides node lists , we directly use it",286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ split \ PageSourceManager . java \n + import com . facebook . presto . spi . FixedPageSource ; \n + import com . google . common . collect . ImmutableList ; \n + / / directly return the result if the given constraint is always false \n + if ( dynamicFilter . isPresent ( ) & & dynamicFilter . get ( ) . get ( ) . isNone ( ) ) { \n + return new FixedPageSource ( ImmutableList . of ( ) ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalDynamicFiltersCollector . java \n - import com . facebook . presto . spi . ColumnHandle ; \n - import com . facebook . presto . spi . plan . TableScanNode ; \n - import java . util . Map ; \n + import javax . annotation . concurrent . GuardedBy ; \n + import javax . annotation . concurrent . ThreadSafe ; \n + @ ThreadSafe \n + @ GuardedBy ( "" this "" ) \n - LocalDynamicFiltersCollector ( ) \n + public LocalDynamicFiltersCollector ( ) \n - synchronized void intersect ( TupleDomain < VariableReferenceExpression > predicate ) \n + public synchronized TupleDomain < VariableReferenceExpression > getPredicate ( ) \n - this . predicate = this . predicate . intersect ( predicate ) ; \n + return predicate ; \n - synchronized TupleDomain < ColumnHandle > get ( TableScanNode tableScan ) \n + public synchronized void intersect ( TupleDomain < VariableReferenceExpression > predicate ) \n - Map < VariableReferenceExpression , ColumnHandle > assignments = tableScan . getAssignments ( ) ; \n - / / Skips symbols irrelevant to this table scan node . \n - return predicate . transform ( assignments : : get ) ; \n + this . predicate = this . predicate . intersect ( predicate ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n - dynamicFilterSupplier = Optional . of ( ( ) - > collector . get ( tableScanNode ) ) ; \n + dynamicFilterSupplier = Optional . of ( ( ) - > { \n + TupleDomain < VariableReferenceExpression > predicate = collector . getPredicate ( ) ; \n + return predicate . transform ( tableScanNode . getAssignments ( ) : : get ) ; \n + } ) ; \n",Short circuit page source when dynamic filter is none and Clean up LocalDynamicFiltersCollector \n Cherry - pick of https : / / github . com / prestosql / presto / commit / a9cad2dda67a07588bc1cbf43901546bd4974f2d \n Cherry - pick of https : / / github . com / prestosql / presto / commit / cde503c22fd3c4579988303d17fe0939efec20f2 \n Co - Authored - By : James Sun < jamessun @ fb . com > \n Co - Authored - By : Dain Sundstrom < dain @ iq80 . com >,286
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveSplit . java \n + import com . facebook . presto . spi . PrestoException ; \n + import static com . facebook . presto . spi . StandardErrorCode . NO _ NODES _ AVAILABLE ; \n - throw new RuntimeException ( "" sortedCandidates is null or empty for HiveSplit "" ) ; \n + throw new PrestoException ( NO _ NODES _ AVAILABLE , "" sortedCandidates is null or empty for HiveSplit "" ) ; \n",Use NO _ NODES _ AVAILABLE Exception for affinity scheduler,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ nodeSelection \ SimpleNodeSelector . java \n - import java . util . ArrayList ; \n - candidateNodes = convertToInternalNode ( nodeMap , split . getPreferredNodes ( sortedCandidates ) ) ; \n + candidateNodes = selectExactNodes ( nodeMap , split . getPreferredNodes ( sortedCandidates ) , includeCoordinator ) ; \n - private static List < InternalNode > convertToInternalNode ( NodeMap nodeMap , List < HostAddress > preferredNodes ) \n - { \n - List < InternalNode > internalNodes = new ArrayList < > ( ) ; \n - preferredNodes . forEach ( node - > internalNodes . addAll ( nodeMap . getNodesByHostAndPort ( ) . get ( node ) ) ) ; \n - return ImmutableList . copyOf ( internalNodes ) ; \n - } \n - \n",Fix candiateNodes selection for Soft Affinity \n Use the same logic as HARD _ AFFINITY regarding candidates selection,286
"presto - raptor \ src \ main \ java \ com \ facebook \ presto \ raptor \ metadata \ SchemaDao . java \n - "" UNIQUE ( table _ id , bucket _ number , shard _ id , shard _ uuid , create _ time , row _ count , compressed _ size , uncompressed _ size , xxhash64 ) , \ n "" + \n + "" UNIQUE ( table _ id , bucket _ number , shard _ id , shard _ uuid , create _ time , row _ count , compressed _ size , uncompressed _ size , xxhash64 , is _ delta , delta _ uuid ) , \ n "" + \n",Include fields in delta delete to table index,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PredicatePushDown . java \n - DynamicFiltersResult dynamicFiltersResult = createDynamicFilters ( node , equiJoinClauses , session , idAllocator , metadata . getFunctionManager ( ) ) ; \n - Map < String , VariableReferenceExpression > dynamicFilters = dynamicFiltersResult . getDynamicFilters ( ) ; \n - leftPredicate = logicalRowExpressions . combineConjuncts ( leftPredicate , logicalRowExpressions . combineConjuncts ( dynamicFiltersResult . getPredicates ( ) ) ) ; \n - \n + \n + boolean dynamicFilterEnabled = isEnableDynamicFiltering ( session ) ; \n + Map < String , VariableReferenceExpression > dynamicFilters = ImmutableMap . of ( ) ; \n + if ( dynamicFilterEnabled ) { \n + DynamicFiltersResult dynamicFiltersResult = createDynamicFilters ( node , equiJoinClauses , idAllocator , metadata . getFunctionManager ( ) ) ; \n + dynamicFilters = dynamicFiltersResult . getDynamicFilters ( ) ; \n + leftPredicate = logicalRowExpressions . combineConjuncts ( leftPredicate , logicalRowExpressions . combineConjuncts ( dynamicFiltersResult . getPredicates ( ) ) ) ; \n + } \n + \n - if ( ! equiJoinClausesUnmodified & & isEnableDynamicFiltering ( session ) ) { \n + \n + if ( dynamicFilterEnabled & & ! equiJoinClausesUnmodified ) { \n - ! dynamicFilters . equals ( node . getDynamicFilters ( ) ) | | \n + ( dynamicFilterEnabled & & ! dynamicFilters . equals ( node . getDynamicFilters ( ) ) ) | | \n - Session session , \n - if ( node . getType ( ) = = INNER & & isEnableDynamicFiltering ( session ) ) { \n + if ( node . getType ( ) = = INNER ) { \n",Fix generation of dynamic filter \n 1 . Only create DynamicFilters when turned on to avoid unnecessary compute \n 2 . Add dynamicFilterEnabled check,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n + public static final String ENABLE _ DYNAMIC _ FILTERING = "" enable _ dynamic _ filtering "" ; \n - value - > value ! = null ? value . toString ( ) : null ) ) ; \n + value - > value ! = null ? value . toString ( ) : null ) , \n + booleanProperty ( \n + ENABLE _ DYNAMIC _ FILTERING , \n + "" Experimental : Enable dynamic filtering "" , \n + featuresConfig . isEnableDynamicFiltering ( ) , \n + false ) ) ; \n + \n + public static boolean isEnableDynamicFiltering ( Session session ) \n + { \n + return session . getSystemProperty ( ENABLE _ DYNAMIC _ FILTERING , Boolean . class ) ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n + private boolean enableDynamicFiltering ; \n + public boolean isEnableDynamicFiltering ( ) \n + { \n + return enableDynamicFiltering ; \n + } \n + \n + @ Config ( "" experimental . enable - dynamic - filtering "" ) \n + public FeaturesConfig setEnableDynamicFiltering ( boolean value ) \n + { \n + this . enableDynamicFiltering = value ; \n + return this ; \n + } \n + \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n + . setEnableDynamicFiltering ( false ) \n + . put ( "" experimental . enable - dynamic - filtering "" , "" true "" ) \n + . setEnableDynamicFiltering ( true ) \n",Add session properties for dynamic filtering \n Co - Authored - By : James Sun < jamessun @ fb . com > \n Co - Authored - By : Andrii Rosa < andriirosa @ fb . com >,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n + import com . facebook . presto . expressions . DynamicFilters ; \n + import com . facebook . presto . expressions . DynamicFilters . DynamicFilterExtractResult ; \n + import com . facebook . presto . expressions . DynamicFilters . DynamicFilterPlaceholder ; \n + import com . facebook . presto . expressions . LogicalRowExpressions ; \n + import com . facebook . presto . spi . relation . DeterminismEvaluator ; \n + import com . facebook . presto . sql . relational . FunctionResolution ; \n + private final LogicalRowExpressions logicalRowExpressions ; \n - JsonCodec < TableCommitContext > tableCommitContextCodec ) \n + JsonCodec < TableCommitContext > tableCommitContextCodec , \n + DeterminismEvaluator determinismEvaluator ) \n + this . logicalRowExpressions = new LogicalRowExpressions ( \n + requireNonNull ( determinismEvaluator , "" determinismEvaluator is null "" ) , \n + new FunctionResolution ( metadata . getFunctionManager ( ) ) , \n + metadata . getFunctionManager ( ) ) ; \n + Optional < DynamicFilterExtractResult > extractDynamicFilterResult = filterExpression . map ( DynamicFilters : : extractDynamicFilters ) ; \n + \n + / / Extract the static ones \n + filterExpression = extractDynamicFilterResult \n + . map ( DynamicFilterExtractResult : : getStaticConjuncts ) \n + . map ( logicalRowExpressions : : combineConjuncts ) ; \n + \n + / / TODO : Execution must be plugged in here \n + Optional < List < DynamicFilterPlaceholder > > dynamicFilters = extractDynamicFilterResult . map ( DynamicFilterExtractResult : : getDynamicConjuncts ) ; \n + if ( dynamicFilters . isPresent ( ) & & ! dynamicFilters . get ( ) . isEmpty ( ) ) { \n + / / translate filter function \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ testing \ LocalQueryRunner . java \n - jsonCodec ( TableCommitContext . class ) ) ; \n + jsonCodec ( TableCommitContext . class ) , \n + new RowExpressionDeterminismEvaluator ( metadata ) ) ; \n presto - main \ src \ test \ java \ com \ facebook \ presto \ execution \ TaskTestUtils . java \n + import com . facebook . presto . sql . relational . RowExpressionDeterminismEvaluator ; \n - jsonCodec ( TableCommitContext . class ) ) ; \n + jsonCodec ( TableCommitContext . class ) , \n + new RowExpressionDeterminismEvaluator ( metadata ) ) ; \n",Extract dynamic filters in LocalExecutionPlanner \n Co - Authored - By : James Sun < jamessun @ fb . com >,286
presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ FilteringPageSource . java \n + import com . facebook . presto . expressions . DynamicFilters ; \n + import static com . facebook . presto . expressions . DynamicFilters . extractDynamicFilters ; \n + import static com . facebook . presto . expressions . LogicalRowExpressions . and ; \n + \n + DynamicFilters . DynamicFilterExtractResult extractDynamicFilterResult = extractDynamicFilters ( expression ) ; \n + \n + / / dynamic filter will be added through subfield pushdown \n + expression = and ( extractDynamicFilterResult . getStaticConjuncts ( ) ) ; \n + \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcSelectivePageSourceFactory . java \n + import com . facebook . presto . expressions . DynamicFilters . DynamicFilterExtractResult ; \n + import static com . facebook . presto . expressions . DynamicFilters . extractDynamicFilters ; \n + import static com . facebook . presto . expressions . LogicalRowExpressions . and ; \n + DynamicFilterExtractResult extractDynamicFilterResult = extractDynamicFilters ( filter ) ; \n + \n + / / dynamic filter will be added through subfield pushdown \n + filter = and ( extractDynamicFilterResult . getStaticConjuncts ( ) ) ; \n + \n,Extract dynamic filters in Hive ORC reader \n Co - Authored - By : James Sun < jamessun @ fb . com > \n Co - Authored - By : Andrii Rosa < andriirosa @ fb . com >,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ aggregation \ TypedSet . java \n + import java . util . Optional ; \n + \n - static final long FOUR _ MEGABYTES = MAX _ FUNCTION _ MEMORY . toBytes ( ) ; \n + private final long maxBlockMemoryInBytes ; \n + { \n + this ( elementType , blockBuilder , expectedSize , functionName , Optional . of ( MAX _ FUNCTION _ MEMORY ) ) ; \n + } \n + \n + public TypedSet ( Type elementType , BlockBuilder blockBuilder , int expectedSize , String functionName , Optional < DataSize > maxBlockMemory ) \n + this . maxBlockMemoryInBytes = requireNonNull ( maxBlockMemory , "" maxBlockMemory must not be null "" ) . map ( DataSize : : toBytes ) . orElse ( Long . MAX _ VALUE ) ; \n - if ( elementBlock . getSizeInBytes ( ) - initialElementBlockSizeInBytes > FOUR _ MEGABYTES ) { \n + if ( elementBlock . getSizeInBytes ( ) - initialElementBlockSizeInBytes > maxBlockMemoryInBytes ) { \n presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ aggregation \ TestTypedSet . java \n - for ( int i = 0 ; i < = TypedSet . FOUR _ MEGABYTES + 1 ; i + + ) { \n + for ( int i = 0 ; i < = TypedSet . MAX _ FUNCTION _ MEMORY . toBytes ( ) + 1 ; i + + ) { \n",Allow creating unlimited TypedSet \n Existing constructors limit collected values to 4MB . \n Co - Authored - By : James Sun < jamessun @ fb . com > \n Co - Authored - By : Roman Zeyde < zeyde @ varada . io >,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ NodeScheduler . java \n + nodeSelectionStats , \n - BucketNodeMap bucketNodeMap ) \n + BucketNodeMap bucketNodeMap , \n + NodeSelectionStats nodeSelectionStats ) \n + nodeSelectionStats . incrementBucketedPreferredNodeSelectedCount ( ) ; \n + } \n + else { \n + nodeSelectionStats . incrementBucketedNonPreferredNodeSelectedCount ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ nodeSelection \ NodeSelectionStats . java \n + private final CounterStat bucketedPreferredNodeSelectedCount = new CounterStat ( ) ; \n + private final CounterStat bucketedNonPreferredNodeSelectedCount = new CounterStat ( ) ; \n + \n + public void incrementBucketedPreferredNodeSelectedCount ( ) \n + { \n + bucketedPreferredNodeSelectedCount . update ( 1 ) ; \n + } \n + \n + public void incrementBucketedNonPreferredNodeSelectedCount ( ) \n + { \n + bucketedNonPreferredNodeSelectedCount . update ( 1 ) ; \n + } \n + \n + \n + @ Managed \n + @ Nested \n + public CounterStat getBucketedPreferredNodeSelectedCount ( ) \n + { \n + return bucketedPreferredNodeSelectedCount ; \n + } \n + \n + @ Managed \n + @ Nested \n + public CounterStat getBucketedNonPreferredNodeSelectedCount ( ) \n + { \n + return bucketedNonPreferredNodeSelectedCount ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ nodeSelection \ SimpleNodeSelector . java \n - return selectDistributionNodes ( nodeMap . get ( ) . get ( ) , nodeTaskMap , maxSplitsPerNode , maxPendingSplitsPerTask , splits , existingTasks , bucketNodeMap ) ; \n + return selectDistributionNodes ( nodeMap . get ( ) . get ( ) , nodeTaskMap , maxSplitsPerNode , maxPendingSplitsPerTask , splits , existingTasks , bucketNodeMap , nodeSelectionStats ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ scheduler \ nodeSelection \ TopologyAwareNodeSelector . java \n + private final NodeSelectionStats nodeSelectionStats ; \n + NodeSelectionStats nodeSelectionStats , \n + this . nodeSelectionStats = requireNonNull ( nodeSelectionStats , "" nodeSelectionStats is null "" ) ; \n - return selectDistributionNodes ( nodeMap . get ( ) . get ( ) , nodeTaskMap , maxSplitsPerNode , maxPendingSplitsPerTask , splits , existingTasks , bucketNodeMap ) ; \n + return selectDistributionNodes ( nodeMap . get ( ) . get ( ) , nodeTaskMap , maxSplitsPerNode , maxPendingSplitsPerTask , splits , existingTasks , bucketNodeMap , nodeSelectionStats ) ; \n","Include scheduling stats of bucketed table to NodeSelectionStats \n Previously we only took scheduling for unbucketed situation into \n consideration for NodeSelectionStats , which is not sufficient . \n Now add scheduling stats for bucketed table to NodeSelectionStats \n as well .",286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n + import static com . facebook . presto . spi . StandardErrorCode . NOT _ SUPPORTED ; \n - checkState ( \n - buildSource . getPipelineExecutionStrategy ( ) ! = GROUPED _ EXECUTION , \n - "" Dynamic filtering cannot be used with grouped execution "" ) ; \n + if ( buildSource . getPipelineExecutionStrategy ( ) = = GROUPED _ EXECUTION ) { \n + throw new PrestoException ( NOT _ SUPPORTED , "" Dynamic filtering cannot be used with grouped execution "" ) ; \n + } \n",Do not support dynamic filtering with grouped - execution,286
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ rule \ HiveFilterPushdown . java \n - decomposedFilter . getRemainingExpression ( ) , \n + remainingExpression , \n",Fix query plan for dynamic filtering with filter pushed down,286
"presto - docs \ src \ main \ sphinx \ develop \ connectors . rst \n - - - - - - - - - - - - - - - - \n - Instances of your connecor splits . \n + Instances of your connecor splits . \n - The ` ` getNodeSelectionStrategy ` ` method indicates the node affinity \n + The ` ` getNodeSelectionStrategy ` ` method indicates the node affinity \n - The ` ` getPreferredNodes ` ` method provides a list of preferred nodes \n + The ` ` getPreferredNodes ` ` method provides a list of preferred nodes \n - The scheduler will respect the preference if the strategy is \n - HARD _ AFFINITY . Otherwise , the scheduler will prioritize the provided \n + The scheduler will respect the preference if the strategy is \n + HARD _ AFFINITY . Otherwise , the scheduler will prioritize the provided \n","Revert "" Update connectors . rst "" \n This reverts commit 0834046fc180310fa1b33f7f150ca15f201ad5d1 .",286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalDynamicFilter . java \n - import com . facebook . presto . sql . planner . plan . JoinNode ; \n + import com . facebook . presto . sql . planner . plan . AbstractJoinNode ; \n - public static Optional < LocalDynamicFilter > create ( JoinNode planNode , int partitionCount ) \n + public static Optional < LocalDynamicFilter > create ( AbstractJoinNode planNode , int partitionCount ) \n - . searchFrom ( planNode . getLeft ( ) ) \n + . searchFrom ( planNode . getProbe ( ) ) \n - PlanNode buildNode = planNode . getRight ( ) ; \n + PlanNode buildNode = planNode . getBuild ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n + import com . facebook . presto . sql . planner . plan . AbstractJoinNode ; \n - filter - > factoriesBuilder . add ( createDynamicFilterSourceOperatorFactory ( filter , node , buildSource , buildContext ) ) ) ; \n + filter - > factoriesBuilder . add ( createDynamicFilterSourceOperatorFactory ( filter , node . getId ( ) , buildSource , buildContext ) ) ) ; \n - JoinNode node , \n + PlanNodeId planNodeId , \n - node . getId ( ) , \n + planNodeId , \n - private Optional < LocalDynamicFilter > createDynamicFilter ( JoinNode node , LocalExecutionPlanContext context , int partitionCount ) \n + private Optional < LocalDynamicFilter > createDynamicFilter ( AbstractJoinNode node , LocalExecutionPlanContext context , int partitionCount ) \n + \n + ImmutableList . Builder < OperatorFactory > factoriesBuilder = ImmutableList . builder ( ) ; \n + factoriesBuilder . addAll ( buildSource . getOperatorFactories ( ) ) ; \n + \n + / / add collector to the source \n + int partitionCount = buildContext . getDriverInstanceCount ( ) . orElse ( 1 ) ; \n + Optional < LocalDynamicFilter > localDynamicFilter = createDynamicFilter ( node , context , partitionCount ) ; \n + localDynamicFilter . ifPresent ( filter - > factoriesBuilder . add ( createDynamicFilterSourceOperatorFactory ( filter , node . getId ( ) , buildSource , buildContext ) ) ) ; \n + \n + factoriesBuilder . add ( setBuilderOperatorFactory ) ; \n + \n - ImmutableList . < OperatorFactory > builder ( ) \n - . addAll ( buildSource . getOperatorFactories ( ) ) \n - . add ( setBuilderOperatorFactory ) \n - . build ( ) , \n + factoriesBuilder . build ( ) , \n",Implement dynamic filtering collection for semi join \n Co - Authored - By : James Sun < jamessun @ fb . com >,286
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ NodePartitionMap . java \n + private final boolean cacheable ; \n + this . cacheable = false ; \n - public NodePartitionMap ( List < InternalNode > partitionToNode , int [ ] bucketToPartition , ToIntFunction < Split > splitToBucket ) \n + public NodePartitionMap ( List < InternalNode > partitionToNode , int [ ] bucketToPartition , ToIntFunction < Split > splitToBucket , boolean cacheable ) \n + this . cacheable = cacheable ; \n - return new FixedBucketNodeMap ( splitToBucket , bucketToNode . build ( ) , false ) ; \n + return new FixedBucketNodeMap ( splitToBucket , bucketToNode . build ( ) , cacheable ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ NodePartitioningManager . java \n + boolean cacheable ; \n + bucketToNode = getFixedMapping ( connectorBucketNodeMap ) ; \n + cacheable = false ; \n + break ; \n + cacheable = true ; \n + cacheable = false ; \n - return new NodePartitionMap ( partitionToNode , bucketToPartition , getSplitToBucket ( session , partitioningHandle ) ) ; \n + return new NodePartitionMap ( partitionToNode , bucketToPartition , getSplitToBucket ( session , partitioningHandle ) , cacheable ) ; \n","Fix split cacheable setting for affinity scheduling \n As of now , when we schedule a scan for bucketed table which then joins with a remote , \n we don ' t set the cacheable to true even if we enable affinity scheduling",286
"presto - cache \ src \ main \ java \ com \ facebook \ presto \ cache \ alluxio \ AlluxioCacheConfig . java \n + private boolean cacheQuotaEnabled ; \n + \n + public boolean isCacheQuotaEnabled ( ) \n + { \n + return cacheQuotaEnabled ; \n + } \n + \n + @ Config ( "" cache . alluxio . quota - enabled "" ) \n + @ ConfigDescription ( "" Whether to enable quota for alluxio caching operations "" ) \n + public AlluxioCacheConfig setCacheQuotaEnabled ( boolean cacheQuotaEnabled ) \n + { \n + this . cacheQuotaEnabled = cacheQuotaEnabled ; \n + return this ; \n + } \n presto - cache \ src \ test \ java \ com \ facebook \ presto \ cache \ alluxio \ TestAlluxioCacheConfig . java \n - . setTimeoutThreads ( 64 ) ) ; \n + . setTimeoutThreads ( 64 ) \n + . setCacheQuotaEnabled ( false ) ) ; \n + . put ( "" cache . alluxio . quota - enabled "" , "" true "" ) \n - . setTimeoutThreads ( 512 ) ; \n + . setTimeoutThreads ( 512 ) \n + . setCacheQuotaEnabled ( true ) ; \n presto - hive - common \ src \ main \ java \ com \ facebook \ presto \ hive \ CacheQuota . java \n + private final String identity ; \n + this . identity = requireNonNull ( identity , "" identity is null "" ) ; \n + public String getIdentity ( ) \n + { \n + return identity ; \n + } \n + \n - return identifier = = that . identifier & & Objects . equals ( quota , that . quota ) ; \n + return identity . equals ( that . identity ) & & identifier = = that . identifier & & Objects . equals ( quota , that . quota ) ; \n - return Objects . hash ( identifier , quota ) ; \n + return Objects . hash ( identity , identifier , quota ) ; \n",Add extra information in CacheQuota for Alluxio to use,286
"CONTRIBUTING . md \n + \n + # # # Limitations \n + \n + The JUnit team is not accepting changes to the code under the following paths : \n + \n + * ` src / main / java / junit ` \n + * ` test / java / junit / tests / framework ` \n + * ` test / java / junit / tests / extensions ` \n + \n + The reasoning is that the JUnit team feels that our users should focus on using either the JUnit4 APIs \n + or the soon - to - be - released JUnit4 APIs . \n + \n + The team is also reluctant to accept changes that only update code from one code style to another . \n + Generally the code in JUnit was approved by at least one person , so two people agreed that the style was reasonable . \n + \n + To find other places where you can have an impact , please see the [ Issues tagged lowhanging ] ( https : / / github . com / junit - team / junit4 / issues ? q = is % 3Aissue + is % 3Aopen + label % 3Alowhanging ) . \n","Add "" Limitations "" section to CONTRIBUTING . md \n Document the kinds of changes we generally have not been accepting .",291
CONTRIBUTING . md \n - # # # Project License : Eclipse Public License v1 . 0 \n + # # Project License : Eclipse Public License v1 . 0 \n - You will only Submit Contributions where You have authored 100 % of the content . \n - You will only Submit Contributions to which You have the necessary rights . This means that if You are employed You have received the necessary permissions from Your employer to make the Contributions . \n - Whatever content You Contribute will be provided under the Project License ( s ) . \n - - - - \n + # # Coding Conventions \n - # # # How to submit a pull request \n + # # # Formatting \n + \n + See [ CODING _ STYLE . txt ] ( CODING _ STYLE . txt ) for how we format our code . \n + \n + # # How to submit a pull request \n - # # # Limitations \n + # # Limitations \n,Update CONTRIBUTING . md to link to the coding style,291
"CONTRIBUTING . md \n - To find other places where you can have an impact , please see the [ Issues tagged lowhanging ] ( https : / / github . com / junit - team / junit4 / issues ? q = is % 3Aissue + is % 3Aopen + label % 3Alowhanging ) . \n + To find other places where you can have an impact , please see the [ Issues tagged "" up - for - grabs "" ] ( https : / / github . com / junit - team / junit4 / issues ? q = is % 3Aissue + is % 3Aopen + label % 3Aup - for - grabs ) . \n","Fix link to up - for - grab issues \n We renamed the "" lowhanging "" tag to "" up - for - grabs "" ( to match the tag in the JUnit5 repository ) . This change updates the links to use the new tag .",291
new file \n . gitattributes \n + * text eol = lf \n + * . gif binary \n + * . GIF binary \n + * . jar binary \n + * . png binary \n + * . svg text eol = lf \n + \n + # These files do not have unix line endings . Do not normalize them for now . \n + # Will fix these right before we cut JUnit 4 . 13 . \n + / src / main / java / org / junit / experimental / categories / CategoryFilterFactory . java - text \n + / src / main / java / org / junit / experimental / categories / ExcludeCategories . java - text \n + / src / main / java / org / junit / experimental / categories / IncludeCategories . java - text \n + / src / main / java / org / junit / internal / Classes . java - text \n + / src / main / java / org / junit / runner / FilterFactories . java - text \n + / src / main / java / org / junit / runner / FilterFactory . java - text \n + / src / main / java / org / junit / runner / FilterFactoryParams . java - text \n + / src / main / java / org / junit / runner / JUnitCommandLineParseResult . java - text \n + / src / test / java / org / junit / experimental / categories / CategoryFilterFactoryTest . java - text \n + / src / test / java / org / junit / runner / FilterFactoriesTest . java - text \n + / src / test / java / org / junit / runner / JUnitCommandLineParseResultTest . java - text \n . gitignore \n - . gitattributes \n,Use Unix - style line endings . ( # 1405 ),291
"src \ main \ java \ org \ junit \ runners \ BlockJUnit4ClassRunner . java \n + import org . junit . validator . PublicClassValidator ; \n + import org . junit . validator . TestClassValidator ; \n + private static TestClassValidator PUBLIC _ CLASS _ VALIDATOR = new PublicClassValidator ( ) ; \n + validatePublicConstructor ( errors ) ; \n + private void validatePublicConstructor ( List < Throwable > errors ) { \n + if ( getTestClass ( ) . getJavaClass ( ) ! = null ) { \n + errors . addAll ( PUBLIC _ CLASS _ VALIDATOR . validateTestClass ( getTestClass ( ) ) ) ; \n + } \n + } \n + \n src \ main \ java \ org \ junit \ runners \ ParentRunner . java \n - import org . junit . validator . PublicClassValidator ; \n - private static final List < TestClassValidator > VALIDATORS = Arrays . asList ( \n - new AnnotationsValidator ( ) , new PublicClassValidator ( ) ) ; \n + private static final List < TestClassValidator > VALIDATORS = Arrays . < TestClassValidator > asList ( \n + new AnnotationsValidator ( ) ) ; \n src \ test \ java \ org \ junit \ tests \ running \ classes \ ParentRunnerTest . java \n - import static org . hamcrest . CoreMatchers . equalTo ; \n + \n + @ Test \n + public void alwaysPasses ( ) { } \n src \ test \ java \ org \ junit \ tests \ running \ classes \ SuiteTest . java \n + import static org . hamcrest . CoreMatchers . containsString ; \n + @ RunWith ( Suite . class ) \n + @ SuiteClasses ( TestA . class ) \n + static class NonPublicSuite { \n + } \n + \n + @ RunWith ( Suite . class ) \n + @ SuiteClasses ( TestA . class ) \n + static class NonPublicSuiteWithBeforeClass { \n + @ BeforeClass \n + public static void doesNothing ( ) { } \n + } \n + \n + @ Test \n + public void suiteClassDoesNotNeedToBePublic ( ) { \n + JUnitCore core = new JUnitCore ( ) ; \n + Result result = core . run ( NonPublicSuite . class ) ; \n + assertEquals ( 1 , result . getRunCount ( ) ) ; \n + assertEquals ( 0 , result . getFailureCount ( ) ) ; \n + } \n + \n + @ Test \n + public void nonPublicSuiteClassWithBeforeClassFailsWithoutRunningTests ( ) { \n + assertThat ( testResult ( NonPublicSuiteWithBeforeClass . class ) , hasSingleFailureContaining ( "" can not access "" ) ) ; \n + } \n + \n",Classes annotated with @ RunWith ( Suite . class ) do not need to be public . ( # 1408 ) \n This fixes a regression in JUnit 4 . 12 introduced by \n https : / / github . com / junit - team / junit4 / commit / 1d97da7 .,291
src \ main \ java \ org \ junit \ internal \ requests \ ClassRequest . java \n + import java . util . concurrent . locks . Lock ; \n + import java . util . concurrent . locks . ReentrantLock ; \n + \n - private final Object runnerLock = new Object ( ) ; \n + private final Lock runnerLock = new ReentrantLock ( ) ; \n - synchronized ( runnerLock ) { \n + runnerLock . lock ( ) ; \n + try { \n + } finally { \n + runnerLock . unlock ( ) ; \n src \ main \ java \ org \ junit \ runners \ ParentRunner . java \n + import java . util . concurrent . locks . Lock ; \n + import java . util . concurrent . locks . ReentrantLock ; \n - private final Object childrenLock = new Object ( ) ; \n + private final Lock childrenLock = new ReentrantLock ( ) ; \n - synchronized ( childrenLock ) { \n + childrenLock . lock ( ) ; \n + try { \n + } finally { \n + childrenLock . unlock ( ) ; \n - synchronized ( childrenLock ) { \n + childrenLock . lock ( ) ; \n + try { \n + } finally { \n + childrenLock . unlock ( ) ; \n - synchronized ( childrenLock ) { \n + childrenLock . lock ( ) ; \n + try { \n + } finally { \n + childrenLock . unlock ( ) ; \n,"Replace uses of synchronized ( something ) with ReentrantLock . ( # 1343 ) \n In almost all cases , this is more efficent , especially if there is any \n contention on the locks .",291
"src \ test \ java \ org \ junit \ tests \ experimental \ AssumptionTest . java \n - assertEquals ( failures . size ( ) , 1 ) ; \n + assertEquals ( 1 , failures . size ( ) ) ; \n",Fix incorrectly - ordered arguments in call to assertEquals ( ) . ( # 1456 ),291
"pom . xml \n - < excludePackageNames > junit . * , * . internal . * < / excludePackageNames > \n + < excludePackageNames > * . internal . * < / excludePackageNames > \n",Generate Javadoc for the junit . * packages . ( # 1477 ) \n Fixes # 81,291
"src \ main \ java \ org \ junit \ experimental \ categories \ CategoryFilterFactory . java \n - Class < ? > categoryClass = Classes . getClass ( category ) ; \n + / * \n + * Load the category class using the context class loader . \n + * If there is no context class loader , use the class loader for this class . \n + * / \n + Class < ? > categoryClass = Classes . getClass ( category , getClass ( ) ) ; \n src \ main \ java \ org \ junit \ internal \ Classes . java \n + * If the current thread does not have a class loader , falls back to the class loader for \n + * { @ link Classes } . \n - return Class . forName ( className , true , currentThread ( ) . getContextClassLoader ( ) ) ; \n + return getClass ( className , Classes . class ) ; \n + } \n + \n + / * * \n + * Returns Class . forName for { @ code className } using the current thread ' s class loader . \n + * If the current thread does not have a class loader , falls back to the class loader for the \n + * passed - in class . \n + * \n + * @ param className Name of the class . \n + * @ param callingClass Class that is requesting a the class \n + * @ throws ClassNotFoundException \n + * @ since 4 . 13 \n + * / \n + public static Class < ? > getClass ( String className , Class < ? > callingClass ) throws ClassNotFoundException { \n + ClassLoader classLoader = currentThread ( ) . getContextClassLoader ( ) ; \n + return Class . forName ( className , true , classLoader = = null ? callingClass . getClassLoader ( ) : classLoader ) ; \n","Update Classes . getClass ( ) to never use the bootstrap class loader . ( # 1404 ) \n Previously , if there was no context class loader then the \n bootstrap class loader is used . Now , the class loader for \n Classes is used ( or for the passed in class , if the new overloaded \n version of getClass ( ) is used ) .",291
src \ main \ java \ org \ junit \ rules \ ExpectedException . java \n + @ Deprecated \n,Annotate ExpectedException with @ Deprecated . ( # 1597 ) \n The Javadoc already indicates that it is deprecated .,291
"src \ main \ java \ org \ junit \ runners \ BlockJUnit4ClassRunner . java \n - public void accept ( FrameworkMember member , T value ) { \n + public void accept ( FrameworkMember < ? > member , T value ) { \n src \ main \ java \ org \ junit \ runners \ ParentRunner . java \n - public void accept ( FrameworkMember member , TestRule value ) { \n + public void accept ( FrameworkMember < ? > member , TestRule value ) { \n src \ main \ java \ org \ junit \ runners \ model \ MemberValueConsumer . java \n - void accept ( FrameworkMember member , T value ) ; \n + void accept ( FrameworkMember < ? > member , T value ) ; \n src \ main \ java \ org \ junit \ runners \ model \ TestClass . java \n - public void accept ( FrameworkMember member , T value ) { \n + public void accept ( FrameworkMember < ? > member , T value ) { \n - public void accept ( FrameworkMember member , T value ) { \n + public void accept ( FrameworkMember < ? > member , T value ) { \n",Remove usages of FrameworkMember as a raw type . ( # 1596 ),291
CONTRIBUTING . md \n - The reasoning is that the JUnit team feels that our users should focus on using either the JUnit4 APIs \n - or the soon - to - be - released JUnit4 APIs . \n + The reasoning is that the JUnit team feels that our users should focus on using either the JUnit4 or JUnit5 APIs . \n,"Fix typo in CONTRIBUTING . md ( "" JUnit4 "" - > "" JUnit5 "" )",291
"new file \n doc \ ReleaseNotes4 . 13 . 2 . md \n + # # Summary of changes in version 4 . 13 . 2 \n + \n + # Rules \n + \n + # # # [ Pull request # 1687 : ] ( https : / / github . com / junit - team / junit / pull / 1687 ) Mark ThreadGroups created by FailOnTimeout as daemon groups \n + \n + In JUnit 4 . 13 ( [ pull request # 1517 ] ( https : / / github . com / junit - team / junit4 / pull / 1517 ) ) an attempt was \n + made to fix leakage of the ` ThreadGroup ` instances created when a test is run with a timeout . That \n + change explicitly destroyed the ` ThreadGroup ` that was created for the time - limited test . Numerous \n + people reported problems that were caused by explicitly destroying the ` ThreadGroup ` . \n + \n + In this change , the code was updated to call ` ThreadGroup . setDaemon ( true ) ` instead of destroying the \n + ThreadGroup . \n",Initial release notes for 4 . 13 . 2 ( # 1692 ) \n * Initial release notes for 4 . 13 . 2 \n Co - authored - by : Marc Philipp < marc @ gradle . com >,291
core \ java \ android \ text \ Editable . java \n - * Returns a new SpannedStringBuilder from the specified \n + * Returns a new SpannableStringBuilder from the specified \n,Fix typo in documentation . \n There ' s no such a thing as SpannedStringBuilder . \n Change - Id : I41e1f257bb21807e4fc4943798887519ed5b40a9,294
graphics \ java \ android \ graphics \ OWNERS \n + per - file FontFamily . java = file : fonts / OWNERS \n + per - file FontListParser . java = file : fonts / OWNERS \n + per - file Typeface . java = file : fonts / OWNERS \n,Add fonts / OWNERS for font - related files . \n Test : n / a \n Change - Id : I98bd4b1c6274e1414c107fd75f08bcd0367ede00,294
new file \n tests \ UpdatableSystemFontTest \ OWNERS \n + # Bug component : 24939 \n + \n + include / graphics / java / android / graphics / fonts / OWNERS \n,Add tests / UpdatableSystemFontTest / OWNERS . \n Bug : 176939176 \n Test : n / a \n Change - Id : I42c20dd5dd5121720acae6eb747a62953b26b3aa,294
core \ java \ android \ service \ textservice \ OWNERS \n - # Bug component : 34867 \n + # Bug component : 816455 \n - include . . / . . / inputmethodservice / OWNERS \n + include / services / core / java / com / android / server / textservices / OWNERS \n core \ java \ android \ view \ textservice \ OWNERS \n - # Bug component : 34867 \n + # Bug component : 816455 \n - include . . / inputmethod / OWNERS \n + include / services / core / java / com / android / server / textservices / OWNERS \n new file \n core \ java \ com \ android \ internal \ textservice \ OWNERS \n + # Bug component : 816455 \n + \n + include / services / core / java / com / android / server / textservices / OWNERS \n new file \n core \ tests \ coretests \ src \ android \ view \ textservice \ OWNERS \n + # Bug component : 816455 \n + \n + include / services / core / java / com / android / server / textservices / OWNERS \n new file \n services \ core \ java \ com \ android \ server \ textservices \ OWNERS \n + # Bug component : 816455 \n + \n + include / services / core / java / com / android / server / inputmethod / OWNERS \n new file \n services \ tests \ servicestests \ src \ com \ android \ server \ textservices \ OWNERS \n + # Bug component : 816455 \n + \n + include / services / core / java / com / android / server / textservices / OWNERS \n,Add missing textservice OWNERS files . \n Test : n / a \n Change - Id : I56939ce3a22c72ac489e4d9248de9e0ce4ee9413,294
new file \n services \ core \ java \ com \ android \ server \ security \ OWNERS \n + # Bug component : 36824 \n + \n + per - file FileIntegrityService . java = victorhsieh @ google . com \n + per - file VerityUtils . java = victorhsieh @ google . com \n,Add services / core / j / c / a / server / security / OWNERS . \n Test : n / a \n Change - Id : Ibb11af159e8191e3009d6d9975c95f6948be42c1,294
new file \n tests \ ApkVerityTest \ OWNERS \n + # Bug component : 36824 \n + \n + victorhsieh @ google . com \n,Add tests / ApkVerityTest / OWNERS . \n Test : n / a \n Change - Id : I5f1f58a6937d534f1e61bca98e424c8ccde84eeb,294
new file \n core \ tests \ coretests \ src \ android \ graphics \ OWNERS \n + # Bug component : 24939 \n + \n + include / graphics / java / android / graphics / OWNERS \n + \n + per - file Font * = file : / graphics / java / android / graphics / fonts / OWNERS \n + per - file Typeface * = file : / graphics / java / android / graphics / fonts / OWNERS \n new file \n services \ core \ java \ com \ android \ server \ graphics \ fonts \ OWNERS \n + # Bug component : 24939 \n + \n + include / graphics / java / android / graphics / fonts / OWNERS \n new file \n services \ tests \ servicestests \ src \ com \ android \ server \ graphics \ fonts \ OWNERS \n + # Bug component : 24939 \n + \n + include / graphics / java / android / graphics / fonts / OWNERS \n,Add missing graphics / fonts OWNERS . \n Test : n / a \n Change - Id : I7decde568e88bd86d1176b08ab30bd5f016498e0,294
realm \ src \ main \ java \ io \ realm \ BaseRealm . java \n + * @ param key a 64 - byte encryption key \n,Realm . writeEncryptedCopyTo needs @ param key .,296
realm \ src \ main \ java \ io \ realm \ Realm . java \n - * @ param configuration Configuration used to open the Realm . \n + * @ param configuration { @ link RealmConfiguration } used to open the Realm . \n + * @ param configuration { @ link RealmConfiguration } used to open the Realm \n - * @ param configuration \n + * @ param configuration { @ link RealmConfiguration } \n,Add missing @ param of Realm . java .,296
"realm \ realm - library \ src \ main \ java \ io \ realm \ Realm . java \n - * Gets all objects of a specific Class . If no objects exist , the returned RealmResults will not be null . The \n - * RealmResults . size ( ) to check the number of objects instead . \n + * Gets all objects of a specific Class . If no objects exist , the returned RealmResults will not be { @ code null } . \n + * The RealmResults . size ( ) to check the number of objects instead . \n - * will not be null . The RealmResults . size ( ) to check the number of objects instead . \n + * will not be { @ code null } . The RealmResults . size ( ) to check the number of objects instead . \n - * { @ link RealmResults } will not be null . The RealmResults . size ( ) to check the number of objects instead . \n + * { @ link RealmResults } will not be { @ code null } . The RealmResults . size ( ) to check the number of objects instead . \n",null - > { @ code null },296
realm \ realm - library \ src \ main \ java \ io \ realm \ Realm . java \n - * { @ link RealmResults } will not be null . The RealmResults . size ( ) to check the number of objects instead . \n + * { @ link RealmResults } will not be { @ code null } . The RealmResults . size ( ) to check the number of objects instead . \n,null - > { @ code null },296
"README . md \n - * Download the * * Android NDK ( = r10d ) * * . For example , on Mac OS you can do this with [ Homebrew ] ( http : / / brew . sh ) with ` brew install android - ndk ` . \n + * Download the * * Android NDK ( = r10d ) * * for [ Mac ] ( http : / / dl . google . com / android / ndk / android - ndk - r10d - darwin - x86 _ 64 . bin ) or [ Linux ] ( http : / / dl . google . com / android / ndk / android - ndk - r10d - linux - x86 _ 64 . bin ) . \n",Add a description how to install android - ndk r10d . \n Closes # 1576,296
README . md \n + * Or you can use [ Hombrew - versions ] ( https : / / github . com / Homebrew / homebrew - versions ) to install Android NDK for Mac : \n + \n + ` ` ` \n + brew tap homebrew / versions \n + brew install android - ndk - r10d \n + ` ` ` \n,Update README . md . ( homebrew - versions ),296
"changelog . txt \n + * Added Realm . isInWriteTransaction ( ) method . \n realm \ src \ androidTest \ java \ io \ realm \ RealmTest . java \n + public void testCommitTransactionAfterCancelTransaction ( ) { \n + testRealm . beginTransaction ( ) ; \n + testRealm . cancelTransaction ( ) ; \n + try { \n + testRealm . commitTransaction ( ) ; \n + fail ( ) ; \n + } catch ( IllegalStateException ignore ) { \n + } \n + } \n + \n + public void testIsInWriteTransaction ( ) { \n + assertFalse ( testRealm . isInWriteTransaction ( ) ) ; \n + testRealm . beginTransaction ( ) ; \n + assertTrue ( testRealm . isInWriteTransaction ( ) ) ; \n + testRealm . commitTransaction ( ) ; \n + assertFalse ( testRealm . isInWriteTransaction ( ) ) ; \n + testRealm . beginTransaction ( ) ; \n + assertTrue ( testRealm . isInWriteTransaction ( ) ) ; \n + testRealm . cancelTransaction ( ) ; \n + assertFalse ( testRealm . isInWriteTransaction ( ) ) ; \n + } \n realm \ src \ main \ java \ io \ realm \ BaseRealm . java \n + / * * \n + * Indicates if the Realm is currently in a write transaction . \n + * @ return the write transaction status . \n + * @ throws java . lang . IllegalStateException if the Realm is not opened or in a different thread \n + * than the one it was created on . \n + * / \n + public boolean isInWriteTransaction ( ) { \n + checkIfValid ( ) ; \n + return ! sharedGroupManager . isImmutable ( ) ; \n + } \n + \n - * @ throws java . lang . IllegalStateException If the write transaction is in an invalid state \n + * @ throws java . lang . IllegalStateException if the write transaction is in an invalid state \n realm \ src \ main \ java \ io \ realm \ internal \ ImplicitTransaction . java \n - parent . commitAndContinueAsRead ( ) ; \n - immutable = true ; \n + if ( ! immutable ) { \n + parent . commitAndContinueAsRead ( ) ; \n + immutable = true ; \n + } else { \n + throw new IllegalStateException ( "" Cannot commit a non - write transaction . "" ) ; \n + } \n realm \ src \ main \ java \ io \ realm \ internal \ SharedGroupManager . java \n + / * * \n + * Returns if the Realm is currently not in a write transaction . \n + * / \n + public boolean isImmutable ( ) { \n + return transaction . immutable ; \n + } \n + \n",Add Realm . isInWriteTransaction ( ) to indicate if it is in a write transaction . \n See also : \n https : / / realm . io / docs / objc / latest / api / Classes / RLMRealm . html # / / api / name / inWriteTransaction \n Closes # 1549,296
"realm \ src \ main \ java \ io \ realm \ internal \ ImplicitTransaction . java \n - throw new IllegalStateException ( "" Cannot commit a non transaction . "" ) ; \n + throw new IllegalStateException ( "" Not inside a transaction . "" ) ; \n - throw new IllegalStateException ( "" Cannot cancel a non transaction . "" ) ; \n + throw new IllegalStateException ( "" Not inside a transaction . "" ) ; \n",Polish error messages a little . \n Cannot cancel a non transaction . - > Not inside a transaction .,296
changelog . txt \n + * Added support for parsing JSON Dates with timezone information . \n - * Add support for parsing JSON Dates with timezone information . \n - * Add support for parsing JSON Dates with timezone information . \n,Arrangement duplicated items in changelog . txt .,296
"changelog . txt \n - * Fixed a bug that made it possible to migrate open Realms , which could cause undefined behavior when querying , reading or writing data . \n - * Fixed a bug where closed Realms were trying to refresh themselves resulting in a NullPointerException . \n + * Fixed a bug where closed Realms were trying to refresh themselves resulting in a NullPointerException . \n + * Fixed a bug that made it possible to migrate open Realms , which could cause undefined behavior when querying , reading or writing data . \n",Reordering items to categorize according to affinity .,296
rename from distribution \ README . txt \n rename to distribution \ README . md \n,distribution / README . txt - > README . md \n It ' s already Markdown format document .,296
new file \n gradle . properties \n + org . gradle . jvmargs = - XX : MaxPermSize = 512m \n,Increase XX : MaxPermSize to avoid PermGen space problem .,296
"realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmTest . java \n + protected final static dobule DELTA = 1e - 15 ; \n - public void createAndTestFilename ( String language , String fileName ) { \n + private void createAndTestFilename ( String language , String fileName ) { \n - get _ data = testRealm . allObjects ( StringOnly . class ) . get ( 0 ) . getChars ( ) ; \n + testRealm . allObjects ( StringOnly . class ) . get ( 0 ) . getChars ( ) ; \n - assertEquals ( allTypes . getColumnFloat ( ) , realmTypes . getColumnFloat ( ) ) ; \n - assertEquals ( allTypes . getColumnDouble ( ) , realmTypes . getColumnDouble ( ) ) ; \n + assertEquals ( allTypes . getColumnFloat ( ) , realmTypes . getColumnFloat ( ) , DELTA ) ; \n + assertEquals ( allTypes . getColumnDouble ( ) , realmTypes . getColumnDouble ( ) , DELTA ) ; \n - assertEquals ( 2 . 23F , obj . getColumnFloat ( ) ) ; \n - assertEquals ( 2 . 234D , obj . getColumnDouble ( ) ) ; \n + assertEquals ( 2 . 23F , obj . getColumnFloat ( ) , DELTA ) ; \n + assertEquals ( 2 . 234D , obj . getColumnDouble ( ) , DELTA ) ; \n - assertEquals ( 0 . 0F , obj . getColumnFloat ( ) ) ; \n - assertEquals ( 0 . 0D , obj . getColumnDouble ( ) ) ; \n + assertEquals ( 0 . 0F , obj . getColumnFloat ( ) , DELTA ) ; \n + assertEquals ( 0 . 0D , obj . getColumnDouble ( ) , DELTA ) ; \n","Change modifier , remove unused var , and use new JUnit in RealmTest . \n * createAndTestFilename public - > private \n * remove unused variable get _ data \n * Use assertEquals ( expected , actual , delta ) to compare \n floating - point numbers . assertEquals ( expected , actual ) for \n floating - pointer numbers is deprecated in JUnit . \n See also : http : / / junit . org / apidocs / org / junit / Assert . html # assertEquals ( double , double )",296
"realm \ realm - jni \ src \ Makefile \n - # Used by . . / . . / build . sh \n - get - inst - libraries : \n - @ echo $ ( filter - out librealm - jni - cov . % , $ ( TARGETS _ LIB _ SHARED _ ALIASES ) ) \n - \n",Delete an unnecessay target ` get - inst - libraries ` . \n Thanks to @ zaki50,296
examples \ unitTestExample \ build . gradle \n - applicationId ' io . realm . examples . intro ' \n + applicationId ' io . realm . examples . unittesting ' \n examples \ unitTestExample \ src \ test \ java \ io \ realm \ examples \ unittesting \ ExampleRealmTest . java \n - import io . realm . examples . intro . model . Dog ; \n - import io . realm . examples . intro . repository . DogRepository ; \n - import io . realm . examples . intro . repository . DogRepositoryImpl ; \n + import io . realm . examples . unittesting . model . Dog ; \n + import io . realm . examples . unittesting . repository . DogRepository ; \n + import io . realm . examples . unittesting . repository . DogRepositoryImpl ; \n,io . realm . examples . intro - > io . realm . examples . unittesting,296
README . md \n - * Or you can use [ Hombrew - versions ] ( https : / / github . com / Homebrew / homebrew - versions ) to install Android NDK for Mac : \n + * Or you can use [ Hombrew ] ( https : / / github . com / Homebrew / homebrew ) to install Android NDK for Mac : \n - brew tap homebrew / versions \n,Use Homebrew instead of Homebrew - versions .,296
"build . gradle \n - def getSdk ( ) { \n - if ( ! System . env . ANDROID _ HOME ) { \n - throw new GradleException ( ' The ANDROID _ HOME environment variable is not set . ' ) \n - } \n - def sdkDir = file ( System . env . ANDROID _ HOME ) \n - if ( ! sdkDir . directory ) { \n - throw new GradleException ( ' The path provided in the ANDROID _ HOME environment variable is not a folder . ' ) \n - } \n - return sdkDir \n - } \n - \n - def getNdk ( ) { \n - if ( ! System . env . NDK _ HOME ) { \n - throw new GradleException ( ' The NDK _ HOME environment variable is not set . ' ) \n - } \n - def ndkDir = file ( System . env . NDK _ HOME ) \n - if ( ! ndkDir . directory ) { \n - throw new GradleException ( ' The path provided in the NDK _ HOME environment variable is not a folder . ' ) \n - } else if ( ! file ( "" $ { sdndkDirkDir } / RELEASE . TXT "" ) . file ) { \n - throw new GradleException ( ' The path provided in the NDK _ HOME environment variable does not seem to be an Android NDK . ' ) \n - } \n - return ndkDir \n - } \n - \n",Remove unused defs of build . gradle .,296
README . md \n - * Or you can use [ Hombrew ] ( https : / / github . com / Homebrew / homebrew ) to install Android NDK for Mac : \n + * Or you can use [ Hombrew - versions ] ( https : / / github . com / Homebrew / homebrew - versions ) to install Android NDK for Mac : \n - brew install android - ndk \n + brew tap homebrew / versions \n + brew install android - ndk - r10e \n - export NDK _ HOME = / usr / local / Cellar / android - ndk / r10e \n + export NDK _ HOME = / usr / local / Cellar / android - ndk - r10e / r10e \n,Update README . md to use Homebrew - versions,296
examples \ unitTestExample \ build . gradle \n + testCompile ' io . reactivex : rxjava : 1 . 1 . 0 ' \n + \n,"Add "" testCompile ' io . reactivex : rxjava : 1 . 1 . 0 ' "" \n Without this testCompile , we encounter javassist . NotFoundException .",296
"examples \ unitTestExample \ src \ test \ java \ io \ realm \ examples \ unittesting \ ExampleRealmTest . java \n - @ Config ( constants = BuildConfig . class , sdk = 21 ) \n + @ Config ( constants = BuildConfig . class , sdk = 19 ) \n","PowerMock fails with API 21 , works with 19 .",296
realm \ realm - library \ src \ main \ cpp \ objectserver _ shared . hpp \n - / / TODO Use OS SyncSession instead - https : / / github . com / realm / realm - java - private / issues / 123 \n + / / TODO Use OS SyncSession instead \n realm \ realm - library \ src \ main \ java \ io \ realm \ AndroidNotifier . java \n - / / https : / / github . com / realm / realm - java - private / issues / 127 \n,Remove comments that mention realm - java - private ( # 3628 ),296
CHANGELOG . md \n + # # 2 . 3 . 0 \n + \n + # # # Object Server API Changes ( In Beta ) \n + \n + * Add a default ` UserStore ` based on the Realm Object Store ( ` ObjectStoreUserStore ` ) . \n + \n - * Add a default ` UserStore ` based on the Realm Object Store ( ` ObjectStoreUserStore ` ) . \n,Fix CHANGELOG . md \n It ' s not for 2 . 2 . 1 and it was merged into master .,296
"realm \ realm - library \ src \ main \ cpp \ util . cpp \n - ss < < e . what ( ) < < "" in "" < < file < < "" line "" < < line ; \n + ss < < e . what ( ) < < "" ( "" < < e . underlying ( ) < < "" ) in "" < < file < < "" line "" < < line ; \n",Add the underlying information on RealmFileException . ( # 3940 ) \n Add the underlying information on RealmFileException to help \n investigating Incompatible lock file issue .,296
"CHANGELOG . md \n + * ` SyncUser . all ( ) ` now returns Map instead of List . \n realm \ realm - library \ src \ androidTestObjectServer \ java \ io \ realm \ SyncUserTests . java \n - import java . util . Collection ; \n + import java . util . Map ; \n - Collection < SyncUser > users = SyncUser . all ( ) ; \n + Map < String , SyncUser > users = SyncUser . all ( ) ; \n - Collection < SyncUser > users = SyncUser . all ( ) ; \n + Map < String , SyncUser > users = SyncUser . all ( ) ; \n - assertTrue ( users . iterator ( ) . next ( ) . isValid ( ) ) ; \n + assertTrue ( users . get ( users . keySet ( ) . iterator ( ) . next ( ) ) . isValid ( ) ) ; \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncUser . java \n - import java . util . ArrayList ; \n - import java . util . List ; \n + import java . util . Collections ; \n + import java . util . HashMap ; \n + import java . util . Map ; \n - * @ return a list of all known valid users . \n + * @ return a map from user identifier to user . It includes all known valid users . \n - public static Collection < SyncUser > all ( ) { \n + public static Map < String , SyncUser > all ( ) { \n - List < SyncUser > result = new ArrayList < SyncUser > ( storedUsers . size ( ) ) ; \n + Map < String , SyncUser > map = new HashMap < String , SyncUser > ( ) ; \n - result . add ( user ) ; \n + map . put ( user . getIdentity ( ) , user ) ; \n - return result ; \n + return Collections . unmodifiableMap ( map ) ; \n",SyncUser . all ( ) returns Map ( # 4036 ) \n * SyncUser . all ( ) returns Map \n * Update the document,296
CHANGELOG . md \n - * Now ` SyncUser . logout ( ) ` properly revoke tokens ( # 3639 ) . \n + * Now ` SyncUser . logout ( ) ` properly revokes tokens ( # 3639 ) . \n - * Add ` like ` predicate for String fields ( # 3752 ) . \n + * Added ` like ` predicate for String fields ( # 3752 ) . \n,Fixed CHANGELOG . md ( # 4077 ),296
"realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmLinkTests . java \n - assertEquals ( 1 , owners1 . size ( ) ) ; \n + assertEquals ( 1 , owners2 . size ( ) ) ; \n - assertEquals ( 1 , owners1 . size ( ) ) ; \n + assertEquals ( 1 , owners2 . size ( ) ) ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmTests . java \n - String get _ data = "" "" ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ TypeBasedNotificationsTests . java \n - import java . util . concurrent . TimeUnit ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ UnManagedOrderedRealmCollectionTests . java \n - import static org . junit . Assert . assertFalse ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ internal \ JNIQueryTest . java \n - import io . realm . Sort ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ internal \ JNITableInsertTest . java \n - import android . test . MoreAsserts ; \n - \n - import static org . junit . Assert . assertEquals ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ rule \ TestRealmConfigurationFactory . java \n - import android . content . res . AssetManager ; \n realm \ realm - library \ src \ androidTest \ java \ io \ realm \ services \ RemoteProcessService . java \n - import android . util . Log ; \n realm \ realm - library \ src \ main \ java \ io \ realm \ internal \ RealmCore . java \n - import java . lang . reflect . Constructor ; \n - import java . lang . reflect . InvocationTargetException ; \n",Fix tests and remove unnecessary imports and fields . ( # 4125 ) \n * Fix tests . \n * Remove unnecessary imports and fields .,296
realm \ realm - library \ src \ main \ java \ io \ realm \ DynamicRealm . java \n - super . removeListener ( listener ) ; \n + removeListener ( listener ) ; \n - super . removeAllListeners ( ) ; \n + removeAllListeners ( ) ; \n realm \ realm - library \ src \ main \ java \ io \ realm \ Realm . java \n - import io . realm . internal . Capabilities ; \n - super . removeListener ( listener ) ; \n + removeListener ( listener ) ; \n - super . removeAllListeners ( ) ; \n + removeAllListeners ( ) ; \n,"Remove unnecessary ' super ' s ( # 4248 ) \n Since this . removeListener and this . removeAllListeners does not exist , \n super . removeListener and super . removeAllListeners are not necessary . \n Just use removeListener and removeAllListeners instead .",296
realm \ realm - library \ src \ main \ java \ io \ realm \ DynamicRealm . java \n - super . addListener ( listener ) ; \n + addListener ( listener ) ; \n realm \ realm - library \ src \ main \ java \ io \ realm \ Realm . java \n - super . addListener ( listener ) ; \n + addListener ( listener ) ; \n,"Remove unnecessary ' super ' s ( # 4247 ) \n Since this . addListener doesn ' t exist , ' super . ' is not needed .",296
realm \ realm - library \ src \ main \ java \ io \ realm \ BaseRealm . java \n - * @ throws IllegalArgumentException if Realm is encrypted . \n,Update Javadoc of Realm . compactRealm . ( # 3973 ) \n It is related # 3520 .,296
examples \ kotlinExample \ build . gradle \n - ext . kotlin _ version = ' 1 . 1 . 2 - 5 ' \n + ext . kotlin _ version = ' 1 . 1 . 3 ' \n realm \ build . gradle \n - ext . kotlin _ version = ' 1 . 1 . 2 - 5 ' \n + ext . kotlin _ version = ' 1 . 1 . 3 ' \n,Update Kotlin to 1 . 1 . 3 ( # 4886 ),296
realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmTests . java \n - } ) . run ( ) ; \n + } ) . start ( ) ; \n - } ) . run ( ) ; \n + } ) . start ( ) ; \n,Fix tests : Thread # run - > Thread # start ( # 4929 ),296
"README . md \n - * If you will be launching Android Studio from the OS X Finder , you should also run the following two commands : \n + * If you will be launching Android Studio from the macOS Finder , you should also run the following two commands : \n - OS X users must also run the following command in order for Android Studio to see this environment variable . . \n + macOS users must also run the following command in order for Android Studio to see this environment variable . . \n - It would be a good idea to add all of the symbol definitions ( and their accompanying ` launchctl ` commands , if you are using OS X ) to your ` ~ / . profile ` ( or ` ~ / . zprofile ` if the login shell is ` zsh ` ) \n + It would be a good idea to add all of the symbol definitions ( and their accompanying ` launchctl ` commands , if you are using macOS ) to your ` ~ / . profile ` ( or ` ~ / . zprofile ` if the login shell is ` zsh ` ) \n",OS X - > macOS ( # 4859 ),296
"README . md \n - You may unzip the file wherever you choose . For OSX , a suggested location is ` ~ / Library / Android ` . The download will unzip as the directory ` android - ndk - r10e ` . \n + You may unzip the file wherever you choose . For macOS , a suggested location is ` ~ / Library / Android ` . The download will unzip as the directory ` android - ndk - r10e ` . \n",Update README . md ( OSX - > macOS ) ( # 4861 ) \n There was still OSX .,296
"README . md \n - * * _ If you use Realm and are happy with it , all we ask is that you please consider sending out a tweet mentioning [ @ realm ] ( http : / / twitter . com / realm ) , announce your app on [ our mailing - list ] ( https : / / groups . google . com / forum / # ! forum / realm - java ) , or email [ help @ realm . io ] ( mailto : help @ realm . io ) to let us know about it ! _ * * \n + * * _ If you use Realm and are happy with it , all we ask is that you please consider sending out a tweet mentioning [ @ realm ] ( http : / / twitter . com / realm ) , or email [ help @ realm . io ] ( mailto : help @ realm . io ) to let us know about it ! _ * * \n",Update README . md ( # 5006 ) \n remove mailing - list .,296
"realm \ realm - library \ src \ main \ java \ io \ realm \ BaseRealm . java \n + * private static RealmConfiguration config = new RealmConfiguration . Builder ( ) \n + * . schema ( 42 ) \n + * . migration ( new MyMigration ( ) ) / / Potentially lengthy migration \n + * . build ( ) ; \n - * realmAsyncTask = Realm . getDefaultInstanceAsync ( new Callback ( ) { \n + * realmAsyncTask = Realm . getInstanceAsync ( config , new Callback ( ) { \n",Update Javadoc to not reference Realm . getDefaultInstanceAsync . ( # 5119 ) \n * Update Javadoc to not reference Realm . getDefaultInstanceAsync that does not exist . \n * PR feedback : move the config as a static member variable .,296
CHANGELOG . md \n - * [ ObjectServer ] Added support for ` SyncConfigration . Builder . waitForInitialRemoteData ( ) ` ( # 4270 ) . \n + * [ ObjectServer ] Added support for ` SyncConfiguration . Builder . waitForInitialRemoteData ( ) ` ( # 4270 ) . \n - * Changelisteners will now auto - expand variable names to be more descriptive when using Android Studio . \n + * Change listeners will now auto - expand variable names to be more descriptive when using Android Studio . \n,Fix typo in CHANGELOG . md ( # 4617 ),296
"CHANGELOG . md \n - * Workaround for a Android JVM crash when using ' compactOnLaunch ( ) ' ( # 4964 ) . \n + * Workaround for an Android JVM crash when using ` compactOnLaunch ( ) ` ( # 4964 ) . \n - * @ PrimaryKey field value can now be null for String , Byte , Short , Integer , and Long types . Older Realms should be migrated , using RealmObjectSchema . setNullable ( ) , or by adding the @ Required annotation . ( # 2515 ) . \n + * @ PrimaryKey field value can now be null for String , Byte , Short , Integer , and Long types . Older Realms should be migrated , using RealmObjectSchema . setNullable ( ) , or by adding the @ Required annotation ( # 2515 ) . \n - * RealmResults and RealmObjects can no longer accidentially be GC ' ed if using ` asObservable ( ) ` . Previously this caused the observable to stop emitting . ( # 2485 ) . \n + * RealmResults and RealmObjects can no longer accidentially be GC ' ed if using ` asObservable ( ) ` . Previously this caused the observable to stop emitting ( # 2485 ) . \n - Fixed a bug where an async query can be copied incomplete in rare cases ( # 1717 ) . \n - * Added a check to prevent removing a RealmChangeListener from a non - Looper thread ( # 1962 ) . ( Thank you @ hohnamkung ) \n + * Added a check to prevent removing a RealmChangeListener from a non - Looper thread ( # 1962 ) . ( Thank you @ hohnamkung . ) \n - * The Realm AAR now also contains the ProGuard configuration ( # 1767 ) . ( Thank you @ skyisle ) \n + * The Realm AAR now also contains the ProGuard configuration ( # 1767 ) . ( Thank you @ skyisle . ) \n - Removed reliance on POSIX signals when using encryption . \n - * Added support for parsing JSON Dates with timezone information . ( Thank you @ LateralKevin ) \n + * Added support for parsing JSON Dates with timezone information . ( Thank you @ LateralKevin . ) \n - * Realm now works with Kotlin ( M12 + ) . ( Thank you @ cypressious ) \n + * Realm now works with Kotlin ( M12 + ) . ( Thank you @ cypressious . ) \n - * RealmBaseAdapter now allow RealmResults to be null . ( Thanks @ zaki50 ) \n + * RealmBaseAdapter now allow RealmResults to be null . ( Thanks @ zaki50 . ) \n",Update CHANGELOG . md : Improve formatting . ( # 5079 ) \n * Update CHANGELOG . md : Improve formatting . \n * Update CHANGELOG . md again . \n See also : \n https : / / english . stackexchange . com / questions / 6632 / where - does - the - period - go - when - using - parentheses \n * PR feedback,296
"examples \ gridViewExample \ build . gradle \n + proguardFiles getDefaultProguardFile ( ' proguard - android . txt ' ) , ' proguard - rules . pro ' \n + proguardFiles getDefaultProguardFile ( ' proguard - android . txt ' ) , ' proguard - rules . pro ' \n new file \n examples \ gridViewExample \ proguard - rules . pro \n + - keep class io . realm . examples . realmgridview . City { < fields > ; } \n examples \ gridViewExample \ src \ main \ java \ io \ realm \ examples \ realmgridview \ City . java \n - \n + / / If you are using GSON , field names should not be obfuscated . \n + / / Add either the proguard rule in proguard - rules . pro or the @ SerializedName annotation . \n",Add Gridview example ' s proguard configuration . ( # 5274 ) \n * Fix gridView . \n * Add missing proguard configuration file . \n * PR feedback .,296
README . md \n - mavenCentral ( ) \n + jcenter ( ) \n,Update README . md \n Use jcenter instead of mavenCentral . It is specified by new Android projects .,296
"library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ gif \ GifFrameLoader . java \n - pendingTarget = delayTarget ; \n + if ( startFromFirstFrame ) { \n + handler . obtainMessage ( FrameLoaderCallback . MSG _ CLEAR , delayTarget ) . sendToTarget ( ) ; \n + } else { \n + pendingTarget = delayTarget ; \n + } \n library \ test \ src \ test \ java \ com \ bumptech \ glide \ load \ resource \ gif \ GifFrameLoaderTest . java \n + @ Test \n + public void onFrameReady _ whenInvisible _ setVisibleLater ( ) { \n + loader = createGifFrameLoader ( / * handler = * / null ) ; \n + / / The target is invisible at this point . \n + loader . unsubscribe ( callback ) ; \n + loader . setNextStartFromFirstFrame ( ) ; \n + DelayTarget loaded = mock ( DelayTarget . class ) ; \n + when ( loaded . getResource ( ) ) . thenReturn ( Bitmap . createBitmap ( 100 , 100 , Bitmap . Config . ARGB _ 8888 ) ) ; \n + loader . onFrameReady ( loaded ) ; \n + loader . subscribe ( callback ) ; \n + } \n + \n",Avoid IllegalArgumentException in GifFrameLoader . \n IllegalArgumentException is thrown when the target is invisible and \n startFromFirstFrame is called and the target subsequently becomes visible .,296
dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ proxy \ javassist \ JavassistProxyFactory . java \n - * JavaassistRpcProxyFactory \n + * JavassistRpcProxyFactory \n,fix - typo - 5466 ( # 5467 ),302
dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ rpc \ model \ ApplicationModel . java \n - public static void iniFrameworkExts ( ) { \n + public static void initFrameworkExts ( ) { \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ bootstrap \ DubboBootstrap . java \n - ApplicationModel . iniFrameworkExts ( ) ; \n + ApplicationModel . initFrameworkExts ( ) ; \n,code optimization ( # 5486 ) \n fix wrong words .,302
dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ common \ Version . java \n - / / guess version fro jar file name if nothing ' s found from MANIFEST . MF \n + / / guess version from jar file name if nothing ' s found from MANIFEST . MF \n,fix typo : fro ( # 5488 ) \n fix typo,302
"dubbo - remoting \ dubbo - remoting - api \ src \ main \ java \ org \ apache \ dubbo \ remoting \ Constants . java \n - * Every heartbeat duration / HEATBEAT _ CHECK _ TICK , check if a heartbeat should be sent . Every heartbeat timeout \n - * duration / HEATBEAT _ CHECK _ TICK , check if a connection should be closed on server side , and if reconnect on \n + * Every heartbeat duration / HEARTBEAT _ CHECK _ TICK , check if a heartbeat should be sent . Every heartbeat timeout \n + * duration / HEARTBEAT _ CHECK _ TICK , check if a connection should be closed on server side , and if reconnect on \n",Fix typo : HEATBEAT _ CHECK _ TICK ( # 5513 ),302
"dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ common \ constants \ CommonConstants . java \n - * After simplify the registry , should add some paramter individually for provider . \n + * After simplify the registry , should add some parameter individually for provider . \n dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ config \ RegistryConfig . java \n - * After simplify the registry , should add some paramter individually . just for provider . \n + * After simplify the registry , should add some parameter individually . just for provider . \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ bootstrap \ builders \ RegistryBuilder . java \n - * After simplify the registry , should add some paramter individually . just for provider . \n + * After simplify the registry , should add some parameter individually . just for provider . \n",fix typo : paramter in javadoc ( # 5533 ),302
dubbo - bom \ pom . xml \n - < dependency > \n - < groupId > org . apache . dubbo < / groupId > \n - < artifactId > dubbo - metadata - api < / artifactId > \n - < version > $ { project . version } < / version > \n - < / dependency > \n dubbo - demo \ dubbo - demo - xml \ dubbo - demo - xml - consumer \ pom . xml \n - < dependency > \n - < groupId > org . apache . dubbo < / groupId > \n - < artifactId > dubbo - metadata - report - zookeeper < / artifactId > \n - < / dependency > \n,Remove duplicate dependency from [ dubbo - bom ] and [ dubbo - demo - xml - consumer ] ( # 5799 ),302
dubbo - rpc \ dubbo - rpc - grpc \ src \ main \ java \ org \ apache \ dubbo \ rpc \ protocol \ grpc \ GrpcInvoker . java \n - } else if ( status . getCode ( ) = = Status . Code . DEADLINE _ EXCEEDED ) { \n - / / \n,fix : Duplicate condition in ' if ' statement inspection ( # 5802 ),302
. gitignore \n - # flatten ignore \n - . flattened - pom . xml \n - \n,remove duplicate . flattened - pom . xml from . gitignore ( # 5897 ),302
"dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ rpc \ model \ ConsumerModel . java \n - / / Assert . notNull ( proxyObject , "" Proxy object can ' t be null "" ) ; \n - * @ param method metodName \n + * @ param method methodName \n",fix typo : metodName ( # 5596 ),302
"dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ proxy \ AbstractProxyInvoker . java \n - CompletableFuture < Object > future = wrapWithFuture ( value , invocation ) ; \n + CompletableFuture < Object > future = wrapWithFuture ( value ) ; \n - private CompletableFuture < Object > wrapWithFuture ( Object value , Invocation invocation ) { \n + private CompletableFuture < Object > wrapWithFuture ( Object value ) { \n",fix : Remove unused variable parameters in AbstractProxyInvoker ( # 5651 ),302
"dubbo - plugin \ dubbo - qos \ src \ main \ java \ org \ apache \ dubbo \ qos \ command \ impl \ Ready . java \n - @ Cmd ( name = "" start "" , summary = "" Judge if service has started ? "" ) \n + @ Cmd ( name = "" ready "" , summary = "" Judge if service has started ? "" ) \n",Rename the Cmd name of QOS command ' Ready ' to ready ( # 6114 ),302
"src \ main \ java \ io \ vertx \ core \ json \ JsonObject . java \n - public JsonObject ( Object obj ) { \n - this ( ( Map < String , Object > ) Json . mapper . convertValue ( obj , Map . class ) ) ; \n + public static JsonObject fromInstance ( Object obj ) { \n + return new JsonObject ( ( Map < String , Object > ) Json . mapper . convertValue ( obj , Map . class ) ) ; \n",Change from Object - param constructor to static factory method \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"src \ test \ java \ io \ vertx \ test \ core \ JsonPOJOMapperTest . java \n - JsonObject jsonObject = new JsonObject ( myObj1 ) ; \n + JsonObject jsonObject = JsonObject . fromInstance ( myObj1 ) ; \n + "" { \ "" a \ "" : - 1 , \ "" b \ "" : \ "" obj0 \ "" , \ "" c \ "" : { \ "" z \ "" : [ 7 , 8 ] } , \ "" d \ "" : [ ] , \ "" e \ "" : [ 9 ] } "" \n - new JsonObject ( myObj0 ) ; \n + JsonObject . fromInstance ( myObj0 ) ; \n",Update test to use static factory method \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"src \ main \ java \ io \ vertx \ core \ json \ JsonObject . java \n - public static JsonObject fromInstance ( Object obj ) { \n + public static JsonObject mapFrom ( Object obj ) { \n - public < T > T toInstance ( Class < T > type ) { \n + public < T > T mapTo ( Class < T > type ) { \n src \ test \ java \ io \ vertx \ test \ core \ JsonPOJOMapperTest . java \n - JsonObject jsonObject = JsonObject . fromInstance ( myObj1 ) ; \n + JsonObject jsonObject = JsonObject . mapFrom ( myObj1 ) ; \n + "" { \ "" a \ "" : - 1 , \ "" b \ "" : \ "" obj0 \ "" , \ "" c \ "" : { \ "" z \ "" : [ 7 , 8 ] } , \ "" d \ "" : [ ] , \ "" e \ "" : [ 9 ] } "" \n + "" ] , \ "" e \ "" : [ 3 ] } "" , jsonStr ) ; \n - MyType myObj2 = jsonObject . toInstance ( MyType . class ) ; \n + MyType myObj2 = jsonObject . mapTo ( MyType . class ) ; \n - JsonObject . fromInstance ( myObj0 ) ; \n + JsonObject . mapFrom ( myObj0 ) ; \n",Rename mapping methods to mapFrom / mapTo \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
src \ main \ java \ io \ vertx \ core \ json \ JsonObject . java \n - * Method for instantiating a Java object from a JsonObject . \n + * Instantiate a Java object from a JsonObject . \n,Reword a JavaDoc comment \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"src \ main \ java \ io \ vertx \ core \ json \ JsonObject . java \n + * Faster than calling ` Json . decodeValue ( Json . encode ( jsonObject ) , type ) ` . \n src \ test \ java \ io \ vertx \ test \ core \ JsonPOJOMapperTest . java \n + Thread . currentThread ( ) . setName ( "" vert . x - 1 "" ) ; \n",Improve JavaDoc comment \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
src \ main \ java \ io \ vertx \ core \ json \ JsonObject . java \n - * Faster than calling ` new JsonObject ( Json . encode ( pojo ) ) ` . \n + * Faster than calling ` new JsonObject ( Json . encode ( obj ) ) ` . \n,Improve JavaDoc comment \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"src \ test \ java \ io \ vertx \ test \ core \ JsonPOJOMapperTest . java \n - JsonObject jsonObject = JsonObject . mapFrom ( myObj1 ) ; \n - String jsonStr = jsonObject . encode ( ) ; \n + JsonObject jsonObject1 = JsonObject . mapFrom ( myObj1 ) ; \n + String jsonStr1 = jsonObject1 . encode ( ) ; \n + "" { \ "" a \ "" : - 1 , \ "" b \ "" : \ "" obj0 \ "" , \ "" c \ "" : { \ "" z \ "" : [ 7 , 8 ] } , \ "" d \ "" : [ ] , \ "" e \ "" : [ 9 ] } "" \n - + "" ] , \ "" e \ "" : [ 3 ] } "" , jsonStr ) ; \n + + "" ] , \ "" e \ "" : [ 3 ] } "" , jsonStr1 ) ; \n - MyType myObj2 = jsonObject . mapTo ( MyType . class ) ; \n - assertEquals ( myObj2 . b , "" obj1 "" ) ; \n - assertEquals ( myObj2 . d . get ( 0 ) . b , "" obj0 "" ) ; \n + MyType myObj1Roundtrip = jsonObject1 . mapTo ( MyType . class ) ; \n + assertEquals ( myObj1Roundtrip . a , 5 ) ; \n + assertEquals ( myObj1Roundtrip . b , "" obj1 "" ) ; \n + assertEquals ( myObj1Roundtrip . c . get ( "" x "" ) , "" 1 "" ) ; \n + assertEquals ( myObj1Roundtrip . c . get ( "" y "" ) , new Integer ( 2 ) ) ; \n + assertEquals ( myObj1Roundtrip . e , Arrays . asList ( 3 ) ) ; \n + MyType myObj0Roundtrip = myObj1Roundtrip . d . get ( 0 ) ; \n + assertEquals ( myObj0Roundtrip . a , - 1 ) ; \n + assertEquals ( myObj0Roundtrip . b , "" obj0 "" ) ; \n + assertEquals ( myObj0Roundtrip . c . get ( "" z "" ) , Arrays . asList ( 7 , 8 ) ) ; \n + assertEquals ( myObj0Roundtrip . e , Arrays . asList ( 9 ) ) ; \n",Improve test coverage \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"src \ test \ java \ io \ vertx \ test \ core \ JsonPOJOMapperTest . java \n - Thread . currentThread ( ) . setName ( "" vert . x - 1 "" ) ; \n",Remove temp thread name override \n Signed - off - by : Luke Hutchison < luke . hutch @ gmail . com >,306
"rename from agera \ src \ main \ java \ com \ google \ android \ agera \ IdentityMultiMap . java \n rename to agera \ src \ main \ java \ com \ google \ android \ agera \ IdentityMultimap . java \n - final class IdentityMultiMap < K , V > { \n + final class IdentityMultimap < K , V > { \n - private Object [ ] keysValues ; \n - \n - IdentityMultiMap ( ) { \n - this . keysValues = NO _ KEY _ VALUES ; \n - } \n - \n - @ NonNull \n - Object [ ] getKeysValues ( ) { \n - return keysValues ; \n - } \n + private Object [ ] keysValues = NO _ KEY _ VALUES ; \n - if ( keysValues [ index ] = = keysValues & & keysValues [ index + 1 ] = = value ) { \n + if ( keysValues [ index ] = = key & & keysValues [ index + 1 ] = = value ) { \n agera \ src \ main \ java \ com \ google \ android \ agera \ WorkerHandler . java \n - private final IdentityMultiMap < Updatable , Object > updatableObservable ; \n + private final IdentityMultimap < Updatable , Object > scheduledUpdatables ; \n - this . updatableObservable = new IdentityMultiMap < > ( ) ; \n + this . scheduledUpdatables = new IdentityMultimap < > ( ) ; \n - updatableObservable . removeKeyValuePair ( updatable , token ) ; \n + scheduledUpdatables . removeKeyValuePair ( updatable , token ) ; \n - if ( updatableObservable . addKeyValuePair ( updatable , token ) ) { \n + if ( scheduledUpdatables . addKeyValuePair ( updatable , token ) ) { \n - updatableObservable . removeKey ( updatable ) ; \n - updatable . update ( ) ; \n + if ( scheduledUpdatables . removeKey ( updatable ) ) { \n + updatable . update ( ) ; \n + } \n agera \ src \ test \ java \ com \ google \ android \ agera \ ObservablesTest . java \n - @ Test \n - public void shouldCallMessageObjUpdateForMsgCallUpdatableMessage ( ) { \n - workerHandler ( ) . obtainMessage ( WorkerHandler . MSG _ CALL _ UPDATABLE , updatable ) . sendToTarget ( ) ; \n - \n - assertThat ( updatable , wasUpdated ( ) ) ; \n - } \n - \n",Fixed some problems in update scheduling ( # 69 ),311
. travis . yml \n - - platform - tools \n - tools \n - - build - tools - 23 . 0 . 3 \n - - android - 23 \n + - platform - tools \n + - build - tools - 24 . 0 . 0 \n + - android - 24 \n - extra - android - m2repository \n - oraclejdk8 \n settings . gradle \n - gradle . ext . compileSdkVersion = 23 \n - gradle . ext . buildToolsVersion = ' 23 . 0 . 3 ' \n - gradle . ext . supportLibraryVersion = ' 23 . 4 . 0 ' \n + gradle . ext . compileSdkVersion = 24 \n + gradle . ext . buildToolsVersion = ' 24 . 0 . 0 ' \n + gradle . ext . supportLibraryVersion = ' 24 . 1 . 1 ' \n,Updated sdk / support library version to 24 ( # 89 ),311
agera \ src \ main \ java \ com \ google \ android \ agera \ CompiledRepository . java \n + if ( runState = = CANCEL _ REQUESTED ) { \n + restartNeeded = true ; \n + } \n,Fixed restart racing condition in repo compiler ( # 73 ),311
settings . gradle \n - gradle . ext . versionName = ' 1 . 2 . 0 - beta2 ' \n + gradle . ext . versionName = ' 1 . 2 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 2 . 0 - SNAPSHOT ( # 103 ),311
extensions \ content \ src \ main \ java \ com \ google \ android \ agera \ content \ ContentObservables . java \n + this . filter = new IntentFilter ( ) ; \n + for ( final String action : actions ) { \n + this . filter . addAction ( action ) ; \n + } \n - dispatchUpdate ( ) ; \n + if ( filter . hasAction ( intent . getAction ( ) ) ) { \n + dispatchUpdate ( ) ; \n + } \n - this . filter = new IntentFilter ( ) ; \n - for ( final String action : actions ) { \n - this . filter . addAction ( action ) ; \n - } \n,Added explicit action filtering to BroadcastObservable ( # 104 ),311
"README . md \n - Agera is a set of classes and interfaces to help write functional , asynchronous , and reactive \n + Agera is a set of classes and interfaces to help write functional , asynchronous , and reactive \n - compile ' com . google . android . agera : agera : 1 . 0 . 0 - rc2 ' \n + compile ' com . google . android . agera : agera : 1 . 1 . 0 - beta1 ' \n - Database - For ` SQLiteDatabase ` interaction \n - Net - For ` HTTPUrlConnection ` interaction \n - RVAdapter - For ` RecyclerView ` interaction \n + - RVDatabinding - For ` RecyclerView ` data binding interaction \n - compile ' com . google . android . agera : content : 1 . 0 . 0 - rc2 ' \n - compile ' com . google . android . agera : database : 1 . 0 . 0 - rc2 ' \n - compile ' com . google . android . agera : net : 1 . 0 . 0 - rc2 ' \n - compile ' com . google . android . agera : rvadapter : 1 . 0 . 0 - rc2 ' \n + compile ' com . google . android . agera : content : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : database : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : net : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : rvadapter : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : rvdatabinding : 1 . 1 . 0 - beta1 ' \n extensions \ rvdatabinding \ build . gradle \n + apply plugin : ' com . novoda . bintray - release ' \n + \n + \n + publish { \n + userOrg = gradle . bintrayUser \n + uploadName = gradle . bintrayName \n + repoName = gradle . bintrayRepo \n + groupId = gradle . group \n + artifactId = ' rvdatabinding ' \n + version = gradle . versionName \n + autoPublish = false \n + } \n + \n settings . gradle \n - gradle . ext . versionName = ' 1 . 1 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 1 . 0 - beta1 ' \n - gradle . ext . bintrayName = ' Agera ' \n + gradle . ext . bintrayName = ' agera ' \n",Tagged 1 . 1 . 0 - beta1,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 1 . 0 - beta1 ' \n + gradle . ext . versionName = ' 1 . 1 . 0 - SNAPSHOT ' \n,Changed bin version to SNAPSHOT ( # 77 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n - return new Result < > ( null , checkNotNull ( failure ) ) ; \n + return failure = = ABSENT _ THROWABLE \n + ? Result . < T > absent ( ) : new Result < T > ( null , checkNotNull ( failure ) ) ; \n",Changed Result # failure to return absent given the absent failure ( # 75 ) \n Can potentially happen when directly wrapping a throwable in . attemptX \n . orEnd ( for instance . orEnd ( Result : : failure ) ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n - private final int shortestUpdateWindowMillis ; \n + final int shortestUpdateWindowMillis ; \n agera \ src \ main \ java \ com \ google \ android \ agera \ Observables . java \n - return new CompositeObservable ( 0 ) ; \n + return new CompositeObservable ( shortestUpdateWindowMillis ) ; \n - if ( singleObservable instanceof CompositeObservable ) { \n - return new CompositeObservable ( 0 , \n + if ( singleObservable instanceof CompositeObservable \n + & & ( ( CompositeObservable ) singleObservable ) . shortestUpdateWindowMillis = = 0 ) { \n + return new CompositeObservable ( shortestUpdateWindowMillis , \n - return new CompositeObservable ( 0 , singleObservable ) ; \n + return new CompositeObservable ( shortestUpdateWindowMillis , singleObservable ) ; \n - if ( observable instanceof CompositeObservable ) { \n + if ( observable instanceof CompositeObservable \n + & & ( ( CompositeObservable ) observable ) . shortestUpdateWindowMillis = = 0 ) { \n - return new CompositeObservable ( 0 , \n + return new CompositeObservable ( shortestUpdateWindowMillis , \n",Fixed a bug causing low pass filter not to work ( # 74 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ FunctionCompiler . java \n - Collections . sort ( input , comparator ) ; \n - return input ; \n + final List < T > output = new ArrayList < > ( input ) ; \n + Collections . sort ( output , comparator ) ; \n + return output ; \n agera \ src \ test \ java \ com \ google \ android \ agera \ FunctionsTest . java \n - assertThat ( function . apply ( INPUT _ LIST ) , contains ( 3 , 4 , 7 , 7 ) ) ; \n + final List < String > inputList = new ArrayList < > ( INPUT _ LIST ) ; \n + assertThat ( function . apply ( inputList ) , contains ( 3 , 4 , 7 , 7 ) ) ; \n + } \n + \n + @ Test \n + public void shouldNotMutateInputListWhenSorting ( ) { \n + final Function < List < String > , List < String > > function = functionFromListOf ( String . class ) \n + . thenSort ( new Comparator < String > ( ) { \n + @ Override \n + public int compare ( String lhs , String rhs ) { \n + return lhs . compareTo ( rhs ) ; \n + } \n + } ) ; \n + \n + final List < String > inputList = new ArrayList < > ( INPUT _ LIST ) ; \n + assertThat ( function . apply ( inputList ) , contains ( "" for "" , "" some "" , "" strings "" , "" testing "" ) ) ; \n + assertThat ( inputList , is ( INPUT _ LIST ) ) ; \n",Changed sort not to mutate input list ( # 78 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n - private static final Result < Object > FAILURE = \n - new Result < > ( null , new Throwable ( "" Attempt failed "" ) ) ; \n - @ SuppressWarnings ( "" ThrowableInstanceNeverThrown "" ) \n + private static final Result < Object > ABSENT ; \n - private static final Throwable ABSENT _ THROWABLE = new NullPointerException ( "" Value is absent "" ) ; \n + private static final Result < Object > FAILURE ; \n - private static final Result < Object > ABSENT = new Result < > ( null , ABSENT _ THROWABLE ) ; \n + private static final Throwable ABSENT _ THROWABLE ; \n + \n + static { \n + final Throwable failureThrowable = new Throwable ( "" Attempt failed "" ) ; \n + failureThrowable . setStackTrace ( new StackTraceElement [ 0 ] ) ; \n + FAILURE = new Result < > ( null , failureThrowable ) ; \n + ABSENT _ THROWABLE = new NullPointerException ( "" Value is absent "" ) ; \n + ABSENT _ THROWABLE . setStackTrace ( new StackTraceElement [ 0 ] ) ; \n + ABSENT = new Result < > ( null , ABSENT _ THROWABLE ) ; \n + } \n",Removed storing of nonsense stack - trace in Result default failures ( # 79 ),311
testapp \ src \ androidTest \ java \ com \ google \ android \ agera \ testapp \ NotesActivityTest . java \n - onView ( withText ( THIRD _ TEXT ) ) . perform ( longClick ( ) ) ; \n,Removed flaky part of UI test caused by RV animation,311
README . md \n - compile ' com . google . android . agera : agera : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : agera : 1 . 2 . 0 - beta3 ' \n - compile ' com . google . android . agera : content : 1 . 2 . 0 - beta2 ' \n - compile ' com . google . android . agera : database : 1 . 2 . 0 - beta2 ' \n - compile ' com . google . android . agera : net : 1 . 2 . 0 - beta2 ' \n - compile ' com . google . android . agera : rvadapter : 1 . 2 . 0 - beta2 ' \n - compile ' com . google . android . agera : rvdatabinding : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : content : 1 . 2 . 0 - beta3 ' \n + compile ' com . google . android . agera : database : 1 . 2 . 0 - beta3 ' \n + compile ' com . google . android . agera : net : 1 . 2 . 0 - beta3 ' \n + compile ' com . google . android . agera : rvadapter : 1 . 2 . 0 - beta3 ' \n + compile ' com . google . android . agera : rvdatabinding : 1 . 2 . 0 - beta3 ' \n settings . gradle \n - gradle . ext . versionName = ' 1 . 2 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 2 . 0 - beta3 ' \n,Tagged 1 . 2 . 0 - beta3,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 0 . 0 - RC1 ' \n + gradle . ext . versionName = ' 1 . 0 . 0 - SNAPSHOT ' \n,Changed version to 1 . 0 . 0 - SNAPSHOT,311
"agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n - handler . obtainMessage ( MSG _ UPDATE , this ) . sendToTarget ( ) ; \n + if ( ! handler . hasMessages ( MSG _ UPDATE , this ) ) { \n + handler . obtainMessage ( MSG _ UPDATE , this ) . sendToTarget ( ) ; \n + } \n - } else { \n + } else if ( ! handler . hasMessages ( WorkerHandler . MSG _ CALL _ UPDATABLE , updatable ) ) { \n agera \ src \ main \ java \ com \ google \ android \ agera \ Repositories . java \n - import static com . google . android . agera . Preconditions . checkState ; \n - return new SimpleRepository < > ( object , false ) ; \n + return new SimpleRepository < > ( object ) ; \n - return new SimpleRepository < > ( object , true ) ; \n + return new SimpleRepository < > ( object ) ; \n - private final boolean mutable ; \n - SimpleRepository ( @ NonNull final T reference , boolean mutable ) { \n - this . mutable = mutable ; \n + SimpleRepository ( @ NonNull final T reference ) { \n - checkState ( mutable , "" So you cast me ? "" ) ; \n",Improved performance by reducing redundant updates \n Resolves # 31,311
"agera \ src \ test \ java \ com \ google \ android \ agera \ RepositoryConfigTest . java \n - @ Ignore ( "" Interrupt test flaky on CI server "" ) \n",Turned on no longer flaky concurrency interrupt test,311
"agera \ src \ test \ java \ com \ google \ android \ agera \ RepositoryConfigTest . java \n + @ Ignore ( "" Interrupt test flaky on CI server "" ) \n","Revert "" Turned on no longer flaky concurrency interrupt test "" \n This reverts commit 77fee57c2b5f8d6cab41a8103dc8d2c34f0f6cfa .",311
settings . gradle \n - gradle . ext . versionName = ' 1 . 0 . 0 - rc2 ' \n + gradle . ext . versionName = ' 1 . 0 . 0 - SNAPSHOT ' \n,Changed version to 1 . 0 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionCode = 10000 \n - gradle . ext . versionName = ' 1 . 0 . 0 - SNAPSHOT ' \n + gradle . ext . versionCode = 10100 \n + gradle . ext . versionName = ' 1 . 1 . 0 - SNAPSHOT ' \n,Changed version to 1 . 1 . 0 - SNAPSHOT \n Master will be used for 1 . 1 . 0 features \n 1 . 0 . 0 fixes ( including the pending 1 . 0 . 0 ) to be done on the 1 . 0 . x branch \n Versioning scheme as follows ; \n Major version for compatibility break ( prey we never need it ) \n Minor version for new features \n Incremental version for bug fixes,311
"agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n - handler . obtainMessage ( WorkerHandler . MSG _ FIRST _ ADDED , this ) . sendToTarget ( ) ; \n + if ( handler . hasMessages ( MSG _ LAST _ REMOVED , this ) ) { \n + handler . removeMessages ( MSG _ LAST _ REMOVED , this ) ; \n + } else { \n + handler . obtainMessage ( WorkerHandler . MSG _ FIRST _ ADDED , this ) . sendToTarget ( ) ; \n + } \n","Changed BaseObservable to survive rotation \n If LAST _ REMOVED is sent when FIRST _ ADDED is queued , both are instead \n removed . Re - activating a repository within the same loop have no value \n and in this way a global repository can survive device rotation .",311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Common . java \n - ( ( Worker ) message . obj ) . callFirstUpdatableAdded ( ) ; \n + if ( ! hasMessages ( MSG _ LAST _ REMOVED , message . obj ) ) { \n + ( ( Worker ) message . obj ) . callFirstUpdatableAdded ( ) ; \n + } \n - ( ( Worker ) message . obj ) . callLastUpdatableRemoved ( ) ; \n + if ( ! hasMessages ( MSG _ FIRST _ ADDED , message . obj ) ) { \n + ( ( Worker ) message . obj ) . callLastUpdatableRemoved ( ) ; \n + } \n","Changed WorkerHandler to make Observables survive rotation \n If LAST _ REMOVED is queued when FIRST _ ADDED is processed , do nothing . \n If FIRST _ ADDED is queued when LAST _ REMOVED is processed , do nothing .",311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Common . java \n - if ( ! hasMessages ( MSG _ LAST _ REMOVED , message . obj ) ) { \n - ( ( Worker ) message . obj ) . callFirstUpdatableAdded ( ) ; \n - } \n + ( ( Worker ) message . obj ) . callFirstUpdatableAdded ( ) ; \n - if ( ! hasMessages ( MSG _ FIRST _ ADDED , message . obj ) ) { \n - ( ( Worker ) message . obj ) . callLastUpdatableRemoved ( ) ; \n - } \n + ( ( Worker ) message . obj ) . callLastUpdatableRemoved ( ) ; \n","Revert "" Changed WorkerHandler to make Observables survive rotation "" \n This reverts commit 459cb702e686c0e013458059672048ba4c694953 .",311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Common . java \n + import static com . google . android . agera . Result . failure ; \n + static final Function < Throwable , ? extends Result < ? > > FAILED _ RESULT = new FailedResult < > ( ) ; \n + private static final class FailedResult < T > implements Function < Throwable , Result < T > > { \n + @ NonNull \n + @ Override \n + public Result < T > apply ( @ NonNull final Throwable input ) { \n + return failure ( input ) ; \n + } \n + } \n + \n agera \ src \ main \ java \ com \ google \ android \ agera \ Functions . java \n + import static com . google . android . agera . Common . FAILED _ RESULT ; \n + / * * \n + * Returns a { @ link Function } that wraps a { @ link Throwable } in a \n + * { @ link Result # failure ( Throwable ) } ) . \n + * / \n + @ SuppressWarnings ( "" unchecked "" ) \n + @ NonNull \n + public static < T > Function < Throwable , Result < T > > failedResult ( ) { \n + return ( Function < Throwable , Result < T > > ) FAILED _ RESULT ; \n + } \n + \n agera \ src \ test \ java \ com \ google \ android \ agera \ FunctionsTest . java \n + import static com . google . android . agera . Functions . failedResult ; \n + @ Test \n + public void shouldWrapThrowableInFailedResult ( ) { \n + final Throwable throwable = new Throwable ( ) ; \n + \n + assertThat ( failedResult ( ) . apply ( throwable ) . getFailure ( ) , is ( throwable ) ) ; \n + } \n + \n","Added a function that wrap a Throwable in a Result \n When ending an attemptXYZ operation with . orSkip the failure is not \n stored in the repository ( as is the intention ) . To route the failure \n back into a repository of Result . orEnd needs to be used , and the \n Throwable needs to be wrapped in a Result . This function does exactly \n that .",311
"agera \ src \ test \ java \ com \ google \ android \ agera \ RepositoriesTest . java \n + private static final String STRING _ VALUE = "" string "" ; \n + private Binder < List < Integer > , String > mockIntegerListStringBinder ; \n + @ Mock \n + private Supplier < String > mockStringSupplier ; \n + @ Mock \n + when ( mockStringSupplier . get ( ) ) . thenReturn ( STRING _ VALUE ) ; \n + @ Test \n + public void shouldBindWith ( ) throws Exception { \n + final Repository < List < Integer > > repository = repositoryWithInitialValue ( INITIAL _ VALUE ) \n + . observe ( ) \n + . onUpdatesPerLoop ( ) \n + . bindWith ( mockStringSupplier , mockIntegerListStringBinder ) \n + . thenSkip ( ) \n + . compile ( ) ; \n + \n + updatable . addToObservable ( repository ) ; \n + \n + verify ( mockIntegerListStringBinder ) . bind ( INITIAL _ VALUE , STRING _ VALUE ) ; \n + assertThat ( updatable , wasNotUpdated ( ) ) ; \n + assertThat ( repository , has ( INITIAL _ VALUE ) ) ; \n + } \n + \n agera \ src \ test \ java \ com \ google \ android \ agera \ ResultTest . java \n + @ Test \n + public void shouldHaveSameHashcodeForSameFailure ( ) { \n + assertThat ( FAILURE _ WITH _ THROWABLE , hasHashCodeOf ( failure ( THROWABLE ) ) ) ; \n + } \n + \n",Added missing Repository bindWith unit test \n Also bumped coverage of Result,311
README . md \n - compile ' com . google . android . agera : agera : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : agera : 1 . 1 . 0 - beta2 ' \n - compile ' com . google . android . agera : content : 1 . 1 . 0 - beta1 ' \n - compile ' com . google . android . agera : database : 1 . 1 . 0 - beta1 ' \n - compile ' com . google . android . agera : net : 1 . 1 . 0 - beta1 ' \n - compile ' com . google . android . agera : rvadapter : 1 . 1 . 0 - beta1 ' \n - compile ' com . google . android . agera : rvdatabinding : 1 . 1 . 0 - beta1 ' \n + compile ' com . google . android . agera : content : 1 . 1 . 0 - beta2 ' \n + compile ' com . google . android . agera : database : 1 . 1 . 0 - beta2 ' \n + compile ' com . google . android . agera : net : 1 . 1 . 0 - beta2 ' \n + compile ' com . google . android . agera : rvadapter : 1 . 1 . 0 - beta2 ' \n + compile ' com . google . android . agera : rvdatabinding : 1 . 1 . 0 - beta2 ' \n settings . gradle \n - gradle . ext . versionName = ' 1 . 1 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 1 . 0 - beta2 ' \n,Tagged 1 . 1 . 0 - beta2,311
settings . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 1 . 0 ' \n + classpath ' com . android . tools . build : gradle : 2 . 1 . 2 ' \n,Changed gradle plugin version to 2 . 1 . 2 ( # 91 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n + @ SuppressWarnings ( "" ThrowableInstanceNeverThrown "" ) \n - private static final Result < Object > ABSENT = \n - new Result < > ( null , new NullPointerException ( "" Value is absent "" ) ) ; \n + private static final Throwable ABSENT _ THROWABLE = new NullPointerException ( "" Value is absent "" ) ; \n + @ NonNull \n + private static final Result < Object > ABSENT = new Result < > ( null , ABSENT _ THROWABLE ) ; \n - if ( failure ! = null & & failure = = ABSENT . failure ) { \n + if ( failure = = ABSENT _ THROWABLE ) { \n - if ( failure ! = null & & failure ! = ABSENT . failure ) { \n + if ( failure ! = null & & failure ! = ABSENT _ THROWABLE ) { \n agera \ src \ test \ java \ com \ google \ android \ agera \ ResultTest . java \n + @ Test \n + public void shouldNotApplySendIfSucceededIfAbsent ( ) { \n + SUCCESS _ WITH _ VALUE . ifNonAbsentFailureSendTo ( mockThrowableReceiver ) ; \n + \n + verifyZeroInteractions ( mockThrowableReceiver ) ; \n + } \n + \n + @ Test \n + public void shouldNotApplySendIfFailedAbsentIfSucceeded ( ) { \n + failure ( THROWABLE ) . ifAbsentFailureSendTo ( mockThrowableReceiver ) ; \n + \n + verifyZeroInteractions ( mockThrowableReceiver ) ; \n + } \n + \n",Added missing tests to ( non ) absent send result methods,311
"agera \ src \ test \ java \ com \ google \ android \ agera \ ObservablesTest . java \n + import static org . hamcrest . Matchers . is ; \n + import android . support . annotation . NonNull ; \n + import java . util . concurrent . atomic . AtomicBoolean ; \n + @ Test \n + public void shouldNotAllowAddingUpdatablesOnNonLooperThreadInBaseObservable ( ) { \n + final Observable observable = new BaseObservable ( ) { } ; \n + \n + assertThat ( throwsIllegalStateExceptionForCallOnNonLooperThread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + updatable . addToObservable ( observable ) ; \n + } \n + } ) , is ( true ) ) ; \n + } \n + \n + @ Test \n + public void shouldNotAllowCreatingBaseObservableOnNonLooperThread ( ) { \n + \n + assertThat ( throwsIllegalStateExceptionForCallOnNonLooperThread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + new BaseObservable ( ) { } ; \n + } \n + } ) , is ( true ) ) ; \n + } \n + \n + @ Test \n + public void shouldNotAllowRemovingUpdatablesOnNonLooperThreadInBaseObservable ( ) { \n + final Observable observable = new BaseObservable ( ) { } ; \n + updatable . addToObservable ( observable ) ; \n + \n + assertThat ( throwsIllegalStateExceptionForCallOnNonLooperThread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + updatable . removeFromObservables ( ) ; \n + } \n + } ) , is ( true ) ) ; \n + } \n + \n + @ Test \n + public void shouldHandleLifeCycleInBaseObservable ( ) { \n + final Observable observable = new BaseObservable ( ) { } ; \n + \n + updatable . addToObservable ( observable ) ; \n + updatable . removeFromObservables ( ) ; \n + } \n + \n + \n + private boolean throwsIllegalStateExceptionForCallOnNonLooperThread ( \n + @ NonNull final Runnable runnable ) { \n + final AtomicBoolean gotException = new AtomicBoolean ( false ) ; \n + final Thread thread = new Thread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + try { \n + runnable . run ( ) ; \n + } catch ( IllegalStateException e ) { \n + gotException . set ( true ) ; \n + } \n + } \n + } ) ; \n + thread . start ( ) ; \n + try { \n + thread . join ( ) ; \n + } catch ( InterruptedException ignored ) { \n + } \n + return gotException . get ( ) ; \n + } \n",Added test of illegal add / remove from non looper thread,311
agera \ src \ main \ java \ com \ google \ android \ agera \ Repositories . java \n - if ( this . reference . equals ( checkNotNull ( reference ) ) ) { \n + if ( reference . equals ( this . reference ) ) { \n,Made a slight perf improvement of single repository ( # 55 ) \n Removed checkNotNull but kept the behaviour of throwing \n NullPointerException,311
agera \ src \ main \ java \ com \ google \ android \ agera \ Repositories . java \n - public synchronized void accept ( @ NonNull final T reference ) { \n - if ( reference . equals ( this . reference ) ) { \n - / / Keep the old reference to have a slight performance edge if GC is generational . \n - return ; \n + public void accept ( @ NonNull final T reference ) { \n + synchronized ( this ) { \n + if ( reference . equals ( this . reference ) ) { \n + / / Keep the old reference to have a slight performance edge if GC is generational . \n + return ; \n + } \n + this . reference = reference ; \n - this . reference = reference ; \n,Improved performance on SimpleRepository ( # 57 ) \n Excluded the update from the lock around reference,311
agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n + import static com . google . android . agera . Preconditions . checkNotNull ; \n + checkNotNull ( updatable ) ; \n + checkNotNull ( updatable ) ; \n agera \ src \ test \ java \ com \ google \ android \ agera \ ObservablesTest . java \n + @ Test ( expected = NullPointerException . class ) \n + public void shouldThrowNullPointerExceptionForAddNullUpdatable ( ) { \n + updateDispatcher . addUpdatable ( null ) ; \n + } \n + \n + @ Test ( expected = NullPointerException . class ) \n + public void shouldThrowNullPointerExceptionForRemoveNullUpdatable ( ) { \n + updateDispatcher . removeUpdatable ( null ) ; \n + } \n,Changed BaseObservable to throw NPE if adding / removing null updatable ( # 60 ) \n Fixes # 51,311
agera \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n extensions \ content \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n extensions \ database \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n extensions \ net \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n extensions \ rvadapter \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n extensions \ rvdatabinding \ build . gradle \n + defaultConfig { \n + minSdkVersion gradle . minSdkVersion \n + } \n settings . gradle \n - minSdkVersion gradle . minSdkVersion \n testapp \ build . gradle \n + minSdkVersion 14 \n,Changed gradle files to minSdkVersion for each lib ( # 65 ),311
agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n - pendingUpdate = true ; \n,Removed unnecessary pendingUpdate update in BaseObservable ( # 68 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n + boolean activateNow = false ; \n + } else if ( Looper . myLooper ( ) = = handler . getLooper ( ) ) { \n + activateNow = true ; \n + if ( activateNow ) { \n + observableActivated ( ) ; \n + } \n - if ( timeFromLastUpdate < shortestUpdateWindowMillis ) { \n + if ( timeFromLastUpdate < shortestUpdateWindowMillis ) { \n agera \ src \ test \ java \ com \ google \ android \ agera \ RepositoriesTest . java \n + import static org . mockito . Mockito . atLeastOnce ; \n - verify ( mockIntegerListToIntValueFunction ) . apply ( LIST ) ; \n + verify ( mockIntegerListToIntValueFunction , atLeastOnce ( ) ) . apply ( LIST ) ; \n",Changed observable activated to be called immediately ( # 58 ) \n When adding an updatable observableActivated is now called immediately \n if the updatable is added from the same looper as the observable is \n operating on,311
README . md \n - [ GitHub project ] ( https : / / github . com / google / agera ) \n - [ Issue tracker ] ( https : / / github . com / google / agera / issues / new ) \n + \n + # # # ( Unofficial ) wiki translations \n + \n + - [ Chinese ] ( https : / / github . com / captain - miao / AndroidAgeraTutorial / wiki ) \n + - [ Korean ] ( https : / / github . com / ZeroBrain / agera - wiki - kr / wiki ) \n,Added links to unofficial translations to README ( # 82 ) \n Fixes # 33 \n Fixes # 81,311
"agera \ src \ main \ java \ com \ google \ android \ agera \ FunctionCompiler . java \n + import com . google . android . agera . FunctionCompilerStates . FItem ; \n + import com . google . android . agera . FunctionCompilerStates . FList ; \n + \n - @ SuppressWarnings ( "" unchecked "" ) \n - final class FunctionCompiler implements FunctionCompilerStates . FList , FunctionCompilerStates . FItem { \n + @ SuppressWarnings ( { "" unchecked , rawtypes "" } ) \n + final class FunctionCompiler implements FList , FItem { \n - public FunctionCompilerStates . FList unpack ( @ NonNull final Function function ) { \n + public FList unpack ( @ NonNull final Function function ) { \n - public FunctionCompilerStates . FItem apply ( @ NonNull final Function function ) { \n + public FItem apply ( @ NonNull final Function function ) { \n - public FunctionCompilerStates . FList morph ( @ NonNull Function function ) { \n + public FList morph ( @ NonNull Function function ) { \n - public FunctionCompilerStates . FList filter ( @ NonNull final Predicate filter ) { \n + public FList filter ( @ NonNull final Predicate filter ) { \n - public FunctionCompilerStates . FList limit ( final int limit ) { \n + public FList limit ( final int limit ) { \n - public FunctionCompilerStates . FList sort ( @ NonNull final Comparator comparator ) { \n + public FList sort ( @ NonNull final Comparator comparator ) { \n - public FunctionCompilerStates . FList map ( @ NonNull final Function function ) { \n + public FList map ( @ NonNull final Function function ) { \n extensions \ database \ src \ main \ java \ com \ google \ android \ agera \ database \ SqlRequestCompiler . java \n - import static com . google . android . agera . database . SqlRequestCompilerStates . DBColumnConflictCompile ; \n - import static com . google . android . agera . database . SqlRequestCompilerStates . DBColumnWhereConflictCompile ; \n + import com . google . android . agera . database . SqlRequestCompilerStates . DBColumnConflictCompile ; \n + import com . google . android . agera . database . SqlRequestCompilerStates . DBColumnWhereConflictCompile ; \n + @ SuppressWarnings ( { "" unchecked , rawtypes "" } ) \n extensions \ rvadapter \ src \ main \ java \ com \ google \ android \ agera \ rvadapter \ RepositoryPresenterCompiler . java \n - import static com . google . android . agera . rvadapter . RepositoryPresenterCompilerStates . RPViewBinderCompile ; \n + import com . google . android . agera . rvadapter . RepositoryPresenterCompilerStates . RPViewBinderCompile ; \n - @ SuppressWarnings ( "" unchecked "" ) \n + @ SuppressWarnings ( { "" unchecked , rawtypes "" } ) \n",Fixed a few static analysis warnings ( # 83 ),311
settings . gradle \n - gradle . ext . supportLibraryVersion = ' 23 . 3 . 0 ' \n + gradle . ext . supportLibraryVersion = ' 23 . 4 . 0 ' \n,Updated to latest support lib ( # 84 ),311
settings . gradle \n - gradle . ext . versionCode = 10100 \n - gradle . ext . versionName = ' 1 . 1 . 0 ' \n + gradle . ext . versionCode = 10200 \n + gradle . ext . versionName = ' 1 . 2 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 2 . 0 - SNAPSHOT ( # 88 ),311
testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesActivity . java \n - setThreadPolicy ( new ThreadPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . penaltyDeath ( ) . build ( ) ) ; \n - setVmPolicy ( new VmPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . penaltyDeath ( ) . build ( ) ) ; \n + setThreadPolicy ( new ThreadPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n + setVmPolicy ( new VmPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n,Removed penaltyDeath from test app \n To make life easier for potential Huawei users of the test app,311
"agera \ src \ main \ java \ com \ google \ android \ agera \ ActivationHandler . java \n - * service of the service can implement an < i > active < / i > / < i > inactive < / i > lifecycle , \n - * saving memory and execution time when not needed . \n + * service can implement an < i > active < / i > / < i > inactive < / i > lifecycle , saving memory and execution \n + * time when not needed . \n agera \ src \ main \ java \ com \ google \ android \ agera \ BaseObservable . java \n + / / Pairs of updatables and their associated handlers . Always of even length . \n agera \ src \ test \ java \ com \ google \ android \ agera \ test \ mocks \ MockUpdatable . java \n - private final List < Observable > observables = new ArrayList < > ( ) ; \n + private final List < Observable > observables ; \n - private boolean updated = false ; \n + private boolean updated ; \n - private MockUpdatable ( ) { } \n + private MockUpdatable ( ) { \n + this . observables = new ArrayList < > ( ) ; \n + this . updated = false ; \n + } \n",Tidied up a few minor issues found in review ( # 108 ),311
agera \ src \ main \ java \ com \ google \ android \ agera \ Observables . java \n - private AsyncUpdateDispatcher ( @ Nullable ActivationHandler activationHandler ) { \n + private AsyncUpdateDispatcher ( @ Nullable final ActivationHandler activationHandler ) { \n,Added missing final in AsyncUpdateDispatcher ( # 94 ),311
"agera \ src \ test \ java \ com \ google \ android \ agera \ ObservablesTest . java \n + @ Test \n + public void shouldUpdateCompositeOfPerMillisecondObservable ( ) { \n + final long expectedDelayedTime = scheduler . getCurrentTime ( ) + FILTER _ TIME ; \n + updatable . addToObservable ( compositeObservable ( perMillisecondObservable ( \n + FILTER _ TIME , updateDispatcher ) , updateDispatcher ( ) ) ) ; \n + \n + updateDispatcher . update ( ) ; \n + idleMainLooper ( FILTER _ TIME ) ; \n + \n + assertThat ( updatable , wasUpdated ( ) ) ; \n + assertThat ( scheduler . getCurrentTime ( ) , greaterThanOrEqualTo ( expectedDelayedTime ) ) ; \n + } \n + \n + @ Test \n + public void shouldUpdateCompositeOfSinglePerMillisecondObservable ( ) { \n + final long expectedDelayedTime = scheduler . getCurrentTime ( ) + FILTER _ TIME ; \n + updatable . addToObservable ( compositeObservable ( perMillisecondObservable ( \n + FILTER _ TIME , updateDispatcher ) ) ) ; \n + \n + updateDispatcher . update ( ) ; \n + idleMainLooper ( FILTER _ TIME ) ; \n + \n + assertThat ( updatable , wasUpdated ( ) ) ; \n + assertThat ( scheduler . getCurrentTime ( ) , greaterThanOrEqualTo ( expectedDelayedTime ) ) ; \n + } \n + \n agera \ src \ test \ java \ com \ google \ android \ agera \ ResultTest . java \n + @ Test \n + public void shouldReturnAbsentForFailureWithAbsentFailure ( ) { \n + assertThat ( Result . < Integer > failure ( ABSENT . getFailure ( ) ) , sameInstance ( ABSENT ) ) ; \n + } \n + \n",Added a few missing unit tests ( # 98 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ FunctionCompiler . java \n + private static final ThreadLocal < FunctionCompiler > compilers = new ThreadLocal < > ( ) ; \n + \n + @ NonNull \n + static FunctionCompiler functionCompiler ( ) { \n + FunctionCompiler compiler = compilers . get ( ) ; \n + if ( compiler = = null ) { \n + compiler = new FunctionCompiler ( ) ; \n + } else { \n + / / Remove compiler from the ThreadLocal to prevent reuse in the middle of a compilation . \n + / / recycle ( ) , called by compile ( ) , will return the compiler here . ThreadLocal . set ( null ) keeps \n + / / the entry ( with a null value ) whereas remove ( ) removes the entry ; because we expect the \n + / / return of the compiler , don ' t use the heavier remove ( ) . \n + compilers . set ( null ) ; \n + } \n + return compiler ; \n + } \n + \n + private static void recycle ( @ NonNull final FunctionCompiler compiler ) { \n + compiler . functions . clear ( ) ; \n + compilers . set ( compiler ) ; \n + } \n + \n - return new ChainFunction ( functions . toArray ( new Function [ functions . size ( ) ] ) ) ; \n + final Function [ ] newFunctions = functions . toArray ( new Function [ functions . size ( ) ] ) ; \n + recycle ( this ) ; \n + return new ChainFunction ( newFunctions ) ; \n - public FList morph ( @ NonNull Function function ) { \n + public FList morph ( @ NonNull final Function function ) { \n agera \ src \ main \ java \ com \ google \ android \ agera \ Functions . java \n + import static com . google . android . agera . FunctionCompiler . functionCompiler ; \n - return new FunctionCompiler ( ) ; \n + return functionCompiler ( ) ; \n - return new FunctionCompiler ( ) ; \n + return functionCompiler ( ) ; \n",Reused function compiler instance per thread ( # 100 ),311
README . md \n - compile ' com . google . android . agera : agera : 1 . 1 . 0 ' \n + compile ' com . google . android . agera : agera : 1 . 2 . 0 - beta2 ' \n - compile ' com . google . android . agera : content : 1 . 1 . 0 ' \n - compile ' com . google . android . agera : database : 1 . 1 . 0 ' \n - compile ' com . google . android . agera : net : 1 . 1 . 0 ' \n - compile ' com . google . android . agera : rvadapter : 1 . 1 . 0 ' \n - compile ' com . google . android . agera : rvdatabinding : 1 . 1 . 0 ' \n + compile ' com . google . android . agera : content : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : database : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : net : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : rvadapter : 1 . 2 . 0 - beta2 ' \n + compile ' com . google . android . agera : rvdatabinding : 1 . 2 . 0 - beta2 ' \n settings . gradle \n - gradle . ext . versionName = ' 1 . 2 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 2 . 0 - beta2 ' \n,Tagged 1 . 2 . 0 - beta2,311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n + public boolean contains ( @ NonNull final T value ) { \n + return this . value ! = null & & this . value . equals ( value ) ; \n + } \n + \n agera \ src \ test \ java \ com \ google \ android \ agera \ ResultTest . java \n + import static org . hamcrest . Matchers . is ; \n + @ Test \n + public void shouldReturnTrueForContainsOfSameValue ( ) { \n + assertThat ( SUCCESS _ WITH _ VALUE . contains ( VALUE ) , is ( true ) ) ; \n + } \n + \n + @ Test \n + public void shouldReturnFalseForContainsOfOtherValue ( ) { \n + assertThat ( SUCCESS _ WITH _ OTHER _ VALUE . contains ( VALUE ) , is ( false ) ) ; \n + } \n + \n + @ Test \n + public void shouldReturnFalseForContainsOfFailure ( ) { \n + assertThat ( ABSENT . contains ( VALUE ) , is ( false ) ) ; \n + } \n + \n",Added contains to result ( # 118 ),311
settings . gradle \n + testOptions { \n + unitTests . all { \n + jacoco { \n + includeNoLocationClasses = true \n + } \n + } \n + } \n,Fixed coverage missing after move to 25 ( # 119 ),311
settings . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 2 ' \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 3 ' \n,Changed gradle plugin version ( # 120 ),311
settings . gradle \n - gradle . ext . versionCode = 10200 \n - gradle . ext . versionName = ' 1 . 2 . 0 ' \n + gradle . ext . versionCode = 10300 \n + gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 3 . 0 - SNAPSHOT,311
"extensions \ rvadapter \ src \ main \ java \ com \ google \ android \ agera \ rvadapter \ RepositoryPresenterCompilerStates . java \n - TRet stableIdForItem ( @ NonNull Function < TVal , Long > stableIdForItem ) ; \n + TRet stableIdForItem ( @ NonNull Function < ? super TVal , Long > stableIdForItem ) ; \n extensions \ rvadapter \ src \ test \ java \ com \ google \ android \ agera \ rvadapter \ RepositoryPresentersTest . java \n + \n + @ Test \n + public void shouldAllowStableIdMethodForAnySuperType ( ) { \n + repositoryPresenterOf ( String . class ) \n + . layout ( LAYOUT _ ID ) \n + . stableIdForItem ( Functions . < CharSequence , Long > staticFunction ( STABLE _ ID ) ) \n + . forResult ( ) ; \n + } \n",Changed stableIdForItem function to allow for any super type ( # 117 ),311
". travis . yml \n - tools \n - platform - tools \n - - build - tools - 24 . 0 . 0 \n - - android - 24 \n + - build - tools - 25 . 0 . 1 \n + - android - 25 \n - extra - android - m2repository \n - oraclejdk8 \n gradle \ wrapper \ gradle - wrapper . properties \n - # Mon Dec 28 10 : 00 : 20 PST 2015 \n + # Sun Nov 27 21 : 36 : 49 GMT 2016 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 10 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 14 . 1 - all . zip \n settings . gradle \n - gradle . ext . compileSdkVersion = 24 \n - gradle . ext . buildToolsVersion = ' 24 . 0 . 0 ' \n - gradle . ext . supportLibraryVersion = ' 24 . 1 . 1 ' \n + gradle . ext . compileSdkVersion = 25 \n + gradle . ext . buildToolsVersion = ' 25 . 0 . 1 ' \n + gradle . ext . supportLibraryVersion = ' 25 . 0 . 1 ' \n - classpath ' com . android . tools . build : gradle : 2 . 1 . 2 ' \n - classpath ' com . github . dcendents : android - maven - gradle - plugin : 1 . 3 ' \n + classpath ' com . android . tools . build : gradle : 2 . 2 . 2 ' \n + classpath ' com . github . dcendents : android - maven - gradle - plugin : 1 . 5 ' \n testapp \ build . gradle \n + resolutionStrategy . force "" com . android . support : support - v4 : $ gradle . supportLibraryVersion "" \n",Upgraded to android 25 / gradle 2 . 2 ( # 116 ),311
agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n - return value ! = null ? value : checkNotNull ( supplier . get ( ) ) ; \n + return value ! = null ? value : Preconditions . < T > checkNotNull ( supplier . get ( ) ) ; \n,Expanded a static import in Result ( # 122 ) \n The import caused an ( unwarranted ) error in Android Studio ( not in javac ),311
"testapp \ src \ main \ AndroidManifest . xml \n - < application > \n - < activity android : name = "" com . google . android . agera . testapp . NotesActivity "" \n + < application android : name = "" . NotesApplication "" > \n + < activity android : name = "" . NotesActivity "" \n testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesActivity . java \n - / / Setup strict mode , no violations using Agera \n - setThreadPolicy ( new ThreadPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n - setVmPolicy ( new VmPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n - \n new file \n testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesApplication . java \n + package com . google . android . agera . testapp ; \n + \n + import static android . os . StrictMode . setThreadPolicy ; \n + import static android . os . StrictMode . setVmPolicy ; \n + \n + import android . app . Application ; \n + import android . os . StrictMode . ThreadPolicy ; \n + import android . os . StrictMode . VmPolicy ; \n + \n + public final class NotesApplication extends Application { \n + @ Override \n + public void onCreate ( ) { \n + super . onCreate ( ) ; \n + setThreadPolicy ( new ThreadPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n + setVmPolicy ( new VmPolicy . Builder ( ) . detectAll ( ) . penaltyLog ( ) . build ( ) ) ; \n + } \n + } \n",Moved testapp strict mode config to Application ( # 123 ),311
testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ Note . java \n - public int getId ( ) { \n + public long getId ( ) { \n testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesFragment . java \n - import com . google . android . agera . Predicate ; \n - . stableIdForItem ( input - > ( long ) input . getId ( ) ) \n + . stableIdForItem ( Note : : getId ) \n,Simplified call to testapp note stable id ( # 127 ),311
testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesFragment . java \n + private RecyclerView recyclerView ; \n - final RecyclerView recyclerView = ( RecyclerView ) view . findViewById ( R . id . result ) ; \n + recyclerView = ( RecyclerView ) view . findViewById ( R . id . result ) ; \n + \n + @ Override \n + public void onDestroyView ( ) { \n + super . onDestroyView ( ) ; \n + recyclerView . setAdapter ( null ) ; \n + } \n,Cleared out the testapp adapter in onDestroyView ( # 131 ),311
testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesFragment . java \n + recyclerView = null ; \n,Clear out test app recyclerview ref . in onDestroyView ( # 132 ),311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - alpha1 ' \n,Tagged 1 . 3 . 0 - alpha1,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - alpha1 ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 3 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . supportLibraryVersion = ' 25 . 0 . 1 ' \n + gradle . ext . supportLibraryVersion = ' 25 . 1 . 0 ' \n,Changed support lib version ( # 135 ),311
"extensions \ rvdatabinding \ src \ main \ java \ com \ google \ android \ agera \ rvdatabinding \ DataBindingRepositoryPresenterCompilerStates . java \n + import com . google . android . agera . Repository ; \n + import com . google . android . agera . rvadapter . RepositoryPresenter ; \n + / * * \n + * Container of the compiler state interfaces supporting the creation of a data binding \n + * { @ link RepositoryPresenter } . \n + * / \n + \n + / * * \n + * Compiler state to specify how to bind the { @ code View } using data binding . \n + * / \n + \n + / * * \n + * Specifies a data binding @ { code itemId } from the previously given { @ code layout } to bind a \n + * single item in the { @ link Repository } . \n + * / \n + / * * \n + * Specifies a { @ link Function } to return a data binding @ { code itemId } from the previously \n + * given { @ code layout } to bind a single item in the { @ link Repository } . \n + * / \n + / * * \n + * Compiler state to specify index independent handlers from the given { @ code layout } . \n + * / \n + / * * \n + * Specifies what { @ code handler } is associated with the { @ code handlerId } in the previously \n + * given { @ code layout } . \n + * / \n + / * * \n + * Compiler state allowing to specify handlers , Recycle , StableId or compile . \n + * / \n",Documented the data binding repo presenter compiler ( # 139 ),311
settings . gradle \n - gradle . ext . supportLibraryVersion = ' 25 . 1 . 0 ' \n + gradle . ext . supportLibraryVersion = ' 25 . 1 . 1 ' \n,Changed support lib to 25 . 1 . 1 ( # 141 ),311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - alpha3 ' \n,Tagged 1 . 3 . 0 - alpha3,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - alpha3 ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 3 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 4 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - alpha2 ' \n,Tagged 1 . 3 . 0 - alpha2,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 3 . 0 - alpha2 ' \n + gradle . ext . versionName = ' 1 . 3 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 3 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionCode = 10300 \n - gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n + gradle . ext . versionCode = 10400 \n + gradle . ext . versionName = ' 1 . 4 . 0 - alpha1 ' \n,Tagged 1 . 4 . 0 - alpha1,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 4 . 0 - alpha1 ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 4 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - alpha2 ' \n,Tagged 1 . 4 . 0 - alpha2,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 4 . 0 - alpha2 ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 4 . 0 - SNAPSHOT,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - alpha4 ' \n,Tagged 1 . 4 . 0 - alpha4,311
settings . gradle \n - gradle . ext . versionName = ' 1 . 4 . 0 - alpha4 ' \n + gradle . ext . versionName = ' 1 . 4 . 0 - SNAPSHOT ' \n,Changed bin version to 1 . 4 . 0 - SNAPSHOT,311
"testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ NotesFragment . java \n + import android . support . v7 . widget . RecyclerView . RecycledViewPool ; \n + private RecycledViewPool pool ; \n - final RowHandler < NoteGroup , List < Note > > rowHandler = rowBinder ( \n + pool = new RecycledViewPool ( ) ; \n + final RowHandler < NoteGroup , List < Note > > rowHandler = rowBinder ( pool , \n + pool . clear ( ) ; \n testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ RowHandler . java \n - private RowHandler ( @ NonNull final Function < TRow , TRowItems > data , \n + private RowHandler ( @ NonNull final RecycledViewPool pool , \n + @ NonNull final Function < TRow , TRowItems > data , \n - this . pool = new RecycledViewPool ( ) ; \n + this . pool = pool ; \n + @ NonNull final RecycledViewPool pool , \n - return new RowHandler < > ( dataFunction , stableIdFunction , presenterFromView , layoutManager ) ; \n + return new RowHandler < > ( pool , dataFunction , stableIdFunction , presenterFromView , layoutManager ) ; \n",Extracted pool from test app row handler ( # 138 ),311
"extensions \ rvdatabinding \ src \ main \ java \ com \ google \ android \ agera \ rvdatabinding \ DataBindingRepositoryPresenterCompiler . java \n - public Object handler ( @ LayoutRes final int handlerId , @ NonNull final Object handler ) { \n + public Object handler ( final int handlerId , @ NonNull final Object handler ) { \n - public Object itemId ( @ LayoutRes final int itemId ) { \n + public Object itemId ( final int itemId ) { \n extensions \ rvdatabinding \ src \ main \ java \ com \ google \ android \ agera \ rvdatabinding \ DataBindingRepositoryPresenterCompilerStates . java \n - import android . support . annotation . LayoutRes ; \n - TRet itemId ( @ LayoutRes int itemId ) ; \n + TRet itemId ( int itemId ) ; \n - TRet handler ( @ LayoutRes int handlerId , @ NonNull Object handler ) ; \n + TRet handler ( int handlerId , @ NonNull Object handler ) ; \n",Removed layout annotation from data binding methods ( # 136 ),311
"agera \ src \ main \ java \ com \ google \ android \ agera \ Result . java \n + import static java . util . Collections . singletonList ; \n + import java . util . Collections ; \n + import java . util . List ; \n + private transient volatile List < T > list ; \n + @ Nullable \n + this . list = value ! = null ? null : Collections . < T > emptyList ( ) ; \n + \n + / * * \n + * Returns a list containing the value if it is present , or an empty list . \n + * / \n + @ NonNull \n + public List < T > asList ( ) { \n + List < T > list = this . list ; \n + if ( list = = null ) { \n + synchronized ( this ) { \n + list = this . list ; \n + if ( list = = null ) { \n + this . list = list = singletonList ( value ) ; \n + } \n + } \n + } \n + return list ; \n + } \n + \n agera \ src \ test \ java \ com \ google \ android \ agera \ ResultTest . java \n + import static org . hamcrest . Matchers . contains ; \n + import static org . hamcrest . Matchers . empty ; \n - public void shouldVerifyEqualsForSqlDeleteRequest ( ) { \n + public void shouldVerifyEqualsForResult ( ) { \n + \n + @ Test \n + public void shouldReturnEmptyListForAbsent ( ) { \n + assertThat ( ABSENT . asList ( ) , is ( ( empty ( ) ) ) ) ; \n + } \n + \n + @ Test \n + public void shouldReturnEmptyListForFailure ( ) { \n + assertThat ( FAILURE . asList ( ) , is ( ( empty ( ) ) ) ) ; \n + } \n + \n + @ Test \n + public void shouldReturnListWithValueForPresentWithValue ( ) { \n + assertThat ( PRESENT _ WITH _ VALUE . asList ( ) , contains ( VALUE ) ) ; \n + } \n",Added Result # asList method ( # 148 ),311
"testapp \ src \ main \ java \ com \ google \ android \ agera \ testapp \ RowHandler . java \n - final LayoutManager layoutManager = recyclerView . getLayoutManager ( ) ; \n - final Parcelable state = itemRowStates . get ( id ) ; \n - layoutManager . onRestoreInstanceState ( state ) ; \n - if ( state = = null ) { \n - layoutManager . scrollToPosition ( 0 ) ; \n - } \n - } \n - \n - @ Override \n - public void onScrollStateChanged ( final RecyclerView recyclerView , final int newState ) { \n - if ( recyclerView ! = null \n - & & recyclerView . getLayoutManager ( ) ! = null ) { \n - itemRowStates . put ( previousStableIds . get ( recyclerView . getAdapter ( ) ) , \n - recyclerView . getLayoutManager ( ) . onSaveInstanceState ( ) ) ; \n - } \n + recyclerView . getLayoutManager ( ) . onRestoreInstanceState ( itemRowStates . get ( id ) ) ; \n + itemRowStates . put ( previousStableIds . get ( adapter ) , \n + recyclerView . getLayoutManager ( ) . onSaveInstanceState ( ) ) ; \n",Simplified test app row handler ( # 140 ),311
extensions \ rvdatabinding \ src \ main \ java \ com \ google \ android \ agera \ rvdatabinding \ RecycleConfig . java \n - int CLEAR _ HANDLERS = 2 ; \n + int CLEAR _ HANDLERS = 1 < < 1 ; \n settings . gradle \n - gradle . ext . supportLibraryVersion = ' 25 . 1 . 1 ' \n + gradle . ext . supportLibraryVersion = ' 25 . 2 . 0 ' \n,"Fixed lint warnings , updated to support lib 25 . 2 . 0 ( # 151 )",311
new file \n DaoGenerator \ performance \ performance - data . xlsx \n Binary files / dev / null and b / DaoGenerator / performance / performance - data . xlsx differ \n,Collected performance data : greenDAO vs . ORMLite,317
"DaoGenerator \ . classpath \n - < classpathentry kind = "" src "" path = "" src - gen - testentities "" / > \n + < classpathentry kind = "" src "" path = "" src - generator - testentities "" / > \n rename from DaoGenerator \ src - gen - testentities \ de \ greenrobot \ daogenerator \ gentest \ TestDaoGenerator . java \n rename to DaoGenerator \ src - generator - testentities \ de \ greenrobot \ daogenerator \ gentest \ TestDaoGenerator . java \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ DaoGenerator . java \n + \n - outDirFile . mkdirs ( ) ; \n + if ( ! outDirFile . exists ( ) ) { \n + throw new IOException ( outDir + "" does not exist . This check is to prevent accidential file generation into a wrong path . "" ) ; \n + } \n","out path must exist , changed src dir",317
"DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoTestSinglePk . java \n - T entity1 = createEntity ( null ) ; \n - if ( daoAccess . isEntityUpdateable ( ) & & entity1 ! = null ) { \n - T entity2 = createEntity ( null ) ; \n + if ( daoAccess . isEntityUpdateable ( ) ) { \n + T entity1 = createEntity ( null ) ; \n + if ( entity1 ! = null ) { \n + T entity2 = createEntity ( null ) ; \n - dao . insert ( entity1 ) ; \n - dao . insert ( entity2 ) ; \n + dao . insert ( entity1 ) ; \n + dao . insert ( entity2 ) ; \n - K pk1 = daoAccess . getKey ( entity1 ) ; \n - K pk2 = daoAccess . getKey ( entity2 ) ; \n + K pk1 = daoAccess . getKey ( entity1 ) ; \n + K pk2 = daoAccess . getKey ( entity2 ) ; \n - assertFalse ( pk1 . equals ( pk2 ) ) ; \n + assertFalse ( pk1 . equals ( pk2 ) ) ; \n - assertNotNull ( dao . load ( pk1 ) ) ; \n - assertNotNull ( dao . load ( pk2 ) ) ; \n + assertNotNull ( dao . load ( pk1 ) ) ; \n + assertNotNull ( dao . load ( pk2 ) ) ; \n + } else { \n + DaoLog . d ( "" Skipping testAssignPk for "" + daoClass + "" ( createEntity returned null for null key ) "" ) ; \n + } \n - DaoLog . d ( "" Skipping testAssignPk for "" + daoClass ) ; \n + DaoLog . d ( "" Skipping testAssignPk for not updateable "" + daoClass ) ; \n DaoGenerator \ src - template \ entity . ftl \n + \n","fixed testAssignPk for protobuf tests , new line",317
"new file \n DaoCore \ res \ values \ dummy . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + \n + < / resources > \n new file \n DaoTest \ res \ values \ dummy . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + \n + < / resources > \n",added dummy ressources as a workaround for the git empty directory \n problem,317
"DaoTest \ src \ de \ greenrobot \ daotest \ QueryBuilderSimpleTest . java \n - TestEntity testEntity3 = dao . queryBuilder ( ) . where ( Properties . SimpleDate . eq ( date . getTime ( ) ) ) . uniqueOrThrow ( ) ; \n - assertEquals ( testEntity . getId ( ) , testEntity3 . getId ( ) ) ; \n + testEntity2 = dao . queryBuilder ( ) . where ( Properties . SimpleDate . eq ( date . getTime ( ) ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntity . getId ( ) , testEntity2 . getId ( ) ) ; \n - TestEntity testEntity3 = dao . queryBuilder ( ) . where ( Properties . SimpleBoolean . eq ( Boolean . TRUE ) ) . uniqueOrThrow ( ) ; \n - assertEquals ( testEntity . getId ( ) , testEntity3 . getId ( ) ) ; \n + testEntity2 = dao . queryBuilder ( ) . where ( Properties . SimpleBoolean . eq ( Boolean . TRUE ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntity . getId ( ) , testEntity2 . getId ( ) ) ; \n + \n + testEntity2 = dao . queryBuilder ( ) . where ( Properties . SimpleBoolean . eq ( "" TRUE "" ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntity . getId ( ) , testEntity2 . getId ( ) ) ; \n + \n + testEntity2 = dao . queryBuilder ( ) . where ( Properties . SimpleBoolean . eq ( "" truE "" ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntity . getId ( ) , testEntity2 . getId ( ) ) ; \n + } \n + \n + public void testIsNullIsNotNull ( ) { \n + ArrayList < TestEntity > inserted = insert ( 2 ) ; \n + TestEntity testEntityNull = inserted . get ( 0 ) ; \n + TestEntity testEntityNotNull = inserted . get ( 1 ) ; \n + \n + testEntityNull . setSimpleInteger ( null ) ; \n + testEntityNotNull . setSimpleInteger ( 42 ) ; \n + dao . update ( testEntityNull ) ; \n + dao . update ( testEntityNotNull ) ; \n + \n + TestEntity testEntityNull2 = dao . queryBuilder ( ) . where ( Properties . SimpleInteger . isNull ( ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntityNull . getId ( ) , testEntityNull2 . getId ( ) ) ; \n + \n + TestEntity testEntityNotNull2 = dao . queryBuilder ( ) . where ( Properties . SimpleInteger . isNotNull ( ) ) . uniqueOrThrow ( ) ; \n + assertEquals ( testEntityNotNull . getId ( ) , testEntityNotNull2 . getId ( ) ) ; \n",( not ) Null tests for query builder,317
DaoGenerator \ src - template \ dao . ftl \n + < / # list > \n + < # list entity . toOneRelations as toOne > \n + < # if ! toOne . fkProperties ? has _ content > \n + \n + $ { toOne . targetEntity . className } $ { toOne . name } = entity . peak $ { toOne . name ? cap _ first } ( ) ; \n + if ( $ { toOne . name } ! = null ) { \n + $ { toOne . targetEntity . pkProperty . javaType } $ { toOne . name } _ _ targetKey = $ { toOne . name } . get $ { toOne . targetEntity . pkProperty . propertyName ? cap _ first } ( ) ; \n + < # if ! toOne . targetEntity . pkProperty . notNull > \n + if ( $ { toOne . name } _ _ targetKey ! = null ) { \n + / / TODO bind $ { toOne . name } _ _ targetKey \n + } \n + < # else > \n + / / TODO bind $ { toOne . name } _ _ targetKey \n + < / # if > \n + } \n + < / # if > \n,prepared : bind to - one values without fk property,317
"DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoSessionTest . java \n + import android . app . Application ; \n + public AbstractDaoSessionTest ( Class < Application > appClass , Class < T > daoMasterClass , boolean inMemory ) { \n + super ( appClass , inMemory ) ; \n + this . daoMasterClass = daoMasterClass ; \n + } \n + \n DaoCore \ src \ de \ greenrobot \ dao \ test \ DbTest . java \n - super ( Application . class ) ; \n + this ( Application . class , inMemory ) ; \n + } \n + \n + public DbTest ( Class < Application > appClass , boolean inMemory ) { \n + super ( appClass ) ; \n",allow to pass App class for project specific unit tests,317
"DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoSessionTest . java \n - public abstract class AbstractDaoSessionTest < T extends AbstractDaoMaster , S extends AbstractDaoSession > extends DbTest { \n + public abstract class AbstractDaoSessionTest < A extends Application , T extends AbstractDaoMaster , S extends AbstractDaoSession > extends DbTest < A > { \n - public AbstractDaoSessionTest ( Class < Application > appClass , Class < T > daoMasterClass , boolean inMemory ) { \n + public AbstractDaoSessionTest ( Class < A > appClass , Class < T > daoMasterClass , boolean inMemory ) { \n DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoTest . java \n + import android . app . Application ; \n - public abstract class AbstractDaoTest < D extends AbstractDao < T , K > , T , K > extends DbTest { \n + public abstract class AbstractDaoTest < D extends AbstractDao < T , K > , T , K > extends DbTest < Application > { \n DaoCore \ src \ de \ greenrobot \ dao \ test \ DbTest . java \n - public abstract class DbTest extends ApplicationTestCase < Application > { \n + public abstract class DbTest < T extends Application > extends ApplicationTestCase < T > { \n + @ SuppressWarnings ( "" unchecked "" ) \n - this ( Application . class , inMemory ) ; \n + this ( ( Class < T > ) Application . class , inMemory ) ; \n - public DbTest ( Class < Application > appClass , boolean inMemory ) { \n + public DbTest ( Class < T > appClass , boolean inMemory ) { \n DaoTest \ src \ de \ greenrobot \ daotest \ DaoSessionTest . java \n + import android . app . Application ; \n - public class DaoSessionTest extends AbstractDaoSessionTest < DaoMaster , DaoSession > { \n + public class DaoSessionTest extends AbstractDaoSessionTest < Application , DaoMaster , DaoSession > { \n DaoTest \ src \ de \ greenrobot \ daotest \ entity \ AnActiveEntityTest . java \n + import android . app . Application ; \n - public class AnActiveEntityTest extends AbstractDaoSessionTest < DaoMaster , DaoSession > { \n + public class AnActiveEntityTest extends AbstractDaoSessionTest < Application , DaoMaster , DaoSession > { \n DaoTest \ src \ de \ greenrobot \ daotest \ entity \ ToManyEntityTest . java \n + import android . app . Application ; \n + \n - public class ToManyEntityTest extends AbstractDaoSessionTest < DaoMaster , DaoSession > { \n + public class ToManyEntityTest extends AbstractDaoSessionTest < Application , DaoMaster , DaoSession > { \n DaoTest \ src \ de \ greenrobot \ daotest \ entity \ TreeEntityTest . java \n + import android . app . Application ; \n - import de . greenrobot . dao . test . AbstractDaoTestLongPk ; \n - public class TreeEntityTest extends AbstractDaoSessionTest < DaoMaster , DaoSession > { \n + public class TreeEntityTest extends AbstractDaoSessionTest < Application , DaoMaster , DaoSession > { \n","better generics for test , still not perfect though",317
"DaoCore \ src \ de \ greenrobot \ dao \ QueryBuilder . java \n + values . clear ( ) ; \n DaoTest \ src \ de \ greenrobot \ daotest \ query \ DeleteQueryTest . java \n + import de . greenrobot . dao . Query ; \n + \n + public void testBuildQueryAndDeleteQuery ( ) { \n + insert ( 3 ) ; \n + int value = getSimpleInteger ( 1 ) ; \n + \n + QueryBuilder < TestEntity > builder = dao . queryBuilder ( ) . where ( Properties . SimpleInteger . eq ( value ) ) ; \n + Query < TestEntity > query = builder . build ( ) ; \n + DeleteQuery < TestEntity > deleteQuery = builder . buildDelete ( ) ; \n + \n + assertEquals ( 1 , query . list ( ) . size ( ) ) ; \n + deleteQuery . executeDeleteWithoutDetachingEntities ( ) ; \n + assertEquals ( 0 , query . list ( ) . size ( ) ) ; \n + } \n DaoTest \ src \ de \ greenrobot \ daotest \ query \ QueryBuilderSimpleTest . java \n + import de . greenrobot . dao . Query ; \n + \n + public void testBuildTwice ( ) { \n + insert ( 3 ) ; \n + String value = getSimpleString ( 1 ) ; \n + \n + QueryBuilder < TestEntity > builder = dao . queryBuilder ( ) . where ( Properties . SimpleString . eq ( value ) ) ; \n + Query < TestEntity > query1 = builder . build ( ) ; \n + Query < TestEntity > query2 = builder . build ( ) ; \n + List < TestEntity > list1 = query1 . list ( ) ; \n + List < TestEntity > list2 = query2 . list ( ) ; \n + assertEquals ( 1 , list1 . size ( ) ) ; \n + assertEquals ( 1 , list2 . size ( ) ) ; \n + assertEquals ( list1 . get ( 0 ) . getId ( ) , list2 . get ( 0 ) . getId ( ) ) ; \n + } \n",fix for building multiple queries with one queryBuilder,317
DaoGenerator \ performance \ performance - data . xlsx \n Binary files a / DaoGenerator / performance / performance - data . xlsx and b / DaoGenerator / performance / performance - data . xlsx differ \n,Added performance results for Android 4 . 0 plus a comparison to 2 . 3,317
"DaoCore \ src \ de \ greenrobot \ dao \ AbstractDao . java \n - / * * Loads all available entities from the database . * / \n + / * * Loads all available entities from the database . * / \n - if ( window . getNumRows ( ) = = count ) { \n - cursor = new FastCursor ( window ) ; \n - } else { \n - DaoLog . d ( "" Window vs . result size : "" + window . getNumRows ( ) + "" / "" + count ) ; \n + if ( window ! = null ) { / / E . g . Roboelectric has no Window at this point \n + if ( window . getNumRows ( ) = = count ) { \n + cursor = new FastCursor ( window ) ; \n + } else { \n + DaoLog . d ( "" Window vs . result size : "" + window . getNumRows ( ) + "" / "" + count ) ; \n + } \n - / * * @ deprecated groupBy & having does not make sense for entities . Method will be removed . * / \n + / * * @ deprecated groupBy & having does not make sense for entities . Method will be removed . * / \n",Don ' t assume that a Cursor has a CursorWindow ( fix for Roboelectric ),317
"DaoCore \ src \ de \ greenrobot \ dao \ AbstractDao . java \n - return identityScope . detach ( getKey ( entity ) , entity ) ; \n + K key = getKeyVerified ( entity ) ; \n + return identityScope . detach ( key , entity ) ; \n - K key = getKey ( entity ) ; \n + K key = getKeyVerified ( entity ) ; \n - K key = getKey ( entity ) ; \n + K key = getKeyVerified ( entity ) ; \n + / * * See { @ link # getKey ( Object ) } , but guarantees that the returned key is never null ( throws if null ) . * / \n + protected K getKeyVerified ( T entity ) { \n + K key = getKey ( entity ) ; \n + if ( key = = null ) { \n + if ( entity = = null ) { \n + throw new NullPointerException ( "" Entity may not be null "" ) ; \n + } else { \n + throw new DaoException ( "" Entity has no key "" ) ; \n + } \n + } else { \n + return key ; \n + } \n + } \n + \n",Additional check that key can be acquired ( issue # 5 ),317
"README . md \n - - - - - - - - - - - - - - - \n - # # # V1 . 1 . 0 ( 2012 - 02 - 13 unreleased ) : Feature release \n + # # # V1 . 1 . 1 ( 2012 - 02 - ? ? , unrelease ) : Bugfix release \n + * Fix for Roboelectric ( Issue # 22 ) \n + * Minor fixes ( Issue # 5 ) \n + * . . . \n + \n + # # # V1 . 1 . 0 ( 2012 - 02 - 13 ) : Feature release \n",updated readme for version 1 . 1 . 0 and 1 . 1 . 1,317
"DaoCore \ src \ de \ greenrobot \ dao \ Property . java \n + / * * Creates an "" NOT IN ( . . . , . . . , . . . ) "" condition for this property . * / \n + public WhereCondition notIn ( Object . . . notInValues ) { \n + StringBuilder condition = new StringBuilder ( "" NOT IN ( "" ) ; \n + SqlUtils . appendPlaceholders ( condition , notInValues . length ) . append ( ' ) ' ) ; \n + return new PropertyCondition ( this , condition . toString ( ) , notInValues ) ; \n + } \n + \n + / * * Creates an "" NOT IN ( . . . , . . . , . . . ) "" condition for this property . * / \n + public WhereCondition notIn ( Collection < ? > notInValues ) { \n + return notIn ( notInValues . toArray ( ) ) ; \n + } \n + \n DaoTest \ src \ de \ greenrobot \ daotest \ query \ QueryBuilderSimpleTest . java \n + } \n + \n + public void testNotIn ( ) { \n + ArrayList < TestEntity > inserted = insert ( 5 ) ; \n + String value1 = getSimpleString ( 0 ) ; \n + String value2 = getSimpleString ( 2 ) ; \n + String value3 = getSimpleString ( 4 ) ; \n + \n + List < TestEntity > result = dao . queryBuilder ( ) . where ( Properties . SimpleString . notIn ( value1 , value2 , value3 ) ) \n + . orderAsc ( Properties . SimpleString ) . list ( ) ; \n + assertEquals ( 2 , result . size ( ) ) ; \n + TestEntity resultEntity1 = result . get ( 0 ) ; \n + assertEquals ( inserted . get ( 1 ) . getId ( ) , resultEntity1 . getId ( ) ) ; \n + \n + TestEntity resultEntity2 = result . get ( 1 ) ; \n + assertEquals ( inserted . get ( 3 ) . getId ( ) , resultEntity2 . getId ( ) ) ; \n - \n + \n - \n + \n",added NOT IN condition ( # 23 ),317
"DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Entity . java \n + if ( protobuf ) { \n + throw new IllegalStateException ( "" Protobuf entities do not support realtions , currently "" ) ; \n + } \n + \n + if ( protobuf ) { \n + throw new IllegalStateException ( "" Protobuf entities do not support realtions , currently "" ) ; \n + } \n + \n",throw exception when trying to add relations to protobuf entities,317
DaoGenerator \ src - template \ dao - master . ftl \n + < # if ! entity . skipTableCreation > \n + < / # if > \n + < # if ! entity . skipTableCreation > \n + < / # if > \n DaoGenerator \ src - template \ dao . ftl \n + < # if ! entity . skipTableCreation > \n - \n + \n + < / # if > \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Entity . java \n + private boolean skipTableCreation ; \n + / * * \n + * Flag if CREATE & DROP TABLE scripts should be skipped in Dao . \n + * / \n + public void setSkipTableCreation ( boolean skipTableCreation ) { \n + this . skipTableCreation = skipTableCreation ; \n + } \n + \n + public boolean isSkipTableCreation ( ) { \n + return skipTableCreation ; \n + } \n + \n,new flag for skipping table creation & dropping,317
DaoGenerator \ src - template \ dao . ftl \n - \n + \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Entity . java \n - if ( ! javaPackage . equals ( javaPackageDao ) ) { \n + if ( active & & ! javaPackage . equals ( javaPackageDao ) ) { \n DaoTest \ src - gen \ de \ greenrobot \ daotest2 \ KeepEntity . java \n - import de . greenrobot . daotest2 . dao . KeepEntityDao ; \n - \n DaoTest \ src - gen \ de \ greenrobot \ daotest2 \ ToManyTarget2 . java \n - import de . greenrobot . daotest2 . dao . ToManyTarget2Dao ; \n - \n DaoTest \ src - gen \ de \ greenrobot \ daotest2 \ to1 _ specialentity \ ToOneTarget2 . java \n - import de . greenrobot . daotest2 . to1 _ specialdao . ToOneTarget2Dao ; \n - \n,removed unnecessary DAO import for non - active entities,317
"DaoCore \ src \ de \ greenrobot \ dao \ Query . java \n + / * * \n + * Sets the limit of the maximum number of results returned by this Query . { @ link QueryBuilder # limit ( int ) must have \n + * been called on the QueryBuilder that created this Query object . \n + * / \n + / * * \n + * Sets the offset for results returned by this Query . { @ link QueryBuilder # offset ( int ) must have been called on the \n + * QueryBuilder that created this Query object . \n + * / \n DaoCore \ src \ de \ greenrobot \ dao \ QueryBuilder . java \n - / * * Sets the offset for query results . * / \n + / * * \n + * Sets the offset for query results in combination with { @ link # limit ( int ) } . The first { @ code limit } results are \n + * skipped and the total number of results will be limited by { @ code limit } . You cannot use offset without limit . \n + * / \n DaoTest \ src \ de \ greenrobot \ daotest \ query \ QueryLimitOffsetTest . java \n + \n + \n + public void testQueryLimitAndSetParameter ( ) { \n + Query < TestEntity > query = dao . queryBuilder ( ) . limit ( 5 ) . offset ( 1 ) . build ( ) ; \n + try { \n + query . setParameter ( 0 , null ) ; \n + fail ( "" Offset / limit parameters must not interfere with user parameters "" ) ; \n + } catch ( RuntimeException expected ) { \n + / / OK \n + } \n + } \n + \n + public void testQueryUnsetLimit ( ) { \n + Query < TestEntity > query = dao . queryBuilder ( ) . build ( ) ; \n + try { \n + query . setLimit ( 1 ) ; \n + fail ( "" Limit must be defined in builder first "" ) ; \n + } catch ( RuntimeException expected ) { \n + / / OK \n + } \n + } \n + \n + public void testQueryUnsetOffset ( ) { \n + Query < TestEntity > query = dao . queryBuilder ( ) . limit ( 1 ) . build ( ) ; \n + try { \n + query . setOffset ( 1 ) ; \n + fail ( "" Offset must be defined in builder first "" ) ; \n + } catch ( RuntimeException expected ) { \n + / / OK \n + } \n + } \n",Additional docs and unit tests for query limit & offset,317
"DaoExample \ . classpath \n + < classpathentry kind = "" lib "" path = "" libs / greenDAO . jar "" > \n + < attributes > \n + < attribute name = "" javadoc _ location "" value = "" jar : platform : / resource / DaoExample / docs / greenDAO - javadoc . jar ! / "" / > \n + < / attributes > \n + < / classpathentry > \n - < classpathentry kind = "" lib "" path = "" lib / greenDAO . jar "" > \n - < attributes > \n - < attribute name = "" javadoc _ location "" value = "" jar : platform : / resource / DaoExample / lib / greenDAO - javadoc . jar ! / "" / > \n - < / attributes > \n - < / classpathentry > \n + < classpathentry exported = "" true "" kind = "" con "" path = "" com . android . ide . eclipse . adt . LIBRARIES "" / > \n rename from DaoExample \ lib \ greenDAO - javadoc . jar \n rename to DaoExample \ docs \ greenDAO - javadoc . jar \n rename from DaoExample \ lib \ greenDAO . jar \n rename to DaoExample \ libs \ greenDAO . jar \n",moved jar to libs ( ADT 17 ),317
"DaoExample \ docs \ greenDAO - javadoc . jar \n Binary files a / DaoExample / docs / greenDAO - javadoc . jar and b / DaoExample / docs / greenDAO - javadoc . jar differ \n DaoExample \ libs \ greenDAO . jar \n Binary files a / DaoExample / libs / greenDAO . jar and b / DaoExample / libs / greenDAO . jar differ \n DaoExampleGenerator \ lib \ greenDAO - generator - javadoc . jar \n Binary files a / DaoExampleGenerator / lib / greenDAO - generator - javadoc . jar and b / DaoExampleGenerator / lib / greenDAO - generator - javadoc . jar differ \n DaoExampleGenerator \ lib \ greenDAO - generator . jar \n Binary files a / DaoExampleGenerator / lib / greenDAO - generator . jar and b / DaoExampleGenerator / lib / greenDAO - generator . jar differ \n DaoGenerator \ mybuild . xml \n - < copy file = "" . . / DaoCore / release / greenDAO . jar "" todir = "" . . / DaoExample / lib "" > < / copy > \n - < copy file = "" . . / DaoCore / release / greenDAO - javadoc . jar "" todir = "" . . / DaoExample / lib "" > < / copy > \n + < copy file = "" . . / DaoCore / release / greenDAO . jar "" todir = "" . . / DaoExample / libs "" > < / copy > \n + < copy file = "" . . / DaoCore / release / greenDAO - javadoc . jar "" todir = "" . . / DaoExample / docs "" > < / copy > \n",preparing jars for V1 . 1 . 2,317
README . md \n - - - - - - - - - - - - - - - \n + # # # V1 . 1 . 2 ( 2012 - 03 - 26 ) : ADT 17 support for demo project \n + * Demo projects works with ADT 17 ( moved greendao . jar into libs ) \n + * CREATE / DROP TABLE may be skipped for entity types : This allows having multiple entity tapes operate on one table \n + * Minor improvements \n + \n,V1 . 1 . 2 release notes added,317
README . md \n - - - - - - - - - - - - - - - \n + # # # V1 . 1 . 0 ( 2012 - 02 - ? ? unreleased ) : Feature release \n + * DeleteQuery for bulk deletes \n + * Entities may implement Java interfaces \n + * Entities may extend a Java class \n + * Added LIMIT and OFFSET support for QueryBuilder and Query \n + * Convenience methods to add named relationships \n + * SQL scripts are executed in a transaction by default \n + * Fixed queries with special column names ( SQL keywords ) \n + \n,Feature list of 1 . 1 pre - release,317
EventBus \ build . gradle \n + sourceCompatibility = 1 . 6 \n,added sourceCompatibility = 1 . 6 to build . gradle,317
"rename from DaoTest \ src \ de \ greenrobot \ daotest \ query \ QuerySpecialNames . java \n rename to DaoTest \ src \ de \ greenrobot \ daotest \ query \ QuerySpecialNamesTest . java \n - public class QuerySpecialNames extends AbstractDaoTest < SpecialNamesEntityDao , SpecialNamesEntity , Long > { \n + public class QuerySpecialNamesTest extends AbstractDaoTest < SpecialNamesEntityDao , SpecialNamesEntity , Long > { \n - public QuerySpecialNames ( ) { \n + public QuerySpecialNamesTest ( ) { \n - / / TODO Auto - generated constructor stub \n",renamed to QuerySpecialNamesTest ( missing Test suffix ),317
"DaoGenerator \ src - generator - testentities \ de \ greenrobot \ daogenerator \ gentest \ TestDaoGenerator . java \n + specialNamesEntity . addStringProperty ( "" order "" ) ; \n DaoTest \ src - gen \ de \ greenrobot \ daotest \ SpecialNamesEntity . java \n + private String order ; \n - public SpecialNamesEntity ( Long id , String count , String select , String sum , String avg , String join , String distinct , String on , String index ) { \n + public SpecialNamesEntity ( Long id , String count , String select , String sum , String avg , String join , String distinct , String on , String index , String order ) { \n + this . order = order ; \n + public String getOrder ( ) { \n + return order ; \n + } \n + \n + public void setOrder ( String order ) { \n + this . order = order ; \n + } \n + \n DaoTest \ src - gen \ de \ greenrobot \ daotest \ SpecialNamesEntityDao . java \n + public final static Property Order = new Property ( 9 , String . class , "" order "" , false , "" ORDER "" ) ; \n - "" ' INDEX ' TEXT ) ; "" ; / / 8 : index \n + "" ' INDEX ' TEXT , "" + / / 8 : index \n + "" ' ORDER ' TEXT ) ; "" ; / / 9 : order \n + \n + String order = entity . getOrder ( ) ; \n + if ( order ! = null ) { \n + stmt . bindString ( 10 , order ) ; \n + } \n - cursor . isNull ( offset + 8 ) ? null : cursor . getString ( offset + 8 ) / / index \n + cursor . isNull ( offset + 8 ) ? null : cursor . getString ( offset + 8 ) , / / index \n + cursor . isNull ( offset + 9 ) ? null : cursor . getString ( offset + 9 ) / / order \n + entity . setOrder ( cursor . isNull ( offset + 9 ) ? null : cursor . getString ( offset + 9 ) ) ; \n DaoTest \ src \ de \ greenrobot \ daotest \ query \ QuerySpecialNamesTest . java \n + queryBuilder . where ( Properties . Order . isNotNull ( ) ) ; \n + queryBuilder . orderAsc ( Properties . Order ) ; \n","Added "" order "" to special names test",317
"DaoCore \ src \ de \ greenrobot \ dao \ DaoConfig . java \n + import java . lang . reflect . Modifier ; \n - Property [ ] properties = new Property [ fields . length ] ; \n + \n + ArrayList < Property > propertyList = new ArrayList < Property > ( ) ; \n - Property property = ( Property ) field . get ( null ) ; \n + / / There might be other fields introduced by some tools , just ignore them ( see issue # 28 ) \n + if ( ( field . getModifiers ( ) & Modifier . STATIC ) ! = 0 ) { \n + Object fieldValue = field . get ( null ) ; \n + if ( fieldValue instanceof Property ) { \n + propertyList . add ( ( Property ) fieldValue ) ; \n + } \n + } \n + } \n + \n + Property [ ] properties = new Property [ propertyList . size ( ) ] ; \n + for ( Property property : propertyList ) { \n","There might be other fields introduced by some tools , just ignore them \n ( see issue # 28 )",317
DaoCore \ src \ de \ greenrobot \ dao \ DaoConfig . java \n - if ( ( field . getModifiers ( ) & Modifier . STATIC ) ! = 0 ) { \n + if ( ( field . getModifiers ( ) & Modifier . STATIC ) ! = 0 & & ( field . getModifiers ( ) & Modifier . PUBLIC ) ! = 0 ) { \n,Refelected Properties must be public also ( issue # 28 ),317
"README . md \n - - - - - - - - - - - - - - - \n + # # # Next version ( unreleased ) : Minor features \n + * Added getDatabase in DaoMaster , DaoSession , and Dao \n + * Added insertOrReplaceInTx in Dao \n + * Minor fixes \n + \n",prepared readme for next version ( unreleased ),317
"DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoSessionTest . java \n - public abstract class AbstractDaoSessionTest < A extends Application , T extends AbstractDaoMaster , S extends AbstractDaoSession > extends DbTest < A > { \n + public abstract class AbstractDaoSessionTest < A extends Application , T extends AbstractDaoMaster , S extends AbstractDaoSession > \n + extends DbTest < A > { \n - public AbstractDaoSessionTest ( Class < A > appClass , Class < T > daoMasterClass , boolean inMemory ) { \n + public AbstractDaoSessionTest ( Class < A > appClass , Class < T > daoMasterClass , boolean inMemory ) { \n DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoTest . java \n - \n + \n DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoTestSinglePk . java \n + assertNotNull ( pk1 ) ; \n + assertNotNull ( pk2 ) ; \n - assertEquals ( rowId1 , rowId2 ) ; \n + if ( dao . getPkProperty ( ) . type = = Long . class ) { \n + assertEquals ( rowId1 , rowId2 ) ; \n + } \n DaoCore \ src \ de \ greenrobot \ dao \ test \ DbTest . java \n + try { \n + super . setUp ( ) ; \n + } catch ( Exception e ) { \n + throw new RuntimeException ( e ) ; \n + } \n + super . tearDown ( ) ; \n - \n + \n","Tests : added missing super . setUp and super . teardown , formatting",317
"DaoGenerator \ src - template \ dao - unit - test . ftl \n - - > \n + < # assign isStringPK = entity . pkProperty ? ? & & entity . pkProperty . propertyType = = "" String "" / > \n + < # if isStringPK > \n + import de . greenrobot . dao . test . AbstractDaoTestStringPk ; \n + < # else > \n + < / # if > \n + \n - public class $ { entity . classNameTest } extends AbstractDaoTestLongPk < $ { entity . classNameDao } , $ { entity . className } > { \n + public class $ { entity . classNameTest } extends < # if \n + isStringPK > AbstractDaoTestStringPk < $ { entity . classNameDao } , $ { entity . className } > < # else > AbstractDaoTestLongPk < $ { entity . classNameDao } , $ { entity . className } > < / # if > { \n - protected $ { entity . className } createEntity ( Long key ) { \n + protected $ { entity . className } createEntity ( < # if isStringPK > String < # else > Long < / # if > key ) { \n - entity . setId ( key ) ; \n + entity . set $ { entity . pkProperty . propertyName ? cap _ first } ( key ) ; \n DaoGenerator \ src - template \ dao . ftl \n - / / TODO XXX Only Long PKs are supported currently \n DaoTest \ src - gen \ de \ greenrobot \ daotest \ StringKeyValueEntityDao . java \n - / / TODO XXX Only Long PKs are supported currently \n README . md \n - - - - - - - - - - - - - - - \n - # # # Next version ( unreleased ) : Minor features \n + # # # Next version ( unreleased ) : Feature release \n",prepared unit test generation for String PK entities,317
"DaoCore \ src \ de \ greenrobot \ dao \ QueryBuilder . java \n + / * * \n + * Creates a WhereCondition by combining the given conditions using OR . The returned WhereCondition must be used \n + * inside { @ link # where ( WhereCondition , WhereCondition . . . ) } or \n + * { @ link # whereOr ( WhereCondition , WhereCondition , WhereCondition . . . ) } . \n + * / \n + / * * \n + * Creates a WhereCondition by combining the given conditions using AND . The returned WhereCondition must be used \n + * inside { @ link # where ( WhereCondition , WhereCondition . . . ) } or \n + * { @ link # whereOr ( WhereCondition , WhereCondition , WhereCondition . . . ) } . \n + * / \n",added javaDoc for or ( ) and and ( ),317
"DaoCore \ src \ de \ greenrobot \ dao \ test \ AbstractDaoTest . java \n - Method createTableMethod = daoClass . getMethod ( "" createTable "" , SQLiteDatabase . class , boolean . class ) ; \n - createTableMethod . invoke ( null , db , false ) ; \n + try { \n + Method createTableMethod = daoClass . getMethod ( "" createTable "" , SQLiteDatabase . class , boolean . class ) ; \n + createTableMethod . invoke ( null , db , false ) ; \n + } catch ( NoSuchMethodException e ) { \n + DaoLog . i ( "" No createTable method "" ) ; \n + } \n DaoGenerator \ src - template \ dao - unit - test . ftl \n + < # if entity . pkProperty ? ? > \n + < / # if > \n DaoGenerator \ src - template \ dao . ftl \n - < # if entity . pkProperty ? ? & & entity . pkProperty . propertyType = = "" Long "" > \n + < # if entity . pkProperty ? ? > \n + < # if entity . pkProperty . propertyType = = "" Long "" > \n + < / # if > \n + < # else > \n + / / Unsupported or missing PK type \n + return null ; \n","fixed templates for PK - less entities , test fix",317
README . md \n - - - - - - - - - - - - - - - \n - # # # Next version ( unreleased ) : Feature release \n - * Limited support of String PKs \n + # # # V1 . 2 . 0 RC ( to be released 2012 - 06 - ? ? ) : Feature release \n + * Limited support of String PKs ( no relations using String FKs yet ) \n + * Fixed index creation ( please update your schema ) \n,updated readme for V1 . 2 . 0RC,317
"EventBus \ src \ de \ greenrobot \ event \ EventBus . java \n - if ( subscribedClasses ! = null & & ! subscribedClasses . isEmpty ( ) ) { \n + if ( subscribedClasses ! = null ) { \n + if ( subscribedClasses . isEmpty ( ) ) { \n + typesBySubscriber . remove ( subscriber ) ; \n + } \n - if ( subscribedTypes ! = null & & ! subscribedTypes . isEmpty ( ) ) { \n + if ( subscribedTypes ! = null ) { \n - subscribedTypes . clear ( ) ; \n + typesBySubscriber . remove ( subscriber ) ; \n EventBusTest \ src \ de \ greenrobot \ event \ test \ EventBusBasicTest . java \n + import java . lang . ref . WeakReference ; \n + \n + public void testUnregisterNotLeaking ( ) { \n + EventBusBasicTest subscriber = new EventBusBasicTest ( ) ; \n + eventBus . register ( subscriber ) ; \n + eventBus . unregister ( subscriber ) ; \n + \n + WeakReference < EventBusBasicTest > ref = new WeakReference < EventBusBasicTest > ( subscriber ) ; \n + subscriber = null ; \n + assertSubscriberNotReferenced ( ref ) ; \n + } \n + \n + public void testUnregisterForClassNotLeaking ( ) { \n + EventBusBasicTest subscriber = new EventBusBasicTest ( ) ; \n + eventBus . register ( subscriber , String . class ) ; \n + eventBus . unregister ( subscriber , String . class ) ; \n + \n + WeakReference < EventBusBasicTest > ref = new WeakReference < EventBusBasicTest > ( subscriber ) ; \n + subscriber = null ; \n + assertSubscriberNotReferenced ( ref ) ; \n + } \n + \n + private void assertSubscriberNotReferenced ( WeakReference < EventBusBasicTest > ref ) { \n + EventBusBasicTest subscriberTest = new EventBusBasicTest ( ) ; \n + WeakReference < EventBusBasicTest > refTest = new WeakReference < EventBusBasicTest > ( subscriberTest ) ; \n + subscriberTest = null ; \n + \n + / / Yeah , in theory is is questionable ( in practice just fine so far . . . ) \n + System . gc ( ) ; \n + \n + assertNull ( refTest . get ( ) ) ; \n + assertNull ( ref . get ( ) ) ; \n + } \n + \n - \n + \n",Fixed leaking subscribers ( issue # 2 ),317
"DaoCore \ src \ de \ greenrobot \ dao \ AbstractDaoSession . java \n + / * * \n + * Creates a new { @ link AsyncSession } to issue asynchronous entity operations . See { @ link AsyncSession } for details . \n + * / \n + public AsyncSession startAsyncSession ( ) { \n + return new AsyncSession ( this ) ; \n + } \n + \n new file \n DaoTest \ src \ de \ greenrobot \ daotest \ async \ BasicAsyncTest . java \n + package de . greenrobot . daotest . async ; \n + \n + import android . app . Application ; \n + import de . greenrobot . dao . AsyncSession ; \n + import de . greenrobot . dao . test . AbstractDaoSessionTest ; \n + import de . greenrobot . daotest . DaoMaster ; \n + import de . greenrobot . daotest . DaoSession ; \n + import de . greenrobot . daotest . SimpleEntity ; \n + \n + public class BasicAsyncTest extends AbstractDaoSessionTest < Application , DaoMaster , DaoSession > { \n + \n + private AsyncSession asyncSession ; \n + \n + public BasicAsyncTest ( ) { \n + super ( DaoMaster . class ) ; \n + } \n + \n + @ Override \n + protected void setUp ( ) { \n + super . setUp ( ) ; \n + asyncSession = daoSession . startAsyncSession ( ) ; \n + } \n + \n + public void testWaitForCompletionNoOps ( ) throws InterruptedException { \n + assertTrue ( asyncSession . isCompleted ( ) ) ; \n + assertTrue ( asyncSession . waitForCompletion ( 1 ) ) ; \n + asyncSession . waitForCompletion ( ) ; \n + } \n + \n + public void testAsyncInsert ( ) throws InterruptedException { \n + SimpleEntity entity = new SimpleEntity ( ) ; \n + entity . setSimpleString ( "" heho "" ) ; \n + asyncSession . insert ( entity ) ; \n + assertTrue ( asyncSession . waitForCompletion ( 1000 ) ) ; \n + SimpleEntity entity2 = daoSession . load ( SimpleEntity . class , entity . getId ( ) ) ; \n + assertNotNull ( entity2 ) ; \n + assertEquals ( "" heho "" , entity2 . getSimpleString ( ) ) ; \n + } \n + \n + } \n","start AsyncSession in DaoSession , first two async tests up and running",317
"README . md \n - - - - - - - - - - - - - - - \n + # # # V1 . 3 . 0 Preview ( 2012 - ? ? - ? ? ) : New asynchronous API \n + * AsyncSession ( acquired from DaoSession . startAsyncSession ( ) ) provides most operations for DAOs , Queries , and transactions in a asynchronously variant \n + * AsyncOperations are processed in order by a background thread \n + * waitForCompletion methods for AsyncSession and AsyncOperations \n + * AsyncOperationListener for asynchronous callback when operations complete \n + * Asynchronous operations can be merged in single transactions ( details follow ) \n + \n",updated README . md for V1 . 3 . 0 Preview ( 2012 - ? ? - ? ? ) : New asynchronous API,317
DaoCore \ src \ de \ greenrobot \ dao \ LazyList . java \n + / / Ignore FindBugs : increment of volatile is fine here because we use a lock \n,Ignore FindBugs : increment of volatile is fine here because we use a \n lock,317
"EventBusTest \ src \ de \ greenrobot \ event \ test \ EventBusMultithreadedTest . java \n - for ( int i = 0 ; i < 10 ; i + + ) { \n + for ( int i = 0 ; i < 5 ; i + + ) { \n - runThreadsMixedEventType ( 10 ) ; \n + / / This test takes a bit longer , so just use fraction the regular count \n + runThreadsMixedEventType ( COUNT / 4 , 5 ) ; \n + runThreadsMixedEventType ( COUNT , threadCount ) ; \n + } \n + \n + private void runThreadsMixedEventType ( int count , int threadCount ) throws InterruptedException { \n - int iterations = COUNT / threadCount / eventTypeCount ; \n + int iterations = count / threadCount / eventTypeCount ; \n","make testSubscribeUnSubscribeAndPostMixedEventType less intense , but \n faster",317
"README . md \n - - - - - - - - - - - - - - - \n - * Event methods define for themselves in which thread they get called . This is done by providing "" modifiers "" to the method name , e . g . onEvent is still called in the same thread as it was posted , but onEventMainThread will be called by the main thread without further configuration . \n + * Event methods define for themselves in which thread they get called . This is done by providing "" modifiers "" to the method name , e . g . onEventMainThread is called by the main thread without further configuration . Have a look at the JavaDoc of the enum ThreadMode for all available thread modes . \n - * New "" BackgroundThread "" modifier for onEvent handler methods are called in a background thread . If an event is posted from a non - main thread , handler methods will be called directly . If posted from the main thread , EventBus will use a background thread to call the handler methods . \n - * Delivery of multiple events in the main thread got significantly faster . \n - * Fixed some event leakage . \n + * New "" BackgroundThread "" modifier for onEvent handler methods ensures that event handler methods are called in a background thread . If an event is posted from a non - main thread , handler methods will be called directly . If posted from the main thread , EventBus will use a background thread to call the handler methods . \n + * New "" Async "" modifier for onEvent handler methods ensures that each event handler method is called completely asynchronously . \n + * Better performace : Delivery of multiple events in the main thread got significantly faster . \n + * Added sticky events , which are inspired by sticky broadcasts of the Android system . EventBus keeps the most recent sticky events in memory . Subscribers registering with the new method registerSticky , will receive sticky events right away . You can also query and remove sticky events ( methods getStickyEvent and removeStickyEvent ) . \n + * Bug fixes \n + * Internal refactorings , moved inner classes of EventBus to separate files to keep the code more managable . \n","extended README . md to reflect the latest changes , e . g . sticky events",317
"EventBus \ src \ de \ greenrobot \ event \ EventBus . java \n - if ( subscription . equals ( newSubscription ) ) { \n - throw new RuntimeException ( "" Subscriber "" + subscriber . getClass ( ) + "" already registered to event "" \n + if ( subscription = = newSubscription ) { \n + throw new EventBusException ( "" Subscriber "" + subscriber . getClass ( ) + "" already registered to event "" \n + eventType ) ; \n + subscription . subscriber . getClass ( ) , cause ) ; \n - SubscriberExceptionEvent exEvent = new SubscriberExceptionEvent ( this , cause , event , subscription . subscriber ) ; \n + SubscriberExceptionEvent exEvent = new SubscriberExceptionEvent ( this , cause , event , \n + subscription . subscriber ) ; \n",Don ' t use equals for subscriber already registered check,317
"EventBus \ src \ de \ greenrobot \ event \ EventBus . java \n - if ( subscription = = newSubscription ) { \n - throw new EventBusException ( "" Subscriber "" + subscriber . getClass ( ) + "" already registered to event "" \n + if ( subscription . equals ( newSubscription ) ) { \n + throw new RuntimeException ( "" Subscriber "" + subscriber . getClass ( ) + "" already registered to event "" \n + eventType ) ; \n + subscription . subscriber . getClass ( ) , cause ) ; \n - SubscriberExceptionEvent exEvent = new SubscriberExceptionEvent ( this , cause , event , \n - subscription . subscriber ) ; \n + SubscriberExceptionEvent exEvent = new SubscriberExceptionEvent ( this , cause , event , subscription . subscriber ) ; \n","Revert "" Don ' t use equals for subscriber already registered check "" \n This reverts commit a39b054c550ba91a05d2ae57ba3ef94ba4f53e77 .",317
"DaoCore \ src \ de \ greenrobot \ dao \ QueryBuilder . java \n - for ( Property property : properties ) { \n - checkOrderBuilder ( ) ; \n - append ( orderBuilder , property ) . append ( "" ASC "" ) ; \n - } \n + orderAscOrDesc ( "" ASC "" , properties ) ; \n + orderAscOrDesc ( "" DESC "" , properties ) ; \n + return this ; \n + } \n + \n + private void orderAscOrDesc ( String ascOrDescWithLeadingSpace , Property . . . properties ) { \n - append ( orderBuilder , property ) . append ( "" DESC "" ) ; \n + append ( orderBuilder , property ) ; \n + if ( String . class . equals ( property . type ) ) { \n + orderBuilder . append ( "" COLLATE LOCALIZED "" ) ; \n + } \n + orderBuilder . append ( ascOrDescWithLeadingSpace ) ; \n - return this ; \n",use LOCALIZED collation for Strings in ORDER BY,317
"EventBus \ build . gradle \n + group = ' de . greenrobot . eventbus ' \n + version = ' 2 . 0 . 0 ' \n + \n - \n + } \n + \n + task javadocJar ( type : Jar , dependsOn : javadoc ) { \n + classifier = ' javadoc ' \n + from ' build / docs / javadoc ' \n + } \n + \n + task sourcesJar ( type : Jar ) { \n + from sourceSets . main . allSource \n + classifier = ' sources ' \n + } \n + \n + artifacts { \n + archives jar \n + archives javadocJar \n + archives sourcesJar \n",added javadoc and sources artifacts to build . gradle,317
"EventBusPerformance \ AndroidManifest . xml \n - android : minSdkVersion = "" 6 "" \n + android : minSdkVersion = "" 7 "" \n + < uses - feature \n + android : name = "" android . hardware . touchscreen "" \n + android : required = "" false "" / > \n + \n EventBusPerformance \ project . properties \n - target = android - 4 \n + target = android - 7 \n EventBusPerformance \ res \ values \ strings . xml \n - < string name = "" app _ name "" > Performance < / string > \n + < string name = "" app _ name "" > Event Performance < / string > \n","don ' t require touch , raised build target to api level 7",317
"DaoGenerator \ performance \ performance - data . xlsx \n Binary files a / DaoGenerator / performance / performance - data . xlsx and b / DaoGenerator / performance / performance - data . xlsx differ \n PerformanceTestOrmLite \ . classpath \n - < classpathentry kind = "" lib "" path = "" lib / ormlite - android - 4 . 24 . jar "" sourcepath = "" lib / ormlite - android - 4 . 24 - sources . jar "" / > \n - < classpathentry kind = "" lib "" path = "" lib / ormlite - core - 4 . 24 . jar "" sourcepath = "" C : / Users / Markus / . m2 / repository / com / j256 / ormlite / ormlite - core / 4 . 24 / ormlite - core - 4 . 24 - sources . jar "" / > \n + < classpathentry kind = "" lib "" path = "" lib / ormlite - android - 4 . 34 - SNAPSHOT . jar "" / > \n + < classpathentry kind = "" lib "" path = "" lib / ormlite - core - 4 . 34 - SNAPSHOT . jar "" / > \n deleted file \n PerformanceTestOrmLite \ lib \ ormlite - android - 4 . 24 - sources . jar \n Binary files a / PerformanceTestOrmLite / lib / ormlite - android - 4 . 24 - sources . jar and / dev / null differ \n deleted file \n PerformanceTestOrmLite \ lib \ ormlite - android - 4 . 24 . jar \n Binary files a / PerformanceTestOrmLite / lib / ormlite - android - 4 . 24 . jar and / dev / null differ \n new file \n PerformanceTestOrmLite \ lib \ ormlite - android - 4 . 34 - SNAPSHOT . jar \n Binary files / dev / null and b / PerformanceTestOrmLite / lib / ormlite - android - 4 . 34 - SNAPSHOT . jar differ \n deleted file \n PerformanceTestOrmLite \ lib \ ormlite - core - 4 . 24 - sources . jar \n Binary files a / PerformanceTestOrmLite / lib / ormlite - core - 4 . 24 - sources . jar and / dev / null differ \n deleted file \n PerformanceTestOrmLite \ lib \ ormlite - core - 4 . 24 . jar \n Binary files a / PerformanceTestOrmLite / lib / ormlite - core - 4 . 24 . jar and / dev / null differ \n new file \n PerformanceTestOrmLite \ lib \ ormlite - core - 4 . 34 - SNAPSHOT . jar \n Binary files / dev / null and b / PerformanceTestOrmLite / lib / ormlite - core - 4 . 34 - SNAPSHOT . jar differ \n",updated ormlite libs to 4 . 34 - SNAPSHOT and performance test against it,317
DaoCore \ src \ de \ greenrobot \ dao \ AbstractDao . java \n - / * * Performs a standard Android - style query for entities . * / \n + / * * @ deprecated groupBy & having does not make sense for entities . Method will be removed . * / \n,deprecated query : groupBy & having does not make sense for entities . \n Method will be removed,317
execute - around \ index . md \n - # # Credits \n + # # Credits \n,"added missing space , ' cause website didnt display correctly",318
". travis . yml \n - export DISPLAY = : 99 . 0 \n - sh - e / etc / init . d / xvfb start \n + # default install command is just "" mvn install - DskipTests = true - Dmaven . javadoc . skip = true - B - V "" \n + install : \n + - mvn install - DskipTests = true - Dmaven . javadoc . skip = true - B - V - e \n + \n - mvn clean test jacoco : report coveralls : report \n - bash update - ghpages . sh \n","Turn Error Tracing on when installing \n Travis currently errors and i cant reproduce locally , so this might help finding the culprit",318
. travis . yml \n - mvn clean test jacoco : report coveralls : report \n - bash update - ghpages . sh \n - sudo : false \n + sudo : false # route the build to the container - based infrastructure for a faster build \n,Test commit for # 255 \n ignore the minor documentation change . \n This is to test our build chain with travis !,318
. travis . yml \n - mvn clean test jacoco : report coveralls : report \n - bash update - ghpages . sh \n + # use latest java version available instead of travis default \n,add documentation to ' use latest java 8 ' change,318
data - mapper \ index . md \n - permalink : / patterns / dm / \n + permalink : / patterns / data - mapper / \n - Java \n,"Fix permalink to represent its current dir \n Otherwise the picture cant be found , as the jekyll build process will put this file in a ' dm ' directory and the other stuff like resources in a ' data - mapper ' directory ( because resources dont have permalink specified they are served static )",318
README . md \n - [ Programming / Software Design Principles ] ( http : / / webpro . github . io / programming - principles / ) . \n + Programming / Software Design Principles . \n,"remove link , resolves # 479 \n to avoid confusion , the link is removed . \n For more information on why this is done please look at the referenced issue",318
faq . md \n - page - index : 1 \n + page - index : 5 \n - - - \n,Addendum # 481 \n Change page - index for faq . md,318
rename from data - mapper \ index . md \n rename to data - mapper \ README . md \n,"Rename index . md to README . md \n to conform to our standards , every other file is named README . md",318
. travis . yml \n - iluwatar @ gmail . com \n + webhooks : \n + urls : \n + - https : / / webhooks . gitter . im / e / 3319623945358a093a6f \n + on _ success : change # options : [ always | never | change ] default : always \n + on _ failure : always # options : [ always | never | change ] default : always \n + on _ start : never # options : [ always | never | change ] default : always \n,Add webhook for travis build failures to gitter \n Only the core group ( private ) gitter room,318
"presto - geospatial \ src \ main \ java \ com \ facebook \ presto \ plugin \ geospatial \ BingTileFunctions . java \n - @ Description ( "" Given a ( longitude , latitude ) point , returns the containing Bing tile at the specified zoom level "" ) \n + @ Description ( "" Given a ( latitude , longitude ) point , returns the containing Bing tile at the specified zoom level "" ) \n",Fix a typo in the description of the bing _ tile _ at function,324
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ SubfieldTokenizer . java \n - return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | isUnquotedSubscriptCharacter ( c ) ; \n + return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | c = = ' / ' | | isUnquotedSubscriptCharacter ( c ) ; \n presto - spi \ src \ test \ java \ com \ facebook \ presto \ spi \ TestSubfieldTokenizer . java \n + assertPath ( new Subfield ( "" a / b / c : 12 "" , ImmutableList . of ( ) ) ) ; \n",Add support for column names with slashes to SubfieldTokenizer,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ OrcSelectiveRecordReader . java \n + import com . facebook . presto . spi . block . LazyBlock ; \n + import com . facebook . presto . spi . block . LazyBlockLoader ; \n + import javax . annotation . Nullable ; \n + \n + import java . io . UncheckedIOException ; \n + int offset = getNextRowInGroup ( ) ; \n + if ( ! hasAnyFilter ( columnIndex ) ) { \n + break ; \n + } \n + \n - positionCount = streamReader . read ( getNextRowInGroup ( ) , positionsToRead , positionCount ) ; \n + positionCount = streamReader . read ( offset , positionsToRead , positionCount ) ; \n + else if ( ! hasAnyFilter ( columnIndex ) ) { \n + blocks [ i ] = new LazyBlock ( positionCount , new OrcBlockLoader ( getStreamReader ( columnIndex ) , coercers [ columnIndex ] , offset , positionsToRead , positionCount ) ) ; \n + } \n + \n + private static final class OrcBlockLoader \n + implements LazyBlockLoader < LazyBlock > \n + { \n + private final SelectiveStreamReader reader ; \n + @ Nullable \n + private final Function < Block , Block > coercer ; \n + private final int offset ; \n + private final int [ ] positions ; \n + private final int positionCount ; \n + private boolean loaded ; \n + \n + public OrcBlockLoader ( SelectiveStreamReader reader , @ Nullable Function < Block , Block > coercer , int offset , int [ ] positions , int positionCount ) \n + { \n + this . reader = requireNonNull ( reader , "" reader is null "" ) ; \n + this . coercer = coercer ; / / can be null \n + this . offset = offset ; \n + this . positions = requireNonNull ( positions , "" positions is null "" ) ; \n + this . positionCount = positionCount ; \n + } \n + \n + @ Override \n + public final void load ( LazyBlock lazyBlock ) \n + { \n + if ( loaded ) { \n + return ; \n + } \n + \n + try { \n + reader . read ( offset , positions , positionCount ) ; \n + } \n + catch ( IOException e ) { \n + throw new UncheckedIOException ( e ) ; \n + } \n + \n + Block block = reader . getBlock ( positions , positionCount ) ; \n + if ( coercer ! = null ) { \n + block = coercer . apply ( block ) ; \n + } \n + lazyBlock . setBlock ( block ) ; \n + \n + loaded = true ; \n + } \n + } \n","Use LazyBlock for columns with no filters \n In cases when table scan is followed by projection with a conditional expression , it could \n be beneficial to delay loading some columns as they may never be needed . For example , if \n a = 2 is very selective ( less than 1 in a 1000 ) , using LazyBlock for b allows us to avoid \n reading b for pages with no hits . \n SELECT COUNT _ IF ( a = 2 AND cardinality ( b ) > 4 AND b [ 4 ] = 7 )",324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHivePushdownFilterQueries . java \n + \n + / / case sensitivity \n + assertQuery ( "" SELECT INFO . orderkey FROM lineitem _ ex "" , "" SELECT CASE WHEN orderkey % 23 = 0 THEN null ELSE orderkey END FROM lineitem "" ) ; \n + assertQuery ( "" SELECT INFO . ORDERKEY FROM lineitem _ ex "" , "" SELECT CASE WHEN orderkey % 23 = 0 THEN null ELSE orderkey END FROM lineitem "" ) ; \n + assertQuery ( "" SELECT iNfO . oRdErKeY FROM lineitem _ ex "" , "" SELECT CASE WHEN orderkey % 23 = 0 THEN null ELSE orderkey END FROM lineitem "" ) ; \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ StructSelectiveStreamReader . java \n - String name = ( ( Subfield . NestedField ) path . get ( 0 ) ) . getName ( ) ; \n + String name = ( ( Subfield . NestedField ) path . get ( 0 ) ) . getName ( ) . toLowerCase ( Locale . ENGLISH ) ; \n","Make subfield name matching case insensitive \n Before this fix , with subfield pruning enabled , the following \n query returned NULLs : \n SELECT INFO . ORDERKEY FROM lineitem _ ex",324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveLogicalPlanner . java \n + / / Case sensitivity \n + assertPushdownSubfields ( "" SELECT x . a , x . b , x . A + 2 FROM test _ pushdown _ struct _ subfields WHERE x . B LIKE ' abc % ' "" , "" test _ pushdown _ struct _ subfields "" , \n + ImmutableMap . of ( "" x "" , toSubfields ( "" x . a "" , "" x . b "" ) ) ) ; \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PushdownSubfields . java \n + import java . util . Locale ; \n - newSubfields . add ( new Subfield ( container . getName ( ) , ImmutableList . of ( allSubscripts ( ) , new NestedField ( field . getName ( ) ) ) ) ) ; \n + newSubfields . add ( new Subfield ( container . getName ( ) , ImmutableList . of ( allSubscripts ( ) , nestedField ( field . getName ( ) ) ) ) ) ; \n - . add ( new NestedField ( field . getName ( ) ) ) \n + . add ( nestedField ( field . getName ( ) ) ) \n - elements . add ( new NestedField ( dereference . getField ( ) . getValue ( ) ) ) ; \n + elements . add ( nestedField ( dereference . getField ( ) . getValue ( ) ) ) ; \n + private static NestedField nestedField ( String name ) \n + { \n + return new NestedField ( name . toLowerCase ( Locale . ENGLISH ) ) ; \n + } \n + \n","Create NestedField using lowercase field name \n Fix subfield pruning for queries that refer to the same subfield using \n different word casings : . \n SELECT s . a , s . A FROM t \n Without the fix the query above generated two subfield paths : s . a and s . A .",324
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveMetadata . java \n - . transform ( Subfield : : getRootName ) \n + . transform ( subfield - > isEntireColumn ( subfield ) ? subfield . getRootName ( ) : null ) \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveLogicalPlanner . java \n + import com . facebook . presto . spi . type . ArrayType ; \n + import static com . facebook . presto . spi . predicate . Domain . notNull ; \n + assertPushdownFilterOnSubfields ( "" SELECT * FROM test _ pushdown _ filter _ on _ subfields WHERE c . a IS NOT NULL AND c . c IS NOT NULL "" , \n + ImmutableMap . of ( new Subfield ( "" c . a "" ) , notNull ( BIGINT ) , new Subfield ( "" c . c "" ) , notNull ( new ArrayType ( BIGINT ) ) ) ) ; \n + \n",Fix pushdown for filters on multiple subfields of a struct,324
"presto - geospatial \ src \ test \ java \ com \ facebook \ presto \ plugin \ geospatial \ TestSpatialJoinOperator . java \n + / / Make sure that spatial index reference counting works with duplicate factories \n + joinOperatorFactory . duplicate ( ) . noMoreOperators ( ) ; \n + \n + / / Release the spatial index reference \n + pagesSpatialIndexFactory . probeOperatorFinished ( ) ; \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ PagesSpatialIndexFactory . java \n + / * * \n + * Called by SpatialJoinOperatorFactory to indicate that a duplicate factory will be created \n + * and this class should wait for an extra { @ link noMoreProbeOperators } call before \n + * releasing spatial index . \n + * / \n + public synchronized void addProbeOperatorFactory ( ) \n + { \n + activeProbeOperators . retain ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ SpatialJoinOperator . java \n + checkState ( ! closed , "" Factory is already closed "" ) ; \n + pagesSpatialIndexFactory . addProbeOperatorFactory ( ) ; \n",Fix spatial join on top of colocated right join \n Reference counting for the spatial index didn ' t take into account a possibility \n of having multiple SpatialJoinOperatorFactories . This caused the index to be \n deleted before all the probe operators were done processing . \n The fix is to increment reference count by 1 for each duplicate factory .,324
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ SubfieldTokenizer . java \n - return c = = ' : ' | | isUnquotedSubscriptCharacter ( c ) ; \n + return c = = ' : ' | | c = = ' $ ' | | isUnquotedSubscriptCharacter ( c ) ; \n presto - spi \ src \ test \ java \ com \ facebook \ presto \ spi \ TestSubfieldTokenizer . java \n + new NestedField ( "" $ bucket "" ) , \n","Support synthetic column names in Subfield \n Make $ - sign a valid character in subfield path to support filters on $ bucket \n and $ path columns , e . g . SELECT * FROM t WHERE $ bucket = 1 .",324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ AbstractTestHiveClient . java \n - doTestBucketSortedTables ( table , false ) ; \n - doTestBucketSortedTables ( tableWithTempPath , true ) ; \n + doTestBucketSortedTables ( table , false , ORC ) ; \n + doTestBucketSortedTables ( tableWithTempPath , true , ORC ) ; \n - private void doTestBucketSortedTables ( SchemaTableName table , boolean useTempPath ) \n + private void doTestBucketSortedTables ( SchemaTableName table , boolean useTempPath , HiveStorageFormat storageFormat ) \n - . put ( STORAGE _ FORMAT _ PROPERTY , RCBINARY ) \n + . put ( STORAGE _ FORMAT _ PROPERTY , storageFormat ) \n","Change testBucketSortedTables to use ORC format \n ORC files can be read by both selective and batch readers , while RCBINARY \n can be read only by batch readers . Using ORC format allows to run the test \n for both kinds of readers . \n An alternative of expanding the test to cover all storage formats significantly \n increases test runtime ( from 10s to more than a minute ) .",324
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveClientConfig . java \n + private boolean pushdownFilterEnabled ; \n + \n + \n + public boolean isPushdownFilterEnabled ( ) \n + { \n + return pushdownFilterEnabled ; \n + } \n + \n + @ Config ( "" hive . pushdown - filter - enabled "" ) \n + @ ConfigDescription ( "" Experimental : enable complex filter pushdown "" ) \n + public HiveClientConfig setPushdownFilterEnabled ( boolean pushdownFilterEnabled ) \n + { \n + this . pushdownFilterEnabled = pushdownFilterEnabled ; \n + return this ; \n + } \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveSessionProperties . java \n - false , \n + hiveClientConfig . isPushdownFilterEnabled ( ) , \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveClientConfig . java \n - . setTemporaryTableCompressionCodec ( SNAPPY ) ) ; \n + . setTemporaryTableCompressionCodec ( SNAPPY ) \n + . setPushdownFilterEnabled ( false ) ) ; \n + . put ( "" hive . pushdown - filter - enabled "" , "" true "" ) \n - . setTemporaryTableCompressionCodec ( NONE ) ; \n + . setTemporaryTableCompressionCodec ( NONE ) \n + . setPushdownFilterEnabled ( true ) ; \n",Add hive . pushdown - filter - enabled configuration property,324
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HivePageSourceProvider . java \n - Optional < BucketAdaptation > bucketAdaptation = bucketConversion . map ( conversion - > { \n - Map < Integer , ColumnMapping > hiveIndexToBlockIndex = uniqueIndex ( regularAndInterimColumnMappings , columnMapping - > columnMapping . getHiveColumnHandle ( ) . getHiveColumnIndex ( ) ) ; \n - int [ ] bucketColumnIndices = conversion . getBucketColumnHandles ( ) . stream ( ) \n - . mapToInt ( columnHandle - > hiveIndexToBlockIndex . get ( columnHandle . getHiveColumnIndex ( ) ) . getIndex ( ) ) \n - . toArray ( ) ; \n - List < HiveType > bucketColumnHiveTypes = conversion . getBucketColumnHandles ( ) . stream ( ) \n - . map ( columnHandle - > hiveIndexToBlockIndex . get ( columnHandle . getHiveColumnIndex ( ) ) . getHiveColumnHandle ( ) . getHiveType ( ) ) \n - . collect ( toImmutableList ( ) ) ; \n - return new BucketAdaptation ( bucketColumnIndices , bucketColumnHiveTypes , conversion . getTableBucketCount ( ) , conversion . getPartitionBucketCount ( ) , tableBucketNumber . getAsInt ( ) ) ; \n - } ) ; \n + Optional < BucketAdaptation > bucketAdaptation = bucketConversion . map ( conversion - > toBucketAdaptation ( conversion , regularAndInterimColumnMappings , tableBucketNumber ) ) ; \n + private static BucketAdaptation toBucketAdaptation ( BucketConversion conversion , List < ColumnMapping > columnMappings , OptionalInt tableBucketNumber ) \n + { \n + Map < Integer , ColumnMapping > hiveIndexToBlockIndex = uniqueIndex ( columnMappings , columnMapping - > columnMapping . getHiveColumnHandle ( ) . getHiveColumnIndex ( ) ) ; \n + int [ ] bucketColumnIndices = conversion . getBucketColumnHandles ( ) . stream ( ) \n + . map ( HiveColumnHandle : : getHiveColumnIndex ) \n + . map ( hiveIndexToBlockIndex : : get ) \n + . mapToInt ( ColumnMapping : : getIndex ) \n + . toArray ( ) ; \n + List < HiveType > bucketColumnHiveTypes = conversion . getBucketColumnHandles ( ) . stream ( ) \n + . map ( HiveColumnHandle : : getHiveColumnIndex ) \n + . map ( hiveIndexToBlockIndex : : get ) \n + . map ( ColumnMapping : : getHiveColumnHandle ) \n + . map ( HiveColumnHandle : : getHiveType ) \n + . collect ( toImmutableList ( ) ) ; \n + return new BucketAdaptation ( bucketColumnIndices , bucketColumnHiveTypes , conversion . getTableBucketCount ( ) , conversion . getPartitionBucketCount ( ) , tableBucketNumber . getAsInt ( ) ) ; \n + } \n + \n",Extract helper method to create BucketAdaptation from BucketConversion,324
"presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ BenchmarkBatchStreamReaders . java \n - public static final DecimalType DECIMAL _ TYPE = createDecimalType ( 10 , 5 ) ; \n + public static final DecimalType SHORT _ DECIMAL _ TYPE = createDecimalType ( 10 , 5 ) ; \n - public Object readDecimalNoNull ( DecimalNoNullBenchmarkData data ) \n + public Object readShortDecimalNoNull ( ShortDecimalNoNullBenchmarkData data ) \n - public Object readDecimalWithNull ( DecimalWithNullBenchmarkData data ) \n + public Object readShortDecimalWithNull ( ShortDecimalWithNullBenchmarkData data ) \n - public static class DecimalNoNullBenchmarkData \n + public static class ShortDecimalNoNullBenchmarkData \n - setup ( DECIMAL _ TYPE ) ; \n + setup ( SHORT _ DECIMAL _ TYPE ) ; \n - public static class DecimalWithNullBenchmarkData \n + public static class ShortDecimalWithNullBenchmarkData \n - setup ( DECIMAL _ TYPE ) ; \n + setup ( SHORT _ DECIMAL _ TYPE ) ; \n",Rename * Decimal * to * ShortDecimal * in BenchmarkBatchStreamReaders,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ BooleanSelectiveStreamReader . java \n + checkArgument ( positionCount > 0 , "" positionCount must be greater than zero "" ) ; \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ListSelectiveStreamReader . java \n + checkArgument ( positionCount > 0 , "" positionCount must be greater than zero "" ) ; \n - if ( elementStreamReader ! = null ) { \n + if ( elementStreamReader ! = null & & elementPositionCount > 0 ) { \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongDictionarySelectiveStreamReader . java \n + checkArgument ( positionCount > 0 , "" positionCount must be greater than zero "" ) ; \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongDirectSelectiveStreamReader . java \n + checkArgument ( positionCount > 0 , "" positionCount must be greater than zero "" ) ; \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ TimestampSelectiveStreamReader . java \n + checkArgument ( positionCount > 0 , "" positionCount must be greater than zero "" ) ; \n",Avoid calling SelectiveStreamReader # read with zero positions to read,324
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ DwrfSelectivePageSourceFactory . java \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcLazyReadSmallRanges ; \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcMaxBufferSize ; \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcMaxMergeDistance ; \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcMaxReadBlockSize ; \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcStreamBufferSize ; \n - import static com . facebook . presto . hive . HiveSessionProperties . getOrcTinyStripeThreshold ; \n + session , \n - session . getUser ( ) , \n - getOrcMaxMergeDistance ( session ) , \n - getOrcMaxBufferSize ( session ) , \n - getOrcStreamBufferSize ( session ) , \n - getOrcTinyStripeThreshold ( session ) , \n - getOrcMaxReadBlockSize ( session ) , \n - getOrcLazyReadSmallRanges ( session ) , \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcSelectivePageSourceFactory . java \n + session , \n - session . getUser ( ) , \n - getOrcMaxMergeDistance ( session ) , \n - getOrcMaxBufferSize ( session ) , \n - getOrcStreamBufferSize ( session ) , \n - getOrcTinyStripeThreshold ( session ) , \n - getOrcMaxReadBlockSize ( session ) , \n - getOrcLazyReadSmallRanges ( session ) , \n + ConnectorSession session , \n - String sessionUser , \n - DataSize maxMergeDistance , \n - DataSize maxBufferSize , \n - DataSize streamBufferSize , \n - DataSize tinyStripeThreshold , \n - DataSize maxReadBlockSize , \n - boolean lazyReadSmallRanges , \n + DataSize maxMergeDistance = getOrcMaxMergeDistance ( session ) ; \n + DataSize maxBufferSize = getOrcMaxBufferSize ( session ) ; \n + DataSize streamBufferSize = getOrcStreamBufferSize ( session ) ; \n + DataSize tinyStripeThreshold = getOrcTinyStripeThreshold ( session ) ; \n + DataSize maxReadBlockSize = getOrcMaxReadBlockSize ( session ) ; \n + boolean lazyReadSmallRanges = getOrcLazyReadSmallRanges ( session ) ; \n + \n - FileSystem fileSystem = hdfsEnvironment . getFileSystem ( sessionUser , path , configuration ) ; \n + FileSystem fileSystem = hdfsEnvironment . getFileSystem ( session . getUser ( ) , path , configuration ) ; \n",Replace session - based arguments with session argument in createOrcPageSource \n The full session object will be used in the next commit to evaluate arbitrary \n filters .,324
presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ OrcSelectiveRecordReader . java \n - for ( FilterFunctionWithStats functionWithStats : filterFunctions ) { \n + for ( int i = 0 ; i < filterFunctions . size ( ) ; i + + ) { \n + FilterFunctionWithStats functionWithStats = filterFunctions . get ( i ) ; \n + \n - for ( int i = 0 ; i < inputs . length ; i + + ) { \n - inputBlocks [ i ] = blocks [ filterFunctionInputMapping . get ( inputs [ i ] ) ] ; \n + for ( int j = 0 ; j < inputs . length ; j + + ) { \n + inputBlocks [ j ] = blocks [ filterFunctionInputMapping . get ( inputs [ j ] ) ] ; \n,Optimize loop over filter functions in applyFilterFunctions \n This loop showed up at the top of the profile for a simple query : \n ns percent samples top \n - - - - - - - - - - - - - - - - - - - - - - - - - - - \n 19750000000 22 . 89 % 1975 zError \n 5980000000 6 . 93 % 598 _ block _ invoke . modules \n 5040000000 5 . 84 % 504 com . facebook . presto . orc . reader . LongDirectSelectiveStreamReader . read \n 4820000000 5 . 59 % 482 itable stub \n 4820000000 5 . 59 % 482 _ platform _ memmove $ VARIANT $ Haswell \n 2060000000 2 . 39 % 206 com . facebook . presto . orc . OrcSelectiveRecordReader . applyFilterFunctions \n 1820000000 2 . 11 % 182 com . facebook . presto . orc . FilterFunction . filter \n select count ( * ) from lineitem _ sf100 where orderkey % 5 = 0 AND partkey % 7 = 0 ;,324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestDomainTranslator . java \n + import static com . facebook . presto . hive . HiveTestUtils . mapType ; \n - import static com . facebook . presto . util . Reflection . methodHandle ; \n - private static MapType mapType ( Type keyType , Type valueType ) \n - { \n - return new MapType ( \n - keyType , \n - valueType , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) ) ; \n - } \n - \n - public static void throwUnsupportedOperationException ( ) \n - { \n - throw new UnsupportedOperationException ( ) ; \n - } \n - \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestSubfieldExtractor . java \n + import static com . facebook . presto . hive . HiveTestUtils . mapType ; \n - import static com . facebook . presto . util . Reflection . methodHandle ; \n - private static MapType mapType ( Type keyType , Type valueType ) \n - { \n - return new MapType ( \n - keyType , \n - valueType , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) , \n - methodHandle ( TestDomainTranslator . class , "" throwUnsupportedOperationException "" ) ) ; \n - } \n - \n - public static void throwUnsupportedOperationException ( ) \n - { \n - throw new UnsupportedOperationException ( ) ; \n - } \n - \n",Use HiveTestUtils . mapType in TestSubfieldExtractor and TestDomainTranslator,324
". travis . yml \n - TEST _ SPECIFIC _ MODULES = presto - hive \n - TEST _ SPECIFIC _ MODULES = presto - hive TEST _ FLAGS = "" - P test - hive - materialized "" \n - TEST _ SPECIFIC _ MODULES = presto - hive TEST _ FLAGS = "" - P test - hive - recoverable - grouped - execution "" \n + - TEST _ SPECIFIC _ MODULES = presto - hive TEST _ FLAGS = "" - P test - hive - pushdown - filter - queries "" \n + - TEST _ SPECIFIC _ MODULES = presto - hive TEST _ FLAGS = "" - P test - hive - parquet "" \n - TEST _ SPECIFIC _ MODULES = presto - main \n - TEST _ SPECIFIC _ MODULES = presto - mongodb \n - TEST _ OTHER _ MODULES = ! presto - tests , ! presto - raptor , ! presto - accumulo , ! presto - cassandra , ! presto - hive , ! presto - kudu , ! presto - docs , ! presto - server , ! presto - server - rpm , ! presto - main , ! presto - mongodb \n presto - hive \ pom . xml \n + < exclude > * * / TestHivePushdownFilterQueries . java < / exclude > \n + < exclude > * * / TestParquetDistributedQueries . java < / exclude > \n + < profile > \n + < id > test - hive - pushdown - filter - queries < / id > \n + < build > \n + < plugins > \n + < plugin > \n + < groupId > org . apache . maven . plugins < / groupId > \n + < artifactId > maven - surefire - plugin < / artifactId > \n + < configuration > \n + < includes > \n + < include > * * / TestHivePushdownFilterQueries . java < / include > \n + < / includes > \n + < / configuration > \n + < / plugin > \n + < / plugins > \n + < / build > \n + < / profile > \n + < profile > \n + < id > test - hive - parquet < / id > \n + < build > \n + < plugins > \n + < plugin > \n + < groupId > org . apache . maven . plugins < / groupId > \n + < artifactId > maven - surefire - plugin < / artifactId > \n + < configuration > \n + < includes > \n + < include > * * / TestParquetDistributedQueries . java < / include > \n + < / includes > \n + < / configuration > \n + < / plugin > \n + < / plugins > \n + < / build > \n + < / profile > \n","Reduce running time of presto - hive Travis job \n presto - hive Travis job regularly times out after 1 hour and 20 minutes . This \n change is to move some of the longer running tests into separate jobs . \n Specifically , move TestHivePushdownFilterQueries and \n TestParquetDistributedQueries into their own jobs .",324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ MapDirectSelectiveStreamReader . java \n - if ( presentStream = = null ) { \n + if ( lengthStream = = null ) { \n + readAllNulls ( positions , positionCount ) ; \n + } \n + else if ( presentStream = = null ) { \n + private int readAllNulls ( int [ ] positions , int positionCount ) \n + { \n + if ( nullsAllowed ) { \n + outputPositionCount = positionCount ; \n + outputPositions = positions ; \n + outputPositionsReadOnly = true ; \n + } \n + else { \n + outputPositionCount = 0 ; \n + } \n + \n + allNulls = true ; \n + return positions [ positionCount - 1 ] + 1 ; \n + } \n + \n presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ TestSelectiveOrcReader . java \n + \n + / / read selected positions from all nulls map column \n + tester . testRoundTripTypes ( ImmutableList . of ( INTEGER , mapType ( INTEGER , INTEGER ) ) , \n + ImmutableList . of ( \n + createList ( NUM _ ROWS , i - > random . nextInt ( 10 ) ) , \n + createList ( NUM _ ROWS , i - > null ) ) , \n + toSubfieldFilters ( ImmutableMap . of ( 0 , BigintRange . of ( 0 , 5 , false ) ) ) ) ; \n",Fix NPE in MapDirectSelectiveStreamReader \n MapDirectSelectiveStreamReader was throwing NPE when reading selected \n positions from all - nulls column .,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongDirectSelectiveStreamReader . java \n - if ( readOffset < offset ) { \n - skip ( offset - readOffset ) ; \n - } \n - \n + if ( readOffset < offset ) { \n + skip ( offset - readOffset ) ; \n + } \n + \n presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ TestSelectiveOrcReader . java \n + \n + Random random = new Random ( 0 ) ; \n + \n + / / read selected positions from all nulls column \n + tester . testRoundTripTypes ( ImmutableList . of ( INTEGER , INTEGER ) , \n + ImmutableList . of ( \n + createList ( NUM _ ROWS , i - > random . nextInt ( 10 ) ) , \n + createList ( NUM _ ROWS , i - > null ) ) , \n + toSubfieldFilters ( ImmutableMap . of ( 0 , BigintRange . of ( 0 , 5 , false ) ) ) ) ; \n",Fix NPE in LongDirectSelectiveStreamReader \n LongDirectSelectiveStreamReader was throwing NPE when reading selected \n positions from all - nulls column .,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ AbstractLongSelectiveStreamReader . java \n - protected void ensureValuesCapacity ( int capacity , boolean recordNulls ) \n + private void ensureValuesCapacity ( int capacity , boolean recordNulls ) \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongDictionarySelectiveStreamReader . java \n - if ( nulls ! = null ) { \n + if ( presentStream ! = null & & nullsAllowed ) { \n",Fix index out of bounds in LongDictionary . . . Reader,324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveLogicalPlanner . java \n + import java . util . Optional ; \n - super ( ( ) - > createQueryRunner ( LINE _ ITEM ) ) ; \n + super ( ( ) - > createQueryRunner ( ImmutableList . of ( LINE _ ITEM ) , ImmutableMap . of ( "" experimental . pushdown - subfields - enabled "" , "" true "" ) , Optional . empty ( ) ) ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n + public static final String PUSHDOWN _ SUBFIELDS _ ENABLED = "" pushdown _ subfields _ enabled "" ; \n + false ) , \n + booleanProperty ( \n + PUSHDOWN _ SUBFIELDS _ ENABLED , \n + "" Experimental : enable subfield pruning "" , \n + featuresConfig . isPushdownSubfieldsEnabled ( ) , \n + \n + public static boolean isPushdownSubfieldsEnabled ( Session session ) \n + { \n + return session . getSystemProperty ( PUSHDOWN _ SUBFIELDS _ ENABLED , Boolean . class ) ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n + private boolean pushdownSubfieldsEnabled ; \n + \n + \n + @ Config ( "" experimental . pushdown - subfields - enabled "" ) \n + @ ConfigDescription ( "" Experimental : enable subfield pruning "" ) \n + public FeaturesConfig setPushdownSubfieldsEnabled ( boolean pushdownSubfieldsEnabled ) \n + { \n + this . pushdownSubfieldsEnabled = pushdownSubfieldsEnabled ; \n + return this ; \n + } \n + \n + public boolean isPushdownSubfieldsEnabled ( ) \n + { \n + return pushdownSubfieldsEnabled ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PushdownSubfields . java \n + import static com . facebook . presto . SystemSessionProperties . isPushdownSubfieldsEnabled ; \n + if ( ! isPushdownSubfieldsEnabled ( session ) ) { \n + return plan ; \n + } \n + \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n - . setMaxConcurrentMaterializations ( 10 ) ) ; \n + . setMaxConcurrentMaterializations ( 10 ) \n + . setPushdownSubfieldsEnabled ( false ) ) ; \n + . put ( "" experimental . pushdown - subfields - enabled "" , "" true "" ) \n - . setMaxConcurrentMaterializations ( 5 ) ; \n + . setMaxConcurrentMaterializations ( 5 ) \n + . setPushdownSubfieldsEnabled ( true ) ; \n","Disable PushdownSubfields rule \n Turns out PushdownSubfields doesn ' t interoperate with CBO yet . PushdownSubfields \n changes ColumnHandles , but TableScanStatsRule uses them to look up statistics in \n a map keyed by unmodified ColumnHandles . \n Introduced pushdown _ subfields _ enabled session property and \n experimental . pushdown - subfields - enabled configuration property with default value \n ' false ' to control whether PushdownSubfields rule runs or not .",324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ AbstractTestHiveClient . java \n + . add ( new ColumnMetadata ( "" tinyint _ append "" , TINYINT ) ) \n + result . add ( null ) ; \n + / / tinyint _ append \n + TupleDomain . withColumnDomains ( ImmutableMap . of ( SubfieldWithType . of ( "" tinyint _ append "" , TINYINT ) , Domain . singleValue ( TINYINT , 1L ) ) ) , \n + TupleDomain . withColumnDomains ( ImmutableMap . of ( SubfieldWithType . of ( "" tinyint _ append "" , TINYINT ) , Domain . onlyNull ( TINYINT ) ) ) , \n + TupleDomain . withColumnDomains ( ImmutableMap . of ( SubfieldWithType . of ( "" tinyint _ append "" , TINYINT ) , Domain . notNull ( TINYINT ) ) ) , \n + / / integer _ to _ varchar \n + / / varchar _ to _ integer \n + / / tinyint _ append \n + row - > false , \n + row - > true , \n + row - > false , \n + / / struct _ to _ struct \n",Add test for range filter on a newly added column,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ SliceDirectBatchStreamReader . java \n - format ( "" Values in column \ "" % s \ "" are too large to process for Presto . % s column values are larger than 1GB [ % s ] "" , streamDescriptor . getFieldName ( ) , nextBatchSize , streamDescriptor . getOrcDataSourceId ( ) ) ) ; \n + format ( "" Values in column \ "" % s \ "" are too large to process for Presto . % s column values are larger than 1GB [ % s ] "" , streamDescriptor . getFieldName ( ) , currentBatchSize , streamDescriptor . getOrcDataSourceId ( ) ) ) ; \n",Fix Values are too large error message \n Number of columns in the error message was always zero .,324
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ SubfieldTokenizer . java \n - return c = = ' : ' | | c = = ' $ ' | | isUnquotedSubscriptCharacter ( c ) ; \n + return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | isUnquotedSubscriptCharacter ( c ) ; \n presto - spi \ src \ test \ java \ com \ facebook \ presto \ spi \ TestSubfieldTokenizer . java \n - new NestedField ( "" $ bucket "" ) , \n + @ Test \n + public void testColumnNames ( ) \n + { \n + assertPath ( new Subfield ( "" $ bucket "" , ImmutableList . of ( ) ) ) ; \n + assertPath ( new Subfield ( "" apollo - 11 "" , ImmutableList . of ( ) ) ) ; \n + } \n + \n",Add support for column names with hyphen to SubfieldTokenizer,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ OrcSelectiveRecordReader . java \n + for ( SelectiveStreamReader reader : getStreamReaders ( ) ) { \n + if ( reader ! = null ) { \n + reader . throwAnyError ( positionsToRead , positionCount ) ; \n + } \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ AbstractLongSelectiveStreamReader . java \n + @ Override \n + public void throwAnyError ( int [ ] positions , int positionCount ) \n + { \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ BooleanSelectiveStreamReader . java \n + @ Override \n + public void throwAnyError ( int [ ] positions , int positionCount ) \n + { \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ByteSelectiveStreamReader . java \n + @ Override \n + public void throwAnyError ( int [ ] positions , int positionCount ) \n + { \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongSelectiveStreamReader . java \n + \n + @ Override \n + public void throwAnyError ( int [ ] positions , int positionCount ) \n + { \n + currentReader . throwAnyError ( positions , positionCount ) ; \n + } \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ SelectiveStreamReader . java \n + / * * \n + * Throws any error that occurred while reading specified positions . \n + * \n + * Used by list and map readers to raise "" subscript out of bounds "" error . \n + * / \n + void throwAnyError ( int [ ] positions , int positionCount ) ; \n + \n","Add SelectiveStreamReader . throwAnyError method \n Range filters on elements of lists and maps may result in "" subscript out of bounds "" \n errors , e . g . SELECT * FROM t WHERE a [ 10 ] > 0 query should fail if there is a row \n where a has fewer than 10 elements . Corresponding readers need a way to raise these \n errors , but only for positions that survived all other filters . Raising these errors \n from getBlock works only for readers that filter and project values out . Filter - only \n readers need a different mechanism and the new API provides that .",324
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveClientConfig . java \n + private boolean adaptiveFilterReorderingEnabled = true ; \n + \n + public boolean isAdaptiveFilterReorderingEnabled ( ) \n + { \n + return adaptiveFilterReorderingEnabled ; \n + } \n + \n + @ Config ( "" hive . adaptive - filter - reordering - enabled "" ) \n + @ ConfigDescription ( "" Experimental : enable adaptive filter reordering "" ) \n + public HiveClientConfig setAdaptiveFilterReorderingEnabled ( boolean adaptiveFilterReorderingEnabled ) \n + { \n + this . adaptiveFilterReorderingEnabled = adaptiveFilterReorderingEnabled ; \n + return this ; \n + } \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveSessionProperties . java \n + public static final String ADAPTIVE _ FILTER _ REORDERING _ ENABLED = "" adaptive _ filter _ reordering _ enabled "" ; \n + booleanProperty ( \n + ADAPTIVE _ FILTER _ REORDERING _ ENABLED , \n + "" Experimental : enable adaptive filter reordering "" , \n + hiveClientConfig . isAdaptiveFilterReorderingEnabled ( ) , \n + false ) , \n + public static boolean isAdaptiveFilterReorderingEnabled ( ConnectorSession session ) \n + { \n + return session . getProperty ( ADAPTIVE _ FILTER _ REORDERING _ ENABLED , Boolean . class ) ; \n + } \n + \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcSelectivePageSourceFactory . java \n + import static com . facebook . presto . hive . HiveSessionProperties . isAdaptiveFilterReorderingEnabled ; \n + if ( ! isAdaptiveFilterReorderingEnabled ( session ) ) { \n + filterFunctions . add ( new FilterFunction ( session , determinismEvaluator . isDeterministic ( filter ) , predicateCompiler . compilePredicate ( session . getSqlFunctionProperties ( ) , filter ) . get ( ) ) ) ; \n + return filterFunctions . build ( ) ; \n + } \n + \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveClientConfig . java \n - . setRangeFiltersOnSubscriptsEnabled ( false ) ) ; \n + . setRangeFiltersOnSubscriptsEnabled ( false ) \n + . setAdaptiveFilterReorderingEnabled ( true ) ) ; \n + . put ( "" hive . adaptive - filter - reordering - enabled "" , "" false "" ) \n - . setRangeFiltersOnSubscriptsEnabled ( true ) ; \n + . setRangeFiltersOnSubscriptsEnabled ( true ) \n + . setAdaptiveFilterReorderingEnabled ( false ) ; \n",Add session property to disable adaptive filter reordering,324
"presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n + public static final String LEGACY _ MAP _ SUBSCRIPT = "" do _ not _ use _ legacy _ map _ subscript "" ; \n + booleanProperty ( \n + LEGACY _ MAP _ SUBSCRIPT , \n + "" Do not fail the query if map key is missing "" , \n + featuresConfig . isLegacyMapSubscript ( ) , \n + true ) , \n + public static boolean isLegacyMapSubscript ( Session session ) \n + { \n + return session . getSystemProperty ( LEGACY _ MAP _ SUBSCRIPT , Boolean . class ) ; \n + } \n + \n",Add legacy _ map _ subscript hidden session property,324
"presto - main \ src \ main \ java \ com \ facebook \ presto \ execution \ TaskManagerConfig . java \n + private boolean perOperatorAllocationTrackingEnabled = true ; \n + private boolean taskAllocationTrackingEnabled = true ; \n + public boolean isPerOperatorAllocationTrackingEnabled ( ) \n + { \n + return perOperatorAllocationTrackingEnabled ; \n + } \n + \n + @ Config ( "" task . per - operator - allocation - tracking - enabled "" ) \n + public TaskManagerConfig setPerOperatorAllocationTrackingEnabled ( boolean perOperatorAllocationTrackingEnabled ) \n + { \n + this . perOperatorAllocationTrackingEnabled = perOperatorAllocationTrackingEnabled ; \n + return this ; \n + } \n + \n + public boolean isTaskAllocationTrackingEnabled ( ) \n + { \n + return taskAllocationTrackingEnabled ; \n + } \n + \n + @ Config ( "" task . allocation - tracking - enabled "" ) \n + public TaskManagerConfig setTaskAllocationTrackingEnabled ( boolean taskAllocationTrackingEnabled ) \n + { \n + this . taskAllocationTrackingEnabled = taskAllocationTrackingEnabled ; \n + return this ; \n + } \n + \n presto - main \ src \ test \ java \ com \ facebook \ presto \ execution \ TestTaskManagerConfig . java \n + . setPerOperatorAllocationTrackingEnabled ( true ) \n + . setTaskAllocationTrackingEnabled ( true ) \n + . put ( "" task . per - operator - allocation - tracking - enabled "" , "" false "" ) \n + . put ( "" task . allocation - tracking - enabled "" , "" false "" ) \n + . setPerOperatorAllocationTrackingEnabled ( false ) \n + . setTaskAllocationTrackingEnabled ( false ) \n",Add config properties to enable tracking memory allocations,324
presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ TupleDomainFilter . java \n + / * * \n + * @ return true if getPrecedingPositionsToFail or getSucceedingPositionsToFail may return \n + * non - zero values \n + * / \n + boolean isPositionalFilter ( ) ; \n + \n + \n + @ Override \n + public boolean isPositionalFilter ( ) \n + { \n + return false ; \n + } \n + @ Override \n + public boolean isPositionalFilter ( ) \n + { \n + return true ; \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ LongDirectSelectiveStreamReader . java \n + if ( positions [ positionCount - 1 ] = = positionCount - 1 ) { \n + / / no skipping \n + if ( presentStream = = null ) { \n + / / no nulls \n + if ( ! outputRequired & & filter ! = null & & ! filter . isPositionalFilter ( ) ) { \n + / / no output ; just filter \n + for ( int i = 0 ; i < positionCount ; i + + ) { \n + long value = dataStream . next ( ) ; \n + if ( filter . testLong ( value ) ) { \n + outputPositions [ outputPositionCount ] = positions [ i ] ; \n + outputPositionCount + + ; \n + } \n + } \n + readOffset = offset + positionCount ; \n + return outputPositionCount ; \n + } \n + } \n + } \n + \n,Optimize scan of filter - only no - nulls integers,324
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ RunLengthEncodedBlock . java \n - throw new IllegalArgumentException ( "" position is not valid "" ) ; \n + throw new IllegalArgumentException ( "" position is not valid : "" + position ) ; \n",Add position to ' position is not valid ' error message,324
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ MapDirectSelectiveStreamReader . java \n + int nestedPositionCount = 0 ; \n + nestedPositionCount + = length ; \n - int nestedPositionCount = populateNestedPositions ( positionCount , nestedOffset ) ; \n + populateNestedPositions ( positionCount , nestedPositionCount ) ; \n + int nestedPositionCount = 0 ; \n + nestedPositionCount + = length ; \n - int nestedPositionCount = populateNestedPositions ( nonNullPositionCount , nestedOffset ) ; \n + populateNestedPositions ( nonNullPositionCount , nestedPositionCount ) ; \n - private int populateNestedPositions ( int positionCount , int nestedOffset ) \n + private void populateNestedPositions ( int positionCount , int nestedPositionCount ) \n - nestedPositions = ensureCapacity ( nestedPositions , nestedOffset ) ; \n - int nestedPositionCount = 0 ; \n + nestedPositions = ensureCapacity ( nestedPositions , nestedPositionCount ) ; \n + int index = 0 ; \n - nestedPositions [ nestedPositionCount + + ] = nestedOffsets [ i ] + j ; \n + nestedPositions [ index + + ] = nestedOffsets [ i ] + j ; \n - return nestedPositionCount ; \n",Fix memory allocation for nestedPositions in the map reader,324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveExternalWorkersQueries . java \n - ImmutableMap . of ( "" optimizer . optimize - hash - generation "" , "" false "" ) , \n + ImmutableMap . of ( "" optimizer . optimize - hash - generation "" , "" false "" , \n + "" parse - decimal - literals - as - double "" , "" true "" ) , \n + assertQuery ( "" SELECT * FROM nation WHERE nationkey BETWEEN 3 AND 7 "" ) ; \n + \n + @ Test \n + public void testCast ( ) \n + { \n + / / TODO Fix cast double - to - varchar and boolean - to - varchar . \n + / / cast ( 0 . 0 as varchar ) should return "" 0 . 0 "" , not "" 0 "" . \n + / / cast ( bool as varchar ) should return "" TRUE "" or "" FALSE "" , not "" true "" or "" false "" . \n + assertQuery ( "" SELECT CAST ( linenumber as TINYINT ) , CAST ( linenumber AS SMALLINT ) , "" + \n + "" CAST ( linenumber AS INTEGER ) , CAST ( linenumber AS BIGINT ) , CAST ( quantity AS REAL ) , "" + \n + "" CAST ( orderkey AS DOUBLE ) , CAST ( orderkey AS VARCHAR ) FROM lineitem "" ) ; \n + } \n + \n + @ Test \n + public void testValues ( ) \n + { \n + assertQuery ( "" SELECT 1 , 0 . 24 , ceil ( 4 . 5 ) , ' A not too short ASCII string ' "" ) ; \n + } \n","Add queries with cast , between and values to TestHiveExternalWorkersQueries",324
"presto - common \ src \ main \ java \ com \ facebook \ presto \ common \ SubfieldTokenizer . java \n - return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | c = = ' / ' | | c = = ' @ ' | | c = = ' | ' | | isUnquotedSubscriptCharacter ( c ) ; \n + return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | c = = ' / ' | | c = = ' @ ' | | c = = ' | ' | | c = = ' ' | | isUnquotedSubscriptCharacter ( c ) ; \n presto - common \ src \ test \ java \ com \ facebook \ presto \ common \ TestSubfieldTokenizer . java \n + assertPath ( new Subfield ( "" a and b "" , ImmutableList . of ( ) ) ) ; \n",Add support for column names with spaces to SubfieldTokenizer,324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveExternalWorkersQueries . java \n + import java . util . UUID ; \n - Path tempDirectoryPath = Files . createTempDirectory ( TestHiveExternalWorkersQueries . class . getSimpleName ( ) ) ; \n - \n - if ( workerIndex = = 0 ) { \n - / / Write discovery URL to / tmp / config . properties \n - Files . write ( tempDirectoryPath . resolve ( "" config . properties "" ) , \n - format ( "" discovery . uri = % s \ n "" , discoveryUri ) . getBytes ( ) ) ; \n - } \n + Path tempDirectoryPath = Files . createTempDirectory ( TestHiveExternalWorkersQueries . class . getSimpleName ( ) ) ; \n + int port = 1234 + workerIndex ; \n + \n + / / Write config files \n + Files . write ( tempDirectoryPath . resolve ( "" config . properties "" ) , \n + format ( "" discovery . uri = % s \ n "" + \n + "" node . version = testversion \ n "" + \n + "" http - server . http . port = % d "" , discoveryUri , port ) . getBytes ( ) ) ; \n + Files . write ( tempDirectoryPath . resolve ( "" node . properties "" ) , \n + format ( "" node . id = % s \ n "" + \n + "" node . address = 127 . 0 . 0 . 1 \ n "" + \n + "" node . environment = testing "" , UUID . randomUUID ( ) ) . getBytes ( ) ) ; \n + \n",Catch up TestHiveExternalWorkersQueries with presto _ cpp \n Native worker now reads properties from config . properties \n and node . properties . Updated the test to generate these .,324
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveExternalWorkersQueries . java \n + Path catalogDirectoryPath = tempDirectoryPath . resolve ( "" catalog "" ) ; \n + Files . createDirectory ( catalogDirectoryPath ) ; \n + Files . write ( catalogDirectoryPath . resolve ( "" hive . properties "" ) , "" connector . name = hive "" . getBytes ( ) ) ; \n + \n",Update TestHiveExternalWorkersQueries to create hive . properties file \n Create catalog directory with hive . properties file to allow the worker \n to register connectors dynamically .,324
"imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ BitmapMemoryCacheKeyMultiplexProducer . java \n - super ( inputProducer ) ; \n + super ( inputProducer , "" BitmapMemoryCacheKeyMultiplexProducer "" ) ; \n imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ EncodedCacheKeyMultiplexProducer . java \n - super ( inputProducer , keepCancelledFetchAsLowPriority ) ; \n + super ( inputProducer , "" EncodedCacheKeyMultiplexProducer "" , keepCancelledFetchAsLowPriority ) ; \n imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ producers \ MultiplexProducer . java \n - protected MultiplexProducer ( Producer < T > inputProducer ) { \n - mInputProducer = inputProducer ; \n - mMultiplexers = new HashMap < > ( ) ; \n - mKeepCancelledFetchAsLowPriority = false ; \n + private final String mProducerName ; \n + \n + protected MultiplexProducer ( Producer < T > inputProducer , String producerName ) { \n + this ( inputProducer , producerName , false ) ; \n - protected MultiplexProducer ( Producer < T > inputProducer , boolean keepCancelledFetchAsLowPriority ) { \n + protected MultiplexProducer ( \n + Producer < T > inputProducer , String producerName , boolean keepCancelledFetchAsLowPriority ) { \n + mProducerName = producerName ; \n + \n + context . getProducerListener ( ) . onProducerStart ( context , mProducerName ) ; \n + \n + pair . second \n + . getProducerListener ( ) \n + . onProducerFinishWithFailure ( pair . second , mProducerName , t , null ) ; \n + if ( BaseConsumer . isLast ( status ) ) { \n + pair . second \n + . getProducerListener ( ) \n + . onProducerFinishWithSuccess ( pair . second , mProducerName , null ) ; \n + } \n",Log Multiplexor duration to QPL \n Reviewed By : defHLT \n Differential Revision : D18959760 \n fbshipit - source - id : a7e7324eb673a0376170a59a246a027372273ae8,326
"tools \ flipper \ src \ main \ java \ com \ facebook \ imagepipeline \ debug \ FlipperImageTracker . java \n + public synchronized ImageDebugData trackImage ( String localPath , CacheKey key ) { \n + ImageDebugData data = new ImageDebugData ( localPath ) ; \n + mImageDebugDataMap . put ( key , data ) ; \n + return data ; \n + } \n + \n - ImageDebugData data = new ImageDebugData ( null ) ; \n + ImageDebugData data = new ImageDebugData ( ) ; \n + @ Nullable \n + public synchronized String getLocalPath ( CacheKey key ) { \n + ImageDebugData imageDebugData = getImageDebugData ( key ) ; \n + if ( imageDebugData ! = null ) { \n + return imageDebugData . getLocalPath ( ) ; \n + } \n + return null ; \n + } \n + \n + private @ Nullable String mLocalPath ; \n + \n + public ImageDebugData ( ) { \n + this ( null , null ) ; \n + } \n + this ( imageRequest , null ) ; \n + } \n + \n + public ImageDebugData ( @ Nullable String localPath ) { \n + this ( null , localPath ) ; \n + } \n + \n + public ImageDebugData ( @ Nullable ImageRequest imageRequest , @ Nullable String localPath ) { \n + mLocalPath = localPath ; \n + \n + @ Nullable \n + public String getLocalPath ( ) { \n + return mLocalPath ; \n + } \n",Add option to track image path \n Reviewed By : defHLT \n Differential Revision : D20001055 \n fbshipit - source - id : a6b8d442d85ab6f03eddeb2306e92c474b7b07b5,326
"imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ disk \ DefaultDiskStorage . java \n - return new DiskDumpInfoEntry ( path , type , entryImpl . getSize ( ) , firstBits ) ; \n + return new DiskDumpInfoEntry ( entryImpl . getId ( ) , path , type , entryImpl . getSize ( ) , firstBits ) ; \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ disk \ DiskStorage . java \n + public final String id ; \n - protected DiskDumpInfoEntry ( String path , String type , float size , String firstBits ) { \n + protected DiskDumpInfoEntry ( String id , String path , String type , float size , String firstBits ) { \n + this . id = id ; \n",Implement DiskDumpInfo for FrescoStash and add id to DiskDumpInfo \n Reviewed By : defHLT \n Differential Revision : D20001047 \n fbshipit - source - id : dd2c6785afa2803c3c031e33d3195ec8c1a39aa8,326
"animated - base \ src \ main \ java \ com \ facebook \ fresco \ animation \ bitmap \ cache \ AnimationFrameCacheKey . java \n + \n + @ Override \n + public boolean isResourceIdForDebugging ( ) { \n + return false ; \n + } \n animated - base \ src \ main \ java \ com \ facebook \ imagepipeline \ animated \ impl \ AnimatedFrameCache . java \n + \n + @ Override \n + public boolean isResourceIdForDebugging ( ) { \n + return false ; \n + } \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ CacheKey . java \n + \n + / * * \n + * Returns true if this key was constructed from a resource ID . If this ever changes , the disk \n + * cache entries corresponding to this cache key would be invalidated . \n + * / \n + boolean isResourceIdForDebugging ( ) ; \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ CacheKeyUtil . java \n - ids . add ( secureHashKey ( key ) ) ; \n + ids . add ( key . isResourceIdForDebugging ( ) ? key . getUriString ( ) : secureHashKey ( key ) ) ; \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ MultiCacheKey . java \n + \n + @ Override \n + public boolean isResourceIdForDebugging ( ) { \n + return false ; \n + } \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ SimpleCacheKey . java \n + final boolean mIsResourceIdForDebugging ; \n + this ( key , false ) ; \n + } \n + \n + public SimpleCacheKey ( final String key , boolean isResourceIdForDebugging ) { \n + mIsResourceIdForDebugging = isResourceIdForDebugging ; \n + \n + @ Override \n + public boolean isResourceIdForDebugging ( ) { \n + return mIsResourceIdForDebugging ; \n + } \n imagepipeline \ src \ main \ java \ com \ facebook \ imagepipeline \ cache \ BitmapMemoryCacheKey . java \n + @ Override \n + public boolean isResourceIdForDebugging ( ) { \n + return false ; \n + } \n + \n",Don ' t compute secure hash of CacheKey that already represents a resource \n Reviewed By : defHLT \n Differential Revision : D20001040 \n fbshipit - source - id : 2e1b684aa207d980810ba856456bdc9f7dcfe557,326
fbcore \ src \ main \ java \ com \ facebook \ datasource \ AbstractDataSource . java \n - private void notifyDataSubscriber ( \n + protected void notifyDataSubscriber ( \n,Fix flakiness of screenshot tests \n Reviewed By : oprisnik \n Differential Revision : D19695516 \n fbshipit - source - id : 2d95b4affa9d2acc92f7f0bb5583b8cb7e357011,326
". circleci \ config . yml \n - TERM : dumb \n - ADB _ INSTALL _ TIMEOUT : 10 \n - - _ JAVA _ OPTIONS : - XX : + UnlockExperimentalVMOptions - XX : + UseCGroupMemoryLimitForHeap \n - - GRADLE _ OPTS : - Xmx1536m - Dkotlin . incremental = false - Dorg . gradle . daemon = false - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" - Dorg . gradle . caching = true - Dkotlin . compiler . execution . strategy = in - process \n + - _ JAVA _ OPTIONS : - Xmx4g - XX : + UnlockExperimentalVMOptions - XX : + UseCGroupMemoryLimitForHeap \n + - GRADLE _ OPTS : - Dkotlin . incremental = false - Dorg . gradle . daemon = true - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" - Dorg . gradle . caching = true - Dkotlin . compiler . execution . strategy = in - process \n - BUILD _ THREADS : 2 \n - - JVM _ OPTS : - Xmx2048m \n gradle . properties \n - # Robolectric 4 . x \n - android . enableUnitTestBinaryResources = true \n - \n - ANDROID _ GRADLE _ PLUGIN _ VERSION = 3 . 5 . 3 \n + ANDROID _ GRADLE _ PLUGIN _ VERSION = 3 . 6 . 1 \n gradle \ wrapper \ gradle - wrapper . properties \n - # Fri Jan 31 11 : 48 : 05 GMT 2020 \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 6 . 4 - bin . zip \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 6 . 4 - all . zip \n gradlew \n - # http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + # https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - # For Cygwin , switch paths to Windows format before running java \n - if $ cygwin ; then \n + # For Cygwin or MSYS , switch paths to Windows format before running java \n + if [ "" $ cygwin "" = "" true "" - o "" $ msys "" = "" true "" ] ; then \n gradlew . bat \n - @ rem http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + @ rem https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n",Bump Gradle version \n Reviewed By : oprisnik \n Differential Revision : D20386710 \n fbshipit - source - id : a87337aa55d92ea61f3056332b5145cdb5d39fd3,326
vito \ core \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ drawee - support \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ ktx \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ litho \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ options \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ provider \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n vito \ view \ build . gradle \n - apply from : rootProject . file ( ' release . gradle ' ) \n - \n,Don ' t release Vito packages \n Reviewed By : oprisnik \n Differential Revision : D20536052 \n fbshipit - source - id : bb0ff276a8263f4a8c112f70cdc55878af440bb0,326
tools \ flipper \ src \ main \ java \ com \ facebook \ imagepipeline \ debug \ FlipperImageTracker . java \n - private static final int MAX _ IMAGES _ TO _ TRACK = 200 ; \n + private static final int MAX _ IMAGES _ TO _ TRACK = 1000 ; \n,Add disk cache support for Images plugin \n Reviewed By : defHLT \n Differential Revision : D20001062 \n fbshipit - source - id : 1e7a7900e9f42d05e3bf30472e57cd643caa5aca,326
rename from tools \ stetho \ src \ main \ java \ com \ facebook \ imagepipeline \ cache \ CountingMemoryCacheInspector . java \n rename to imagepipeline - base \ src \ main \ java \ com \ facebook \ imagepipeline \ cache \ CountingMemoryCacheInspector . java \n,Remove stetho dependency \n Reviewed By : jknoxville \n Differential Revision : D19719454 \n fbshipit - source - id : 1dfc054cf19836c39e8397455a1a84ce689d1018,326
README . md \n - implementation ' com . facebook . fresco : fresco : 2 . 1 . 0 ' \n + implementation ' com . facebook . fresco : fresco : 2 . 2 . 0 ' \n docs \ _ config . yml \n - current _ version : 2 . 1 . 0 \n + current _ version : 2 . 2 . 0 \n,Bump version to 2 . 2 . 0 in readme and docs \n Reviewed By : oprisnik \n Differential Revision : D20362252 \n fbshipit - source - id : 70e3189fecf50c7fb01f97b57ce8a99b2f20c834,326
"build . gradle \n + mavenCentral ( ) \n imagepipeline \ build . gradle \n + testImplementation "" com . google . truth : truth : 1 . 0 . 1 "" \n",Add Truth dep to unbreak master \n Reviewed By : oprisnik \n Differential Revision : D19742655 \n fbshipit - source - id : 03dd192608e422318425c7328a8cd2c25c33bf07,326
tools \ flipper \ src \ main \ java \ com \ facebook \ imagepipeline \ debug \ FlipperImageTracker . java \n - \n - if ( mImageRequestDebugDataMap . containsKey ( imagePerfData . getImageRequest ( ) ) ) { \n - mImageRequestDebugDataMap \n - . get ( imagePerfData . getImageRequest ( ) ) \n - . setImagePerfData ( imagePerfData ) ; \n + ImageDebugData debugData = mImageRequestDebugDataMap . get ( imagePerfData . getImageRequest ( ) ) ; \n + if ( debugData ! = null ) { \n + debugData . setImagePerfData ( imagePerfData ) ; \n,Fix NPE in FlipperImageTracker \n Reviewed By : oprisnik \n Differential Revision : D21323423 \n fbshipit - source - id : 31175d6bdb6d2b9c0c4fce63cb7d3d8cdff0cdc0,326
". circleci \ config . yml \n - TERM : dumb \n - ADB _ INSTALL _ TIMEOUT : 10 \n - _ JAVA _ OPTIONS : - XX : + UnlockExperimentalVMOptions - XX : + UseCGroupMemoryLimitForHeap \n - - GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" \n + - GRADLE _ OPTS : - Xmx1536m - Dkotlin . incremental = false - Dorg . gradle . daemon = false - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" \n - BUILD _ THREADS : 2 \n + - JVM _ OPTS : - Xmx2048m \n",Try to fix sporadic CircleCI exception \n Reviewed By : oprisnik \n Differential Revision : D20362110 \n fbshipit - source - id : d0b493df4c081de6d54aaa1d35e1185db7400d79,326
gradle . properties \n - VERSION _ NAME = 2 . 1 . 0 \n + VERSION _ NAME = 2 . 2 . 0 \n,Bump version to 2 . 2 . 0 \n Reviewed By : oprisnik \n Differential Revision : D20362219 \n fbshipit - source - id : 72fc176503e24b5dfc8dbb04e00a9a4244bbffc3,326
". circleci \ config . yml \n - TERM : dumb \n - ADB _ INSTALL _ TIMEOUT : 10 \n - _ JAVA _ OPTIONS : - XX : + UnlockExperimentalVMOptions - XX : + UseCGroupMemoryLimitForHeap \n - - GRADLE _ OPTS : - Xmx1536m - Dkotlin . incremental = false - Dorg . gradle . daemon = false - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" \n + - GRADLE _ OPTS : - Xmx1536m - Dkotlin . incremental = false - Dorg . gradle . daemon = false - Dorg . gradle . jvmargs = "" - XX : + HeapDumpOnOutOfMemoryError "" - Dorg . gradle . caching = true - Dkotlin . compiler . execution . strategy = in - process \n - BUILD _ THREADS : 2 \n - JVM _ OPTS : - Xmx2048m \n",Try to fix sporadic CircleCI exception ( 2 ) \n Reviewed By : oprisnik \n Differential Revision : D20363869 \n fbshipit - source - id : 8cf082d45f53f38f60bcd962ed160924a906c61e,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ imagepipeline \ core \ DefaultExecutorSupplier . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imagepipeline \ core \ ExecutorSupplier . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imagepipeline \ core \ PriorityThreadFactory . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fresco / imagepipeline - base / . . . / imagepipeline / core nullsafe \n Reviewed By : oprisnik \n Differential Revision : D24254770 \n fbshipit - source - id : bb9f5b1270fbdce85472173cca36f8a00da51aa0,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ BaseCacheEventListener . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ CacheErrorLogger . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ CacheEvent . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ CacheEventListener . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ DebuggingCacheKey . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ HasDebugData . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ SimpleCacheKey . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ WriterCallback . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ cache \ common \ WriterCallbacks . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fresco / imagepipeline - base / . . . / cache / common nullsafe \n Reviewed By : oprisnik \n Differential Revision : D24251407 \n fbshipit - source - id : b6a0a1a18abe989da6528c14d0158ac5e86b252e,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ BitmapUtil . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ HeifExifUtil . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ ImageMetaData . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ JfifUtil . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ StreamProcessor . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ TiffUtil . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageutils \ WebpUtil . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fresco / imagepipeline - base / . . . / imageutils nullsafe \n Reviewed By : oprisnik \n Differential Revision : D24249642 \n fbshipit - source - id : a936d2733131a57e7868325b3ed74bb4f42ea69b,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ binaryresource \ BinaryResource . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ binaryresource \ ByteArrayBinaryResource . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ binaryresource \ FileBinaryResource . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n - public boolean equals ( Object obj ) { \n + public boolean equals ( @ Nullable Object obj ) { \n,Make fresco / imagepipeline - base / . . . / binaryresource nullsafe \n Reviewed By : defHLT \n Differential Revision : D24249164 \n fbshipit - source - id : 4396cbc887781c72fa28defaf7d0919e5b6545dd,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ callercontext \ CallerContextVerifier . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fresco / imagepipeline - base / . . . / callercontext nullsafe \n Reviewed By : oprisnik \n Differential Revision : D24249166 \n fbshipit - source - id : ee0e6951ea693d74c5cc59bca099bb09bdabd6e0,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ drawable \ base \ DrawableWithCaches . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fresco / imagepipeline - base / . . . / drawable nullsafe \n Reviewed By : oprisnik \n Differential Revision : D24249167 \n fbshipit - source - id : 0a404ef657fb83042ab8a272b89dba1a7ea846a9,326
imagepipeline - base \ src \ main \ java \ com \ facebook \ imageformat \ DefaultImageFormatChecker . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageformat \ DefaultImageFormats . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageformat \ ImageFormat . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageformat \ ImageFormatChecker . java \n - @ Nullsafe ( Nullsafe . Mode . LOCAL ) \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n imagepipeline - base \ src \ main \ java \ com \ facebook \ imageformat \ ImageFormatCheckerUtils . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,"Make fresco / imagepipeline - base / . . . / imageformat nullsafe \n Reviewed By : oprisnik , defHLT \n Differential Revision : D24249165 \n fbshipit - source - id : 17692a3bd8747304d11eb6bf9f523744dd7b89af",326
fbcore \ src \ main \ java \ com \ facebook \ common \ util \ ByteConstants . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n fbcore \ src \ main \ java \ com \ facebook \ common \ util \ ExceptionWithNoStacktrace . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n fbcore \ src \ main \ java \ com \ facebook \ common \ util \ StreamUtil . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fbcore / . . . / common / util : util nullsafe \n Reviewed By : oprisnik \n Differential Revision : D25532013 \n fbshipit - source - id : 2bdf8d3f21e38bfad52936cd27aa7d80115e9044,326
fbcore \ src \ main \ java \ com \ facebook \ common \ util \ HashCodeUtil . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fbcore / . . . / common / util / HashCodeUtil nullsafe \n Reviewed By : oprisnik \n Differential Revision : D25531877 \n fbshipit - source - id : 8634b7147dd0d54b302c92bf8667728670f0f039,326
fbcore \ src \ main \ java \ com \ facebook \ common \ util \ Hex . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n,Make fbcore / . . . / common / util / Hex nullsafe \n Reviewed By : oprisnik \n Differential Revision : D25531847 \n fbshipit - source - id : 302b1b9a5f8861a8ff1fd8824162bfef81785532,326
"fbcore \ src \ main \ java \ com \ facebook \ common \ util \ UriUtil . java \n + import static com . facebook . infer . annotation . Assertions . assumeNotNull ; \n + \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n - Uri . withAppendedPath ( ContactsContract . AUTHORITY _ URI , "" display _ photo "" ) ; \n + Uri . withAppendedPath ( assumeNotNull ( ContactsContract . AUTHORITY _ URI ) , "" display _ photo "" ) ; \n + if ( uri . getPath ( ) = = null ) { \n + return false ; \n + } \n - & & ! uri . getPath ( ) . startsWith ( LOCAL _ CONTACT _ IMAGE _ URI . getPath ( ) ) ; \n + & & ! uri . getPath ( ) . startsWith ( assumeNotNull ( LOCAL _ CONTACT _ IMAGE _ URI . getPath ( ) ) ) ; \n",Make fbcore / . . . / common / util / UriUtil nullsafe \n Reviewed By : defHLT \n Differential Revision : D25531720 \n fbshipit - source - id : e82224c791a40ef407fd004343c066b261686889,326
fbcore \ src \ main \ java \ com \ facebook \ common \ util \ TriState . java \n + import com . facebook . infer . annotation . Nullsafe ; \n + @ Nullsafe ( Nullsafe . Mode . STRICT ) \n - public static TriState valueOf ( Boolean bool ) { \n + public static TriState valueOf ( @ Nullable Boolean bool ) { \n,Make fbcore / . . . / common / util / TriState nullsafe \n Reviewed By : oprisnik \n Differential Revision : D25531412 \n fbshipit - source - id : 79729ca199f9ce8c119e36624460aebf577bf575,326
"AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ ItemClicksHandledActivity . java \n + @ ViewById \n + ListView listViewWithPosition ; \n + \n + int listViewWithPositionClickedPosition ; \n + \n + boolean listViewWithPositionItemSelected ; \n + int listViewWithPositionItemSelectedPosition ; \n + \n + listViewWithPosition . setAdapter ( adapter ) ; \n - \n + listViewWithPositionClickedPosition = position ; \n - \n + listViewWithPositionItemSelected = selected ; \n + listViewWithPositionItemSelectedPosition = position ; \n - \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ test \ java \ com \ googlecode \ androidannotations \ test15 \ ItemClicksHandledActivityTest . java \n + @ Test \n + public void handlingListViewItemClickWithPosition ( ) { \n + ListView listView = ( ListView ) activity . findViewById ( R . id . listViewWithPosition ) ; \n + long itemId = listView . getAdapter ( ) . getItemId ( TESTED _ CLICKED _ INDEX ) ; \n + View view = listView . getChildAt ( TESTED _ CLICKED _ INDEX ) ; \n + \n + assertThat ( activity . listViewWithPositionClickedPosition ) . isEqualTo ( 0 ) ; \n + listView . performItemClick ( view , TESTED _ CLICKED _ INDEX , itemId ) ; \n + assertThat ( activity . listViewWithPositionClickedPosition ) . isEqualTo ( TESTED _ CLICKED _ INDEX ) ; \n + } \n + \n + @ Test \n + public void handlingListViewWithPositionItemSelected ( ) { \n + ListView listView = ( ListView ) activity . findViewById ( R . id . listViewWithPosition ) ; \n + \n + assertThat ( activity . listViewWithPositionClickedPosition ) . isEqualTo ( 0 ) ; \n + listView . setSelection ( TESTED _ CLICKED _ INDEX ) ; \n + assertThat ( activity . listViewWithPositionItemSelected ) . isTrue ( ) ; \n + assertThat ( activity . listViewWithPositionItemSelectedPosition ) . isEqualTo ( TESTED _ CLICKED _ INDEX ) ; \n + } \n + \n",Added new tests to check ListView item action handling,327
AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ SaveInstanceStateActivity . java \n - import java . util . List ; \n + import java . util . ArrayList ; \n - List < String > myStringList ; \n + ArrayList < String > myStringList ; \n,Modified the type of a tested attribute because android Bundle API does not accept List but accept ArrayList,327
"AndroidAnnotations \ functional - test - 1 - 5 - tests \ src \ test \ java \ com \ googlecode \ androidannotations \ test15 \ ClicksHandledActivityTest . java \n + @ Test \n + public void avoidStackOverflow ( ) { \n + assertThat ( activity . avoidStackOverflowEventHandled ) . isFalse ( ) ; \n + \n + activity . findViewById ( R . id . stackOverflowProofButton ) . performClick ( ) ; \n + \n + assertThat ( activity . avoidStackOverflowEventHandled ) . isTrue ( ) ; \n + } \n + \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ src \ test \ java \ com \ googlecode \ androidannotations \ test15 \ LongClicksHandledActivityTest . java \n + @ Test \n + public void avoidStackOverflow ( ) throws InterruptedException { \n + assertThat ( activity . avoidStackOverflowEventHandled ) . isFalse ( ) ; \n + \n + activity . findViewById ( R . id . stackOverflowProofButton ) . performLongClick ( ) ; \n + \n + assertThat ( activity . avoidStackOverflowEventHandled ) . isTrue ( ) ; \n + } \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ res \ layout \ clickable _ widgets . xml \n + < Button \n + android : id = "" @ + id / stackOverflowProofButton "" \n + android : layout _ width = "" fill _ parent "" \n + android : layout _ height = "" wrap _ content "" / > \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ ClicksHandledActivity . java \n + @ Click ( R . id . stackOverflowProofButton ) \n + public void onClick ( View v ) { \n + avoidStackOverflowEventHandled = true ; \n + } \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ EventsHandledAbstractActivity . java \n + protected boolean avoidStackOverflowEventHandled ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ LongClicksHandledActivity . java \n + @ LongClick ( R . id . stackOverflowProofButton ) \n + public void onLongClick ( View v ) { \n + avoidStackOverflowEventHandled = true ; \n + } \n + \n",Added some tests on @ Click and @ LongClick to show stackoverflow error will not appear using those annotations .,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ EBeanHolder . java \n - } catch ( Exception e ) { \n + } catch ( Throwable t ) { \n,Catched Throwable instead of Exception . \n See # 156 for more informations .,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ AndroidAnnotationProcessor . java \n - SaveOnActivityDestroy . class / / \n - EApplication . class , / / \n + SaveOnActivityDestroy . class , / / \n + EApplication . class / / \n",Fixed : missed comma on supported annotations list,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ helper \ ValidatorHelper . java \n - annotationHelper . printError ( element , "" % s annotated element should have an empty constructor "" ) ; \n + annotationHelper . printAnnotationError ( element , "" % s annotated element should have an empty constructor "" ) ; \n - annotationHelper . printError ( element , "" % s annotated element should not have a private constructor "" ) ; \n + annotationHelper . printAnnotationError ( element , "" % s annotated element should not have a private constructor "" ) ; \n - annotationHelper . printError ( element , "" % s annotated element should have only one constructor "" ) ; \n + annotationHelper . printAnnotationError ( element , "" % s annotated element should have only one constructor "" ) ; \n",Fixed # 100 : error message is not well printed,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ AndroidAnnotationProcessor . java \n - if ( traceActivated ( ) ) { \n - modelValidator . register ( new TraceValidator ( processingEnv ) ) ; \n - } \n + modelValidator . register ( new TraceValidator ( processingEnv ) ) ; \n - modelProcessor . register ( new TraceProcessor ( ) ) ; \n + if ( traceActivated ( ) ) { \n + modelProcessor . register ( new TraceProcessor ( ) ) ; \n + } \n,Fixed @ Trace annotation validation when traces are disabled . See # 233,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ helper \ CanonicalNameConstants . java \n + public static final String SEEKBAR = "" android . widget . SeekBar "" ; \n + public static final String ON _ SEEKBAR _ CHANGE _ LISTENER = "" android . widget . SeekBar . OnSeekBarChangeListener "" ; \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ EBeansHolder . java \n + public final JClass SEEKBAR = refClass ( CanonicalNameConstants . SEEKBAR ) ; \n + public final JClass ON _ SEEKBAR _ CHANGE _ LISTENER = refClass ( CanonicalNameConstants . ON _ SEEKBAR _ CHANGE _ LISTENER ) ; \n",Added new class reference to support SeekBar . OnSeekBarChangeListener,327
"AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ SeekBarChangeListenedActivity . java \n - void m4 ( SeekBar seekBar , boolean fromUser , int progress ) { \n + void m4 ( boolean fromUser , int progress ) { \n - void m6 ( Boolean fromUser , SeekBar seekBar , Integer progress ) { \n + void m6 ( Boolean fromUser , Integer progress ) { \n + } \n + \n + @ ProgressChange ( { R . id . seekBar1 , R . id . seekBar2 } ) \n + void m7 ( ) { \n - void m7 ( SeekBar seekBar ) { \n + void m8 ( SeekBar seekBar ) { \n - void m8 ( SeekBar seekBar ) { \n + void m9 ( SeekBar seekBar ) { \n + } \n + \n + @ TrackingTouchStop ( R . id . seekBar1 ) \n + void m10 ( ) { \n - void m9 ( SeekBar seekBar ) { \n + void m11 ( SeekBar seekBar ) { \n + } \n + \n + @ TrackingTouchStart ( R . id . seekBar1 ) \n + void m12 ( ) { \n",Added new unit tests to make sure that SeekBar parameter is not mandatored while validaion phase,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ annotations \ ProgressChange . java \n + * < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n - * Some usage examples of & # 064 ; ProgressChange annotation : < blockquote > \n + * < / blockquote > < blockquote > \n + * \n + * Some usage examples of & # 064 ; ProgressChange annotation : \n - * < / pre > \n - * < / blockquote > < blockquote > \n - * < pre > \n - * < / blockquote > < blockquote > \n - * \n - * < / blockquote > < blockquote > \n - * \n - * < / blockquote > < blockquote > \n + * < / blockquote > \n + * \n + * @ since 2 . 7 \n + * @ see com . googlecode . androidannotations . annotations . TrackingTouchStart \n + * @ see com . googlecode . androidannotations . annotations . TrackingTouchStop \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ annotations \ TrackingTouchStart . java \n + * < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > \n + * \n + * @ since 2 . 7 \n + * \n + * @ see com . googlecode . androidannotations . annotations . TrackingTouchStop \n + * @ see com . googlecode . androidannotations . annotations . ProgressChange \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ annotations \ TrackingTouchStop . java \n + * < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > < blockquote > \n + * \n + * < / blockquote > \n + * \n + * @ since 2 . 7 \n + * \n + * @ see com . googlecode . androidannotations . annotations . TrackingTouchStart \n + * @ see com . googlecode . androidannotations . annotations . ProgressChange \n,"Enhanced javadoc formatting for @ ProgressChange , @ TrackingTouchStart and @ TrackingTouchStop",327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ helper \ TargetAnnotationHelper . java \n + if ( target . getSimpleName ( ) . endsWith ( "" e "" ) ) { \n + return target . getSimpleName ( ) + "" d "" ; \n + } \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ AfterTextChangeProcessor . java \n - List < JFieldRef > idsRefs = helper . extractFieldRefsFromAnnotationValues ( element , annotation . value ( ) , "" TextChanged "" , holder ) ; \n + List < JFieldRef > idsRefs = helper . extractFieldRefsFromAnnotationValues ( element , annotation . value ( ) , "" AfterTextChanged "" , holder ) ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TextWatchedActivity . java \n + @ BeforeTextChange \n + void helloTextViewBeforeTextChanged ( ) { } \n + \n + @ AfterTextChange \n + void helloTextViewAfterTextChanged ( ) { } \n + \n + @ TextChange \n + void helloTextViewTextChanged ( ) { } \n + \n","@ TextChange , @ BeforeTextChange and @ AfterTextChange is unable to determine targeted view when no value is passed through annotation .",327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ ProgressChangeProcessor . java \n - String parameterName = parameter . toString ( ) ; \n - } else if ( parameterType . getKind ( ) = = TypeKind . INT | | CanonicalNameConstants . INTEGER . equals ( parameterType . toString ( ) ) / / \n - & & "" progress "" . equals ( parameterName ) ) { \n + } else if ( parameterType . getKind ( ) = = TypeKind . INT | | CanonicalNameConstants . INTEGER . equals ( parameterType . toString ( ) ) ) { \n - } else if ( ( parameterType . getKind ( ) = = TypeKind . BOOLEAN | | CanonicalNameConstants . BOOLEAN . equals ( parameterType . toString ( ) ) ) / / \n - & & "" fromUser "" . equals ( parameterName ) ) { \n + } else if ( parameterType . getKind ( ) = = TypeKind . BOOLEAN | | CanonicalNameConstants . BOOLEAN . equals ( parameterType . toString ( ) ) ) { \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ validation \ ProgressChangeValidator . java \n + boolean fromUserParameterFound = false ; \n + boolean progressParameterFound = false ; \n - String parameterName = parameter . toString ( ) ; \n - if ( "" progress "" . equals ( parameterName ) ) { \n - continue ; \n + if ( progressParameterFound ) { \n + annotationHelper . printAnnotationError ( executableElement , "" You can have only one parameter of type "" + CanonicalNameConstants . INTEGER ) ; \n + valid . invalidate ( ) ; \n - annotationHelper . printAnnotationError ( executableElement , "" Unrecognized parameter name . The parameter name must be ' progress ' . "" ) ; \n - valid . invalidate ( ) ; \n + progressParameterFound = true ; \n - String parameterName = parameter . toString ( ) ; \n - if ( "" fromUser "" . equals ( parameterName ) ) { \n - continue ; \n + if ( fromUserParameterFound ) { \n + annotationHelper . printAnnotationError ( executableElement , "" You can have only one parameter of type "" + CanonicalNameConstants . BOOLEAN ) ; \n + valid . invalidate ( ) ; \n - annotationHelper . printAnnotationError ( executableElement , "" Unrecognized parameter name . The parameter name must be ' fromUser ' . "" ) ; \n - valid . invalidate ( ) ; \n + fromUserParameterFound = true ; \n - \n","progress and fromUser parameters names are not fixed by AA . Developpers can choose their own , AA decide what it means using parameter types .",327
AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ ThreadActivity . java \n + import com . googlecode . androidannotations . test15 . instancestate . MySerializableBean ; \n + \n + @ UiThread \n + void arrayParamtersMethod ( MySerializableBean [ ] array ) { \n + \n + } \n,Added new test to show compilation error in the generated code when a method annotated using @ UiThread take an array parameter,327
"AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ ThreadActivity . java \n - void genericBackgroundMethod ( List < Map < String , List < Set < Void > > > > param ) { \n + void genericBackgroundMethod ( List < Map < String , List < Set < MySerializableBean [ ] > > > > param ) { \n - void arrayParamtersMethod ( MySerializableBean [ ] array ) { \n - \n - } \n + void uiThreadedUsingArrayParamtersMethod ( MySerializableBean [ ] array ) { } \n + \n + @ UiThread \n + void uiThreadedUsingArrayParamtersMethod ( MySerializableBean [ ] [ ] array ) { } \n + @ Background \n + void backgrounddUsingArrayParamtersMethod ( MySerializableBean [ ] array ) { } \n + \n + @ Background \n + void backgroundUsingArrayParamtersMethod ( MySerializableBean [ ] [ ] array ) { } \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TracedActivity . java \n + import com . googlecode . androidannotations . test15 . instancestate . MySerializableBean ; \n + \n + @ Trace \n + void tracedUsingArrayParameters ( / / \n + MySerializableBean [ ] array , \n + MySerializableBean [ ] [ ] multiDimArray ) { \n + \n + } \n","Added new tests to show errors in generated code when methods annotated using @ Background , @ Trace and @ UiThread use arrays in the parameters .",327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ helper \ APTCodeModelHelper . java \n + import javax . lang . model . type . ArrayType ; \n + } else if ( type instanceof ArrayType ) { \n + ArrayType arrayType = ( ArrayType ) type ; \n + \n + JClass refClass = typeMirrorToJClass ( arrayType . getComponentType ( ) , holder ) ; \n + \n + return refClass . array ( ) ; \n","Handle correctly arrays parameters on method annotated using @ Background , @ Trace , @ UiThread ( see Issue 131 )",327
"AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TransactionalActivity . java \n + import java . util . List ; \n + \n + import com . googlecode . androidannotations . test15 . instancestate . MySerializableBean ; \n + @ Transactional \n + void mehodUsingArrayParameters ( SQLiteDatabase db , / / \n + MySerializableBean [ ] parameters ) { \n + / / do some stuff here \n + } \n + \n + @ Transactional \n + void mehodUsingParametrizedParameters ( SQLiteDatabase db , / / \n + List < MySerializableBean > parameters ) { \n + / / do some stuff here \n + } \n + \n",Added a new test that show errors on generated code when @ Transactional is used with parameterized parameters or array parameters,327
AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TracedActivity . java \n + import android . database . sqlite . SQLiteDatabase ; \n + import com . googlecode . androidannotations . annotations . Transactional ; \n + @ Trace \n + @ Transactional \n + void mixedTransactionalMethod ( SQLiteDatabase db ) { \n + \n + } \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TransactionalActivity . java \n + import com . googlecode . androidannotations . annotations . Trace ; \n + @ Transactional \n + MySerializableBean transactionnalWithReturnStatement ( SQLiteDatabase db ) { \n + return null ; \n + } \n + \n,Added some tests related to @ Trace and @ Transactional .,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ TransactionalProcessor . java \n - import java . util . ArrayList ; \n - import java . util . List ; \n - import javax . lang . model . element . VariableElement ; \n + import com . googlecode . androidannotations . helper . APTCodeModelHelper ; \n - import com . sun . codemodel . JMod ; \n + private final APTCodeModelHelper helper = new APTCodeModelHelper ( ) ; \n + \n - String methodName = element . getSimpleName ( ) . toString ( ) ; \n - JMethod method = holder . eBean . method ( JMod . PUBLIC , returnType , methodName ) ; \n - method . annotate ( Override . class ) ; \n - \n - List < JVar > params = new ArrayList < JVar > ( ) ; \n - for ( VariableElement parameter : executableElement . getParameters ( ) ) { \n - String parameterName = parameter . getSimpleName ( ) . toString ( ) ; \n - String parameterType = parameter . asType ( ) . toString ( ) ; \n - JVar param = method . param ( holder . refClass ( parameterType ) , parameterName ) ; \n - params . add ( param ) ; \n - } \n + JMethod method = helper . overrideAnnotatedMethod ( executableElement , holder ) ; \n + helper . removeBody ( method ) ; \n - JVar db = params . get ( 0 ) ; \n + JVar db = method . params ( ) . get ( 0 ) ; \n - for ( JVar param : params ) { \n + for ( JVar param : method . params ( ) ) { \n",Fixing error in generated code when a method contains a parameterized parameters and array parameters,327
"AndroidAnnotations \ androidannotations - api \ META - INF \ MANIFEST . MF \n - Require - Bundle : org . eclipse . core . runtime ; bundle - version = "" 3 . 8 . 0 "" , \n + Require - Bundle : org . eclipse . core . runtime ; bundle - version = "" 3 . 6 . 0 "" , \n",Fixed : Eclipse plugin library dependency version was only compatible with Juno,327
"AndroidAnnotations \ androidannotations - api \ src \ main \ java \ com \ googlecode \ androidannotations \ annotations \ OnActivityResult . java \n - public static final int DEFAULT _ VALUE = Integer . MAX _ VALUE - 1 ; \n - \n - int value ( ) default DEFAULT _ VALUE ; \n + int value ( ) ; \n AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ validation \ OnActivityResultValidator . java \n - if ( onResultAnnotation . value ( ) = = OnActivityResult . DEFAULT _ VALUE ) { \n - annotationHelper . printAnnotationError ( element , "" A value has to be filled into the annotation parameter "" ) ; \n - valid . invalidate ( ) ; \n - } \n - \n",Fixed : no need to add default value for annotation field in order to check that a value has been filled,327
"AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ com \ googlecode \ androidannotations \ test15 \ TransactionalActivity . java \n + import com . googlecode . androidannotations . annotations . Background ; \n + @ Transactional \n + @ Background \n + void backgroundTransactionalAnnotatedMethod ( SQLiteDatabase db , / / \n + List < MySerializableBean [ ] > parameters ) { \n + / / do some stuff here \n + } \n + \n",Added a new test that show error in generated code when a method is annotated using @ Background and @ Transactional,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ com \ googlecode \ androidannotations \ processing \ TransactionalProcessor . java \n + import com . sun . codemodel . JExpression ; \n - JInvocation superCall = JExpr . invoke ( JExpr . _ super ( ) , method ) ; \n + JExpression activitySuper = holder . eBean . staticRef ( "" super "" ) ; \n + JInvocation superCall = JExpr . invoke ( activitySuper , method ) ; \n + \n",Fixed bad generated code when a method s invoked using @ Background and @ Transactional .,327
"AndroidAnnotations \ androidannotations - api \ src \ main \ java \ org \ androidannotations \ annotations \ EBean . java \n - import org . androidannotations . api . Scope ; \n - \n + public enum Scope { \n + \n + / * * \n + * A new instance of the bean is created each time it is needed \n + * / \n + Default , / / \n + \n + / * * \n + * A new instance of the bean is created the first time it is needed , it is \n + * then retained and the same instance is always returned . \n + * / \n + Singleton , / / \n + } \n + \n deleted file \n AndroidAnnotations \ androidannotations - api \ src \ main \ java \ org \ androidannotations \ api \ Scope . java \n - / * * \n - * Copyright ( C ) 2010 - 2012 eBusiness Information , Excilys Group \n - * \n - * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; you may not \n - * use this file except in compliance with the License . You may obtain a copy of \n - * the License at \n - * \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - * \n - * Unless required by applicable law or agreed To in writing , software \n - * distributed under the License is distributed on an "" AS IS "" BASIS , WITHOUT \n - * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the \n - * License for the specific language governing permissions and limitations under \n - * the License . \n - * / \n - package org . androidannotations . api ; \n - \n - public enum Scope { \n - \n - / * * \n - * A new instance of the bean is created each time it is needed \n - * / \n - Default , / / \n - \n - / * * \n - * A new instance of the bean is created the first time it is needed , it is \n - * then retained and the same instance is always returned . \n - * / \n - Singleton , / / \n - ; \n - } \n",Refactoring : Scope is now declared as an inner class of EBean . \n * * This change make the future release non backward compatible * *,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ helper \ APTCodeModelHelper . java \n + import javax . lang . model . type . WildcardType ; \n + \n + } else if ( type instanceof WildcardType ) { \n + / / TODO : At his time ( 01 / 2013 ) , it is not possible to handle the \n + / / super bound because code model does not offer a way to model \n + / / statement like "" ? super X "" \n + / / ( see http : / / java . net / jira / browse / CODEMODEL - 11 ) \n + WildcardType wildcardType = ( WildcardType ) type ; \n + \n + TypeMirror extendsBound = wildcardType . getExtendsBound ( ) ; \n + \n + return typeMirrorToJClass ( extendsBound , holder ) . wildcard ( ) ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ ThreadActivity . java \n - \n - import android . app . Activity ; \n + import java . util . SortedSet ; \n + import org . androidannotations . test15 . ebean . GenericBean ; \n + import org . androidannotations . test15 . ebean . SomeBean ; \n + import android . app . Activity ; \n + \n + @ Background \n + void genericBackgroundMethod ( Set < ? extends GenericBean < ? extends SomeBean > > param ) { \n + \n + } \n + \n new file \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ ebean \ GenericBean . java \n + / * * \n + * Copyright ( C ) 2010 - 2012 eBusiness Information , Excilys Group \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; you may not \n + * use this file except in compliance with the License . You may obtain a copy of \n + * the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed To in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , WITHOUT \n + * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the \n + * License for the specific language governing permissions and limitations under \n + * the License . \n + * / \n + package org . androidannotations . test15 . ebean ; \n + \n + \n + public class GenericBean < T > { \n + \n + } \n","Take care of statements like "" ? extends X "" when trying to translate a TypeMirror into a JClass",327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ generation \ ApiCodeGenerator . java \n + import javax . annotation . processing . FilerException ; \n - if ( apiClassOriginatingElements = = null ) { \n - targetedClassFile = filer . createSourceFile ( canonicalApiClassName ) ; \n - } else { \n - targetedClassFile = filer . createSourceFile ( canonicalApiClassName , apiClassOriginatingElements ) ; \n - } \n - OutputStream classFileOutputStream = targetedClassFile . openOutputStream ( ) ; \n - copyStream ( apiClassStream , classFileOutputStream ) ; \n - classFileOutputStream . close ( ) ; \n + try { \n + if ( apiClassOriginatingElements = = null ) { \n + targetedClassFile = filer . createSourceFile ( canonicalApiClassName ) ; \n + } else { \n + targetedClassFile = filer . createSourceFile ( canonicalApiClassName , apiClassOriginatingElements ) ; \n + } \n + \n + OutputStream classFileOutputStream = targetedClassFile . openOutputStream ( ) ; \n + copyStream ( apiClassStream , classFileOutputStream ) ; \n + classFileOutputStream . close ( ) ; \n + \n + } catch ( FilerException e ) { \n + / / This exception is thrown when we are trying to generate \n + / / an already generated file . This is happening on an \n + / / incremental build . \n + / / Unfortunately there is no way to check if a file has \n + / / already been generated . \n + } \n",Handle FilerException from Filer . createSourceFile ( . . . ),327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ validation \ OrmLiteDaoValidator . java \n - validatorHelper . enclosingElementHasEnhancedViewSupportAnnotation ( element , validatedElements , valid ) ; \n + validatorHelper . enclosingElementHasEnhancedComponentAnnotation ( element , validatedElements , valid ) ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ efragment \ MyFragment . java \n + import org . androidannotations . annotations . OrmLiteDao ; \n + import org . androidannotations . test15 . ormlite . DatabaseHelper ; \n + import org . androidannotations . test15 . ormlite . User ; \n + import org . androidannotations . test15 . ormlite . UserDao ; \n + \n + @ OrmLiteDao ( helper = DatabaseHelper . class , model = User . class ) \n + UserDao userDao ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ eprovider \ MyProvider . java \n + import org . androidannotations . annotations . OrmLiteDao ; \n + import org . androidannotations . test15 . ormlite . DatabaseHelper ; \n + import org . androidannotations . test15 . ormlite . User ; \n + import org . androidannotations . test15 . ormlite . UserDao ; \n + @ OrmLiteDao ( helper = DatabaseHelper . class , model = User . class ) \n + UserDao userDao ; \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ eservice \ MyService . java \n + import org . androidannotations . annotations . OrmLiteDao ; \n + import org . androidannotations . test15 . ormlite . DatabaseHelper ; \n + import org . androidannotations . test15 . ormlite . User ; \n + import org . androidannotations . test15 . ormlite . UserDao ; \n + @ OrmLiteDao ( helper = DatabaseHelper . class , model = User . class ) \n + UserDao userDao ; \n + \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ roboguice \ SampleRoboApplication . java \n + import org . androidannotations . annotations . OrmLiteDao ; \n + import org . androidannotations . test15 . ormlite . DatabaseHelper ; \n + import org . androidannotations . test15 . ormlite . User ; \n + import org . androidannotations . test15 . ormlite . UserDao ; \n + @ OrmLiteDao ( helper = DatabaseHelper . class , model = User . class ) \n + UserDao userDao ; \n + \n",Extended @ OrmLiteDao support for enhanced components .,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ helper \ RestAnnotationHelper . java \n + import java . util . HashSet ; \n + import java . util . Set ; \n - public void urlVariableNamesExistInParameters ( ExecutableElement element , List < String > variableNames , IsValid valid ) { \n + public void urlVariableNamesExistInParameters ( ExecutableElement element , Set < String > variableNames , IsValid valid ) { \n - List < String > variableNames = extractUrlVariableNames ( element ) ; \n + Set < String > variableNames = extractUrlVariableNames ( element ) ; \n - \n + \n - List < String > variableNames = extractUrlVariableNames ( element ) ; \n + Set < String > variableNames = extractUrlVariableNames ( element ) ; \n - public List < String > extractUrlVariableNames ( ExecutableElement element ) { \n + public Set < String > extractUrlVariableNames ( ExecutableElement element ) { \n - List < String > variableNames = new ArrayList < String > ( ) ; \n + Set < String > variableNames = new HashSet < String > ( ) ; \n AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ processing \ rest \ MethodProcessor . java \n + import java . util . Set ; \n - import org . androidannotations . processing . EBeanHolder ; \n + import org . androidannotations . processing . EBeanHolder ; \n + \n - List < String > urlVariables = restAnnotationHelper . extractUrlVariableNames ( element ) ; \n + Set < String > urlVariables = restAnnotationHelper . extractUrlVariableNames ( element ) ; \n - body . invoke ( hashMapVar , "" put "" ) . arg ( urlVariable ) . arg ( methodParams . get ( urlVariable ) ) ; \n + JVar urlValue = methodParams . get ( urlVariable ) ; \n + body . invoke ( hashMapVar , "" put "" ) . arg ( urlVariable ) . arg ( urlValue ) ; \n AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ rest \ MyService . java \n + \n + @ Get ( "" / events / { year } / { year } "" ) \n + @ Accept ( MediaType . APPLICATION _ JSON ) \n + Event [ ] [ ] urlWithAParameterDeclaredTwice ( int year ) ; \n + \n",Users can now use an url with a parameter declared twice in annotations related to Rest API,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ model \ ModelExtractor . java \n - Set < DeclaredType > annotationTypesToCheck = buildAnnotationTypes ( ) ; \n + Set < String > annotationTypesToCheck = buildAnnotationTypes ( ) ; \n - private Set < DeclaredType > buildAnnotationTypes ( ) { \n - Set < DeclaredType > annotationTypesToCheck = new HashSet < DeclaredType > ( ) ; \n + private Set < String > buildAnnotationTypes ( ) { \n + Set < String > annotationTypesToCheck = new HashSet < String > ( ) ; \n - annotationTypesToCheck . add ( ( DeclaredType ) typeElement . asType ( ) ) ; \n + annotationTypesToCheck . add ( typeElement . asType ( ) . toString ( ) ) ; \n - private void extractAncestorsAnnotations ( AnnotationElementsHolder extractedModel , Set < DeclaredType > annotationTypesToCheck , Set < TypeElement > rootTypeElements ) { \n + private void extractAncestorsAnnotations ( AnnotationElementsHolder extractedModel , Set < String > annotationTypesToCheck , Set < TypeElement > rootTypeElements ) { \n - private void extractAnnotations ( AnnotationElementsHolder extractedModel , Set < DeclaredType > annotationTypesToCheck , TypeElement rootTypeElement , Element ancestorEnclosedElement ) { \n + private void extractAnnotations ( AnnotationElementsHolder extractedModel , Set < String > annotationTypesToCheck , TypeElement rootTypeElement , Element ancestorEnclosedElement ) { \n - if ( annotationTypesToCheck . contains ( annotationType ) ) { \n - \n + if ( annotationTypesToCheck . contains ( annotationType . toString ( ) ) ) { \n",Use String type to compare DeclaredType into ModelExtractor,327
AndroidAnnotations \ androidannotations - api \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - bundle \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - with - codemodel \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n,Updated artifacts version n order to prepare 2 . 7 . 1 release,327
AndroidAnnotations \ androidannotations - api \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations - bundle \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations - with - codemodel \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ functional - test - 1 - 5 \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ pom . xml \n - < version > 2 . 7 . 1 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n,[ maven - release - plugin ] prepare release androidannotations - 2 . 7 . 1,327
AndroidAnnotations \ androidannotations - api \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - bundle \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - with - codemodel \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n AndroidAnnotations \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 2 . 7 . 1 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,327
AndroidAnnotations \ androidannotations - api \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations - bundle \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations - with - codemodel \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ androidannotations \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ functional - test - 1 - 5 \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n AndroidAnnotations \ pom . xml \n - < version > 3 . 0 - SNAPSHOT < / version > \n + < version > 2 . 7 . 1 < / version > \n,[ maven - release - plugin ] prepare release androidannotations - 2 . 7 . 1,327
AndroidAnnotations \ androidannotations - api \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - bundle \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations - with - codemodel \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ androidannotations \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 - tests \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ functional - test - 1 - 5 \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n AndroidAnnotations \ pom . xml \n - < version > 2 . 7 . 1 < / version > \n + < version > 3 . 0 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,327
examples \ maveneclipse \ pom . xml \n - < androidannotations . version > 2 . 7 < / androidannotations . version > \n + < androidannotations . version > 2 . 7 . 1 < / androidannotations . version > \n,Updated AndroidAnnotations version into maven + eclipse example,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ processing \ rest \ RestProcessor . java \n + import static org . androidannotations . helper . CanonicalNameConstants . CLIENT _ HTTP _ REQUEST _ INTERCEPTOR ; \n + JClass clientInterceptorClass = eBeansHolder . refClass ( CLIENT _ HTTP _ REQUEST _ INTERCEPTOR ) ; \n + listClass = listClass . narrow ( clientInterceptorClass ) ; \n,Added a type parameter to the instanciation of an ArrayList,327
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ processing \ rest \ GetProcessor . java \n + import javax . lang . model . element . ExecutableElement ; \n + import org . androidannotations . helper . CanonicalNameConstants ; \n + import org . androidannotations . processing . EBeanHolder ; \n + \n + import com . sun . codemodel . JBlock ; \n + import com . sun . codemodel . JClass ; \n + import com . sun . codemodel . JExpr ; \n + import com . sun . codemodel . JExpression ; \n + import com . sun . codemodel . JInvocation ; \n + import com . sun . codemodel . JVar ; \n + @ Override \n + protected JVar generateHttpEntityVar ( MethodProcessorHolder methodHolder ) { \n + ExecutableElement executableElement = ( ExecutableElement ) methodHolder . getElement ( ) ; \n + EBeanHolder holder = methodHolder . getHolder ( ) ; \n + JClass httpEntity = holder . refClass ( CanonicalNameConstants . HTTP _ ENTITY ) ; \n + JExpression httpEntityValue ; \n + \n + JBlock body = methodHolder . getBody ( ) ; \n + JVar httpHeadersVar = generateHttpHeadersVar ( holder , body , executableElement ) ; \n + \n + boolean hasHeaders = httpHeadersVar ! = null ; \n + \n + if ( hasHeaders ) { \n + JInvocation newHttpEntityVarCall = JExpr . _ new ( httpEntity . narrow ( Object . class ) ) ; \n + newHttpEntityVarCall . arg ( httpHeadersVar ) ; \n + httpEntityValue = newHttpEntityVarCall ; \n + } else { \n + httpEntityValue = httpEntity . staticRef ( "" EMPTY "" ) ; \n + } \n + \n + JVar httpEntityVar ; \n + String httpEntityVarName = "" requestEntity "" ; \n + httpEntityVar = body . decl ( httpEntity . narrow ( Object . class ) , httpEntityVarName , httpEntityValue ) ; \n + \n + return httpEntityVar ; \n + } \n",Fixed bad use of HttpEntity on Get method generation,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ helper \ ValidatorHelper . java \n + \n + if ( converters = = null ) { \n + valid . invalidate ( ) ; \n + return ; \n + } \n + \n,Fixed NPE when converters are not defined in the @ Rest annotation,327
AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ processing \ rest \ MethodProcessor . java \n + JVar hashMapVar = generateHashMapVar ( methodHolder ) ; \n + \n - JVar hashMapVar = generateHashMapVar ( methodHolder ) ; \n,Do the analyse of path parameter before HttpEntity generation to avoid a path parameter considered as the entity,327
AndroidAnnotations \ pom . xml \n - < version > 2 . 7 < / version > \n + < version > 2 . 9 < / version > \n,Enhanced build time ( ~ 40 sec ) by updating the maven - javadoc - plugin,327
"src \ test \ java \ rx \ internal \ operators \ OperatorMergeDelayErrorTest . java \n - import static org . junit . Assert . assertEquals ; \n - import static org . junit . Assert . assertNotNull ; \n - import static org . junit . Assert . fail ; \n - import static org . mockito . Matchers . any ; \n - import static org . mockito . Matchers . anyInt ; \n - import static org . mockito . Mockito . inOrder ; \n - import static org . mockito . Mockito . mock ; \n - import static org . mockito . Mockito . never ; \n - import static org . mockito . Mockito . times ; \n - import static org . mockito . Mockito . verify ; \n - \n - import java . util . ArrayList ; \n - import java . util . List ; \n - \n - \n + import java . util . ArrayList ; \n + import java . util . List ; \n + import java . util . concurrent . CountDownLatch ; \n + \n + import static org . junit . Assert . * ; \n + import static org . mockito . Matchers . any ; \n + import static org . mockito . Matchers . anyInt ; \n + import static org . mockito . Mockito . * ; \n + \n + @ Test ( timeout = 1000L ) \n + public void testSynchronousError ( ) { \n + final Observable < Observable < String > > o1 = Observable . error ( new RuntimeException ( "" unit test "" ) ) ; \n + \n + final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n + Observable . mergeDelayError ( o1 ) . subscribe ( new Subscriber < String > ( ) { \n + @ Override \n + public void onCompleted ( ) { \n + fail ( "" Expected onError path "" ) ; \n + } \n + \n + @ Override \n + public void onError ( Throwable e ) { \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onNext ( String s ) { \n + fail ( "" Expected onError path "" ) ; \n + } \n + } ) ; \n + \n + try { \n + latch . await ( ) ; \n + } catch ( InterruptedException ex ) { \n + fail ( "" interrupted "" ) ; \n + } \n + } \n + \n + \n",Added a unit test to demonstrate regression in Observable . mergeDelayError,329
"src \ main \ java \ rx \ internal \ operators \ OperatorMerge . java \n - if ( wip = = 0 & & completed ) { \n + if ( ( wip = = 0 & & completed ) | | ( wip < 0 ) ) { \n src \ test \ java \ rx \ internal \ operators \ OperatorMergeDelayErrorTest . java \n - @ Test ( timeout = 1000L ) \n - public void testSynchronousError ( ) { \n - final Observable < Observable < String > > o1 = Observable . error ( new RuntimeException ( "" unit test "" ) ) ; \n - \n - final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n - Observable . mergeDelayError ( o1 ) . subscribe ( new Subscriber < String > ( ) { \n - @ Override \n - public void onCompleted ( ) { \n - fail ( "" Expected onError path "" ) ; \n - } \n - \n - @ Override \n - public void onError ( Throwable e ) { \n - latch . countDown ( ) ; \n - } \n - \n - @ Override \n - public void onNext ( String s ) { \n - fail ( "" Expected onError path "" ) ; \n - } \n - } ) ; \n - \n - try { \n - latch . await ( ) ; \n - } catch ( InterruptedException ex ) { \n - fail ( "" interrupted "" ) ; \n - } \n - } \n - \n - \n + @ Test ( timeout = 1000L ) \n + public void testSynchronousError ( ) { \n + final Observable < Observable < String > > o1 = Observable . error ( new RuntimeException ( "" unit test "" ) ) ; \n + \n + final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n + Observable . mergeDelayError ( o1 ) . subscribe ( new Subscriber < String > ( ) { \n + @ Override \n + public void onCompleted ( ) { \n + fail ( "" Expected onError path "" ) ; \n + } \n + \n + @ Override \n + public void onError ( Throwable e ) { \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onNext ( String s ) { \n + fail ( "" Expected onError path "" ) ; \n + } \n + } ) ; \n + \n + try { \n + latch . await ( ) ; \n + } catch ( InterruptedException ex ) { \n + fail ( "" interrupted "" ) ; \n + } \n + } \n + \n",Fix the failing Observable . mergeDelayError synchronous error unit test,329
hystrix - contrib \ hystrix - clj \ src \ main \ clojure \ com \ netflix \ hystrix \ core . clj \n - ( observe - later - on * [ this scheduler ] ( . toObservable this scheduler ) ) \n + ( observe - later - on * [ this scheduler ] ( . observeOn ( . toObservable this ) scheduler ) ) \n - ( observe - later - on * [ this scheduler ] ( . toObservable this scheduler ) ) ) \n + ( observe - later - on * [ this scheduler ] ( . observeOne ( . toObservable this ) scheduler ) ) ) \n hystrix - contrib \ hystrix - clj \ src \ test \ clojure \ com \ netflix \ hystrix \ core _ test . clj \n - ( - > o . toBlockingObservable . single ) ) \n + ( - > o . toBlocking . single ) ) \n,Fixed Clojure unit tests that faied with RxJava 1 . 0 \n * s / toBlockingObservable / toBlocking \n * Changed implementation of observe - later - on to use Observable . observeOn,329
"settings . gradle \n - ' hystrix - contrib : hystrix - javanica ' , \ \n + / / ' hystrix - contrib : hystrix - javanica ' , \ \n",Temporarily comment out hystrix - javanica module to get master green,329
"hystrix - contrib \ hystrix - rx - netty - metrics - stream \ src \ test \ java \ com \ netflix \ hystrix \ contrib \ rxnetty \ metricsstream \ HystrixMetricsStreamHandlerTest . java \n - Object first = Observable . amb ( objectObservable , Observable . timer ( 1000 , TimeUnit . MILLISECONDS ) ) . toBlockingObservable ( ) . first ( ) ; \n + Object first = Observable . amb ( objectObservable , Observable . timer ( 1000 , TimeUnit . MILLISECONDS ) ) . toBlocking ( ) . first ( ) ; \n - } \n + } \n",s / toBlockingObservable / toBlocking in hystrix - rxnetty - metrics - stream,329
hystrix - contrib \ hystrix - servo - metrics - publisher \ build . gradle \n - compile ' com . netflix . servo : servo - core : 0 . 6 . + ' \n + compile ' com . netflix . servo : servo - core : 0 . 7 . 5 ' \n,Upgrade Servo to 0 . 7 . 5,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommand . java \n - . andCommandKey ( HystrixCommandKey . Factory . asKey ( "" CommandName "" ) ) \n - . andEventNotifier ( notifier ) ; \n + . andCommandKey ( HystrixCommandKey . Factory . asKey ( "" CommandName "" ) ) ; \n",Fixed Javadoc suggesting incorrect addEventNotifier method in HystrixCommand . Setter,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + threadPool . markThreadExecution ( ) ; \n + threadPool . markThreadCompletion ( ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixThreadPoolMetricsTest . java \n - HystrixThreadPoolMetrics . resetAll ( ) ; \n + HystrixThreadPoolMetrics . reset ( ) ; \n,Added back calls to threadPool . markThreadExecution ( ) and . markThreadCompletion ( ) in AbstractCommand,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - executionHook . onRunStart ( _ self ) ; \n + executionHook . onRunStart ( _ self ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onComplete - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n","Switching order on onRunStart , onThreadStart hook execution to match 1 . 3",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - return getFallbackWithProtection ( ) . map ( new Func1 < R , R > ( ) { \n - \n - @ Override \n - public R call ( R t1 ) { \n - System . out . println ( "" > > > > > > > > > > > > fallback on thread : "" + Thread . currentThread ( ) ) ; \n - return executionHook . onComplete ( _ cmd , t1 ) ; \n - } \n - \n - } ) . doOnCompleted ( new Action0 ( ) { \n + return getFallbackWithProtection ( ) . doOnCompleted ( new Action0 ( ) { \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onFallbackStart - onFallbackError - onError - onRunSuccess - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onFallbackStart - onFallbackSuccess - onComplete - onRunSuccess - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onFallbackStart - onFallbackSuccess - onComplete - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n",Removed assertions that executionHook . onRunSuccess gets called in timeout case,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackError - onError - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackError - onError - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackSuccess - onComplete - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackSuccess - onComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackSuccess - onComplete - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackSuccess - onComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackError - onError - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n - assertEquals ( "" onStart - onThreadStart - onRunStart - onRunError - onFallbackStart - onFallbackError - onError - onThreadComplete - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n + assertEquals ( "" onStart - onThreadStart - onRunStart - onThreadComplete - onRunError - onFallbackStart - onFallbackError - onError - "" , command . builder . executionHook . executionSequence . toString ( ) ) ; \n","Switch assertion order of hooks , as onThreadComplete is firing earlier in 1 . 4",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - System . out . println ( "" map "" + t1 ) ; \n + try { \n + Exception decorated = executionHook . onError ( _ self , FailureType . BAD _ REQUEST _ EXCEPTION , ( Exception ) t ) ; \n + \n + if ( decorated instanceof HystrixBadRequestException ) { \n + t = ( HystrixBadRequestException ) decorated ; \n + } else { \n + logger . warn ( "" ExecutionHook . onError returned an exception that was not an instance of HystrixBadRequestException so will be ignored . "" , decorated ) ; \n + } \n + } catch ( Exception hookException ) { \n + logger . warn ( "" Error calling ExecutionHook . onError "" , hookException ) ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ exception \ HystrixRuntimeException . java \n - COMMAND _ EXCEPTION , TIMEOUT , SHORTCIRCUIT , REJECTED _ THREAD _ EXECUTION , REJECTED _ SEMAPHORE _ EXECUTION , REJECTED _ SEMAPHORE _ FALLBACK \n + BAD _ REQUEST _ EXCEPTION , COMMAND _ EXCEPTION , TIMEOUT , SHORTCIRCUIT , REJECTED _ THREAD _ EXECUTION , REJECTED _ SEMAPHORE _ EXECUTION , REJECTED _ SEMAPHORE _ FALLBACK \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - / / we expect a successful response from run ( ) \n + / / we expect no response from run ( ) \n - / / the fallback ( ) method should not be run as we were successful \n + / / the fallback ( ) method should not be run as BadRequestException is handled by immediate propagation \n - / / we should not have an exception since run ( ) succeeded \n - assertNull ( command . builder . executionHook . endExecuteFailureException ) ; \n + / / we should have a HystrixBadRequest exception since run ( ) succeeded \n + assertNotNull ( command . builder . executionHook . endExecuteFailureException ) ; \n",Added ExecutionHook . onError call to HystrixBadRequestException handling,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - public void testExceptionConvertedToBadRequestExceptionInExecutionHookBypassesCircuitBreaker ( ) { \n + public void testExceptionConvertedToBadRequestExceptionInExecutionHookBypassesCircuitBreaker ( ) { \n + @ Test \n + public void testInterruptFutureOnTimeout ( ) throws InterruptedException , ExecutionException { \n + / / given \n + InterruptibleCommand cmd = new InterruptibleCommand ( new TestCircuitBreaker ( ) ) ; \n + \n + / / when \n + Future < Boolean > f = cmd . queue ( ) ; \n + \n + / / then \n + Thread . sleep ( 3000 ) ; \n + System . out . println ( "" RESULT : "" + f . get ( ) ) ; \n + assertTrue ( cmd . hasBeenInterrupted ( ) ) ; \n + } \n + \n + @ Test \n + public void testInterruptObservableOnTimeout ( ) throws InterruptedException { \n + / / given \n + InterruptibleCommand cmd = new InterruptibleCommand ( new TestCircuitBreaker ( ) ) ; \n + \n + / / when \n + cmd . observe ( ) . subscribe ( ) ; \n + \n + / / then \n + Thread . sleep ( 3000 ) ; \n + assertTrue ( cmd . hasBeenInterrupted ( ) ) ; \n + } \n + \n + private static class InterruptibleCommand extends TestHystrixCommand < Boolean > { \n + \n + public InterruptibleCommand ( TestCircuitBreaker circuitBreaker ) { \n + super ( testPropsBuilder ( ) \n + . setCircuitBreaker ( circuitBreaker ) . setMetrics ( circuitBreaker . metrics ) \n + . setCommandPropertiesDefaults ( HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) \n + . withExecutionIsolationThreadInterruptOnTimeout ( true ) \n + . withExecutionIsolationThreadTimeoutInMilliseconds ( 100 ) ) ) ; \n + } \n + \n + private volatile boolean hasBeenInterrupted ; \n + \n + public boolean hasBeenInterrupted ( ) \n + { \n + return hasBeenInterrupted ; \n + } \n + \n + @ Override \n + protected Boolean run ( ) throws Exception \n + { \n + try { \n + Thread . sleep ( 2000 ) ; \n + } \n + catch ( InterruptedException e ) { \n + System . out . println ( "" Interrupted ! "" ) ; \n + e . printStackTrace ( ) ; \n + hasBeenInterrupted = true ; \n + } \n + \n + return hasBeenInterrupted ; \n + } \n + } \n + \n",Failing unit tests for timeouts on HystrixCommands not causing thread interruptions \n Conflicts : \n hystrix - core / src / test / java / com / netflix / hystrix / HystrixCommandTest . java,329
hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - String jsonString = getThreadPoolJson ( threadPoolMetrics ) ; \n - listener . handleJsonMetric ( jsonString ) ; \n + if ( hasExecutedCommandsOnThread ( threadPoolMetrics ) ) { \n + String jsonString = getThreadPoolJson ( threadPoolMetrics ) ; \n + listener . handleJsonMetric ( jsonString ) ; \n + } \n + private boolean hasExecutedCommandsOnThread ( HystrixThreadPoolMetrics threadPoolMetrics ) { \n + return threadPoolMetrics . getCurrentCompletedTaskCount ( ) . intValue ( ) > 0 ; \n + } \n + \n,Filter out thread pools from metrics stream that have had no commands executed on them,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - getExecutionObservable ( ) . unsafeSubscribe ( s ) ; \n + getExecutionObservable ( ) . map ( new Func1 < R , R > ( ) { \n + @ Override \n + public R call ( R r ) { \n + return executionHook . onRunSuccess ( _ self , r ) ; \n + } \n + } ) . unsafeSubscribe ( s ) ; \n - run = getExecutionObservable ( ) ; \n + run = getExecutionObservable ( ) . map ( new Func1 < R , R > ( ) { \n + @ Override \n + public R call ( R r ) { \n + return executionHook . onRunSuccess ( _ self , r ) ; \n + } \n + } ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommand . java \n - final HystrixInvokable < R > _ self = this ; \n - \n - } ) . map ( new Func1 < R , R > ( ) { \n - @ Override \n - public R call ( R r ) { \n - return executionHook . onRunSuccess ( _ self , r ) ; \n - } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixObservableCommand . java \n + import rx . functions . Func1 ; \n",Made execution hook for ' onRunSuccess ' get fired in both HystrixCommand and HystrixObservableCommand cases,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ Hystrix . java \n + currentCommand . set ( new LinkedList < HystrixCommandKey > ( ) ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n + import org . junit . Before ; \n + @ Before \n + public void reset ( ) { \n + Hystrix . reset ( ) ; \n + } \n + \n,Added a reset of Hystrix . currentCommand to Hystrix . reset ( ),329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ executionhook \ HystrixCommandExecutionHook . java \n - * \n + * In a { @ link HystrixCommand } using { @ link ExecutionIsolationStrategy # THREAD } , this will get invoked if the Hystrix thread \n + * successfully runs , regardless of whether the calling thread encountered a timeout . \n + * \n + * This will get invoked if the Hystrix thread successfully executes , regardless of whether the calling thread \n + * encountered a timeout . \n","Added Javadoc after clarifying # 510 . When a Hystrix thread executes , \n onRunSuccess and onThreadCompelte hooks get invoked even if calling thread times out .",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - getFallbackOrThrowException ( HystrixEventType . SEMAPHORE _ REJECTED , FailureType . REJECTED _ SEMAPHORE _ EXECUTION , "" could not acquire a semaphore for execution "" ) . unsafeSubscribe ( observer ) ; \n + getFallbackOrThrowException ( HystrixEventType . SEMAPHORE _ REJECTED , FailureType . REJECTED _ SEMAPHORE _ EXECUTION , "" could not acquire a semaphore for execution "" ) . \n + map ( new Func1 < R , R > ( ) { \n + \n + @ Override \n + public R call ( R t1 ) { \n + / / allow transforming the results via the executionHook if the fallback succeeds \n + return executionHook . onComplete ( _ this , t1 ) ; \n + } \n + \n + } ) . unsafeSubscribe ( observer ) ; \n",Add call to onComplete hook in semaphore rejection path,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - executionHook . onThreadStart ( _ self ) ; \n - executionHook . onRunStart ( _ self ) ; \n + executionHook . onThreadStart ( _ self ) ; \n + executionHook . onRunStart ( _ self ) ; \n,Move onThreadStart execution hook after check that wrapping thread timed out,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 2 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 4 ' \n - \n + \n,Bump RxJava to 1 . 0 . 4,329
build . gradle \n - id ' nebula . netflixoss ' version ' 2 . 2 . 3 ' \n + id ' nebula . netflixoss ' version ' 2 . 2 . 5 ' \n,Bumped nebula . netflixoss from 2 . 2 . 3 to 2 . 2 . 5,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n - @ Test \n + / * @ Test \n - } \n + } * / \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ strategy \ HystrixPluginsTest . java \n - @ Test \n + / * @ Test \n - } \n + } * / \n - @ Test \n + / * @ Test \n - } \n + } * / \n - @ Test \n + / * @ Test \n - } \n + } * / \n - @ Test \n + / * @ Test \n - } \n + } * / \n - @ Test \n + / * @ Test \n - } \n + } * / \n - @ Test \n + / * @ Test \n - } \n + } * / \n,Commenting out the flaky HystrixTest and HystrixPluginsTest until someone has time to de - flake them,329
"hystrix - contrib \ hystrix - codahale - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ codahalemetricspublisher \ HystrixCodaHaleMetricsPublisherCommand . java \n + createCumulativeCountForEvent ( "" countBadRequests "" , HystrixRollingNumberEvent . BAD _ REQUEST ) ; \n + createRollingCountForEvent ( "" rollingCountBadRequests "" , HystrixRollingNumberEvent . BAD _ REQUEST ) ; \n",Add BAD _ REQUEST to CodaHale metrics publisher,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n + json . writeNumberField ( "" rollingCountBadRequests "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . BAD _ REQUEST ) ) ; \n",Add BAD _ REQUEST metrics to metrics - event - stream,329
"hystrix - contrib \ hystrix - rx - netty - metrics - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ rxnetty \ metricsstream \ JsonMappers . java \n + json . writeNumberField ( "" rollingCountBadRequests "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . BAD _ REQUEST ) ) ; \n",Add BAD _ REQUEST to RxNetty metrics stream,329
"hystrix - contrib \ hystrix - yammer - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ yammermetricspublisher \ HystrixYammerMetricsPublisherCommand . java \n + createCumulativeCountForEvent ( "" countBadRequests "" , HystrixRollingNumberEvent . BAD _ REQUEST ) ; \n + createRollingCountForEvent ( "" rollingCountBadRequests "" , HystrixRollingNumberEvent . BAD _ REQUEST ) ; \n",Add BAD _ REQUEST to Yammer metrics publisher,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + @ Test \n + public void testNonBlockingCommandQueueFiresTimeout ( ) { / / see https : / / github . com / Netflix / Hystrix / issues / 514 \n + final TestHystrixCommand < Boolean > cmd = new TestCommandWithTimeout ( 50 , TestCommandWithTimeout . FALLBACK _ SUCCESS ) ; \n + \n + new Thread ( ) { \n + @ Override \n + public void run ( ) { \n + cmd . queue ( ) ; \n + } \n + } . start ( ) ; \n + \n + try { \n + Thread . sleep ( 200 ) ; \n + / / timeout should occur in 50ms , and underlying thread should run for 500ms \n + / / therefore , after 200ms , the command should have finished with a fallback on timeout \n + } catch ( InterruptedException ie ) { \n + throw new RuntimeException ( ie ) ; \n + } \n + \n + assertTrue ( cmd . isExecutionComplete ( ) ) ; \n + assertTrue ( cmd . isResponseTimedOut ( ) ) ; \n + } \n + \n + \n",Add unit test that demonstrates non - blocking timeout for HystrixCommand . queue ( ),329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - for ( HystrixEventType e : events ) { \n - newEvents . add ( e ) ; \n - } \n + Collections . addAll ( newEvents , events ) ; \n",Replace explicit iteration with library support for fast list creation,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCollapserTest . java \n - if ( request . getArgument ( ) = = "" TIMEOUT "" ) { \n + if ( request . getArgument ( ) . equals ( "" TIMEOUT "" ) ) { \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - if ( request . getArgument ( ) = = "" TIMEOUT "" ) { \n + if ( request . getArgument ( ) . equals ( "" TIMEOUT "" ) ) { \n",Fix string comparisons that were using = =,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTimeoutConcurrencyTesting . java \n - final int NUM _ TRIALS = 1000 ; \n + final int NUM _ TRIALS = 10 ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - for ( int i = 0 ; i < 1000 ; i + + ) { \n + for ( int i = 0 ; i < 10 ; i + + ) { \n,"Reduce number of trails of long unit tests , to help CI turnaround time",329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 14 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 17 ' \n,Upgrade to RxJava 1 . 0 . 17,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - for ( int i = 0 ; i < 100 ; i + + ) { \n + for ( int i = 0 ; i < 10 ; i + + ) { \n,Reduce number of trials of observable collapser test,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + metrics . incrementConcurrentExecutionCount ( ) ; \n - / / allow tracking how many concurrent commands are executing \n - metrics . incrementConcurrentExecutionCount ( ) ; \n - \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( 0 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; \n - \n + assertEquals ( 1 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; / / pool - filler still going \n - assertEquals ( 0 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; \n - \n + assertEquals ( 1 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; / / pool - filler still going \n",Move invocation of the increment of concurrent count to the proper spot in the toObservable ( ) flow,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandProperties . java \n - return executionTimeoutInMilliseconds ; \n + / * * \n + * Calling a deprecated method here is a temporary workaround . We do this because { @ link # executionTimeoutInMilliseconds ( ) } is a new method ( as of 1 . 4 . 0 - rc . 7 ) and an extending \n + * class will not have this method . It will have { @ link # executionIsolationThreadTimeoutInMilliseconds ( ) } , however . \n + * So , to stay compatible with an extension , we perform this redirect . \n + * / \n + return executionIsolationThreadTimeoutInMilliseconds ( ) ; \n",Make HystrixCommandProperties backwards - compatible for classes which extend it,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 5 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 7 ' \n,Upgrade to RxJava 1 . 0 . 7,329
hystrix - contrib \ hystrix - javanica \ build . gradle \n - aspectjVersion = ' 1 . 7 . 4 ' \n + aspectjVersion = ' 1 . 8 . 6 ' \n,Upgreade to AspectJ 1 . 8 . 6 to fix Java8 build issue,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - final public Observable < R > observe ( ) { \n + public Observable < R > observe ( ) { \n - final public Observable < R > toObservable ( ) { \n + public Observable < R > toObservable ( ) { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommand . java \n - final public R execute ( ) { \n + public R execute ( ) { \n - final public Future < R > queue ( ) { \n + public Future < R > queue ( ) { \n,Make HystrixCommand . execute ( ) / queue ( ) and AbstractCommand . observe ( ) / toObservable ( ) nonfinal,329
"hystrix - dashboard \ src \ main \ webapp \ monitor \ monitor . html \n + $ ( "" # dependencies . loading "" ) . html ( "" Unable to connect to Command Metric Stream . "" ) ; \n + $ ( "" # dependencies . loading "" ) . addClass ( "" failed "" ) ; \n + $ ( "" # dependencyThreadPools . loading "" ) . html ( "" Unable to connect to Thread Pool Metric Stream . "" ) ; \n + $ ( "" # dependencyThreadPools . loading "" ) . addClass ( "" failed "" ) ; \n",Add error message to HTML when connecting to metrics source fails,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - latch . await ( 5 , TimeUnit . SECONDS ) ; \n + latch . await ( 30 , TimeUnit . SECONDS ) ; \n",Up the time before failure in HystrixCommandTest . testFallbackRejectionOccursWithLatentFallback,329
"hystrix - dashboard \ src \ main \ webapp \ components \ hystrixCommand \ templates \ hystrixCircuit . html \n + < % if ( propertyValue _ executionIsolationStrategy = = ' SEMAPHORE ' ) { % > \n + < a href = "" javascript : / / "" title = "" Semaphore Rejected Request Count "" class = "" line tooltip rejected "" > < % = addCommas ( rollingCountSemaphoreRejected ) % > < / a > \n + < % } % > \n",Add semaphore - rejected metric to commands in Hystrix dashboard,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 4 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 5 ' \n,Upgrade RxJava from 1 . 0 . 4 - > 1 . 0 . 5,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + if ( eventType . equals ( HystrixEventType . FALLBACK _ FAILURE ) | | eventType . equals ( HystrixEventType . FALLBACK _ REJECTION ) | | eventType . equals ( HystrixEventType . FALLBACK _ MISSING ) ) { \n + eventCounts [ HystrixEventType . EXCEPTION _ THROWN . ordinal ( ) ] + + ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandMetrics . java \n - import com . netflix . hystrix . exception . HystrixBadRequestException ; \n - import com . netflix . hystrix . util . HystrixRollingNumber ; \n - private final HystrixEventNotifier eventNotifier ; \n - this . eventNotifier = eventNotifier ; \n,Calculating EXCEPTION _ THROWN count from other HystrixEventTypes,329
"hystrix - dashboard \ src \ main \ webapp \ components \ hystrixCommand \ templates \ hystrixCircuit . html \n + < a href = "" javascript : / / "" title = "" Timed - out Request Count "" class = "" line tooltip timeout "" > < % = addCommas ( rollingCountTimeout ) % > < / a > \n - < a href = "" javascript : / / "" title = "" Timed - out Request Count "" class = "" line tooltip timeout "" > < % = addCommas ( rollingCountTimeout ) % > < / a > \n",Add timed - out metrics to dashboard for semaphore commands,329
hystrix - core \ build . gradle \n + compile ' org . hdrhistogram : HdrHistogram : 2 . 1 . 4 ' \n - \n,Added dependency on HdrHistogram 2 . 1 . 4,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 7 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 9 ' \n,Upgrade RxJava to 1 . 0 . 9,329
hystrix - core \ build . gradle \n + jmhVersion = ' 1 . 9 ' \n + profilers = [ ' gc ' ] \n,Upgrade to jmh 1 . 9 and profile gc as well,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + / * * \n + * Tests that the circuit - breaker reports itself as "" OPEN "" if set as forced - open \n + * / \n + @ Test \n + public void testCircuitBreakerReportsOpenIfForcedOpen ( ) { \n + HystrixCommand < Boolean > cmd = new HystrixCommand < Boolean > ( HystrixCommand . Setter . withGroupKey ( HystrixCommandGroupKey . Factory . asKey ( "" GROUP "" ) ) . andCommandPropertiesDefaults ( new HystrixCommandProperties . Setter ( ) . withCircuitBreakerForceOpen ( true ) ) ) { \n + \n + @ Override \n + protected Boolean run ( ) throws Exception { \n + return true ; \n + } \n + \n + @ Override \n + protected Boolean getFallback ( ) { \n + return false ; \n + } \n + } ; \n + \n + assertFalse ( cmd . execute ( ) ) ; / / fallback should fire \n + System . out . println ( "" RESULT : "" + cmd . getExecutionEvents ( ) ) ; \n + assertTrue ( cmd . isCircuitBreakerOpen ( ) ) ; \n + } \n + \n",Currently - failing unit test demonstrating that HystrixCommand . isCircuitBreakerOpen ( ) does not check if a circuit is forced open,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - * \n + * \n + * 4 columns are ForcedOpen | ForcedClosed | CircuitBreaker open due to health | | | Expected Result \n + * \n + * T | T | T | | | OPEN ( true ) \n + * T | T | F | | | OPEN ( true ) \n + * T | F | T | | | OPEN ( true ) \n + * T | F | F | | | OPEN ( true ) \n + * F | T | T | | | CLOSED ( false ) \n + * F | T | F | | | CLOSED ( false ) \n + * F | F | T | | | OPEN ( true ) \n + * F | F | F | | | CLOSED ( false ) \n + * \n - return circuitBreaker . isOpen ( ) ; \n + return properties . circuitBreakerForceOpen ( ) . get ( ) | | ( ! properties . circuitBreakerForceClosed ( ) . get ( ) & & circuitBreaker . isOpen ( ) ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + / * * \n + * Tests that the circuit - breaker reports itself as "" CLOSED "" if set as forced - closed \n + * / \n + @ Test \n + public void testCircuitBreakerReportsClosedIfForcedClosed ( ) { \n + HystrixCommand < Boolean > cmd = new HystrixCommand < Boolean > ( HystrixCommand . Setter . withGroupKey ( HystrixCommandGroupKey . Factory . asKey ( "" GROUP "" ) ) . andCommandPropertiesDefaults ( \n + new HystrixCommandProperties . Setter ( ) . withCircuitBreakerForceOpen ( false ) . withCircuitBreakerForceClosed ( true ) ) ) { \n + \n + @ Override \n + protected Boolean run ( ) throws Exception { \n + return true ; \n + } \n + \n + @ Override \n + protected Boolean getFallback ( ) { \n + return false ; \n + } \n + } ; \n + \n + assertTrue ( cmd . execute ( ) ) ; \n + System . out . println ( "" RESULT : "" + cmd . getExecutionEvents ( ) ) ; \n + assertFalse ( cmd . isCircuitBreakerOpen ( ) ) ; \n + } \n + \n",Fixed result of AbstractCommand . isCircuitBreakerOpen ( ) in light of forced - open / closed properties,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - json . writeStringField ( "" threadPool "" , commandMetrics . getThreadPoolKey ( ) . name ( ) ) ; \n + json . writeStringField ( "" threadPool "" , commandMetrics . getThreadPoolKey ( ) . name ( ) ) ; \n",Moved new metric to end of JSON for metrics stream,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandGroupKey . java \n + \n + / * package - private * / static int getGroupCount ( ) { \n + return intern . size ( ) ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandKey . java \n + \n + / * package - private * / static int getCommandCount ( ) { \n + return intern . size ( ) ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCounters . java \n + / * * \n + * Class with global statistics on Hystrix runtime behavior . \n + * All of the data available via this class is static and scoped at the JVM level \n + * / \n + / * * \n + * Return the number of currently - executing Hystrix threads \n + * @ return number of currently - executing Hystrix threads \n + * / \n + \n + / * * \n + * Return the number of unique { @ link HystrixCommand } s that have been registered \n + * @ return number of unique { @ link HystrixCommand } s that have been registered \n + * / \n + public static int getCommandCount ( ) { \n + return HystrixCommandKey . Factory . getCommandCount ( ) ; \n + } \n + \n + / * * \n + * Return the number of unique { @ link HystrixThreadPool } s that have been registered \n + * @ return number of unique { @ link HystrixThreadPool } s that have been registered \n + * / \n + public static int getThreadPoolCount ( ) { \n + return HystrixThreadPoolKey . Factory . getThreadPoolCount ( ) ; \n + } \n + \n + / * * \n + * Return the number of unique { @ link HystrixCommandGroupKey } s that have been registered \n + * @ return number of unique { @ link HystrixCommandGroupKey } s that have been registered \n + * / \n + public static int getGroupCount ( ) { \n + return HystrixCommandGroupKey . Factory . getGroupCount ( ) ; \n + } \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolKey . java \n + \n + / * package - private * / static int getThreadPoolCount ( ) { \n + return intern . size ( ) ; \n + } \n,Add HystrixCounters methods to return number of commands / threadpools / groups,329
hystrix - core \ build . gradle \n - fork = 1 \n - iterations = 25 \n + fork = 10 \n + iterations = 3 \n,Use more forks and less iterations / fork in JMH config,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - } catch ( Exception hookException ) { \n - logger . warn ( "" Error calling ExecutionHook . onError "" , hookException ) ; \n + } catch ( Exception hookEx ) { \n + logger . warn ( "" Error calling ExecutionHook . onError "" , hookEx ) ; \n","Revert "" Handle hook failures more gracefully "" \n This reverts commit 60c9297f61a3386007b3556e38dcba6dec9513b9 .",329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - for ( int i = 0 ; i < 1000 ; i + + ) { \n + for ( int i = 0 ; i < 100 ; i + + ) { \n,Shorten stress test of HystrixObservableCollapser from 1000 - > 100 to limit OOM problems,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 9 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 10 ' \n,Upgrade RxJava to 1 . 0 . 10,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixRollingPercentile . java \n + import org . HdrHistogram . Histogram ; \n + final AtomicReference < Histogram > stableHistogram = new AtomicReference < Histogram > ( null ) ; \n - private final IntCountsHistogram aggregateHistogram ; \n + / * package - private * / final IntCountsHistogram aggregateHistogram ; \n - aggregateHistogram . add ( bucket . bucketData . recorder . getIntervalHistogram ( ) ) ; \n + PercentileBucketData bucketData = bucket . bucketData ; \n + / / if stable snapshot not already generated , generate it now \n + bucketData . stableHistogram . compareAndSet ( null , bucketData . recorder . getIntervalHistogram ( ) ) ; \n + aggregateHistogram . add ( bucket . bucketData . stableHistogram . get ( ) ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ util \ HystrixRollingPercentileTest . java \n + \n + int maxSoFar = - 1 ; \n + \n + if ( latency > maxSoFar ) { \n + System . out . println ( "" New MAX latency : "" + latency ) ; \n + maxSoFar = latency ; \n + } \n + System . out . println ( "" MAX : "" + p . currentPercentileSnapshot . aggregateHistogram . getMaxValue ( ) ) ; \n + \n + System . out . println ( "" MAX : "" + p . currentPercentileSnapshot . aggregateHistogram . getMaxValue ( ) ) ; \n + \n",Fix to only get an interval histogram once per recorder,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPool . java \n - * If a SynchronousQueue implementation is used ( < code > maxQueueSize < / code > = = - 1 ) , it always returns 0 as the size so this would always return true . \n + * If a SynchronousQueue implementation is used ( < code > maxQueueSize < / code > < = 0 ) , it always returns 0 as the size so this would always return true . \n - if ( properties . maxQueueSize ( ) . get ( ) < 0 ) { \n + if ( properties . maxQueueSize ( ) . get ( ) < = 0 ) { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ concurrency \ HystrixContextScheduler . java \n - System . out . println ( "" delayed scheduling "" ) ; \n",Fixed HystrixThreadPool to always return true for isQueueSpaceAvailable ( ) when size = 0 ( the SynchronousQueue case ),329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - final AtomicReference < Action0 > endCurrentThreadExecutingCommand = new AtomicReference < Action0 > ( ) ; / / don ' t like how this is being done \n - / / store the command that is being run \n - endCurrentThreadExecutingCommand . set ( Hystrix . startCurrentThreadExecutingCommand ( getCommandKey ( ) ) ) ; \n + \n - \n - / / pop the command that is being run \n - if ( endCurrentThreadExecutingCommand . get ( ) ! = null ) { \n - endCurrentThreadExecutingCommand . get ( ) . call ( ) ; \n - } \n + final AtomicReference < Action0 > endCurrentThreadExecutingCommand = new AtomicReference < Action0 > ( ) ; / / don ' t like how this is being done \n - final Action0 endCurrentThread = Hystrix . startCurrentThreadExecutingCommand ( getCommandKey ( ) ) ; \n + / / store the command that is being run \n + endCurrentThreadExecutingCommand . set ( Hystrix . startCurrentThreadExecutingCommand ( getCommandKey ( ) ) ) ; \n - endCurrentThread . call ( ) ; \n + / / store the command that is being run \n + endCurrentThreadExecutingCommand . set ( Hystrix . startCurrentThreadExecutingCommand ( getCommandKey ( ) ) ) ; \n + } ) . doOnTerminate ( new Action0 ( ) { \n + @ Override \n + public void call ( ) { \n + / / pop the command that is being run \n + if ( endCurrentThreadExecutingCommand . get ( ) ! = null ) { \n + endCurrentThreadExecutingCommand . get ( ) . call ( ) ; \n + } \n + } \n,Only call the Hystrix . startCurrentThreadExecutingCommand / endCurrentThreadExecutingCommand \n sequence once per command invocation,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertTrue ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertTrue ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n + \n + assertFalse ( command . isResponseFromFallback ( ) ) ; \n,Added more comprehensive tests for HystrixObservableCommand . isResponseFromFallback ( ),329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ Hystrix . java \n + import com . netflix . hystrix . strategy . HystrixPlugins ; \n + HystrixPlugins . reset ( ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ HystrixPlugins . java \n + / * * \n + * Reset all of the HystrixPlugins to null . You may invoke this directly , or it also gets invoked via < code > Hystrix . reset ( ) < / code > \n + * / \n + public static void reset ( ) { \n + getInstance ( ) . notifier . set ( null ) ; \n + getInstance ( ) . concurrencyStrategy . set ( null ) ; \n + getInstance ( ) . metricsPublisher . set ( null ) ; \n + getInstance ( ) . propertiesFactory . set ( null ) ; \n + getInstance ( ) . commandExecutionHook . set ( null ) ; \n + } \n + \n + \n",Add the capability to reset HystrixPlugins and make Hystrix . reset ( ) invoke it,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n + / / see https : / / github . com / Netflix / Hystrix / issues / 280 \n + @ Test \n + public void testResetCommandProperties ( ) { \n + HystrixCommand < Boolean > cmd1 = new ResettableCommand ( 100 , 10 ) ; \n + assertEquals ( 100L , ( long ) cmd1 . getProperties ( ) . executionIsolationThreadTimeoutInMilliseconds ( ) . get ( ) ) ; \n + assertEquals ( 10L , ( long ) cmd1 . threadPool . getExecutor ( ) . getCorePoolSize ( ) ) ; \n + \n + Hystrix . reset ( ) ; \n + \n + HystrixCommand < Boolean > cmd2 = new ResettableCommand ( 700 , 40 ) ; \n + assertEquals ( 700L , ( long ) cmd2 . getProperties ( ) . executionIsolationThreadTimeoutInMilliseconds ( ) . get ( ) ) ; \n + assertEquals ( 40L , ( long ) cmd2 . threadPool . getExecutor ( ) . getCorePoolSize ( ) ) ; \n + \n + } \n + \n + private static class ResettableCommand extends HystrixCommand < Boolean > { \n + ResettableCommand ( int timeout , int poolCoreSize ) { \n + super ( Setter . withGroupKey ( HystrixCommandGroupKey . Factory . asKey ( "" GROUP "" ) ) \n + . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationThreadTimeoutInMilliseconds ( timeout ) ) \n + . andThreadPoolPropertiesDefaults ( HystrixThreadPoolProperties . Setter ( ) . withCoreSize ( poolCoreSize ) ) ) ; \n + } \n + \n + @ Override \n + protected Boolean run ( ) throws Exception { \n + return true ; \n + } \n + } \n",Unit test which demonstrates Hystrix . reset ( ) not resetting command / thread pool defaults,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ Hystrix . java \n + import com . netflix . hystrix . strategy . properties . HystrixPropertiesFactory ; \n + HystrixPropertiesFactory . reset ( ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ properties \ HystrixPropertiesFactory . java \n + / * * \n + * Clears all the defaults in the static property cache . This makes it possible for property defaults to not persist for \n + * an entire JVM lifetime . May be invoked directly , and also gets invoked by < code > Hystrix . reset ( ) < / code > \n + * / \n + public static void reset ( ) { \n + commandProperties . clear ( ) ; \n + threadPoolProperties . clear ( ) ; \n + } \n + \n",Added HystrixPropertiesFactory . reset ( ) method to allow command and thread - pool \n property defaults to be reset ( ) . Hystrix . reset ( ) calls this method as well,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - } else if ( t instanceof VirtualMachineError ) { \n + } else if ( cause instanceof VirtualMachineError ) { \n - } else if ( t instanceof ThreadDeath ) { \n + } else if ( cause instanceof ThreadDeath ) { \n - } else if ( t instanceof LinkageError ) { \n + } else if ( cause instanceof LinkageError ) { \n,Properly check for all unrecoverable types of errors,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandProperties . java \n + * \n + * @ deprecated As of release 1 . 4 . 0 , replaced by { @ link # executionTimeoutInMilliseconds ( ) } . Timeout is no longer specific to thread - isolation commands , so the thread - specific name is misleading . \n + * \n",Add @ deprecated Javadoc to getExecutionIsolationThreadTimeoutInMilliseconds ( ),329
. travis . yml \n + sudo : false \n - oraclejdk7 \n,Added Travis config so it can run in a container,329
hystrix - contrib \ hystrix - servo - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ servopublisher \ HystrixServoMetricsPublisherCommand . java \n - return new CounterMetric ( MonitorConfig . builder ( name ) . withTag ( getServoTypeTag ( ) ) . withTag ( getServoInstanceTag ( ) ) . build ( ) ) { \n + return new GaugeMetric ( MonitorConfig . builder ( name ) . withTag ( DataSourceLevel . DEBUG ) . withTag ( getServoTypeTag ( ) ) . withTag ( getServoInstanceTag ( ) ) . build ( ) ) { \n,Add DEBUG tag to Servo rolling counter and made it a GaugeMetric,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 13 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 14 ' \n,Upgrade to RxJava 1 . 0 . 14,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPool . java \n + private final int queueSize ; \n - this . queue = concurrencyStrategy . getBlockingQueue ( properties . maxQueueSize ( ) . get ( ) ) ; \n + this . queueSize = properties . maxQueueSize ( ) . get ( ) ; \n + this . queue = concurrencyStrategy . getBlockingQueue ( queueSize ) ; \n + * \n + * Note that the < code > queueSize < / code > is an final instance variable on HystrixThreadPoolDefault , and not looked up dynamically . \n + * The data structure is static , so this does not make sense as a dynamic lookup . \n + * The < code > queueSizeRejectionThreshold < / code > can be dynamic ( up to < code > queueSize < / code > ) , so that should \n + * still get checked on each invocation . \n - if ( properties . maxQueueSize ( ) . get ( ) < = 0 ) { \n + if ( queueSize < = 0 ) { \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolProperties . java \n + * \n + * This should only affect the instantiation of a threadpool - it is not eliglible to change a queue size on the fly . \n + * For that , use { @ link # queueSizeRejectionThreshold ( ) } . \n",Modify logic to only check the dynamic maxQueueSize property on creation of a threadPool,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsStreamServlet . java \n - delay = Integer . parseInt ( d ) ; \n + delay = Math . max ( Integer . parseInt ( d ) , 1 ) ; \n",Safely handle negative input on the delay input to metrics - stream,329
hystrix - core \ build . gradle \n - jmhVersion = ' 1 . 9 . 3 ' \n - / / profilers = [ ' gc ' ] \n + jmhVersion = ' 1 . 10 . 3 ' \n + profilers = [ ' gc ' ] \n,Updated jmh config to version 1 . 10 . 3 and to include GC measurements,329
"hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 17 ' \n + compile ' io . reactivex : rxjava : 1 . 1 . 0 ' \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ collapser \ CollapsedRequestObservableFunction . java \n - import rx . subjects . Subject ; \n - private final Subject < T , T > responseSubject = PublishSubject . create ( ) ; \n + private final PublishSubject < T > responseSubject = PublishSubject . create ( ) ; \n",Upgrade to RxJava 1 . 1 . 0,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 12 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 13 ' \n,Upgrade to RxJava 1 . 0 . 13,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n + import org . junit . Test ; \n + \n + import static org . junit . Assert . assertEquals ; \n + import static org . junit . Assert . assertNull ; \n + import static org . junit . Assert . assertTrue ; \n - / * @ Test \n + @ Test \n - . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n + . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n - . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n + . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n - . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n + . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionIsolationStrategy ( HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ) { \n - HystrixCommand < Boolean > cmd1 = new ResettableCommand ( 100 , 10 ) ; \n - assertEquals ( 100L , ( long ) cmd1 . getProperties ( ) . executionIsolationThreadTimeoutInMilliseconds ( ) . get ( ) ) ; \n + HystrixCommand < Boolean > cmd1 = new ResettableCommand ( 100 , 1 , 10 ) ; \n + assertEquals ( 100L , ( long ) cmd1 . getProperties ( ) . executionTimeoutInMilliseconds ( ) . get ( ) ) ; \n + assertEquals ( 1L , ( long ) cmd1 . getProperties ( ) . executionIsolationSemaphoreMaxConcurrentRequests ( ) . get ( ) ) ; \n - HystrixCommand < Boolean > cmd2 = new ResettableCommand ( 700 , 40 ) ; \n - assertEquals ( 700L , ( long ) cmd2 . getProperties ( ) . executionIsolationThreadTimeoutInMilliseconds ( ) . get ( ) ) ; \n + HystrixCommand < Boolean > cmd2 = new ResettableCommand ( 700 , 2 , 40 ) ; \n + assertEquals ( 700L , ( long ) cmd2 . getProperties ( ) . executionTimeoutInMilliseconds ( ) . get ( ) ) ; \n + assertEquals ( 2L , ( long ) cmd2 . getProperties ( ) . executionIsolationSemaphoreMaxConcurrentRequests ( ) . get ( ) ) ; \n - \n - } * / \n + } \n - ResettableCommand ( int timeout , int poolCoreSize ) { \n + ResettableCommand ( int timeout , int semaphoreCount , int poolCoreSize ) { \n - . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) . withExecutionTimeoutInMilliseconds ( timeout ) ) \n + . andCommandPropertiesDefaults ( HystrixCommandProperties . Setter ( ) \n + . withExecutionTimeoutInMilliseconds ( timeout ) \n + . withExecutionIsolationSemaphoreMaxConcurrentRequests ( semaphoreCount ) ) \n",Reinstated HystrixTest and added unit test for modifying semaphore count,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - scheduledTask = executor . scheduleWithFixedDelay ( new MetricsPoller ( listener ) , 0 , delay , TimeUnit . MILLISECONDS ) ; \n + try { \n + scheduledTask = executor . scheduleWithFixedDelay ( new MetricsPoller ( listener ) , 0 , delay , TimeUnit . MILLISECONDS ) ; \n + } catch ( Throwable ex ) { \n + logger . error ( "" Exception while creating the MetricsPoller task "" ) ; \n + ex . printStackTrace ( ) ; \n + running . set ( false ) ; \n + } \n - logger . info ( "" Stopping the Servo Metrics Poller "" ) ; \n + logger . info ( "" Stopping the HystrixMetricsPoller "" ) ; \n + } else { \n + logger . debug ( "" Attempted to pause a stopped poller "" ) ; \n",Handle an error during construction of a MetricsPoller more gracefully,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCircuitBreaker . java \n - / / How could previousValue be true ? If another thread was going through this code at the same time a race - condition could have \n - / / caused another thread to set it to true already even though we were in the process of doing the same \n - return false ; \n + / / How could previousValue be true ? If another thread was going through this code at the same time a race - condition could have \n + / / caused another thread to set it to true already even though we were in the process of doing the same \n + / / In this case , we know the circuit is open , so let the other thread set the currentTime and report back that the circuit is open \n + return true ; \n",Fix return value of HystrixCircuitBreakerImpl . isOpen when we lose the race to open a circuit,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ concurrency \ HystrixConcurrencyStrategy . java \n + * When you implement a concrete { @ link HystrixConcurrencyStrategy } , you should make the strategy idempotent w . r . t ThreadLocals . \n + * Since the usage of threads by Hystrix is internal , Hystrix does not attempt to apply the strategy in an idempotent way . \n + * Instead , you should write your strategy to work idempotently . See https : / / github . com / Netflix / Hystrix / issues / 351 for a more detailed discussion . \n + * < p > \n",Added comment to HystrixConcurrencyStrategy about non - idempotency of strategy application,329
"hystrix - core \ src \ jmh \ java \ com \ netflix \ hystrix \ perf \ ObservableCollapserPerfTest . java \n - @ Param ( { "" 1 "" } ) / / until bugfix for https : / / github . com / Netflix / Hystrix / issues / 865 , 1 is only value that works as expected \n + @ Param ( { "" 1 "" , "" 10 "" , "" 100 "" } ) \n",Modify ObservableCollapser JMH test to allow multiple response per argument,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - \n + final boolean requestCacheEnabled = isRequestCachingEnabled ( ) ; \n + \n - if ( isRequestCachingEnabled ( ) ) { \n + if ( requestCacheEnabled ) { \n - if ( isRequestCachingEnabled ( ) ) { \n + if ( requestCacheEnabled ) { \n,Only lookup if the request cache is enabled once per command invocation \n * This helps performance and eliminates chance that start / end of command see this value differently,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCollapser . java \n + final boolean isRequestCacheEnabled = getProperties ( ) . requestCacheEnabled ( ) . get ( ) ; \n + \n - if ( getProperties ( ) . requestCacheEnabled ( ) . get ( ) ) { \n + if ( isRequestCacheEnabled ) { \n - if ( getProperties ( ) . requestCacheEnabled ( ) . get ( ) ) { \n + if ( isRequestCacheEnabled ) { \n,"In HystrixCollapser , only check if request cache is enabled once",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + executionResult = executionResult . addEvents ( HystrixEventType . RESPONSE _ FROM _ CACHE ) ; \n + metrics . markCommandCompletion ( this , executionResult ) ; \n",Track execution result of RESPONSE _ FROM _ CACHE,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTestWithCustomConcurrencyStrategy . java \n + HystrixPlugins . reset ( ) ; \n,Added call to HystrixPlugins . reset ( ) in HystrixCommandTestWithCustomConcurrencyStrategy,329
build . gradle \n - classpath ' com . netflix . nebula : gradle - extra - configurations - plugin : 2 . 0 . 1 ' \n + classpath ' com . netflix . nebula : gradle - extra - configurations - plugin : 3 . 0 . 3 ' \n,Upgrade gradle - extra - configurations - plugin,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolMetrics . java \n - import rx . subjects . Subject ; \n - private final Subject < long [ ] , long [ ] > cumulativeCounter = BehaviorSubject . create ( new long [ 2 ] ) ; \n + private final BehaviorSubject < long [ ] > cumulativeCounter = BehaviorSubject . create ( new long [ 2 ] ) ; \n - private final Subject < long [ ] , long [ ] > rollingCounter = BehaviorSubject . create ( new long [ 2 ] ) ; \n + private final BehaviorSubject < long [ ] > rollingCounter = BehaviorSubject . create ( new long [ 2 ] ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ CumulativeCommandEventCounterStream . java \n - import rx . subjects . Subject ; \n - private final Subject < long [ ] , long [ ] > cumulativeCounter = BehaviorSubject . create ( new long [ HystrixEventType . values ( ) . length ] ) ; \n + private final BehaviorSubject < long [ ] > cumulativeCounter = BehaviorSubject . create ( new long [ HystrixEventType . values ( ) . length ] ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HealthCountsStream . java \n - import rx . subjects . Subject ; \n - private final Subject < HystrixCommandMetrics . HealthCounts , HystrixCommandMetrics . HealthCounts > healthCountsSubject = \n + private final BehaviorSubject < HystrixCommandMetrics . HealthCounts > healthCountsSubject = \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ RollingCommandConcurrencyStream . java \n - import rx . subjects . Subject ; \n - private final Subject < Integer , Integer > rollingMax = BehaviorSubject . create ( 0 ) ; \n + private final BehaviorSubject < Integer > rollingMax = BehaviorSubject . create ( 0 ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ RollingCommandEventCounterStream . java \n - import rx . subjects . Subject ; \n - private final Subject < long [ ] , long [ ] > rollingCounter = BehaviorSubject . create ( new long [ HystrixEventType . values ( ) . length ] ) ; \n + private final BehaviorSubject < long [ ] > rollingCounter = BehaviorSubject . create ( new long [ HystrixEventType . values ( ) . length ] ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ RollingCommandLatencyStream . java \n - import com . netflix . hystrix . HystrixEventType ; \n - import rx . subjects . Subject ; \n - private final Subject < HystrixLatencyDistribution , HystrixLatencyDistribution > rollingLatencyDistribution = \n + private final BehaviorSubject < HystrixLatencyDistribution > rollingLatencyDistribution = \n",Upgrade to RxJava 1 . 1 . 0,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - System . out . println ( "" Starting to observe collapser1 "" ) ; \n - Observable < String > result1 = collapser1 . observe ( ) ; \n - Observable < String > result2 = collapser2 . observe ( ) ; \n - System . out . println ( "" Done with collapser observe ( ) s "" ) ; \n - \n - / / timer . incrementTime ( 10 ) ; / / let time pass that equals the default delay / period \n - Thread . sleep ( 10 ) ; \n - \n - result1 . subscribe ( testSubscriber1 ) ; \n - \n - result2 . subscribe ( testSubscriber2 ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" Starting to observe collapser1 "" ) ; \n + collapser1 . observe ( ) . subscribe ( testSubscriber1 ) ; \n + collapser2 . observe ( ) . subscribe ( testSubscriber2 ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" Done with collapser observe ( ) s "" ) ; \n + \n + / / Note that removing these awaits breaks the unit test . That implies that the above subscribe does not wait for a terminal event \n",Moving the subscribe ( ) to before the await in HystrixObservableCollapserTest,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + import java . util . ArrayList ; \n + @ Test \n + public void testCommandConcurrencyExceedsQueueSizeButNotThreadPoolSize ( ) { \n + List < Observable < Boolean > > cmdResults = new ArrayList < Observable < Boolean > > ( ) ; \n + \n + HystrixThreadPool threadPool = null ; \n + \n + / / thread pool size is 20 , so we have room for concurrent execution of all 20 commands \n + / / but queue size is 2 - do we see any queue rejections ? - we should not \n + for ( int i = 0 ; i < 20 ; i + + ) { \n + HystrixCommand < Boolean > cmd = new CommandWithLargeThreadPoolSmallQueue ( ) ; \n + if ( threadPool = = null ) { \n + threadPool = cmd . threadPool ; \n + } \n + cmdResults . add ( cmd . toObservable ( ) ) ; \n + } \n + \n + Observable < Boolean > allObservables = Observable . merge ( cmdResults ) ; \n + \n + TestSubscriber < Boolean > subscriber = new TestSubscriber < Boolean > ( ) ; \n + \n + allObservables . subscribe ( subscriber ) ; \n + \n + subscriber . awaitTerminalEvent ( 1 , TimeUnit . SECONDS ) ; \n + if ( subscriber . getOnErrorEvents ( ) . size ( ) > 0 ) { \n + subscriber . getOnErrorEvents ( ) . get ( 0 ) . printStackTrace ( ) ; \n + } \n + \n + subscriber . assertCompleted ( ) ; \n + subscriber . assertNoErrors ( ) ; \n + subscriber . assertValueCount ( 20 ) ; \n + } \n + \n + @ Test \n + public void stressTestLargeThreadPoolSmallQueue ( ) { \n + for ( int n = 0 ; n < 20 ; n + + ) { \n + testCommandConcurrencyExceedsQueueSizeButNotThreadPoolSize ( ) ; \n + Hystrix . reset ( ) ; \n + } \n + } \n + \n + \n + private static class CommandWithLargeThreadPoolSmallQueue extends TestHystrixCommand < Boolean > { \n + \n + public CommandWithLargeThreadPoolSmallQueue ( ) { \n + super ( testPropsBuilder ( ) . setThreadPoolPropertiesDefaults ( HystrixThreadPoolProperties . Setter ( ) . withMaxQueueSize ( 2 ) . withCoreSize ( 20 ) ) ) ; \n + } \n + \n + @ Override \n + protected Boolean run ( ) throws Exception { \n + return true ; \n + } \n + } \n",Added unit test to see what happens when a large pool with a small queue sees high concurrency,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - public void testCommandConcurrencyExceedsQueueSizeButNotThreadPoolSize ( ) { \n + public void testCommandConcurrencyViaObserveExceedsQueueSizeButNotThreadPoolSize ( ) { \n - public void stressTestLargeThreadPoolSmallQueue ( ) { \n + public void stressTestLargeThreadPoolSmallQueueUsingObserve ( ) { \n - testCommandConcurrencyExceedsQueueSizeButNotThreadPoolSize ( ) ; \n + testCommandConcurrencyViaObserveExceedsQueueSizeButNotThreadPoolSize ( ) ; \n + Hystrix . reset ( ) ; \n + } \n + } \n + \n + @ Test \n + public void testCommandConcurrencyViaQueueExceedsQueueSizeButNotThreadPoolSize ( ) throws Exception { \n + List < Future < Boolean > > cmdResults = new ArrayList < Future < Boolean > > ( ) ; \n + \n + HystrixThreadPool threadPool = null ; \n + \n + / / thread pool size is 20 , so we have room for concurrent execution of all 20 commands \n + / / but queue size is 2 - do we see any queue rejections ? - we should not \n + for ( int i = 0 ; i < 20 ; i + + ) { \n + HystrixCommand < Boolean > cmd = new CommandWithLargeThreadPoolSmallQueue ( ) ; \n + if ( threadPool = = null ) { \n + threadPool = cmd . threadPool ; \n + } \n + cmdResults . add ( cmd . queue ( ) ) ; \n + } \n + \n + for ( Future < Boolean > f : cmdResults ) { \n + f . get ( 1 , TimeUnit . SECONDS ) ; \n + } \n + } \n + \n + @ Test \n + public void stressTestLargeThreadPoolSmallQueueUsingQueue ( ) throws Exception { \n + for ( int n = 0 ; n < 20 ; n + + ) { \n + testCommandConcurrencyViaQueueExceedsQueueSizeButNotThreadPoolSize ( ) ; \n - super ( testPropsBuilder ( ) . setThreadPoolPropertiesDefaults ( HystrixThreadPoolProperties . Setter ( ) . withMaxQueueSize ( 2 ) . withCoreSize ( 20 ) ) ) ; \n + super ( testPropsBuilder ( ) . setThreadPoolPropertiesDefaults ( \n + HystrixThreadPoolProperties . Setter ( ) . withMaxQueueSize ( 2 ) . withQueueSizeRejectionThreshold ( 2 ) . withCoreSize ( 20 ) ) ) ; \n",Added the queue ( ) case to large threadpool / small queue testcase,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixObservableCollapser . java \n + final boolean isRequestCacheEnabled = getProperties ( ) . requestCacheEnabled ( ) . get ( ) ; \n + \n - if ( getProperties ( ) . requestCacheEnabled ( ) . get ( ) ) { \n + if ( isRequestCacheEnabled ) { \n - if ( getProperties ( ) . requestCacheEnabled ( ) . get ( ) ) { \n + if ( isRequestCacheEnabled ) { \n,Only check the property value of isRequestCacheEnabled ( ) once in HystrixObservableCollapser,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - * @ param MetricsAsJsonPollerListener \n - * for callbacks \n + * @ param listener for callbacks \n + json . writeNumberField ( "" rollingMaxConcurrentExecutionCount "" , commandMetrics . getRollingMaxConcurrentExecutions ( ) ) ; \n hystrix - contrib \ hystrix - rx - netty - metrics - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ rxnetty \ metricsstream \ JsonMappers . java \n + json . writeNumberField ( "" rollingMaxConcurrentExecutionCount "" , commandMetrics . getRollingMaxConcurrentExecutions ( ) ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - / / allow tracking how many concurrent threads are executing \n + / / allow tracking how many concurrent commands are executing \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandMetrics . java \n - * \n - * @ param numberOfPermitsUsed \n - concurrentExecutionCount . incrementAndGet ( ) ; \n + int numConcurrent = concurrentExecutionCount . incrementAndGet ( ) ; \n + counter . updateRollingMax ( HystrixRollingNumberEvent . COMMAND _ MAX _ ACTIVE , ( long ) numConcurrent ) ; \n - * Increment concurrent requests counter . \n - * \n - * @ param numberOfPermitsUsed \n + * Decrement concurrent requests counter . \n + public long getRollingMaxConcurrentExecutions ( ) { \n + return counter . getRollingMaxValue ( HystrixRollingNumberEvent . COMMAND _ MAX _ ACTIVE ) ; \n + } \n + \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixRollingNumberEvent . java \n - FALLBACK _ SUCCESS ( 1 ) , FALLBACK _ FAILURE ( 1 ) , FALLBACK _ REJECTION ( 1 ) , EXCEPTION _ THROWN ( 1 ) , \n + FALLBACK _ SUCCESS ( 1 ) , FALLBACK _ FAILURE ( 1 ) , FALLBACK _ REJECTION ( 1 ) , EXCEPTION _ THROWN ( 1 ) , COMMAND _ MAX _ ACTIVE ( 2 ) , \n",Added a rolling max counter for command execution,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - testObserveFailureWithTimeoutAndFallback ( ExecutionIsolationStrategy . SEMAPHORE , TestCommandWithTimeout . RESULT _ SUCCESS ) ; \n + testObserveFailureWithTimeoutAndFallback ( ExecutionIsolationStrategy . THREAD , TestCommandWithTimeout . RESULT _ SUCCESS ) ; \n - testObserveFailureWithTimeoutAndFallback ( ExecutionIsolationStrategy . SEMAPHORE , TestCommandWithTimeout . RESULT _ EXCEPTION ) ; \n + testObserveFailureWithTimeoutAndFallback ( ExecutionIsolationStrategy . THREAD , TestCommandWithTimeout . RESULT _ EXCEPTION ) ; \n - TestHystrixCommand < Boolean > command = new TestCommandWithTimeout ( 2000 , TestCommandWithTimeout . FALLBACK _ SUCCESS , isolationStrategy , executionResult , true ) ; \n + TestHystrixCommand < Boolean > command = new TestCommandWithTimeout ( 200 , TestCommandWithTimeout . FALLBACK _ SUCCESS , isolationStrategy , executionResult , true ) ; \n + long observedCommandDuration = 0 ; \n + long startTime = System . currentTimeMillis ( ) ; \n + observedCommandDuration = System . currentTimeMillis ( ) - startTime ; \n - assertTrue ( command . getExecutionTimeInMilliseconds ( ) > - 1 ) ; \n + System . out . println ( "" Command time : "" + command . getExecutionTimeInMilliseconds ( ) ) ; \n + System . out . println ( "" Observed command time : "" + observedCommandDuration ) ; \n + assertTrue ( command . getExecutionTimeInMilliseconds ( ) > 200 ) ; \n + assertTrue ( observedCommandDuration > 200 ) ; \n + assertTrue ( command . getExecutionTimeInMilliseconds ( ) < 1000 ) ; \n + assertTrue ( observedCommandDuration < 1000 ) ; \n - Thread . sleep ( timeout * 10 ) ; \n + for ( int i = 0 ; i < ( timeout * 5 ) ; i + + ) { \n + if ( ! sub . isUnsubscribed ( ) ) { \n + Thread . sleep ( 1 ) ; \n + } \n + } \n",Added unit tests to demonstrate a non - blocking semaphore timeout,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - assertTrue ( command . getExecutionTimeInMilliseconds ( ) > 200 ) ; \n - assertTrue ( observedCommandDuration > 200 ) ; \n + assertTrue ( command . getExecutionTimeInMilliseconds ( ) > = 200 ) ; \n + assertTrue ( observedCommandDuration > = 200 ) ; \n,Fixing test assertions for fast ( ! ) Cloudbees,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + if ( isRecoverableError ( originalException ) ) { \n + logger . warn ( "" Recovered from java . lang . Error by serving Hystrix fallback "" , originalException ) ; \n + } \n + \n + private boolean isRecoverableError ( Throwable t ) { \n + if ( t ! = null & & t . getCause ( ) ! = null ) { \n + Throwable cause = t . getCause ( ) ; \n + if ( cause instanceof java . lang . Error ) { \n + return ! isUnrecoverable ( t ) ; \n + } \n + } \n + return false ; \n + } \n + \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - public void testRecoverableErrorThrownWithNoFallback ( ) { \n + public void testRecoverableErrorWithNoFallbackThrowsError ( ) { \n - public void testRecoverableErrorThrownWithFallback ( ) { \n + public void testRecoverableErrorMaskedByFallbackButLogged ( ) { \n","On recoverable java . lang . Error , log something so that application owners are notified , even as Hystrix serves a fallback",329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 0 . 10 ' \n + compile ' io . reactivex : rxjava : 1 . 0 . 12 ' \n,Upgrade to RxJava 1 . 0 . 12,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCollapserProperties . java \n + / * * \n + * Factory method to retrieve the default Setter . \n + * Groovy has a bug ( GROOVY - 6286 ) which does not allow method names and inner classes to have the same name \n + * This method fixes Issue # 967 and allows Groovy consumers to choose this method and not trigger the bug \n + * / \n + public static Setter defaultSetter ( ) { \n + return Setter ( ) ; \n + } \n + \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandProperties . java \n + / * * \n + * Factory method to retrieve the default Setter . \n + * Groovy has a bug ( GROOVY - 6286 ) which does not allow method names and inner classes to have the same name \n + * This method fixes Issue # 967 and allows Groovy consumers to choose this method and not trigger the bug \n + * / \n + public static Setter defaultSetter ( ) { \n + return Setter ( ) ; \n + } \n + \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolProperties . java \n + / * * \n + * Factory method to retrieve the default Setter . \n + * Groovy has a bug ( GROOVY - 6286 ) which does not allow method names and inner classes to have the same name \n + * This method fixes Issue # 967 and allows Groovy consumers to choose this method and not trigger the bug \n + * / \n + public static Setter defaultSetter ( ) { \n + return Setter ( ) ; \n + } \n + \n,Added defaultSetter ( ) methods to properties classes as a workaround for GROOVY - 6286,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + import com . netflix . hystrix . exception . HystrixTimeoutException ; \n - } else if ( t instanceof HystrixObservableTimeoutOperator . HystrixTimeoutException ) { \n + } else if ( t instanceof HystrixTimeoutException ) { \n - public static class HystrixTimeoutException extends Exception { \n - \n - private static final long serialVersionUID = 7460860948388895401L ; \n - \n - } \n - \n new file \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ exception \ HystrixTimeoutException . java \n + / * * \n + * Copyright 2015 Netflix , Inc . \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * / \n + package com . netflix . hystrix . exception ; \n + \n + import com . netflix . hystrix . HystrixCommand ; \n + import com . netflix . hystrix . HystrixObservableCommand ; \n + \n + / * * \n + * An exception representing an error where the provided execution method took longer than the Hystrix timeout . \n + * < p > \n + * Hystrix will trigger an exception of this type if it times out an execution . This class is public , so \n + * user - defined execution methods ( { @ link HystrixCommand # run ( ) } / { @ link HystrixObservableCommand # construct ( ) ) may also \n + * throw this error . If you want some types of failures to be counted as timeouts , you may wrap those failures in \n + * a HystrixTimeoutException . See https : / / github . com / Netflix / Hystrix / issues / 920 for more discussion . \n + * / \n + public class HystrixTimeoutException extends Exception { \n + \n + private static final long serialVersionUID = - 5085623652043595962L ; \n + \n + } \n + \n",Make HystrixTimeoutException public so that user - defined execution methods may return it,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandMetrics . java \n - * \n - * Marked final so that concrete implementation may vary how to implement { @ link # getRollingCount ( HystrixRollingNumberEvent ) } \n - * and the health check ( used for opening a { @ link HystrixCircuitBreaker } is constant \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ metrics \ HystrixCommandMetricsSummary . java \n + public long getRollingMaxConcurrentExecutions ( ) { \n + return counter . getRollingMaxValue ( HystrixRollingNumberEvent . COMMAND _ MAX _ ACTIVE ) ; \n + } \n + \n,"Revert "" Cleanup Javadoc for HystrixCommandMetrics "" \n This reverts commit dfb2be675375a2a93a1d1d55272ef34b78b28b43 .",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolMetrics . java \n + import org . slf4j . Logger ; \n + import org . slf4j . LoggerFactory ; \n + \n + import com . netflix . hystrix . util . HystrixRollingNumber ; \n - * Metrics class to track usage of { @ link HystrixThreadPool } s . \n - * \n - * This is an abstract class that provides a home for statics that manage caching of HystrixThreadPoolMetrics instances . \n - * It also provides a limited surface - area for concrete subclasses to implement . This allows different data structures \n - * to be used in the actual storage of metrics . \n - * \n - * For instance , you may drop all metrics . You may also keep references to all threadpool events that pass through \n - * the JVM . The default is to take a middle ground and summarize threadpool metrics into counts of events and \n - * percentiles of batch / shard size . \n - * \n - * As in { @ link HystrixMetrics } , all read methods are public and write methods are package - private or protected . \n + * Used by { @ link HystrixThreadPool } to record metrics . \n - protected void markThreadExecution ( ) { \n + public void markThreadExecution ( ) { \n - protected void markThreadCompletion ( ) { \n + public void markThreadCompletion ( ) { \n - / * * \n - * Update the rolling max counter of active threads \n - * \n - * / \n - protected void markThreadRejection ( ) { \n + public void markThreadRejection ( ) { \n","Revert "" Cleanup Javadoc for HystrixThreadPoolMetrics "" \n This reverts commit 17d37e6695809e23dd47f6610905d5a8caffac53 .",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixMetrics . java \n - * \n - * Read methods are public , as they may get called by arbitrary metrics consumers in other projects \n - * Write methods are protected , so that only internals may trigger them . \n - * @ param event { @ link HystrixRollingNumberEvent } of the event to retrieve a sum for \n + * @ param event \n + * { @ link HystrixRollingNumberEvent } of the event to retrieve a sum for \n - * @ param event { @ link HystrixRollingNumberEvent } of the event to retrieve a sum for \n + * @ param event \n + * { @ link HystrixRollingNumberEvent } of the event to retrieve a sum for \n - / * * \n - * Get the rolling max for the given { @ link HystrixRollingNumberEvent } . This number is the high - water mark \n - * that the metric has observed in the rolling window . \n - * < p > \n - * The rolling window is defined by { @ link HystrixCommandProperties # metricsRollingStatisticalWindowInMilliseconds ( ) } . \n - * \n - * @ param event { @ link HystrixRollingNumberEvent } of the event to retrieve a rolling max for \n - * @ return long rolling max \n - * / \n - public abstract long getRollingMax ( HystrixRollingNumberEvent event ) ; \n - \n - / * * \n - * Increment the count of an { @ link HystrixRollingNumberEvent } . \n - * \n - * @ param event event type to increment \n - * / \n - / * * \n - * Add a count of { @ link HystrixRollingNumberEvent } s \n - * \n - * @ param event event type to add to \n - * @ param value count to add \n - * / \n - / * * \n - * Set the observed value of a { @ link HystrixRollingNumberEvent } into a counter that keeps track of maximum values \n - * \n - * @ param event event type to observe count of \n - * @ param value count observed \n - * / \n + \n + protected abstract long getRollingMax ( HystrixRollingNumberEvent event ) ; \n","Revert "" Add Javadoc for HystrixMetrics "" \n This reverts commit f13314a34436374ac80b92c0ae56641da4a20dd0 .",329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandMetrics . java \n - public final HealthCounts getHealthCounts ( ) { \n + / / TODO Should this be final ? \n + public HealthCounts getHealthCounts ( ) { \n,"Revert "" Made HystrixCommandMetrics . getHealthCounts ( ) final "" \n This reverts commit 795e937d8be8e449f28d04b74c21370b0f5dd3f5 .",329
"hystrix - contrib \ hystrix - codahale - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ codahalemetricspublisher \ HystrixCodaHaleMetricsPublisherCommand . java \n + createCumulativeCountForEvent ( "" countFallbackMissing "" , HystrixRollingNumberEvent . FALLBACK _ MISSING ) ; \n + createRollingCountForEvent ( "" rollingCountFallbackMissing "" , HystrixRollingNumberEvent . FALLBACK _ MISSING ) ; \n",Added FALLBACK _ MISSING counter to CodaHale metrics publisher,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n + json . writeNumberField ( "" rollingCountFallbackMissing "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . FALLBACK _ MISSING ) ) ; \n",Added FALLBACK _ MISSING to hystrix - metrics - event - stream,329
"hystrix - contrib \ hystrix - rx - netty - metrics - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ rxnetty \ metricsstream \ JsonMappers . java \n + json . writeNumberField ( "" rollingCountFallbackMissing "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . FALLBACK _ MISSING ) ) ; \n",Added FALLBACK _ MISSING to hystrix - rx - netty - metrics - stream,329
"hystrix - contrib \ hystrix - servo - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ servopublisher \ HystrixServoMetricsPublisherCommand . java \n + case FALLBACK _ MISSING : return HystrixRollingNumberEvent . FALLBACK _ MISSING ; \n + monitors . add ( getCumulativeMonitor ( "" countFallbackMissing "" , HystrixEventType . FALLBACK _ MISSING ) ) ; \n + monitors . add ( getRollingMonitor ( "" rollingCountFallbackMissing "" , HystrixEventType . FALLBACK _ MISSING ) ) ; \n",Added FALLBACK _ MISSING to hystrix - servo - metrics - publisher,329
"hystrix - contrib \ hystrix - yammer - metrics - publisher \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ yammermetricspublisher \ HystrixYammerMetricsPublisherCommand . java \n + createCumulativeCountForEvent ( "" countFallbackMissing "" , HystrixRollingNumberEvent . FALLBACK _ MISSING ) ; \n + createRollingCountForEvent ( "" rollingCountFallbackMissing "" , HystrixRollingNumberEvent . FALLBACK _ MISSING ) ; \n",Added FALLBACK _ MISSING to hystrix - yammer - metrics - publisher,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ metrics \ eventstream \ HystrixMetricsPoller . java \n - json . writeNumberField ( "" rollingCountEmit "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . FALLBACK _ EMIT ) ) ; \n + json . writeNumberField ( "" rollingCountFalbackEmit "" , commandMetrics . getRollingCount ( HystrixRollingNumberEvent . FALLBACK _ EMIT ) ) ; \n",Fix JSON key for FALLBACK _ EMIT in hystrix - metrics - event - stream,329
build . gradle \n - id ' nebula . netflixoss ' version ' 2 . 2 . 5 ' \n + id ' nebula . netflixoss ' version ' 3 . 1 . 2 ' \n,Upgrade Nebula plugin to 3 . 1 . 2 ( from 2 . 2 . 5 ),329
gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 2 . 1 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 7 - bin . zip \n,Upgraded Gradle from 2 . 2 . 1 to 2 . 7,329
build . gradle \n - \n + \n + publishing { \n + publications { \n + nebula ( MavenPublication ) { \n + pom . withXml { \n + configurations . compile . resolvedConfiguration . firstLevelModuleDependencies . each { dep - > \n + asNode ( ) . dependencies [ 0 ] . dependency . find { \n + it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n + it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n + } . scope [ 0 ] . value = ' compile ' \n + } \n + } \n + } \n + } \n + } \n,"Fix generated POMs to mark Hystrix dependencies as ' compile ' , not ' runtime '",329
hystrix - contrib \ hystrix - rx - netty - metrics - stream \ build . gradle \n - compile ' io . reactivex : rxnetty : 0 . 4 . 7 ' \n + compile ' io . reactivex : rxnetty : 0 . 4 . 12 ' \n,Upgrade RxNetty from 0 . 4 . 7 to 0 . 4 . 12,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixRequestCacheTest . java \n + @ Test \n + public void testCacheWithoutRequestContext ( ) { \n + HystrixConcurrencyStrategy strategy = HystrixConcurrencyStrategyDefault . getInstance ( ) ; \n + / / HystrixRequestContext context = HystrixRequestContext . initializeContext ( ) ; \n + try { \n + HystrixRequestCache cache1 = HystrixRequestCache . getInstance ( HystrixCommandKey . Factory . asKey ( "" command1 "" ) , strategy ) ; \n + / / this should fail , as there ' s no HystrixRequestContext instance to place the cache into \n + cache1 . putIfAbsent ( "" valueA "" , new TestObservable ( "" a1 "" ) ) ; \n + fail ( "" should throw an exception on cache put "" ) ; \n + } catch ( Exception e ) { \n + / / expected \n + e . printStackTrace ( ) ; \n + } \n + } \n + \n",Add unit test for behavior of HystrixRequestCache without a HystrixRequestContext,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTestWithCustomConcurrencyStrategy . java \n - HystrixPlugins . getInstance ( ) . registerConcurrencyStrategy ( new CustomConcurrencyStrategy ( true ) ) ; \n + HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy ( true ) ; \n + HystrixPlugins . getInstance ( ) . registerConcurrencyStrategy ( strategy ) ; \n - try { \n - HystrixCommand < Boolean > cmd2 = new TestCommand ( true , true ) ; \n - assertTrue ( cmd2 . execute ( ) ) ; / / command execution throws with missing context \n - fail ( "" command should fail and throw ( no fallback ) "" ) ; \n - } catch ( IllegalStateException ise ) { \n - / / expected \n - ise . printStackTrace ( ) ; \n - } \n - \n - try { \n - printRequestLog ( ) ; \n - fail ( "" static access to HystrixRequestLog should fail and throw "" ) ; \n - } catch ( IllegalStateException ise ) { \n - / / expected \n - ise . printStackTrace ( ) ; \n - } \n + HystrixCommand < Boolean > cmd2 = new TestCommand ( true , true ) ; \n + assertTrue ( cmd2 . execute ( ) ) ; / / command execution not affected by missing context \n + printRequestLog ( ) ; \n + assertNull ( HystrixRequestLog . getCurrentRequest ( ) ) ; \n + assertNull ( HystrixRequestLog . getCurrentRequest ( strategy ) ) ; \n + assertNull ( cmd2 . currentRequestLog ) ; \n - try { \n - printRequestLog ( ) ; \n - fail ( "" static access to HystrixRequestLog fails "" ) ; \n - } catch ( IllegalStateException ise ) { \n - / / expected \n - ise . printStackTrace ( ) ; \n - } \n + printRequestLog ( ) ; \n + assertNull ( HystrixRequestLog . getCurrentRequest ( ) ) ; \n + assertNull ( HystrixRequestLog . getCurrentRequest ( strategy ) ) ; \n + assertNull ( cmd1 . currentRequestLog ) ; \n",Fix test assertions after fixes in # 951,329
hystrix - core \ build . gradle \n - jmhVersion = ' 1 . 10 . 3 ' \n + jmhVersion = ' 1 . 11 . 1 ' \n,Upgrade JMH to 1 . 11 . 1 from 1 . 10 . 3,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + @ Test \n + public void testSlowFallback ( ) { \n + class PrimaryCommand extends TestHystrixCommand < Integer > { \n + public PrimaryCommand ( TestCircuitBreaker circuitBreaker ) { \n + super ( testPropsBuilder ( ) . setCircuitBreaker ( circuitBreaker ) . setMetrics ( circuitBreaker . metrics ) ) ; \n + } \n + \n + @ Override \n + protected Integer run ( ) throws Exception { \n + throw new RuntimeException ( "" primary failure "" ) ; \n + } \n + \n + @ Override \n + protected Integer getFallback ( ) { \n + try { \n + Thread . sleep ( 1500 ) ; \n + return 1 ; \n + } catch ( InterruptedException ie ) { \n + System . out . println ( "" Caught Interrupted Exception "" ) ; \n + ie . printStackTrace ( ) ; \n + } \n + return - 1 ; \n + } \n + } \n + \n + assertTrue ( 1 = = new PrimaryCommand ( new TestCircuitBreaker ( ) ) . execute ( ) ) ; \n + } \n + \n",A smaller testcase demonstrating that a slow fallback also triggers a failure,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n + @ Test \n + public void stressTestRequestCollapser ( ) throws Exception { \n + for ( int i = 0 ; i < 100 ; i + + ) { \n + init ( ) ; \n + testTwoRequests ( ) ; \n + cleanup ( ) ; \n + } \n + } \n + \n,Reinstate the HystrixObservableCollapserTest stress test after some runs showed there might still be a bug,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCircuitBreaker . java \n - / / Unsubscribe from the current stream to reset the health counts stream . This only affects the health counts view , \n - / / and all other metric consumers are unaffected by the reset \n - metrics . resetStream ( ) ; \n - / / If we have been ' open ' and have a success then we want to close the circuit . This handles the ' singleTest ' logic \n - circuitOpen . set ( false ) ; \n + if ( circuitOpen . compareAndSet ( true , false ) ) { \n + / / win the thread race to reset metrics \n + / / Unsubscribe from the current stream to reset the health counts stream . This only affects the health counts view , \n + / / and all other metric consumers are unaffected by the reset \n + metrics . resetStream ( ) ; \n + } \n",Ensure only a single thread can reset the command health stream,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + public boolean isResponseSemaphoreRejected ( ) { \n + return events . contains ( HystrixEventType . SEMAPHORE _ REJECTED ) ; \n + } \n + \n + public boolean isResponseThreadPoolRejected ( ) { \n + return events . contains ( HystrixEventType . THREAD _ POOL _ REJECTED ) ; \n + } \n + \n - return events . contains ( HystrixEventType . THREAD _ POOL _ REJECTED ) | | events . contains ( HystrixEventType . SEMAPHORE _ REJECTED ) ; \n + return isResponseThreadPoolRejected ( ) | | isResponseSemaphoreRejected ( ) ; \n - * Whether the response received was a fallback as result of being \n - * rejected ( from thread - pool or semaphore ) and < code > getFallback ( ) < / code > being called . \n - * \n + * Whether the response received was a fallback as result of being rejected via sempahore \n + * \n + * @ return boolean \n + * / \n + public boolean isResponseSemaphoreRejected ( ) { \n + return executionResult . isResponseSemaphoreRejected ( ) ; \n + } \n + \n + / * * \n + * Whether the response received was a fallback as result of being rejected via threadpool \n + * \n + * @ return boolean \n + * / \n + public boolean isResponseThreadPoolRejected ( ) { \n + return executionResult . isResponseThreadPoolRejected ( ) ; \n + } \n + \n + / * * \n + * Whether the response received was a fallback as result of being rejected ( either via threadpool or semaphore ) \n + * \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixInvokableInfo . java \n + boolean isResponseSemaphoreRejected ( ) ; \n + \n + boolean isResponseThreadPoolRejected ( ) ; \n + \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HystrixThreadPoolEventStream . java \n - HystrixThreadPoolKey executionThreadPoolKey = hystrixCommandExecution . getThreadPoolKey ( ) ; \n - if ( executionThreadPoolKey ! = null ) { \n - return executionThreadPoolKey . equals ( threadPoolKey ) ; \n + if ( hystrixCommandExecution . getCommandInstance ( ) . isExecutedInThread ( ) | | hystrixCommandExecution . getCommandInstance ( ) . isResponseThreadPoolRejected ( ) ) { \n + HystrixThreadPoolKey executionThreadPoolKey = hystrixCommandExecution . getThreadPoolKey ( ) ; \n + if ( executionThreadPoolKey ! = null ) { \n + return executionThreadPoolKey . equals ( threadPoolKey ) ; \n + } else { \n + return false ; \n + } \n,Bugfixes to accurately count only executions on a threadpool and threadpool - rejections,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n + private static final HystrixTimeoutException TIMEOUT _ EXCEPTION _ INSTANCE = new HystrixTimeoutException ( ) ; \n + \n - child . onError ( new HystrixTimeoutException ( ) ) ; \n + child . onError ( TIMEOUT _ EXCEPTION _ INSTANCE ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTimeoutConcurrencyTesting . java \n - private final static int NUM _ CONCURRENT _ COMMANDS = 25 ; \n + private final static int NUM _ CONCURRENT _ COMMANDS = 30 ; \n - public void testTimeoutRace ( ) { \n - final int NUM _ TRIALS = 10 ; \n + public void testTimeoutRace ( ) throws InterruptedException { \n + final int NUM _ TRIALS = 1000 ; \n + HystrixRequestContext context = null ; \n - HystrixRequestContext . initializeContext ( ) ; \n + context = HystrixRequestContext . initializeContext ( ) ; \n - for ( String s : results ) { \n + for ( String s : results ) { \n - HystrixRequestContext . getContextForCurrentThread ( ) . shutdown ( ) ; \n + if ( context ! = null ) { \n + context . shutdown ( ) ; \n + } \n + \n + System . out . println ( "" * * * * * * * * * * * * * * * TRIAL "" + i + "" * * * * * * * * * * * * * * * * * * "" ) ; \n + System . out . println ( ) ; \n + Thread . sleep ( 50 ) ; \n - . withExecutionTimeoutInMilliseconds ( 1 ) \n + . withExecutionTimeoutInMilliseconds ( 3 ) \n - Thread . sleep ( 5 ) ; \n + / / System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" sleeping "" ) ; \n + Thread . sleep ( 100 ) ; \n + / / System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" awake and returning "" ) ; \n",Adjusting command latency to 100ms and timeout to 3ms,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTimeoutConcurrencyTesting . java \n - . withCircuitBreakerEnabled ( false ) ) \n + . withCircuitBreakerEnabled ( false ) \n + . withFallbackIsolationSemaphoreMaxConcurrentRequests ( NUM _ CONCURRENT _ COMMANDS ) ) \n,Made fallback semaphore allow maximum concurrent fallbacks in unit test,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTimeoutConcurrencyTesting . java \n - . withCoreSize ( NUM _ CONCURRENT _ COMMANDS ) ) ) ; \n + . withCoreSize ( NUM _ CONCURRENT _ COMMANDS ) \n + . withMaxQueueSize ( NUM _ CONCURRENT _ COMMANDS ) \n + . withQueueSizeRejectionThreshold ( NUM _ CONCURRENT _ COMMANDS ) ) ) ; \n,Enlarging thread pool queue size in unit test to prevent spurious failures,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandMetricsTest . java \n + @ Test \n + public void testBadRequestsDoNotAffectErrorPercentage ( ) { \n + HystrixCommandProperties . Setter properties = HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) ; \n + HystrixCommandMetrics metrics = getMetrics ( properties ) ; \n + \n + metrics . markSuccess ( 100 ) ; \n + assertEquals ( 0 , metrics . getHealthCounts ( ) . getErrorPercentage ( ) ) ; \n + \n + metrics . markFailure ( 1000 ) ; \n + assertEquals ( 50 , metrics . getHealthCounts ( ) . getErrorPercentage ( ) ) ; \n + \n + metrics . markBadRequest ( 1 ) ; \n + metrics . markBadRequest ( 2 ) ; \n + assertEquals ( 50 , metrics . getHealthCounts ( ) . getErrorPercentage ( ) ) ; \n + \n + metrics . markFailure ( 45 ) ; \n + metrics . markFailure ( 55 ) ; \n + assertEquals ( 75 , metrics . getHealthCounts ( ) . getErrorPercentage ( ) ) ; \n + } \n + \n",Add test to confirm that bad requests do not affect circuit breaker ' s computer error percentage,329
"build . gradle \n + / / mark all first - level dependencies as ' compile ' in generated POM \n + / / except for ' servlet - api ' , which should be ' provided ' \n - asNode ( ) . dependencies [ 0 ] . dependency . find { \n - it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n - it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n - } . scope [ 0 ] . value = ' compile ' \n + if ( dep . moduleName = = "" servlet - api "" ) { \n + asNode ( ) . dependencies [ 0 ] . dependency . find { \n + it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n + it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n + } . scope [ 0 ] . value = ' provided ' \n + } else { \n + asNode ( ) . dependencies [ 0 ] . dependency . find { \n + it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n + it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n + } . scope [ 0 ] . value = ' compile ' \n + } \n",Mark servlet - api as ' provided ' in generated POMs,329
hystrix - dashboard \ src \ main \ webapp \ components \ hystrixCommand \ magnifying - glass - icon - 20 . png \n Binary files a / hystrix - dashboard / src / main / webapp / components / hystrixCommand / magnifying - glass - icon - 20 . png and b / hystrix - dashboard / src / main / webapp / components / hystrixCommand / magnifying - glass - icon - 20 . png differ \n hystrix - dashboard \ src \ main \ webapp \ components \ hystrixCommand \ magnifying - glass - icon . png \n Binary files a / hystrix - dashboard / src / main / webapp / components / hystrixCommand / magnifying - glass - icon . png and b / hystrix - dashboard / src / main / webapp / components / hystrixCommand / magnifying - glass - icon . png differ \n,Swapping out magnifying glass logos for properly - licensed images,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n + try { \n + Thread . sleep ( 100 ) ; \n + } catch ( Throwable ex ) { \n + fail ( ex . getMessage ( ) ) ; \n + } \n + \n + System . out . println ( "" CMD1 : "" + command1 . getExecutionEvents ( ) ) ; \n + System . out . println ( "" CMD2 : "" + command2 . getExecutionEvents ( ) ) ; \n + System . out . println ( "" CMD3 : "" + command3 . getExecutionEvents ( ) ) ; \n",Add a sleep to get a more deterministic unit test result,329
"hystrix - contrib \ hystrix - javanica \ README . md \n - Based on [ this ] ( https : / / github . com / Netflix / Hystrix / wiki / How - To - Use # ErrorPropagation ) description , ` @ HystrixCommand ` has an ability to specify exceptions types which should be ignored and wrapped to throw in ` HystrixBadRequestException ` . \n + Based on [ this ] ( https : / / github . com / Netflix / Hystrix / wiki / How - To - Use # ErrorPropagation ) description , ` @ HystrixCommand ` has an ability to specify exceptions types which should be ignored . \n - If ` userResource . getUserById ( id ) ; ` throws an exception which type is _ BadRequestException _ then this exception will be wrapped in ` HystrixBadRequestException ` and will not affect metrics and will not trigger fallback logic . \n + If ` userResource . getUserById ( id ) ; ` throws an exception which type is _ BadRequestException _ then this exception will be thrown without triggering fallback logic . \n",Removed reference to wrapped HystrixBadRequestException in javanica docs,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - super ( testPropsBuilder ( ) . setCircuitBreaker ( circuitBreaker ) . setMetrics ( circuitBreaker . metrics ) ) ; \n + super ( testPropsBuilder ( ) \n + . setCommandKey ( HystrixCommandKey . Factory . asKey ( "" ObservableSlowCacheable "" ) ) \n + . setCircuitBreaker ( circuitBreaker ) . setMetrics ( circuitBreaker . metrics ) ) ; \n",Use separate key for SlowCacheableCommand in HystrixCommandTest and HystrixObservableCommandTest,329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ requests \ stream \ HystrixRequestEventsJsonStream . java \n - public static String convertToJson ( Collection < HystrixRequestEvents > requests ) throws IOException { \n + public static String convertRequestsToJson ( Collection < HystrixRequestEvents > requests ) throws IOException { \n - convertRequestToJson ( json , request ) ; \n + writeRequestAsJson ( json , request ) ; \n - private static void convertRequestToJson ( JsonGenerator json , HystrixRequestEvents request ) throws IOException { \n + public static String convertRequestToJson ( HystrixRequestEvents request ) throws IOException { \n + StringWriter jsonString = new StringWriter ( ) ; \n + JsonGenerator json = jsonFactory . createGenerator ( jsonString ) ; \n + writeRequestAsJson ( json , request ) ; \n + json . close ( ) ; \n + return jsonString . getBuffer ( ) . toString ( ) ; \n + } \n + \n + private static void writeRequestAsJson ( JsonGenerator json , HystrixRequestEvents request ) throws IOException { \n",Added a JSON converter for a single request in HystrixRequestEventsJsonStream,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ consumer \ RollingDistributionStream . java \n - import sun . misc . Cache ; \n,Remove accidental import of sun . misc . Cache,329
build . gradle \n - id ' nebula . netflixoss ' version ' 3 . 1 . 2 ' \n + id ' nebula . netflixoss ' version ' 3 . 2 . 0 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 7 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 10 - bin . zip \n,Updated Nebula plugin to 3 . 2 . 0 and Gradle to 2 . 10,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n + import java . util . concurrent . TimeUnit ; \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnCompleted "" ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnError : "" + e ) ; \n + e . printStackTrace ( ) ; \n - System . out . println ( "" OnNext : "" + value ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnNext : "" + value ) ; \n - assertEquals ( "" CommandName "" , Hystrix . getCurrentThreadExecutingCommand ( ) . name ( ) ) ; \n - assertEquals ( 1 , Hystrix . getCommandCount ( ) ) ; \n - latch . await ( ) ; \n + assertTrue ( latch . await ( 1000 , TimeUnit . MILLISECONDS ) ) ; \n",Fix assertions which are no longer true after this commit,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixTest . java \n - import java . util . concurrent . TimeUnit ; \n - System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnCompleted "" ) ; \n - System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnError : "" + e ) ; \n - e . printStackTrace ( ) ; \n - System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" OnNext : "" + value ) ; \n + System . out . println ( "" OnNext : "" + value ) ; \n + assertEquals ( "" CommandName "" , Hystrix . getCurrentThreadExecutingCommand ( ) . name ( ) ) ; \n + assertEquals ( 1 , Hystrix . getCommandCount ( ) ) ; \n - assertTrue ( latch . await ( 1000 , TimeUnit . MILLISECONDS ) ) ; \n + latch . await ( ) ; \n","Revert "" Fix assertions which are no longer true after this commit "" \n This reverts commit bde8615e59ba30ee4b2c87a9dd04bc08c033607a .",329
hystrix - contrib \ hystrix - rx - netty - metrics - stream \ build . gradle \n - compile ' io . reactivex : rxnetty : 0 . 4 . 12 ' \n + compile ' io . reactivex : rxnetty : 0 . 4 . 17 ' \n,Update RxNetty version which depends on netty 4 . 1 . 3 . Final,329
hystrix - contrib \ hystrix - clj \ build . gradle \n - classpath ' com . netflix . nebula : nebula - clojure - plugin : 1 . 12 . 2 ' \n + classpath ' com . netflix . nebula : nebula - clojure - plugin : 4 . 0 . 1 ' \n - apply plugin : ' nebula - clojure ' / / this is a wrapper around clojuresque to make it behave well with other plugins \n + apply plugin : ' nebula . clojure ' / / this is a wrapper around clojuresque to make it behave well with other plugins \n - compile ' org . clojure : clojure : 1 . 5 . 1 ' \n + compile ' org . clojure : clojure : 1 . 7 . 0 ' \n,Update nebula - clojure Gradle plugin and dependency on Clojure,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 1 . 5 ' \n + compile ' io . reactivex : rxjava : 1 . 1 . 8 ' \n,Update RxJava from 1 . 1 . 5 to 1 . 1 . 8,329
hystrix - core \ build . gradle \n - jmhVersion = ' 1 . 11 . 2 ' \n + jmhVersion = ' 1 . 13 ' \n,Update jmh from 1 . 11 . 2 - > 1 . 13,329
hystrix - core \ build . gradle \n - compile ' org . hdrhistogram : HdrHistogram : 2 . 1 . 7 ' \n + compile ' org . hdrhistogram : HdrHistogram : 2 . 1 . 9 ' \n,Update HdrHistogram from 2 . 1 . 7 to 2 . 1 . 9,329
build . gradle \n - id ' nebula . netflixoss ' version ' 3 . 2 . 3 ' \n + id ' nebula . netflixoss ' version ' 3 . 3 . 0 ' \n,Update nebula . netflixoss Gradle plugin from 3 . 2 . 3 to 3 . 3 . 0,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCollapserProperties . java \n - @ SuppressWarnings ( "" unused "" ) \n - private static HystrixProperty < String > getProperty ( String propertyPrefix , HystrixCollapserKey key , String instanceProperty , String builderOverrideValue , String defaultValue ) { \n - return forString ( ) \n - . add ( propertyPrefix + "" . collapser . "" + key . name ( ) + "" . "" + instanceProperty , builderOverrideValue ) \n - . add ( propertyPrefix + "" . collapser . default . "" + instanceProperty , defaultValue ) \n - . build ( ) ; \n - } \n - \n","Remove unused method HystrixCollapserProperties . getProperty ( String , HystrixCollapserKey , String , String , String )",329
README . md \n - [ ! [ ] [ release img ] ] [ release ] \n,"Remove release badge , as it doesn ' t track the actual highest release",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandMetrics . java \n + * \n + * This metrics should measure the actual health of a { @ link HystrixCommand } . For that reason , the following are included : \n + * < p > < ul > \n + * < li > { @ link HystrixRollingNumberEvent # SUCCESS } \n + * < li > { @ link HystrixRollingNumberEvent # FAILURE } \n + * < li > { @ link HystrixRollingNumberEvent # TIMEOUT } \n + * < li > { @ link HystrixRollingNumberEvent # THREAD _ POOL _ REJECTED } \n + * < li > { @ link HystrixRollingNumberEvent # SEMAPHORE _ REJECTED } \n + * < / ul > < p > \n + * The following are not included in either attempts / failures : \n + * < p > < ul > \n + * < li > { @ link HystrixRollingNumberEvent # BAD _ REQUEST } - this event denotes bad arguments to the command and not a problem with the command \n + * < li > { @ link HystrixRollingNumberEvent # SHORT _ CIRCUITED } - this event measures a health problem in the past , not a problem with the current state \n + * < li > All Fallback metrics \n + * < li > { @ link HystrixRollingNumberEvent # EMIT } - this event is not a terminal state for the command \n + * < li > { @ link HystrixRollingNumberEvent # COLLAPSED } - this event is about the batching process , not the command execution \n + * < / ul > < p > \n - long shortCircuited = counter . getRollingSum ( HystrixRollingNumberEvent . SHORT _ CIRCUITED ) ; / / fallbacks occur on this \n - long totalCount = failure + success + timeout + threadPoolRejected + shortCircuited + semaphoreRejected ; \n - long errorCount = failure + timeout + threadPoolRejected + shortCircuited + semaphoreRejected ; \n + long totalCount = failure + success + timeout + threadPoolRejected + semaphoreRejected ; \n + long errorCount = failure + timeout + threadPoolRejected + semaphoreRejected ; \n",Remove SHORT - CIRCUITS from Health check calculation,329
"hystrix - core \ build . gradle \n - jmhVersion = ' 1 . 11 . 1 ' \n + jmhVersion = ' 1 . 11 . 2 ' \n + include = ' . * Construction . * ' \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandGroupKey . java \n - intern . putIfAbsent ( name , new HystrixCommandGroupDefault ( name ) ) ; \n + k = new HystrixCommandGroupDefault ( name ) ; \n + intern . putIfAbsent ( name , k ) ; \n - return intern . get ( name ) ; \n + return k ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixCommandKey . java \n - intern . putIfAbsent ( name , new HystrixCommandKeyDefault ( name ) ) ; \n + k = new HystrixCommandKeyDefault ( name ) ; \n + intern . putIfAbsent ( name , k ) ; \n - return intern . get ( name ) ; \n + return k ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPoolKey . java \n - intern . putIfAbsent ( name , new HystrixThreadPoolKeyDefault ( name ) ) ; \n + k = new HystrixThreadPoolKeyDefault ( name ) ; \n + intern . putIfAbsent ( name , k ) ; \n - return intern . get ( name ) ; \n + return k ; \n",Reduced gets on key name concurrent hash maps,329
hystrix - core \ src \ jmh \ java \ com \ netflix \ hystrix \ perf \ CommandExecutionPerfTest . java \n - } ) ; \n + } ) . subscribeOn ( Schedulers . computation ( ) ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - \n,Added subscribeOn to HystrixObservableCommand in JMH test to make it async,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 1 . 1 ' \n + compile ' io . reactivex : rxjava : 1 . 1 . 5 ' \n,Upgrade RxJava from 1 . 1 . 1 to 1 . 1 . 5,329
"hystrix - contrib \ hystrix - rx - netty - metrics - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ rxnetty \ metricsstream \ HystrixMetricsStreamHandler . java \n - Subscription actionSubscription = Observable . timer ( 0 , interval , TimeUnit . MILLISECONDS , Schedulers . computation ( ) ) \n + Subscription actionSubscription = Observable . interval ( interval , TimeUnit . MILLISECONDS ) \n",Switch usage of Observable . timer for Observable . interval,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - } ) . finallyDo ( new Action0 ( ) { \n + } ) . doAfterTerminate ( new Action0 ( ) { \n - } ) . finallyDo ( new Action0 ( ) { \n + } ) . doAfterTerminate ( new Action0 ( ) { \n - } ) . finallyDo ( new Action0 ( ) { \n + } ) . doAfterTerminate ( new Action0 ( ) { \n,Switch usage of Observable . finallyDo to Observable . doAfterTerminate,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 150 , AbstractTestHystrixCommand . FallbackResult . UNIMPLEMENTED , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 500 , AbstractTestHystrixCommand . FallbackResult . UNIMPLEMENTED , 200 ) ; \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 150 , AbstractTestHystrixCommand . FallbackResult . SUCCESS , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 500 , AbstractTestHystrixCommand . FallbackResult . SUCCESS , 200 ) ; \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 150 , AbstractTestHystrixCommand . FallbackResult . FAILURE , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . SUCCESS , 500 , AbstractTestHystrixCommand . FallbackResult . FAILURE , 200 ) ; \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 150 , AbstractTestHystrixCommand . FallbackResult . UNIMPLEMENTED , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 500 , AbstractTestHystrixCommand . FallbackResult . UNIMPLEMENTED , 200 ) ; \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 150 , AbstractTestHystrixCommand . FallbackResult . SUCCESS , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 500 , AbstractTestHystrixCommand . FallbackResult . SUCCESS , 200 ) ; \n - return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 150 , AbstractTestHystrixCommand . FallbackResult . FAILURE , 50 ) ; \n + return getCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 500 , AbstractTestHystrixCommand . FallbackResult . FAILURE , 200 ) ; \n",Raising execution latency and timeout for execution hook tests,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCircuitBreakerTest . java \n + import com . hystrix . junit . HystrixRequestContextRule ; \n + import org . junit . Rule ; \n + @ Rule \n + public HystrixRequestContextRule ctx = new HystrixRequestContextRule ( ) ; \n + \n - / / this should remain open as the failure threshold is below the percentage limit \n + / / this should remain closed as the failure threshold is below the percentage limit \n + System . out . println ( "" ReqLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n - withExecutionTimeoutInMilliseconds ( 100 ) . \n + withExecutionTimeoutInMilliseconds ( 500 ) . \n",Raised command timeout in circuit - breaker tests,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCircuitBreakerTest . java \n - import com . netflix . hystrix . strategy . eventnotifier . HystrixEventNotifierDefault ; \n - import com . netflix . hystrix . util . HystrixRollingNumberEvent ; \n - HystrixCommand < Boolean > cmd5 = new FailureCommand ( key , 1 ) ; \n + HystrixCommand < Boolean > cmd5 = new SuccessCommand ( key , 1 ) ; \n - HystrixCommand < Boolean > cmd6 = new SuccessCommand ( key , 1 ) ; \n + HystrixCommand < Boolean > cmd6 = new FailureCommand ( key , 1 ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandMetricsTest . java \n + import com . hystrix . junit . HystrixRequestContextRule ; \n + import org . junit . Rule ; \n + import rx . Observable ; \n + import rx . Subscriber ; \n + import rx . observers . SafeSubscriber ; \n + \n + import java . util . ArrayList ; \n + import java . util . List ; \n + import java . util . concurrent . CountDownLatch ; \n + import java . util . concurrent . TimeUnit ; \n + @ Rule \n + public HystrixRequestContextRule ctx = new HystrixRequestContextRule ( ) ; \n + \n - public void testCurrentConcurrentExecutionCount ( ) { \n + public void testCurrentConcurrentExecutionCount ( ) throws InterruptedException { \n + List < Observable < Boolean > > cmdResults = new ArrayList < Observable < Boolean > > ( ) ; \n - cmd . queue ( ) ; \n + Observable < Boolean > eagerObservable = cmd . observe ( ) ; \n + cmdResults . add ( eagerObservable ) ; \n + System . out . println ( "" ReqLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n + \n + final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n + Observable . merge ( cmdResults ) . subscribe ( new Subscriber < Boolean > ( ) { \n + @ Override \n + public void onCompleted ( ) { \n + System . out . println ( "" All commands done "" ) ; \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onError ( Throwable e ) { \n + System . out . println ( "" Error duing command execution "" ) ; \n + e . printStackTrace ( ) ; \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onNext ( Boolean aBoolean ) { \n + \n + } \n + } ) ; \n + \n + latch . await ( 10000 , TimeUnit . MILLISECONDS ) ; \n + assertEquals ( 0 , metrics . getCurrentConcurrentExecutionCount ( ) ) ; \n",Added await step to metrics - concurrency test and reordered command execution in circuitbreaker test,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCircuitBreakerTest . java \n - HystrixCommand < Boolean > cmd1 = new FailureCommand ( key , 60 , sleepWindow ) ; \n + HystrixCommand < Boolean > cmd1 = new FailureCommand ( key , 1 , sleepWindow ) ; \n + System . out . println ( "" ReqLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n",Made it less likely for metrics bucket to roll in circuit - breaker unit test before assert runs,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ CommonHystrixCommandTests . java \n - final C cmd1 = getLatentCommand ( ExecutionIsolationStrategy . SEMAPHORE , ExecutionResult . SUCCESS , 500 , FallbackResult . SUCCESS , semaphore ) ; \n - final C cmd2 = getLatentCommand ( ExecutionIsolationStrategy . SEMAPHORE , ExecutionResult . SUCCESS , 500 , FallbackResult . SUCCESS , semaphore ) ; \n + final C cmd1 = getLatentCommand ( ExecutionIsolationStrategy . SEMAPHORE , ExecutionResult . SUCCESS , 1500 , FallbackResult . SUCCESS , semaphore ) ; \n + final C cmd2 = getLatentCommand ( ExecutionIsolationStrategy . SEMAPHORE , ExecutionResult . SUCCESS , 1500 , FallbackResult . SUCCESS , semaphore ) ; \n",Lengthen latent commands for semaphore - rejection unit test,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTimeoutConcurrencyTesting . java \n - Thread . sleep ( 100 ) ; \n + Thread . sleep ( 500 ) ; \n,Increased timeout in TimeoutConcurency test to make timeout more reproducible,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ strategy \ concurrency \ HystrixContextScheduler . java \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" Unsubscribe happening , value of thunk : "" + shouldInterruptThread . call ( ) ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - @ Test \n - public void testDoNotInterruptObserveOnTimeoutIfPropertySaysNotTo ( ) throws InterruptedException { \n - / / given \n - InterruptibleCommand cmd = new InterruptibleCommand ( new TestCircuitBreaker ( ) , false ) ; \n - \n - / / when \n - cmd . observe ( ) . subscribe ( ) ; \n - \n - / / then \n - Thread . sleep ( 500 ) ; \n - assertFalse ( cmd . hasBeenInterrupted ( ) ) ; \n - } \n - \n - @ Test \n - public void testDoNotInterruptToObservableOnTimeoutIfPropertySaysNotTo ( ) throws InterruptedException { \n - / / given \n - InterruptibleCommand cmd = new InterruptibleCommand ( new TestCircuitBreaker ( ) , false ) ; \n - \n - / / when \n - cmd . toObservable ( ) . subscribe ( ) ; \n - / / then \n - Thread . sleep ( 500 ) ; \n - assertFalse ( cmd . hasBeenInterrupted ( ) ) ; \n - } \n - } ) . subscribeOn ( Schedulers . computation ( ) ) ; \n + } ) . subscribeOn ( Schedulers . io ( ) ) ; \n - Thread . sleep ( 2000 ) ; \n + Thread . sleep ( 1000 ) ; \n",Removing bad tests of thread - interruption on HystrixObservableCommand,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ RollingThreadPoolMaxConcurrencyStreamTest . java \n - Command cmd2 = Command . from ( groupKey , key , HystrixEventType . SUCCESS , 10 ) ; \n - Command cmd3 = Command . from ( groupKey , key , HystrixEventType . SUCCESS , 15 ) ; \n + Command cmd2 = Command . from ( groupKey , key , HystrixEventType . SUCCESS , 50 ) ; \n + Command cmd3 = Command . from ( groupKey , key , HystrixEventType . SUCCESS , 75 ) ; \n",Lengthen command latencies in thread pool max - counter unit tests,329
"hystrix - data - stream \ src \ main \ java \ com \ netflix \ hystrix \ metric \ consumer \ HystrixDashboardStream . java \n + import com . netflix . config . DynamicIntProperty ; \n + import com . netflix . config . DynamicPropertyFactory ; \n + private static final DynamicIntProperty dataEmissionIntervalInMs = \n + DynamicPropertyFactory . getInstance ( ) . getIntProperty ( "" hystrix . stream . dashboard . intervalInMilliseconds "" , 500 ) ; \n + \n - private static final HystrixDashboardStream INSTANCE = new HystrixDashboardStream ( 500 ) ; \n + / / The data emission interval is looked up on startup only \n + private static final HystrixDashboardStream INSTANCE = \n + new HystrixDashboardStream ( dataEmissionIntervalInMs . get ( ) ) ; \n",Made dashboard data emission interval configurable on startup,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HystrixCollapserEventStream . java \n - import java . util . concurrent . TimeUnit ; \n - private final Subject < HystrixCollapserEvent , HystrixCollapserEvent > stream ; \n + private final Subject < HystrixCollapserEvent , HystrixCollapserEvent > writeOnlyStream ; \n + private final Observable < HystrixCollapserEvent > readOnlyStream ; \n - this . stream = new SerializedSubject < HystrixCollapserEvent , HystrixCollapserEvent > ( PublishSubject . < HystrixCollapserEvent > create ( ) ) ; \n + this . writeOnlyStream = new SerializedSubject < HystrixCollapserEvent , HystrixCollapserEvent > ( PublishSubject . < HystrixCollapserEvent > create ( ) ) ; \n + this . readOnlyStream = writeOnlyStream . share ( ) ; \n - stream . onNext ( event ) ; \n + writeOnlyStream . onNext ( event ) ; \n - return stream ; \n - } \n - \n - public Observable < Observable < HystrixCollapserEvent > > getBucketedStream ( int bucketSizeInMs ) { \n - return observe ( ) \n - . window ( bucketSizeInMs , TimeUnit . MILLISECONDS ) ; \n + return readOnlyStream ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ metric \ HystrixCommandEventStream . java \n - private final Subject < HystrixCommandCompletion , HystrixCommandCompletion > stream ; \n + private final Subject < HystrixCommandCompletion , HystrixCommandCompletion > writeOnlySubject ; \n + private final Observable < HystrixCommandCompletion > readOnlyStream ; \n - this . stream = new SerializedSubject < HystrixCommandCompletion , HystrixCommandCompletion > ( PublishSubject . < HystrixCommandCompletion > create ( ) ) ; \n + this . writeOnlySubject = new SerializedSubject < HystrixCommandCompletion , HystrixCommandCompletion > ( PublishSubject . < HystrixCommandCompletion > create ( ) ) ; \n + this . readOnlyStream = writeOnlySubject . share ( ) ; \n - stream . onNext ( event ) ; \n + writeOnlySubject . onNext ( event ) ; \n - return stream ; \n + return readOnlyStream ; \n",Using dedicated write - only subject and multi - cast read - only Observable for event streams,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ AbstractCommand . java \n - private static final HystrixTimeoutException TIMEOUT _ EXCEPTION _ INSTANCE = new HystrixTimeoutException ( ) ; \n - \n - child . onError ( TIMEOUT _ EXCEPTION _ INSTANCE ) ; \n + child . onError ( new HystrixTimeoutException ( ) ) ; \n,"Making the HystrixTimeoutException instance per - command , not static",329
build . gradle \n - id ' nebula . netflixoss ' version ' 3 . 2 . 0 ' \n + id ' nebula . netflixoss ' version ' 3 . 2 . 2 ' \n,Upgrade netflixoss Nebula plugin to 3 . 2 . 2,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 1 . 8 ' \n + compile ' io . reactivex : rxjava : 1 . 2 . 0 ' \n,Upgrade to RxJava 1 . 2 . 0,329
hystrix - core \ src \ jmh \ java \ com \ netflix \ hystrix \ perf \ CommandConstructionPerfTest . java \n - @ BenchmarkMode ( { Mode . SampleTime } ) \n + @ BenchmarkMode ( { Mode . SingleShotTime } ) \n,"jmh test is more accurate when measuring the first command construction \n Otherwise , data structures are cached and constructions does less work",329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ PlatformSpecific . java \n - private final boolean isAppEngineStandardEnvironment ; \n + private final Platform platform ; \n + \n + private enum Platform { \n + STANDARD , APPENGINE _ STANDARD , APPENGINE _ FLEXIBLE \n + } \n - isAppEngineStandardEnvironment = determineAppEngineReflectively ( ) ; \n + platform = determinePlatformReflectively ( ) ; \n - return INSTANCE . isAppEngineStandardEnvironment ; \n + return INSTANCE . platform = = Platform . APPENGINE _ STANDARD ; \n + } \n + \n + public static boolean isAppEngine ( ) { \n + return INSTANCE . platform = = Platform . APPENGINE _ FLEXIBLE | | INSTANCE . platform = = Platform . APPENGINE _ STANDARD ; \n - private static boolean determineAppEngineReflectively ( ) { \n + private static Platform determinePlatformReflectively ( ) { \n - return false ; \n + return Platform . STANDARD ; \n - return false ; \n + return Platform . APPENGINE _ FLEXIBLE ; \n - return Class . forName ( "" com . google . apphosting . api . ApiProxy "" ) \n + boolean isInsideAppengine = Class . forName ( "" com . google . apphosting . api . ApiProxy "" ) \n + return isInsideAppengine ? Platform . APPENGINE _ STANDARD : Platform . STANDARD ; \n - return false ; \n + return Platform . STANDARD ; \n - return false ; \n + return Platform . STANDARD ; \n - return false ; \n + return Platform . STANDARD ; \n - return false ; \n + return Platform . STANDARD ; \n",Re - add PlatformSpecific . isAppEngine ( ) for backwards - compatibility,329
hystrix - core \ build . gradle \n - jmhVersion = ' 1 . 13 ' \n + jmhVersion = ' 1 . 14 . 1 ' \n,Upgrade jmh to 1 . 14 . 1,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( 1 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; / / pool - filler still going \n + int numInFlight = circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ; \n + assertEquals ( "" Expected 1 in flight but got : "" + numInFlight , 1 , numInFlight ) ; / / pool - filler still going \n - assertCommandExecutionEvents ( command , HystrixEventType . THREAD _ POOL _ REJECTED , HystrixEventType . FALLBACK _ MISSING ) ; \n + try { \n + assertCommandExecutionEvents ( command , HystrixEventType . THREAD _ POOL _ REJECTED , HystrixEventType . FALLBACK _ MISSING ) ; \n + } catch ( Throwable ex ) { \n + System . out . println ( "" Unexpected command execution events : "" + command . getExecutionEvents ( ) ) ; \n + throw new RuntimeException ( ex ) ; \n + } \n",Added some logging to unit tests to help deflake them when running on CI,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ util \ HystrixTimerTest . java \n + HystrixPlugins . reset ( ) ; \n,Added explicit HystrixPlugins . reset ( ) to HystrixTimerThread init of each test,329
. travis . yml \n - oraclejdk7 \n + \n + script : \n + - . / gradlew - - info check \n,Adding - - info to Travis script step,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ CumulativeThreadPoolEventCounterStreamTest . java \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 200 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 300 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n - Thread . sleep ( 100 ) ; \n + Thread . sleep ( 10 ) ; \n",Adjusted timing of cumulative thred pool counter stream test,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ CommandStreamTest . java \n - . withExecutionTimeoutInMilliseconds ( 300 ) \n + . withExecutionTimeoutInMilliseconds ( 600 ) \n - return new Command ( setter , HystrixEventType . SUCCESS , 400 , uniqueArg , desiredFallbackEventType , fallbackLatency ) ; \n + return new Command ( setter , HystrixEventType . SUCCESS , 700 , uniqueArg , desiredFallbackEventType , fallbackLatency ) ; \n",Increased the timeout value for commands to accommodate Travis slowness,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCollapserTest . java \n - super ( testPropsBuilder ( ) . setCommandPropertiesDefaults ( HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) . withExecutionTimeoutInMilliseconds ( 50 ) ) ) ; \n + super ( testPropsBuilder ( ) . setCommandPropertiesDefaults ( HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) . withExecutionTimeoutInMilliseconds ( 1000 ) ) ) ; \n,Increased timeout value in HystrixObservableCollapserTest to accomodate slow Travis,329
"hystrix - contrib \ hystrix - reactivesocket - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ reactivesocket \ serialize \ SerialHystrixConfiguration . java \n + import org . slf4j . Logger ; \n + import org . slf4j . LoggerFactory ; \n + private static final Logger logger = LoggerFactory . getLogger ( SerialHystrixConfiguration . class ) ; \n + \n - System . out . println ( "" IO Exception : "" + ioe ) ; \n + logger . error ( "" IO Exception during deserialization of HystrixConfiguration : "" + ioe ) ; \n hystrix - contrib \ hystrix - reactivesocket - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ reactivesocket \ serialize \ SerialHystrixMetric . java \n + import org . slf4j . Logger ; \n + import org . slf4j . LoggerFactory ; \n + protected final static Logger logger = LoggerFactory . getLogger ( SerialHystrixMetric . class ) ; \n - System . out . println ( "" IO Exception : "" + ioe ) ; \n + logger . error ( "" IO Exception during deserialization of ByteBuffer of Hystrix Metric : "" + ioe ) ; \n hystrix - contrib \ hystrix - reactivesocket - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ reactivesocket \ serialize \ SerialHystrixUtilization . java \n + import org . slf4j . Logger ; \n + import org . slf4j . LoggerFactory ; \n + private final static Logger logger = LoggerFactory . getLogger ( SerialHystrixUtilization . class ) ; \n + \n - System . out . println ( "" IO Exception : "" + ioe ) ; \n + logger . error ( "" IO Exception during desrialization of HystrixUtilization : "" + ioe ) ; \n",Converted System . out . printlns to logger . errors,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + System . out . println ( "" RequestLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n + System . out . println ( "" RequestLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n",Add printlns to understand why some tests are failing,329
"hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ HystrixThreadPool . java \n + / / if user sets maximum < core ( or defaults get us there ) , we need to maintain invariant of core < = maximum \n + if ( ! allowSizesToDiverge ) { \n + / / if user has not opted in to allowing sizes to diverge , ensure maximum = = core \n + dynamicMaximumSize = dynamicCoreSize ; \n + } \n + \n","When user has not opted in to letting core / maximum threadpools diverge , ensure dynamic updates to coreSize apply to both",329
"hystrix - contrib \ hystrix - metrics - event - stream \ src \ main \ java \ com \ netflix \ hystrix \ contrib \ sample \ stream \ HystrixConfigurationJsonStream . java \n + json . writeBooleanField ( "" allowMaximumSizeToDivergeFromCoreSize "" , threadPoolConfig . getAllowMaximumSizeToDivergeFromCoreSize ( ) ) ; \n hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ config \ HystrixThreadPoolConfiguration . java \n + private final boolean allowMaximumSizeToDivergeFromCoreSize ; \n - int keepAliveTimeInMinutes , int rollingCounterNumberOfBuckets , \n + int keepAliveTimeInMinutes , boolean allowMaximumSizeToDivergeFromCoreSize , int rollingCounterNumberOfBuckets , \n + this . allowMaximumSizeToDivergeFromCoreSize = allowMaximumSizeToDivergeFromCoreSize ; \n + threadPoolProperties . getAllowMaximumSizeToDivergeFromCoreSize ( ) , \n - return maximumSize ; \n + if ( allowMaximumSizeToDivergeFromCoreSize ) { \n + return maximumSize ; \n + } else { \n + return coreSize ; \n + } \n + public boolean getAllowMaximumSizeToDivergeFromCoreSize ( ) { \n + return allowMaximumSizeToDivergeFromCoreSize ; \n + } \n + \n hystrix - serialization \ src \ main \ java \ com \ netflix \ hystrix \ serial \ SerialHystrixConfiguration . java \n + threadPool . getValue ( ) . path ( "" allowMaximumSizeToDivergeFromCoreSize "" ) . asBoolean ( ) , \n + json . writeBooleanField ( "" allowMaximumSizeToDivergeFromCoreSize "" , threadPoolConfig . getAllowMaximumSizeToDivergeFromCoreSize ( ) ) ; \n",Output setting around maximum thread pool size and whether this config is enabled,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n + import com . sun . javafx . collections . NonIterableChange ; \n + @ Test \n + public void testRxRetry ( ) throws Exception { \n + / / see https : / / github . com / Netflix / Hystrix / issues / 1100 \n + / / Since each command instance is single - use , the expectation is that applying the . retry ( ) operator \n + / / results in only a single execution and propagation out of that error \n + HystrixCommand < Integer > cmd = getLatentCommand ( ExecutionIsolationStrategy . THREAD , AbstractTestHystrixCommand . ExecutionResult . FAILURE , 300 , \n + AbstractTestHystrixCommand . FallbackResult . UNIMPLEMENTED , 100 ) ; \n + \n + final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n + \n + System . out . println ( System . currentTimeMillis ( ) + "" : Starting "" ) ; \n + Observable < Integer > o = cmd . toObservable ( ) . retry ( 2 ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" Created retried command : "" + o ) ; \n + \n + o . subscribe ( new Subscriber < Integer > ( ) { \n + @ Override \n + public void onCompleted ( ) { \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" : OnCompleted "" ) ; \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onError ( Throwable e ) { \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" : OnError : "" + e ) ; \n + latch . countDown ( ) ; \n + } \n + \n + @ Override \n + public void onNext ( Integer integer ) { \n + System . out . println ( System . currentTimeMillis ( ) + "" : "" + Thread . currentThread ( ) . getName ( ) + "" : OnNext : "" + integer ) ; \n + } \n + } ) ; \n + \n + latch . await ( 1000 , TimeUnit . MILLISECONDS ) ; \n + System . out . println ( System . currentTimeMillis ( ) + "" ReqLog : "" + HystrixRequestLog . getCurrentRequest ( ) . getExecutedCommandsAsString ( ) ) ; \n + } \n + \n",Added unit test that demonstrates calling . retry ( ) on an Observable produced by Hystrix does not result in deadlock,329
hystrix - core \ src \ main \ java \ com \ netflix \ hystrix \ util \ HystrixRollingPercentile . java \n + \n + / / and also make sure the percentile snapshot gets reset \n + currentPercentileSnapshot = new PercentileSnapshot ( buckets . getArray ( ) ) ; \n,Clear the percentile snapshot whenever all buckets get cleared,329
"hystrix - core \ src \ jmh \ java \ com \ netflix \ hystrix \ perf \ CommandExecutionPerfTest . java \n + import com . netflix . hystrix . strategy . concurrency . HystrixRequestContext ; \n + HystrixRequestContext requestContext ; \n + \n + @ Param ( { "" true "" , "" false "" } ) \n + public boolean setUpRequestContext ; \n + if ( setUpRequestContext ) { \n + requestContext = HystrixRequestContext . initializeContext ( ) ; \n + } \n + \n + \n + @ TearDown ( Level . Invocation ) \n + public void tearDown ( ) { \n + if ( setUpRequestContext ) { \n + requestContext . shutdown ( ) ; \n + } \n + } \n + HystrixRequestContext requestContext ; \n + \n + @ Param ( { "" true "" , "" false "" } ) \n + public boolean setUpRequestContext ; \n + if ( setUpRequestContext ) { \n + requestContext = HystrixRequestContext . initializeContext ( ) ; \n + } \n + \n + \n + @ TearDown ( Level . Invocation ) \n + public void tearDown ( ) { \n + if ( setUpRequestContext ) { \n + requestContext . shutdown ( ) ; \n + } \n + } \n - \n",Measure the impact of setting up a HystrixRequestContext,329
build . gradle \n - id ' nebula . netflixoss ' version ' 3 . 2 . 2 ' \n + id ' nebula . netflixoss ' version ' 3 . 2 . 3 ' \n,Upgrade Nebula netflixoss plugin to 3 . 2 . 3,329
hystrix - core \ build . gradle \n - compile ' io . reactivex : rxjava : 1 . 1 . 0 ' \n + compile ' io . reactivex : rxjava : 1 . 1 . 1 ' \n,Upgrade to RxJava 1 . 1 . 1,329
"build . gradle \n - pom . withXml { \n - configurations . compile . resolvedConfiguration . firstLevelModuleDependencies . each { dep - > \n - if ( dep . moduleName = = "" servlet - api "" ) { \n - asNode ( ) . dependencies [ 0 ] . dependency . find { \n - it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n - it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n - } . scope [ 0 ] . value = ' provided ' \n - } else { \n - asNode ( ) . dependencies [ 0 ] . dependency . find { \n - it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n - it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n - } . scope [ 0 ] . value = ' compile ' \n - } \n - } \n - } \n - } \n + println ( "" project . name - > "" + project . name ) \n + if ( ! project . name . equals ( "" hystrix - dashboard "" ) & & ! project . name . equals ( "" hystrix - examples - webapp "" ) ) { \n + pom . withXml { \n + configurations . compile . resolvedConfiguration . firstLevelModuleDependencies . each { dep - > \n + if ( dep . moduleName = = "" servlet - api "" ) { \n + asNode ( ) . dependencies [ 0 ] . dependency . find { \n + it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n + it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n + } . scope [ 0 ] . value = ' provided ' \n + } else { \n + asNode ( ) . dependencies [ 0 ] . dependency . find { \n + it . artifactId [ 0 ] . text ( ) = = dep . moduleName & & \n + it . groupId [ 0 ] . text ( ) = = dep . moduleGroup \n + } . scope [ 0 ] . value = ' compile ' \n + } \n + } \n + } \n + } \n + } \n",Special casing the 2 WAR artifacts to not have POMs rewritten,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixRequestLogTest . java \n - for ( int i = 0 ; i < 100 ; i + + ) { \n + for ( int i = 0 ; i < 10 ; i + + ) { \n - super ( Setter . withGroupKey ( HystrixCommandGroupKey . Factory . asKey ( "" RequestLogTestCommand "" ) ) . andCommandPropertiesDefaults ( new HystrixCommandProperties . Setter ( ) . withExecutionTimeoutInMilliseconds ( 20 ) ) ) ; \n + super ( Setter . withGroupKey ( HystrixCommandGroupKey . Factory . asKey ( "" RequestLogTestCommand "" ) ) . andCommandPropertiesDefaults ( new HystrixCommandProperties . Setter ( ) . withExecutionTimeoutInMilliseconds ( 500 ) ) ) ; \n",Increased timeout in HystrixRequestLogTest to accommodate Travis slowness,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ RollingCommandLatencyDistributionStreamTest . java \n - assertBetween ( 150 , 250 , stream . getLatestMean ( ) ) ; \n + assertBetween ( 150 , 400 , stream . getLatestMean ( ) ) ; \n - assertBetween ( 300 , 400 , stream . getLatestPercentile ( 100 . 0 ) ) ; \n + assertBetween ( 300 , 800 , stream . getLatestPercentile ( 100 . 0 ) ) ; \n",Made latency check in unit test more lenient to account for Travis slowness,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ RollingCommandLatencyDistributionStreamTest . java \n - assertBetween ( 95 , 140 , stream . getLatestMean ( ) ) ; / / now timeout latency of 300ms is there \n + assertBetween ( 95 , 250 , stream . getLatestMean ( ) ) ; / / now timeout latency of 300ms is there \n - assertBetween ( 300 , 400 , stream . getLatestPercentile ( 100 . 0 ) ) ; \n + assertBetween ( 300 , 800 , stream . getLatestPercentile ( 100 . 0 ) ) ; \n",Made latency check in unit test more lenient to account for Travis slowness,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandTest . java \n - assertEquals ( "" Expected 1 in flight but got : "" + numInFlight , 1 , numInFlight ) ; / / pool - filler still going \n + assertTrue ( "" Expected at most 1 in flight but got : "" + numInFlight , numInFlight < = 1 ) ; / / pool - filler still going \n",Made unit test more lenient on timing to accommodate Travis slowness,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixObservableCommandTest . java \n - assertEquals ( 0 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; \n - assertEquals ( 0 , circuitBreaker . metrics . getCurrentConcurrentExecutionCount ( ) ) ; \n hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ TestableExecutionHook . java \n - if ( numOnNext + numOnError + numOnCompleted ! = l . size ( ) ) { \n - System . err . println ( "" Events : "" + l . size ( ) + "" don ' t add up to the events you asked to verify "" ) ; \n - return false ; \n - } \n - boolean matchSoFar = true ; \n + boolean matchFailed = false ; \n + int actualOnNext = 0 ; \n + int actualOnError = 0 ; \n + int actualOnCompleted = 0 ; \n + \n - matchSoFar = false ; \n + matchFailed = true ; \n + } else { \n + actualOnNext + + ; \n - matchSoFar = false ; \n + matchFailed = true ; \n + } else { \n + actualOnError + + ; \n - matchSoFar = false ; \n + matchFailed = true ; \n + } else { \n + actualOnCompleted + + ; \n - return matchSoFar ; \n + if ( matchFailed ) { \n + System . out . println ( "" Expected : "" + numOnNext + "" OnNexts , "" + numOnError + "" OnErrors , and "" + numOnCompleted ) ; \n + System . out . println ( "" Actual : "" + actualOnNext + "" OnNexts , "" + actualOnError + "" OnErrors , and "" + actualOnCompleted ) ; \n + } \n + return ! matchFailed ; \n","Made errors in hook unit tests easier to debug , and removed some assertions that were not working under concurrent test runs",329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCollapserTest . java \n - super ( testPropsBuilder ( ) . setCommandPropertiesDefaults ( HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) . withExecutionTimeoutInMilliseconds ( 50 ) ) ) ; \n + super ( testPropsBuilder ( ) . setCommandPropertiesDefaults ( HystrixCommandPropertiesTest . getUnitTestPropertiesSetter ( ) . withExecutionTimeoutInMilliseconds ( 500 ) ) ) ; \n,Increased batch command timeout in HystrixCollapserTest to accommodate Travis slowness,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCollapserTest . java \n - Thread . sleep ( 200 ) ; \n + Thread . sleep ( 800 ) ; \n,Increased sleep time to make Timeout work as expected in HystrixCollapserTest,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ HystrixCommandMetricsTest . java \n - HystrixCommand < Boolean > cmd = new SuccessCommand ( key , 400 ) ; \n + HystrixCommand < Boolean > cmd = new SuccessCommand ( key , 900 ) ; \n",Increased time spent in command to allow concurrency check to work as expected,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ CumulativeThreadPoolEventCounterStreamTest . java \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 200 ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 700 ) ) ; \n",Increased the time spent in commands to ensure commands get rejected as expected,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ HealthCountsStreamTest . java \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 200 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 700 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 200 ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 700 ) ) ; \n",Increasing time spent in commands in HealthCountsStreamTest to make sure rejections happen as expected,329
"hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ HealthCountsStreamTest . java \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 700 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 400 , HystrixCommandProperties . ExecutionIsolationStrategy . SEMAPHORE ) ) ; \n - saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 700 ) ) ; \n + saturators . add ( CommandStreamTest . Command . from ( groupKey , key , HystrixEventType . SUCCESS , 400 ) ) ; \n",Reducing latency to make sure we ' re not inducing timeouts,329
hystrix - core \ src \ test \ java \ com \ netflix \ hystrix \ metric \ consumer \ HealthCountsStreamTest . java \n - Thread . sleep ( 100 ) ; \n + Thread . sleep ( 500 ) ; \n,Lengthened wait period in shortCircuited HealthCounts unit test,329
hystrix - core \ src \ jmh \ java \ com \ netflix \ hystrix \ perf \ CommandExecutionAndConcurrentMetricsReadPerfTest . java \n - public Integer writeHeavyReadMetrics ( CommandState state ) { \n + public long writeHeavyReadMetrics ( CommandState state ) { \n - return metrics . getExecutionTimeMean ( ) + metrics . getExecutionTimePercentile ( 50 ) + metrics . getExecutionTimePercentile ( 75 ) + metrics . getExecutionTimePercentile ( 99 ) ; \n + return metrics . getExecutionTimeMean ( ) \n + + metrics . getExecutionTimePercentile ( 50 ) \n + + metrics . getExecutionTimePercentile ( 75 ) \n + + metrics . getExecutionTimePercentile ( 99 ) \n + + metrics . getCumulativeCount ( HystrixEventType . SUCCESS ) \n + + metrics . getRollingCount ( HystrixEventType . FAILURE ) \n + + metrics . getRollingMaxConcurrentExecutions ( ) ; \n - public Integer evenSplitOfWritesAndReadsReadMetrics ( CommandState state ) { \n + public long evenSplitOfWritesAndReadsReadMetrics ( CommandState state ) { \n - return metrics . getExecutionTimeMean ( ) + metrics . getExecutionTimePercentile ( 50 ) + metrics . getExecutionTimePercentile ( 75 ) + metrics . getExecutionTimePercentile ( 99 ) ; \n + return metrics . getExecutionTimeMean ( ) \n + + metrics . getExecutionTimePercentile ( 50 ) \n + + metrics . getExecutionTimePercentile ( 75 ) \n + + metrics . getExecutionTimePercentile ( 99 ) \n + + metrics . getCumulativeCount ( HystrixEventType . SUCCESS ) \n + + metrics . getRollingCount ( HystrixEventType . FAILURE ) \n + + metrics . getRollingMaxConcurrentExecutions ( ) ; \n,Consistency between work being performance - tested in metrics - read JMH test,329
"new file \n build . gradle \n + apply plugin : ' java ' \n + apply plugin : ' eclipse ' \n + apply plugin : ' idea ' \n + apply plugin : ' osgi ' \n + \n + sourceCompatibility = JavaVersion . VERSION _ 1 _ 6 \n + targetCompatibility = JavaVersion . VERSION _ 1 _ 6 \n + \n + dependencies { \n + compile project ( ' : rxjava - core ' ) \n + provided ' junit : junit - dep : 4 . 10 ' \n + provided ' org . mockito : mockito - core : 1 . 8 . 5 ' \n + provided ' com . google . android : android : 4 . 0 . 1 . 2 ' \n + } \n + \n + eclipse { \n + classpath { \n + / / include ' provided ' dependencies on the classpath \n + plusConfigurations + = configurations . provided \n + \n + downloadSources = true \n + downloadJavadoc = true \n + } \n + } \n + \n + idea { \n + module { \n + / / include ' provided ' dependencies on the classpath \n + scopes . PROVIDED . plus + = configurations . provided \n + } \n + } \n + \n + javadoc { \n + options { \n + doclet = "" org . benjchristensen . doclet . DocletExclude "" \n + docletpath = [ rootProject . file ( ' . / gradle / doclet - exclude . jar ' ) ] \n + stylesheetFile = rootProject . file ( ' . / gradle / javadocStyleSheet . css ' ) \n + windowTitle = "" RxJava Javadoc $ { project . version } "" \n + } \n + options . addStringOption ( ' top ' ) . value = ' < h2 class = "" title "" style = "" padding - top : 40px "" > RxJava < / h2 > ' \n + } \n + \n + jar { \n + manifest { \n + name = ' rxjava - android ' \n + instruction ' Bundle - Vendor ' , ' Netflix ' \n + instruction ' Bundle - DocURL ' , ' https : / / github . com / Netflix / RxJava ' \n + instruction ' Import - Package ' , ' ! org . junit , ! junit . framework , ! org . mockito . * , * ' \n + } \n + } \n",Add rxjava - android build module + config \n Should this be shared with other contribs through the parent module ? Lots of copy and paste here .,332
"new file \n src \ main \ java \ rx \ concurrency \ HandlerThreadScheduler . java \n + package rx . concurrency ; \n + \n + import android . os . Handler ; \n + import rx . Scheduler ; \n + import rx . Subscription ; \n + import rx . operators . AtomicObservableSubscription ; \n + import rx . util . functions . Func2 ; \n + \n + import java . util . concurrent . TimeUnit ; \n + \n + / * * \n + * Schedules actions to run on an Android Handler thread . \n + * / \n + public class HandlerThreadScheduler extends Scheduler { \n + \n + private final Handler handler ; \n + \n + public HandlerThreadScheduler ( Handler handler ) { \n + this . handler = handler ; \n + } \n + \n + @ Override \n + public < T > Subscription schedule ( final T state , final Func2 < Scheduler , T , Subscription > action ) { \n + final AtomicObservableSubscription subscription = new AtomicObservableSubscription ( ) ; \n + final Scheduler _ scheduler = this ; \n + \n + handler . post ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + subscription . wrap ( action . call ( _ scheduler , state ) ) ; \n + } \n + } ) ; \n + return subscription ; \n + } \n + \n + @ Override \n + public < T > Subscription schedule ( final T state , final Func2 < Scheduler , T , Subscription > action , long delayTime , TimeUnit unit ) { \n + if ( delayTime = = 0 ) { \n + return schedule ( state , action ) ; \n + } else { \n + final AtomicObservableSubscription subscription = new AtomicObservableSubscription ( ) ; \n + final Scheduler _ scheduler = this ; \n + handler . postDelayed ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + subscription . wrap ( action . call ( _ scheduler , state ) ) ; \n + } \n + } , unit . toMillis ( delayTime ) ) ; \n + return subscription ; \n + } \n + } \n + } \n + \n + \n",Add HandlerThreadScheduler which schedules actions on an Android Handler thread,332
"src \ main \ java \ rx \ concurrency \ HandlerThreadScheduler . java \n - import static org . mockito . Matchers . any ; \n - import static org . mockito . Matchers . anyLong ; \n - import static org . mockito . Mockito . never ; \n + return schedule ( state , action , 0L , TimeUnit . MILLISECONDS ) ; \n + } \n + \n + @ Override \n + public < T > Subscription schedule ( final T state , final Func2 < Scheduler , T , Subscription > action , long delayTime , TimeUnit unit ) { \n - \n - handler . post ( new Runnable ( ) { \n + handler . postDelayed ( new Runnable ( ) { \n - } ) ; \n + } , unit . toMillis ( delayTime ) ) ; \n - @ Override \n - public < T > Subscription schedule ( final T state , final Func2 < Scheduler , T , Subscription > action , long delayTime , TimeUnit unit ) { \n - if ( delayTime = = 0 ) { \n - return schedule ( state , action ) ; \n - } else { \n - final AtomicObservableSubscription subscription = new AtomicObservableSubscription ( ) ; \n - final Scheduler _ scheduler = this ; \n - handler . postDelayed ( new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - subscription . wrap ( action . call ( _ scheduler , state ) ) ; \n - } \n - } , unit . toMillis ( delayTime ) ) ; \n - return subscription ; \n - } \n - } \n - \n - public void shouldScheduleActionOnHandlerThread ( ) { \n + public void shouldScheduleImmediateActionOnHandlerThread ( ) { \n - verify ( handler ) . post ( runnable . capture ( ) ) ; \n + verify ( handler ) . postDelayed ( runnable . capture ( ) , eq ( 0L ) ) ; \n - \n - @ Test \n - public void scheduleDelayedActionShouldForwardToNormalPostIfDelayIsZero ( ) { \n - final Handler handler = mock ( Handler . class ) ; \n - final Object state = new Object ( ) ; \n - final Func2 < Scheduler , Object , Subscription > action = mock ( Func2 . class ) ; \n - \n - Scheduler scheduler = new HandlerThreadScheduler ( handler ) ; \n - scheduler . schedule ( state , action , 0L , TimeUnit . SECONDS ) ; \n - \n - / / verify that we post to the given Handler \n - verify ( handler ) . post ( any ( Runnable . class ) ) ; \n - verify ( handler , never ( ) ) . postDelayed ( any ( Runnable . class ) , anyLong ( ) ) ; \n - } \n - \n","Reduce duplication by making "" schedule now "" the special case \n Forwards to "" schedule later "" with delay of 0 now .",332
new file \n src \ test \ resources \ res \ values \ . gitignore \n + # dummy so that git checks out this directory \n,Add empty . gitignore file so that git checks out the values folder,332
"src \ main \ java \ rx \ operators \ OperationObserveFromAndroidComponent . java \n + import android . os . Looper ; \n + import java . util . concurrent . Callable ; \n + import java . util . concurrent . Executors ; \n + import java . util . concurrent . Future ; \n + import java . util . concurrent . TimeUnit ; \n - private volatile AndroidComponent componentRef ; \n - private volatile Observer < ? super T > observerRef ; \n + private AndroidComponent componentRef ; \n + private Observer < ? super T > observerRef ; \n + assertUiThread ( ) ; \n + \n + private void assertUiThread ( ) { \n + if ( Looper . getMainLooper ( ) ! = Looper . myLooper ( ) ) { \n + throw new IllegalStateException ( "" Observers must subscribe from the main UI thread , but was "" + Thread . currentThread ( ) ) ; \n + } \n + } \n + @ Test \n + public void itThrowsIfObserverSubscribesFromBackgroundThread ( ) throws Exception { \n + final Future < Object > future = Executors . newSingleThreadExecutor ( ) . submit ( new Callable < Object > ( ) { \n + @ Override \n + public Object call ( ) throws Exception { \n + OperationObserveFromAndroidComponent . observeFromAndroidComponent ( \n + mockObservable , mockFragment ) . subscribe ( mockObserver ) ; \n + return null ; \n + } \n + } ) ; \n + future . get ( 1 , TimeUnit . SECONDS ) ; \n + verify ( mockObserver ) . onError ( any ( IllegalStateException . class ) ) ; \n + verifyNoMoreInteractions ( mockObserver ) ; \n + } \n + \n",Drop volatile in favor of failing fast if not subscribed from UI thread,332
src \ main \ java \ rx \ operators \ OperationObserveFromAndroidComponent . java \n - releaseReferences ( ) ; \n - releaseReferences ( ) ; \n - releaseReferences ( ) ; \n,"Only release references in unsubscribe \n We decided it ' s better to leave it to the caller when it ' s appropriate to release , cf . # 1",332
"src \ main \ java \ rx \ operators \ OperationObserveFromAndroidComponent . java \n - return Observable . create ( new OnSubscribeActivity < T > ( source , activity ) ) ; \n + return Observable . create ( new OnSubscribeBase < T , Activity > ( source , activity ) ) ; \n - private static abstract class OnSubscribeBase < T , AndroidComponent > implements Observable . OnSubscribeFunc < T > { \n + private static class OnSubscribeBase < T , AndroidComponent > implements Observable . OnSubscribeFunc < T > { \n - protected abstract boolean isComponentValid ( AndroidComponent component ) ; \n + protected boolean isComponentValid ( AndroidComponent component ) { \n + return true ; \n + } \n - private static final class OnSubscribeActivity < T > extends OnSubscribeBase < T , Activity > { \n - \n - private OnSubscribeActivity ( Observable < T > source , Activity activity ) { \n - super ( source , activity ) ; \n - } \n - \n - @ Override \n - protected boolean isComponentValid ( Activity activity ) { \n - return ! activity . isFinishing ( ) ; \n - } \n - } \n - \n - @ Test \n - public void isDoesNotForwardOnNextOnCompletedSequenceIfActivityIsFinishing ( ) { \n - PublishSubject < Integer > source = PublishSubject . create ( ) ; \n - OperationObserveFromAndroidComponent . observeFromAndroidComponent ( source , mockActivity ) . subscribe ( mockObserver ) ; \n - \n - source . onNext ( 1 ) ; \n - \n - when ( mockActivity . isFinishing ( ) ) . thenReturn ( true ) ; \n - source . onNext ( 2 ) ; \n - source . onNext ( 3 ) ; \n - source . onCompleted ( ) ; \n - \n - verify ( mockObserver ) . onNext ( 1 ) ; \n - verify ( mockObserver , never ( ) ) . onCompleted ( ) ; \n - } \n - \n - @ Test \n - public void itDoesNotForwardOnErrorIfActivityIsFinishing ( ) { \n - PublishSubject < Integer > source = PublishSubject . create ( ) ; \n - OperationObserveFromAndroidComponent . observeFromAndroidComponent ( source , mockActivity ) . subscribe ( mockObserver ) ; \n - \n - source . onNext ( 1 ) ; \n - \n - when ( mockActivity . isFinishing ( ) ) . thenReturn ( true ) ; \n - source . onError ( new Exception ( ) ) ; \n - \n - verify ( mockObserver ) . onNext ( 1 ) ; \n - verify ( mockObserver , never ( ) ) . onError ( any ( Exception . class ) ) ; \n - } \n - \n",Remove isFinishing check when calling back to activities \n We decided it ' s sufficient for the callback to be safe as long as the caller unsubscribes in onDestroy,332
"rxjava - contrib \ rxjava - android - samples - build - wrapper \ build . gradle \n - commandLine "" . / gradlew "" , "" clean "" , "" packageDebug "" , "" - PrxjVersion = $ { version } "" \n + commandLine "" . / gradlew "" , "" clean "" , "" packageDebug "" \n rxjava - contrib \ rxjava - android - samples \ samples \ build . gradle \n + / / make sure we always compile against the latest version of RxJava \n + def rootProjectProperties = new Properties ( ) \n + file ( "" . . / . . / . . / gradle . properties "" ) . withReader { reader - > \n + rootProjectProperties . load ( reader ) \n + properties . putAll ( rootProjectProperties ) \n + } \n + \n + def rxjVersion = rootProjectProperties . get ( "" version "" ) \n rxjava - contrib \ rxjava - android - samples \ samples \ src \ main \ java \ com \ netflix \ rxjava \ android \ samples \ RetainedFragment . java \n - strings = SampleObservables . numberStrings2 ( ) . cache ( ) ; \n + strings = SampleObservables . numberStrings ( ) . cache ( ) ; \n",Fix project import issue in Android Studio and a compilation failure,332
rxjava - contrib \ rxjava - android - samples \ gradle \ wrapper \ gradle - wrapper . properties \n - # Wed Mar 12 12 : 09 : 46 CET 2014 \n + # Sat Apr 05 11 : 18 : 06 CEST 2014 \n - distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 10 - all . zip \n + distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 11 - all . zip \n,Upgrade Gradle wrapper for Android samples to Gradle 1 . 11 \n Android Studio 0 . 5 . 4 refuses to build with 1 . 10,332
rxjava - core \ src \ main \ java \ rx \ operators \ OperatorToObservableList . java \n - import java . util . ArrayList ; \n - import java . util . List ; \n - \n + import java . util . ArrayList ; \n + import java . util . LinkedList ; \n + import java . util . List ; \n + \n - final List < T > list = new ArrayList < T > ( ) ; \n + final List < T > list = new LinkedList < T > ( ) ; \n,"use LinkedList to buffer the sequence’s items \n LinkedList has guaranteed constant insertion time when appending to the end of the list , whereas ArrayList takes O ( 1 ) amortized , since a reallocation might be necessary to insert further items . Since no capacity was specified for the buffer , on Hotspot this would cause the array to reallocate after the first 10 insertions , on Android after the first insertion ( since Android’s ArrayList uses a default capacity of zero . ) \n Since the buffer is copied to an ArrayList before emission , subscriber performance when working with the list should remain unaffected . \n Refs # 1141",332
"rxjava - contrib \ rxjava - android - samples \ build . gradle \n - classpath ' com . android . tools . build : gradle : 0 . 9 . + ' \n + classpath ' com . android . tools . build : gradle : 0 . 11 . + ' \n rxjava - contrib \ rxjava - android - samples \ gradle \ wrapper \ gradle - wrapper . properties \n - # Sat Apr 05 11 : 18 : 06 CEST 2014 \n + # Sat Jun 07 16 : 12 : 40 CEST 2014 \n - distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 11 - all . zip \n + distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 12 - all . zip \n rxjava - contrib \ rxjava - android - samples \ samples \ build . gradle \n - buildToolsVersion "" 19 . 0 . 0 "" \n + buildToolsVersion "" 19 . 1 . 0 "" \n",Bump build tools to 19 . 1 and android plugin to 0 . 11 \n This is to make the project compatible with Studio 0 . 6 . x,332
". gitignore \n - * . jar \n samples - build - wrapper \ build . gradle \n - if ( ! System . getenv ( "" ANDROID _ HOME "" ) ) { \n + def androidHome = System . getenv ( "" ANDROID _ HOME "" ) \n + if ( androidHome ) { \n + println "" Found ANDROID _ HOME at $ androidHome "" \n + } else { \n new file \n samples \ gradle \ wrapper \ gradle - wrapper . jar \n Binary files / dev / null and b / samples / gradle / wrapper / gradle - wrapper . jar differ \n","Do not gitignore JAR files , required for Gradle wrapper",332
build . gradle \n - testCompile ' org . robolectric : robolectric : 2 . 2 ' \n + testCompile ( ' org . robolectric : robolectric : 2 . 3 ' ) { \n + exclude group : ' com . android . support ' \n + } \n,"Bump to Robolectric 2 . 3 , make samples build under Studio 0 . 8 . + \n refs https : / / github . com / Netflix / RxJava / pull / 1449",332
"rxjava - contrib \ rxjava - android - samples \ build . gradle \n - classpath ' com . android . tools . build : gradle : 0 . 11 . + ' \n + classpath ' com . android . tools . build : gradle : 0 . 12 . + ' \n rxjava - contrib \ rxjava - android - samples \ samples \ build . gradle \n - apply plugin : ' android ' \n + apply plugin : ' com . android . application ' \n - buildToolsVersion "" 19 . 1 . 0 "" \n + buildToolsVersion "" 20 "" \n rxjava - contrib \ rxjava - android \ build . gradle \n - testCompile ' org . robolectric : robolectric : 2 . 2 ' \n + testCompile ( ' org . robolectric : robolectric : 2 . 3 ' ) { \n + exclude group : ' com . android . support ' \n + } \n","Bump to Robolectric 2 . 3 , make samples build under Studio 0 . 8 . + \n refs https : / / github . com / Netflix / RxJava / pull / 1449",332
build . gradle \n - dependencies { classpath ' com . netflix . nebula : gradle - rxjava - project - plugin : 1 . 12 . + ' } \n + dependencies { \n + classpath ' com . netflix . nebula : gradle - rxjava - project - plugin : 1 . 12 . + ' \n + classpath ' com . netflix . nebula : gradle - extra - configurations - plugin : 1 . 12 . + ' \n + } \n - \n + apply plugin : ' provided - base ' \n,Add Nebula extra - config plugin so the project actually imports / builds,332
src \ test \ java \ rx \ android \ operators \ OperatorObserveFromAndroidComponentTest . java \n - import java . lang . reflect . Constructor ; \n - import java . lang . reflect . Field ; \n - import java . lang . reflect . InvocationTargetException ; \n - import java . util . Arrays ; \n - import java . util . concurrent . Callable ; \n - import java . util . concurrent . Executors ; \n - import java . util . concurrent . Future ; \n - import java . util . concurrent . TimeUnit ; \n - import java . util . concurrent . atomic . AtomicReference ; \n - \n - \n + \n + import java . lang . reflect . Constructor ; \n + import java . lang . reflect . Field ; \n + import java . lang . reflect . InvocationTargetException ; \n + import java . util . Arrays ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n - final Observable < Integer > testObservable = Observable . from ( 1 ) \n + final Observable < Integer > testObservable = Observable . just ( 1 ) \n,Fix test compilation ( now removed method was being used ),332
rxjava - contrib \ rxjava - android - samples \ build . gradle \n - classpath ' com . android . tools . build : gradle : 0 . 8 . + ' \n + classpath ' com . android . tools . build : gradle : 0 . 9 . + ' \n,Bump Android plugin version to 0 . 9,332
"rxjava - contrib \ rxjava - android - samples - build - wrapper \ build . gradle \n - def androidHome = System . getenv ( "" ANDROID _ HOME "" ) \n - if ( androidHome . isEmpty ( ) ) { \n - println ( "" No Android SDK detected ; skipping Android samples build "" ) \n - } else { \n + def androidHome = System . getenv ( "" ANDROID _ HOME "" ) \n + if ( project . hasProperty ( ' buildAndroidSamples ' ) & & ! androidHome . isEmpty ( ) ) { \n - } \n + } \n",Trigger samples build manually via Gradle build property,332
rxjava - contrib \ rxjava - android - samples \ gradle \ wrapper \ gradle - wrapper . properties \n - # Wed Mar 12 11 : 02 : 06 CET 2014 \n + # Wed Mar 12 12 : 09 : 46 CET 2014 \n - distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 10 - bin . zip \n + distributionUrl = http \ : / / services . gradle . org / distributions / gradle - 1 . 10 - all . zip \n,Revert to using the all Gradle wrapper dist type,332
"rxjava - contrib \ rxjava - android - samples \ samples \ src \ main \ java \ com \ netflix \ rxjava \ android \ samples \ RetainedFragmentActivity . java \n - strings = SampleObservables . fakeApiCall ( 2000 ) . map ( PARSE _ JSON ) . cache ( ) ; \n + / / in retained fragments , it ' s sufficient to bind the fragment in onCreate , since \n + / / Android takes care of detaching the Activity for us , and holding a reference for \n + / / the duration of the observable does not harm . \n + strings = bindFragment ( this , SampleObservables . fakeApiCall ( 2000 ) . map ( PARSE _ JSON ) . cache ( ) ) ; \n - subscription = bindFragment ( this , strings ) . subscribe ( new Action1 < String > ( ) { \n + subscription = strings . subscribe ( new Action1 < String > ( ) { \n","Move bindFragment call in sample to onCreate \n Having it in onViewCreated is fine , but misleading , since we don ' t need to reattach retained fragments . ( the referenced object remains the same . )",332
build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 0 . 0 - alpha3 ' \n + classpath ' com . android . tools . build : gradle : 1 . 5 . 0 ' \n,Gradle Plugin : Go back to stable version to prevent warnings when using outdated pre - releases,333
library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntro . java \n - public AppIntro ( ) { \n - super ( R . layout . intro _ layout ) ; \n - } \n - \n + @ Override \n + protected int getLayoutId ( ) { \n + return R . layout . intro _ layout ; \n + } \n + \n library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntro2 . java \n - public AppIntro2 ( ) { \n - super ( R . layout . intro _ layout2 ) ; \n - } \n - \n + @ Override \n + protected int getLayoutId ( ) { \n + return R . layout . intro _ layout2 ; \n + } \n + \n library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n - private int layoutId ; \n - public AppIntroBase ( int layoutId ) \n - { \n - this . layoutId = layoutId ; \n - } \n - \n - setContentView ( layoutId ) ; \n + setContentView ( getLayoutId ( ) ) ; \n + / * * \n + * Gets the layout id of the layout used by the current activity \n + * @ return Layout to use \n + * / \n + protected abstract int getLayoutId ( ) ; \n + \n,AppIntro classes : Use overridden method to get layoutId instead of constructor,333
"library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n + handleSlideChanged ( currentFragment , null ) ; \n - * Called when the selected fragment changed \n + * Called when the selected fragment changed . This will be called automatically if the into starts or is finished via the done button . \n - * @ param newFragment Instance of the fragment which is displayed now \n + * @ param newFragment Instance of the fragment which is displayed now . This might be null if the intro has finished \n - public void onSlideChanged ( Fragment oldFragment , Fragment newFragment ) { \n + public void onSlideChanged ( @ Nullable Fragment oldFragment , @ Nullable Fragment newFragment ) { \n",AppIntroFragment : Call onSlideChanged if the intro is finished via pressing the done button,333
"library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n + handleSlideChanged ( currentFragment , null ) ; \n - * Called when the selected fragment changed \n + * Called when the selected fragment changed . This will be called automatically if the into starts or is finished via the done button . \n - * @ param newFragment Instance of the fragment which is displayed now \n + * @ param newFragment Instance of the fragment which is displayed now . This might be null if the intro has finished \n - public void onSlideChanged ( Fragment oldFragment , Fragment newFragment ) { \n + public void onSlideChanged ( @ Nullable Fragment oldFragment , @ Nullable Fragment newFragment ) { \n",AppIntroFragment : Call onSlideChanged if the intro is finished via pressing the done button,333
"library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n - ISlideBackgroundColorHolder currentSlide = ( ISlideBackgroundColorHolder ) mPagerAdapter . getItem ( position ) ; \n - ISlideBackgroundColorHolder nextSlide = ( ISlideBackgroundColorHolder ) mPagerAdapter . getItem ( position + 1 ) ; \n + Fragment currentSlide = mPagerAdapter . getItem ( position ) ; \n + Fragment nextSlide = mPagerAdapter . getItem ( position + 1 ) ; \n - int newColor = ( int ) argbEvaluator . evaluate ( positionOffset , currentSlide . getDefaultBackgroundColor ( ) , nextSlide . getDefaultBackgroundColor ( ) ) ; \n + ISlideBackgroundColorHolder currentSlideCasted = ( ISlideBackgroundColorHolder ) currentSlide ; \n + ISlideBackgroundColorHolder nextSlideCasted = ( ISlideBackgroundColorHolder ) nextSlide ; \n - currentSlide . setBackgroundColor ( newColor ) ; \n - nextSlide . setBackgroundColor ( newColor ) ; \n + / / Check if both fragments are attached to an activity , otherwise getDefaultBackgroundColor may fail . \n + if ( currentSlide . isAdded ( ) & & nextSlide . isAdded ( ) ) { \n + int newColor = ( int ) argbEvaluator . evaluate ( positionOffset , currentSlideCasted . getDefaultBackgroundColor ( ) , nextSlideCasted . getDefaultBackgroundColor ( ) ) ; \n + \n + currentSlideCasted . setBackgroundColor ( newColor ) ; \n + nextSlideCasted . setBackgroundColor ( newColor ) ; \n + } \n",AppIntroBase : Fix : Check if both fragments are attached to their activities before calling getDefaultBackgroundColor,333
"library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n - ISlideBackgroundColorHolder currentSlide = ( ISlideBackgroundColorHolder ) mPagerAdapter . getItem ( position ) ; \n - ISlideBackgroundColorHolder nextSlide = ( ISlideBackgroundColorHolder ) mPagerAdapter . getItem ( position + 1 ) ; \n + Fragment currentSlide = mPagerAdapter . getItem ( position ) ; \n + Fragment nextSlide = mPagerAdapter . getItem ( position + 1 ) ; \n - int newColor = ( int ) argbEvaluator . evaluate ( positionOffset , currentSlide . getDefaultBackgroundColor ( ) , nextSlide . getDefaultBackgroundColor ( ) ) ; \n + ISlideBackgroundColorHolder currentSlideCasted = ( ISlideBackgroundColorHolder ) currentSlide ; \n + ISlideBackgroundColorHolder nextSlideCasted = ( ISlideBackgroundColorHolder ) nextSlide ; \n - currentSlide . setBackgroundColor ( newColor ) ; \n - nextSlide . setBackgroundColor ( newColor ) ; \n + / / Check if both fragments are attached to an activity , otherwise getDefaultBackgroundColor may fail . \n + if ( currentSlide . isAdded ( ) & & nextSlide . isAdded ( ) ) { \n + int newColor = ( int ) argbEvaluator . evaluate ( positionOffset , currentSlideCasted . getDefaultBackgroundColor ( ) , nextSlideCasted . getDefaultBackgroundColor ( ) ) ; \n + \n + currentSlideCasted . setBackgroundColor ( newColor ) ; \n + nextSlideCasted . setBackgroundColor ( newColor ) ; \n + } \n",AppIntroBase : Fix : Check if both fragments are attached to their activities before calling getDefaultBackgroundColor,333
"new file \n library \ src \ main \ res \ values - sw600dp \ dimen . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + < dimen name = "" appIntroDefaultPaddingLeft "" > 80dp < / dimen > \n + < dimen name = "" appIntroDefaultPaddingRight "" > 80dp < / dimen > \n + < / resources > \n new file \n library \ src \ main \ res \ values - sw720dp \ dimen . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + < dimen name = "" appIntroDefaultPaddingLeft "" > 80dp < / dimen > \n + < dimen name = "" appIntroDefaultPaddingRight "" > 80dp < / dimen > \n + < / resources > \n",DefaultStyles : Add dimen variants for tablets to ensure correct padding,333
"new file \n library \ src \ main \ res \ values - sw600dp \ dimen . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + < dimen name = "" appIntroDefaultPaddingLeft "" > 80dp < / dimen > \n + < dimen name = "" appIntroDefaultPaddingRight "" > 80dp < / dimen > \n + < / resources > \n new file \n library \ src \ main \ res \ values - sw720dp \ dimen . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + < dimen name = "" appIntroDefaultPaddingLeft "" > 80dp < / dimen > \n + < dimen name = "" appIntroDefaultPaddingRight "" > 80dp < / dimen > \n + < / resources > \n",DefaultStyles : Add dimen variants for tablets to ensure correct padding,333
"library \ src \ main \ java \ com \ github \ paolorotolo \ appintro \ AppIntroBase . java \n - protected boolean isVibrateOn = false ; \n + \n - protected boolean baseProgressButtonEnabled = true ; \n - protected boolean progressButtonEnabled = true ; \n + protected boolean isVibrateOn = false ; \n + protected boolean baseProgressButtonEnabled = true ; \n + protected boolean progressButtonEnabled = true ; \n + private boolean isGoBackLockEnabled = false ; \n + \n + @ Override \n + public void onBackPressed ( ) \n + { \n + / / Do nothing if goBack lock is enabled \n + if ( ! isGoBackLockEnabled ) { \n + super . onBackPressed ( ) ; \n + } \n + } \n + \n + / * * \n + * Enables / Disables leaving the intro via the device ' s software / hardware back button . \n + * Note , that does does NOT lock swiping back through the slides . \n + * @ param lockEnabled Whether leaving the intro via the phone ' s back button is locked . \n + * / \n + public void setGoBackLock ( boolean lockEnabled ) { \n + isGoBackLockEnabled = lockEnabled ; \n + } \n + \n",AppIntroBase : Implement a lock which prevents the user from leaving the intro via the phones back button \n The lock can be set and unset via the method setGoBackLock,333
"build . gradle \n - classpath ' com . android . tools . build : gradle : 1 . 5 . 0 ' \n + classpath ' com . android . tools . build : gradle : 2 . 0 . 0 ' \n example \ build . gradle \n - buildToolsVersion "" 23 . 0 . 2 "" \n + buildToolsVersion "" 23 . 0 . 3 "" \n - compile ' com . android . support : appcompat - v7 : 23 . 1 . 1 ' \n + compile ' com . android . support : appcompat - v7 : 23 . 3 . 0 ' \n - androidTestCompile ' com . android . support : appcompat - v7 : 23 . 1 . 1 ' \n + androidTestCompile ' com . android . support : appcompat - v7 : 23 . 3 . 0 ' \n library \ build . gradle \n - buildToolsVersion "" 23 . 0 . 2 "" \n + buildToolsVersion "" 23 . 0 . 3 "" \n - compile ' com . android . support : support - v4 : 23 . 1 . 1 ' \n + compile ' com . android . support : support - v4 : 23 . 3 . 0 ' \n - compile ' com . android . support : support - annotations : 23 . 1 . 1 ' \n + compile ' com . android . support : support - annotations : 23 . 3 . 0 ' \n - compile ' com . android . support : appcompat - v7 : 23 . 1 . 1 ' \n + compile ' com . android . support : appcompat - v7 : 23 . 3 . 0 ' \n",General : Updated gradle plugin version to v2 . 0 . 0 and support libraries to their newest versions,333
"LICENSE \n + AppIntro library \n + \n + Copyright 2015 Paolo Rotolo \n + Copyright 2016 Maximilian Narr \n + \n + Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + you may not use this file except in compliance with the License . \n + You may obtain a copy of the License at \n + \n + http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + \n + Unless required by applicable law or agreed to in writing , software \n + distributed under the License is distributed on an "" AS IS "" BASIS , \n + WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + See the License for the specific language governing permissions and \n + limitations under the License . \n + \n + \n - END OF TERMS AND CONDITIONS \n - \n - APPENDIX : How to apply the Apache License to your work . \n - \n - To apply the Apache License to your work , attach the following \n - boilerplate notice , with the fields enclosed by brackets "" { } "" \n - replaced with your own identifying information . ( Don ' t include \n - the brackets ! ) The text should be enclosed in the appropriate \n - comment syntax for the file format . We also recommend that a \n - file or class name and description of purpose be included on the \n - same "" printed page "" as the copyright notice for easier \n - identification within third - party archives . \n - \n - Copyright { 2015 } { Paolo Rotolo } \n - \n - Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - you may not use this file except in compliance with the License . \n - You may obtain a copy of the License at \n - \n - http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - \n - Unless required by applicable law or agreed to in writing , software \n - distributed under the License is distributed on an "" AS IS "" BASIS , \n - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - See the License for the specific language governing permissions and \n - limitations under the License . \n - \n + END OF TERMS AND CONDITIONS \n","License : Updated copyright information , reordered text",333
"web - service \ experimental . py \n + \n + if not helpers . ENABLE _ EXPERIMENTAL : \n + app = webapp2 . WSGIApplication ( [ ] , debug = True ) \n web - service \ helpers . py \n - from google . appengine . api import taskqueue , urlfetch \n + try : \n + from google . appengine . api import taskqueue , urlfetch , app _ identity \n + import models \n + except Exception as e : \n + if _ _ name _ _ ! = ' _ _ main _ _ ' : \n + raise e \n + else : \n + print "" Warning : import exception ' { 0 } ' "" . format ( e ) \n + \n - import models \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + ENABLE _ EXPERIMENTAL = app _ identity . get _ application _ id ( ) . endswith ( ' - dev ' ) \n - if distance is not None : \n + if ENABLE _ EXPERIMENTAL and distance is not None : \n + \n + if _ _ name _ _ = = ' _ _ main _ _ ' : \n + for i in range ( - 22 , - 100 , - 1 ) : \n + print i , ComputeDistance ( i , - 22 ) \n",Disable experimental features outside of - dev deployement,340
"deleted file \n web - service \ local _ redirector . py \n - # ! / usr / bin / env python \n - # \n - # Copyright 2015 Google Inc . \n - # \n - # Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - # you may not use this file except in compliance with the License . \n - # You may obtain a copy of the License at \n - # \n - # http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - # \n - # Unless required by applicable law or agreed to in writing , software \n - # distributed under the License is distributed on an "" AS IS "" BASIS , \n - # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - # See the License for the specific language governing permissions and \n - # limitations under the License . \n - # \n - \n - import SimpleHTTPServer \n - import SocketServer \n - \n - class myHandler ( SimpleHTTPServer . SimpleHTTPRequestHandler ) : \n - def do _ GET ( self ) : \n - try : \n - rssi = float ( self . headers [ ' X - PhysicalWeb - Rssi ' ] ) \n - txpower = float ( self . headers [ ' X - PhysicalWeb - TxPower ' ] ) \n - path _ loss = txpower - rssi ; \n - except : \n - path _ loss = None \n - \n - if path _ loss > 50 : \n - self . send _ response ( 204 ) \n - else : \n - self . send _ response ( 301 ) \n - # redirect to same path on goo . gl ! \n - self . send _ header ( ' Location ' , ' https : / / goo . gl / ' + self . path ) \n - self . end _ headers ( ) \n - \n - PORT = 8800 \n - handler = SocketServer . TCPServer ( ( "" "" , PORT ) , myHandler ) \n - print "" serving at port { 0 } "" . format ( PORT ) \n - handler . serve _ forever ( ) \n",Removing standalone redirector since its now part of experimental / PWS endpoint,340
"web - service \ helpers . py \n - metadata _ output = RankedResponse ( metadata _ output ) \n - # TODO : remove txpower and rssi keys \n + def ReplaceRssiTxPowerWithPathLossAsRank ( device _ data ) : \n + try : \n + path _ loss = device _ data [ ' txpower ' ] - device _ data [ ' rssi ' ] \n + device _ data [ ' rank ' ] = path _ loss \n + except : \n + # TODO : We could leave rank off , but this makes clients job easier \n + device _ data [ ' rank ' ] = 1000 . 0 \n + finally : \n + del device _ data [ ' txpower ' ] \n + del device _ data [ ' rssi ' ] \n + return device _ data \n + \n + metadata _ output = map ( ReplaceRssiTxPowerWithPathLossAsRank , RankedResponse ( metadata _ output ) ) \n","Proxy Service includes "" rank "" value to better sort on clients \n Currently the rank is set to the signal path loss , but may include other \n signals in the future . If the requests includes multiple values , they \n will be sorted on the server automatically . However , this rank value is \n useful for merging separate replies from multiple independant metadata \n requests on the client .",340
"web - service \ helpers . py \n - if dista is None and distb is None : \n - return 0 # No winner \n - if dista is None : \n - return - 1 # assume b is closer \n - if distb is None : \n - return 1 # assume a is closer \n - return int ( dista - distb ) \n + return cmp ( dista , distb ) \n",Use the python builtin cmp to help sorting,340
"web - service \ tests . py \n + REMOTE _ DEV _ ENDPOINT = ' http : / / url - caster - dev . appspot . com / resolve - scan ' \n - def testDemoData ( ) : \n + def testDemoData ( endpoint ) : \n - result = resolveScanForValues ( LOCAL _ ENDPOINT , values ) \n + result = resolveScanForValues ( endpoint , values ) \n - def testRssiRanking ( ) : \n + def testRssiRanking ( endpoint ) : \n - result = resolveScanForValues ( LOCAL _ ENDPOINT , values ) \n + result = resolveScanForValues ( endpoint , values ) \n - testDemoData ( ) \n - testRssiRanking ( ) \n + testDemoData ( LOCAL _ ENDPOINT ) \n + testRssiRanking ( LOCAL _ ENDPOINT ) \n",Update tests to work with - dev server,340
web - service \ tests . py \n - ' longUrl ' : ' www . github . com / Google / physical - web ' \n + ' longUrl ' : ' http : / / www . github . com / Google / physical - web ' \n,Add http : / / prefix to url shortener test,340
web - service \ tests . py \n - testDemoData ( LOCAL _ ENDPOINT ) \n - testRssiRanking ( LOCAL _ ENDPOINT ) \n - testUrlShortener ( LOCAL _ ENDPOINT ) \n + endpoint = LOCAL _ ENDPOINT \n + testDemoData ( endpoint ) \n + testRssiRanking ( endpoint ) \n + testUrlShortener ( endpoint ) \n,"Minor change , make it easier to swap PWS testing endpoint",340
"web - service \ handlers . py \n - # logging . info ( ' refreshing ' + url ) \n - siteInfo = models . SiteInformation . get _ by _ id ( url ) \n - siteInfo = helpers . FetchAndStoreUrl ( siteInfo , url ) \n + helpers . RefreshUrl ( url ) \n web - service \ helpers . py \n + def RefreshUrl ( url ) : \n + siteInfo = models . SiteInformation . get _ by _ id ( url ) \n + \n + # If we ' ve done an update within the last 5 seconds , don ' t do another one . \n + # This is just to prevent abuse , accidental or otherwise \n + if siteInfo . updated _ on > datetime . datetime . now ( ) - datetime . timedelta ( seconds = 5 ) : \n + logging . info ( ' Skipping RefreshUrl for url : ' + url ) \n + return \n + \n + # Update the timestamp before starting the request \n + siteInfo . put ( ) \n + \n + siteInfo = FetchAndStoreUrl ( siteInfo , url ) \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n",Don ' t RefreshUrl more often than every 5 seconds,340
"web - service \ helpers . py \n - # If we ' ve done an update within the last 5 seconds , don ' t do another one . \n - # This is just to prevent abuse , accidental or otherwise \n - if siteInfo . updated _ on > datetime . datetime . now ( ) - datetime . timedelta ( seconds = 5 ) : \n - logging . info ( ' Skipping RefreshUrl for url : ' + url ) \n - return \n - \n - # Update the timestamp before starting the request \n - siteInfo . put ( ) \n + if siteInfo is not None : \n + # If we ' ve done an update within the last 5 seconds , don ' t do another one . \n + # This is just to prevent abuse , accidental or otherwise \n + if siteInfo . updated _ on > datetime . datetime . now ( ) - datetime . timedelta ( seconds = 5 ) : \n + logging . info ( ' Skipping RefreshUrl for url : ' + url ) \n + return \n + \n + # Update the timestamp before starting the request \n + siteInfo . put ( ) \n web - service \ tests . py \n + import urllib \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + def testRefreshUrl ( endpoint ) : \n + params = { ' url ' : ' https : / / github . com / google / physical - web ' } \n + req = urllib2 . Request ( endpoint + ' / refresh - url ? ' + urllib . urlencode ( params ) , ' ' ) \n + response = urllib2 . urlopen ( req ) \n + ret = response . read ( ) \n + print ret \n + \n + testRefreshUrl ( endpoint ) \n","Add test for RefreshUrl , and fix issue with refreshing a new url",340
"web - service \ handlers . py \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + class GooglRedirect ( webapp2 . RequestHandler ) : \n + def get ( self , path ) : \n + try : \n + rssi = float ( self . request . headers [ ' X - PhysicalWeb - Rssi ' ] ) \n + txpower = float ( self . request . headers [ ' X - PhysicalWeb - TxPower ' ] ) \n + path _ loss = txpower - rssi ; \n + except : \n + path _ loss = None \n + \n + if path _ loss > 50 : \n + self . status _ code ( 204 ) \n + return \n + \n + self . redirect ( ' http : / / goo . gl / { 0 } ' . format ( path ) ) \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + ( ' / googl / ( . * ) ' , GooglRedirect ) , \n web - service \ helpers . py \n - siteInfo = models . SiteInformation . get _ or _ insert ( url , \n + siteInfo = models . SiteInformation . get _ or _ insert ( url , \n web - service \ tests . py \n - ' url ' : ' http : / / localhost : 8800 / KYvLwO ' , \n + ' url ' : endpoint + ' / googl / KYvLwO ' , \n + { \n + ' url ' : endpoint + ' / googl / r8iJqW ' , \n + ' rssi ' : - 91 , \n + ' txpower ' : - 22 , \n + ' force ' : True \n + } , \n",Adding a conditional redirector to PWS for test,340
web - service \ handlers . py \n + rssi = None \n + txpower = None \n - if path _ loss > 40 : \n + if path _ loss > 60 : \n,Add some much needed logging to help diagnose server issues,340
"web - service \ helpers . py \n - append _ invalid ( ) \n - # append _ invalid ( ) \n + logging . info ( ' GetSiteInfoForUrl url : { 0 } , rssi : { 1 } , txpower : { 2 } ' . format ( url , rssi , txpower ) ) \n + \n - return StoreInvalidUrl ( siteInfo , url ) \n + return None \n + logging . info ( ' FetchAndStoreUrl url : { 0 } , status _ code : { 1 } ' . format ( url , result . status _ code ) ) \n - return StoreInvalidUrl ( siteInfo , url ) \n + return None \n - def StoreInvalidUrl ( siteInfo , url ) : \n - if siteInfo is None : \n - siteInfo = models . SiteInformation . get _ or _ insert ( url , \n - url = url , \n - title = None , \n - favicon _ url = None , \n - description = None , \n - jsonlds = None ) \n - else : \n - # Don ' t update if it was already cached . \n - siteInfo . put ( ) \n - \n - return siteInfo \n - \n - # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n - \n web - service \ tests . py \n + def testInvalidData ( endpoint ) : \n + values = { \n + ' objects ' : [ \n + { ' url ' : ' http : / / totallybadurlthatwontwork . com / ' } , \n + { ' usdf ' : ' http : / / badkeys ' } , \n + ] \n + } \n + \n + result = resolveScanForValues ( endpoint , values ) \n + print json . dumps ( result , indent = 4 ) \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + testInvalidData ( endpoint ) \n",Do not store invalid urls in the cache,340
"web - service \ README . md \n + 2 . Install pyyaml ` pip install pyyaml ` \n web - service \ tests . py \n - \n + import yaml \n + def GetAppSettings ( ) : \n + with open ( ' app . yaml ' , ' r ' ) as f : \n + return yaml . load ( f ) \n + \n + settings = GetAppSettings ( ) \n + if not settings [ ' application ' ] . endswith ( ' - dev ' ) : \n + return \n + \n",Fix # 365 : Don ' t run experimental tests when server not in dev mode,340
web - service \ helpers . py \n - PHYSICAL _ WEB _ USER _ AGENT = ' Mozilla / 5 . 0 ( compatible ; PhysicalWeb / 1 . 0 ; + http : / / physical - web . org ) ' \n - headers = { ' User - Agent ' : PHYSICAL _ WEB _ USER _ AGENT } \n + headers = { } \n,"Revert "" [ PWS ] Added Physical Web User Agent "" \n This reverts commit 1e5cbcca7725b2a5410cf417c84c7263804fbcca .",340
"web - service \ README . md \n - 2 . Install pyyaml ` pip install pyyaml ` \n web - service \ tests . py \n - import yaml \n - def GetAppSettings ( ) : \n - with open ( ' app . yaml ' , ' r ' ) as f : \n - return yaml . load ( f ) \n - \n + _ ENABLE _ EXPERIMENTAL = False \n + @ property \n + def ENABLE _ EXPERIMENTAL ( self ) : \n + PwsTest . _ ENABLE _ EXPERIMENTAL \n + \n - settings = GetAppSettings ( ) \n - if not settings [ ' application ' ] . endswith ( ' - dev ' ) : \n + if not self . ENABLE _ EXPERIMENTAL : \n - ' - e ' , ' - - endpoint ' , dest = ' endpoint ' , default = ' AUTO ' , \n + ' - e ' , ' - - endpoint ' , dest = ' endpoint ' , default = ' auto ' , \n - ' AUTO : { } ( server starts automatically ) \ n ' \n - ' LOCAL : http : / / localhost : 8080 \ n ' \n - ' PROD : http : / / url - caster . appspot . com \ n ' \n - ' DEV : http : / / url - caster - dev . appspot . com \ n ' \n + ' auto : { } ( server starts automatically ) \ n ' \n + ' local : http : / / localhost : 8080 \ n ' \n + ' prod : http : / / url - caster . appspot . com \ n ' \n + ' dev : http : / / url - caster - dev . appspot . com \ n ' \n + parser . add _ argument ( ' - x ' , ' - - experimental ' , dest = ' experimental ' , action = ' store _ true ' , default = False ) \n - if endpoint = = ' AUTO ' : \n + if endpoint . lower ( ) = = ' auto ' : \n - elif endpoint = = ' LOCAL ' : \n + elif endpoint . lower ( ) = = ' local ' : \n - elif endpoint = = ' PROD ' : \n + elif endpoint . lower ( ) = = ' prod ' : \n - elif endpoint = = ' DEV ' : \n + elif endpoint . lower ( ) = = ' dev ' : \n + PwsTest . ENABLE _ EXPERIMENTAL = args . experimental \n",Fix # 365 : Change to use flag instead of auto - detecting,340
"web - service \ handlers . py \n - metadata _ output = helpers . BuildResponse ( objects ) \n - output = { \n - ' metadata ' : metadata _ output \n - } \n + output = helpers . BuildResponse ( objects ) \n + \n - metadata _ output = helpers . BuildResponse ( objects ) \n - output = { \n - ' metadata ' : metadata _ output \n - } \n + output = helpers . BuildResponse ( objects ) \n + \n web - service \ helpers . py \n + unresolved _ output = [ ] \n - metadata _ output . append ( { \n - ' id ' : url , \n - ' url ' : url \n + unresolved _ output . append ( { \n + ' id ' : url \n - siteInfo = GetSiteInfoForUrl ( url , distance , force _ update ) \n + try : \n + siteInfo = GetSiteInfoForUrl ( url , distance , force _ update ) \n + except FailedFetchException : \n + append _ invalid ( ) \n + continue \n + # No Content \n - return metadata _ output \n + \n + ret = { \n + "" metadata "" : metadata _ output , \n + "" unresolved "" : unresolved _ output , \n + } \n + \n + return ret \n + class FailedFetchException ( Exception ) : \n + pass \n + \n - return None \n + raise FailedFetchException ( ) \n - return None \n + raise FailedFetchException ( ) \n","Adding support for unresolved urls , by including a new key in resolve - scan output",340
web - service \ helpers . py \n - # TODO : What do we return ? we want to filter this result out \n + elif 500 < = result . status _ code < = 599 : \n + return None \n,Don ' t include 500 ' s in unresolved results,340
"web - service \ helpers . py \n + # TODO : change url to the original url ( perhaps minus our goo . gl shortened values ) \n + # TODO : change displayUrl to the "" most applicable "" url ( resolve shorteners , but perhaps not all redirects ) \n + device _ data [ ' displayUrl ' ] = siteInfo . url \n web - service \ tests . py \n + self . assertIn ( ' displayUrl ' , result [ ' metadata ' ] [ 0 ] ) \n + # TODO : This url may change to the original url \n + self . assertEqual ( result [ ' metadata ' ] [ 0 ] [ ' displayUrl ' ] , \n + ' https : / / github . com / Google / physical - web ' ) \n",Add new displayUrl value to resolve - scan,340
web - service \ helpers . py \n - title = FlattenString ( title . encode ( encoding ) ) \n + title = FlattenString ( title ) \n - description = FlattenString ( description . encode ( encoding ) ) \n + description = FlattenString ( description ) \n,"Revert "" [ PWS ] Fixed encoding on title and description metadata "" \n This reverts commit 48b9e3493521cb67e4f19aabbac050ccd677b1b0 .",340
"web - service \ helpers . py \n + # Icon \n - # make sure the icon exists \n - try : \n - result = urlfetch . fetch ( icon , method = ' HEAD ' ) \n - if result . status _ code ! = 200 : \n - icon = None \n - else : \n - contentType = result . headers [ ' Content - Type ' ] \n - if contentType is None : \n - icon = None \n - elif ( contentType ! = ' application / octet - stream ' and \n - not contentType . startswith ( ' image / ' ) ) : \n - icon = None \n - except : \n - s _ url = url \n - s _ icon = icon \n - if s _ url is None : \n - s _ url = ' [ none ] ' \n - if s _ icon is None : \n - s _ icon = ' [ none ] ' \n - logging . warning ( ' icon error with ' + s _ url + ' - > ' + s _ icon ) \n - icon = None \n + # json - lds \n + # Add to cache \n + # Add a new value \n","Remove icon HEAD fetch \n Don ' t check for the existance of the icon . Trust the site is configured \n correctly , and so trust to markdown provided icon url . \n The clients will still handle erorrs fetching the content , so don ' t slow \n down metdata fetching here .",340
"android \ PhysicalWeb \ app \ src \ main \ java \ org \ physical _ web \ physicalweb \ PwsClient . java \n - private static String constructUrlStr ( final String path ) { \n - return PROD _ URL + "" / "" + path ; \n + private String constructUrlStr ( final String path ) { \n + return mEndpointUrl + "" / "" + path ; \n",Fix # 401 : Use dev endpoint in debug mode,340
"web - service \ tests . py \n + req . add _ header ( "" Content - Type "" , "" application / json "" ) \n - ' txpower ' : - 22 , \n - ' force ' : True , \n + ' txpower ' : - 22 \n - ' txpower ' : - 22 , \n - ' force ' : True , \n + ' txpower ' : - 22 \n - \n + \n - \n + \n",Fixing tests . py to add more compliant json communications,340
"web - service \ helpers . py \n + return RankedResponse ( metadata _ output ) \n + \n + # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n + \n + def RankedResponse ( metadata _ output ) : \n + def ComputeDistance ( obj ) : \n + try : \n + rssi = int ( obj [ "" rssi "" ] ) \n + tx = int ( obj [ "" tx "" ] ) \n + if rssi = = 127 : \n + # TODO : What does rssi 127 mean , compared to no value ? \n + return None \n + path _ loss = tx - rssi \n + distance = pow ( 10 . 0 , path _ loss - 41 ) \n + return distance \n + except : \n + return None \n + \n + def SortByDistanceCmp ( a , b ) : \n + dista , distb = ComputeDistance ( a ) , ComputeDistance ( b ) \n + if dista is None and distb is None : \n + return 0 # No winner \n + if dista is None : \n + return - 1 # assume b is closer \n + if distb is None : \n + return 1 # assume a is closer \n + return distb - dista # We want smaller distance first \n + \n + metadata _ output . sort ( SortByDistanceCmp ) \n","First attempt at server side ranking , derived from Hoa ' s original \n distance score patch",340
"web - service \ helpers . py \n - device _ data [ ' groupid ' ] = ComputeGroupId ( url , siteInfo . title , siteInfo . description ) \n + device _ data [ ' groupid ' ] = ComputeGroupId ( siteInfo . url , siteInfo . title , siteInfo . description ) \n - seed = domain + title \n + seed = domain + ' \ 0 ' + title \n","Update groupid to use final Url , and update how we create groupid seed",340
"web - service \ helpers . py \n - from urlparse import urljoin , urlparse \n + from urlparse import urljoin , urlparse , urlsplit , urlunsplit \n + # Url fragment is usually not preserved across fetches , so store request fragment here . \n + url _ fragment = parsed _ url . fragment \n + \n + scheme , netloc , path , query , _ = urlsplit ( siteInfo . url ) \n + finalUrl = urlunsplit ( ( scheme , netloc , path , query , url _ fragment ) ) \n + \n - device _ data [ ' url ' ] = siteInfo . url \n + device _ data [ ' url ' ] = finalUrl \n - device _ data [ ' displayUrl ' ] = siteInfo . url \n + device _ data [ ' displayUrl ' ] = finalUrl \n",Fix # 556 - Persist url fragment in PWS fetch,340
"web - service \ helpers . py \n - # Url fragment is usually not preserved across fetches , so store request fragment here . \n - url _ fragment = parsed _ url . fragment \n - \n - scheme , netloc , path , query , _ = urlsplit ( siteInfo . url ) \n - finalUrl = urlunsplit ( ( scheme , netloc , path , query , url _ fragment ) ) \n + scheme , netloc , path , query , fragment = urlsplit ( siteInfo . url ) \n + if fragment = = ' ' : \n + fragment = parsed _ url . fragment \n + finalUrl = urlunsplit ( ( scheme , netloc , path , query , fragment ) ) \n + \n + scheme , netloc , path , query , fragment = urlsplit ( final _ url ) \n + if fragment = = ' ' : \n + fragment = urlparse ( url ) . fragment \n + final _ url = urlunsplit ( ( scheme , netloc , path , query , fragment ) ) \n + \n",Fix # 556 : Use fragments which come from redirectors,340
"new file \n ios \ PhyWeb \ third - party \ uribeacon \n + Subproject commit 11616693b00e4edeba3f9eac9f39cdc7baf4fffd \n web - service \ helpers . py \n - # Try to find web manifest < link rel = "" manifest "" href = "" . . . "" > . \n - value = htmltree . xpath ( "" / / link [ @ rel = ' manifest ' ] / attribute : : href "" ) \n - if ( len ( value ) > 0 ) : \n - # Fetch web manifest . \n - manifestUrl = value [ 0 ] \n - if "" : / / "" not in manifestUrl : \n - manifestUrl = urljoin ( url , manifestUrl ) \n - try : \n - result = urlfetch . fetch ( manifestUrl ) \n - if result . status _ code = = 200 : \n - manifestData = json . loads ( result . content ) \n - if ' short _ name ' in manifestData : \n - title = manifestData [ ' short _ name ' ] \n - else : \n - title = manifestData [ ' name ' ] \n - except : \n - pass \n + # TODO ( mmocny ) : Removing until we test for URL = = manifestData [ ' start _ url ' ] \n + # . . will need to adjust to site root . \n + # \n + # # Try to find web manifest < link rel = "" manifest "" href = "" . . . "" > \n + # value = htmltree . xpath ( "" / / link [ @ rel = ' manifest ' ] / attribute : : href "" ) \n + # if ( len ( value ) > 0 ) : \n + # # Fetch web manifest . \n + # manifestUrl = value [ 0 ] \n + # if "" : / / "" not in manifestUrl : \n + # manifestUrl = urljoin ( url , manifestUrl ) \n + # try : \n + # result = urlfetch . fetch ( manifestUrl ) \n + # if result . status _ code = = 200 : \n + # manifestData = json . loads ( result . content ) \n + # if ' short _ name ' in manifestData : \n + # title = manifestData [ ' short _ name ' ] \n + # else : \n + # title = manifestData [ ' name ' ] \n + # except : \n + # pass \n",remove support for Web App Manifest from PWS,340
"libraries \ tools \ kotlin - gradle - plugin - integration - tests \ src \ test \ kotlin \ org \ jetbrains \ kotlin \ gradle \ KaptIncrementalWithIsolatingApt . kt \n + / / https : / / youtrack . jetbrains . com / issue / KTI - 405 \n + if ( System . getProperty ( "" os . name "" ) ? . toLowerCase ( ) ? . contains ( "" windows "" ) = = true ) return \n + \n",Disable test on Windows \n # KTI - 405,344
"plugins \ kapt3 \ kapt3 - base \ src \ org \ jetbrains \ kotlin \ kapt3 \ base \ util \ java9Utils . kt \n - fun isJava9OrLater ( ) : Boolean = ! System . getProperty ( "" java . version "" ) . startsWith ( "" 1 . "" ) \n - fun isJava11OrLater ( ) : Boolean { \n - val majorVersion = System . getProperty ( "" java . version "" ) . substringBefore ( "" . "" ) \n - if ( majorVersion . isEmpty ( ) ) return false \n + private fun getJavaVersion ( ) : Int = \n + System . getProperty ( "" java . specification . version "" ) ? . substringAfter ( ' . ' ) ? . toIntOrNull ( ) ? : 6 \n - return try { \n - majorVersion . toInt ( ) > = 11 \n - } catch ( ignored : Throwable ) { \n - false \n - } \n - } \n + fun isJava9OrLater ( ) = getJavaVersion ( ) > = 9 \n + fun isJava11OrLater ( ) = getJavaVersion ( ) > = 11 \n",Properly extract JVM version in kapt \n # KT - 41788,344
"build . gradle . kts \n + dependsOn ( "" : kotlin - annotation - processing - base : test "" ) \n plugins \ kapt3 \ kapt3 - base \ build . gradle . kts \n + testRuntimeOnly ( toolsJar ( ) ) \n + \n + testCompileOnly ( toolsJarApi ( ) ) \n",Enable kotlin - annotation - processing - base tests on TC,344
"plugins \ kapt3 \ kapt3 - base \ test \ KaptPathsTest . kt \n + if ( System . getProperty ( "" os . name "" ) . toLowerCase ( ) . contains ( "" win "" ) ) return \n",Don ' t run KaptPathsTest . testSymbolicLinks test on Windows,344
"build . gradle . kts \n + dependsOn ( "" : kotlin - annotation - processing - cli : test "" ) \n",Enable kotlin - annotation - processing - cli tests on TC,344
compiler \ light - classes \ src \ org \ jetbrains \ kotlin \ asJava \ classes \ ultraLightMembersCreator . kt \n - \n - if ( ktFunction . modifierList ? . hasSuspendModifier ( ) = = true & & ktFunction . isPrivate ( ) ) { \n - return emptyList ( ) \n - } \n - \n compiler \ light - classes \ src \ org \ jetbrains \ kotlin \ asJava \ classes \ ultraLightParameters . kt \n + import org . jetbrains . kotlin . psi . psiUtil . isPrivate \n - get ( ) = computeQualifiedNameForNullabilityAnnotation ( ktType ) \n + get ( ) = if ( ! ktFunction . isPrivate ( ) ) computeQualifiedNameForNullabilityAnnotation ( ktType ) else null \n plugins \ uast - kotlin \ testData \ Suspend . log - ide . txt \n - UMethod ( name = Context ) \n + UParameter ( name = $ completion ) \n + UAnnotation ( fqName = null ) \n + UMethod ( name = Context ) \n plugins \ uast - kotlin \ testData \ Suspend . log . txt \n - UMethod ( name = Context ) \n + UParameter ( name = $ completion ) \n + UAnnotation ( fqName = null ) \n + UMethod ( name = Context ) \n plugins \ uast - kotlin \ testData \ Suspend . render - ide . txt \n - public fun Context ( ) = UastEmptyExpression \n - fun suspendPrivate ( ) : int { \n + private final fun suspendPrivate ( @ null $ completion : kotlin . coroutines . Continuation < ? super java . lang . Integer > ) : java . lang . Object { \n + public fun Context ( ) = UastEmptyExpression \n plugins \ uast - kotlin \ testData \ Suspend . render . txt \n - public fun Context ( ) = UastEmptyExpression \n - fun suspendPrivate ( ) : int { \n + private final fun suspendPrivate ( @ null $ completion : kotlin . coroutines . Continuation < ? super java . lang . Integer > ) : java . lang . Object { \n + public fun Context ( ) = UastEmptyExpression \n,Fix ultra light class generation for private suspend methods,344
"idea \ jvm - debugger \ jvm - debugger - test \ test \ org \ jetbrains \ kotlin \ idea \ debugger \ test \ IrKotlinSteppingTestGenerated . java \n + @ TestMetadata ( "" kt44074 . kt "" ) \n + public void testKt44074 ( ) throws Exception { \n + runTest ( "" idea / jvm - debugger / jvm - debugger - test / testData / stepping / stepOver / kt44074 . kt "" ) ; \n + } \n + \n idea \ jvm - debugger \ jvm - debugger - test \ test \ org \ jetbrains \ kotlin \ idea \ debugger \ test \ KotlinSteppingTestGenerated . java \n + @ TestMetadata ( "" kt44074 . kt "" ) \n + public void testKt44074 ( ) throws Exception { \n + runTest ( "" idea / jvm - debugger / jvm - debugger - test / testData / stepping / stepOver / kt44074 . kt "" ) ; \n + } \n + \n new file \n idea \ jvm - debugger \ jvm - debugger - test \ testData \ stepping \ stepOver \ kt44074 . kt \n + package test \n + \n + fun main ( ) { \n + val toSet = setOf < Int > ( ) \n + val clusterToReports = toSet . groupBy { it } \n + val updatedClusters = mutableListOf < Int > ( ) \n + / / Breakpoint ! \n + updatedClusters . addAll ( clusterToReports . map { it . value [ 0 ] } ) / / step over here \n + test ( updatedClusters ) \n + } \n + \n + fun test ( a : Any ) { \n + \n + } \n new file \n idea \ jvm - debugger \ jvm - debugger - test \ testData \ stepping \ stepOver \ kt44074 . out \n + LineBreakpoint created at kt44074 . kt : 8 \n + Run Java \n + Connected to the target VM \n + kt44074 . kt : 8 \n + kt44074 . kt : 9 \n + Disconnected from the target VM \n + \n + Process finished with exit code 0 \n",Add test for KT - 44074 \n # KT - 44074,344
"compiler \ fir \ analysis - tests \ tests - gen \ org \ jetbrains \ kotlin \ test \ runners \ codegen \ FirBlackBoxCodegenTestGenerated . java \n + @ Test \n + @ TestMetadata ( "" 26360 . kt "" ) \n + public void test26360 ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / jvm8 / defaults / 26360 . kt "" ) ; \n + } \n + \n new file \n compiler \ testData \ codegen \ box \ jvm8 \ defaults \ 26360 . kt \n + / / ! JVM _ TARGET : 1 . 8 \n + / / ! JVM _ DEFAULT _ MODE : enable \n + / / WITH _ RUNTIME \n + / / TARGET _ BACKEND : JVM \n + interface Base { \n + fun value ( ) : String \n + } \n + \n + interface SubA : Base \n + \n + interface SubB : Base { \n + @ JvmDefault \n + override fun value ( ) : String = "" OK "" \n + } \n + \n + interface SubAB : SubA , SubB \n + \n + fun box ( ) : String { \n + return object : SubAB { } . value ( ) \n + } \n compiler \ tests - common - new \ tests - gen \ org \ jetbrains \ kotlin \ test \ runners \ codegen \ BlackBoxCodegenTestGenerated . java \n + @ Test \n + @ TestMetadata ( "" 26360 . kt "" ) \n + public void test26360 ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / jvm8 / defaults / 26360 . kt "" ) ; \n + } \n + \n compiler \ tests - common - new \ tests - gen \ org \ jetbrains \ kotlin \ test \ runners \ codegen \ IrBlackBoxCodegenTestGenerated . java \n + @ Test \n + @ TestMetadata ( "" 26360 . kt "" ) \n + public void test26360 ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / jvm8 / defaults / 26360 . kt "" ) ; \n + } \n + \n compiler \ tests - gen \ org \ jetbrains \ kotlin \ codegen \ LightAnalysisModeTestGenerated . java \n + @ TestMetadata ( "" 26360 . kt "" ) \n + public void test26360 ( ) throws Exception { \n + runTest ( "" compiler / testData / codegen / box / jvm8 / defaults / 26360 . kt "" ) ; \n + } \n + \n",Test for obsolete KT - 26360 \n # KT - 26360,344
"compiler \ android - tests \ tests \ org \ jetbrains \ kotlin \ android \ tests \ emulator \ Emulator . java \n + System . out . println ( "" Setting ANDROID _ HOME / ANDROID _ SDK _ ROOT : "" + pathManager . getAndroidSdkRoot ( ) ) ; \n + bootCheckCommand . withEnvironment ( "" ANDROID _ SDK _ ROOT "" , pathManager . getAndroidSdkRoot ( ) ) ; \n + bootCheckCommand . withEnvironment ( "" ANDROID _ HOME "" , pathManager . getAndroidSdkRoot ( ) ) ; \n + \n",Set ANDROID _ HOME / ANDROID _ SDK _ ROOT for android box tests \n In some cases emulator execution on TC fails cause of problem with pathes,344
"compiler \ android - tests \ android - module \ build . gradle \n - ext { \n - isD8Enabled = project . findProperty ( ' android . enableD8 ' ) . toBoolean ( ) \n - } \n - if ( isD8Enabled ) { \n - compileOptions { \n - sourceCompatibility = 1 . 8 \n - targetCompatibility = 1 . 8 \n - } \n + compileOptions { \n + sourceCompatibility = 1 . 8 \n + targetCompatibility = 1 . 8 \n + jvm80 { \n + dimension "" box "" \n + } \n - if ( isD8Enabled ) { \n - jvm80 { \n - dimension "" box "" \n - } \n - \n - reflectjvm80 { \n - dimension "" box "" \n - } \n + reflectjvm80 { \n + dimension "" box "" \n compiler \ android - tests \ android - module \ gradle . properties \n - android . builder . sdkDownload = false \n - android . enableD8 = true \n + android . builder . sdkDownload = false \n compiler \ android - tests \ tests \ org \ jetbrains \ kotlin \ android \ tests \ CodegenTestsOnAndroidRunner . kt \n - \n - renameFlavorFolder ( ) \n - enableD8 ( false ) \n - runTestsOnEmulator ( gradleRunner , TestSuite ( "" DX "" ) ) . apply { \n - ( 0 until this . countTestCases ( ) ) . forEach { \n - val testCase = testAt ( it ) as TestCase \n - testCase . name + = "" _ DX "" \n - } \n - rootSuite . addTest ( this ) \n - } \n - private fun enableD8 ( enable : Boolean ) { \n - val file = File ( pathManager . androidTmpFolder , "" gradle . properties "" ) \n - val lines = file . readLines ( ) . map { \n - if ( it . startsWith ( "" android . enableD8 = "" ) ) { \n - "" android . enableD8 = $ enable "" \n - } else it \n - } \n - file . writeText ( lines . joinToString ( "" \ n "" ) ) \n - } \n - \n",Don ' t run dx test in emulator,344
"compiler \ android - tests \ android - module \ build . gradle \n - classpath ' com . android . tools . build : gradle : 3 . 5 . 3 ' \n + classpath ' com . android . tools . build : gradle : 4 . 1 . 1 ' \n - buildToolsVersion "" 28 . 0 . 3 "" \n + buildToolsVersion "" 29 . 0 . 3 "" \n compiler \ android - tests \ tests \ org \ jetbrains \ kotlin \ android \ tests \ CodegenTestsOnAndroidGenerator . kt \n - const val GRADLE _ VERSION = "" 5 . 6 . 4 "" / / update GRADLE _ SHA _ 256 on change \n - const val GRADLE _ SHA _ 256 = "" 1f3067073041bc44554d0efe5d402a33bc3d3c93cc39ab684f308586d732a80d "" \n + const val GRADLE _ VERSION = "" 6 . 8 . 1 "" / / update GRADLE _ SHA _ 256 on change \n + const val GRADLE _ SHA _ 256 = "" fd591a34af7385730970399f473afabdb8b28d57fd97d6625c388d090039d6fd "" \n dependencies \ android - sdk \ build . gradle . kts \n + unzipSdkTask ( "" build - tools "" , "" r29 . 0 . 3 "" , "" build - tools / 29 . 0 . 3 "" , toolsOs , buildTools , 1 ) \n",Upgrade gradle plugin to 4 . 1 . and build tools to 29 . 0 . 3 for android box tests,344
"compiler \ android - tests \ tests \ org \ jetbrains \ kotlin \ android \ tests \ emulator \ Emulator . java \n - System . out . println ( "" Starting emulator . . . "" ) ; \n - RunUtils . executeOnSeparateThread ( new RunUtils . RunSettings ( getStartCommand ( ) , null , false , "" START : "" , true ) ) ; \n + System . out . println ( "" Starting emulator with ANDROID _ HOME / ANDROID _ SDK _ ROOT : "" + pathManager . getAndroidSdkRoot ( ) ) ; \n + GeneralCommandLine startCommand = getStartCommand ( ) ; \n + startCommand . withEnvironment ( "" ANDROID _ SDK _ ROOT "" , pathManager . getAndroidSdkRoot ( ) ) ; \n + startCommand . withEnvironment ( "" ANDROID _ HOME "" , pathManager . getAndroidSdkRoot ( ) ) ; \n + RunUtils . executeOnSeparateThread ( new RunUtils . RunSettings ( startCommand , null , false , "" START : "" , true ) ) ; \n - System . out . println ( "" Setting ANDROID _ HOME / ANDROID _ SDK _ ROOT : "" + pathManager . getAndroidSdkRoot ( ) ) ; \n - bootCheckCommand . withEnvironment ( "" ANDROID _ SDK _ ROOT "" , pathManager . getAndroidSdkRoot ( ) ) ; \n - bootCheckCommand . withEnvironment ( "" ANDROID _ HOME "" , pathManager . getAndroidSdkRoot ( ) ) ; \n",Set ANDROID _ SDK _ ROOT for android box tests,344
"compiler \ backend \ src \ org \ jetbrains \ kotlin \ codegen \ state \ GenerationState . kt \n - configuration . get ( JVMConfigurationKeys . STRING _ CONCAT ) ? : JvmStringConcat . INLINE \n + configuration . get ( JVMConfigurationKeys . STRING _ CONCAT ) ? : JvmStringConcat . INDY _ WITH _ CONSTANTS \n compiler \ cli \ cli - common \ src \ org \ jetbrains \ kotlin \ cli \ common \ arguments \ K2JVMCompilerArguments . kt \n - Xstring - concat = indy - with - constants Concatenate strings using ` invokedynamic ` ` makeConcatWithConstants ` . Requires ` - jvm - target 9 ` or greater . \n - Xstring - concat = indy Concatenate strings using ` invokedynamic ` ` makeConcat ` . Requires ` - jvm - target 9 ` or greater . \n - - Xstring - concat = inline Concatenate strings using ` StringBuilder ` "" "" "" \n + - Xstring - concat = inline Concatenate strings using ` StringBuilder ` \n + default : ` indy - with - constants ` for JVM target 9 or greater , ` inline ` otherwise "" "" "" \n + \n compiler \ testData \ cli \ jvm \ extraHelp . out \n - Xstring - concat = indy - with - constants Concatenate strings using ` invokedynamic ` ` makeConcatWithConstants ` . Requires ` - jvm - target 9 ` or greater . \n - Xstring - concat = indy Concatenate strings using ` invokedynamic ` ` makeConcat ` . Requires ` - jvm - target 9 ` or greater . \n - Xstring - concat = inline Concatenate strings using ` StringBuilder ` \n + default : ` indy - with - constants ` for JVM target 9 or greater , ` inline ` otherwise \n - Xsupport - compatqual - checker - framework - annotations = enable | disable \n",Make ` indy - with - constants ` default for - jvm - target 9 + \n # KT - 42522 Fixed,344
"idea \ idea - jvm \ src \ org \ jetbrains \ kotlin \ idea \ internal \ KotlinBytecodeToolWindow . kt \n + import com . intellij . openapi . ui . ComboBox \n - import javax . swing . JButton \n - import javax . swing . JCheckBox \n - import javax . swing . JPanel \n + import javax . swing . * \n - private val jvm8Target : JCheckBox \n + private val jvmTargets : JComboBox < String > \n - if ( jvm8Target . isSelected ) { \n - configuration . put ( JVMConfigurationKeys . JVM _ TARGET , JvmTarget . JVM _ 1 _ 8 ) \n - } \n + configuration . put ( JVMConfigurationKeys . JVM _ TARGET , JvmTarget . fromString ( jvmTargets . selectedItem as String ) ! ! ) \n - jvm8Target = JCheckBox ( KotlinJvmBundle . message ( "" checkbox . text . jvm . 8 . target "" ) , false ) \n + jvmTargets = ComboBox ( JvmTarget . values ( ) . map { it . description } . toTypedArray ( ) ) \n + jvmTargets . selectedItem = JvmTarget . DEFAULT . description \n - optionPanel . add ( jvm8Target ) \n + \n + optionPanel . add ( JLabel ( "" Target : "" ) ) \n + optionPanel . add ( jvmTargets ) \n",Support new targets in KotlinBytecodeToolWindow \n # KT - 30222 Fixed,344
"compiler \ tests - different - jdk \ build . gradle . kts \n - codegenTest ( target = 6 , jvm = 15 ) { \n - jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n - } \n + codegenTest ( target = 6 , jvm = 15 ) { } \n - codegenTest ( target = 8 , jvm = 15 ) { \n - jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n - } \n + codegenTest ( target = 8 , jvm = 15 ) { } \n - jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n","Remove deprecated "" - XX : - FailOverToOldVerifier "" as it breaks JDK on TC",344
"compiler \ tests - different - jdk \ tests \ org \ jetbrains \ kotlin \ codegen \ jdk \ CustomJvmTargetOnJvmBaseTest . kt \n - import org . jetbrains . kotlin . codegen . jdk . RunOnlyJdk6Test \n - import org . jetbrains . kotlin . test . runners . codegen . BlackBoxCodegenTestGenerated \n - import org . jetbrains . kotlin . test . runners . codegen . BlackBoxInlineCodegenTestGenerated \n - import org . jetbrains . kotlin . test . runners . codegen . CompileKotlinAgainstInlineKotlinTestGenerated \n + import org . jetbrains . kotlin . test . runners . codegen . * \n - CompileKotlinAgainstInlineKotlinTestGenerated : : class \n + CompileKotlinAgainstInlineKotlinTestGenerated : : class , \n + \n + IrBlackBoxCodegenTestGenerated : : class , \n + IrBlackBoxInlineCodegenTestGenerated : : class , \n + IrCompileKotlinAgainstInlineKotlinTestGenerated : : class \n",Run IR test on ` Test Codegen on different platforms `,344
"compiler \ tests - compiler - utils \ tests \ org \ jetbrains \ kotlin \ codegen \ D8Checker . java \n - public static final boolean RUN _ D8 _ CHECKER = true ; \n + public static final boolean RUN _ D8 _ CHECKER = ! Boolean . valueOf ( System . getProperty ( "" kotlin . test . box . d8 . disable "" ) ) ; \n + if ( ! RUN _ D8 _ CHECKER ) return ; \n + \n + if ( ! RUN _ D8 _ CHECKER ) return ; \n compiler \ tests - different - jdk \ build . gradle . kts \n + systemProperty ( "" kotlin . test . box . d8 . disable "" , true ) \n - ) { } \n + ) { \n + jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n + systemProperty ( "" kotlin . test . box . d8 . disable "" , true ) \n + } \n",Disable D8 checks for ` - jvm - target 15 ` tests,344
"compiler \ tests - different - jdk \ build . gradle . kts \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n + jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n + jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n + jvmArgs ( "" - XX : - FailOverToOldVerifier "" ) \n - codegenTest ( target = 6 , jvm = "" Last "" , jdk = mostRecentJdk ) { \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n - } \n + codegenTest ( target = 6 , jvm = "" Last "" , jdk = mostRecentJdk ) { } \n - codegenTest ( target = 8 , jvm = "" Last "" , jdk = mostRecentJdk ) { \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n - } \n + codegenTest ( target = 8 , jvm = "" Last "" , jdk = mostRecentJdk ) { } \n - jvmArgs ! ! . add ( "" - XX : - FailOverToOldVerifier "" ) \n","Use proper ` jvmArgs ` syntax , remove ` - FailOverToOldVerifier ` from last configurations \n ` FailOverToOldVerifier ` support is removed from JDK 16",344
compiler \ ir \ backend . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ lower \ SingleAbstractMethodLowering . kt \n - val hashCode = builtIns . anyClass . owner . functions . single ( : : isHashCode ) . symbol \n + val hashCode = context . irBuiltIns . functionClass . owner . functions . single ( : : isHashCode ) . symbol \n,Generate proper hashCode for fun interface wrappers \n # KT - 44875 Fixed,344
"realm - jni \ build . gradle \n - new Toolchain ( name : ' x86 ' , fullName : ' x86 ' , commandPrefix : ' i686 - linux - android ' , version : [ ( Compiler . GCC ) : ' 4 . 8 ' , ( Compiler . CLANG ) : ' 3 . 5 ' ] , platform : 9 ) \n + new Toolchain ( name : ' x86 ' , fullName : ' x86 ' , commandPrefix : ' i686 - linux - android ' , version : [ ( Compiler . GCC ) : ' 4 . 8 ' , ( Compiler . CLANG ) : ' 3 . 5 ' ] , platform : 9 ) , \n + new Toolchain ( name : ' x86 _ 64 ' , fullName : ' x86 _ 64 ' , commandPrefix : ' x86 _ 64 - linux - android ' , version : [ ( Compiler . GCC ) : ' 4 . 9 ' , ( Compiler . CLANG ) : ' 3 . 5 ' ] , platform : 21 ) \n - new Target ( name : ' x86 ' , jniFolder : ' x86 ' , toolchain : toolchains . find { it . name = = ' x86 ' } , cflags : [ ] ) \n + new Target ( name : ' x86 ' , jniFolder : ' x86 ' , toolchain : toolchains . find { it . name = = ' x86 ' } , cflags : [ ] ) , \n + new Target ( name : ' x86 _ 64 ' , jniFolder : ' x86 _ 64 ' , toolchain : toolchains . find { it . name = = ' x86 _ 64 ' } , cflags : [ ] ) \n",add conf to build for x86 _ 64,349
"realm \ src \ main \ java \ io \ realm \ internal \ async \ QueryUpdateTask . java \n - private boolean isUpdatingRealmResults ; \n + private final static int MODE _ UPDATE _ REALM _ RESULTS = 0 ; \n + private final static int MODE _ UPDATE _ REALM _ OBJECT = 1 ; \n + private final int updateMode ; \n + \n - private QueryUpdateTask ( boolean isUpdatingRealmResults , \n + private QueryUpdateTask ( int mode , \n - this . isUpdatingRealmResults = isUpdatingRealmResults ; \n + this . updateMode = mode ; \n - if ( isUpdatingRealmResults ) { \n + if ( updateMode = = MODE _ UPDATE _ REALM _ RESULTS ) { \n - return new QueryUpdateTask ( realmResultsEntries ! = null , \n + return new QueryUpdateTask ( \n + ( realmResultsEntries ! = null ) ? MODE _ UPDATE _ REALM _ RESULTS : MODE _ UPDATE _ REALM _ OBJECT , \n",update QueryUpdateTask to use constants for update modes instead of boolean,349
"realm \ src \ androidTest \ java \ io \ realm \ RealmTest . java \n + import java . util . concurrent . TimeUnit ; \n - populateTestRealm ( testRealm , 20 ) ; \n + / / we have 8 reference so far let ' s add more \n + final int numberOfPopulateTest = 10000 ; \n + final int totalNumberOfReferences = 8 + 20 * 2 * numberOfPopulateTest ; \n - final int MAX _ WAITING _ RETRY = 5 ; \n - int nbRetry = 0 ; \n - while ( references . size ( ) > 0 & & nbRetry < MAX _ WAITING _ RETRY ) { \n - SystemClock . sleep ( 5 ) ; / / 5ms \n - nbRetry + + ; \n + for ( int i = 0 ; i < numberOfPopulateTest ; i + + ) { \n + populateTestRealm ( testRealm , 20 ) ; \n + } \n + \n + final int MAX _ GC _ RETRIES = 5 ; \n + int numberbRetries = 0 ; \n + while ( references . size ( ) > 0 & & numberbRetries < MAX _ GC _ RETRIES ) { \n + SystemClock . sleep ( TimeUnit . SECONDS . toMillis ( 1 ) ) ; / / 1s \n + numberbRetries + + ; \n - if ( nbRetry > = MAX _ WAITING _ RETRY ) { \n - fail ( "" FinalizerRunnable didn ' t close all native resources : ( "" ) ; \n + / / we can ' t guarantee that all references have been GC ' d but we should detect a decrease \n + boolean isDecreasing = references . size ( ) < totalNumberOfReferences ; \n + if ( ! isDecreasing ) { \n + fail ( "" FinalizerRunnable is not closing all native resources "" ) ; \n + \n + } else { \n + android . util . Log . d ( RealmTest . class . getName ( ) , "" FinalizerRunnable freed : "" \n + + ( totalNumberOfReferences - references . size ( ) ) + "" out of "" + totalNumberOfReferences ) ; \n + \n",refactor the test to detect a decrease in references ( rather than trying to achieve 0 reference left ),349
"realm - jni \ src \ io _ realm _ internal _ LinkView . cpp \n - / / try { \n - / / LinkView * lv = LV ( nativeLinkViewPtr ) ; \n - / / Query query = lv - > get _ target _ table ( ) . where ( lv ) ; \n - / / TableQuery * queryPtr = new TableQuery ( query ) ; \n - / / return reinterpret _ cast < jlong > ( queryPtr ) ; \n - / / } CATCH _ STD ( ) \n + try { \n + LinkView * lv = LV ( nativeLinkViewPtr ) ; \n + Query query = lv - > get _ target _ table ( ) . where ( LinkViewRef ( lv ) ) ; \n + TableQuery * queryPtr = new TableQuery ( query ) ; \n + return reinterpret _ cast < jlong > ( queryPtr ) ; \n + } CATCH _ STD ( ) \n realm - jni \ src \ io _ realm _ internal _ SharedGroup . cpp \n - std : : unique _ ptr < ClientHistory > hist = make _ client _ history ( file _ name , false , key . data ( ) ) ; \n + std : : unique _ ptr < ClientHistory > hist = make _ client _ history ( file _ name , key . data ( ) ) ; \n",we need to wrap LinkView * in a LinkViewRef as per Core change,349
realm \ src \ main \ java \ io \ realm \ Realm . java \n + android . os . Process . setThreadPriority ( android . os . Process . THREAD _ PRIORITY _ BACKGROUND ) ; \n + \n + if ( callback ! = null ) { \n + handler . post ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + callback . onSuccess ( ) ; \n + } \n + } ) ; \n + } \n + } else { \n + bgRealm . cancelTransaction ( ) ; \n - if ( callback ! = null & & ! Thread . currentThread ( ) . isInterrupted ( ) ) { \n - handler . post ( new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - callback . onSuccess ( ) ; \n - } \n - } ) ; \n - } \n + \n + \n realm \ src \ main \ java \ io \ realm \ RealmQuery . java \n - public Request findAll ( RealmResults . QueryCallback < E > callback ) { \n + public Request findAll ( final RealmResults . QueryCallback < E > callback ) { \n + android . os . Process . setThreadPriority ( android . os . Process . THREAD _ PRIORITY _ BACKGROUND ) ; \n + android . os . Process . setThreadPriority ( android . os . Process . THREAD _ PRIORITY _ BACKGROUND ) ; \n + android . os . Process . setThreadPriority ( android . os . Process . THREAD _ PRIORITY _ BACKGROUND ) ; \n + android . os . Process . setThreadPriority ( android . os . Process . THREAD _ PRIORITY _ BACKGROUND ) ; \n realm \ src \ main \ java \ io \ realm \ RealmResults . java \n - void onError ( Exception t ) ; \n + void onError ( Exception e ) ; \n,using Thread priority for async queries / transaction,349
realm - jni \ src \ io _ realm _ internal _ TableQuery . cpp \n + / / queryPtr would be owned and released by this function \n + \n + / / queryPtr would be owned and released by this function \n - std : : unique _ ptr < SharedGroup : : Handover < TableView > > handover = SG ( \n + std : : unique _ ptr < SharedGroup : : Handover < TableView > > handover = SG ( \n + delete tableView ; \n + delete tableView ; \n + delete tableView ; \n + / / handoverPtr will be released in this function \n,deleting a handover TableView to avoid memory leaks,349
"realm - jni \ src \ io _ realm _ internal _ TableQuery . cpp \n - ( JNIEnv * env , jobject , jlong nativeHandoverQuery ) \n + ( JNIEnv * , jobject , jlong nativeHandoverQuery ) \n realm \ src \ main \ java \ io \ realm \ RealmObject . java \n + } else { \n + throw new IllegalArgumentException ( "" Can not add listener from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n + } else { \n + throw new IllegalArgumentException ( "" Can not remove listener from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n + } else { \n + throw new IllegalArgumentException ( "" Can not remove listeners from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n realm \ src \ main \ java \ io \ realm \ RealmResults . java \n + } else { \n + throw new IllegalArgumentException ( "" Can not add listener from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n + } else { \n + throw new IllegalArgumentException ( "" Can not remove listener from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n - \n + } else { \n + throw new IllegalArgumentException ( "" Can not remove listeners from this unmanaged RealmObject ( created outside of Realm ) "" ) ; \n",now throwing Exception if we try to add / remove listener for unmanaged RealmObject / RealmResults,349
"realm \ src \ androidTest \ java \ io \ realm \ RealmAsyncQueryTests . java \n - TestHelper . awaitOrFail ( signalTestFinished , 60 ) ; \n + TestHelper . awaitOrFail ( signalTestFinished , 120 ) ; \n",increase timeout of async stress tests because of slow device in CI,349
"realm \ src \ main \ java \ io \ realm \ Realm . java \n - import java . util . concurrent . atomic . AtomicInteger ; \n - / / will use the Looper of the caller thread to post the result \n - final Handler handler = new Handler ( ) ; \n + / / If the user provided a Callback then we make sure , the current Realm has a Handler \n + / / we can use to deliver the result \n + if ( callback ! = null & & handler = = null ) { \n + throw new IllegalStateException ( "" Your Realm is opened from a thread without a Looper "" + \n + "" and you provided a callback , we need a Handler to invoke your callback "" ) ; \n + } \n + & & handler ! = null \n + & & handler ! = null \n",using the caller ' s Realn handler for async write transaction,349
realm \ src \ androidTest \ java \ io \ realm \ RealmAsyncQueryTests . java \n + final CountDownLatch signalClosedRealm = new CountDownLatch ( 1 ) ; \n - \n + signalClosedRealm . countDown ( ) ; \n + TestHelper . awaitOrFail ( signalClosedRealm ) ; \n,waiting for finally block to run before exiting the test,349
"realm \ realm - library \ src \ androidTest \ java \ io \ realm \ RealmJsonTest . java \n - InputStream in = loadJsonFromAssets ( "" date _ as _ iso8601 _ string . json "" ) ; \n + InputStream in = TestHelper . loadJsonFromAssets ( getContext ( ) , "" date _ as _ iso8601 _ string . json "" ) ; \n",fixing master after release / 0 . 86 merge,349
realm \ realm - jni \ build . gradle \n - ext . coreVersion = ' 0 . 95 . 6 ' \n + ext . coreVersion = ' 0 . 95 . 7 ' \n - ext . coreSha256Hash = ' e040350420dda9e276ead1366f309e52f2dfa1551c9ed6e97639c7de2fee62d0 ' \n + ext . coreSha256Hash = ' 11c82f5da9b43b62fbf55fbd3aa61dc6956bc3483bbaa5f69262018144c8cc3c ' \n,update to Core 0 . 95 . 7,349
version . txt \n - 0 . 87 . 1 \n + 0 . 87 . 2 - SNAPSHOT \n,Prepare next release v0 . 87 . 2 - SNAPSHOT,349
realm \ realm - library \ build . gradle \n + / / Clean . so files that were created by old build script ( realm / realm - jni / build . gradle ) . \n + delete project . file ( ' src / main / jniLibs ' ) \n,Clean . so files that were created by old build script ( # 3542 ),349
realm \ realm - library \ proguard - rules . pro \n - keep @ io . realm . internal . Keep class * { * ; } \n - dontwarn javax . * * \n - dontwarn io . realm . * * \n + - keep class io . realm . RealmCollection \n + - keep class io . realm . OrderedRealmCollection \n,Fixes # 2670 ProGuard configuration ( # 2690 ),349
realm \ realm - library \ src \ androidTestObjectServer \ java \ io \ realm \ SyncConfigurationTests . java \n - public void not _ equals _ same ( ) { \n + public void equals _ same ( ) { \n - assertFalse ( config1 . equals ( config2 ) ) ; \n + assertTrue ( config1 . equals ( config2 ) ) ; \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit a7df0504d6a5cd73d4ee6a9de6d38fe2f5c95bba \n + Subproject commit 9ec19d106c3f12916ba64b89557daae82d47c756 \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ syncpolicy \ AutomaticSyncPolicy . java \n + \n + @ Override \n + public boolean equals ( Object o ) { \n + if ( this = = o ) return true ; \n + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; \n + \n + AutomaticSyncPolicy that = ( AutomaticSyncPolicy ) o ; \n + \n + if ( recurringErrors ! = that . recurringErrors ) return false ; \n + return lastError ! = null ? lastError . equals ( that . lastError ) : that . lastError = = null ; \n + } \n + \n + @ Override \n + public int hashCode ( ) { \n + int result = lastError ! = null ? lastError . hashCode ( ) : 0 ; \n + result = 31 * result + recurringErrors ; \n + return result ; \n + } \n,Nh / fix test ( # 3868 ) \n * Fix SyncConfiguration test,349
"new file \n examples \ introExample \ lint . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" UTF - 8 "" ? > \n + < lint > \n + < ! - - Disable the given check in this project - - > \n + < issue id = "" AllowBackup "" severity = "" ignore "" / > \n + < issue id = "" IconLauncherShape "" severity = "" ignore "" / > \n + < issue id = "" IconMissingDensityFolder "" severity = "" ignore "" / > \n + < issue id = "" GoogleAppIndexingWarning "" severity = "" ignore "" / > \n + \n + < / lint > \n examples \ introExample \ src \ main \ AndroidManifest . xml \n - android : allowBackup = "" true "" \n examples \ introExample \ src \ main \ res \ layout \ activity _ realm _ basic _ example . xml \n - android : text = "" Status Output . . . "" \n + android : text = "" @ string / status _ output "" \n examples \ introExample \ src \ main \ res \ values \ strings . xml \n - < string name = "" hello _ world "" > Hello world ! < / string > \n - < string name = "" action _ settings "" > Settings < / string > \n + < string name = "" status _ output "" > Status Output… < / string > \n",fix intro Lint warning ( # 2578 ),349
"examples \ moduleExample \ app \ src \ main \ AndroidManifest . xml \n - android : allowBackup = "" true "" \n new file \n examples \ moduleExample \ library \ lint . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" UTF - 8 "" ? > \n + < lint > \n + < ! - - Disable the given check in this project - - > \n + < issue id = "" AllowBackup "" severity = "" ignore "" / > \n + < issue id = "" IconLauncherShape "" severity = "" ignore "" / > \n + < issue id = "" IconMissingDensityFolder "" severity = "" ignore "" / > \n + < issue id = "" GoogleAppIndexingWarning "" severity = "" ignore "" / > \n + < / lint > \n examples \ moduleExample \ library \ src \ main \ AndroidManifest . xml \n - android : allowBackup = "" true "" \n",Nh / lint / module example ( # 2586 ),349
"realm \ realm - library \ src \ main \ cpp \ io _ realm _ internal _ OsRealmConfig . cpp \n - util : : Optional < std : : array < char , 64 > > sync _ encryption _ key ( util : : none ) ; \n - if ( ! config . encryption _ key . empty ( ) ) { \n - sync _ encryption _ key = std : : array < char , 64 > ( ) ; \n - std : : copy _ n ( config . encryption _ key . begin ( ) , 64 , sync _ encryption _ key - > begin ( ) ) ; \n - } \n + \n - config . sync _ config = std : : make _ shared < SyncConfig > ( SyncConfig { \n - user , realm _ url , session _ stop _ policy , std : : move ( bind _ handler ) , std : : move ( error _ handler ) , \n - nullptr , sync _ encryption _ key } ) ; \n + config . sync _ config = std : : make _ shared < SyncConfig > ( SyncConfig { user , realm _ url } ) ; \n + config . sync _ config - > stop _ policy = session _ stop _ policy ; \n + config . sync _ config - > bind _ session _ handler = std : : move ( bind _ handler ) ; \n + config . sync _ config - > error _ handler = std : : move ( error _ handler ) ; \n + if ( ! config . encryption _ key . empty ( ) ) { \n + config . sync _ config - > realm _ encryption _ key = std : : array < char , 64 > ( ) ; \n + std : : copy _ n ( config . encryption _ key . begin ( ) , 64 , config . sync _ config - > realm _ encryption _ key - > begin ( ) ) ; \n + } \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit 136b3a32a218f50275f1183ed078b31945a9e29f \n + Subproject commit 1cb3a165dc703a706cd107318b38c2f49fa3f31f \n",update ObjectStore to reflect SyncConfig refactor https : / / github . com / realm / realm - object - store / pull / 590 \ ),349
"CHANGELOG . md \n + * Fixed bug , preventing Sync client to renew the access token ( # 4038 ) ( # 4039 ) . \n realm \ realm - library \ src \ main \ cpp \ objectserver _ shared . hpp \n - if ( error _ code . category ( ) ! = realm : : sync : : protocol _ error _ category ( ) | | \n + if ( error _ code . category ( ) ! = realm : : sync : : protocol _ error _ category ( ) & & \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ objectserver \ BoundState . java \n + / / the server can send a 202 ( expired access token ) even if the client \n + / / still consider this token to be valid ( based on timestamps for example ) \n + / / \n + / / this may cause the server to send a fatal error ( 203 bad refresh ) if we try to bind \n + / / the session with this token . To be safe we remove the token that has been considered by the \n + / / the server to be invalid . \n + \n + / / stop the session to avoid sending a bind to the server which will cause it to return \n + / / a fatal 203 ( bad refresh ) \n + session . stopNativeSession ( ) ; \n + session . removeAccessToken ( ) ; \n + \n + / / Create a new session & bind it \n + session . createNativeSession ( ) ; \n + \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ objectserver \ ObjectServerSession . java \n - import io . realm . SyncSession ; \n + import io . realm . SyncSession ; \n + void removeAccessToken ( ) { \n + user . removeAccessToken ( configuration . getServerUrl ( ) ) ; \n + } \n + \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ objectserver \ ObjectServerUser . java \n - import io . realm . SyncSession ; \n + import io . realm . SyncSession ; \n - public void setRefreshToken ( final Token refreshToken ) { \n + private void setRefreshToken ( final Token refreshToken ) { \n - public boolean isAuthenticated ( SyncConfiguration configuration ) { \n + boolean isAuthenticated ( SyncConfiguration configuration ) { \n - public Token getAccessToken ( URI serverUrl ) { \n + Token getAccessToken ( URI serverUrl ) { \n + void removeAccessToken ( URI serverUrl ) { \n + realms . remove ( serverUrl ) ; \n + } \n + \n",Nh / fixes token renew ( # 4040 ) \n * fixes # 4039 and fixes # 4038,349
"realm \ realm - library \ src \ main \ cpp \ CMakeLists . txt \n - "" object - store / src / sync / * "" \n - "" object - store / src / sync / impl / * "" ) \n + "" object - store / src / results . cpp "" \n + "" object - store / src / impl / results _ notifier . cpp "" \n + "" object - store / src / sync / * . cpp "" \n + "" object - store / src / sync / impl / * . cpp "" ) \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ SyncManager . cpp \n + # include "" sync / sync _ manager . hpp "" \n + # include "" sync / sync _ user . hpp "" \n + # include "" util . hpp "" \n + \n + JNIEXPORT void JNICALL \n + Java _ io _ realm _ SyncManager _ nativeConfigureMetaDataSystem ( JNIEnv * env , jclass , \n + jstring baseFile ) { \n + TR _ ENTER ( ) \n + try { \n + JStringAccessor base _ file _ path ( env , baseFile ) ; / / throws \n + SyncManager : : shared ( ) . configure _ file _ system ( base _ file _ path , SyncManager : : MetadataMode : : NoEncryption ) ; \n + } CATCH _ STD ( ) \n + } \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit 163c1e8fb026a05d281e82096e64622d2e735f17 \n + Subproject commit ac2f60726434654cace0bb5e57a92df7555c8f1f \n realm \ realm - library \ src \ main \ cpp \ objectserver _ shared . hpp \n - nullptr , \n - nullptr , \n + "" "" , \n + "" "" , \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ ObjectServer . java \n + \n + / / init the "" sync _ manager . cpp "" metadata Realm , this is also needed later , when re try \n + / / to schedule a client reset . in realm - java # master this is already done , when initialising \n + / / the RealmFileUserStore ( not available now on releases ) \n + SyncManager . nativeConfigureMetaDataSystem ( context . getFilesDir ( ) . getPath ( ) ) ; \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncManager . java \n - \n + / / init and load the Metadata Realm containing SyncUsers \n + protected static native void nativeConfigureMetaDataSystem ( String baseFile ) ; \n","Nh / init metadata ( # 4053 ) \n * init ObjectStore metadata , to store File Action \n * avoid null pointer exception , by passing empty strings",349
"realm \ realm - library \ src \ androidTestObjectServer \ java \ io \ realm \ SyncUserTests . java \n - UserStore userStore = new RealmFileUserStore ( InstrumentationRegistry . getTargetContext ( ) . getFilesDir ( ) . getPath ( ) ) ; \n + UserStore userStore = new RealmFileUserStore ( ) ; \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ RealmFileUserStore . cpp \n - JNIEXPORT void JNICALL \n - Java _ io _ realm _ RealmFileUserStore _ nativeConfigureMetaDataSystem ( JNIEnv * env , jclass , jstring baseFile ) \n - { \n - TR _ ENTER ( ) \n - try { \n - JStringAccessor base _ file _ path ( env , baseFile ) ; / / throws \n - SyncManager : : shared ( ) . configure _ file _ system ( base _ file _ path , SyncManager : : MetadataMode : : NoEncryption ) ; \n - } CATCH _ STD ( ) \n - } \n - \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ ObjectServer . java \n - / / Configure default UserStore \n - UserStore userStore = new RealmFileUserStore ( context . getFilesDir ( ) . getPath ( ) ) ; \n - \n - SyncManager . init ( appId , userStore ) ; \n - \n + \n + / / Configure default UserStore \n + UserStore userStore = new RealmFileUserStore ( ) ; \n + \n + SyncManager . init ( appId , userStore ) ; \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ RealmFileUserStore . java \n - protected RealmFileUserStore ( String path ) { \n - nativeConfigureMetaDataSystem ( path ) ; \n - } \n - / / init and load the Metadata Realm containing SyncUsers \n - protected static native void nativeConfigureMetaDataSystem ( String baseFile ) ; \n - \n",remove duplicate init of the metadata ( # 4116 ),349
CHANGELOG . md \n + # # 3 . 1 . 3 \n + \n + # # # Internal \n + \n + * Upgraded to Realm Sync 1 . 5 . 2 . \n + \n dependencies . list \n - REALM _ SYNC _ VERSION = 1 . 5 . 0 \n - REALM _ SYNC _ SHA256 = 2da0de557182e7d717d74808bf6d3f1e5f18d5c082744d29b96dca80555733a7 \n + REALM _ SYNC _ VERSION = 1 . 5 . 2 \n + REALM _ SYNC _ SHA256 = e7a0134b5b69c5a571e3f49901bb8d8ca634b166873c5a422909e7d2016a00e7 \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ internal _ TableQuery . cpp \n - # include < realm / group _ shared . hpp > \n + # include < realm / query _ expression . hpp > \n realm \ realm - library \ src \ main \ cpp \ util . hpp \n - # include < realm / util / meta . hpp > \n,update to Core 2 . 6 . 0 & Sync 1 . 5 . 2 ( # 4486 ),349
"CHANGELOG . md \n + # # # Enhancements \n + \n + * [ ObjectServer ] Resume synchronization as soon as the connectivity is back ( # 4141 ) . \n + \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ SyncManager . cpp \n + \n + JNIEXPORT void JNICALL Java _ io _ realm _ SyncManager _ nativeReconnect ( JNIEnv * env , jclass ) \n + { \n + TR _ ENTER ( ) \n + try { \n + SyncManager : : shared ( ) . reconnect ( ) ; \n + } \n + CATCH _ STD ( ) \n + } \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncManager . java \n + import io . realm . internal . network . NetworkStateReceiver ; \n + private static NetworkStateReceiver . ConnectionListener networkListener = new NetworkStateReceiver . ConnectionListener ( ) { \n + @ Override \n + public void onChange ( boolean connectionAvailable ) { \n + if ( connectionAvailable ) { \n + RealmLog . debug ( "" NetworkListener : Connection available "" ) ; \n + / / notify all sessions \n + notifyNetworkIsBack ( ) ; \n + } else { \n + RealmLog . debug ( "" NetworkListener : Connection lost "" ) ; \n + } \n + } \n + } ; \n + \n + if ( sessions . size ( ) = = 1 ) { \n + RealmLog . debug ( "" first session created add network listener "" ) ; \n + NetworkStateReceiver . addListener ( networkListener ) ; \n + } \n + if ( sessions . isEmpty ( ) ) { \n + RealmLog . debug ( "" last session dropped , remove network listener "" ) ; \n + NetworkStateReceiver . removeListener ( networkListener ) ; \n + } \n + private static synchronized void notifyNetworkIsBack ( ) { \n + try { \n + nativeReconnect ( ) ; \n + } catch ( Exception exception ) { \n + RealmLog . error ( exception ) ; \n + } \n + } \n + \n + private static native void nativeReconnect ( ) ; \n",Sync reconnect ( # 4498 ) \n * calling Sync reconnect when network is back,349
"CHANGELOG . md \n + * [ ObjectServer ] Prevent the use of a ` SyncUser ` that explicitly logged out , to open a Realm ( # 4975 ) . \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncManager . java \n - static UserStore getUserStore ( ) { \n + public static UserStore getUserStore ( ) { \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncUser . java \n - return syncUser . isLoggedIn ( ) & & userToken ! = null & & userToken . expiresMs ( ) > System . currentTimeMillis ( ) & & SyncManager . getUserStore ( ) . isActive ( syncUser . getIdentity ( ) ) ; \n + return userToken ! = null & & userToken . expiresMs ( ) > System . currentTimeMillis ( ) & & SyncManager . getUserStore ( ) . isActive ( syncUser . getIdentity ( ) ) ; \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ SyncObjectServerFacade . java \n - if ( user . getAccessToken ( ) = = null ) { \n + if ( ! SyncManager . getUserStore ( ) . isActive ( user . getIdentity ( ) ) ) { \n - RealmLog . warn ( "" Can not use the provided configuration to open a Realm , the SyncUser is no longer valid . "" ) ; \n + RealmLog . warn ( "" The provided configuration uses an expired SyncUser token , this Realm instance will work offline . "" ) ; \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ AuthTests . java \n + @ Test \n + public void logout _ currentUserMoreThanOne ( ) { \n + SyncUser user = UserFactory . createUniqueUser ( Constants . AUTH _ URL ) ; \n + final RealmConfiguration config1 = configurationFactory . createSyncConfigurationBuilder ( user , Constants . USER _ REALM ) \n + . build ( ) ; \n + SyncUser . currentUser ( ) . logout ( ) ; \n + SyncUser user2 = UserFactory . createUniqueUser ( Constants . AUTH _ URL ) ; \n + try { \n + Realm . getInstance ( config1 ) ; \n + fail ( "" SyncUser is not longer valid , it should not be possible to get a Realm instance "" ) ; \n + } catch ( IllegalStateException expected ) { \n + } \n + assertEquals ( user2 , SyncUser . currentUser ( ) ) ; \n + } \n + \n",fixes # 4975 ( # 5000 ) \n * fixes # 4975,349
realm \ realm - library \ src \ androidTest \ kotlin \ io \ realm \ KotlinSchemaTests . kt \n - import kotlin . reflect . full . memberProperties \n - val objSchema = realm . getSchema ( ) . get ( AllKotlinTypes : : class . simpleName ) \n + val objSchema = realm . schema . get ( AllKotlinTypes : : class . simpleName ) \n,using property access syntax ( # 5127 ),349
"realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ SyncSessionTests . java \n + import org . junit . Ignore ; \n + @ Ignore ( "" until https : / / github . com / realm / realm - java / issues / 5294 is fixed "" ) \n",Disable flaky test until 5294 is fixed ( # 5295 ),349
CHANGELOG . md \n - \n + * [ ObjectServer ] now retrying network query when encountering any ` IOException ` ( # 5453 ) . \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ ErrorCode . java \n - import java . net . ConnectException ; \n + \n + import java . io . IOException ; \n - / / ConnectException is recoverable ( with exponential backoff ) \n - return ( exception instanceof ConnectException ) ? ErrorCode . IO _ EXCEPTION : ErrorCode . UNKNOWN ; \n + / / IOException are recoverable ( with exponential backoff ) \n + if ( exception instanceof IOException ) { \n + return ErrorCode . IO _ EXCEPTION ; \n + } else { \n + return ErrorCode . UNKNOWN ; \n + } \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncUser . java \n - networkPoolExecutor . submit ( new ExponentialBackoffTask < LogoutResponse > ( ) { \n + networkPoolExecutor . submit ( new ExponentialBackoffTask < LogoutResponse > ( 3 ) { \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ internal \ network \ ExponentialBackoffTask . java \n + private final int maxRetries ; \n + \n + public ExponentialBackoffTask ( int maxRetries ) { \n + this . maxRetries = maxRetries ; \n + } \n + \n + public ExponentialBackoffTask ( ) { \n + this ( Integer . MAX _ VALUE - 1 ) ; \n + } \n - if ( shouldAbortTask ( response ) ) { \n + if ( shouldAbortTask ( response ) | | attempt = = maxRetries + 1 ) { \n,"fix SocketTimeout ( # 5453 ) \n * Adding a max retries to the ExponentialBackoff to avoid retrying indefinitely the logout ( revoke ) query , which causes some tests to block \n * Binding IOException to ErrorCode . IO _ EXCEPTION",349
CHANGELOG . md \n + * [ ObjectServer ] now retrying network query when encountering any ` IOException ` ( # 5453 ) . \n + * Fixed a ` NoClassDefFoundError ` due to using ` @ SafeVarargs ` below API 19 ( # 5463 ) . \n - # # # Interal \n + # # # Internal \n - * [ ObjectServer ] now retrying network query when encountering any ` IOException ` ( # 5453 ) . \n + \n realm \ realm - library \ src \ main \ java \ io \ realm \ RealmConfiguration . java \n - @ SafeVarargs \n realm \ realm - library \ src \ main \ java \ io \ realm \ RealmList . java \n - @ SafeVarargs \n,"Removed @ SafeVarargs annotation since it ' s not available until API 19 ( # 5469 ) \n * removed @ SafeVarargs annotation since it ' s not available until API 19 , fixes # 5463",349
"examples \ secureTokenAndroidKeyStore \ src \ main \ java \ io \ realm \ examples \ securetokenandroidkeystore \ MainActivity . java \n - import org . json . JSONException ; \n - import org . json . JSONObject ; \n - \n - import java . util . UUID ; \n + import io . realm . ObjectServerError ; \n + import io . realm . SyncCredentials ; \n - import io . realm . internal . objectserver . Token ; \n - SyncUser user = createTestUser ( Long . MAX _ VALUE ) ; \n - String url = "" realm : / / objectserver . realm . io / default "" ; \n - SyncConfiguration secureConfig = new SyncConfiguration . Builder ( user , url ) . build ( ) ; \n - Realm realm = Realm . getInstance ( secureConfig ) ; \n - / / . . . \n - } \n - \n - / / Helpers \n - private final static String USER _ TOKEN = UUID . randomUUID ( ) . toString ( ) ; \n + SyncCredentials credentials = SyncCredentials . usernamePassword ( "" username "" , "" password "" ) ; \n + final String urlAuth = "" http : / / objectserver . realm . io : 9080 / auth "" ; \n + final String url = "" realm : / / objectserver . realm . io / default "" ; \n + \n + SyncUser . loginAsync ( credentials , urlAuth , new SyncUser . Callback < SyncUser > ( ) { \n + @ Override \n + public void onSuccess ( SyncUser user ) { \n + SyncConfiguration secureConfig = new SyncConfiguration . Builder ( user , url ) . build ( ) ; \n + Realm realm = Realm . getInstance ( secureConfig ) ; \n + / / . . . \n + } \n - private static SyncUser createTestUser ( long expires ) { \n - Token userToken = new Token ( USER _ TOKEN , "" JohnDoe "" , null , expires , null ) ; \n - JSONObject obj = new JSONObject ( ) ; \n - try { \n - JSONObject realmDesc = new JSONObject ( ) ; \n - realmDesc . put ( "" uri "" , "" realm : / / objectserver . realm . io / default "" ) ; \n - \n - obj . put ( "" authUrl "" , "" http : / / objectserver . realm . io / auth "" ) ; \n - obj . put ( "" userToken "" , userToken . toJson ( ) ) ; \n - return SyncUser . fromJson ( obj . toString ( ) ) ; \n - } catch ( JSONException e ) { \n - throw new RuntimeException ( e ) ; \n - } \n + @ Override \n + public void onError ( ObjectServerError error ) { } \n + } ) ; \n",fix secureTokenAndroidKeyStore example to pass monkey test ( # 5477 ) \n * fix secureTokenAndroidKeyStore example to pass monkey test,349
version . txt \n - 4 . 1 . 1 \n + 4 . 1 . 2 - SNAPSHOT \n,Prepare next release v4 . 1 . 2 - SNAPSHOT,349
dependencies . list \n - REALM _ OBJECT _ SERVER _ DE _ VERSION = 2 . 0 . 0 - alpha . 46 \n + REALM _ OBJECT _ SERVER _ DE _ VERSION = 2 . 0 . 0 - rc . 4 \n,Update to ROS 2 . 0 . 0 - rc4 for testing ( # 5408 ),349
"Jenkinsfile \n - boolean archiveLog = true \n - stopLogCatCollector ( backgroundPid , archiveLog ) \n + stopLogCatCollector ( backgroundPid ) \n - def stopLogCatCollector ( String backgroundPid , boolean archiveLog ) { \n + def stopLogCatCollector ( String backgroundPid ) { \n - zip ( [ \n - ' zipFile ' : ' logcat . zip ' , \n + ' zipFile ' : ' logcat . zip ' , \n - ] ) \n",CI to always create the zip file even if the tests passes,349
version . txt \n - 4 . 3 . 2 \n + 4 . 3 . 3 - SNAPSHOT \n,Prepare next release v4 . 3 . 3 - SNAPSHOT,349
CHANGELOG . md \n + # # 4 . 3 . 3 ( YYYY - MM - DD ) \n + \n + # # # Internal \n + \n + * Downgrade JavaAssist to 3 . 21 . 0 - GA to fix an issue with a ` ClassNotFoundException ` at runtime ( # 5641 ) . \n + \n + \n realm - transformer \ build . gradle \n - compile ' org . javassist : javassist : 3 . 22 . 0 - GA ' \n + compile ' org . javassist : javassist : 3 . 21 . 0 - GA ' \n,downgrade javassist ( # 5698 ) \n * Downgrade version of Javassist causing issue with classloader at runtime # 5641,349
version . txt \n - 4 . 3 . 3 \n + 4 . 3 . 4 - SNAPSHOT \n,Prepare next release v4 . 3 . 4 - SNAPSHOT,349
version . txt \n - 4 . 4 . 0 \n + 4 . 4 . 1 - SNAPSHOT \n,Prepare next release v4 . 4 . 1 - SNAPSHOT,349
"CHANGELOG . md \n + # # Bug Fixes \n + \n + * [ ObjectServer ] Fixed an issue where login after a logout will not resume Syncing ( https : / / github . com / realm / my - first - realm - app / issues / 22 ) . \n + \n - * [ ObjectServer ] Fixed an issue where login after a logout will not resume Syncing ( https : / / github . com / realm / my - first - realm - app / issues / 22 ) . \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ SyncedRealmTests . java \n + . sessionStopPolicy ( OsRealmConfig . SyncSessionStopPolicy . IMMEDIATELY ) \n - assertTrue ( Realm . deleteRealm ( config ) ) ; \n + try { \n + assertTrue ( Realm . deleteRealm ( config ) ) ; \n + } catch ( IllegalStateException e ) { \n + / / FIXME : We don ' t have a way to ensure that the Realm instance on client thread has been \n + / / closed for now . \n + / / https : / / github . com / realm / realm - java / issues / 5416 \n + if ( e . getMessage ( ) . contains ( "" It ' s not allowed to delete the file "" ) ) { \n + / / retry after 1 second \n + SystemClock . sleep ( 1000 ) ; \n + assertTrue ( Realm . deleteRealm ( config ) ) ; \n + } \n + } \n",deleteRealm throwing in loginLogoutResumeSyncing ( # 5836 ) \n - Workaround deleteRealm throwing in test \n - Fixed Changelog entries,349
"dependencies . list \n - REALM _ SYNC _ VERSION = 3 . 0 . 0 - beta . 10 \n - REALM _ SYNC _ SHA256 = d5f2b1639efb5d64369d628c38e6d0698a1fbe6c2112b0f3321a85e170d6824e \n + REALM _ SYNC _ VERSION = 3 . 0 . 0 \n + REALM _ SYNC _ SHA256 = 9141177ccc92d8f9282625dace61eee5c3d971d2daca7593266e175b610a24cf \n - REALM _ OBJECT _ SERVER _ DE _ VERSION = 3 . 0 . 0 - alpha . 8 \n + REALM _ OBJECT _ SERVER _ DE _ VERSION = 3 . 0 . 0 - rc . 1 \n realm \ realm - library \ src \ androidTestObjectServer \ java \ io \ realm \ ObjectLevelPermissionsTest . java \n - assertEquals ( 1 , roles . size ( ) ) ; \n - Role role = roles . first ( ) ; \n + assertEquals ( 2 , roles . size ( ) ) ; \n + \n + roles = roles . where ( ) . sort ( "" name "" ) . findAll ( ) ; \n + Role role = roles . get ( 0 ) ; \n + assertEquals ( "" _ _ User : "" + user . getIdentity ( ) , role . getName ( ) ) ; \n + assertTrue ( role . hasMember ( user . getIdentity ( ) ) ) ; \n + \n + role = roles . get ( 1 ) ; \n + \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit bb559df9237ece49f9c889993f7c1aff619b48f9 \n + Subproject commit f2a536d29de48e34e60799a5bf3f36e13806387e \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ ObjectLevelPermissionIntegrationTests . java \n + . partialRealm ( ) \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ PartialSyncTests . java \n + . partialRealm ( ) \n - / / Create server data \n",Update dependencies ( # 5834 ) \n * Partial Sync is needed to create the Reference Realm for permission tests \n * Add partial Sync to create the reference Realm \n * Using latest OS,349
"CHANGELOG . md \n + # # 5 . 0 . 1 ( YYYY - MM - DD ) \n + \n + # # # Enhancements \n + \n + * [ ObjectServer ] ` SyncConfiguration . automatic ( ) ` will make use of the host port to work out the default Realm URL . \n + \n realm \ realm - library \ src \ androidTestObjectServer \ java \ io \ realm \ SyncConfigurationTests . java \n - { "" http : / / ros . realm . io : 7777 "" , "" realm : / / ros . realm . io / default "" } , \n + { "" http : / / ros . realm . io : 7777 "" , "" realm : / / ros . realm . io : 7777 / default "" } , \n - { "" https : / / ros . realm . io : 7777 "" , "" realms : / / ros . realm . io / default "" } , \n + { "" https : / / ros . realm . io : 7777 "" , "" realms : / / ros . realm . io : 7777 / default "" } , \n + / / with port \n + { "" http : / / 192 . 168 . 1 . 65 : 9080 "" , "" realm : / / 192 . 168 . 1 . 65 : 9080 / default "" } , \n + { "" http : / / 192 . 168 . 1 . 65 : 9080 / auth "" , "" realm : / / 192 . 168 . 1 . 65 : 9080 / default "" } , \n + { "" https : / / 192 . 168 . 1 . 65 : 9080 / auth "" , "" realms : / / 192 . 168 . 1 . 65 : 9080 / default "" } , \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncConfiguration . java \n + int port = url . getPort ( ) ; \n + if ( port ! = - 1 ) { / / port set \n + host + = "" : "" + port ; \n + } \n",SyncConfiguration # automatic to use the host port ( # 5844 ) \n * port is inferred for automatic SyncConfiguration,349
"CHANGELOG . md \n - \n + * [ ObjectServer ] Fixed an issue preventing sync to resume when the network is back ( # 5677 ) . \n realm \ realm - library \ src \ objectServer \ java \ io \ realm \ SyncSession . java \n - private NetworkStateReceiver . ConnectionListener networkListener ; \n - RealmLog . error ( e , "" Session [ % s ] : Can not parse the refresh _ token into a valid JSONObject : "" , configuration . getPath ( ) ) ; \n + RealmLog . error ( e , "" Session [ % s ] : Can not parse the refresh _ token into a valid JSONObject : "" , configuration . getPath ( ) ) ; \n - if ( ! onGoingAccessTokenQuery . getAndSet ( true ) ) { \n - if ( NetworkStateReceiver . isOnline ( SyncObjectServerFacade . getApplicationContext ( ) ) ) { \n - authenticateRealm ( authServer ) ; \n - \n - } else { \n - / / Wait for connection to become available , before trying again . \n - / / The Session might potentially stay in this state for the lifetime of the application . \n - / / This is acceptable . \n - networkListener = new NetworkStateReceiver . ConnectionListener ( ) { \n - @ Override \n - public void onChange ( boolean connectionAvailable ) { \n - if ( connectionAvailable ) { \n - if ( ! onGoingAccessTokenQuery . getAndSet ( true ) ) { \n - authenticateRealm ( authServer ) ; \n - } \n - NetworkStateReceiver . removeListener ( this ) ; \n - } \n - } \n - } ; \n - NetworkStateReceiver . addListener ( networkListener ) ; \n - } \n + if ( ! onGoingAccessTokenQuery . get ( ) & & NetworkStateReceiver . isOnline ( SyncObjectServerFacade . getApplicationContext ( ) ) ) { \n + authenticateRealm ( authServer ) ; \n + onGoingAccessTokenQuery . set ( true ) ; \n + onGoingAccessTokenQuery . set ( true ) ; \n",Fixes # 5677 ( # 5741 ) \n * Fixes # 5677 \n - removed session network listener since it ' s redundant with the SyncManager one,349
version . txt \n - 4 . 3 . 4 \n + 4 . 3 . 5 - SNAPSHOT \n,Prepare next release v4 . 3 . 5 - SNAPSHOT,349
CHANGELOG . md \n + * [ ObjectServer ] Fixed a bug which could potentially flood Realm Object Server with PING messages . \n - * Upgraded to Realm Core 3 . 5 . 4 \n + * Upgraded to Realm Sync 3 . 5 . 6 \n + * Upgraded to Object Store commit ` 0bcb9643b8fb14323df697999b79c4a5341a8a21 ` \n dependencies . list \n - REALM _ SYNC _ VERSION = 3 . 5 . 4 \n - REALM _ SYNC _ SHA256 = 72ff45e9e8d285c1baa13f83492652de2199542dfe80d075951d6277957baaed \n + REALM _ SYNC _ VERSION = 3 . 5 . 6 \n + REALM _ SYNC _ SHA256 = f24e404bbd649d3f5071ece7eb8ab7d667a3d2a95dc83766ebf8e0534b83125d \n realm \ realm - library \ src \ main \ cpp \ object - store \n - Subproject commit 58f106676f96d0a5dcb52b6d705cf20db797d5c6 \n + Subproject commit 0bcb9643b8fb14323df697999b79c4a5341a8a21 \n,Upgrading to Realm Sync v3 . 5 . 6,349
version . txt \n - 5 . 3 . 1 \n + 5 . 3 . 2 - SNAPSHOT \n,Prepare next release v5 . 3 . 2 - SNAPSHOT,349
"CHANGELOG . md \n + * Fixes issue with the incremental build causing direct access to model without accessor to fail ( # 6056 ) . \n realm - transformer \ src \ main \ kotlin \ io \ realm \ transformer \ ByteCodeModifier . kt \n - if ( isRealmModelClass ( fieldAccess . enclosingClass ) & & isModelField ( fieldAccess . field ) ) { \n + \n + val fieldAccessCtClass : CtClass ? = try { classPool . get ( fieldAccess . className ) } catch ( e : NotFoundException ) { null } \n + if ( fieldAccessCtClass ! = null & & isRealmModelClass ( fieldAccessCtClass ) & & isModelField ( fieldAccess . field ) ) { \n + \n + / / make sure accessors are added , otherwise javassist will fail with \n + / / javassist . CannotCompileException : [ source error ] realmGet $ id ( ) not found in ' foo . Model ' \n + addRealmAccessors ( fieldAccessCtClass ) \n + \n realm - transformer \ src \ main \ kotlin \ io \ realm \ transformer \ RealmTransformer . kt \n - build . prepareReferencedClasses ( referencedInputs ! ! ) ; \n + build . prepareReferencedClasses ( referencedInputs ! ! ) \n - build . transformModelClasses ( ) ; \n + build . transformModelClasses ( ) \n - build . transformDirectAccessToModelFields ( ) ; \n + build . transformDirectAccessToModelFields ( ) \n - build . copyResourceFiles ( ) ; \n + build . copyResourceFiles ( ) \n",Incremental build causing direct access to model without accessor to fail ( # 6058 ),349
version . txt \n - 5 . 0 . 1 \n + 5 . 0 . 2 - SNAPSHOT \n,Prepare next release v5 . 0 . 2 - SNAPSHOT,349
"Jenkinsfile \n + stage ( ' Gradle plugin tests ' ) { \n + try { \n + gradle ( ' gradle - plugin ' , ' check ' ) \n + } finally { \n + storeJunitResults ' gradle - plugin / build / test - results / test / TEST - * . xml ' \n + } \n + } \n + \n + stage ( ' Realm Transformer tests ' ) { \n + try { \n + gradle ( ' realm - transformer ' , ' check ' ) \n + } finally { \n + storeJunitResults ' realm - transformer / build / test - results / test / TEST - * . xml ' \n + } \n + } \n + \n gradle - plugin \ src \ test \ groovy \ io \ realm \ gradle \ PluginTest . groovy \n + import io . realm . transformer . RealmTransformer \n + \n - import static org . junit . Assert . assertFalse \n - public void setUp ( ) { \n + void setUp ( ) { \n - public void pluginAddsRightDependencies ( ) { \n + void pluginAddsRightDependencies ( ) { \n - assertTrue ( containsUrl ( project . repositories , ' https : / / jitpack . io ' ) ) \n - \n - public void pluginFailsWithoutAndroidPlugin ( ) { \n + void pluginFailsWithoutAndroidPlugin ( ) { \n - def compileConfiguration = configurationContainer . findByName ( "" compile "" ) \n + def compileConfiguration = configurationContainer . findByName ( "" api "" ) \n",Fixing Plugin Test ( # 5672 ) \n * Fixing Plugin Test ( not passing ) \n * Added a Jenkins step to run Gradle plugin tests \n * Added a Jenkins step to run Transformer tests,349
CHANGELOG . md \n + * Prevent Realms Gradle plugin from transitively forcing specific versions of Google Build Tools onto downstream projects ( # 5640 ) . \n gradle - plugin \ build . gradle \n - provided ' com . android . tools . build : gradle : 3 . 1 . 0 - alpha06 ' \n + compileOnly ' com . android . tools . build : gradle : 3 . 1 . 0 - alpha06 ' \n + testCompile ' com . android . tools . build : gradle : 3 . 1 . 0 - alpha06 ' \n realm - transformer \ build . gradle \n - provided ' com . android . tools . build : gradle : 3 . 1 . 0 - alpha06 ' \n + compileOnly ' com . android . tools . build : gradle : 3 . 1 . 0 - alpha06 ' \n,fixing deps scope ( # 5675 ) \n * fixing scope of maven - publish POM files,349
"dependencies . list \n - REALM _ OBJECT _ SERVER _ DE _ VERSION = 2 . 5 . 1 \n + REALM _ OBJECT _ SERVER _ DE _ VERSION = 2 . 1 . 0 \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ AuthTests . java \n + @ Ignore ( "" Test still times out https : / / github . com / realm / realm - java / issues / 5681 "" ) \n","Nh / reverting ros to fix tests ( # 5682 ) \n * Reverting to ROS 2 . 1 . 0 for tests , since we have permission tests flakiness with 2 . 5 . 1",349
tools \ sync _ test _ server \ Dockerfile \n - RUN npm install winston temp httpdispatcher @ 1 . 0 . 0 fs - extra moment \n + RUN npm install winston @ 2 . 4 . 0 temp httpdispatcher @ 1 . 0 . 0 fs - extra moment \n,Using a specific version of winston library ( # 5827 ),349
version . txt \n - 5 . 12 . 0 \n + 5 . 12 . 1 - SNAPSHOT \n,Prepare next release v5 . 12 . 1 - SNAPSHOT,349
version . txt \n - 5 . 13 . 0 \n + 5 . 13 . 1 - SNAPSHOT \n,Prepare next release v5 . 13 . 1 - SNAPSHOT,349
"CHANGELOG . md \n - # # 7 . 0 . 0 - beta . 0 ( YYYY - MM - DD ) \n + # # 7 . 0 . 0 - beta ( YYYY - MM - DD ) \n - * [ ObjectServer ] Query - based Sync is now the default mode of synchronization . To enable Full Realm synchronization use ` SyncConfiguration . Builder . fullSynchronization ( ) ` . ` SyncConfiguration . Builder . partialRealm ( ) ` has been deprecated . \n - * [ ObjectServer ] ` SyncConfiguration . isPartialRealm ( ) ` has been replaced by ` SyncConfiguration . isFullySynchronizedRealm ( ) ` . \n + * Core 6 only support file upgrades from the file format introduced in Realm Java 2 . 0 . \n + * [ ObjectServer ] Query - based Sync is now the default mode of synchronization . To enable Full Realm synchronization use ` SyncConfiguration . Builder . fullSynchronization ( ) ` . ` SyncConfiguration . Builder . partialRealm ( ) ` has been deprecated . \n + * [ ObjectServer ] ` SyncConfiguration . isPartialRealm ( ) ` has been replaced by ` SyncConfiguration . isFullySynchronizedRealm ( ) ` . \n - * File format : Generates Realms with format v9 ( Reads and upgrades all previous formats ) \n + * File format : Generates Realms with format v10 ( Reads and upgrades all previous formats up to Realm Java 2 . 0 ) . \n realm \ realm - library \ src \ main \ cpp \ io _ realm _ internal _ OsSharedRealm . cpp \n - table = group . add _ table ( table _ name ) ; \n - ColKey column _ key = table - > add _ column ( pkType , field _ name , is _ nullable ) ; \n - table - > add _ search _ index ( column _ key ) ; \n - table - > set _ primary _ key _ column ( column _ key ) ; \n + table = group . add _ table _ with _ primary _ key ( table _ name , pkType , field _ name , is _ nullable ) ; \n version . txt \n - 7 . 0 . 0 - beta . 0 - SNAPSHOT \n + 7 . 0 . 0 - beta - SNAPSHOT \n",- Updated Changelog version & notes \n - Fixed an issue where an index was added to a String PK ( on non Sync flavour ),349
"realm \ realm - library \ src \ main \ cpp \ io _ realm _ internal _ OsSharedRealm . cpp \n - table = group . add _ table _ with _ primary _ key ( table _ name , pkType , field _ name , is _ nullable ) ; \n + / / _ _ CORE6 _ _ work around until we decide if add _ table _ with _ primary _ key should throw if called with the same table name \n + if ( ! group . has _ table ( table _ name ) ) { \n + table = group . add _ table _ with _ primary _ key ( table _ name , pkType , field _ name , is _ nullable ) ; \n + } else { \n + throw TableNameInUse ( ) ; \n + } \n",Adding a work around to throw TableNameInUse if we try to create table with primary key using an existing name,349
"realm \ realm - library \ src \ main \ cpp \ util . cpp \n + catch ( const InvalidDatabase & e ) { \n + ss < < e . what ( ) < < "" ( "" < < e . get _ path ( ) < < "" ) in "" < < file < < "" line "" < < line ; \n + ThrowRealmFileException ( env , ss . str ( ) , realm : : RealmFileException : : Kind : : AccessError , e . get _ path ( ) ) ; \n + } \n realm \ realm - library \ src \ syncIntegrationTest \ java \ io \ realm \ objectserver \ EncryptedSynchronizedRealmTests . java \n - import io . realm . exceptions . RealmError ; \n + import io . realm . exceptions . RealmFileException ; \n - } catch ( RealmError ignored ) { \n + } catch ( RealmFileException ignored ) { \n",Throwing a RealmFileException when an invalid encryption key is used,349
"src \ clj \ backtype \ storm \ scheduler \ IsolationScheduler . clj \n - ( log - warn "" Unable to isolate topologies "" ( pr - str failed - iso - topologies ) "" . Will wait for enough resources for isolated topologies before allocating any other resources . "" ) \n + ( do \n + ( log - warn "" Unable to isolate topologies "" ( pr - str failed - iso - topologies ) "" . No machine had enough worker slots to run the remaining workers for these topologies . Clearing all other resources and will wait for enough resources for isolated topologies before allocating any other resources . "" ) \n + ; ; clear workers off all hosts that are not blacklisted \n + ( doseq [ [ host slots ] ( host - > used - slots cluster ) ] \n + ( if - not ( . isBlacklistedHost cluster host ) \n + ( . freeSlots cluster slots ) \n + ) ) ) \n src \ jvm \ backtype \ storm \ scheduler \ Cluster . java \n + \n + public boolean isBlacklistedHost ( String host ) { \n + return blackListedHosts ! = null & & blackListedHosts . contains ( host ) ; \n + } \n",make isolationscheduler kill workers for all non - isolated topologies in case of squeezed cluster to make room for remaining isolated topology workers,355
"src \ jvm \ backtype \ storm \ utils \ ShellProcess . java \n + errorMessage . append ( "" Shell Process Exception : \ n "" ) ; \n + errorMessage . append ( getErrorsString ( ) + "" \ n "" ) ; \n",add back in dumping of error stream when pipe to subprocess is broken,355
". gitignore \n - / target \n - / storm - core / target \n + target \n VERSION \n - 0 . 9 . 0 - wip17 \n + 0 . 9 . 0 - wip19 \n storm - netty \ project . clj \n - : url "" http : / / storm - project . net "" \n - : description "" Distributed and fault - tolerant realtime computation "" \n - : license { : name "" Eclipse Public License - Version 1 . 0 "" : url "" https : / / github . com / nathanmarz / storm / blob / master / LICENSE . html "" } \n - : mailing - list { : name "" Storm user mailing list "" \n - : archive "" https : / / groups . google . com / group / storm - user "" \n - : post "" storm - user @ googlegroups . com "" } \n - : source - paths [ "" src / jvm "" ] \n - : aot : all ) ) \n + : aot : all ) ) \n storm - netty \ test \ clj \ backtype \ storm \ messaging \ netty _ integration _ test . clj \n + : storm - conf { TOPOLOGY - WORKERS 3 } \n","ensure netty test uses netty transport , slim down project . clj , bump version",355
"storm - core \ src \ jvm \ storm \ trident \ testing \ LRUMemoryMapState . java \n - return new LRUMemoryMapState ( _ maxSize , _ id ) ; \n + return new LRUMemoryMapState ( _ maxSize , _ id + partitionIndex ) ; \n storm - core \ src \ jvm \ storm \ trident \ testing \ MemoryMapState . java \n - return new MemoryMapState ( _ id ) ; \n + return new MemoryMapState ( _ id + partitionIndex ) ; \n storm - core \ test \ clj \ storm \ trident \ integration _ test . clj \n + ( . broadcast ) \n","fix memorymapstate and lrumemorymapstate to avoid concurrent access to same map , update trident integration test of getting all tuples to properly do broadcast",355
"src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( : port worker ) ) ] \n + ( : port worker ) ) \n + state ( worker - state conf ( : worker - id worker ) ) ] \n - ( . put ( worker - state conf ( : worker - id worker ) ) \n + ( . put state \n - hb ) \n + hb \n + false \n + ) \n + ( . cleanup state 60 ) ; this is just in case supervisor is down so that disk doesn ' t fill up . \n + ; it shouldn ' t take supervisor 120 seconds between listing dir and reading it \n + \n src \ jvm \ backtype \ storm \ utils \ LocalState . java \n + put ( key , val , true ) ; \n + } \n + \n + public synchronized void put ( Object key , Object val , boolean cleanup ) throws IOException { \n - persist ( curr ) ; \n + persist ( curr , cleanup ) ; \n + remove ( key , true ) ; \n + } \n + \n + public synchronized void remove ( Object key , boolean cleanup ) throws IOException { \n - persist ( curr ) ; \n + persist ( curr , cleanup ) ; \n + } \n + \n + public synchronized void cleanup ( int keepVersions ) throws IOException { \n + _ vs . cleanup ( keepVersions ) ; \n - private void persist ( Map < Object , Object > val ) throws IOException { \n + private void persist ( Map < Object , Object > val , boolean cleanup ) throws IOException { \n - _ vs . cleanup ( 4 ) ; \n + if ( cleanup ) _ vs . cleanup ( 4 ) ; \n",greatly lesson likelihood of race condition between supervisor and worker,355
"src \ jvm \ backtype \ storm \ utils \ LocalState . java \n + \n - String latestPath = _ vs . mostRecentVersionPath ( ) ; \n - if ( latestPath = = null ) return new HashMap < Object , Object > ( ) ; \n - return ( Map < Object , Object > ) Utils . deserialize ( FileUtils . readFileToByteArray ( new File ( latestPath ) ) ) ; \n + int attempts = 0 ; \n + while ( true ) { \n + String latestPath = _ vs . mostRecentVersionPath ( ) ; \n + if ( latestPath = = null ) return new HashMap < Object , Object > ( ) ; \n + try { \n + return ( Map < Object , Object > ) Utils . deserialize ( FileUtils . readFileToByteArray ( new File ( latestPath ) ) ) ; \n + } catch ( IOException e ) { \n + attempts + + ; \n + if ( attempts > = 10 ) { \n + throw e ; \n + } \n + } \n + } \n",have localstate try again if exception while trying to read from disk,355
"storm - core \ project . clj \n - [ storm / libthrift7 "" 0 . 7 . 0 "" \n + [ storm / libthrift7 "" 0 . 7 . 0 - 1 "" \n",bump thrift version to pull in d2r changes,355
"storm - core \ src \ clj \ backtype \ storm \ daemon \ logviewer . clj \n + ( : use [ hiccup core page - helpers ] ) \n - ( : use [ backtype . storm . ui . core : only [ ui - template ] ] ) \n + ( defn log - template [ body ] \n + ( html \n + [ : head \n + [ : title "" Storm log viewer "" ] \n + ( include - css "" / css / bootstrap - 1 . 1 . 0 . css "" ) \n + ( include - css "" / css / style . css "" ) \n + ( include - js "" / js / jquery - 1 . 6 . 2 . min . js "" ) \n + ( include - js "" / js / jquery . tablesorter . min . js "" ) \n + ( include - js "" / js / jquery . cookies . 2 . 2 . 0 . min . js "" ) \n + ( include - js "" / js / script . js "" ) \n + ] \n + [ : body \n + ( seq body ) \n + ] ) ) \n + \n - ( ui - template ( log - page ( : file m ) ( : tail m ) ( : grep m ) ) ) ) \n + ( log - template ( log - page ( : file m ) ( : tail m ) ( : grep m ) ) ) ) \n - ( ui - template ( log - level - page ( : name m ) ( : level m ) ) ) ) \n + ( log - template ( log - level - page ( : name m ) ( : level m ) ) ) ) \n storm - core \ src \ clj \ backtype \ storm \ ui \ core . clj \n - host ( * STORM - CONF * LOGVIEWER - PORT ) port ) ( str port "" log "" ) ) ) \n + host ( * STORM - CONF * LOGVIEWER - PORT ) port ) ( str port ) ) ) \n","remove UI template from log because it doesn ' t link to right place , remove ' log ' from port display",355
"src \ jvm \ backtype \ storm \ utils \ NimbusClient . java \n - Integer timeout = Utils . getInt ( conf . get ( Config . NIMBUS _ TASK _ TIMEOUT _ SECS ) ) ; \n - return new NimbusClient ( conf , nimbusHost , nimbusPort , timeout ) ; \n + return new NimbusClient ( conf , nimbusHost , nimbusPort ) ; \n",remove the use of NIMBUS _ TASK _ TIMEOUT _ SECS from NimbusClient,355
"src \ jvm \ backtype \ storm \ task \ ShellBolt . java \n - throw new RuntimeException ( e ) ; \n + throw new RuntimeException ( "" Error when launching multilang subprocess "" , e ) ; \n - throw new RuntimeException ( e ) ; \n + throw new RuntimeException ( "" Error during multilang processing "" , e ) ; \n",better error messages when problem with multilang subprocess,356
src \ clj \ backtype \ storm \ ui \ core . clj \n - ( - > ( component - page id ( Integer / parseInt component ) ( : window m ) ) \n + ( - > ( component - page id component ( : window m ) ) \n,fix bug in displaying component pages in UI,356
"bin \ storm \n + def identity ( x ) : \n + return x \n + \n + def cygpath ( x ) : \n + command = [ "" cygpath "" , "" - wp "" , x ] \n + p = sub . Popen ( command , stdout = sub . PIPE ) \n + output , errors = p . communicate ( ) \n + lines = output . split ( "" \ n "" ) \n + return lines [ 0 ] \n + \n + if sys . platform = = "" cygwin "" : \n + normclasspath = cygpath \n + else : \n + normclasspath = identity \n + \n - return "" : "" . join ( ret ) \n + return normclasspath ( "" : "" . join ( ret ) ) \n",make storm client work on windows under cygwin,356
"src \ jvm \ backtype \ storm \ drpc \ ReturnResults . java \n + import org . apache . log4j . Logger ; \n + public static final Logger LOG = Logger . getLogger ( ReturnResults . class ) ; \n + LOG . error ( "" Failed to return results to DRPC server "" , e ) ; \n",log errors when returning results fails in ReturnResults,356
src \ jvm \ backtype \ storm \ Config . java \n - * The maximum parallelism allowed for a component in this topology . This configuration is \n - * typically used in testing to limit the number of threads spawned in local mode . \n + * The maximum number of tuples that can be pending on a spout at any given time . A pending \n + * tuple is one that has been emitted from a spout but has not been acked or failed yet . \n + * Note that this config parameter has no effect for unreliable spouts that don ' t tag \n + * their tuples with a message id . \n,fix javadoc for TOPOLOGY _ MAX _ SPOUT _ PENDING,356
"src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n + / * * \n + * Gets the declared output fields for the specified global stream id . \n + * / \n + public Fields getComponentOutputFields ( GlobalStreamId id ) { \n + return getComponentOutputFields ( id . get _ componentId ( ) , id . get _ streamId ( ) ) ; \n + } \n + \n src \ jvm \ backtype \ storm \ tuple \ Tuple . java \n + import backtype . storm . generated . GlobalStreamId ; \n + \n + / * * \n + * Returns the global stream id ( component + stream ) of this tuple . \n + * / \n + public GlobalStreamId getSourceGlobalStreamid ( ) { \n + return new GlobalStreamId ( getSourceComponent ( ) , streamId ) ; \n + } \n + \n",more convenience methods for introspection of Tuple and context,356
"bin \ storm \n - def exec _ storm _ class ( klass , jvmtype = "" - server "" , childopts = "" "" , extrajars = [ ] , args = [ ] , prefix = "" "" ) : \n + def exec _ storm _ class ( klass , jvmtype = "" - server "" , childopts = "" "" , extrajars = [ ] , args = [ ] ) : \n - command = prefix + "" java "" + jvmtype + "" - Djava . library . path = "" + nativepath + "" "" + childopts + "" - cp "" + get _ classpath ( extrajars ) + "" "" + klass + "" "" + "" "" . join ( args ) \n + command = "" java "" + jvmtype + "" - Djava . library . path = "" + nativepath + "" "" + childopts + "" - cp "" + get _ classpath ( extrajars ) + "" "" + klass + "" "" + "" "" . join ( args ) \n - prefix = "" export STORM _ JAR = "" + jarfile + "" ; "" ) \n + childopts = "" - Dstorm . jar = "" + jarfile ) \n src \ jvm \ backtype \ storm \ StormSubmitter . java \n - String localJar = System . getenv ( "" STORM _ JAR "" ) ; \n + String localJar = System . getProperty ( "" storm . jar "" ) ; \n",pass jar name in using java property rather than environment var,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( launch - process command ) \n + ( launch - process command : environment { "" LD _ LIBRARY _ PATH "" ( conf JAVA - LIBRARY - PATH ) } ) \n src \ clj \ backtype \ storm \ util . clj \n - ( defn launch - process [ command ] \n + ( defnk launch - process [ command : environment { } ] \n - builder ( ProcessBuilder . ( cons "" nohup "" command ) ) ] \n + builder ( ProcessBuilder . ( cons "" nohup "" command ) ) \n + process - env ( . environment builder ) ] \n + ( doseq [ [ k v ] environment ] \n + ( . put process - env k v ) ) \n",set LD _ LIBRARY _ PATH environment variable on worker subprocess,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + ; ; active - > check reassign every X seconds ( or do so when something fails ) \n + ; ; inactive - > don ' t do anything \n + ; ; rebalance - > sleep for X seconds and then \n + ; ; what if a topology is killed while rebalancing ? need to clear out its scheduled tasks . \n + ; ; have another thread that every X seconds schedules rebalance for all active topologies \n + \n + \n + ( log - message "" Starting Nimbus with conf "" conf ) \n src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n + ( log - message "" Starting Supervisor with conf "" conf ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( log - message "" Launching worker for "" storm - id "" on "" supervisor - id "" : "" port "" with id "" worker - id ) \n + ( log - message "" Launching worker for "" storm - id "" on "" supervisor - id "" : "" port "" with id "" worker - id \n + "" and conf "" conf ) \n","log conf on nimbus , supervisor , and worker startup",356
"src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n + final static int SERIALIZATION _ LIMIT _ SIZE = 64 * 1024 - 1 ; \n + \n - stream . writeUTF ( object ) ; \n + / / this hack is here because writeUTF doesn ' t work for strings greater than 64K \n + / / but writeUTF seems to be twice than writing the byte array directly , so there ' s \n + / / a switch here based on the size of the string \n + if ( object . length ( ) < = SERIALIZATION _ LIMIT _ SIZE ) { \n + stream . writeInt ( - 1 ) ; \n + stream . writeUTF ( object ) ; \n + } else { \n + byte [ ] bytes = object . getBytes ( ) ; \n + stream . writeInt ( bytes . length ) ; \n + stream . write ( bytes ) ; \n + } \n - return stream . readUTF ( ) ; \n + int size = stream . readInt ( ) ; \n + if ( size = = - 1 ) { \n + return stream . readUTF ( ) ; \n + } else { \n + byte [ ] bytes = new byte [ size ] ; \n + stream . readFully ( bytes ) ; \n + return new String ( bytes ) ; \n + } \n",fix bug preventing strings > 64K from serializing,356
"project . clj \n + [ org . apache . httpcomponents / httpclient "" 4 . 1 . 1 "" ] \n",override httpclient dependency to be version 4 . 1 . 1 to fix conflicts with aws sdk,356
"src \ jvm \ backtype \ storm \ tuple \ Tuple . java \n + import clojure . lang . ILookup ; \n + import clojure . lang . Keyword ; \n + import clojure . lang . Symbol ; \n - public class Tuple { \n + public class Tuple implements ILookup { \n + \n + private static final Keyword makeKeyword ( String name ) { \n + return Keyword . intern ( Symbol . create ( name ) ) ; \n + } \n + \n + private static final Keyword STREAM _ KEYWORD = makeKeyword ( "" stream "" ) ; \n + private static final Keyword COMPONENT _ KEYWORD = makeKeyword ( "" component "" ) ; \n + private static final Keyword TASK _ KEYWORD = makeKeyword ( "" task "" ) ; \n + \n + @ Override \n + public Object valAt ( Object o ) { \n + if ( o . equals ( STREAM _ KEYWORD ) ) { \n + return getSourceStreamId ( ) ; \n + } else if ( o . equals ( COMPONENT _ KEYWORD ) ) { \n + return getSourceComponent ( ) ; \n + } else if ( o . equals ( TASK _ KEYWORD ) ) { \n + return getSourceTask ( ) ; \n + } \n + return null ; \n + } \n + \n + @ Override \n + public Object valAt ( Object o , Object def ) { \n + Object ret = valAt ( o ) ; \n + if ( ret = = null ) ret = def ; \n + return ret ; \n + } \n",make it possible to lookup metadata from Tuples in clojure using keywords,356
"bin \ build _ release . sh \n - mv conf / log4j . properties conf / storm . log . properties \n - mv conf / storm . log . properties conf / log4j . properties \n bin \ storm \n - childopts = "" - Dlog4j . configuration = storm . log . properties "" , \n - exec _ storm _ class ( "" backtype . storm . command . kill _ topology "" , args = [ name ] , jvmtype = "" - client "" , extrajars = [ CONF _ DIR , STORM _ DIR + "" / bin "" ] , childopts = "" - Dlog4j . configuration = storm . log . properties "" ) \n + exec _ storm _ class ( "" backtype . storm . command . kill _ topology "" , args = [ name ] , jvmtype = "" - client "" , extrajars = [ CONF _ DIR , STORM _ DIR + "" / bin "" ] ) \n - exec _ storm _ class ( "" backtype . storm . command . shell _ submission "" , args = runnerargs , jvmtype = "" - client "" , extrajars = [ CONF _ DIR ] , childopts = "" - Dlog4j . configuration = storm . log . properties "" ) \n + exec _ storm _ class ( "" backtype . storm . command . shell _ submission "" , args = runnerargs , jvmtype = "" - client "" , extrajars = [ CONF _ DIR ] ) \n - childopts = confvalue ( "" nimbus . childopts "" ) + "" - Dlogfile . name = nimbus . log "" \n + childopts = confvalue ( "" nimbus . childopts "" ) + "" - Dlogfile . name = nimbus . log - Dlog4j . configuration = storm . log . properties "" \n - childopts = confvalue ( "" nimbus . childopts "" ) + "" - Dlogfile . name = supervisor . log "" \n + childopts = confvalue ( "" nimbus . childopts "" ) + "" - Dlogfile . name = supervisor . log - Dlog4j . configuration = storm . log . properties "" \n - childopts = "" - Xmx768m - Dlogfile . name = ui . log "" \n + childopts = "" - Xmx768m - Dlogfile . name = ui . log - Dlog4j . configuration = storm . log . properties "" \n rename from log4j \ log4j . properties \n rename to log4j \ storm . log . properties \n src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n + "" - Dlog4j . configuration = storm . log . properties "" \n","fix logging to use rolling file in production , console everywhere else",356
"project . clj \n - ( defproject storm "" 0 . 5 . 2 "" \n + ( defproject storm "" 0 . 5 . 3 - SNAPSHOT "" \n",starting 0 . 5 . 3 - SNAPSHOT,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ) ) \n + ) ) ) \n + ( when - not ( . get state LS - WORKER - HEARTBEAT ) \n + ( log - message "" Worker "" id "" failed to start "" ) \n",make supervisor log when a worker fails to start within the start timeout,356
src \ clj \ backtype \ storm \ clojure . clj \n - ( : use backtype . storm . bootstrap ) \n + ( : use [ clojure . contrib . def : only [ defnk ] ] ) \n + ( : use [ backtype . storm bootstrap util ] ) \n + ( : import [ backtype . storm . utils Utils ] ) \n + \n + ( defnk emit ! [ ^ OutputCollector collector ^ List values : stream Utils / DEFAULT _ STREAM _ ID : anchor [ ] ] \n + ( let [ ^ List anchor ( collectify anchor ) ] \n + ( . emit collector stream ( collectify anchor ) values ) ) ) \n + \n + ( defnk emit - direct ! [ ^ OutputCollector collector task ^ List values : stream Utils / DEFAULT _ STREAM _ ID : anchor [ ] ] \n + ( let [ ^ List anchor ( collectify anchor ) ] \n + ( . emitDirect collector task stream ( collectify anchor ) values ) ) ) \n + \n + ( defn ack ! [ ^ OutputCollector collector ^ Tuple tuple ] \n + ( . ack collector tuple ) ) \n test \ clj \ backtype \ storm \ integration _ test . clj \n - ( . emit collector tuple [ i ] ) ) \n - ( . ack collector tuple ) ) \n + ( emit ! collector [ i ] : anchor tuple ) ) \n + ( ack ! collector tuple ) ) \n - ( . emit collector @ seen [ 1 ] ) \n + ( emit ! collector [ 1 ] : anchor @ seen ) \n - ( . ack collector s ) ) \n + ( ack ! collector s ) ) \n - ( . ack collector tuple ) ) \n + ( ack ! collector tuple ) ) \n - ( . emit collector tuple ( . getValues tuple ) ) \n - ( . ack collector tuple ) ) \n + ( emit ! collector ( . getValues tuple ) : anchor tuple ) \n + ( ack ! collector tuple ) ) \n - ( . emit collector [ tuple tuple ] [ 1 ] ) \n - ( . ack collector tuple ) ) \n + ( emit ! collector [ 1 ] : anchor [ tuple tuple ] ) \n + ( ack ! collector tuple ) ) \n,added emit and acking helpers to clojure dsl,356
src \ clj \ backtype \ storm \ clojure . clj \n + ( defalias shell - bolt - spec thrift / mk - shell - bolt - spec ) \n src \ clj \ backtype \ storm \ thrift . clj \n - ( defnk mk - spout - spec [ spout : parallelism - hint nil ] \n - ( SpoutSpec . ( ComponentObject / serialized _ java ( Utils / serialize spout ) ) \n - ( mk - component - common spout parallelism - hint ) \n - ( . isDistributed spout ) ) \n - ) \n + ( defnk mk - spout - spec [ spout : parallelism - hint nil : p nil ] \n + ; ; for backwards compatibility \n + ( let [ parallelism - hint ( if p p parallelism - hint ) ] \n + ( SpoutSpec . ( ComponentObject / serialized _ java ( Utils / serialize spout ) ) \n + ( mk - component - common spout parallelism - hint ) \n + ( . isDistributed spout ) ) \n + ) ) \n - ( defnk mk - bolt - spec [ inputs bolt : parallelism - hint nil ] \n - ( let [ bolt ( if ( instance ? IBasicBolt bolt ) ( BasicBoltExecutor . bolt ) bolt ) ] \n + ( defnk mk - bolt - spec [ inputs bolt : parallelism - hint nil : p nil ] \n + ; ; for backwards compatibility \n + ( let [ parallelism - hint ( if p p parallelism - hint ) \n + bolt ( if ( instance ? IBasicBolt bolt ) ( BasicBoltExecutor . bolt ) bolt ) ] \n - ( defnk mk - shell - bolt - spec [ inputs command script output - spec : parallelism - hint nil ] \n - ( Bolt . \n - ( mk - inputs inputs ) \n - ( ComponentObject / shell ( ShellComponent . command script ) ) \n - ( mk - plain - component - common output - spec parallelism - hint ) \n - ) ) \n + ( defnk mk - shell - bolt - spec [ inputs command script output - spec : parallelism - hint nil : p nil ] \n + ; ; for backwards compatibility \n + ( let [ parallelism - hint ( if p p parallelism - hint ) ] \n + ( Bolt . \n + ( mk - inputs inputs ) \n + ( ComponentObject / shell ( ShellComponent . command script ) ) \n + ( mk - plain - component - common output - spec parallelism - hint ) \n + ) ) ) \n,"improvements to clojure DSL : p for specifying parallelism , and access to shell bolts",356
"src \ clj \ backtype \ storm \ config . clj \n + ( defn master - local - dir [ conf ] \n + ( let [ ret ( str ( conf STORM - LOCAL - DIR ) "" / nimbus "" ) ] \n + ( FileUtils / forceMkdir ( File . ret ) ) \n + ret \n + ) ) \n + \n - ( str ( conf STORM - LOCAL - DIR ) "" / stormdist / "" storm - id ) ) \n + ( str ( master - local - dir conf ) "" / stormdist / "" storm - id ) ) \n - ( let [ ret ( str ( conf STORM - LOCAL - DIR ) "" / inbox "" ) ] \n + ( let [ ret ( str ( master - local - dir conf ) "" / inbox "" ) ] \n + ( defn supervisor - local - dir [ conf ] \n + ( let [ ret ( str ( conf STORM - LOCAL - DIR ) "" / supervisor "" ) ] \n + ( FileUtils / forceMkdir ( File . ret ) ) \n + ret \n + ) ) \n + \n - ( [ conf ] ( str ( conf STORM - LOCAL - DIR ) "" / stormdist "" ) ) \n + ( [ conf ] ( str ( supervisor - local - dir conf ) "" / stormdist "" ) ) \n - ( let [ ret ( str ( conf STORM - LOCAL - DIR ) "" / tmp "" ) ] \n + ( let [ ret ( str ( supervisor - local - dir conf ) "" / tmp "" ) ] \n - ( LocalState . ( str ( conf STORM - LOCAL - DIR ) "" / localstate "" ) ) ) \n + ( LocalState . ( str ( supervisor - local - dir conf ) "" / localstate "" ) ) ) \n",allow nimbus and supervisor to share local dir,356
"project . clj \n - ( defproject storm "" 0 . 5 . 3 "" \n + ( defproject storm "" 0 . 5 . 4 - SNAPSHOT "" \n",starting 0 . 5 . 4 - SNAPSHOT,356
"src \ clj \ backtype \ storm \ daemon \ task . clj \n - ( . report - task - error storm - cluster - state storm - id task - id error ) \n - ( halt - process ! 1 "" Task died ! "" ) ) \n + ( . report - task - error storm - cluster - state storm - id task - id error ) ) \n + \n + report - error - and - die ( fn [ error ] \n + ( report - error error ) \n + ( halt - process ! 1 "" Task died "" ) ) \n - : kill - fn report - error ) \n + : kill - fn report - error - and - die ) \n - : kill - fn report - error ) ) \n + : kill - fn report - error - and - die ) ) \n",don ' t die on a user report error,356
"src \ jvm \ backtype \ storm \ utils \ Utils . java \n - InputStream is = Object . class . getResourceAsStream ( "" / "" + name ) ; \n + InputStream is = Utils . class . getResourceAsStream ( "" / "" + name ) ; \n",change how Storm looks for configs to play nicely with sbt,356
"src \ jvm \ backtype \ storm \ utils \ Utils . java \n + import java . net . URL ; \n + import java . util . Enumeration ; \n - / / It ' s important to use Utils . class here instead of Object . class here . \n - / / If Object . class is used , sbt can ' t find defaults . yaml \n - InputStream is = Utils . class . getResourceAsStream ( "" / "" + name ) ; \n - if ( is = = null ) { \n - if ( mustExist ) throw new RuntimeException ( "" Could not find config file on classpath "" + name ) ; \n - else return new HashMap ( ) ; \n + try { \n + Enumeration resources = Thread . currentThread ( ) . getContextClassLoader ( ) . getResources ( name ) ; \n + if ( ! resources . hasMoreElements ( ) ) { \n + if ( mustExist ) throw new RuntimeException ( "" Could not find config file on classpath "" + name ) ; \n + else return new HashMap ( ) ; \n + } \n + URL resource = ( URL ) resources . nextElement ( ) ; \n + Map ret = ( Map ) YAML . load ( new InputStreamReader ( resource . openStream ( ) ) ) ; \n + if ( ret = = null ) ret = new HashMap ( ) ; \n + \n + if ( resources . hasMoreElements ( ) ) { \n + throw new RuntimeException ( "" Found multiple "" + name + "" resources "" ) ; \n + } \n + return new HashMap ( ret ) ; \n + \n + } catch ( IOException e ) { \n + throw new RuntimeException ( e ) ; \n - Map ret = ( Map ) YAML . load ( new InputStreamReader ( is ) ) ; \n - if ( ret = = null ) ret = new HashMap ( ) ; \n - return new HashMap ( ret ) ; \n",throw error if detect multiple defaults . yaml or storm . yaml files of the same name,356
"new file \n test \ clj \ backtype \ storm \ drpc _ test . clj \n + ( ns backtype . storm . drpc - test \n + ( : use [ clojure test ] ) \n + ( : import [ backtype . storm . drpc ReturnResults DRPCSpout ] ) \n + ( : import [ backtype . storm LocalDRPC LocalCluster ] ) \n + ( : use [ backtype . storm bootstrap testing ] ) \n + ( : use [ backtype . storm . daemon common ] ) \n + ( : use [ backtype . storm clojure ] ) \n + ) \n + \n + ( bootstrap ) \n + \n + ( defbolt exclamation - bolt [ "" result "" "" return - info "" ] [ tuple collector ] \n + ( emit - bolt ! collector \n + [ ( str ( . getString tuple 0 ) "" ! ! ! "" ) ( . getValue tuple 1 ) ] \n + : anchor tuple ) \n + ) \n + \n + ( deftest test - drpc - flow \n + ( let [ drpc ( LocalDRPC . ) \n + spout ( DRPCSpout . "" test "" drpc ) \n + cluster ( LocalCluster . ) \n + topology ( topology \n + { 1 ( spout - spec spout ) } \n + { 2 ( bolt - spec { 1 : shuffle } \n + exclamation - bolt ) \n + 3 ( bolt - spec { 2 : shuffle } \n + ( ReturnResults . ) ) } ) ] \n + ( . submitTopology cluster "" test "" { TOPOLOGY - DEBUG true } topology ) \n + \n + ( is ( = "" aaa ! ! ! "" ) ( . execute drpc "" test "" "" aaa "" ) ) \n + ( is ( = "" b ! ! ! "" ) ( . execute drpc "" test "" "" b "" ) ) \n + ( is ( = "" c ! ! ! "" ) ( . execute drpc "" test "" "" c "" ) ) \n + \n + \n + ( . shutdown cluster ) \n + ( . shutdown drpc ) \n + ) ) \n","finished simplified drpc , added test of local workflow",356
"project . clj \n - ( defproject storm "" 0 . 5 . 4 "" \n + ( defproject storm "" 0 . 5 . 5 - SNAPSHOT "" \n",starting 0 . 5 . 5 - SNAPSHOT,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - childopts ( conf WORKER - CHILDOPTS ) \n + childopts ( . replaceAll ( conf WORKER - CHILDOPTS ) "" % ID % "" ( str port ) ) \n",support % ID % template string in worker childopts,356
"bin \ storm \n - COMMAND = sys . argv [ 1 ] \n - ARGS = sys . argv [ 2 : ] \n - \n - COMMANDS [ COMMAND ] ( * ARGS ) \n + def print _ commands ( ) : \n + global COMMANDS \n + cmds = COMMANDS . keys ( ) \n + cmds . sort ( ) \n + print "" Commands : \ n \ t "" , reduce ( lambda x , y : x + ' , ' + y , cmds [ 1 : ] , cmds [ 0 ] ) \n + \n + def print _ usage ( msg = None ) : \n + if msg ! = None : \n + print msg \n + print _ commands ( ) \n + \n + def main ( ) : \n + if len ( sys . argv ) < = 1 : \n + print _ usage ( ) \n + sys . exit ( - 1 ) \n + \n + COMMAND = sys . argv [ 1 ] \n + ARGS = sys . argv [ 2 : ] \n + COMMANDS [ COMMAND ] ( * ARGS ) \n + \n + if _ _ name _ _ = = "" _ _ main _ _ "" : \n + main ( ) \n",print usage if no arguments given to storm script,356
src \ clj \ backtype \ storm \ daemon \ task . clj \n - [ exec ( mk - executors task - object storm - conf puller send - fn \n - storm - active - atom topology - context \n - task - stats report - error ) ] \n + [ exec ( with - error - reaction report - error - and - die \n + ( mk - executors task - object storm - conf puller send - fn \n + storm - active - atom topology - context \n + task - stats report - error ) ) ] \n src \ clj \ backtype \ storm \ util . clj \n + \n + ( defmacro with - error - reaction [ afn & body ] \n + ` ( try ~ @ body \n + ( catch Throwable t # ( ~ afn t # ) ) ) ) \n,report errors during preparation of spouts / bolts,356
src \ clj \ backtype \ storm \ clojure . clj \n - ( : import [ backtype . storm LocalCluster StormSubmitter ] ) \n + ( : import [ backtype . storm StormSubmitter ] ) \n - ( defn local - cluster [ ] \n - ( LocalCluster . ) ) \n + ( defn local - cluster [ ] \n + ; ; do this to avoid a cyclic dependency of \n + ; ; LocalCluster - > testing - > nimbus - > bootstrap - > clojure - > LocalCluster \n + ( eval ' ( new backtype . storm . LocalCluster ) ) \n,avoid cyclic dependency between LocalCluster and backtype . storm . clojure,356
"src \ clj \ backtype \ storm \ daemon \ acker . clj \n - ( reify IBolt \n + ( reify IRichBolt \n + ( declareOutputFields [ this declarer ] \n + ( . declareStream declarer ACKER - ACK - STREAM - ID true ( Fields . [ "" id "" ] ) ) \n + ( . declareStream declarer ACKER - FAIL - STREAM - ID true ( Fields . [ "" id "" ] ) ) ) \n - ( . declareStream declarer ACKER - ACK - STREAM - ID true ( Fields . [ "" id "" ] ) ) \n - ( . declareStream declarer ACKER - FAIL - STREAM - ID true ( Fields . [ "" id "" ] ) ) ) \n + ( . declareOutputFields ( mk - acker - bolt ) declarer ) ) \n src \ clj \ backtype \ storm \ daemon \ common . clj \n - ( . put _ to _ bolts ret "" _ _ acker "" acker - bolt ) \n + ( . put _ to _ bolts ret "" _ _ acker "" acker - bolt ) \n src \ clj \ backtype \ storm \ testing . clj \n - all - ids ( concat ( keys spouts ) ( keys bolts ) ) \n - max - id ( apply max all - ids ) \n - ( inc max - id ) \n + ( uuid ) \n - ( def TRACKER - BOLT - ID "" _ _ tracker "" ) \n + ( def TRACKER - BOLT - ID "" + + + tracker - bolt "" ) \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - if ( id . get _ componentId ( ) = = componentId ) { \n + if ( id . get _ componentId ( ) . equals ( componentId ) ) { \n src \ jvm \ backtype \ storm \ tuple \ MessageId . java \n - return _ anchorsToIds = = ( ( MessageId ) other ) . _ anchorsToIds ; \n + return _ anchorsToIds . equals ( ( ( MessageId ) other ) . _ anchorsToIds ) ; \n",mostly working . . . tracked topologies not,356
"project . clj \n + [ storm / carbonite "" 1 . 0 . 0 "" ] \n src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n + import carbonite . JavaBridge ; \n - / / TODO : do clojure persistent data structures \n + JavaBridge clojureSerializersBridge = new JavaBridge ( ) ; \n + clojureSerializersBridge . registerClojureCollections ( k ) ; \n + clojureSerializersBridge . registerClojurePrimitives ( k ) ; \n + \n test \ clj \ backtype \ storm \ serialization _ test . clj \n + \n + ( deftest test - clojure - serialization \n + ( is - roundtrip [ : a ] ) \n + ( is - roundtrip [ [ "" a "" 1 2 : a ] 2 "" aaa "" ] ) \n + ( is - roundtrip [ # { : a : b : c } ] ) \n + ( is - roundtrip [ # { : a : b } 1 2 [ "" a "" 3 5 # { 5 6 } ] ] ) \n + ( is - roundtrip [ { : a [ 1 2 # { : a : b 1 } ] : b 3 } ] ) ) \n",added clojure primitives / collections serialization using carbonite,356
"src \ jvm \ backtype \ storm \ drpc \ CoordinatedBolt . java \n + import backtype . storm . generated . GlobalStreamId ; \n + \n + @ Override \n + public String toString ( ) { \n + return "" < Single : "" + singleCount + "" > "" ; \n + } \n - String sourceComponent = context . getThisSources ( ) . keySet ( ) . iterator ( ) . next ( ) . get _ componentId ( ) ; \n - _ numSourceReports = context . getComponentTasks ( sourceComponent ) . size ( ) ; \n + Iterator < GlobalStreamId > it = context . getThisSources ( ) . keySet ( ) . iterator ( ) ; \n + while ( it . hasNext ( ) ) { \n + String sourceComponent = it . next ( ) . get _ componentId ( ) ; \n + if ( _ idComponent = = null | | ! sourceComponent . equals ( _ idComponent ) ) { \n + _ numSourceReports = context . getComponentTasks ( sourceComponent ) . size ( ) ; \n + break ; \n + } \n + } \n",fix bad bug introduced in CoordinatedBolt due to earlier id stream update,356
src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n + k . register ( byte [ ] . class ) ; \n,add byte [ ] as a default serialization,356
"project . clj \n - ( defproject storm "" 0 . 6 . 0 "" \n + ( defproject storm "" 0 . 6 . 1 - SNAPSHOT "" \n",starting 0 . 6 . 1 - SNAPSHOT,356
README . markdown \n - The [ Rationale page ] ( https : / / github . com / nathanmarz / storm / wiki / Rationale ) on the wiki explains what Storm is and why it was built . The [ slides ] ( http : / / www . slideshare . net / nathanmarz / storm - distributed - and - faulttolerant - realtime - computation ) from Storm ' s launch presentation also provide a good introduction to the project . \n + The [ Rationale page ] ( https : / / github . com / nathanmarz / storm / wiki / Rationale ) on the wiki explains what Storm is and why it was built . The [ video ] ( http : / / www . infoq . com / presentations / Storm ) and [ slides ] ( http : / / www . slideshare . net / nathanmarz / storm - distributed - and - faulttolerant - realtime - computation ) of Storm ' s launch presentation are also good introductions to the project . \n,link to Storm ' s launch presentation video in README,356
"src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n + import backtype . storm . generated . StreamInfo ; \n - return new Fields ( getComponentCommon ( componentId ) . get _ streams ( ) . get ( streamId ) . get _ output _ fields ( ) ) ; \n + StreamInfo streamInfo = getComponentCommon ( componentId ) . get _ streams ( ) . get ( streamId ) ; \n + if ( streamInfo = = null ) { \n + throw new IllegalArgumentException ( "" No output fields defined for component : stream "" + componentId + "" : "" + streamId ) ; \n + } \n + return new Fields ( streamInfo . get _ output _ fields ( ) ) ; \n",friendlier error message when emitting to undeclared stream,356
"new file \n bin \ to _ maven . sh \n + # ! / bin / bash \n + \n + RELEASE = ` head - 1 project . clj | awk ' { print $ 3 } ' | sed - e ' s / \ "" / / ' | sed - e ' s / \ "" / / ' ` \n + \n + rm * jar \n + rm * xml \n + lein jar \n + lein pom \n + scp storm * jar pom . xml clojars @ clojars . org : \n + \n + rm * jar \n + rm conf / log4j . properties \n + lein jar \n + mv pom . xml old - pom . xml \n + sed ' s / artifactId \ > storm / artifactId \ > storm - lib / g ' old - pom . xml > pom . xml \n + mv storm - $ RELEASE . jar storm - lib - $ RELEASE . jar \n + scp storm * jar pom . xml clojars @ clojars . org : \n + rm * xml \n + rm * jar \n + git checkout conf / log4j . properties \n",added script to upload storm and storm - lib to maven,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( when error - on - no - transition ? \n - ( throw - runtime "" No transition for event : "" event \n - "" , status : "" status , \n - "" storm - id : "" storm - id ) \n - ) ) ) \n + ( let [ msg ( str "" No transition for event : "" event \n + "" , status : "" status , \n + "" storm - id : "" storm - id ) ] \n + ( if error - on - no - transition ? \n + ( throw - runtime msg ) \n + ( log - message msg ) \n + ) ) ) ) \n",log when a transition isn ' t possible,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ; ; there ' s a minor problem where rebalancing is scheduled over and over until it finally happens \n - ; ; can fix this by either : \n - ; ; 1 . detecting whether it ' s scheduled or not . . . \n - ; ; 2 . not using monitor event , but rather some sort of "" on startup "" event \n - ; ; 3 . generating a "" rebalance id "" and only rebalancing if current status has that id \n - \n - : killed { : monitor ( fn [ ] ( delay - event nimbus \n + : killed { : startup ( fn [ ] ( delay - event nimbus \n - : rebalancing { : monitor ( fn [ ] ( delay - event nimbus \n + : rebalancing { : startup ( fn [ ] ( delay - event nimbus \n - ( let [ [ event & event - args ] ( if ( keyword ? event ) [ event ] event ) \n + ( let [ system - events # { : startup : monitor } \n + [ event & event - args ] ( if ( keyword ? event ) [ event ] event ) \n - ( do ( log - message msg ) nil ) \n - ) ) ) ) \n + ( do ( when - not ( contains ? system - events event ) \n + ( log - message msg ) ) \n + nil ) ) \n + ) ) ) \n + ( doseq [ storm - id ( . active - storms ( : storm - cluster - state nimbus ) ) ] \n + ( transition ! nimbus storm - id : startup ) ) \n - ( doseq [ storm - id ( . active - storms \n - ( : storm - cluster - state nimbus ) ) ] \n + ( doseq [ storm - id ( . active - storms ( : storm - cluster - state nimbus ) ) ] \n",added : startup transition event and replaced kill and rebalance : monitor transitions with it,356
"src \ jvm \ backtype \ storm \ coordination \ CoordinatedBolt . java \n - private String _ idComponent ; \n + private GlobalStreamId _ idSource ; \n - public CoordinatedBolt ( IRichBolt delegate , SourceArgs sourceArgs , String idComponent ) { \n + public CoordinatedBolt ( IRichBolt delegate , SourceArgs sourceArgs , GlobalStreamId idSource ) { \n - _ idComponent = idComponent ; \n + _ idSource = idSource ; \n - if ( _ idComponent = = null | | ! sourceComponent . equals ( _ idComponent ) ) { \n + / / this works because if it consumes something like PrepareRequest , sourceargs . singlecount is true \n + if ( _ idSource = = null | | ! sourceComponent . equals ( _ idSource . get _ componentId ( ) ) ) { \n - _ collector . emitDirect ( task , Constants . COORDINATED _ STREAM _ ID , new Values ( id , numTuples ) ) ; \n + _ collector . emitDirect ( task , Constants . COORDINATED _ STREAM _ ID , tup , new Values ( id , numTuples ) ) ; \n - if ( _ idComponent = = null ) track . receivedId = true ; \n + if ( _ idSource = = null ) track . receivedId = true ; \n - if ( _ idComponent ! = null \n - & & tuple . getSourceComponent ( ) . equals ( _ idComponent ) \n - & & tuple . getSourceStreamId ( ) . equals ( PrepareRequest . ID _ STREAM ) ) { \n + if ( _ idSource ! = null \n + & & tuple . getSourceComponent ( ) . equals ( _ idSource . get _ componentId ( ) ) \n + & & tuple . getSourceStreamId ( ) . equals ( _ idSource . get _ streamId ( ) ) ) { \n src \ jvm \ backtype \ storm \ drpc \ LinearDRPCTopologyBuilder . java \n + import backtype . storm . generated . GlobalStreamId ; \n - String idComponent = null ; \n + GlobalStreamId idSource = null ; \n - idComponent = PREPARE _ ID ; \n + idSource = new GlobalStreamId ( PREPARE _ ID , PrepareRequest . ID _ STREAM ) ; \n - new CoordinatedBolt ( component . bolt , source , idComponent ) , \n + new CoordinatedBolt ( component . bolt , source , idSource ) , \n - if ( idComponent ! = null ) { \n - declarer . fieldsGrouping ( idComponent , PrepareRequest . ID _ STREAM , new Fields ( "" request "" ) ) ; \n + if ( idSource ! = null ) { \n + declarer . fieldsGrouping ( idSource . get _ componentId ( ) , PrepareRequest . ID _ STREAM , new Fields ( "" request "" ) ) ; \n","generalize idstream for CoordinatedBolt , anchor direct tuples from coordinatedbolt",356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalBoltExecutor . java \n + / / bolt ! = null & & receiving commit message - > this task processed the whole batch for this attempt \n + / / this is because : commit message only send when tuple tree acked \n + / / if it failed after , then bolt will equal null , if it failed before , then it doesn ' t get acked \n - public void finishedId ( FinishedTuple id ) { \n - _ collector . setAnchor ( id ) ; \n - ITransactionalBolt bolt = _ openTransactions . get ( ( TransactionAttempt ) id ) ; \n + public void finishedId ( FinishedTuple tup ) { \n + _ collector . setAnchor ( tup ) ; \n + ITransactionalBolt bolt = _ openTransactions . get ( ( TransactionAttempt ) tup . getId ( ) ) ; \n","fix bug in TransactionalBoltExecutor , comments on validity of commit condition",356
"bin \ build _ release . sh \n + echo $ RELEASE > $ DIR / RELEASE \n + \n bin \ storm \n + if not os . path . exists ( STORM _ DIR + "" / RELEASE "" ) : \n + print "" * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * "" \n + print "" The storm client can only be run from within a release . You appear to be trying to run the client from a checkout of Storm ' s source code . "" \n + print "" \ nYou can download a Storm release at https : / / github . com / nathanmarz / storm / downloads "" \n + print "" * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * "" \n + sys . exit ( 1 ) \n + \n - print "" Commands : \ n \ t "" , reduce ( lambda x , y : x + ' , ' + y , cmds [ 1 : ] , cmds [ 0 ] ) \n + print "" Commands : \ n \ t "" , reduce ( lambda x , y : x + ' \ n \ t ' + y , cmds [ 1 : ] , cmds [ 0 ] ) \n + print "" \ nDocumentation for the storm client can be found at https : / / github . com / nathanmarz / storm / wiki / Command - line - client \ n "" \n",storm client improvements : better docs and detect when not in a release,356
src \ clj \ backtype \ storm \ timer . clj \n - ( reset ! ( : active timer ) false ) \n + ( reset ! ( : active timer ) false ) \n,fix subtle concurrency bug between cancelling a timer and schedule - recurring,356
"src \ jvm \ backtype \ storm \ StormSubmitter . java \n + import java . util . HashMap ; \n + stormConf = new HashMap ( stormConf ) ; \n + stormConf . putAll ( Utils . readCommandLineOpts ( ) ) ; \n src \ jvm \ backtype \ storm \ utils \ Utils . java \n + \n + public static Map readCommandLineOpts ( ) { \n + Map ret = new HashMap ( ) ; \n + String commandOptions = System . getProperty ( "" storm . options "" ) ; \n + if ( commandOptions ! = null ) { \n + commandOptions = commandOptions . replaceAll ( "" % % % % "" , "" "" ) ; \n + String [ ] configs = commandOptions . split ( "" , "" ) ; \n + for ( String config : configs ) { \n + String [ ] options = config . split ( "" = "" ) ; \n + if ( options . length = = 2 ) { \n + ret . put ( options [ 0 ] , options [ 1 ] ) ; \n + } \n + } \n + } \n + return ret ; \n + } \n - public static Map readStormConfig ( ) { \n - Map ret = readDefaultConfig ( ) ; \n - Map storm = findAndReadConfigFile ( "" storm . yaml "" , false ) ; \n - ret . putAll ( storm ) ; \n - String commandOptions = System . getProperty ( "" storm . options "" ) ; \n - if ( commandOptions ! = null ) { \n - commandOptions = commandOptions . replaceAll ( "" % % % % "" , "" "" ) ; \n - String [ ] configs = commandOptions . split ( "" , "" ) ; \n - for ( String config : configs ) { \n - String [ ] options = config . split ( "" = "" ) ; \n - if ( options . length = = 2 ) { \n - ret . put ( options [ 0 ] , options [ 1 ] ) ; \n - } \n - } \n - } \n - return ret ; \n - } \n + public static Map readStormConfig ( ) { \n + Map ret = readDefaultConfig ( ) ; \n + Map storm = findAndReadConfigFile ( "" storm . yaml "" , false ) ; \n + ret . putAll ( storm ) ; \n + ret . putAll ( readCommandLineOpts ( ) ) ; \n + return ret ; \n + } \n","refactor command line storm overrides , ensure they have highest priority",356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ; ; TODO : this needs to be mocked out \n new file \n src \ jvm \ backtype \ storm \ scheduler \ INimbusScheduler . java \n + package backtype . storm . scheduler ; \n + \n + import backtype . storm . task . GeneralTopologyContext ; \n + import java . util . List ; \n + import java . util . Map ; \n + \n + public interface INimbusScheduler { \n + void prepare ( Map stormConf ) ; \n + List < WorkerSlot > availableSlots ( Map < String , Object > existingSupervisorMeta , String topologyId , Map topologyConf , GeneralTopologyContext topology ) ; \n + void assignSlot ( WorkerSlot slot ) ; \n + } \n new file \n src \ jvm \ backtype \ storm \ scheduler \ ISupervisorScheduler . java \n + package backtype . storm . scheduler ; \n + \n + import java . util . Map ; \n + \n + \n + public interface ISupervisorScheduler { \n + void prepare ( Map stormConf , String localDir ) ; \n + boolean isAssigned ( int port ) ; \n + Object getMetadata ( ) ; \n + } \n new file \n src \ jvm \ backtype \ storm \ scheduler \ WorkerSlot . java \n + package backtype . storm . scheduler ; \n + \n + public class WorkerSlot { \n + String nodeId ; \n + int port ; \n + } \n",initial interfaces to generalize Storm to work either standalone or with Mesos,356
src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( mk - assignments nimbus ) ) \n + ( locking ( : submit - lock nimbus ) \n + ( mk - assignments nimbus ) ) ) \n,fix race condition - ensure that scheduling code is not called concurrently ( this was a regression ),356
"src \ jvm \ storm \ trident \ TridentTopology . java \n + import storm . trident . spout . RichSpoutBatchExecutor ; \n - public Stream newStream ( IRichSpout spout ) { \n - Node n = new SpoutNode ( getUniqueStreamId ( ) , TridentUtils . getSingleOutputStreamFields ( spout ) , null , spout , SpoutNode . SpoutType . BATCH ) ; \n - return addNode ( n ) ; \n + / / public Stream newStream ( IRichSpout spout ) { \n + / / Node n = new SpoutNode ( getUniqueStreamId ( ) , TridentUtils . getSingleOutputStreamFields ( spout ) , null , spout , SpoutNode . SpoutType . BATCH ) ; \n + / / return addNode ( n ) ; \n + / / } \n + \n + public Stream newStream ( String txId , IRichSpout spout ) { \n + return newStream ( txId , new RichSpoutBatchExecutor ( spout ) ) ; \n",add method for adding rich spouts to tridenttopology,356
conf \ defaults . yaml \n - topology . executor . receive . buffer . size : 8192 # batched \n - topology . executor . send . buffer . size : 16384 # individual messages \n + topology . executor . receive . buffer . size : 1024 # batched \n + topology . executor . send . buffer . size : 1024 # individual messages \n - topology . transfer . buffer . size : 32 # batched \n + topology . transfer . buffer . size : 1024 # batched \n,change default buffer sizes to work better in local mode and have less latency spikes,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ; ; remove any downloaded code that ' s no longer assigned or active \n - ( doseq [ storm - id downloaded - storm - ids ] \n - ( when - not ( assigned - storm - ids storm - id ) \n - ( log - message "" Removing code for storm id "" \n - storm - id ) \n - ( rmr ( supervisor - stormdist - root conf storm - id ) ) \n - ) ) \n + \n + ; ; remove any downloaded code that ' s no longer assigned or active \n + ; ; important that this happens after setting the local assignment so that \n + ; ; synchronize - supervisor doesn ' t try to launch workers for which the \n + ; ; resources don ' t exist \n + ( doseq [ storm - id downloaded - storm - ids ] \n + ( when - not ( assigned - storm - ids storm - id ) \n + ( log - message "" Removing code for storm id "" \n + storm - id ) \n + ( rmr ( supervisor - stormdist - root conf storm - id ) ) \n + ) ) \n","fix race condition in supervisor where resources for a worker were being cleaned up before setting the new assignment , potentially leading to the supervisor continuously dying",356
"src \ jvm \ storm \ trident \ topology \ MasterBatchCoordinator . java \n - Map < Number , Number > attempts = ( Map ) state . getData ( CURRENT _ ATTEMPTS ) ; \n + Map < Object , Number > attempts = ( Map ) state . getData ( CURRENT _ ATTEMPTS ) ; \n - for ( Number n : attempts . keySet ( ) ) { \n - long txid = n . longValue ( ) ; \n + for ( Object o : attempts . keySet ( ) ) { \n + / / this is because json doesn ' t allow numbers as keys . . . \n + / / TODO : replace json with a better form of encoding \n + if ( o instanceof String ) { \n + o = Long . parseLong ( ( String ) o ) ; \n + } \n + long txid = ( ( Number ) o ) . longValue ( ) ; \n",fix coordinator to parse txids from string keys in state due to how json converts number keys into strings,356
"src \ jvm \ storm \ trident \ topology \ MasterBatchCoordinator . java \n + import java . util . Map . Entry ; \n - for ( Object o : attempts . keySet ( ) ) { \n + for ( Entry < Object , Number > e : attempts . entrySet ( ) ) { \n - if ( o instanceof String ) { \n - o = Long . parseLong ( ( String ) o ) ; \n + Number txidObj ; \n + if ( e . getKey ( ) instanceof String ) { \n + txidObj = Long . parseLong ( ( String ) e . getKey ( ) ) ; \n + } else { \n + txidObj = ( Number ) e . getKey ( ) ; \n - long txid = ( ( Number ) o ) . longValue ( ) ; \n - int attemptId = ( ( Number ) attempts . get ( txid ) ) . intValue ( ) ; \n + long txid = ( ( Number ) txidObj ) . longValue ( ) ; \n + int attemptId = ( ( Number ) e . getValue ( ) ) . intValue ( ) ; \n",fix master coordinator to correctly parse the stored attempt ids,356
"src \ clj \ backtype \ storm \ timer . clj \n - ( if elem \n - ( if ( > = ( current - time - secs ) time - secs ) \n - ; ; can ' t hold the lock while executing the task function , or else \n - ; ; deadlocks are possible ( if the task function locks another lock \n - ; ; and another thread locks that other lock before trying to schedule \n - ; ; something on the timer ) \n - ( let [ exec - fn ( locking lock ( second ( . poll queue ) ) ) ] \n - ( exec - fn ) ) \n - ( Time / sleepUntil ( to - millis time - secs ) ) \n - ) \n - ( Time / sleep 10000 ) \n + ( if ( and elem ( > = ( current - time - secs ) time - secs ) ) \n + ; ; imperative to not run the function inside the timer lock \n + ; ; otherwise , it ' s possible to deadlock if function deals with other locks \n + ; ; ( like the submit lock ) \n + ( let [ afn ( locking lock ( second ( . poll queue ) ) ) ] \n + ( afn ) ) \n + ( Time / sleep 1000 ) \n - \n - ( when ( and ( not = ( : timer - thread timer ) ( Thread / currentThread ) ) \n - ( = id ( nth ( . peek queue ) 2 ) ) ) \n - ( . interrupt ^ Thread ( : timer - thread timer ) ) ) \n",fix concurrency and time simulation problems with timer by taking a much simpler approach,356
"src \ clj \ backtype \ storm \ timer . clj \n - ( : use [ backtype . storm util ] ) \n + ( : use [ backtype . storm util log ] ) \n - ( defn timer - waiting ? [ timer ] \n + ( defn timer - waiting ? [ timer ] \n src \ clj \ backtype \ storm \ util . clj \n + \n + ( defn spy [ prefix val ] \n + ( log - message prefix "" : "" val ) \n + val ) \n src \ jvm \ backtype \ storm \ utils \ Time . java \n - return time ! = null & & currentTimeMillis ( ) < time . longValue ( ) ; \n + return ! t . isAlive ( ) | | time ! = null & & currentTimeMillis ( ) < time . longValue ( ) ; \n",fix detection of waiting with time simulation in case of dead threads,356
"CHANGELOG . md \n + # # 0 . 6 . 2 \n + \n + * Automatically delete old files in Nimbus ' s inbox . Configurable with "" nimbus . cleanup . inbox . freq . secs "" and "" nimbus . inbox . jar . expiration . secs "" \n + * Redirect System . out and System . err to log4j \n + * Added "" topology . worker . child . opts "" config , for topology - configurable worker options . \n + * Use Netflix ' x Curator library for Zookeeper communication . Workers now reconnect to Zookeeper rather than crash when there ' s a disconnection . \n + * Bug fix : DRPC server no longer hangs with too many concurrent requests . DPRC server now requires two ports : "" drpc . port "" and "" drpc . invocations . port "" \n + * Bug fix : Fix race condition where time simulation fails to detect that Storm cluster is waiting due to threads that are not alive \n + \n - * New serialization system based on Kryo : \n + * New serialization system based on Kryo \n conf \ defaults . yaml \n - nimbus . cleanup . inbox . freq . secs : 1800 \n + nimbus . cleanup . inbox . freq . secs : 600 \n",update changelog for 0 . 6 . 2,356
CHANGELOG . md \n - * Bug fix : Fix race condition where time simulation fails to detect that Storm cluster is waiting due to threads that are not alive \n + * Bug fix : Fix race condition in unit testing where time simulation fails to detect that Storm cluster is waiting due to threads that are not alive \n,clarify changelog for 0 . 6 . 2,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( FileUtils / forceMkdir ( File . tmproot ) ) \n + ( FileUtils / forceMkdir ( File . tmproot ) ) \n + ( defn resources - jar [ ] \n + ( - > > ( . split ( current - classpath ) "" : "" ) \n + ( filter # ( . endsWith % "" . jar "" ) ) \n + ( filter # ( zip - contains - dir ? % RESOURCES - SUBDIR ) ) \n + first ) ) \n + \n - ; ; should detect if it was run with "" storm jar "" and copy or extract appropriately \n + resources - jar ( resources - jar ) \n - ( when url \n - ( log - message "" Copying resources at "" ( str url ) "" to "" target - dir ) \n - ( FileUtils / copyDirectory ( File . ( . getFile url ) ) ( File . target - dir ) ) \n - ) ) ) ) \n + ( cond \n + resources - jar \n + ( do \n + ( log - message "" Extracting resources from jar at "" resources - jar "" to "" target - dir ) \n + ( extract - dir - from - jar resources - jar RESOURCES - SUBDIR stormroot ) ) \n + url \n + ( do \n + ( log - message "" Copying resources at "" ( str url ) "" to "" target - dir ) \n + ( FileUtils / copyDirectory ( File . ( . getFile url ) ) ( File . target - dir ) ) \n + ) ) \n + ) ) ) \n src \ clj \ backtype \ storm \ util . clj \n + ( : import [ java . util . zip ZipFile ] ) \n + \n + ( defn zip - contains - dir ? [ zipfile target ] \n + ( let [ entries ( - > > zipfile ( ZipFile . ) . entries enumeration - seq ( map ( memfn getName ) ) ) ] \n + ( some ? # ( . startsWith % ( str target "" / "" ) ) entries ) \n + ) ) \n","extract resources dir from jar in local mode when necessary , fixes # 82",356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( - > > ( . split ( current - classpath ) "" : "" ) \n + ( - > > ( . split ( current - classpath ) File / pathSeparator ) \n",make fix for # 82 work on windows as well,356
src \ jvm \ backtype \ storm \ transactional \ TransactionalBoltExecutor . java \n - ITransactionalBolt bolt = _ openTransactions . get ( ( TransactionAttempt ) tup . getId ( ) ) ; \n + TransactionAttempt attempt = ( TransactionAttempt ) tup . getId ( ) ; \n + ITransactionalBolt bolt = _ openTransactions . get ( attempt ) ; \n + if ( ! ( bolt instanceof ICommittable ) ) { \n + _ openTransactions . remove ( attempt ) ; \n + } \n,cleanup resources when finished with non - committed batch,356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalTopologyBuilder . java \n + / * * \n + * TODO : check to see if there are two topologies active with the same transactional id \n + * essentially want to implement a file lock on top of zk ( use ephemeral nodes ? ) \n + * \n + * Testing TODO : \n + * \n + * 1 . Test that commits are strongly ordered \n + * 2 . Test that commits are strongly ordered even in the case of failure \n + * 3 . Test that batch emitters emit nothing when a future batch has been emitted and its state saved \n + * 4 . Test that transactionalbolts only commit when they ' ve received the whole batch for that attempt , \n + * not a partial batch \n + * 5 . Test that transactions are properly pipelined \n + * 6 . Test that commit isn ' t considered successful until the entire tree has been completed ( including tuples emitted from commit method ) \n + * 7 . Test that batch isn ' t considered processed until the entire tuple tree has been completed \n + * 8 . Test that it picks up where it left off when restarting the topology \n + * 9 . Test that coordinator and partitioned state are cleaned up properly ( and not too early ) \n + * / \n",notes on what needs to be tested for transactional topologies,356
"project . clj \n - ( defproject storm "" 0 . 6 . 2 - SNAPSHOT "" \n + ( defproject storm "" 0 . 7 . 0 - SNAPSHOT "" \n",bump project . clj to 0 . 7 . 0 - SNAPSHOT,356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalTopologyBuilder . java \n + GlobalStreamId idStream = null ; \n + if ( component . committer ) { \n + idStream = new GlobalStreamId ( coordinator , TransactionalSpoutCoordinator . TRANSACTION _ BATCH _ STREAM _ ID ) ; \n + } \n - null ) , \n + idStream ) , \n",make sure transactional topology coordinates on the batch id for committer bolts,356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalBoltExecutor . java \n - TimeCacheMap < TransactionAttempt , ITransactionalBolt > _ openTransactions ; \n + TimeCacheMap < TransactionAttempt , OpenTransaction > _ openTransactions ; \n - _ openTransactions = new TimeCacheMap < TransactionAttempt , ITransactionalBolt > ( Utils . getInt ( conf . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ) ) ; \n + _ openTransactions = new TimeCacheMap < TransactionAttempt , OpenTransaction > ( Utils . getInt ( conf . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ) ) ; \n - ITransactionalBolt bolt = _ openTransactions . get ( attempt ) ; \n + OpenTransaction tx = _ openTransactions . get ( attempt ) ; \n - if ( bolt ! = null ) { \n - ( ( ICommittable ) bolt ) . commit ( ) ; \n + if ( tx ! = null & & tx . finished ) { \n + ( ( ICommittable ) tx . bolt ) . commit ( ) ; \n - if ( bolt = = null ) { \n - bolt = newTransactionalBolt ( ) ; \n - bolt . prepare ( _ conf , _ context , _ collector , attempt ) ; \n - _ openTransactions . put ( attempt , bolt ) ; \n + if ( tx = = null ) { \n + tx = new OpenTransaction ( ) ; \n + tx . bolt . prepare ( _ conf , _ context , _ collector , attempt ) ; \n + _ openTransactions . put ( attempt , tx ) ; \n - bolt . execute ( input ) ; \n + tx . bolt . execute ( input ) ; \n - ITransactionalBolt bolt = _ openTransactions . get ( attempt ) ; \n + OpenTransaction tx = _ openTransactions . get ( attempt ) ; \n - if ( bolt ! = null ) { \n - if ( ! ( bolt instanceof ICommittable ) ) { \n + if ( tx ! = null ) { \n + if ( ! ( tx instanceof ICommittable ) ) { \n - bolt . finishBatch ( ) ; \n + tx . bolt . finishBatch ( ) ; \n + tx . finished = true ; \n + \n + private class OpenTransaction { \n + public boolean finished = false ; \n + public ITransactionalBolt bolt = newTransactionalBolt ( ) ; \n + } \n",make transactionalbolt enforce that it only commits when it has received a finishedBatch message,356
"src \ jvm \ backtype \ storm \ coordination \ CoordinatedBolt . java \n + boolean failed = false ; \n - _ tracked . get ( id ) . receivedTuples + + ; \n + TrackingInfo info = _ tracked . get ( id ) ; \n + info . receivedTuples + + ; \n + failed = info . failedTuples > 0 ; \n - _ delegate . ack ( tuple ) ; \n + if ( failed ) { \n + _ delegate . fail ( tuple ) ; \n + } else { \n + _ delegate . ack ( tuple ) ; \n + } \n - / / don ' t increment here . . . don ' t want to complete in case of failure \n + Object id = tuple . getValue ( 0 ) ; \n + synchronized ( _ tracked ) { \n + _ tracked . get ( id ) . failedTuples + + ; \n + } \n + int failedTuples = 0 ; \n + "" failedTuples : "" + failedTuples + "" \ n "" + \n - public static class IdStreamSpec { \n + public static class IdStreamSpec implements Serializable { \n + boolean failed = false ; \n + failed = track . failedTuples > 0 ; \n - _ collector . ack ( tuple ) ; \n + if ( failed ) { \n + _ collector . fail ( tuple ) ; \n + } else { \n + _ collector . ack ( tuple ) ; \n + } \n - _ collector . ack ( tuple ) ; \n + if ( failed ) { \n + _ collector . fail ( tuple ) ; \n + } else { \n + _ collector . ack ( tuple ) ; \n + } \n",propogate fails in coordinatedbolt to rest of the tuples . . . this makes fail work again for transactional and drpc topologies ( without requiring every tuple to be anchored ),356
"bin \ storm \n - return tokens [ 1 ] \n + return "" "" . join ( tokens [ 1 : ] ) \n",fix conf parsing code to not filter out whitespace,356
src \ clj \ backtype \ storm \ timer . clj \n - ( catch InterruptedException e \n - ) \n - ( kill - fn t ) \n - ( reset ! active false ) \n - ( throw t ) \n + ; ; because the interrupted exception can be wrapped in a runtimeexception \n + ( when - not ( exception - cause ? InterruptedException t ) \n + ( kill - fn t ) \n + ( reset ! active false ) \n + ( throw t ) ) \n,fix timer shutdown code to check for interruptedexceptions nested as a cause of a runtime exception,356
src \ jvm \ backtype \ storm \ coordination \ BatchBoltExecutor . java \n - import backtype . storm . transactional . TransactionAttempt ; \n - TransactionAttempt attempt = ( TransactionAttempt ) input . getValue ( 0 ) ; \n - IBatchBolt bolt = getBatchBolt ( attempt ) ; \n + Object id = input . getValue ( 0 ) ; \n + IBatchBolt bolt = getBatchBolt ( id ) ; \n - _ openTransactions . remove ( ( TransactionAttempt ) attempt ) ; \n + _ openTransactions . remove ( attempt ) ; \n,fix batchboltexecutor to not be specific to transactionattempts,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( log - error e "" Failed to cleanup worker "" id "" . Will retry later "" ) \n + ( log - warn - error e "" Failed to cleanup worker "" id "" . Will retry later "" ) \n",downgrade supervisor cleanup log message to a warning from an error ( since it ' s expected ),356
src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - import backtype . storm . generated . Bolt ; \n - import backtype . storm . generated . SpoutSpec ; \n - import backtype . storm . generated . StateSpoutSpec ; \n - import java . util . HashSet ; \n + private Object _ taskData = null ; \n + \n + public void setTaskData ( Object data ) { \n + _ taskData = data ; \n + } \n + \n + public Object getTaskData ( ) { \n + return _ taskData ; \n + } \n,"add ability to store data inside the topology context ( for data that ' s needed across different instances of a batchbolt , for instance",356
"CHANGELOG . md \n + # # 0 . 7 . 1 \n + \n project . clj \n - ( defproject storm "" 0 . 7 . 1 "" \n + ( defproject storm "" 0 . 7 . 2 - SNAPSHOT "" \n",start 0 . 7 . 2 - SNAPSHOT,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + : scheduler ( if ( conf STORM - SCHEDULER ) \n + ( do ( log - message "" Using custom scheduler : "" ( conf STORM - SCHEDULER ) ) \n + ( - > ( conf STORM - SCHEDULER ) ( Class / forName ) . newInstance ) ) \n + ( do ( log - message "" Using default scheduler "" ) \n + ( DefaultScheduler . ) ) ) \n - scheduler ( if ( conf STORM - SCHEDULER ) \n - ( do \n - ( log - message "" Using custom scheduler : "" ( conf STORM - SCHEDULER ) ) \n - ( - > ( conf STORM - SCHEDULER ) ( Class / forName ) . newInstance ) ) \n - ( do \n - ( log - message "" Using system default scheduler "" ) \n - ( DefaultScheduler . ) ) ) \n - _ ( . schedule scheduler topologies cluster ) \n + _ ( . schedule ( : scheduler nimbus ) topologies cluster ) \n",create the scheduler one time instead of creating a new one for each mk - assignments call,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n + : shared - executor - data ( HashMap . ) \n src \ clj \ backtype \ storm \ daemon \ task . clj \n - ( defn mk - topology - context - builder [ worker topology ] \n + ( defn mk - topology - context - builder [ worker executor - data topology ] \n + ( : shared - executor - data executor - data ) \n - ( defn system - topology - context [ worker tid ] \n + ( defn system - topology - context [ worker executor - data tid ] \n + executor - data \n - ( defn user - topology - context [ worker tid ] \n + ( defn user - topology - context [ worker executor - data tid ] \n + executor - data \n - : system - context ( system - topology - context ( : worker executor - data ) task - id ) \n - : user - context ( user - topology - context ( : worker executor - data ) task - id ) \n + : system - context ( system - topology - context ( : worker executor - data ) executor - data task - id ) \n + : user - context ( user - topology - context ( : worker executor - data ) executor - data task - id ) \n src \ clj \ backtype \ storm \ testing . clj \n + ( : import [ java . util HashMap ] ) \n - { } ) ] \n + { } \n + ( HashMap . ) ) ] \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n + private Map < String , Object > _ executorData ; \n - Map < String , Object > userResources ) { \n + Map < String , Object > userResources , Map < String , Object > executorData ) { \n + _ executorData = executorData ; \n + \n + public void setExecutorData ( String name , Object data ) { \n + _ executorData . put ( name , data ) ; \n + } \n + \n + public Object getExecutorData ( String name ) { \n + return _ executorData . get ( name ) ; \n + } \n","added shared executor data between tasks , make task data have a map - like interface",356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n + ; ; in its own function so that it can be mocked out by tracked topologies \n + ( defn mk - executor - transfer - fn [ batch - transfer - > worker ] \n + ( fn [ task tuple ] \n + ( disruptor / publish batch - transfer - > worker [ task tuple ] ) ) ) \n + \n - : transfer - fn ( fn [ task tuple ] \n - ( disruptor / publish batch - transfer - > worker [ task tuple ] ) ) \n + : transfer - fn ( mk - executor - transfer - fn batch - transfer - > worker ) \n src \ clj \ backtype \ storm \ testing . clj \n - worker / mk - transfer - fn ( let [ old # worker / mk - transfer - fn ] \n - ( fn [ & args # ] \n - ( let [ transferrer # ( apply old # args # ) ] \n - ( fn [ ser # batch # ] \n - ; ; ( log - message "" Transferring : "" transfer - args # ) \n - ( increment - global ! id # "" transferred "" ( count batch # ) ) \n - ( transferrer # ser # batch # ) \n - ) ) ) ) \n + executor / mk - executor - transfer - fn \n + ( let [ old # executor / mk - executor - transfer - fn ] \n + ( fn [ & args # ] \n + ( let [ transferrer # ( apply old # args # ) ] \n + ( fn [ & args2 # ] \n + ; ; ( log - message "" Transferring : "" transfer - args # ) \n + ( increment - global ! id # "" transferred "" 1 ) \n + ( apply transferrer # args2 # ) \n + ) ) ) ) \n","Fix tracked topologies . Need to increment transferred at the moment of emit , and not on the batch - transfer thread . \n This was a regression from the introduction of the multi - level disruptor queueing system .",356
"src \ clj \ backtype \ storm \ zookeeper . clj \n - ( . . fk \n - ( getUnhandledErrorListenable ) \n - ( addListener \n - ( reify UnhandledErrorListener \n - ( unhandledError [ this msg error ] \n - ( if ( or ( exception - cause ? InterruptedException error ) \n - ( exception - cause ? java . nio . channels . ClosedByInterruptException error ) ) \n - ( do ( log - warn - error error "" Zookeeper exception "" msg ) \n - ( let [ to - throw ( InterruptedException . ) ] \n - ( . initCause to - throw error ) \n - ( throw to - throw ) \n - ) ) \n - ( do ( log - error error "" Unrecoverable Zookeeper error "" msg ) \n - ( halt - process ! 1 "" Unrecoverable Zookeeper error "" ) ) ) \n - ) ) ) ) \n + ; ; ( . . fk \n + ; ; ( getUnhandledErrorListenable ) \n + ; ; ( addListener \n + ; ; ( reify UnhandledErrorListener \n + ; ; ( unhandledError [ this msg error ] \n + ; ; ( if ( or ( exception - cause ? InterruptedException error ) \n + ; ; ( exception - cause ? java . nio . channels . ClosedByInterruptException error ) ) \n + ; ; ( do ( log - warn - error error "" Zookeeper exception "" msg ) \n + ; ; ( let [ to - throw ( InterruptedException . ) ] \n + ; ; ( . initCause to - throw error ) \n + ; ; ( throw to - throw ) \n + ; ; ) ) \n + ; ; ( do ( log - error error "" Unrecoverable Zookeeper error "" msg ) \n + ; ; ( halt - process ! 1 "" Unrecoverable Zookeeper error "" ) ) ) \n + ; ; ) ) ) ) \n",get rid of overly agressive shutdown on unhandled error . . . let errors just bubble up in client calls instead,356
src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - [ ( Integer . port ) ( LocalAssignment . storm - id executors ) ] \n + ; ; doall is to avoid serialization / deserialization problems with lazy seqs \n + [ ( Integer . port ) ( LocalAssignment . storm - id ( doall executors ) ) ] \n,backport fix to realize executor list heartbeated by worker to avoid ser / deser problems,356
"project . clj \n - [ com . google . guava / guava "" 13 . 0 "" ] ] \n + [ com . google . guava / guava "" 13 . 0 "" ] \n + [ ch . qos . logback / logback - classic "" 1 . 0 . 6 "" ] \n + [ org . slf4j / log4j - over - slf4j "" 1 . 6 . 6 "" ] \n + ] \n - : profiles { : dev { : resource - paths [ "" src / dev "" ] \n - : dependencies [ [ ch . qos . logback / logback - classic "" 1 . 0 . 6 "" ] \n - [ org . slf4j / log4j - over - slf4j "" 1 . 6 . 6 "" ] ] } \n - : release { : dependencies [ [ ch . qos . logback / logback - classic "" 1 . 0 . 6 "" ] \n - [ org . slf4j / log4j - over - slf4j "" 1 . 6 . 6 "" ] ] } \n - : lib { : dependencies [ [ log4j / log4j "" 1 . 2 . 16 "" ] ] } } \n + : profiles { : dev { : resource - paths [ "" src / dev "" ] } \n + : release { } \n + : lib { } \n + } \n",include log4j - > slf4j and logback as dependencies of storm,356
"src \ clj \ backtype \ storm \ cluster . clj \n - ( : import [ org . apache . zookeeper KeeperException ] ) \n + ( : import [ org . apache . zookeeper KeeperException KeeperException $ NoNodeException ] ) \n - ( zk / set - data zk path data ) ; should verify that it ' s ephemeral \n + ( try - cause \n + ( zk / set - data zk path data ) ; should verify that it ' s ephemeral \n + ( catch KeeperException $ NoNodeException e \n + ( log - warn - error e "" Ephemeral node disappeared between checking for existing and setting data "" ) \n + ( zk / create - node zk path data : ephemeral ) \n + ) ) \n - ( set - ephemeral - node cluster - state ( taskbeat - path storm - id task - id ) ( Utils / serialize info ) ) \n + ( set - data cluster - state ( taskbeat - path storm - id task - id ) ( Utils / serialize info ) ) \n",fix setting data for ephemeral nodes if there ' s a timeout after checking for existence . switch task heartbeats to non - ephemeral zk nodes,356
src \ clj \ backtype \ storm \ event . clj \n - ( try \n + ( try - cause \n,mixed a try - > try - cause,356
"src \ clj \ backtype \ storm \ event . clj \n - ( try - cause \n - ( r ) \n - ( swap ! processed inc ) \n - ( catch InterruptedException t \n - ( throw t ) ) \n - ( catch Throwable t \n - ( log - error t "" Error when processing event "" r ) \n - ( halt - process ! 20 "" Error when processing an event "" ) ) \n - ) ) \n + ( r ) \n + ( swap ! processed inc ) ) \n - ( log - message "" Event manager interrupted "" ) ) ) \n - ) ) ) ] \n + ( log - message "" Event manager interrupted "" ) ) \n + ( catch Throwable t \n + ( log - error t "" Error when processing event "" ) \n + ( halt - process ! 20 "" Error when processing an event "" ) ) \n + ) ) ) ) ] \n",simplify try - cause code in event manager,356
"src \ clj \ backtype \ storm \ event . clj \n - ( while @ running \n - ( try - cause \n + ( try - cause \n + ( while @ running \n - ( swap ! processed inc ) ) \n - ( catch InterruptedException t \n - ( log - message "" Event manager interrupted "" ) ) \n - ( catch Throwable t \n - ( log - error t "" Error when processing event "" ) \n - ( halt - process ! 20 "" Error when processing an event "" ) ) \n - ) ) ) ) ] \n + ( swap ! processed inc ) ) ) \n + ( catch InterruptedException t \n + ( log - message "" Event manager interrupted "" ) ) \n + ( catch Throwable t \n + ( log - error t "" Error when processing event "" ) \n + ( halt - process ! 20 "" Error when processing an event "" ) ) \n + ) ) ) ] \n",place try - cause in event - manager around complete while loop,356
"src \ jvm \ backtype \ storm \ drpc \ DRPCSpout . java \n - return new HashMap < String , Object > ( ) ; \n + return null ; \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - Map conf = ( Map ) JSONValue . parse ( common . get _ json _ conf ( ) ) ; \n - Object comp = conf . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ; \n - if ( comp ! = null ) { \n - max = Math . max ( Utils . getInt ( comp ) , max ) ; \n + String jsonConf = common . get _ json _ conf ( ) ; \n + if ( jsonConf ! = null ) { \n + Map conf = ( Map ) JSONValue . parse ( jsonConf ) ; \n + Object comp = conf . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ; \n + if ( comp ! = null ) { \n + max = Math . max ( Utils . getInt ( comp ) , max ) ; \n + } \n src \ jvm \ backtype \ storm \ testing \ TestWordSpout . java \n - Map < String , Object > ret = new HashMap < String , Object > ( ) ; \n + Map < String , Object > ret = new HashMap < String , Object > ( ) ; \n + return ret ; \n + } else { \n + return null ; \n - return ret ; \n",fix npe when component configuration for spout is null,356
"bin \ storm \n - command = "" java "" + jvmtype + "" - Dstorm . home = "" + STORM _ DIR + "" "" + get _ config _ opts ( ) + "" - Djava . library . path = "" + nativepath + "" "" + childopts + "" - cp "" + get _ classpath ( extrajars ) + "" "" + klass + "" "" + "" "" . join ( args ) \n + args _ str = "" "" . join ( map ( lambda s : "" \ "" "" + s + "" \ "" "" , args ) ) \n + command = "" java "" + jvmtype + "" - Dstorm . home = "" + STORM _ DIR + "" "" + get _ config _ opts ( ) + "" - Djava . library . path = "" + nativepath + "" "" + childopts + "" - cp "" + get _ classpath ( extrajars ) + "" "" + klass + "" "" + args _ str \n",allow quoted args with spaces in storm script,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - "" - cp "" classpath "" backtype . storm . daemon . worker "" \n - storm - id "" "" supervisor - id "" "" port "" "" worker - id ) ] \n + "" - cp "" classpath "" backtype . storm . daemon . worker \ "" "" \n + storm - id "" \ "" "" supervisor - id "" "" port "" "" worker - id ) ] \n",fix worker launching bug with space in topology names,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - command ( str "" java - server "" childopts \n - "" - Djava . library . path = "" ( conf JAVA - LIBRARY - PATH ) \n - "" - Dlogfile . name = "" logfilename \n - "" - Dstorm . home = "" ( System / getProperty "" storm . home "" ) \n - "" - Dlog4j . configuration = storm . log . properties "" \n - "" - cp "" classpath "" backtype . storm . daemon . worker \ "" "" \n - storm - id "" \ "" "" supervisor - id "" "" port "" "" worker - id ) ] \n + command [ "" java "" \n + "" - server "" \n + childopts \n + ( str "" - Djava . library . path = "" ( conf JAVA - LIBRARY - PATH ) ) \n + ( str "" - Dlogfile . name = "" logfilename ) \n + ( str "" - Dstorm . home = "" ( System / getProperty "" storm . home "" ) ) \n + "" - Dlog4j . configuration = storm . log . properties "" \n + "" - cp "" classpath \n + "" backtype . storm . daemon . worker "" \n + storm - id supervisor - id port worker - id \n + ] ] \n src \ clj \ backtype \ storm \ util . clj \n - ( let [ command ( - > > ( seq ( . split command "" "" ) ) \n - ( filter ( complement empty ? ) ) ) \n - builder ( ProcessBuilder . ( cons "" nohup "" command ) ) \n + ( let [ builder ( ProcessBuilder . ( cons "" nohup "" command ) ) \n",fix worker launching when topology name has spaces,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - command [ "" java "" \n - "" - server "" \n - childopts \n - ( str "" - Djava . library . path = "" ( conf JAVA - LIBRARY - PATH ) ) \n - ( str "" - Dlogfile . name = "" logfilename ) \n - ( str "" - Dstorm . home = "" ( System / getProperty "" storm . home "" ) ) \n - "" - Dlog4j . configuration = storm . log . properties "" \n - "" - cp "" classpath \n - "" backtype . storm . daemon . worker "" \n - storm - id supervisor - id port worker - id \n - ] ] \n + command ( str "" java - server "" childopts \n + "" - Djava . library . path = "" ( conf JAVA - LIBRARY - PATH ) \n + "" - Dlogfile . name = "" logfilename \n + "" - Dstorm . home = "" ( System / getProperty "" storm . home "" ) \n + "" - Dlog4j . configuration = storm . log . properties "" \n + "" - cp "" classpath "" backtype . storm . daemon . worker \ "" "" \n + storm - id "" \ "" "" supervisor - id "" "" port "" "" worker - id ) ] \n src \ clj \ backtype \ storm \ util . clj \n - ( let [ builder ( ProcessBuilder . ( cons "" nohup "" command ) ) \n + ( let [ command ( - > > ( seq ( . split command "" "" ) ) \n + ( filter ( complement empty ? ) ) ) \n + builder ( ProcessBuilder . ( cons "" nohup "" command ) ) \n","Revert "" fix worker launching when topology name has spaces "" \n This reverts commit 9b3af144847d44c01d69f8f0ccd81eacd4742d7a .",356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - "" - cp "" classpath "" backtype . storm . daemon . worker \ "" "" \n - storm - id "" \ "" "" supervisor - id "" "" port "" "" worker - id ) ] \n + "" - cp "" classpath "" backtype . storm . daemon . worker "" \n + ( java . net . URLEncoder / encode storm - id ) "" "" supervisor - id "" "" port "" "" worker - id ) ] \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( mk - worker conf nil storm - id supervisor - id ( Integer / parseInt port - str ) worker - id ) ) ) \n + ( mk - worker conf nil ( java . net . URLDecoder / decode storm - id ) supervisor - id ( Integer / parseInt port - str ) worker - id ) ) ) \n",url encode / decode storm - id when launching workers,356
"src \ clj \ backtype \ storm \ config . clj \n - ( str ( supervisor - stormdist - root conf ) "" / "" storm - id ) ) ) \n + ( str ( supervisor - stormdist - root conf ) "" / "" ( java . net . URLEncoder / encode storm - id ) ) ) ) \n src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( read - dir - contents ( supervisor - stormdist - root conf ) ) \n + ( map # ( java . net . URLDecoder / decode % ) ( read - dir - contents ( supervisor - stormdist - root conf ) ) ) \n",url encode local storage of jars on supervisor,356
"bin \ storm \n - CONFIG _ OPTS . append ( config [ 1 ] ) \n - \n + CONFIG _ OPTS . append ( config ) \n + \n + def parse _ config _ opts ( args ) : \n + curr = args [ : ] \n + curr . reverse ( ) \n + config _ list = [ ] \n + args _ list = [ ] \n + \n + while len ( curr ) > 0 : \n + token = curr . pop ( ) \n + if token = = "" - c "" : \n + config _ list . append ( curr . pop ( ) ) \n + else : \n + args _ list . append ( token ) \n + \n + return config _ list , args _ list \n + \n - config _ list , args = getopt . gnu _ getopt ( sys . argv [ 1 : ] , "" c : "" ) \n + config _ list , args = parse _ config _ opts ( sys . argv [ 1 : ] ) \n",fix storm client to not squash non - c options,356
src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( : gen - class ) ) \n + ( : gen - class \n + : methods [ ^ { : static true } [ launch [ backtype . storm . scheduler . INimbus ] void ] ] ) ) \n + ( defn - launch [ nimbus ] \n + ( launch - server ! ( read - storm - config ) ) ) \n - ( launch - server ! ( read - storm - config ) ) ) \n + ( - launch nil ) ) \n src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - ( : gen - class ) ) \n + ( : gen - class \n + : methods [ ^ { : static true } [ launch [ backtype . storm . scheduler . ISupervisor ] void ] ] ) ) \n - ( defn - main [ ] \n + ( defn - launch [ supervisor ] \n + \n + ( defn - main [ ] \n + ( - launch nil ) ) \n,added java - exposed static launch methods to nimbus and supervisor,356
"src \ jvm \ backtype \ storm \ scheduler \ INimbus . java \n - List < WorkerSlot > availableSlots ( List < SupervisorInfo > existingSupervisors , List < WorkerSlot > usedSlots , TopologyInfo topology ) ; \n + List < WorkerSlot > availableSlots ( List < SupervisorDetails > existingSupervisors , List < WorkerSlot > usedSlots , TopologyDetails topology ) ; \n - void assignSlot ( WorkerSlot slot , TopologyInfo topology ) ; \n + void assignSlot ( WorkerSlot slot , TopologyDetails topology ) ; \n rename from src \ jvm \ backtype \ storm \ scheduler \ SupervisorInfo . java \n rename to src \ jvm \ backtype \ storm \ scheduler \ SupervisorDetails . java \n - public class SupervisorInfo { \n + public class SupervisorDetails { \n - public SupervisorInfo ( String id , Object meta ) { \n + public SupervisorDetails ( String id , Object meta ) { \n rename from src \ jvm \ backtype \ storm \ scheduler \ TopologyInfo . java \n rename to src \ jvm \ backtype \ storm \ scheduler \ TopologyDetails . java \n - public class TopologyInfo { \n + public class TopologyDetails { \n - public TopologyInfo ( String topologyId , Map topologyConf , GeneralTopologyContext context ) { \n + public TopologyDetails ( String topologyId , Map topologyConf , GeneralTopologyContext context ) { \n",rename scheduler * Info - > * Details,356
"src \ jvm \ backtype \ storm \ utils \ Utils . java \n - throw new RuntimeException ( "" Found multiple "" + name + "" resources "" ) ; \n + throw new RuntimeException ( "" Found multiple "" + name + "" resources . You ' re probably bundling the Storm jars with your topology jar . "" ) ; \n",improved error message for duplicate config files on classpath,356
"src \ clj \ backtype \ storm \ thrift . clj \n - ( : use [ backtype . storm util config ] ) \n + ( : use [ backtype . storm util config log ] ) \n + ( log - message "" Connecting to Nimbus at "" host "" : "" port ) \n",log the host and port of Nimbus when using storm client,356
"src \ clj \ backtype \ storm \ daemon \ task . clj \n + ( doseq [ hook ( . getHooks user - context ) ] \n + ( . cleanup hook ) ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - % ) \n + % \n + port ) \n - % ) \n + % \n + port ) \n src \ clj \ backtype \ storm \ testing . clj \n - context ( TopologyContext . topology ( read - storm - config ) { 1 component } "" test - storm - id "" nil nil 1 ) ] \n + context ( TopologyContext . topology ( read - storm - config ) { 1 component } "" test - storm - id "" nil nil 1 nil ) ] \n src \ jvm \ backtype \ storm \ hooks \ BaseTaskHook . java \n + @ Override \n + public void cleanup ( ) { \n + } \n + \n src \ jvm \ backtype \ storm \ hooks \ ITaskHook . java \n + void cleanup ( ) ; \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n + private Integer _ workerPort ; \n - public TopologyContext ( StormTopology topology , Map stormConf , Map < Integer , String > taskToComponent , String stormId , String codeDir , String pidDir , Integer taskId ) { \n + public TopologyContext ( StormTopology topology , Map stormConf , Map < Integer , String > taskToComponent , String stormId , String codeDir , String pidDir , Integer taskId , Integer workerPort ) { \n + _ workerPort = workerPort ; \n + public Integer getThisWorkerPort ( ) { \n + return _ workerPort ; \n + } \n + \n test \ clj \ backtype \ storm \ integration _ test . clj \n + ( cleanup [ this ] \n + ) \n","added cleanup method to task hook , added getThisWorkerPort to TopologyContext",356
src \ jvm \ backtype \ storm \ utils \ InprocMessaging . java \n - LinkedBlockingQueue < Object > queue = getQueue ( port ) ; \n - synchronized ( _ lock ) { \n - queue . add ( msg ) ; \n - } \n + getQueue ( port ) . add ( msg ) ; \n - LinkedBlockingQueue < Object > queue = getQueue ( port ) ; \n - Object ret = queue . take ( ) ; \n - synchronized ( _ lock ) { \n - if ( queue . size ( ) = = 0 ) { \n - _ queues . remove ( port ) ; \n - } \n - } \n - return ret ; \n + return getQueue ( port ) . take ( ) ; \n - LinkedBlockingQueue < Object > queue = getQueue ( port ) ; \n - Object ret = queue . poll ( ) ; \n - synchronized ( _ lock ) { \n - if ( queue . size ( ) = = 0 ) { \n - _ queues . remove ( port ) ; \n - } \n - } \n - return ret ; \n + return getQueue ( port ) . poll ( ) ; \n,make InprocMessaging threadsafe to fix lost messages with FeederSpout,356
src \ clj \ backtype \ storm \ timer . clj \n - ( defn schedule [ timer delay - secs afn ] \n - ( check - active ! timer ) \n + ( defnk schedule [ timer delay - secs afn : check - active true ] \n + ( when check - active ( check - active ! timer ) ) \n - ( schedule timer recur - secs this ) \n - ) ) ) \n + ( schedule timer recur - secs this ) ) \n + : check - active false ; this avoids a race condition with cancel - timer \n + ) ) \n,fix race condition between schedule - recurring and cancel - timer,356
src \ jvm \ backtype \ storm \ transactional \ TransactionalSpoutCoordinator . java \n - if ( _ coordinator . isReady ( ) & & _ activeTx . size ( ) < _ maxTransactionActive ) { \n + if ( _ activeTx . size ( ) < _ maxTransactionActive ) { \n - if ( ! _ activeTx . containsKey ( curr ) ) { \n + if ( ( _ coordinatorState . hasCache ( curr ) | | _ coordinator . isReady ( ) ) \n + & & ! _ activeTx . containsKey ( curr ) ) { \n src \ jvm \ backtype \ storm \ transactional \ state \ RotatingTransactionalState . java \n + \n + public boolean hasCache ( BigInteger txid ) { \n + return _ curr . containsKey ( txid ) ; \n + } \n test \ clj \ backtype \ storm \ transactional _ test . clj \n - ( isReady [ this ] true ) \n + ( isReady [ this ] ( not ( nil ? @ atom ) ) ) \n + ( reset ! coordinator - state nil ) \n - ( verify - and - reset ! { BATCH - STREAM [ [ 6 12 ] ] } emit - capture ) \n + ( verify - and - reset ! { } emit - capture ) \n - ( verify - and - reset ! { BATCH - STREAM [ [ 3 10 ] [ 4 10 ] [ 5 12 ] [ 6 12 ] ] } emit - capture ) \n + ( verify - and - reset ! { BATCH - STREAM [ [ 3 10 ] [ 4 10 ] [ 5 12 ] ] } emit - capture ) \n + \n + ( reset ! coordinator - state 12 ) \n + ( . nextTuple coordinator ) \n + ( verify - and - reset ! { BATCH - STREAM [ [ 6 12 ] ] } emit - capture ) \n,make isReady only apply to transactions that haven ' t been emitted before,356
test \ clj \ backtype \ storm \ integration _ test . clj \n - : storm - conf { TOPOLOGY - DEBUG true \n - TOPOLOGY - WORKERS 2 } ) ] \n + : storm - conf { TOPOLOGY - WORKERS 2 } ) ] \n - { TOPOLOGY - DEBUG true } \n + { } \n,remove TOPOLOGY - DEBUG from a few tests,356
"project . clj \n - ( defproject storm "" 0 . 6 . 1 - SNAPSHOT "" \n + ( defproject storm "" 0 . 6 . 2 - SNAPSHOT "" \n",bump version to 0 . 6 . 2 - SNAPSHOT,356
conf \ defaults . yaml \n + topology . worker . childopts : nil \n src \ clj \ backtype \ storm \ config . clj \n + ( defn read - supervisor - storm - conf [ conf storm - id ] \n + ( let [ stormroot ( supervisor - stormdist - root conf storm - id ) \n + conf - path ( supervisor - stormconf - path stormroot ) \n + topology - path ( supervisor - stormcode - path stormroot ) ] \n + ( merge conf ( Utils / deserialize ( FileUtils / readFileToByteArray ( File . conf - path ) ) ) ) \n + ) ) \n + \n + ( defn read - supervisor - topology [ conf storm - id ] \n + ( let [ stormroot ( supervisor - stormdist - root conf storm - id ) \n + topology - path ( supervisor - stormcode - path stormroot ) ] \n + ( Utils / deserialize ( FileUtils / readFileToByteArray ( File . topology - path ) ) ) \n + ) ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( defn - read - storm - cache [ conf storm - id ] \n - ( let [ stormroot ( supervisor - stormdist - root conf storm - id ) \n - conf - path ( supervisor - stormconf - path stormroot ) \n - topology - path ( supervisor - stormcode - path stormroot ) ] \n - [ ( merge conf ( Utils / deserialize ( FileUtils / readFileToByteArray ( File . conf - path ) ) ) ) \n - ( Utils / deserialize ( FileUtils / readFileToByteArray ( File . topology - path ) ) ) ] \n - ) ) \n - \n - [ storm - conf topology ] ( read - storm - cache conf storm - id ) \n + storm - conf ( read - supervisor - storm - conf conf storm - id ) \n + topology ( read - supervisor - topology conf storm - id ) \n,refactor reading of topology and topology config from supervisor cache,356
"src \ clj \ backtype \ storm \ command \ list . clj \n - ( println "" No topology running . "" ) \n + ( println "" No topologies running . "" ) \n - ( println ( format msg - format "" Topology Name "" "" Status "" "" Num _ tasks "" "" Num _ workers "" "" Uptime _ secs "" ) ) \n + ( println ( format msg - format "" Topology _ name "" "" Status "" "" Num _ tasks "" "" Num _ workers "" "" Uptime _ secs "" ) ) \n",change copy in storm list command a little,356
src \ jvm \ backtype \ storm \ scheduler \ ExecutorDetails . java \n - public void setStartTask ( Integer startTask ) { \n - this . startTask = startTask ; \n - } \n - \n - public void setEndTask ( Integer endTask ) { \n - this . endTask = endTask ; \n - } \n - \n src \ jvm \ backtype \ storm \ scheduler \ SupervisorDetails . java \n - \n - / * * \n - * return all the ports . \n - * \n - * @ return \n - * / \n - public Collection < Integer > getAllPorts ( ) { \n - return this . allPorts ; \n - } \n - \n,get rid of unwanted setter methods in scheduler api,356
"test \ clj \ backtype \ storm \ nimbus _ test . clj \n + \n + ( is ( thrown ? InvalidTopologyException \n + ( . rebalance ( : nimbus cluster ) "" test "" \n + ( doto ( RebalanceOptions . ) \n + ( . set _ num _ executors { "" 1 "" 0 } ) \n + ) ) ) ) \n",added test for error for rebalancing to zero executors,356
"test \ clj \ backtype \ storm \ nimbus _ test . clj \n + ( deftest test - submit - invalid \n + ( with - simulated - time - local - cluster [ cluster \n + : daemon - conf { SUPERVISOR - ENABLE false \n + TOPOLOGY - ACKER - EXECUTORS 0 } ] \n + ( letlocals \n + ( bind topology ( thrift / mk - topology \n + { "" 1 "" ( thrift / mk - spout - spec ( TestPlannerSpout . true ) : parallelism - hint 0 : conf { TOPOLOGY - TASKS 1 } ) } \n + { } ) ) \n + \n + ( is ( thrown ? InvalidTopologyException \n + ( submit - local - topology ( : nimbus cluster ) \n + "" test "" \n + { } \n + topology ) ) ) \n + ) ) ) \n + \n",added test for submitting topology with invalid number of executors,356
"test \ clj \ backtype \ storm \ nimbus _ test . clj \n - ( defn storm - component - info [ cluster storm - name ] \n + ( defn storm - component - > task - info [ cluster storm - name ] \n - task - info ( storm - component - info cluster "" mystorm "" ) ] \n + task - info ( storm - component - > task - info cluster "" mystorm "" ) ] \n - ( let [ task - info ( storm - component - info cluster "" storm2 "" ) ] \n + ( let [ task - info ( storm - component - > task - info cluster "" storm2 "" ) ] \n - task - info ( storm - component - info cluster "" mystorm "" ) ] \n + task - info ( storm - component - > task - info cluster "" mystorm "" ) ] \n - task - info ( storm - component - info cluster "" test "" ) ] \n + task - info ( storm - component - > task - info cluster "" test "" ) ] \n",rename storm - component - info to storm - component - > task - info for clarity,356
test \ clj \ backtype \ storm \ nimbus _ test . clj \n - ( is ( = ( set task - ids ) ( set assigned - task - ids ) ) ) \n + ( is ( = ( sort task - ids ) ( sort assigned - task - ids ) ) ) \n,make check - consistency in nimbus _ test stronger by checking that assigned tasks are identical to topology tasks,356
"conf \ defaults . yaml \n - zmq . high . water . mark : null \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( storm - conf ZMQ - HIGH - WATER - MARK ) \n src \ clj \ backtype \ storm \ messaging \ zmq . clj \n - ( deftype ZMQContext [ context linger - ms hwm ipc ? ] \n + ( deftype ZMQContext [ context linger - ms ipc ? ] \n - ( mq / set - hwm hwm ) \n - ( defn mk - zmq - context [ num - threads linger hwm local ? ] \n - ( ZMQContext . ( mq / context num - threads ) linger hwm local ? ) ) \n + ( defn mk - zmq - context [ num - threads linger local ? ] \n + ( ZMQContext . ( mq / context num - threads ) linger local ? ) ) \n src \ clj \ zilch \ mq . clj \n - ( . setHwm ( long hwm ) ) ) \n + ( . setHWM ( long hwm ) ) ) \n src \ jvm \ backtype \ storm \ Config . java \n - \n - / * * \n - * The high water mark for the underlying push sockets used to send messages . If downstream \n - * tasks to a producer are overloaded , the producer will block until the downstream tasks \n - * have consumed messages . This configuration can be used to prevent overloading in topologies \n - * that use unreliable spouts and are thus not controllable with TOPOLOGY _ MAX _ SPOUT _ PENDING . \n - * / \n - public static String ZMQ _ HIGH _ WATER _ MARK = "" zmq . high . water . mark "" ; \n","remove ability to customize HWM , as it ' s not actually useful",356
"src \ clj \ backtype \ storm \ daemon \ worker . clj \n + ( if - not ( local - mode ? conf ) \n + ( redirect - stdio - to - log4j ! ) ) \n src \ clj \ backtype \ storm \ log . clj \n + \n + ( defn log - capture ! [ & args ] \n + ( apply log / log - capture ! args ) ) \n + \n + ( defn log - stream [ & args ] \n + ( apply log / log - stream args ) ) \n src \ clj \ backtype \ storm \ util . clj \n - ( : import [ java . util Timer ] ) \n + ( : import [ clojure . lang RT ] ) \n + \n + ( defn redirect - stdio - to - log4j ! [ ] \n + ; ; set - var - root doesn ' t work with * out * and * err * , so digging deeper here \n + ( . set RT / OUT ( java . io . OutputStreamWriter . \n + ( log - stream : info "" STDIO "" ) ) ) \n + ( . set RT / ERR ( PrintWriter . \n + ( java . io . OutputStreamWriter . \n + ( log - stream : error "" STDIO "" ) ) \n + true ) ) \n + ( log - capture ! "" STDIO "" ) ) \n",redirect all stdio to regular worker log file,356
"src \ clj \ backtype \ storm \ util . clj \n - ; ; set - var - root doesn ' t work with * out * and * err * , so digging deeper here \n - ( . set RT / OUT ( java . io . OutputStreamWriter . \n - ( log - stream : info "" STDIO "" ) ) ) \n - ( . set RT / ERR ( PrintWriter . \n - ( java . io . OutputStreamWriter . \n - ( log - stream : error "" STDIO "" ) ) \n - true ) ) \n + ; ; set - var - root doesn ' t work with * out * and * err * , so digging much deeper here \n + ; ; Unfortunately , this code seems to work at the REPL but not when spawned as worker processes \n + ; ; it might have something to do with being a child process \n + ; ; ( set ! ( . ( . getThreadBinding RT / OUT ) val ) \n + ; ; ( java . io . OutputStreamWriter . \n + ; ; ( log - stream : info "" STDIO "" ) ) ) \n + ; ; ( set ! ( . ( . getThreadBinding RT / ERR ) val ) \n + ; ; ( PrintWriter . \n + ; ; ( java . io . OutputStreamWriter . \n + ; ; ( log - stream : error "" STDIO "" ) ) \n + ; ; true ) ) \n",don ' t try to emit clojure stdout / err for now,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( . assignSlots ^ INimbus ( : inimbus nimbus ) \n - ( for [ [ id port ] ( newly - added - slots existing - assignment assignment ) ] \n - ( WorkerSlot . id port ) ) \n - topology - details ) \n - ) ) ) ) ) \n + ) ) ) \n + ( - > > ( dofor [ [ topology - id assignment ] new - assignments \n + : let [ existing - assignment ( get existing - assignments topology - id ) ] ] \n + ( newly - added - slots existing - assignment assignment ) ) \n + ( apply concat ) \n + ( map ( fn [ [ id port ] ] ( WorkerSlot . id port ) ) ) \n + ( . assignSlots ^ INimbus ( : inimbus nimbus ) ( . getTopologies topologies ) ) \n + ) ) ) \n - ( assignSlots [ this slot topology ] \n + ( assignSlots [ this topologies slots ] \n src \ jvm \ backtype \ storm \ scheduler \ INimbus . java \n - void assignSlots ( Collection < WorkerSlot > slot , TopologyDetails topology ) ; \n + void assignSlots ( Collection < TopologyDetails > topologies , Collection < WorkerSlot > newSlots ) ; \n",generalize INimbus # assignSlots to do all new assignments at once ( necessary for storm / mesos,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - . getTopologies \n - ( . assignSlots ^ INimbus ( : inimbus nimbus ) ( . getTopologies topologies ) ) \n + ( . assignSlots ^ INimbus ( : inimbus nimbus ) topologies ) \n src \ jvm \ backtype \ storm \ scheduler \ INimbus . java \n - Collection < WorkerSlot > availableSlots ( Collection < SupervisorDetails > existingSupervisors , Collection < WorkerSlot > usedSlots , Collection < TopologyDetails > topologies ) ; \n + Collection < WorkerSlot > availableSlots ( Collection < SupervisorDetails > existingSupervisors , Collection < WorkerSlot > usedSlots , Topologies topologies ) ; \n - void assignSlots ( Collection < TopologyDetails > topologies , Collection < WorkerSlot > newSlots ) ; \n + void assignSlots ( Topologies topologies , Collection < WorkerSlot > newSlots ) ; \n",improve INimbus interface with Topologies object rather than collection of topologydetails,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( defn - read - all - supervisor - details [ nimbus all - slots supervisor - > dead - ports ] \n + ( defn - read - all - supervisor - details [ nimbus all - slots available - slots supervisor - > dead - ports ] \n + nonexistent - supervisor - slots ( apply dissoc available - slots ( keys supervisor - infos ) ) \n - all - supervisor - details ) ) \n + ( merge all - supervisor - details \n + ( into { } \n + ( for [ [ sid ports ] nonexistent - supervisor - slots ] \n + [ sid ( SupervisorDetails . sid nil ports ) ] ) ) \n + ) ) ) \n - supervisors ( read - all - supervisor - details nimbus all - slots supervisor - > dead - ports ) \n + supervisors ( read - all - supervisor - details nimbus all - slots available - slots supervisor - > dead - ports ) \n src \ jvm \ backtype \ storm \ scheduler \ SupervisorDetails . java \n + \n + public SupervisorDetails ( String id , Object meta , Collection < Integer > allPorts ) { \n + this . id = id ; \n + this . meta = meta ; \n + this . allPorts = allPorts ; \n + } \n",include available slots without supervisor id into scheduler,356
"src \ jvm \ backtype \ storm \ StormSubmitter . java \n + if ( localJar = = null ) { \n + throw new RuntimeException ( "" Must submit topologies using the ' storm ' client script so that StormSubmitter knows which jar to upload . "" ) ; \n + } \n",throw helpful error message if StormSubmitter used without storm client script,356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n + ( defn executor - max - spout - pending [ storm - conf num - tasks ] \n + ( let [ p ( storm - conf TOPOLOGY - MAX - SPOUT - PENDING ) ] \n + ( if p ( * p num - tasks ) ) ) ) \n + \n - max - spout - pending ( * ( storm - conf TOPOLOGY - MAX - SPOUT - PENDING ) ( count task - datas ) ) \n + max - spout - pending ( executor - max - spout - pending storm - conf ( count task - datas ) ) \n src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( let [ start - time ( executor - start - times executor ) \n - nimbus - time ( - > heartbeats - cache executor : nimbus - time ) ] \n + ( let [ start - time ( get executor - start - times executor ) \n + nimbus - time ( - > heartbeats - cache ( get executor ) : nimbus - time ) ] \n - ( map - val ( partial apply partition - fixed ) ) ) \n + ( map - val ( partial apply partition - fixed ) ) \n - ) ) \n + ) ) ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( let [ cluster - state ( cluster / mk - distributed - cluster - state conf ) \n + ( let [ cluster - state ( cluster / mk - distributed - cluster - state conf ) \n - ( schedule - recurring ( : timer worker ) 0 ( conf TASK - HEARTBEAT - FREQUENCY - SECS ) # ( do - executor - heartbeats worker : executors ( : executors worker ) ) ) \n + ( schedule - recurring ( : timer worker ) 0 ( conf TASK - HEARTBEAT - FREQUENCY - SECS ) # ( do - executor - heartbeats worker : executors executors ) ) \n,"fixed bugs , got some integration tests working",356
src \ jvm \ backtype \ storm \ utils \ VersionedStore . java \n - for ( File f : new File ( dir ) . listFiles ( ) ) { \n - ret . add ( f . getAbsolutePath ( ) ) ; \n + File [ ] contents = new File ( dir ) . listFiles ( ) ; \n + if ( contents ! = null ) { \n + for ( File f : contents ) { \n + ret . add ( f . getAbsolutePath ( ) ) ; \n + } \n,"in VersionedStore , always return a list from listDir",356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n - root - id ( MessageId / generateId ) \n + root - id ( if rooted ? ( MessageId / generateId ) ) \n,only generate a root id for spout tuples participating in acking framework,356
CHANGELOG . md \n + * Major optimization for unreliable spouts and unanchored tuples ( will use far less CPU ) \n src \ clj \ backtype \ storm \ daemon \ executor . clj \n - : let [ edge - id ( MessageId / generateId ) ] ] \n - ( put - xor ! pending - acks a edge - id ) \n - ( doseq [ root - id ( - > a . getMessageId . getAnchorsToIds . keySet ) ] \n - ( put - xor ! anchors - to - ids root - id edge - id ) ) ) \n + : let [ root - ids ( - > a . getMessageId . getAnchorsToIds . keySet ) ] ] \n + ( when ( pos ? ( count root - ids ) ) \n + ( let [ edge - id ( MessageId / generateId ) ] \n + ( put - xor ! pending - acks a edge - id ) \n + ( doseq [ root - id root - ids ] \n + ( put - xor ! anchors - to - ids root - id edge - id ) ) \n + ) ) ) \n,optimize bolt emitting when there are no root anchors,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( : import [ java . util . concurrent ConcurrentLinkedQueue ConcurrentHashMap LinkedBlockingQueue ] ) \n + ( : import [ java . util . concurrent ConcurrentLinkedQueue LinkedBlockingQueue ] ) \n - ( - > > ( acquire - random - range - id choices num - tasks ) \n + ( - > > ( acquire - random - range - id choices ) \n - ( log - debug "" Processing message "" msg ) \n + ; ; ( log - debug "" Processing message "" msg ) \n - tuple - start - times ( ConcurrentHashMap . ) \n + tuple - start - times ( HashMap . ) \n - pending - acks ( ConcurrentHashMap . ) \n + pending - acks ( HashMap . ) \n - ( log - debug "" Received tuple "" tuple "" at task "" task - id ) \n + ; ; ( log - debug "" Received tuple "" tuple "" at task "" task - id ) \n src \ clj \ backtype \ storm \ daemon \ task . clj \n - ( : import [ java . util . concurrent ConcurrentLinkedQueue ConcurrentHashMap LinkedBlockingQueue ] ) \n + ( : import [ java . util . concurrent ConcurrentLinkedQueue LinkedBlockingQueue ] ) \n src \ clj \ backtype \ storm \ util . clj \n - ( : import [ backtype . storm . utils Time Container ClojureTimerTask Utils ] ) \n + ( : import [ backtype . storm . utils Time Container ClojureTimerTask Utils MutableObject ] ) \n - ( ref ( shuffle ( range amt ) ) ) ) \n - \n - ( defn acquire - random - range - id [ rr amt ] \n - ( dosync \n - ( let [ ret ( first @ rr ) ] \n - ( alter \n - rr \n - ( fn [ rr ] \n - ( if ( = 1 ( count rr ) ) \n - ( shuffle ( range amt ) ) \n - ( next rr ) ) \n - ) ) \n - ret \n - ) ) ) \n + ( let [ ids ( range amt ) ] \n + { : range ids : state ( MutableObject . ( shuffle ids ) ) } ) ) \n + \n + ( defn acquire - random - range - id [ rr ] \n + ( let [ { ids : range state : state } rr \n + [ ret & rest ] ( . getObject ^ MutableObject state ) ] \n + ( if ( = 0 ( count rest ) ) \n + ( . setObject ^ MutableObject state ( shuffle ids ) ) \n + ( . setObject ^ MutableObject state rest ) ) \n + ret \n + ) ) \n","remove thread - safety from outputcollector in favor of major performance enhancements , esp to shuffle grouping",356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( when - not ( = stored - task - id task - id ) \n - ( throw - runtime "" Fatal error , mismatched task ids : "" task - id "" "" stored - task - id ) ) \n + ( when - not ( = stored - task - id task - id ) \n + ( throw - runtime "" Fatal error , mismatched task ids : "" task - id "" "" stored - task - id ) ) \n",fix incorrect placement of task id sanity check for spout acking,356
"src \ clj \ backtype \ storm \ bootstrap . clj \n - ( import ( quote [ java . util List Random Map HashMap Collections ArrayList ] ) ) \n + ( import ( quote [ java . util Collection List Random Map HashMap Collections ArrayList ] ) ) \n src \ clj \ backtype \ storm \ daemon \ task . clj \n - ( let [ ; ; TODO : this doesn ' t seem to be very fast \n - ; ; and seems to be the current bottleneck \n - out - tasks ( mapcat \n - ( fn [ [ out - component grouper ] ] \n - ( when ( = : direct grouper ) \n - ; ; TODO : this is wrong , need to check how the stream was declared \n - ( throw ( IllegalArgumentException . "" Cannot do regular emit to direct stream "" ) ) ) \n - ( collectify ( grouper values ) ) ) \n - ( stream - > component - > grouper stream ) ) ] \n + ( let [ out - tasks ( ArrayList . ) ] \n + ( doseq [ [ out - component grouper ] ( stream - > component - > grouper stream ) ] \n + ( when ( = : direct grouper ) \n + ; ; TODO : this is wrong , need to check how the stream was declared \n + ( throw ( IllegalArgumentException . "" Cannot do regular emit to direct stream "" ) ) ) \n + ( let [ comp - tasks ( grouper values ) ] \n + ( if ( or ( sequential ? comp - tasks ) ( instance ? Collection comp - tasks ) ) \n + ( . addAll out - tasks comp - tasks ) \n + ( . add out - tasks comp - tasks ) \n + ) ) ) \n",optimize application of groupers in tasks - fn,356
src \ clj \ backtype \ storm \ util . clj \n - ( - ( System / currentTimeMillis ) time - ms ) ) \n + ( - ( System / currentTimeMillis ) ( long time - ms ) ) ) \n - ( let [ start ( int 0 ) \n + ( let [ freq ( int freq ) \n + start ( int 0 ) \n,microoptimizations to even - sampler and time - delta - ms with primitve math,356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n - choices ( rotating - random - range num - tasks ) ] \n + choices ( rotating - random - range target - tasks ) ] \n - ( - > > ( acquire - random - range - id choices ) \n - ( . get target - tasks ) ) ) ) ) \n + ( acquire - random - range - id choices ) ) ) ) \n src \ clj \ backtype \ storm \ util . clj \n - ( : import [ java . util UUID ] ) \n + ( : import [ java . util UUID Random ArrayList List Collections ] ) \n - ( defn rotating - random - range [ amt ] \n - ( let [ ids ( range amt ) ] \n - { : range ids : state ( MutableObject . ( shuffle ids ) ) } ) ) \n + ( defn rotating - random - range [ choices ] \n + ( let [ rand ( Random . ) \n + choices ( ArrayList . choices ) ] \n + ( Collections / shuffle choices rand ) \n + [ ( MutableInt . - 1 ) choices rand ] ) ) \n - ( defn acquire - random - range - id [ rr ] \n - ( let [ { ids : range state : state } rr \n - [ ret & rest ] ( . getObject ^ MutableObject state ) ] \n - ( if ( = 0 ( count rest ) ) \n - ( . setObject ^ MutableObject state ( shuffle ids ) ) \n - ( . setObject ^ MutableObject state rest ) ) \n - ret \n - ) ) \n + ( defn acquire - random - range - id [ [ ^ MutableInt curr ^ List state ^ Random rand ] ] \n + ( when ( > = ( . increment curr ) ( . size state ) ) \n + ( . set curr 0 ) \n + ( Collections / shuffle state rand ) ) \n + ( . get state ( . get curr ) ) ) \n,massive optimization to shuffle grouping ( 10x ),356
"src \ jvm \ backtype \ storm \ task \ GeneralTopologyContext . java \n - import java . util . Collections ; \n + private Map < String , Map < String , Fields > > _ componentToStreamToFields = new HashMap ( ) ; \n + \n + / / precompute this because getComponentOutputFields is called on the critical path \n + / / of tuple creation \n + for ( String component : getComponentIds ( ) ) { \n + Map < String , Fields > streamToFields = _ componentToStreamToFields . get ( component ) ; \n + if ( streamToFields = = null ) { \n + streamToFields = new HashMap ( ) ; \n + _ componentToStreamToFields . put ( component , streamToFields ) ; \n + } \n + ComponentCommon common = getComponentCommon ( component ) ; \n + for ( String stream : common . get _ streams ( ) . keySet ( ) ) { \n + StreamInfo info = common . get _ streams ( ) . get ( stream ) ; \n + streamToFields . put ( stream , new Fields ( info . get _ output _ fields ( ) ) ) ; \n + } \n + } \n - StreamInfo streamInfo = getComponentCommon ( componentId ) . get _ streams ( ) . get ( streamId ) ; \n - if ( streamInfo = = null ) { \n + Fields ret = _ componentToStreamToFields . get ( componentId ) . get ( streamId ) ; \n + if ( ret = = null ) { \n - return new Fields ( streamInfo . get _ output _ fields ( ) ) ; \n + return ret ; \n",precompute component - > stream - > fields since it ' s in the critical path,356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( let [ serialized - pairs ( dofor [ [ task tuple ] remote ] [ task ( . serialize serializer tuple ) ] ) ] \n + ; ; not using map because the lazy seq shows up in perf profiles \n + ( let [ serialized - pairs ( ArrayList . ) ] \n + ( doseq [ [ task tuple ] remote ] \n + ( . add serialized - pairs [ task ( . serialize serializer tuple ) ] ) ) \n - task - > node + port ( : task - > node + port worker ) ] \n + task - > node + port ( : task - > node + port worker ) \n + endpoint - socket - lock ( : endpoint - socket - lock worker ) \n + ] \n - ( read - locked ( : endpoint - socket - lock worker ) \n + ( read - locked endpoint - socket - lock \n,"pre - load map entry , optimize serialization by replacing map with manual arraylist / iteration",356
"conf \ defaults . yaml \n + topology . receiver . buffer . size : 16384 # individual messages \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n + ( - > worker : storm - conf ( get TOPOLOGY - RECEIVER - BUFFER - SIZE ) ) \n src \ clj \ backtype \ storm \ messaging \ loader . clj \n - ( : import [ backtype . storm . utils DisruptorQueue ] ) \n - ( : require [ backtype . storm . messaging [ local : as local ] [ protocol : as msg ] ] ) ) \n + ( : import [ java . util ArrayList ] ) \n + ( : import [ backtype . storm . utils DisruptorQueue MutableObject ] ) \n + ( : require [ backtype . storm . messaging [ local : as local ] [ protocol : as msg ] ] ) \n + ( : require [ backtype . storm [ disruptor : as disruptor ] ] ) ) \n - ; ; TODO : try adding a layer of disruptor single - > other queue batching \n - [ context storm - id port transfer - local - fn \n + [ context storm - id port transfer - local - fn send - buffer - size \n - ( let [ vthread ( async - loop \n + ( let [ receive - batcher ( disruptor / disruptor - queue send - buffer - size : claim - strategy : single - threaded ) \n + cached - emit ( MutableObject . ( ArrayList . ) ) \n + vthread ( async - loop \n - ; ; TODO : write a batch of tuples , do recv - more until whole batch is received ( maybe with a limit ) \n - ( transfer - local - fn [ packet ] ) \n + ( disruptor / publish receive - batcher packet ) \n + ( disruptor / set - handler \n + receive - batcher \n + ( fn [ o seq - id batch - end ? ] \n + ( let [ ^ ArrayList alist ( . getObject cached - emit ) ] \n + ( . add alist o ) \n + ( when batch - end ? \n + ( transfer - local - fn alist ) \n + ( . setObject cached - emit ( ArrayList . ) ) \n + ) ) ) ) \n + ( . shutdown receive - batcher ) \n src \ jvm \ backtype \ storm \ Config . java \n + / * * \n + * The size of the Disruptor queue for the thread that receives messages from the network \n + * ( used to batch messages onto the executor queues ) . \n + * / \n + public static String TOPOLOGY _ RECEIVER _ BUFFER _ SIZE = "" topology . receiver . buffer . size "" ; \n + \n",add batching in receive thread - > executor queues,356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n + ; ; TODO : optimize this by using a hashmap for these maps \n src \ clj \ backtype \ storm \ messaging \ loader . clj \n - ( let [ receive - batcher ( disruptor / disruptor - queue send - buffer - size : claim - strategy : single - threaded ) \n + ( let [ receive - batcher ( disruptor / disruptor - queue send - buffer - size \n + : claim - strategy : single - threaded \n + : wait - strategy : yield ) \n,try using different wait strategy for receive thread,356
conf \ defaults . yaml \n - topology . receiver . buffer . size : 1024 # individual messages \n + topology . receiver . buffer . size : 1 # individual messages \n,reduce receive buffer size to see if it fixes the heartbeating problem,356
"src \ jvm \ backtype \ storm \ testing \ MemoryTransactionalSpout . java \n - getFinishedStatuses ( ) . put ( partition , true ) ; \n + Map < Integer , Boolean > finishedStatuses = getFinishedStatuses ( ) ; \n + / / will be null in remote mode \n + if ( finishedStatuses ! = null ) { \n + finishedStatuses . put ( partition , true ) ; \n + } \n",fix cluster mode for MemoryTransactionalSpout ( don ' t update finishedStatuses in cluster mode ),356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n - task - > short - executor ( : task - > short - executor worker ) ] \n + task - > short - executor ( : task - > short - executor worker ) \n + task - getter ( comp # ( get task - > short - executor % ) fast - first ) ] \n - ( let [ grouped ( group - by ( comp task - > short - executor first ) tuple - batch ) ] \n - ; ; TODO : Need a fast map iter \n + ( let [ grouped ( fast - group - by task - getter tuple - batch ) ] \n - ( into { } ) ) \n + ( into { } ) \n + ( HashMap . ) ) \n src \ clj \ backtype \ storm \ util . clj \n - ( : import [ java . util Map Map $ Entry List ArrayList Collection Iterator ] ) \n + ( : import [ java . util Map Map $ Entry List ArrayList Collection Iterator HashMap ] ) \n - ` ( time \n - ( doseq [ i # ( range 1000000 ) ] \n - ~ @ body ) ) ) \n + ` ( let [ l # ( doall ( range 1000000 ) ) ] \n + ( time \n + ( doseq [ i # l # ] \n + ~ @ body ) ) ) ) \n + \n + ( defn fast - first [ ^ List alist ] \n + ( . get alist 0 ) ) \n + \n + ( defmacro get - with - default [ amap key default - val ] \n + ` ( let [ curr # ( . get ~ amap ~ key ) ] \n + ( if curr # \n + curr # \n + ( do \n + ( let [ new # ~ default - val ] \n + ( . put ~ amap ~ key new # ) \n + new # \n + ) ) ) ) ) \n + \n + ( defn fast - group - by [ afn alist ] \n + ( let [ ret ( HashMap . ) ] \n + ( fast - list - iter [ e alist ] \n + ( let [ key ( afn e ) \n + ^ List curr ( get - with - default ret key ( ArrayList . ) ) ] \n + ( . add curr e ) ) ) \n + ret ) ) \n,use fast - group - by in critical path,356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n - : node + port - > socket ( atom { } ) \n - : task - > node + port ( atom { } ) \n + : cached - node + port - > socket ( atom { } ) \n + : cached - task - > node + port ( atom { } ) \n - current - connections ( set ( keys @ ( : node + port - > socket worker ) ) ) \n + current - connections ( set ( keys @ ( : cached - node + port - > socket worker ) ) ) \n - ( swap ! ( : node + port - > socket worker ) \n + ( swap ! ( : cached - node + port - > socket worker ) \n - ( reset ! ( : task - > node + port worker ) my - assignment ) ) \n + ( reset ! ( : cached - task - > node + port worker ) my - assignment ) ) \n - ( . close ( @ ( : node + port - > socket worker ) endpoint ) ) ) \n + ( . close ( @ ( : cached - node + port - > socket worker ) endpoint ) ) ) \n - ( : node + port - > socket worker ) \n + ( : cached - node + port - > socket worker ) \n - node + port - > socket ( : node + port - > socket worker ) \n - task - > node + port ( : task - > node + port worker ) \n + node + port - > socket ( : cached - node + port - > socket worker ) \n + task - > node + port ( : cached - task - > node + port worker ) \n - ( doseq [ [ _ socket ] @ ( : node + port - > socket worker ) ] \n + ( doseq [ [ _ socket ] @ ( : cached - node + port - > socket worker ) ] \n,rename socket cache vars to be less confusing with the assignment vars,356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( . close ( @ ( : cached - node + port - > socket worker ) endpoint ) ) ) \n + ( . close ( get @ ( : cached - node + port - > socket worker ) endpoint ) ) ) \n,fix lookup from cached node + port hashmap,356
src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n + k . setReferences ( false ) ; \n src \ jvm \ backtype \ storm \ testing \ TestSerObject . java \n - if ( o = = null ) return false ; \n,don ' t do reference serialization with Kryo to make it faster,356
src \ clj \ backtype \ storm \ daemon \ task . clj \n + ( defn hooks - empty ? [ ^ Collection hooks ] \n + ( . isEmpty hooks ) ) \n + \n - ( when - not ( empty ? hooks # ) \n + ( when - not ( hooks - empty ? hooks # ) \n,optimize checking of hooks by avoiding empty ? which uses seq in favor of java isEmpty method,356
"src \ clj \ backtype \ storm \ messaging \ loader . clj \n - ( fn [ socket ] \n - ( let [ batched ( ArrayList . ) \n - init ( msg / recv socket ) ] \n - ( loop [ [ task msg : as packet ] init ] \n - ( if ( = task - 1 ) \n - ( do ( log - message "" Receiving - thread : [ "" storm - id "" , "" port "" ] received shutdown notice "" ) \n - ( . close socket ) \n - nil ) \n - ( do \n - ( when packet ( . add batched packet ) ) \n - ( if ( and packet ( < ( . size batched ) max - buffer - size ) ) \n - ( recur ( msg / recv - with - flags socket 1 ) ) \n - ( do ( transfer - local - fn batched ) \n - 0 ) ) ) ) ) ) ) \n - : args - fn ( fn [ ] [ ( msg / bind context storm - id port ) ] ) \n + ( fn [ ] \n + ( let [ socket ( msg / bind context storm - id port ) ] \n + ( fn [ ] \n + ( let [ batched ( ArrayList . ) \n + init ( msg / recv socket ) ] \n + ( loop [ [ task msg : as packet ] init ] \n + ( if ( = task - 1 ) \n + ( do ( log - message "" Receiving - thread : [ "" storm - id "" , "" port "" ] received shutdown notice "" ) \n + ( . close socket ) \n + nil ) \n + ( do \n + ( when packet ( . add batched packet ) ) \n + ( if ( and packet ( < ( . size batched ) max - buffer - size ) ) \n + ( recur ( msg / recv - with - flags socket 1 ) ) \n + ( do ( transfer - local - fn batched ) \n + 0 ) ) ) ) ) ) ) ) ) \n + : factory ? true \n src \ clj \ backtype \ storm \ util . clj \n - : args - fn ( fn [ ] [ ] ) \n + : factory ? false \n - ( let [ args ( args - fn ) ] \n + ( let [ afn ( if factory ? ( afn ) afn ) ] \n - ( let [ sleep - time ( apply afn args ) ] \n + ( let [ sleep - time ( afn ) ] \n",remove args - fn from async - loop and replace with factory function to avoid seq calls,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n + rand ( Random . ( Utils / secureRandomLong ) ) \n - root - id ( if rooted ? ( MessageId / generateId ) ) \n - out - ids ( fast - list - for [ t out - tasks ] ( if rooted ? ( MessageId / generateId ) ) ) ] \n + root - id ( if rooted ? ( MessageId / generateId rand ) ) \n + out - ids ( fast - list - for [ t out - tasks ] ( if rooted ? ( MessageId / generateId rand ) ) ) ] \n + rand ( Random . ( Utils / secureRandomLong ) ) \n - ( let [ edge - id ( MessageId / generateId ) ] \n + ( let [ edge - id ( MessageId / generateId rand ) ] \n src \ jvm \ backtype \ storm \ task \ ShellBolt . java \n + import java . util . Random ; \n + private Random _ rand ; \n + _ rand = new Random ( ) ; \n - String genId = Long . toString ( MessageId . generateId ( ) ) ; \n + String genId = Long . toString ( _ rand . nextLong ( ) ) ; \n src \ jvm \ backtype \ storm \ transactional \ TransactionalSpoutCoordinator . java \n + import java . util . Random ; \n + private Random _ rand ; \n + _ rand = new Random ( Utils . secureRandomLong ( ) ) ; \n - TransactionAttempt attempt = new TransactionAttempt ( curr , Utils . randomLong ( ) ) ; \n + TransactionAttempt attempt = new TransactionAttempt ( curr , _ rand . nextLong ( ) ) ; \n src \ jvm \ backtype \ storm \ tuple \ MessageId . java \n - import backtype . storm . utils . WritableUtils ; \n + import java . util . Random ; \n - public static long generateId ( ) { \n - return Utils . randomLong ( ) ; \n + public static long generateId ( Random rand ) { \n + return rand . nextLong ( ) ; \n src \ jvm \ backtype \ storm \ utils \ Utils . java \n - public static long randomLong ( ) { \n + public static long secureRandomLong ( ) { \n","replace UUID with much faster Random , since it ' s a bottleneck",356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n + ^ Integer max - spout - pending ( if max - spout - pending ( int max - spout - pending ) ) \n - ( disruptor / publish event - queue # ( ack - spout - msg executor - data task - data message - id { : stream out - stream - id : values values } 0 ) ) ) ) \n + ( disruptor / publish event - queue \n + # ( ack - spout - msg executor - data task - data message - id \n + { : stream out - stream - id : values values } \n + ( if ( sampler ) 0 ) ) ) ) ) \n,fix bug in recording stats for auto - acked tuples when there are no ackers,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( : batch - transfer - > worker executor - data ) \n + ( : batch - transfer - queue executor - data ) \n - active ( atom true ) \n + ; ; technically this is called twice for bolts , but that ' s ok \n - ( reset ! active false ) \n + ( disruptor / halt - with - interrupt ! ( : receive - queue executor - data ) ) \n + ( disruptor / halt - with - interrupt ! ( : batch - transfer - queue executor - data ) ) \n - ( . shutdown ( : batch - transfer - queue executor - data ) ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n + ( disruptor / halt - with - interrupt ! ( : transfer - queue worker ) ) \n + \n src \ clj \ backtype \ storm \ disruptor . clj \n + ( defn halt - with - interrupt ! [ ^ DisruptorQueue queue ] \n + ( . haltWithInterrupt queue ) ) \n + \n src \ jvm \ backtype \ storm \ utils \ DisruptorQueue . java \n - import com . lmax . disruptor . Sequencer ; \n + static final Object INTERRUPT = new Object ( ) ; \n - _ consumer = new Sequence ( Sequencer . INITIAL _ CURSOR _ VALUE ) ; \n + _ consumer = new Sequence ( ) ; \n + _ barrier = _ buffer . newBarrier ( ) ; \n - _ barrier = _ buffer . newBarrier ( _ consumer ) ; \n + public void haltWithInterrupt ( ) { \n + publish ( INTERRUPT ) ; \n + } \n + \n - final long availableSequence = _ barrier . waitFor ( _ consumer . get ( ) + 1 ) ; \n + final long nextSequence = _ consumer . get ( ) + 1 ; \n + final long availableSequence = _ barrier . waitFor ( nextSequence ) ; \n + } else if ( o = = INTERRUPT ) { \n + throw new InterruptedException ( "" Disruptor processing interrupted "" ) ; \n",Add halt method to DisruptorQueue to force it to unblock ( for shutdown purposes ) . Fixed other minor issues to get tests passing .,356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n - event - handler ( mk - task - receiver executor - data tuple - action - fn ) ] \n + event - handler ( mk - task - receiver executor - data tuple - action - fn ) \n + has - ackers ? ( has - ackers ? storm - conf ) ] \n - rooted ? ( and message - id ( has - ackers ? storm - conf ) ) \n + rooted ? ( and message - id has - ackers ? ) \n,precompute has - ackers ? as a micro - optimization,356
"src \ jvm \ backtype \ storm \ testing \ TestGlobalCount . java \n + import backtype . storm . tuple . Values ; \n - import static backtype . storm . utils . Utils . tuple ; \n - _ collector . emit ( tuple ( _ count ) ) ; \n + _ collector . emit ( input , new Values ( _ count ) ) ; \n",fix TestGlobalCount to anchor tuples to it doesn ' t cause errors in tests,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n + : executor - id executor - id \n - ( schedule - recurring \n - ( : timer worker ) \n - tick - time - secs \n - tick - time - secs \n - ( fn [ ] \n - ( disruptor / publish \n - receive - queue \n - [ [ nil ( TupleImpl . context [ tick - time - secs ] - 1 Constants / SYSTEM _ TICK _ STREAM _ ID ) ] ] \n - ) ) ) ) ) ) \n + ( if - not ( pos ? tick - time - secs ) \n + ( log - message "" Timeouts disabled for executor "" ( : executor - id executor - data ) ) \n + ( schedule - recurring \n + ( : timer worker ) \n + tick - time - secs \n + tick - time - secs \n + ( fn [ ] \n + ( disruptor / publish \n + receive - queue \n + [ [ nil ( TupleImpl . context [ tick - time - secs ] - 1 Constants / SYSTEM _ TICK _ STREAM _ ID ) ] ] \n + ) ) ) ) ) ) ) \n src \ clj \ backtype \ storm \ testing . clj \n + TOPOLOGY - MESSAGE - TIMEOUT - SECS - 1 \n - \n",update tests to have timeouts disabled by default to avoid accidental timeouts and broken tests,356
src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( let [ num - tasks ( count target - tasks ) \n - choices ( rotating - random - range target - tasks ) ] \n + ( let [ choices ( rotating - random - range target - tasks ) ] \n,get rid of unused num - tasks local in mk - shuffle - grouper,356
src \ clj \ backtype \ storm \ testing . clj \n + ( throw t # ) \n,fixed accidental suppressing of errors in unit tests,356
"bin \ storm \n + print "" Configs can be overridden using one or more - c flags , e . g . \ "" storm list - c nimbus . host = nimbus . mycompany . com \ "" \ n "" \n",document - c flag for storm client in the help printout,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n + debug ? ( = true ( - > executor - data : storm - conf ( get TOPOLOGY - DEBUG ) ) ) \n - ; ; ( log - debug "" Processing message "" msg ) \n + ( when debug ? ( log - message "" Processing received message "" tuple ) ) \n",have TOPOLOGY - DEBUG show received messages as well,356
"src \ jvm \ backtype \ storm \ drpc \ LinearDRPCTopologyBuilder . java \n - / / need a "" final bolt "" method , that does fields groupings based on the first field of previous streams . \n - / / preparerequest needs to emit to a special stream to indicate which task in the last bolt is responsible for that id ? \n - / / - - what if it ' s shuffle grouping all the way through ? need to enforce that last bolt do fields grouping on id . . . \n + / / Trident subsumes the functionality provided by this class , so it ' s deprecated \n + @ Deprecated \n src \ jvm \ backtype \ storm \ transactional \ TransactionalTopologyBuilder . java \n - * TODO : check to see if there are two topologies active with the same transactional id \n - * essentially want to implement a file lock on top of zk ( use ephemeral nodes ? ) \n - * or just use the topology name ? \n + * Trident subsumes the functionality provided by transactional topologies , so this \n + * class is deprecated . \n - \n + @ Deprecated \n src \ jvm \ backtype \ storm \ utils \ TimeCacheMap . java \n + / / deprecated in favor of non - threaded RotatingMap \n + @ Deprecated \n","deprecated LinearDRPCTopologyBuilder , transactional topologies , and TimeCacheMap",356
src \ jvm \ backtype \ storm \ utils \ DisruptorQueue . java \n - Object o = _ buffer . get ( curr ) . o ; \n + MutableObject mo = _ buffer . get ( curr ) ; \n + Object o = mo . o ; \n + mo . setObject ( null ) ; \n,"clear out an item when it is consumed , avoiding a memory leak",356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - [ supervisor assigned - executors ] \n + [ supervisor assigned - executors now ] \n - now ( current - time - secs ) \n - allocated ( read - allocated - workers supervisor assigned - executors ) \n + now ( current - time - secs ) \n + allocated ( read - allocated - workers supervisor assigned - executors now ) \n + "" . Current supervisor time : "" now \n",more informative logging in supervisor ( ported from 0 . 7 . 3 ),356
"src \ clj \ backtype \ storm \ testing . clj \n - ( while ( not ( every ? ( memfn waiting ? ) daemons ) ) \n + ( while ( not ( every ? ( memfn waiting ? ) daemons ) ) \n + ; ; ( doseq [ d daemons ] \n + ; ; ( if - not ( ( memfn waiting ? ) d ) \n + ; ; ( println d ) ) ) \n src \ jvm \ backtype \ storm \ utils \ Time . java \n - private static Map < Thread , AtomicLong > threadSleepTimes ; \n + private static volatile Map < Thread , AtomicLong > threadSleepTimes ; \n",make threadSleepTimes volatile just in case . . .,356
src \ clj \ backtype \ storm \ daemon \ task . clj \n - debug ? ( storm - conf TOPOLOGY - DEBUG ) ] \n + debug ? ( = true ( storm - conf TOPOLOGY - DEBUG ) ) ] \n,make topology debug = false work correctly by explicitly checking for true,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( check - storm - active ! nimbus storm - name false ) \n + ( if ( . contains storm - name "" / "" ) \n + ( throw ( InvalidTopologyException . "" Topology name cannot contains slashes "" ) ) ) \n + ( check - storm - active ! nimbus storm - name false ) \n test \ clj \ backtype \ storm \ nimbus _ test . clj \n + \n + ( bind topology ( thrift / mk - topology \n + { "" 1 "" ( thrift / mk - spout - spec ( TestPlannerSpout . true ) : parallelism - hint 1 : conf { TOPOLOGY - TASKS 1 } ) } \n + { } ) ) \n + ( is ( thrown ? InvalidTopologyException \n + ( submit - local - topology ( : nimbus cluster ) \n + "" test / aaa "" \n + { } \n + topology ) ) ) \n","disallow topology names with slashes because they mess up how data is stored on filesystem , zk , etc",356
"project . clj \n - [ com . netflix . curator / curator - framework "" 1 . 1 . 3 "" ] \n + [ com . netflix . curator / curator - framework "" 1 . 0 . 1 "" ] \n src \ clj \ backtype \ storm \ zookeeper . clj \n - ( : import [ org . apache . zookeeper . server ZooKeeperServer NIOServerCnxnFactory ] ) \n + ( : import [ org . apache . zookeeper . server ZooKeeperServer NIOServerCnxn $ Factory ] ) \n - ( if - let [ factory - tmp ( try - cause ( NIOServerCnxnFactory / createFactory retport 60 ) ; ; 60 is the default maxclientcnxns \n + ( if - let [ factory - tmp ( try - cause ( NIOServerCnxn $ Factory . ( InetSocketAddress . retport ) ) \n","Revert "" Upgrade to Curator 1 . 1 . 3 / ZooKeeper 3 . 4 . 2 "" \n This reverts commit 8c3918b8fa17fb4711c99653fe0c40616bca936b .",356
src \ clj \ backtype \ storm \ daemon \ worker . clj \n + \n + executors ( atom nil ) \n + ; ; launch heartbeat threads immediately so that slow - loading tasks don ' t cause the worker to timeout \n + ; ; to the supervisor \n + _ ( schedule - recurring ( : heartbeat - timer worker ) 0 ( conf WORKER - HEARTBEAT - FREQUENCY - SECS ) heartbeat - fn ) \n + _ ( schedule - recurring ( : executor - heartbeat - timer worker ) 0 ( conf TASK - HEARTBEAT - FREQUENCY - SECS ) # ( do - executor - heartbeats worker : executors @ executors ) ) \n + \n + \n - executors ( dofor [ e ( : executors worker ) ] ( executor / mk - executor worker e ) ) \n + _ ( reset ! executors ( dofor [ e ( : executors worker ) ] ( executor / mk - executor worker e ) ) ) \n - ( doseq [ executor executors ] ( . shutdown executor ) ) \n + ( doseq [ executor @ executors ] ( . shutdown executor ) ) \n - ( schedule - recurring ( : heartbeat - timer worker ) 0 ( conf WORKER - HEARTBEAT - FREQUENCY - SECS ) heartbeat - fn ) \n - ( schedule - recurring ( : executor - heartbeat - timer worker ) 0 ( conf TASK - HEARTBEAT - FREQUENCY - SECS ) # ( do - executor - heartbeats worker : executors executors ) ) \n,launch the worker heartbeat thread immediately so that slow loading tasks don ' t cause the worker to timeout,356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalSpoutBatchExecutor . java \n + / / this is valid here because the batch has been successfully emitted , \n + / / so we can safely delete metadata for prior transactions \n + _ emitter . cleanupBefore ( ( BigInteger ) input . getValue ( 2 ) ) ; \n - / / this is valid here because the batch has been successfully emitted , \n - / / so we can safely delete metadata for prior transactions \n - _ emitter . cleanupBefore ( ( BigInteger ) input . getValue ( 2 ) ) ; \n",fix bug in TransactionalSpoutBatchExecutor where cleanup could happen before the new metadata is saved,356
"project . clj \n - ( defproject storm "" 0 . 8 . 1 - wip1 "" \n + ( defproject storm "" 0 . 8 . 1 - wip2 - SNAPSHOT "" \n src \ jvm \ storm \ trident \ state \ map \ CachedBatchReadsMap . java \n + _ cached . clear ( ) ; / / if a commit was pending and failed , we need to make sure to clear the cache \n",clear out read cache everytime a commit begins to handle the case where a commit fails and is retried,356
"src \ clj \ backtype \ storm \ ui \ core . clj \n - stats - seq ) ) } \n - ) ) ) \n + stats - seq ) ) \n + } ) ) ) \n + ( defn render - capacity [ capacity ] \n + [ : span ( if ( > capacity 0 . 9 ) \n + { : class "" red "" } \n + { } ) \n + ( float - str capacity ) ] ) \n + \n + ( defn compute - executor - capacity [ ^ ExecutorSummary e ] \n + ( let [ stats ( . get _ stats e ) \n + stats ( if stats \n + ( - > stats \n + ( aggregate - bolt - stats true ) \n + ( aggregate - bolt - streams ) \n + swap - map - order \n + ( get "" 600 "" ) ) ) \n + uptime ( nil - to - zero ( . get _ uptime _ secs e ) ) \n + window ( if ( < uptime 600 ) uptime 600 ) \n + executed ( - > stats : executed nil - to - zero ) \n + latency ( - > stats : execute - latencies nil - to - zero ) \n + ] \n + ( if ( > window 0 ) \n + ( div ( * executed latency ) ( * 1000 window ) ) \n + ) ) ) \n + \n + ( defn compute - bolt - capacity [ executors ] \n + ( - > > executors \n + ( map compute - executor - capacity ) \n + ( apply max ) ) ) \n + \n - [ "" Id "" "" Executors "" "" Tasks "" "" Emitted "" "" Transferred "" "" Execute latency ( ms ) "" "" Executed "" "" Process latency ( ms ) "" \n + [ "" Id "" "" Executors "" "" Tasks "" "" Emitted "" "" Transferred "" "" Capacity ( last 10m ) "" "" Execute latency ( ms ) "" "" Executed "" "" Process latency ( ms ) "" \n + ( render - capacity ( compute - bolt - capacity summs ) ) \n - [ "" Id "" "" Uptime "" "" Host "" "" Port "" "" Emitted "" "" Transferred "" \n + [ "" Id "" "" Uptime "" "" Host "" "" Port "" "" Emitted "" "" Transferred "" "" Capacity ( last 10m ) "" \n + ( render - capacity ( compute - executor - capacity e ) ) \n",Add bolt capacities to UI based on execute latency and executed,356
src \ clj \ backtype \ storm \ scheduler \ DefaultScheduler . clj \n - ( + ( count can - reassign - slots ) ( count alive - assigned ) ) ) \n + ( + ( count can - reassign - slots ) ( count available - slots ) ) ) \n,fix regression in DefaultScheduler where it wouldn ' t reassign squeezed topologies correctly,356
"src \ jvm \ backtype \ storm \ topology \ BasicBoltExecutor . java \n - if ( e instanceof ReportedFailedException ) { \n - _ collector . reportError ( e ) ; \n - } \n + LOG . warn ( "" Failed to process tuple "" , e ) ; \n","Revert "" basic bolts check for reportedfailedexception "" \n This reverts commit e8d886485923b0f7a5101e55ded48103751f55a0 .",356
src \ clj \ backtype \ storm \ ui \ core . clj \n - [ : span ( if ( > capacity 0 . 9 ) \n + [ : span ( if ( and capacity ( > capacity 0 . 9 ) ) \n,only render capacity if it ' s non - null,356
"src \ clj \ backtype \ storm \ ui \ core . clj \n - [ : span ( if ( and capacity ( > capacity 0 . 9 ) ) \n - { : class "" red "" } \n - { } ) \n - ( float - str capacity ) ] ) \n + ( let [ capacity ( nil - to - zero capacity ) ] \n + [ : span ( if ( > capacity 0 . 9 ) \n + { : class "" red "" } \n + { } ) \n + ( float - str capacity ) ] ) ) \n + ( map nil - to - zero ) \n",fix rendering of capacities while topology is starting up,356
"new file \n src \ jvm \ backtype \ storm \ task \ IMetricsContext . java \n + package backtype . storm . task ; \n + \n + \n + public interface IMetricsContext { \n + \n + } \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - public class TopologyContext extends WorkerTopologyContext { \n + public class TopologyContext extends WorkerTopologyContext implements IMetricsContext { \n src \ jvm \ storm \ trident \ planner \ SubtopologyBolt . java \n - State s = n . stateInfo . spec . stateFactory . makeState ( conf , context . getThisTaskIndex ( ) , thisComponentNumTasks ) ; \n + State s = n . stateInfo . spec . stateFactory . makeState ( conf , context , context . getThisTaskIndex ( ) , thisComponentNumTasks ) ; \n src \ jvm \ storm \ trident \ state \ StateFactory . java \n + import backtype . storm . task . IMetricsContext ; \n - State makeState ( Map conf , int partitionIndex , int numPartitions ) ; \n + State makeState ( Map conf , IMetricsContext metrics , int partitionIndex , int numPartitions ) ; \n src \ jvm \ storm \ trident \ testing \ LRUMemoryMapState . java \n + import backtype . storm . task . IMetricsContext ; \n - public State makeState ( Map conf , int partitionIndex , int numPartitions ) { \n + public State makeState ( Map conf , IMetricsContext metrics , int partitionIndex , int numPartitions ) { \n src \ jvm \ storm \ trident \ testing \ MemoryMapState . java \n + import backtype . storm . task . IMetricsContext ; \n - public State makeState ( Map conf , int partitionIndex , int numPartitions ) { \n + public State makeState ( Map conf , IMetricsContext metrics , int partitionIndex , int numPartitions ) { \n",add IMetricsContext so State ' s can keep metrics,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + reported - time ( cond reported - time reported - time \n + last - reported - time last - reported - time \n + : else 0 ) \n - ( if ( contains ? executor - beats executor ) \n - ( update - executor - cache curr ( executor - beats executor ) ) \n - curr \n - ) ] ) ) ) ) \n + ( update - executor - cache curr ( get executor - beats executor ) ) ] \n + ) ) ) ) \n + ( log - debug "" Updating heartbeats for "" storm - id "" "" ( pr - str all - executors ) ) \n + ( log - debug "" Computing alive executors for "" ( . getId topology - details ) "" \ n "" \n + "" Executors : "" ( pr - str all - executors ) "" \ n "" \n + "" Assignment : "" ( pr - str existing - assignment ) "" \ n "" \n + "" Heartbeat cache : "" ( pr - str ( @ ( : heartbeats - cache nimbus ) ( . getId topology - details ) ) ) \n + ) \n",fixed nimbus bug where nimbus would fail to check heartbeats for a topology,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + ( def DISALLOWED - TOPOLOGY - NAME - STRS # { "" / "" "" . "" "" : "" "" \ \ "" } ) \n + \n + ( defn validate - topology - name ! [ name ] \n + ( if ( some # ( . contains name % ) DISALLOWED - TOPOLOGY - NAME - STRS ) \n + ( throw ( InvalidTopologyException . \n + ( str "" Topology name cannot contain any of the following : "" ( pr - str DISALLOWED - TOPOLOGY - NAME - STRS ) ) ) ) ) ) \n + \n - ( if ( . contains storm - name "" / "" ) \n - ( throw ( InvalidTopologyException . "" Topology name cannot contains slashes "" ) ) ) \n + ( validate - topology - name ! storm - name ) \n",disallow a few more characters in topology names,356
src \ jvm \ backtype \ storm \ scheduler \ Cluster . java \n - SupervisorDetails supervisor = this . supervisors . get ( slot . getNodeId ( ) ) ; \n - \n - if ( supervisor ! = null ) { \n - / / remove the slot from the existing assignments \n - for ( SchedulerAssignmentImpl assignment : this . assignments . values ( ) ) { \n - if ( assignment . isSlotOccupied ( slot ) ) { \n - assignment . unassignBySlot ( slot ) ; \n - break ; \n - } \n + / / remove the slot from the existing assignments \n + for ( SchedulerAssignmentImpl assignment : this . assignments . values ( ) ) { \n + if ( assignment . isSlotOccupied ( slot ) ) { \n + assignment . unassignBySlot ( slot ) ; \n,always free slot whether or not that supervisor exists or not,356
"src \ jvm \ backtype \ storm \ spout \ ShellSpout . java \n - throw new RuntimeException ( "" Error when launching multilang subprocess "" , e ) ; \n + throw new RuntimeException ( "" Error when launching multilang subprocess \ n "" + _ process . getErrorsString ( ) , e ) ; \n src \ jvm \ backtype \ storm \ task \ ShellBolt . java \n - throw new RuntimeException ( "" Error when launching multilang subprocess "" , e ) ; \n + throw new RuntimeException ( "" Error when launching multilang subprocess \ n "" + _ process . getErrorsString ( ) , e ) ; \n src \ jvm \ backtype \ storm \ utils \ ShellProcess . java \n + public String getErrorsString ( ) { \n + if ( processErrorStream ! = null ) { \n + try { \n + return IOUtils . toString ( processErrorStream ) ; \n + } catch ( IOException e ) { \n + return "" ( Unable to capture error stream ) "" ; \n + } \n + } else { \n + return "" "" ; \n + } \n + } \n + \n - errorMessage . append ( IOUtils . toString ( processErrorStream ) + "" \ n "" ) ; \n + errorMessage . append ( getErrorsString ( ) + "" \ n "" ) ; \n",print error stream if subprocess fails to launch,356
"src \ clj \ backtype \ storm \ daemon \ worker . clj \n - needed - connections ( - > > my - assignment \n - ( filter - key ( complement ( - > worker : task - ids set ) ) ) \n - vals \n - set ) \n + needed - assignment ( - > > my - assignment \n + ( filter - key ( complement ( - > worker : task - ids set ) ) ) ) \n + needed - connections ( - > needed - assignment vals set ) \n + needed - tasks ( - > needed - assignment keys ) \n + \n - ) ) ) ) ) \n + \n + ( let [ missing - tasks ( - > > needed - tasks \n + ( filter ( complement my - assignment ) ) ) ] \n + ( when - not ( empty ? missing - tasks ) \n + ( log - warn "" Missing assignment for following tasks : "" ( pr - str missing - tasks ) ) \n + ) ) ) ) ) ) ) \n - ( let [ socket ( get node + port - > socket ( get task - > node + port task ) ) ] \n - ( msg / send socket task ser - tuple ) \n - ) ) ) ) \n + ( let [ node - port ( get task - > node + port task ) ] \n + ( when node - port \n + ( msg / send ( get node + port - > socket node - port ) task ser - tuple ) ) \n + ) ) ) ) \n","worker checks and warns for missing outbound connections from assignment , now drops messages for which doesn ' t have outbound connection",356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - [ nimbus topologies ] \n + [ nimbus topologies - missing - assignments topologies ] \n + topologies - missing - assignments \n + \n + missing - assignment - topologies ( - > > topologies \n + . getTopologies \n + ( map ( memfn getId ) ) \n + ( filter ( fn [ t ] \n + ( let [ alle ( get topology - > executors t ) \n + alivee ( get topology - > alive - executors t ) ] \n + ( or ( empty ? alle ) ( not = alle alivee ) ) \n + ) ) ) ) \n - ( available - slots nimbus ) \n + ( available - slots nimbus missing - assignment - topologies ) \n - ( availableSlots [ this supervisors used - slots topologies ] \n + ( availableSlots [ this supervisors used - slots topologies topologies - missing - assignments ] \n src \ jvm \ backtype \ storm \ scheduler \ INimbus . java \n - Collection < WorkerSlot > availableSlots ( Collection < SupervisorDetails > existingSupervisors , Collection < WorkerSlot > usedSlots , Topologies topologies ) ; \n + Collection < WorkerSlot > availableSlots ( Collection < SupervisorDetails > existingSupervisors , Collection < WorkerSlot > usedSlots , Topologies topologies , Collection < String > topologiesWithMissingAssignments ) ; \n",let inimbus know which topologies are missing assignments ( due to timeout or not being scheduled yet ),356
"src \ jvm \ backtype \ storm \ drpc \ DRPCSpout . java \n - try { \n - DRPCRequest req = drpc . fetchRequest ( _ function ) ; \n - if ( req . get _ request _ id ( ) . length ( ) > 0 ) { \n - Map returnInfo = new HashMap ( ) ; \n - returnInfo . put ( "" id "" , req . get _ request _ id ( ) ) ; \n - returnInfo . put ( "" host "" , _ local _ drpc _ id ) ; \n - returnInfo . put ( "" port "" , 0 ) ; \n - gotRequest = true ; \n - _ collector . emit ( new Values ( req . get _ func _ args ( ) , JSONValue . toJSONString ( returnInfo ) ) , new DRPCMessageId ( req . get _ request _ id ( ) , 0 ) ) ; \n + if ( drpc ! = null ) { / / can happen during shutdown of drpc while topology is still up \n + try { \n + DRPCRequest req = drpc . fetchRequest ( _ function ) ; \n + if ( req . get _ request _ id ( ) . length ( ) > 0 ) { \n + Map returnInfo = new HashMap ( ) ; \n + returnInfo . put ( "" id "" , req . get _ request _ id ( ) ) ; \n + returnInfo . put ( "" host "" , _ local _ drpc _ id ) ; \n + returnInfo . put ( "" port "" , 0 ) ; \n + gotRequest = true ; \n + _ collector . emit ( new Values ( req . get _ func _ args ( ) , JSONValue . toJSONString ( returnInfo ) ) , new DRPCMessageId ( req . get _ request _ id ( ) , 0 ) ) ; \n + } \n + } catch ( TException e ) { \n + throw new RuntimeException ( e ) ; \n - } catch ( TException e ) { \n - throw new RuntimeException ( e ) ; \n",make drpcspout check that local mode drpc is still alive,356
"project . clj \n - [ storm / carbonite "" 1 . 4 . 0 "" ] \n + [ storm / carbonite "" 1 . 5 . 0 "" ] \n","upgrade to kryo 2 . 17 , hopefully fixing linkageerror bug",356
"src \ clj \ backtype \ storm \ util . clj \n - ( log - message "" Error when trying to extract "" dir "" from "" jarpath ) ) \n + ( log - message "" Could not extract "" dir "" from "" jarpath ) ) \n",change language for info message when multilang dir is not in jar,356
"src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n - "" Returns map from port to struct containing : storm - id and : executors and : master - code - dir "" \n + "" Returns map from port to struct containing : storm - id and : executors "" \n + ( defn assigned - storm - ids - from - port - assignments [ assignment ] \n + ( - > > assignment \n + vals \n + ( map : storm - id ) \n + set ) ) \n + \n - assigned - storm - ids ( set ( keys storm - code - map ) ) \n + assigned - storm - ids ( assigned - storm - ids - from - port - assignments new - assignment ) \n - ( when - not ( downloaded - storm - ids storm - id ) \n + ( when ( and ( not ( downloaded - storm - ids storm - id ) ) \n + ( assigned - storm - ids storm - id ) ) \n",supervisors only download code for topologies assigned to them,356
src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - : remove ) ) \n + : remove ) \n + nil ) \n - : do - rebalance ) ) \n + : do - rebalance ) \n + nil ) \n,fix bug where a topology ' s status would get corrupted to true if nimbus is restarted while status is rebalancing or killed,356
"src \ jvm \ backtype \ storm \ transactional \ TransactionalSpoutCoordinator . java \n - / / TODO : need a way to override max spout pending with max batch pending conf \n - return _ spout . getComponentConfiguration ( ) ; \n + Map < String , Object > ret = new HashMap < String , Object > ( _ spout . getComponentConfiguration ( ) ) ; \n + if ( ! ret . containsKey ( Config . TOPOLOGY _ MAX _ SPOUT _ PENDING ) ) { \n + ret . put ( Config . TOPOLOGY _ MAX _ SPOUT _ PENDING , 1 ) ; \n + } \n + return ret ; \n",default transactionalspout to only do one transaction at a time,356
conf \ defaults . yaml \n - 6703 \n - supervisor . worker . start . timeout . secs : 240 \n + supervisor . worker . start . timeout . secs : 120 \n,lower supervisor worker start timeout to 120 seconds,356
"src \ jvm \ backtype \ storm \ utils \ ShellProcess . java \n - throw new RuntimeException ( "" Pipe to subprocess seems to be broken ! "" ) ; \n + throw new RuntimeException ( "" Pipe to subprocess seems to be broken ! Currently read output : "" + line . toString ( ) ) ; \n",include as much of currently read output as possible when pipe to subprocess is broken,356
"src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - import backtype . storm . Config ; \n - import backtype . storm . generated . ComponentCommon ; \n - import backtype . storm . generated . StreamInfo ; \n - import backtype . storm . utils . ThriftTopologyUtils ; \n + import java . io . File ; \n + import java . io . IOException ; \n - import java . util . HashMap ; \n - import org . json . simple . JSONValue ; \n - _ pidDir = pidDir ; \n + try { \n + _ pidDir = new File ( pidDir ) . getCanonicalPath ( ) ; \n + } catch ( IOException e ) { \n + throw new RuntimeException ( "" Could not get canonical path for "" + _ pidDir , e ) ; \n + } \n",give absolute piddir to subprocesses ( so that relative paths can be used for storm local dir ),356
src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - _ pidDir = new File ( pidDir ) . getCanonicalPath ( ) ; \n + if ( pidDir ! = null ) { \n + _ pidDir = new File ( pidDir ) . getCanonicalPath ( ) ; \n + } else { \n + _ pidDir = null ; \n + } \n,allow piddir to be null in topologycontext for testing,356
"src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( log - message "" Failing message "" msg - id "" : "" tuple - info ) \n + ( log - debug "" Failing message "" msg - id "" : "" tuple - info ) \n",change log level of failed messages to DEBUG,356
"new file \n src \ jvm \ storm \ trident \ testing \ StringLength . java \n + package storm . trident . testing ; \n + \n + import backtype . storm . tuple . Values ; \n + import storm . trident . operation . BaseFunction ; \n + import storm . trident . operation . TridentCollector ; \n + import storm . trident . tuple . TridentTuple ; \n + \n + public class StringLength extends BaseFunction { \n + \n + @ Override \n + public void execute ( TridentTuple tuple , TridentCollector collector ) { \n + collector . emit ( new Values ( tuple . getString ( 0 ) . length ( ) ) ) ; \n + } \n + \n + } \n src \ jvm \ storm \ trident \ tuple \ TridentTupleView . java \n - _ fieldIndex = parent . getFieldIndex ( ) ; \n + _ fieldIndex = new HashMap ( parent . getFieldIndex ( ) ) ; \n test \ clj \ storm \ trident \ integration _ test . clj \n - ( : import [ storm . trident . testing Split CountAsAggregator ] ) \n + ( : import [ storm . trident . testing Split CountAsAggregator StringLength ] ) \n + ) ) ) ) ) \n + \n + ( deftest test - split - merge \n + ( t / with - local - cluster [ cluster ] \n + ( with - drpc [ drpc ] \n + ( letlocals \n + ( bind topo ( TridentTopology . ) ) \n + ( bind drpc - stream ( - > topo ( . newDRPCStream "" splitter "" drpc ) ) ) \n + ( bind s1 \n + ( - > drpc - stream \n + ( . each ( fields "" args "" ) ( Split . ) ( fields "" word "" ) ) \n + ( . project ( fields "" word "" ) ) ) ) \n + ( bind s2 \n + ( - > drpc - stream \n + ( . each ( fields "" args "" ) ( StringLength . ) ( fields "" len "" ) ) \n + ( . project ( fields "" len "" ) ) ) ) \n + \n + ( . merge topo [ s1 s2 ] ) \n + ( with - topology [ cluster topo ] \n + ( is ( t / ms = [ [ 7 ] [ "" the "" ] [ "" man "" ] ] ( exec - drpc drpc "" splitter "" "" the man "" ) ) ) \n + ( is ( t / ms = [ [ 5 ] [ "" hello "" ] ] ( exec - drpc drpc "" splitter "" "" hello "" ) ) ) \n","fix bug that would occur when splitting a stream in certain situations , added test for it",356
src \ jvm \ storm \ trident \ partition \ IndexHashGrouping . java \n - else return val . hashCode ( ) % numPartitions ; \n + else return Math . abs ( val . hashCode ( ) ) % numPartitions ; \n,ensure that IndexHashGrouping ( partitioning used for batch global ) always produces positive task index,356
"src \ jvm \ storm \ trident \ partition \ IndexHashGrouping . java \n - else return Math . abs ( val . hashCode ( ) ) % numPartitions ; \n + else { \n + return Math . abs ( val . hashCode ( ) ) % numPartitions ; \n + } \n test \ clj \ storm \ trident \ integration _ test . clj \n + ( . parallelismHint 2 ) ; ; this makes sure batchGlobal is working correctly \n - ( is ( = [ [ 1 ] ] ( exec - drpc drpc "" numwords "" "" the "" ) ) ) \n + ( doseq [ i ( range 100 ) ] \n + ( is ( = [ [ 1 ] ] ( exec - drpc drpc "" numwords "" "" the "" ) ) ) ) \n",enhance tests to catch the batch global problem,356
"project . clj \n - ( defproject storm "" 0 . 8 . 1 - wip5 "" \n + ( defproject storm "" 0 . 8 . 1 - wip6 "" \n src \ jvm \ storm \ trident \ planner \ SubtopologyBolt . java \n + boolean outgoingNode = false ; \n - targets . add ( new BridgeReceiver ( batchCollector ) ) ; \n + outgoingNode = true ; \n + if ( outgoingNode ) { \n + targets . add ( new BridgeReceiver ( batchCollector ) ) ; \n + } \n new file \n src \ jvm \ storm \ trident \ testing \ TrueFilter . java \n + package storm . trident . testing ; \n + \n + import storm . trident . operation . BaseFilter ; \n + import storm . trident . tuple . TridentTuple ; \n + \n + public class TrueFilter extends BaseFilter { \n + \n + @ Override \n + public boolean isKeep ( TridentTuple tuple ) { \n + return true ; \n + } \n + \n + } \n test \ clj \ storm \ trident \ integration _ test . clj \n - ( : import [ storm . trident . testing Split CountAsAggregator StringLength ] ) \n + ( : import [ storm . trident . testing Split CountAsAggregator StringLength TrueFilter ] ) \n + ( deftest test - multiple - groupings - same - stream \n + ( t / with - local - cluster [ cluster ] \n + ( with - drpc [ drpc ] \n + ( letlocals \n + ( bind topo ( TridentTopology . ) ) \n + ( bind drpc - stream ( - > topo ( . newDRPCStream "" tester "" drpc ) \n + ( . each ( fields "" args "" ) ( TrueFilter . ) ) ) ) \n + ( bind s1 \n + ( - > drpc - stream \n + ( . groupBy ( fields "" args "" ) ) \n + ( . aggregate ( CountAsAggregator . ) ( fields "" count "" ) ) ) ) \n + ( bind s2 \n + ( - > drpc - stream \n + ( . groupBy ( fields "" args "" ) ) \n + ( . aggregate ( CountAsAggregator . ) ( fields "" count "" ) ) ) ) \n + \n + ( . merge topo [ s1 s2 ] ) \n + ( with - topology [ cluster topo ] \n + ( is ( t / ms = [ [ "" the "" 1 ] [ "" the "" 1 ] ] ( exec - drpc drpc "" tester "" "" the "" ) ) ) \n + ( is ( t / ms = [ [ "" aaaaa "" 1 ] [ "" aaaaa "" 1 ] ] ( exec - drpc drpc "" tester "" "" aaaaa "" ) ) ) \n + ) ) ) ) ) \n",fix bug where having multiple groupings on the same stream would duplicate tuples,356
"project . clj \n - ( defproject storm "" 0 . 8 . 1 - wip6 "" \n + ( defproject storm "" 0 . 8 . 1 - wip7 "" \n src \ jvm \ storm \ trident \ Stream . java \n + import storm . trident . operation . impl . TrueFilter ; \n - return _ topology . addSourcedNode ( this , new PartitionNode ( _ node . streamId , getOutputFields ( ) , grouping ) ) ; \n + if ( _ node instanceof PartitionNode ) { \n + return each ( new Fields ( ) , new TrueFilter ( ) ) . partition ( grouping ) ; \n + } else { \n + return _ topology . addSourcedNode ( this , new PartitionNode ( _ node . streamId , getOutputFields ( ) , grouping ) ) ; \n + } \n test \ clj \ storm \ trident \ integration _ test . clj \n + \n + ( deftest test - multi - repartition \n + ( t / with - local - cluster [ cluster ] \n + ( with - drpc [ drpc ] \n + ( letlocals \n + ( bind topo ( TridentTopology . ) ) \n + ( bind drpc - stream ( - > topo ( . newDRPCStream "" tester "" drpc ) \n + ( . each ( fields "" args "" ) ( Split . ) ( fields "" word "" ) ) \n + ( . shuffle ) \n + ( . shuffle ) \n + ( . aggregate ( CountAsAggregator . ) ( fields "" count "" ) ) \n + ) ) \n + ( with - topology [ cluster topo ] \n + ( is ( t / ms = [ [ 2 ] ] ( exec - drpc drpc "" tester "" "" the man "" ) ) ) \n + ( is ( t / ms = [ [ 1 ] ] ( exec - drpc drpc "" tester "" "" aaa "" ) ) ) \n + ) ) ) ) ) \n","Fix # 306 , repartitioning twice in a row bug",356
"src \ clj \ backtype \ storm \ util . clj \n - ( let [ deleted ? ( . delete ( File . path ) ) ] \n - ( when - not deleted ? \n - ( throw ( RuntimeException . ( str "" Failed to delete "" path ) ) ) ) \n - ) ) \n + ( when ( exists - file ? path ) \n + ( let [ deleted ? ( . delete ( File . path ) ) ] \n + ( when - not deleted ? \n + ( throw ( RuntimeException . ( str "" Failed to delete "" path ) ) ) ) \n + ) ) ) \n",fix rare bug in supervisor where it would continuously fail to clean up workers because the worker was already partially cleaned up,356
"src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n - ( read - json ( . get _ json _ conf common ) ) ) \n + ( from - json ( . get _ json _ conf common ) ) ) \n - base - sers ( if sers sers ( conf TOPOLOGY - KRYO - REGISTER ) ) \n + base - sers ( if base - sers base - sers ( conf TOPOLOGY - KRYO - REGISTER ) ) \n - # ( - > % \n - ThriftTopologyUtils / getComponentCommon \n + # ( - > ( ThriftTopologyUtils / getComponentCommon topology % ) \n - ( mapify - serializations sers ) ) \n + ( mapify - serializations base - sers ) ) \n src \ clj \ backtype \ storm \ thrift . clj \n - ret ( ComponentCommon . ( HashMap . inputs ) ( HashMap . ( . getFieldsDeclaration getter ) ) ) ] \n + ret ( ComponentCommon . ( HashMap . inputs ) ( HashMap . ( . getFieldsDeclaration getter ) ) ) \n + component - conf ( . getComponentConfiguration component ) ] \n + ( when component - conf \n + ( . set _ json _ conf ret ( to - json component - conf ) ) ) \n test \ clj \ backtype \ storm \ nimbus _ test . clj \n - ( is ( = 1 ( count ( task - info "" 3 "" ) ) ) ) \n + ( is ( = 8 ( count ( task - info "" 3 "" ) ) ) ) \n","implemented component configurations for clojure topology builder , fixed nimbus tests",356
"src \ clj \ backtype \ storm \ daemon \ task . clj \n - ( merge storm - conf ( apply disj spec - conf to - remove ) ) \n + ( merge storm - conf ( apply dissoc spec - conf to - remove ) ) \n src \ jvm \ backtype \ storm \ topology \ TopologyBuilder . java \n - common . set _ parallelism _ hint ( parallelism ) ; \n + common . set _ inputs ( new HashMap < GlobalStreamId , Grouping > ( ) ) ; \n + if ( parallelism ! = null ) common . set _ parallelism _ hint ( parallelism ) ; \n - common . set _ json _ conf ( JSONValue . toJSONString ( conf ) ) ; \n + if ( conf ! = null ) common . set _ json _ conf ( JSONValue . toJSONString ( conf ) ) ; \n","fixed typos , tests passing with component specific configuration , need more tests for component specific configuration",356
"src \ jvm \ backtype \ storm \ topology \ ComponentConfigurationDeclarer . java \n + T setDebug ( boolean debug ) ; \n + T setMaxTaskParallelism ( Integer val ) ; \n + T setMaxSpoutPending ( Integer val ) ; \n src \ jvm \ backtype \ storm \ topology \ TopologyBuilder . java \n - } \n + } \n + \n + @ Override \n + public T setDebug ( boolean debug ) { \n + return addConfiguration ( Config . TOPOLOGY _ DEBUG , debug ) ; \n + } \n + \n + @ Override \n + public T setMaxTaskParallelism ( Integer val ) { \n + return addConfiguration ( Config . TOPOLOGY _ MAX _ TASK _ PARALLELISM , val ) ; \n + } \n + \n + @ Override \n + public T setMaxSpoutPending ( Integer val ) { \n + return addConfiguration ( Config . TOPOLOGY _ MAX _ SPOUT _ PENDING , val ) ; \n + } \n",add sugar to fluent API for component configurations,356
"CHANGELOG . md \n + * Removed parameter from TopologyContext # maxTopologyMessageTimeout ( simplification ) . \n + * Storm now automatically sets TOPOLOGY _ NAME in the config passed to the bolts and spouts to the name of the topology . \n src \ clj \ backtype \ storm \ daemon \ acker . clj \n - ( reset ! pending ( TimeCacheMap . ( . maxTopologyMessageTimeout context storm - conf ) ) ) \n + ( reset ! pending ( TimeCacheMap . ( . maxTopologyMessageTimeout context ) ) ) \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n + storm - conf \n + storm - conf \n src \ clj \ backtype \ storm \ testing . clj \n - context ( TopologyContext . topology { 1 component } "" test - storm - id "" nil nil 1 ) ] \n + context ( TopologyContext . topology ( read - storm - config ) { 1 component } "" test - storm - id "" nil nil 1 ) ] \n src \ jvm \ backtype \ storm \ coordination \ CoordinatedBolt . java \n - _ tracked = new TimeCacheMap < Object , TrackingInfo > ( context . maxTopologyMessageTimeout ( config ) , callback ) ; \n + _ tracked = new TimeCacheMap < Object , TrackingInfo > ( context . maxTopologyMessageTimeout ( ) , callback ) ; \n src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n + private Map _ stormConf ; \n - public TopologyContext ( StormTopology topology , Map < Integer , String > taskToComponent , String stormId , String codeDir , String pidDir , Integer taskId ) { \n + public TopologyContext ( StormTopology topology , Map stormConf , Map < Integer , String > taskToComponent , String stormId , String codeDir , String pidDir , Integer taskId ) { \n + _ stormConf = stormConf ; \n - public int maxTopologyMessageTimeout ( Map < String , Object > topologyConfig ) { \n - Integer max = Utils . getInt ( topologyConfig . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ) ; \n + public int maxTopologyMessageTimeout ( ) { \n + Integer max = Utils . getInt ( _ stormConf . get ( Config . TOPOLOGY _ MESSAGE _ TIMEOUT _ SECS ) ) ; \n test \ clj \ backtype \ storm \ integration _ test . clj \n - val ( if ( = name "" ! MAX _ MSG _ TIMEOUT "" ) ( . maxTopologyMessageTimeout context conf ) ( get conf name ) ) ] \n + val ( if ( = name "" ! MAX _ MSG _ TIMEOUT "" ) ( . maxTopologyMessageTimeout context ) ( get conf name ) ) ] \n",simplify topology context by parameterizing it with topology conf,356
"src \ clj \ backtype \ storm \ ui \ core . clj \n - ( defn ui - template [ body include - sys ? ] \n + ( defn mk - system - toggle - button [ include - sys ? ] \n + [ : p [ : input { : type "" button "" \n + : value ( str ( if include - sys ? "" Hide "" "" Show "" ) "" System Stats "" ) \n + : onclick "" toggleSys ( ) "" } ] ] ) \n + \n + ( defn ui - template [ body ] \n - [ : p [ : input { : type "" button "" \n - : value ( str ( if include - sys ? "" Hide "" "" Show "" ) "" System Stats "" ) \n - : onclick "" toggleSys ( ) "" } ] ] \n - ( ui - template ( get - include - sys ? cookies ) ) ) ) \n + ui - template ) ) \n - ( ui - template include - sys ? ) ) ) ) \n + ( concat [ ( mk - system - toggle - button include - sys ? ) ] ) \n + ui - template ) ) ) \n - ( ui - template include - sys ? ) ) ) ) \n + ( concat [ ( mk - system - toggle - button include - sys ? ) ] ) \n + ui - template ) ) ) \n - ( ui - template ( get - include - sys ? cookies ) ) ) ) \n + ui - template ) ) \n",move toggle system stats button to bottom of page and only show on topology and component pages,356
rename from src \ clj \ backtype \ storm \ daemon \ task . clj \n rename to src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( ns backtype . storm . daemon . task \n + ( ns backtype . storm . daemon . executor \n - ( defn mk - task [ worker ^ TopologyContext topology - context ^ TopologyContext user - context ] \n + ( defn mk - executor [ worker ^ TopologyContext topology - context ^ TopologyContext user - context ] \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n - ( : require [ backtype . storm . daemon [ task : as task ] ] ) \n + ( : require [ backtype . storm . daemon [ executor : as executor ] ] ) \n - tasks ( dofor [ tid ( : task - ids worker ) ] ( task / mk - task worker ( system - topology - context worker tid ) ( user - topology - context worker tid ) ) ) \n + tasks ( dofor [ tid ( : task - ids worker ) ] ( executor / mk - executor worker ( system - topology - context worker tid ) ( user - topology - context worker tid ) ) ) \n src \ clj \ backtype \ storm \ testing . clj \n - [ task : as task ] ] ) \n + [ executor : as executor ] ] ) \n,rename task . clj to executor . clj,356
src \ clj \ backtype \ storm \ daemon \ common . clj \n - ( defn component - conf [ storm - conf component ] \n + ( defn component - conf [ component ] \n - from - json \n - ( merge storm - conf ) ) ) \n + from - json ) ) \n - ( defn - component - parallelism [ storm - conf component ] \n - ( let [ storm - conf ( component - conf storm - conf component ) \n - num - tasks ( or ( storm - conf TOPOLOGY - TASKS ) ( num - start - executors component ) ) \n - max - parallelism ( storm - conf TOPOLOGY - MAX - TASK - PARALLELISM ) \n - ] \n - ( if max - parallelism \n - ( min max - parallelism num - tasks ) \n - num - tasks ) ) ) \n - \n - ( map - val ( partial component - parallelism storm - conf ) ) \n + ( map - val ( comp # ( get % TOPOLOGY - TASKS ) component - conf ) ) \n src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + ( defn - component - parallelism [ storm - conf component ] \n + ( let [ storm - conf ( merge storm - conf ( component - conf component ) ) \n + num - tasks ( or ( storm - conf TOPOLOGY - TASKS ) ( num - start - executors component ) ) \n + max - parallelism ( storm - conf TOPOLOGY - MAX - TASK - PARALLELISM ) \n + ] \n + ( if max - parallelism \n + ( min max - parallelism num - tasks ) \n + num - tasks ) ) ) \n + \n + ( defn normalize - topology [ storm - conf ^ StormTopology topology ] \n + ( let [ ret ( . deepCopy topology ) ] \n + ( doseq [ [ _ component ] ( all - components ret ) ] \n + ( . set _ json _ conf \n + ( . get _ common component ) \n + ( - > > { TOPOLOGY - TASKS ( component - parallelism storm - conf component ) } \n + ( merge ( component - conf component ) ) \n + to - json ) ) ) \n + ret ) ) \n + \n - TOPOLOGY - ACKER - TASKS ( total - conf TOPOLOGY - ACKER - TASKS ) \n + TOPOLOGY - ACKER - TASKS ( or ( total - conf TOPOLOGY - ACKER - TASKS ) ( total - conf TOPOLOGY - ACKER - EXECUTORS ) ) \n + topology ( normalize - topology total - storm - conf topology ) \n,normalize topology to ensure # tasks is always the same,356
src \ clj \ backtype \ storm \ daemon \ supervisor . clj \n + ( . assigned isupervisor ( keys new - assignment ) ) \n + ) \n + ( assigned [ this ports ] \n src \ jvm \ backtype \ storm \ scheduler \ ISupervisor . java \n + import java . util . Collection ; \n + void assigned ( Collection < Integer > ports ) ; \n,added assigned method to isupervisor so it knows exactly what ' s running and not running,356
"src \ clj \ backtype \ storm \ disruptor . clj \n - ; ; NOTE : can ' t use : block strategy , as sometimes the consumer stays blocked even when there ' s an item on the queue . \n + ; ; : block strategy requires using a timeout on waitFor ( implemented in DisruptorQueue ) , as sometimes the consumer stays blocked even when there ' s an item on the queue . \n - ( defnk disruptor - queue [ buffer - size : claim - strategy : multi - threaded : wait - strategy : sleep ] \n + ( defnk disruptor - queue [ buffer - size : claim - strategy : multi - threaded : wait - strategy : block ] \n src \ jvm \ backtype \ storm \ utils \ DisruptorQueue . java \n + import java . util . concurrent . TimeUnit ; \n - final long availableSequence = _ barrier . waitFor ( nextSequence ) ; \n - consumeBatchToCursor ( availableSequence , handler ) ; \n + final long availableSequence = _ barrier . waitFor ( nextSequence , 10 , TimeUnit . MILLISECONDS ) ; \n + if ( availableSequence > = nextSequence ) { \n + consumeBatchToCursor ( availableSequence , handler ) ; \n + } \n",use timeout when calling waitFor to prevent race condition in blockingwaitstrategy,356
"CHANGELOG . md \n + * Add ability to plug in custom code into Nimbus to allow / disallow topologies to be submitted via NIMBUS _ TOPOLOGY _ VALIDATOR config \n conf \ defaults . yaml \n + nimbus . topology . validator : "" backtype . storm . nimbus . DefaultTopologyValidator "" \n project . clj \n - ( defproject storm "" 0 . 8 . 2 - wip2 "" \n + ( defproject storm "" 0 . 8 . 2 - wip3 "" \n src \ clj \ backtype \ storm \ daemon \ nimbus . clj \n + : validator ( new - instance ( conf NIMBUS - TOPOLOGY - VALIDATOR ) ) \n + ( . validate ^ backtype . storm . nimbus . ITopologyValidator ( : validator nimbus ) \n + storm - name \n + ( from - json serializedConf ) \n + topology ) \n src \ jvm \ backtype \ storm \ Config . java \n + / * * \n + * A custom class that implements ITopologyValidator that is run whenever a \n + * topology is submitted . Can be used to provide business - specific logic for \n + * whether topologies are allowed to run or not . \n + * / \n + public static String NIMBUS _ TOPOLOGY _ VALIDATOR = "" nimbus . topology . validator "" ; \n + \n + \n new file \n src \ jvm \ backtype \ storm \ nimbus \ DefaultTopologyValidator . java \n + package backtype . storm . nimbus ; \n + \n + import backtype . storm . generated . InvalidTopologyException ; \n + import backtype . storm . generated . StormTopology ; \n + import java . util . Map ; \n + \n + public class DefaultTopologyValidator implements ITopologyValidator { \n + @ Override \n + public void validate ( String topologyName , Map topologyConf , StormTopology topology ) throws InvalidTopologyException { \n + } \n + } \n new file \n src \ jvm \ backtype \ storm \ nimbus \ ITopologyValidator . java \n + package backtype . storm . nimbus ; \n + \n + import backtype . storm . generated . InvalidTopologyException ; \n + import backtype . storm . generated . StormTopology ; \n + import java . util . Map ; \n + \n + public interface ITopologyValidator { \n + void validate ( String topologyName , Map topologyConf , StormTopology topology ) \n + throws InvalidTopologyException ; \n + } \n","added ability to set business - specific topology validators , bumped to 0 . 8 . 2 - wip3",356
"test \ clj \ backtype \ storm \ integration _ test . clj \n + ( defbolt conf - query - bolt [ "" conf "" "" val "" ] { : prepare true : params [ conf ] : conf conf } \n + [ conf context collector ] \n + ( bolt \n + ( execute [ tuple ] \n + ( let [ name ( . getValue tuple 0 ) ] \n + ( emit - bolt ! collector [ name ( get conf name ) ] : anchor tuple ) ) \n + ) ) ) \n + \n + ( deftest test - component - specific - config - clojure \n + ( with - simulated - time - local - cluster [ cluster ] \n + ( let [ topology ( topology { "" 1 "" ( spout - spec ( TestPlannerSpout . ( Fields . [ "" conf "" ] ) ) ) \n + } \n + { "" 2 "" ( bolt - spec { "" 1 "" : shuffle } \n + ( conf - query - bolt { "" fake . config "" 1 \n + TOPOLOGY - MAX - TASK - PARALLELISM 2 \n + TOPOLOGY - MAX - SPOUT - PENDING 10 } ) \n + : conf { TOPOLOGY - MAX - SPOUT - PENDING 3 } ) \n + } ) \n + results ( complete - topology cluster \n + topology \n + : storm - conf { TOPOLOGY - MAX - TASK - PARALLELISM 10 } \n + : mock - sources { "" 1 "" [ [ "" fake . config "" ] \n + [ TOPOLOGY - MAX - TASK - PARALLELISM ] \n + [ TOPOLOGY - MAX - SPOUT - PENDING ] \n + ] } ) ] \n + ( is ( = { "" fake . config "" 1 \n + TOPOLOGY - MAX - TASK - PARALLELISM 2 \n + TOPOLOGY - MAX - SPOUT - PENDING 3 } \n + ( - > > ( read - tuples results "" 2 "" ) \n + ( apply concat ) \n + ( apply hash - map ) ) \n + ) ) ) ) ) \n + \n",added test that component specific configs in clojure dsl work correctly,356
"src \ jvm \ storm \ trident \ operation \ builtin \ TupleCollectionGet . java \n - import backtype . storm . state . ITupleCollection ; \n + import storm . trident . state . ITupleCollection ; \n - public class TupleCollectionGet extends BaseQueryFunction < State , Object > { \n + public class TupleCollectionGet extends BaseQueryFunction < State , Iterator < List < Object > > > { \n - public List < Object > batchRetrieve ( State state , List < TridentTuple > args ) { \n - List < Object > ret = new ArrayList < Object > ( args . size ( ) ) ; \n + public List < Iterator < List < Object > > > batchRetrieve ( State state , List < TridentTuple > args ) { \n + List < Iterator < List < Object > > > ret = new ArrayList ( args . size ( ) ) ; \n - public void execute ( TridentTuple tuple , Object result , TridentCollector collector ) { \n - Iterator < List < Object > > tuplesIterator = ( Iterator < List < Object > > ) result ; \n + public void execute ( TridentTuple tuple , Iterator < List < Object > > tuplesIterator , TridentCollector collector ) { \n rename from src \ jvm \ backtype \ storm \ state \ ITupleCollection . java \n rename to src \ jvm \ storm \ trident \ state \ ITupleCollection . java \n - package backtype . storm . state ; \n + package storm . trident . state ; \n src \ jvm \ storm \ trident \ testing \ LRUMemoryMapState . java \n - import backtype . storm . state . ITupleCollection ; \n + import storm . trident . state . ITupleCollection ; \n src \ jvm \ storm \ trident \ testing \ MemoryMapState . java \n - import backtype . storm . state . ITupleCollection ; \n + import storm . trident . state . ITupleCollection ; \n","move ITupleCollection to right package , fix type parameter to TupleCollectionGet",356
"CHANGELOG . md \n + * Can now submit a topology in inactive state . Storm will wait to call open / prepare on the spouts / bolts until it is first activated . \n src \ clj \ backtype \ storm \ daemon \ executor . clj \n - ( doseq [ obj ( map : object ( vals task - datas ) ) ] \n - ( close - component executor - data obj ) ) \n + ( when @ ( : open - or - prepare - was - called ? executor - data ) \n + ( doseq [ obj ( map : object ( vals task - datas ) ) ] \n + ( close - component executor - data obj ) ) ) \n - ( when @ ( : open - or - prepare - was - called ? executor - data ) \n - ( . close spout ) ) ) \n + ( . close spout ) ) \n - ( when @ ( : open - or - prepare - was - called ? executor - data ) \n - ( . cleanup bolt ) ) ) \n + ( . cleanup bolt ) ) \n src \ jvm \ backtype \ storm \ StormSubmitter . java \n + submitTopology ( name , stormConf , topology , new SubmitOptions ( TopologyInitialStatus . ACTIVE ) ) ; \n + } \n + \n + / * * \n + * Submits a topology to run on the cluster . A topology runs forever or until \n + * explicitly killed . \n + * \n + * \n + * @ param name the name of the storm . \n + * @ param stormConf the topology - specific configuration . See { @ link Config } . \n + * @ param topology the processing to execute . \n + * @ param options to manipulate the starting of the topology \n + * @ throws AlreadyAliveException if a topology with this name is already running \n + * @ throws InvalidTopologyException if an invalid topology was submitted \n + * / \n + public static void submitTopology ( String name , Map stormConf , StormTopology topology , SubmitOptions opts ) throws AlreadyAliveException , InvalidTopologyException { \n - client . getClient ( ) . submitTopology ( name , submittedJar , serConf , topology ) ; \n + client . getClient ( ) . submitTopologyWithOpts ( name , submittedJar , serConf , topology , opts ) ; \n","simplified getComponent , added StormSubmitter method for submitting in inactive state , and updated changelog",356
src \ clj \ backtype \ storm \ messaging \ zmq . clj \n + ( def NOBLOCK - SNDMORE ( bit - or ZMQ / SNDMORE ZMQ / NOBLOCK ) ) \n + \n - ( mq / send socket ( . array bb ) ZMQ / SNDMORE ) \n - ( mq / send socket message ) ) ; ; TODO : temporarily remove the noblock flag \n + ( mq / send socket ( . array bb ) NOBLOCK - SNDMORE ) \n + ( mq / send socket message ZMQ / NOBLOCK ) ) ; ; TODO : how to do backpressure if doing noblock ? . . . need to only unblock if the target disappears \n,use ZMQ / NOBLOCK when sending messages . this fixes # 420,356
conf \ defaults . yaml \n - zmq . hwm : 10000 \n + zmq . hwm : 0 \n,default to hwm of 0 due to problems with zmq,356
"bin \ storm \n + global CONFFILE \n - "" java "" , "" - client "" , get _ config _ opts ( ) , "" - cp "" , get _ classpath ( extrapaths ) , "" backtype . storm . command . config _ value "" , name \n + "" java "" , "" - client "" , get _ config _ opts ( ) , "" - Dstorm . conf . file = "" + CONFFILE , "" - cp "" , get _ classpath ( extrapaths ) , "" backtype . storm . command . config _ value "" , name \n",make - - config work for localconfvalue and remoteconfvalue,356
src \ clj \ backtype \ storm \ scheduler \ DefaultScheduler . clj \n + ( defn slots - can - reassign [ ^ Cluster cluster slots ] \n + ( - > > slots \n + ( filter \n + ( fn [ [ node port ] ] \n + ( if - let [ supervisor ( . getSupervisorById cluster node ) ] \n + ( . contains ( . getAllPorts supervisor ) ( int port ) ) \n + ) ) ) ) ) \n + can - reassign - slots ( slots - can - reassign cluster ( keys alive - assigned ) ) \n - ( + ( count available - slots ) ( count alive - assigned ) ) ) \n - bad - slots ( bad - slots alive - assigned ( count all - executors ) total - slots - to - use ) ] ] \n + ( + ( count can - reassign - slots ) ( count alive - assigned ) ) ) \n + bad - slots ( if ( > total - slots - to - use ( count alive - assigned ) ) \n + ( bad - slots alive - assigned ( count all - executors ) total - slots - to - use ) \n + [ ] ) ] ] \n - ( EvenScheduler / schedule - topologies - evenly topologies cluster ) ) ) ) \n + ( EvenScheduler / schedule - topologies - evenly ( Topologies . { topology - id topology } ) cluster ) ) ) ) \n src \ jvm \ backtype \ storm \ scheduler \ SupervisorDetails . java \n - import java . util . ArrayList ; \n + import java . util . HashSet ; \n + import java . util . Set ; \n - Collection < Integer > allPorts ; \n + Set < Integer > allPorts ; \n + allPorts = new HashSet ( ) ; \n - this . allPorts = new ArrayList < Integer > ( ) ; \n + this . allPorts = new HashSet < Integer > ( ) ; \n + \n + public Set < Integer > getAllPorts ( ) { \n + return allPorts ; \n + } \n,"fix default scheduler to schedule and check available slots one topology at a time , also fix it to check to see how many unassigned slots will become available slots",356
"new file \n src \ jvm \ backtype \ storm \ topology \ ReportedFailedException . java \n + package backtype . storm . topology ; \n + \n + public class ReportedFailedException extends FailedException { \n + public ReportedFailedException ( ) { \n + super ( ) ; \n + } \n + \n + public ReportedFailedException ( String msg ) { \n + super ( msg ) ; \n + } \n + \n + public ReportedFailedException ( String msg , Throwable cause ) { \n + super ( msg , cause ) ; \n + } \n + \n + public ReportedFailedException ( Throwable cause ) { \n + super ( cause ) ; \n + } \n + } \n src \ jvm \ storm \ trident \ topology \ TridentBoltExecutor . java \n + import backtype . storm . topology . ReportedFailedException ; \n - private void failBatch ( TrackedBatch tracked ) { \n + private void failBatch ( TrackedBatch tracked , FailedException e ) { \n + if ( e ! = null & & e instanceof ReportedFailedException ) { \n + _ collector . reportError ( e ) ; \n + } \n + \n + private void failBatch ( TrackedBatch tracked ) { \n + failBatch ( tracked , null ) ; \n + } \n - failBatch ( tracked ) ; \n + failBatch ( tracked , e ) ; \n - failBatch ( tracked ) ; \n + failBatch ( tracked , e ) ; \n",added ReportedFailedException which causes a batch to fail without killing worker and reports the error to the UI,356
"bin \ to _ maven . sh \n - RELEASE = ` head - 1 project . clj | awk ' { print $ 3 } ' | sed - e ' s / \ "" / / ' | sed - e ' s / \ "" / / ' ` \n + RELEASE = ` cat project . clj | sed ' 6q ; d ' | awk ' { print $ 3 } ' | sed - e ' s / \ "" / / ' | sed - e ' s / \ "" / / ' ` \n",fix getting RELEASE in to _ maven script,356
"src \ jvm \ storm \ trident \ Stream . java \n - throw new IllegalArgumentException ( "" Trying to select non - existent field : ' "" + field + "" ' from all fields : "" + allFields + "" ! "" ) ; \n + throw new IllegalArgumentException ( "" Trying to select non - existent field : ' "" + field + "" ' from stream containing fields fields : < "" + allFields + "" > "" ) ; \n",tweak non - existent field error message a bit,356
"src \ jvm \ backtype \ storm \ task \ TopologyContext . java \n - public IMetric registerMetric ( String name , IMetric metric , int timeBucketSizeInSecs ) { \n + public < T extends IMetric > T registerMetric ( String name , T metric , int timeBucketSizeInSecs ) { \n - public IMetric registerMetric ( String name , IReducer reducer , int timeBucketSizeInSecs ) { \n + public ReducedMetric registerMetric ( String name , IReducer reducer , int timeBucketSizeInSecs ) { \n - public IMetric registerMetric ( String name , ICombiner combiner , int timeBucketSizeInSecs ) { \n + public CombinedMetric registerMetric ( String name , ICombiner combiner , int timeBucketSizeInSecs ) { \n src \ jvm \ storm \ trident \ operation \ TridentOperationContext . java \n - public IMetric registerMetric ( String name , IMetric metric , int timeBucketSizeInSecs ) { \n + public < T extends IMetric > T registerMetric ( String name , T metric , int timeBucketSizeInSecs ) { \n - public IMetric registerMetric ( String name , IReducer reducer , int timeBucketSizeInSecs ) { \n + public ReducedMetric registerMetric ( String name , IReducer reducer , int timeBucketSizeInSecs ) { \n - public IMetric registerMetric ( String name , ICombiner combiner , int timeBucketSizeInSecs ) { \n + public CombinedMetric registerMetric ( String name , ICombiner combiner , int timeBucketSizeInSecs ) { \n test \ clj \ backtype \ storm \ metrics _ test . clj \n - ( println "" Waiting for at least "" N "" timebuckets to appear in FakeMetricsConsumer for component id "" comp - id \n - "" and metric name "" metric - name ) \n + ; ; ( println "" Waiting for at least "" N "" timebuckets to appear in FakeMetricsConsumer for component id "" comp - id \n + ; ; "" and metric name "" metric - name ) \n - tracker ( AckFailMapTracker . ) \n - _ ( . setAckFailDelegate feeder tracker ) \n - tracker ( AckFailMapTracker . ) \n - _ ( . setAckFailDelegate feeder tracker ) \n","get rid of unncessary code in metrics implementation , get rid of println , and improve signatures of registerMetric methods to return more specific IMetric types",356
"src \ clj \ backtype \ storm \ timer . clj \n - ( locking lock \n - ( ( second ( . poll queue ) ) ) ) \n + ; ; can ' t hold the lock while executing the task function , or else \n + ; ; deadlocks are possible ( if the task function locks another lock \n + ; ; and another thread locks that other lock before trying to schedule \n + ; ; something on the timer ) \n + ( let [ exec - fn ( locking lock ( second ( . poll queue ) ) ) ] \n + ( exec - fn ) ) \n",resolve # 99 by making the timer lock completely independent from the submit lock . the timer releases the lock before calling the task function .,356
"conf \ defaults . yaml \n - nimbus . cleanup . freq . secs : 1800 \n + nimbus . cleanup . inbox . freq . secs : 1800 \n src \ jvm \ backtype \ storm \ Config . java \n - public static String NIMBUS _ CLEANUP _ FREQ _ SECS = "" nimbus . cleanup . freq . secs "" ; \n + public static String NIMBUS _ CLEANUP _ INBOX _ FREQ _ SECS = "" nimbus . cleanup . inbox . freq . secs "" ; \n",rename inbox frequency config to be more descriptive,356
"src \ jvm \ backtype \ storm \ serialization \ KryoValuesSerializer . java \n - import java . io . ByteArrayOutputStream ; \n - import java . io . OutputStream ; \n new file \n src \ jvm \ backtype \ storm \ serialization \ SerializableSerializer . java \n + package backtype . storm . serialization ; \n + \n + import com . esotericsoftware . kryo . Kryo ; \n + import com . esotericsoftware . kryo . Serializer ; \n + import com . esotericsoftware . kryo . io . Input ; \n + import com . esotericsoftware . kryo . io . Output ; \n + import java . io . ByteArrayInputStream ; \n + import java . io . ByteArrayOutputStream ; \n + import java . io . IOException ; \n + import java . io . ObjectInputStream ; \n + import java . io . ObjectOutputStream ; \n + \n + \n + public class SerializableSerializer extends Serializer < Object > { \n + \n + @ Override \n + public void write ( Kryo kryo , Output output , Object object ) { \n + ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; \n + try { \n + ObjectOutputStream oos = new ObjectOutputStream ( bos ) ; \n + oos . writeObject ( object ) ; \n + oos . flush ( ) ; \n + } catch ( IOException e ) { \n + throw new RuntimeException ( e ) ; \n + } \n + byte [ ] ser = bos . toByteArray ( ) ; \n + output . writeInt ( ser . length ) ; \n + output . writeBytes ( ser ) ; \n + } \n + \n + @ Override \n + public Object create ( Kryo kryo , Input input , Class c ) { \n + int len = input . readInt ( ) ; \n + byte [ ] ser = new byte [ len ] ; \n + input . readBytes ( ser ) ; \n + ByteArrayInputStream bis = new ByteArrayInputStream ( ser ) ; \n + try { \n + ObjectInputStream ois = new ObjectInputStream ( bis ) ; \n + return ois . readObject ( ) ; \n + } catch ( Exception e ) { \n + throw new RuntimeException ( e ) ; \n + } \n + } \n + } \n src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n - import com . esotericsoftware . kryo . serializers . JavaSerializer ; \n - return new JavaSerializer ( ) ; \n + return new SerializableSerializer ( ) ; \n","fix java serialization in cluster mode \n replaces kryo ' s JavaSerializer with one that does the serialization into its own byte array , and then uses normal byte array serialization to read / write to the stream",356
"src \ jvm \ backtype \ storm \ serialization \ SerializationFactory . java \n - k . register ( klass , ( Serializer ) serializerClass . newInstance ( ) ) ; \n + k . register ( klass , resolveSerializerInstance ( k , klass , serializerClass ) ) ; \n - } catch ( InstantiationException e ) { \n - throw new RuntimeException ( e ) ; \n - } catch ( IllegalAccessException e ) { \n - throw new RuntimeException ( e ) ; \n + private static Serializer resolveSerializerInstance ( Kryo k , Class superClass , Class < ? extends Serializer > serializerClass ) { \n + try { \n + try { \n + return serializerClass . getConstructor ( Kryo . class , Class . class ) . newInstance ( k , superClass ) ; \n + } catch ( Exception ex1 ) { \n + try { \n + return serializerClass . getConstructor ( Kryo . class ) . newInstance ( k ) ; \n + } catch ( Exception ex2 ) { \n + try { \n + return serializerClass . getConstructor ( Class . class ) . newInstance ( superClass ) ; \n + } catch ( Exception ex3 ) { \n + return serializerClass . newInstance ( ) ; \n + } \n + } \n + } \n + } catch ( Exception ex ) { \n + throw new IllegalArgumentException ( "" Unable to create serializer \ "" "" \n + + serializerClass . getName ( ) \n + + "" \ "" for class : "" \n + + superClass . getName ( ) , ex ) ; \n + } \n + } \n + \n","make it possible to use kryo serializers that take in Kryo , a class , or combination in constructor",356
"conf \ defaults . yaml \n + zmq . hwm : 10000 \n project . clj \n - ( defproject storm "" 0 . 8 . 1 "" \n + ( defproject storm "" 0 . 8 . 2 - wip1 "" \n src \ clj \ backtype \ storm \ daemon \ worker . clj \n + ( storm - conf ZMQ - HWM ) \n src \ clj \ backtype \ storm \ messaging \ zmq . clj \n - ( deftype ZMQContext [ context linger - ms local ? ] \n + ( deftype ZMQContext [ context linger - ms hwm local ? ] \n + ( mq / set - hwm hwm ) \n + ( mq / set - hwm hwm ) \n - ( defn mk - zmq - context [ num - threads linger local ? ] \n - ( ZMQContext . ( mq / context num - threads ) linger local ? ) ) \n + ( defn mk - zmq - context [ num - threads linger hwm local ? ] \n + ( ZMQContext . ( mq / context num - threads ) linger hwm local ? ) ) \n src \ jvm \ backtype \ storm \ Config . java \n + / * * \n + * The high water for the ZeroMQ push sockets used for networking . Use this config to prevent buffer explosion \n + * on the networking layer . \n + * / \n + public static String ZMQ _ HWM = "" zmq . hwm "" ; \n + \n",set a high water mark that defaults to 10K messages on 0mq sockets,356
"src \ jvm \ backtype \ storm \ StormSubmitter . java \n - submitTopology ( name , stormConf , topology , new SubmitOptions ( TopologyInitialStatus . ACTIVE ) ) ; \n + submitTopology ( name , stormConf , topology , null ) ; \n - client . getClient ( ) . submitTopologyWithOpts ( name , submittedJar , serConf , topology , opts ) ; \n + if ( opts ! = null ) { \n + client . getClient ( ) . submitTopologyWithOpts ( name , submittedJar , serConf , topology , opts ) ; \n + } else { \n + / / this is for backwards compatibility \n + client . getClient ( ) . submitTopology ( name , submittedJar , serConf , topology ) ; \n + } \n",use submitTopology Thrift call when using StormSubmitter # submitTopology for backwards compatibility,356
"src \ jvm \ storm \ trident \ operation \ impl \ GroupedAggregator . java \n + groupColl . currGroup = group ; \n src \ jvm \ storm \ trident \ tuple \ ComboList . java \n + import org . apache . commons . lang . builder . ToStringBuilder ; \n - int numLists ; \n + int [ ] sizes ; \n - numLists = sizes . length ; \n + this . sizes = sizes ; \n - if ( delegates . length ! = numLists ) { \n - throw new RuntimeException ( "" Expected "" + numLists + "" lists , but instead got "" + delegates . length + "" lists "" ) ; \n + if ( delegates . length ! = sizes . length ) { \n + throw new RuntimeException ( "" Expected "" + sizes . length + "" lists , but instead got "" + delegates . length + "" lists "" ) ; \n + } \n + for ( int i = 0 ; i < delegates . length ; i + + ) { \n + List l = delegates [ i ] ; \n + if ( l = = null | | l . size ( ) ! = sizes [ i ] ) { \n + throw new RuntimeException ( "" Got unexpected delegates to ComboList : "" + ToStringBuilder . reflectionToString ( delegates ) ) ; \n + } \n","error checking on ComboList , and fix bug in Aggregator so that it sets the correct group during aggregate",356
CHANGELOG . md \n + * Add whitelist methods to Cluster to allow only a subset of hosts to be revealed as available slots \n src \ jvm \ backtype \ storm \ scheduler \ Cluster . java \n + \n + private Set < String > whiteListedHosts = new HashSet < String > ( ) ; \n - \n + \n + public void setWhitelistedHosts ( Set < String > hosts ) { \n + whiteListedHosts = hosts ; \n + } \n + \n + if ( whiteListedHosts ! = null & & ! whiteListedHosts . isEmpty ( ) & & ! whiteListedHosts . contains ( supervisor . host ) ) return new ArrayList ( ) ; \n,Add whitelist methods to Cluster to allow only a subset of hosts to be revealed as available slots,356
"src \ jvm \ backtype \ storm \ scheduler \ Cluster . java \n + public Set < String > getBlacklistedHosts ( ) { \n + return blackListedHosts ; \n + } \n + \n - public List < Integer > getUsedPorts ( SupervisorDetails supervisor ) { \n + public Set < Integer > getUsedPorts ( SupervisorDetails supervisor ) { \n - List < Integer > usedPorts = new ArrayList < Integer > ( ) ; \n + Set < Integer > usedPorts = new HashSet < Integer > ( ) ; \n - public List < Integer > getAvailablePorts ( SupervisorDetails supervisor ) { \n - List < Integer > usedPorts = this . getUsedPorts ( supervisor ) ; \n + public Set < Integer > getAvailablePorts ( SupervisorDetails supervisor ) { \n + Set < Integer > usedPorts = this . getUsedPorts ( supervisor ) ; \n - List < Integer > ret = new ArrayList < Integer > ( ) ; \n - ret . addAll ( supervisor . allPorts ) ; \n + Set < Integer > ret = new HashSet ( ) ; \n + ret . addAll ( getAssignablePorts ( supervisor ) ) ; \n + \n + public Set < Integer > getAssignablePorts ( SupervisorDetails supervisor ) { \n + if ( isBlackListed ( supervisor . id ) ) return new HashSet ( ) ; \n + return supervisor . allPorts ; \n + } \n - if ( isBlackListed ( supervisor . id ) ) return new ArrayList ( ) ; \n - List < Integer > ports = this . getAvailablePorts ( supervisor ) ; \n + Set < Integer > ports = this . getAvailablePorts ( supervisor ) ; \n + public List < WorkerSlot > getAssignableSlots ( SupervisorDetails supervisor ) { \n + Set < Integer > ports = this . getAssignablePorts ( supervisor ) ; \n + List < WorkerSlot > slots = new ArrayList < WorkerSlot > ( ports . size ( ) ) ; \n + \n + for ( Integer port : ports ) { \n + slots . add ( new WorkerSlot ( supervisor . getId ( ) , port ) ) ; \n + } \n + \n + return slots ; \n + } \n + \n + \n + public List < WorkerSlot > getAssignableSlots ( ) { \n + List < WorkerSlot > slots = new ArrayList < WorkerSlot > ( ) ; \n + for ( SupervisorDetails supervisor : this . supervisors . values ( ) ) { \n + slots . addAll ( this . getAssignableSlots ( supervisor ) ) ; \n + } \n + \n + return slots ; \n + } \n",add getAssignableSlots method to Cluster and improve blacklisting logic,356
"project . clj \n - [ compojure "" 0 . 6 . 4 "" ] \n + [ compojure "" 1 . 1 . 3 "" ] \n",upgrade compojure so that periods work in url parameters,356
src \ clj \ backtype \ storm \ scheduler \ IsolationScheduler . clj \n + ( defn - host - > used - slots [ ^ Cluster cluster ] \n + ( - > > cluster \n + . getUsedSlots \n + ( group - by # ( . getHost cluster ( . getNodeId ^ WorkerSlot % ) ) ) \n + ) ) \n + \n - ( if ( and ( every ? # ( = ( second % ) top - id ) assignments ) \n + ( if ( and ( contains ? iso - ids - set top - id ) \n + ( every ? # ( = ( second % ) top - id ) assignments ) \n - ( let [ ^ LinkedList sorted - assignable - hosts ( host - assignable - slots cluster ) ] \n + ( let [ host - > used - slots ( host - > used - slots cluster ) \n + ^ LinkedList sorted - assignable - hosts ( host - assignable - slots cluster ) ] \n - ( . freeSlots cluster host - slots ) \n + ( . freeSlots cluster ( get host - > used - slots host ) ) \n src \ jvm \ backtype \ storm \ scheduler \ Cluster . java \n - for ( WorkerSlot slot : slots ) { \n - this . freeSlot ( slot ) ; \n + if ( slots ! = null ) { \n + for ( WorkerSlot slot : slots ) { \n + this . freeSlot ( slot ) ; \n + } \n,fix isolation scheduler to properly clear a machine of workers when putting an isolated topology there,356
"src \ clj \ backtype \ storm \ scheduler \ IsolationScheduler . clj \n + shuffle \n - num - workers ( count host - assignments ) \n + num - workers ( count assignments ) \n test \ clj \ backtype \ storm \ nimbus _ test . clj \n + ( defn topology - slots [ state storm - name ] \n + ( let [ storm - id ( get - storm - id state storm - name ) \n + assignment ( . assignment - info state storm - id nil ) ] \n + ( - > > assignment \n + : executor - > node + port \n + vals \n + set \n + ) ) ) \n + \n - ( with - local - cluster [ cluster : supervisors 6 \n + ( with - simulated - time - local - cluster [ cluster : supervisors 6 \n + NIMBUS - MONITOR - FREQ - SECS 10 \n + ( advance - cluster - time cluster 1 ) \n + ( advance - cluster - time cluster 1 ) \n + \n + ; ; check that nothing gets reassigned \n + ( bind tester1 - slots ( topology - slots state "" tester1 "" ) ) \n + ( bind tester2 - slots ( topology - slots state "" tester2 "" ) ) \n + ( bind noniso - slots ( topology - slots state "" noniso "" ) ) \n + ( advance - cluster - time cluster 20 ) \n + ( is ( = tester1 - slots ( topology - slots state "" tester1 "" ) ) ) \n + ( is ( = tester2 - slots ( topology - slots state "" tester2 "" ) ) ) \n + ( is ( = noniso - slots ( topology - slots state "" noniso "" ) ) ) \n + \n","fix checking of correct nodes in isolation scheduler , add test that isolation scheduler doesn ' t reassign after correct assignment",356
"src \ clj \ backtype \ storm \ scheduler \ IsolationScheduler . clj \n - ( doseq [ [ top - id worker - specs ] topology - worker - specs ] \n - ( if - not ( empty ? worker - specs ) \n - ( log - warn "" Unable to isolate topology "" top - id ) \n + ( let [ non - iso - topologies ( - > > topology - worker - specs \n + ( mapcat ( fn [ [ top - id worker - specs ] ] \n + ( if - not ( empty ? worker - specs ) [ top - id ] ) \n + ) ) ) ] \n + ( if ( empty ? non - iso - topologies ) \n + ; ; run default scheduler on non - isolated topologies \n + ( - < > topology - worker - specs \n + allocated - topologies \n + ( leftover - topologies topologies < > ) \n + ( DefaultScheduler / default - schedule < > cluster ) ) \n + ( log - warn "" Unstable to isolate topologies "" ( pr - str non - iso - topologies ) "" . Will wait for enough resources for isolated topologies before allocating any other resources . "" ) \n - \n - \n - ; ; run default scheduler on iso topologies that didn ' t have enough slot + non - isolated topologies \n - ( - < > topology - worker - specs \n - allocated - topologies \n - ( leftover - topologies topologies < > ) \n - ( DefaultScheduler / default - schedule < > cluster ) ) \n",change iso scheduler to not allocate anything else if isolation topologies can ' t be allocated ( wait for enough resources to be available ),356
server \ src \ internalClusterTest \ java \ org \ elasticsearch \ search \ ccs \ CrossClusterSearchIT . java \n + @ Override \n + protected boolean reuseClusters ( ) { \n + return false ; \n + } \n + \n,Do not reuse test cluster in CrossClusterSearchIT \n The ` testProxyConnectionDisconnect ` test can use a node without the \n remote _ cluster _ client that is created in ` testRemoteClusterClientRole ` .,362
"x - pack \ plugin \ ccr \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ ccr \ IndexFollowingIT . java \n - } ) ; \n + } , 60 , TimeUnit . SECONDS ) ; \n","Increase timeout in testCleanUpShardFollowTasksForDeletedIndices ( # 64562 ) \n If the deleted index has N shards , then ShardFollowTaskCleaner can send \n N * ( N - 1 ) / 2 requests to remove N shard - follow tasks . I think that ' s fine \n as the implementation is straightforward . The test failed when the \n deleted index has 8 shards . This commit increases the timeout in the \n test . \n Closes # 64311",362
server \ src \ main \ java \ org \ elasticsearch \ index \ engine \ InternalEngine . java \n + / / TODO : revise https : / / github . com / elastic / elasticsearch / pull / 34553 to use IndexWriter . flushNextBuffer to flush only the largest \n + / / pending DWPT . Note that benchmarking this PR with a heavy update user case ( geonames ) and a small heap ( 1GB ) caused OOM . \n,Add TODO for IndexWriter # flushNextBuffer \n Relates # 34553,362
"server \ src \ main \ java \ org \ elasticsearch \ action \ search \ AbstractSearchAsyncAction . java \n + import org . elasticsearch . tasks . TaskCancelledException ; \n - / / we don ' t aggregate shard failures on non active shards ( but do keep the header counts right ) \n - if ( TransportActions . isShardNotAvailableException ( e ) = = false ) { \n + / / we don ' t aggregate shard failures on non active shards and failures due to the internal cancellation , \n + / / but do keep the header counts right \n + if ( TransportActions . isShardNotAvailableException ( e ) = = false & & ( requestCancelled . get ( ) & & isTaskCancelledException ( e ) ) = = false ) { \n + private static boolean isTaskCancelledException ( Exception e ) { \n + return ExceptionsHelper . unwrapCausesAndSuppressed ( e , ex - > ex instanceof TaskCancelledException ) . isPresent ( ) ; \n + } \n + \n x - pack \ plugin \ async - search \ src \ internalClusterTest \ java \ org \ elasticsearch \ xpack \ search \ AsyncSearchActionIT . java \n - @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 63702 "" ) \n","Ignore cancellation error when search is cancelled ( # 64240 ) \n Since # 63520 , we will cancel a search that hits shard failures and does \n not accept partial results . However , that change can return the wrong \n HTTP code for bad requests ( from 4xx to 5xx ) due to the cancellation . \n Relates # 63520 \n Closes # 64012 \n Closes # 63702",362
"server \ src \ test \ java \ org \ elasticsearch \ search \ SearchServiceTests . java \n - public void testCreateSearchContextFailure ( ) throws IOException { \n + public void testCreateSearchContextFailure ( ) throws Exception { \n - assertEquals ( "" should have 2 store refs ( IndexService + InternalEngine ) "" , 2 , indexService . getShard ( 0 ) . store ( ) . refCount ( ) ) ; \n + / / Needs to busily assert because Engine # refreshNeeded can increase the refCount . \n + assertBusy ( ( ) - > \n + assertEquals ( "" should have 2 store refs ( IndexService + InternalEngine ) "" , 2 , indexService . getShard ( 0 ) . store ( ) . refCount ( ) ) ) ; \n","Busily assert in testCreateSearchContextFailure ( # 64243 ) \n If a background refresh is running , then the refCount assertion will \n fail as Engine # refreshIsNeeded can increase the refCount by 2 . \n Closes # 64052",362
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ search \ SearchCancellationIT . java \n - @ AwaitsFix ( bugUrl = "" https : / / github . com / elastic / elasticsearch / issues / 63976 "" ) \n - assertThat ( searchTasks , hasSize ( 1 ) ) ; \n - assertTrue ( searchTasks . get ( 0 ) . isCancelled ( ) ) ; \n + / / The search request can complete before the "" cancelledLatch "" is latched if the second shard request is sent \n + / / after the request was cancelled ( i . e . , the child task is not allowed to start after the parent was cancelled ) . \n + if ( searchTasks . isEmpty ( ) = = false ) { \n + assertThat ( searchTasks , hasSize ( 1 ) ) ; \n + assertTrue ( searchTasks . get ( 0 ) . isCancelled ( ) ) ; \n + } \n","Fix testCancelFailedSearchWhenPartialResultDisallowed ( # 64248 ) \n The search request in the test can complete before the "" cancelledLatch "" \n is latched if the second shard request is sent after the request was \n canceled ( i . e . , the child task is not allowed to start after the parent \n was canceled ) . \n Closes # 63976 \n Relates # # 63520",362
x - pack \ plugin \ ccr \ src \ main \ java \ org \ elasticsearch \ xpack \ ccr \ action \ ShardFollowNodeTask . java \n - setFatalException ( e ) ; \n + onFatalFailure ( e ) ; \n - void setFatalException ( Exception e ) { \n - fatalException = ExceptionsHelper . convertToElastic ( e ) ; \n + final void onFatalFailure ( Exception e ) { \n + synchronized ( this ) { \n + this . fatalException = ExceptionsHelper . convertToElastic ( e ) ; \n + if ( this . renewable ! = null ) { \n + this . renewable . cancel ( ) ; \n + this . renewable = null ; \n + } \n + } \n x - pack \ plugin \ ccr \ src \ main \ java \ org \ elasticsearch \ xpack \ ccr \ action \ ShardFollowTasksExecutor . java \n - shardFollowNodeTask . setFatalException ( e ) ; \n + shardFollowNodeTask . onFatalFailure ( e ) ; \n x - pack \ plugin \ ccr \ src \ test \ java \ org \ elasticsearch \ xpack \ ccr \ action \ ShardFollowNodeTaskTests . java \n - public void testNonRetryableError ( ) { \n + public void testNonRetryableError ( ) throws Exception { \n + assertBusy ( ( ) - > assertNull ( task . getRenewable ( ) ) ) ; \n,"Stop renew retention leases when follow task fails ( # 65168 ) \n If a shard follow - task hits a non - retryable error and stops , then we \n should also stop the retention - leases renewal process associated with \n that follow - task .",362
"server \ src \ test \ java \ org \ elasticsearch \ index \ translog \ TranslogTests . java \n + long lastModifiedAge = System . currentTimeMillis ( ) - translog . getCurrent ( ) . getLastModifiedTime ( ) ; \n - assertThat ( stats . getEarliestLastModifiedAge ( ) , greaterThan ( 0L ) ) ; \n + assertThat ( stats . getEarliestLastModifiedAge ( ) , greaterThanOrEqualTo ( lastModifiedAge ) ) ; \n","Fix TranslogTests # testStats ( # 66227 ) \n If creating the latest translog file and retrieving a translog stats \n happen within the same millisecond , then the earliestLastModifiedAge \n will be zero . \n Closes # 66092",362
"server \ src \ test \ java \ org \ elasticsearch \ index \ engine \ InternalEngineTests . java \n - Engine . NoOpResult noOpResult = engine . noOp ( new Engine . NoOp ( 1 , primaryTerm . get ( ) , \n + final long seqNo = randomLongBetween ( 0 , 1000 ) ; \n + final long term = this . primaryTerm . get ( ) ; \n + Engine . NoOpResult noOpResult = engine . noOp ( new Engine . NoOp ( seqNo , term , \n + assertThat ( noOpResult . getSeqNo ( ) , equalTo ( seqNo ) ) ; \n + assertThat ( noOpResult . getTerm ( ) , equalTo ( term ) ) ; \n + assertThat ( noOp . getTerm ( ) , equalTo ( primaryTerm . get ( ) ) ) ; \n + assertThat ( noOp . getSeqNo ( ) , equalTo ( ( long ) i ) ) ; \n",Add unit test for NoOpResult \n Relates # 66269,362
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ action \ admin \ cluster \ node \ tasks \ CancellableTasksIT . java \n - import org . junit . Before ; \n + @ ESIntegTestCase . ClusterScope ( scope = ESIntegTestCase . Scope . TEST ) \n - @ Before \n - public void resetTestStates ( ) { \n - idGenerator = 0 ; \n - beforeSendLatches . clear ( ) ; \n - arrivedLatches . clear ( ) ; \n - beforeExecuteLatches . clear ( ) ; \n - completedLatches . clear ( ) ; \n - } \n - \n - arrivedLatches . get ( req ) . await ( ) ; \n + assertTrue ( arrivedLatches . get ( req ) . await ( 60 , TimeUnit . SECONDS ) ) ; \n - completedLatches . get ( req ) . await ( ) ; \n + assertTrue ( completedLatches . get ( req ) . await ( 60 , TimeUnit . SECONDS ) ) ; \n - beforeExecuteLatches . get ( request ) . await ( ) ; \n + assertTrue ( beforeExecuteLatches . get ( request ) . await ( 60 , TimeUnit . SECONDS ) ) ; \n - beforeSendLatches . get ( subRequest ) . await ( ) ; \n + assertTrue ( beforeSendLatches . get ( subRequest ) . await ( 60 , TimeUnit . SECONDS ) ) ; \n","Use test cluster exclusive in CancellableTasksIT ( # 67058 ) \n testRemoveBanParentsOnDisconnect disconnects some nodes and leaves the \n cluster in an unhealthy state , which fails other tests . We can reconnect \n nodes after that test . However , this commit chooses to run this suite \n test - cluster exclusive instead because it is simpler and more stable . \n Closes # 6652",362
"server \ src \ internalClusterTest \ java \ org \ elasticsearch \ cluster \ routing \ AllocationIdIT . java \n + internalCluster ( ) . stopNode ( node1 ) ; \n + node1 = internalCluster ( ) . startNode ( node1DataPathSettings ) ; \n - internalCluster ( ) . restartNode ( node1 , InternalTestCluster . EMPTY _ CALLBACK ) ; \n - \n - / / index is still red due to mismatch of allocation id \n - checkHealthStatus ( indexName , ClusterHealthStatus . RED ) ; \n - checkNoValidShardCopy ( indexName , shardId ) ; \n - \n",Fix AllocationIdIT test failure on WindowFS ( # 67179 ) \n This test failed on WindowsFS . We failed to remove the corrupted file if \n it ' s being opened ( for a short window by ListShardStore action ) and the \n pending delete files were clear when we restarted that node . \n This commit fixes the issue by shutting down the node before removing \n the corrupted file to avoid any access to that file . \n Closes # 66893,362
"server \ src \ main \ java \ org \ elasticsearch \ index \ IndexingPressure . java \n + import org . apache . logging . log4j . LogManager ; \n + import org . apache . logging . log4j . Logger ; \n + import java . util . concurrent . atomic . AtomicBoolean ; \n + private static final Logger logger = LogManager . getLogger ( IndexingPressure . class ) ; \n + \n + private static Releasable wrapReleasable ( Releasable releasable ) { \n + final AtomicBoolean called = new AtomicBoolean ( ) ; \n + return ( ) - > { \n + if ( called . compareAndSet ( false , true ) ) { \n + releasable . close ( ) ; \n + } else { \n + logger . error ( "" IndexingPressure memory is adjusted twice "" , new IllegalStateException ( "" Releasable is called twice "" ) ) ; \n + assert false : "" IndexingPressure is adjusted twice "" ; \n + } \n + } ; \n + } \n + \n - return ( ) - > { \n + return wrapReleasable ( ( ) - > { \n - } ; \n + } ) ; \n - return ( ) - > { \n + return wrapReleasable ( ( ) - > { \n - } ; \n + } ) ; \n - return ( ) - > { \n + return wrapReleasable ( ( ) - > { \n - } ; \n + } ) ; \n - return ( ) - > { \n + return wrapReleasable ( ( ) - > { \n - } ; \n + } ) ; \n server \ src \ test \ java \ org \ elasticsearch \ index \ IndexingPressureTests . java \n - \n - forced . close ( ) ; \n","Ensure IndexingPressure memory is re - adjusted once ( # 67673 ) \n We have seen a case where the memory of IndexingPressure was \n re - adjusted twice . With this commit , we will log that error with a \n stack trace so that we can figure out the source of the issue .",362
"server \ src \ main \ java \ org \ elasticsearch \ action \ support \ replication \ ReplicationOperation . java \n - primary . perform ( request , ActionListener . wrap ( this : : handlePrimaryResult , resultListener : : onFailure ) ) ; \n + primary . perform ( request , ActionListener . wrap ( this : : handlePrimaryResult , this : : finishAsFailed ) ) ; \n",Ensure ReplicationOperation notify listener once ( # 68256 ) \n ReplicationOperation can notify the listener twice if the primary shard \n is demoted after it has completed the primary operation . \n Closes # 68049,362
test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ engine \ ThrowingLeafReaderWrapper . java \n + import org . apache . lucene . codecs . StoredFieldsReader ; \n - import org . apache . lucene . index . FilterLeafReader ; \n + import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - public class ThrowingLeafReaderWrapper extends FilterLeafReader { \n + public class ThrowingLeafReaderWrapper extends SequentialStoredFieldsLeafReader { \n + \n + @ Override \n + protected StoredFieldsReader doGetSequentialStoredFieldsReader ( StoredFieldsReader reader ) { \n + return reader ; \n + } \n,ThrowingLeafReaderWrapper impls sequential access \n The test class ThrowingLeafReaderWrapper needs to implement \n SequentialStoredFieldsLeafReader . \n Closes # 67410,362
rest - api - spec \ src \ main \ resources \ rest - api - spec \ test \ create \ 60 _ refresh . yml \n + # make sure that we don ' t have shard relocations ; otherwise search can be executed by a relocated shard \n + routing . rebalance . enable : none \n - do : \n rest - api - spec \ src \ main \ resources \ rest - api - spec \ test \ delete \ 50 _ refresh . yml \n + # make sure that we don ' t have shard relocations ; otherwise search can be executed by a relocated shard \n + routing . rebalance . enable : none \n - do : \n,Avoid shard relocations in refresh yaml tests ( # 69095 ) \n If shard relocations happen then a search can be executed by a relocated shard . \n Closes # 68562,362
"server \ src \ main \ java \ org \ elasticsearch \ index \ engine \ LuceneChangesSnapshot . java \n - import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - if ( leaf . reader ( ) instanceof SequentialStoredFieldsLeafReader ) { \n - ( ( SequentialStoredFieldsLeafReader ) leaf . reader ( ) ) . getSequentialStoredFieldsReader ( ) . visitDocument ( segmentDocID , fields ) ; \n - } else { \n - assert false : "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ; \n - throw new IllegalStateException ( "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ) ; \n - } \n + leaf . reader ( ) . document ( segmentDocID , fields ) ; \n + \n test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ engine \ ThrowingLeafReaderWrapper . java \n - import org . apache . lucene . codecs . StoredFieldsReader ; \n + import org . apache . lucene . index . FilterLeafReader ; \n - import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - public class ThrowingLeafReaderWrapper extends SequentialStoredFieldsLeafReader { \n + public class ThrowingLeafReaderWrapper extends FilterLeafReader { \n - \n - @ Override \n - protected StoredFieldsReader doGetSequentialStoredFieldsReader ( StoredFieldsReader reader ) { \n - return reader ; \n - } \n","Revert "" Use SequentialStoredFieldsLeafReader to read Lucene changes ( # 67190 ) "" ( # 68586 ) \n This reverts commit 5fe0d67ade5fed3de5b062a1a0837fd02286e0a9 . \n I benchmarked an improvement in CCR and found that changes introduced in \n # 67190 made CCR 10 times slower ( 1816 seconds to 26515 seconds ) . \n "" total _ read _ remote _ exec _ time _ millis "" : 26515182 \n "" total _ read _ remote _ exec _ time _ millis "" : 1816094 \n With concurrent indexing and Lucene merges , documents in segments are no \n longer sorted by sequence numbers . And if the index sorting is \n specified , documents are never sorted by sequence numbers . Using a \n mergeInstance stored field reader will decompress the whole block , which \n we will not use . \n Reverts # 67190",362
server \ src \ main \ java \ org \ elasticsearch \ search \ internal \ ShardSearchContextId . java \n - if ( in . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( in . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n - if ( out . getVersion ( ) . onOrAfter ( Version . V _ 8 _ 0 _ 0 ) ) { \n + if ( out . getVersion ( ) . onOrAfter ( Version . V _ 7 _ 12 _ 0 ) ) { \n,Adjust wire compat version for point in time \n Relates # 66713,362
"server \ src \ main \ java \ org \ elasticsearch \ index \ engine \ LuceneChangesSnapshot . java \n + import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - leaf . reader ( ) . document ( segmentDocID , fields ) ; \n - \n + if ( leaf . reader ( ) instanceof SequentialStoredFieldsLeafReader ) { \n + ( ( SequentialStoredFieldsLeafReader ) leaf . reader ( ) ) . getSequentialStoredFieldsReader ( ) . visitDocument ( segmentDocID , fields ) ; \n + } else { \n + assert false : "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ; \n + throw new IllegalStateException ( "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ) ; \n + } \n test \ framework \ src \ main \ java \ org \ elasticsearch \ test \ engine \ ThrowingLeafReaderWrapper . java \n + import org . apache . lucene . codecs . StoredFieldsReader ; \n - import org . apache . lucene . index . FilterLeafReader ; \n + import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - public class ThrowingLeafReaderWrapper extends FilterLeafReader { \n + public class ThrowingLeafReaderWrapper extends SequentialStoredFieldsLeafReader { \n + \n + @ Override \n + protected StoredFieldsReader doGetSequentialStoredFieldsReader ( StoredFieldsReader reader ) { \n + return reader ; \n + } \n",Use SequentialStoredFieldsLeafReader to read Lucene changes ( # 67190 ) \n Reading operations in Lucene changes is likely sequential and more \n efficient with SequentialStoredFieldsLeafReader . \n Relates # 66944,362
"server \ src \ main \ java \ org \ elasticsearch \ index \ engine \ LuceneChangesSnapshot . java \n + import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - leaf . reader ( ) . document ( segmentDocID , fields ) ; \n - \n + if ( leaf . reader ( ) instanceof SequentialStoredFieldsLeafReader ) { \n + ( ( SequentialStoredFieldsLeafReader ) leaf . reader ( ) ) . getSequentialStoredFieldsReader ( ) . visitDocument ( segmentDocID , fields ) ; \n + } else { \n + assert false : "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ; \n + throw new IllegalStateException ( "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ) ; \n + } \n",Use SequentialStoredFieldsLeafReader to read Lucene changes ( # 67190 ) \n Reading operations in Lucene changes is likely sequential and more \n efficient with SequentialStoredFieldsLeafReader . \n Relates # 66944,362
"server \ src \ main \ java \ org \ elasticsearch \ index \ engine \ LuceneChangesSnapshot . java \n - import org . elasticsearch . common . lucene . index . SequentialStoredFieldsLeafReader ; \n - if ( leaf . reader ( ) instanceof SequentialStoredFieldsLeafReader ) { \n - ( ( SequentialStoredFieldsLeafReader ) leaf . reader ( ) ) . getSequentialStoredFieldsReader ( ) . visitDocument ( segmentDocID , fields ) ; \n - } else { \n - assert false : "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ; \n - throw new IllegalStateException ( "" The changes reader isn ' t wrapped with Lucene # wrapAllDocsLive "" ) ; \n - } \n + leaf . reader ( ) . document ( segmentDocID , fields ) ; \n + \n","Revert "" Use SequentialStoredFieldsLeafReader to read Lucene changes ( # 67190 ) "" \n This reverts commit 6cbaaed8a14f1e33c18bed4f7fa6e2f094559e6b .",362
build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 2 . 0 ' \n + classpath ' com . android . tools . build : gradle : 2 . 3 . 0 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Tue Feb 07 14 : 14 : 10 PST 2017 \n + # Mon Mar 27 09 : 44 : 31 PDT 2017 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 14 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 3 . 3 - all . zip \n mobile \ build . gradle \n - compile ' com . google . android . gms : play - services - cast - framework : 10 . 0 . 1 ' \n + compile ' com . google . android . gms : play - services - cast - framework : 10 . 2 . 1 ' \n - compile ' com . android . support : appcompat - v7 : 25 . 1 . 1 ' \n - compile ' com . android . support : cardview - v7 : 25 . 1 . 1 ' \n - compile ' com . android . support : mediarouter - v7 : 25 . 1 . 1 ' \n - compile ' com . android . support : leanback - v17 : 25 . 1 . 1 ' \n - compile ' com . android . support : design : 25 . 1 . 1 ' \n + compile ' com . android . support : appcompat - v7 : 25 . 3 . 0 ' \n + compile ' com . android . support : cardview - v7 : 25 . 3 . 0 ' \n + compile ' com . android . support : mediarouter - v7 : 25 . 3 . 0 ' \n + compile ' com . android . support : leanback - v17 : 25 . 3 . 0 ' \n + compile ' com . android . support : design : 25 . 3 . 0 ' \n - androidTestCompile ' com . android . support : support - annotations : 25 . 1 . 1 ' \n + androidTestCompile ' com . android . support : support - annotations : 25 . 3 . 0 ' \n,Update to the latest version of the support library \n Bug : 29504817 \n Change - Id : I8c29e41c9161662fe9ec1cdc913f9269498c73a1,369
mobile \ src \ main \ java \ com \ example \ android \ uamp \ ui \ FullScreenPlayerActivity . java \n - if ( mLastPlaybackState . getState ( ) ! = PlaybackStateCompat . STATE _ PAUSED ) { \n + if ( mLastPlaybackState . getState ( ) = = PlaybackStateCompat . STATE _ PLAYING ) { \n,Only update playback time while playing \n Issue : https : / / github . com / googlesamples / android - UniversalMusicPlayer / issues / 145 \n Change - Id : Ifb1f5c86c0941b8c2441f358481b7e37114de7ca,369
"mobile \ src \ main \ res \ xml \ allowed _ media _ browser _ callers . xml \n - Copyright ( C ) 2014 The Android Open Source Project \n + Copyright ( C ) 2017 The Android Open Source Project \n - < signing _ certificate name = "" Media Browser Service Simulator "" release = "" true "" \n - package = "" com . google . android . mediasimulator "" > \n - MIIDvTCCAqWgAwIBAgIJAMePnkuTQTAGMA0GCSqGSIb3DQEBBQUAMHUxCzAJBgNV \n - BAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRYwFAYDVQQHDA1Nb3VudGFpbiBW \n - aWV3MRQwEgYDVQQKDAtHb29nbGUgSW5jLjEQMA4GA1UECwwHQW5kcm9pZDERMA8G \n - A1UEAwwIZ2VhcmhlYWQwHhcNMTQwNTI3MjMwNTM0WhcNNDExMDEyMjMwNTM0WjB1 \n - MQswCQYDVQQGEwJVUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEWMBQGA1UEBwwNTW91 \n - bnRhaW4gVmlldzEUMBIGA1UECgwLR29vZ2xlIEluYy4xEDAOBgNVBAsMB0FuZHJv \n - aWQxETAPBgNVBAMMCGdlYXJoZWFkMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB \n - CgKCAQEA050XDkNIsVRMX2wTvVplpCu4OtnyNK2v5B7PS + DggmH2yuZiwpTurdKD \n - Q9R9UzxH9U4lsC + mIxXkiBYKIWNVgMtiTgxkEy7cgWvdYHgNYpFu8IxZKYDyXes + \n - 02pfvpu63MIBD / PnvVFipo1oUrbfetj + mroEpjnA71gUS0Ok + H6XWWsmb8xFHQVM \n - oZWEIzsUJ2nhm8EcnPkAPfNZAG + + XLPROoRQCaswyYsd42JuYAP3CwZuhDcUbMWm \n - k7rBi9BVQ8gmkrbwqo94A7qStLUp3NyCmlKSWHaZ05SspEPwsfctka0oXG5bhgT6 \n - 67EMCzQ + YsFN1oJRL7Qq + mMQjFJs3wIDAQABo1AwTjAdBgNVHQ4EFgQUGvBfYNeu \n - 6JSJUnJZCiaBGsnXztswHwYDVR0jBBgwFoAUGvBfYNeu6JSJUnJZCiaBGsnXztsw \n - DAYDVR0TBAUwAwEB / zANBgkqhkiG9w0BAQUFAAOCAQEAlGsDY0EPu3NBSH5k6iw / \n - wJh9e3xMwS17ErKGlhyWogxJMzLjAN6g0aCPHxB40IQC + 8qAl + RL7VQx6oxttf0m \n - 31yUGQPcNYbt2CxBTCAr885oLK5t2TAi5tQzhd6ZEYihWSUWUd / X8BQRouxboss9 \n - QbBA / iIx0OpDaxiAcq7Cb67TheXZDxGuQ8fmHYbLx84pEvm3DQOB / LIMkkpQSfEC \n - 1f + oP1zB3urPU / dSvED / LCgOdrpxZ5di7SwSyue + Vq / TZQy34tPygEzD2d8hFlh / \n - yfhWkMizOeIXcayVAQdNn5zpBkuay1skGOjQQ5kTbDcDzigO2R2rqn6HCd9l5Z0W \n - IQ = = \n - < / signing _ certificate > \n - < signing _ certificate name = "" Media Browser Simulator "" release = "" true "" \n - package = "" com . google . android . mediasimulator "" > \n - MIIEqDCCA5CgAwIBAgIJANWFuGx90071MA0GCSqGSIb3DQEBBAUAMIGUMQswCQYD \n - VQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4g \n - VmlldzEQMA4GA1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UE \n - AxMHQW5kcm9pZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTAe \n - Fw0wODA0MTUyMzM2NTZaFw0zNTA5MDEyMzM2NTZaMIGUMQswCQYDVQQGEwJVUzET \n - MBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4G \n - A1UEChMHQW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9p \n - ZDEiMCAGCSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbTCCASAwDQYJKoZI \n - hvcNAQEBBQADggENADCCAQgCggEBANbOLggKv + IxTdGNs8 / TGFy0PTP6DHThvbbR \n - 24kT9ixcOd9W + EaBPWW + wPPKQmsHxajtWjmQwWfna8mZuSeJS48LIgAZlKkpFeVy \n - xW0qMBujb8X8ETrWy550NaFtI6t9 + u7hZeTfHwqNvacKhp1RbE6dBRGWynwMVX8X \n - W8N1 + UjFaq6GCJukT4qmpN2afb8sCjUigq0GuMwYXrFVee74bQgLHWGJwPmvmLHC \n - 69EH6kWr22ijx4OKXlSIx2xT1AsSHee70w5iDBiK4aph27yH3TxkXy9V89TDdexA \n - cKk / cVHYNnDBapcavl7y0RiQ4biu8ymM8Ga / nmzhRKya6G0cGw8CAQOjgfwwgfkw \n - HQYDVR0OBBYEFI0cxb6VTEM8YYY6FbBMvAPyT + CyMIHJBgNVHSMEgcEwgb6AFI0c \n - xb6VTEM8YYY6FbBMvAPyT + CyoYGapIGXMIGUMQswCQYDVQQGEwJVUzETMBEGA1UE \n - CBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNTW91bnRhaW4gVmlldzEQMA4GA1UEChMH \n - QW5kcm9pZDEQMA4GA1UECxMHQW5kcm9pZDEQMA4GA1UEAxMHQW5kcm9pZDEiMCAG \n - CSqGSIb3DQEJARYTYW5kcm9pZEBhbmRyb2lkLmNvbYIJANWFuGx90071MAwGA1Ud \n - EwQFMAMBAf8wDQYJKoZIhvcNAQEEBQADggEBABnTDPEF + 3iSP0wNfdIjIz1AlnrP \n - zgAIHVvXxunW7SBrDhEglQZBbKJEk5kT0mtKoOD1JMrSu1xuTKEBahWRbqHsXcla \n - XjoBADb0kkjVEJu / Lh5hgYZnOjvlba8Ld7HCKePCVePoTJBdI4fvugnL8TsgK05a \n - IskyY0hKI9L8KfqfGTl1lzOv2KoWD0KWwtAWPoGChZxmQ + nBli + gwYMzM1vAkP + a \n - ayLe0a1EQimlOalO762r0GXO0ks + UeXde2Z4e + 8S / pf7pITEI / tP + MxJTALw9QUW \n - Ev9lKTk + jkbqxbsh8nfBUapfKqYn0eidpwq2AzVp3juYl7 / / fKnaPhJD9gs = \n - < / signing _ certificate > \n",Remove media simulators from allowed _ callers list \n Bug : 33077336 \n Change - Id : Iabecd6442c943cc4cdfd299517a8db6e5ed3bbbe,369
"build . gradle \n + maven { \n + url "" https : / / maven . google . com "" \n + } \n mobile \ build . gradle \n - provided ' com . google . android . wearable : wearable : 2 . 0 . 1 ' \n + provided ' com . google . android . wearable : wearable : 2 . 0 . 3 ' \n - compile ' com . google . android . gms : play - services - cast - framework : 10 . 2 . 4 ' \n - compile ' com . google . android . support : wearable : 2 . 0 . 1 ' \n - compile ' com . android . support : appcompat - v7 : 25 . 3 . 1 ' \n - compile ' com . android . support : cardview - v7 : 25 . 3 . 1 ' \n - compile ' com . android . support : mediarouter - v7 : 25 . 3 . 1 ' \n - compile ' com . android . support : leanback - v17 : 25 . 3 . 1 ' \n - compile ' com . android . support : design : 25 . 3 . 1 ' \n + compile ' com . google . android . gms : play - services - cast - framework : 11 . 0 . 0 ' \n + compile ' com . google . android . support : wearable : 2 . 0 . 3 ' \n + compile ' com . android . support : appcompat - v7 : 25 . 4 . 0 ' \n + compile ' com . android . support : cardview - v7 : 25 . 4 . 0 ' \n + compile ' com . android . support : mediarouter - v7 : 25 . 4 . 0 ' \n + compile ' com . android . support : leanback - v17 : 25 . 4 . 0 ' \n + compile ' com . android . support : design : 25 . 4 . 0 ' \n - androidTestCompile ' com . android . support : support - annotations : 25 . 3 . 1 ' \n + androidTestCompile ' com . android . support : support - annotations : 25 . 4 . 0 ' \n","Update library versions . \n Support library 25 . 3 . x did not properly account for API level 26 , which \n was released in Android "" O "" DP3 . Updating to 25 . 4 . 0 fixes a crash when \n browsing . \n Other library versions are updated to the latest version available . \n Bug : 62586349 \n Change - Id : I7daae4325be793cfd0dc067ed8d5c8cef16a3f4b",369
"build . gradle \n - classpath ' com . android . tools . build : gradle : 2 . 3 . 3 ' \n + classpath ' com . android . tools . build : gradle : 3 . 0 . 0 - beta3 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Mon Mar 27 09 : 44 : 31 PDT 2017 \n + # Mon Sep 11 10 : 00 : 07 PDT 2017 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 3 . 3 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 1 - all . zip \n mobile \ build . gradle \n - compile ' com . google . android . exoplayer : exoplayer : r2 . 4 . 1 ' \n + compile ' com . google . android . exoplayer : exoplayer : r2 . 5 . 0 ' \n mobile \ src \ main \ java \ com \ example \ android \ uamp \ playback \ LocalPlayback . java \n + import com . google . android . exoplayer2 . audio . AudioAttributes ; \n + import static com . google . android . exoplayer2 . C . CONTENT _ TYPE _ MUSIC ; \n + import static com . google . android . exoplayer2 . C . USAGE _ MEDIA ; \n - mExoPlayer . setAudioStreamType ( AudioManager . STREAM _ MUSIC ) ; \n + / / Android "" O "" makes much greater use of AudioAttributes , especially \n + / / with regards to AudioFocus . All of UAMP ' s tracks are music , but \n + / / if your content includes spoken word such as audiobooks or podcasts \n + / / then the content type should be set to CONTENT _ TYPE _ SPEECH for those \n + / / tracks . \n + final AudioAttributes audioAttributes = new AudioAttributes . Builder ( ) \n + . setContentType ( CONTENT _ TYPE _ MUSIC ) \n + . setUsage ( USAGE _ MEDIA ) \n + . build ( ) ; \n + mExoPlayer . setAudioAttributes ( audioAttributes ) ; \n + \n + @ Override \n + public void onRepeatModeChanged ( int repeatMode ) { \n + / / Nothing to do . \n + } \n",Update to ExoPlayer 2 . 5 & use AudioAttributes . \n - Update to ExoPlayer 2 . 5 \n - Switch to using AudioAttributes in preparation for updating the \n targetSdkVersion to 26 . \n Bug : 37484135 \n Change - Id : I6638b97a5c79ee350e22e39e3d1dfddbe930c8f9,369
mobile \ src \ main \ java \ com \ example \ android \ uamp \ MusicService . java \n + / * \n + * Handle case when user swipes the app away from the recents apps list by \n + * stopping the service ( and any ongoing playback ) . \n + * / \n + @ Override \n + public void onTaskRemoved ( Intent rootIntent ) { \n + super . onTaskRemoved ( rootIntent ) ; \n + stopSelf ( ) ; \n + } \n + \n,Stop playback when swipped from Android ' s recent list . \n Override onTaskRemoved to call stopSelf ( ) so playback stops when the \n user swipes away the UAMP task from the recent apps list . \n Bug : 19932661 \n Change - Id : I3a80be7e52033564b34f8d6089ff4a58bf47b535,369
build . gradle \n - classpath ' com . android . tools . build : gradle : 3 . 0 . 0 - beta3 ' \n + classpath ' com . android . tools . build : gradle : 2 . 3 . 3 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Mon Sep 11 10 : 00 : 07 PDT 2017 \n + # Thu Sep 14 09 : 56 : 35 PDT 2017 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 3 . 3 - all . zip \n,Revert gradle update until Studio 3 is stable . \n Change - Id : I4794c06a415f6f7614efac34e4007731ee4384eb,369
app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemAdapter . kt \n - import kotlinx . android . synthetic . main . fragment _ mediaitem . view . * \n + import kotlinx . android . synthetic . main . fragment _ mediaitem . view . albumbArt \n + import kotlinx . android . synthetic . main . fragment _ mediaitem . view . item _ state \n + import kotlinx . android . synthetic . main . fragment _ mediaitem . view . subtitle \n + import kotlinx . android . synthetic . main . fragment _ mediaitem . view . title \n app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemFragment . kt \n - import kotlinx . android . synthetic . main . fragment _ mediaitem _ list . * \n + import kotlinx . android . synthetic . main . fragment _ mediaitem _ list . list \n + import kotlinx . android . synthetic . main . fragment _ mediaitem _ list . loadingSpinner \n,"Remove ' * ' imports from the project . \n Don ' t import ' * ' , even for kotlinx . android . synthetic packages . \n Change - Id : I5dbf87a3144f5bf078858be211bf009fd1448f4b",369
"media \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + import android . os . Build \n - val notification = notificationBuilder . buildNotification ( sessionToken ! ! ) \n + / / Skip building a notification when state is "" none "" . \n + val notification = if ( updateState ! = PlaybackStateCompat . STATE _ NONE ) { \n + notificationBuilder . buildNotification ( sessionToken ! ! ) \n + } else { \n + null \n + } \n + \n - notificationManager . notify ( NOW _ PLAYING _ NOTIFICATION , notification ) \n + if ( notification ! = null ) { \n + notificationManager . notify ( NOW _ PLAYING _ NOTIFICATION , notification ) \n + } else { \n + removeNotification ( ) \n + } \n + private fun removeNotification ( ) { \n + / / On Kitkat ( and below ) , removing the notification is a bit different . \n + if ( Build . VERSION . SDK _ INT < Build . VERSION _ CODES . LOLLIPOP ) { \n + stopForeground ( true ) \n + } else { \n + notificationManager . cancelAll ( ) \n + } \n + } \n + \n + removeNotification ( ) \n",Fix crash on Kitkat devices . \n Fix a crash that occurs from an early callback of \n MusicService . updateState ( ) on API < = 19 devices . \n Change - Id : Id9432561b9b676f5d8045c884d1530eefca80a00,369
"media \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ MediaMetadataCompatExt . kt \n + import android . os . Bundle \n + import com . example . android . uamp . media . MusicService \n + inline val MediaMetadataCompat . downloadStatus \n + get ( ) = getLong ( MediaMetadataCompat . METADATA _ KEY _ DOWNLOAD _ STATUS ) \n + \n + inline var MediaMetadataCompat . Builder . downloadStatus : Long \n + @ Deprecated ( NO _ GET , level = DeprecationLevel . ERROR ) \n + get ( ) = throw IllegalAccessException ( "" Cannot get from MediaMetadataCompat . Builder "" ) \n + set ( value ) { \n + putLong ( MediaMetadataCompat . METADATA _ KEY _ DOWNLOAD _ STATUS , value ) \n + } \n + \n + / * * \n + * Custom property for retrieving a [ MediaDescriptionCompat ] which also includes \n + * all of the keys from the [ MediaMetadataCompat ] object in its extras . \n + * \n + * These keys are used by the ExoPlayer MediaSession extension when announcing metadata changes . \n + * / \n + inline val MediaMetadataCompat . fullDescription \n + get ( ) = \n + description . also { \n + it . extras ? . putAll ( bundle ) \n + } \n + \n - . setTag ( description ) \n + . setTag ( fullDescription ) \n media \ src \ main \ java \ com \ example \ android \ uamp \ media \ library \ JsonSource . kt \n + import android . support . v4 . media . MediaDescriptionCompat . STATUS _ NOT _ DOWNLOADED \n + import com . example . android . uamp . media . extensions . downloadStatus \n + / / Add downloadStatus to force the creation of an "" extras "" bundle in the resulting \n + / / MediaMetadataCompat object . This is needed to send accurate metadata to the \n + / / media session during updates . \n + downloadStatus = STATUS _ NOT _ DOWNLOADED \n + \n","Ensure metadata is propagated . \n This change works around a peculiarity in the ExoPlayer media session \n extension and how metadata is propagated . \n By including a download status , MediaMetadataCompat will create an \n "" extras "" bundle , which will then be included when retreiving \n its MediaDescriptionCompat ( with ` . getDescription ( ) ` ) \n This in turn allows the placing of * all * of the metadata from \n the MediaMetadataCompat into the MediaDescriptionCompat that \n ` . getDescription ( ) ` returns , which is then passed along to the \n media session as one would expect . \n This should fix the issue of album art not appearing on the \n lockscreen : GitHub issue \n [ # 227 ] ( https : / / github . com / googlesamples / android - UniversalMusicPlayer / issues / 227 ) . \n Change - Id : I924dfd8caf0166e60b9d405e769d8cfa7f2351dc",369
"app \ src \ main \ java \ com \ example \ android \ uamp \ MainActivity . kt \n - fragment = MediaItemFragment . newInstance ( mediaId ) \n + fragment = MediaItemFragment . newInstance ( mediaId ) { mediaItem - > \n + navigateToBrowser ( mediaItem . mediaId ) \n + } \n + \n app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemData . kt \n + import android . support . v4 . media . MediaBrowserCompat \n + import com . example . android . uamp . viewmodels . MediaItemFragmentViewModel \n + * \n + * If an item is [ browsable ] it means that it has a list of child media items that \n + * can be retrieved by passing the mediaId to [ MediaBrowserCompat . subscribe ] . \n + * \n + * Objects of this class are built from [ MediaItem ] s in \n + * [ MediaItemFragmentViewModel . subscriptionCallback ] . \n - data class MediaItemData ( val mediaId : String , \n - val title : String , \n - val subtitle : String , \n - val albumArtUri : Uri , \n - var playbackRes : Int ) { \n + data class MediaItemData ( \n + val mediaId : String , \n + val title : String , \n + val subtitle : String , \n + val albumArtUri : Uri , \n + val browsable : Boolean , \n + var playbackRes : Int ) { \n app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemFragment . kt \n + private lateinit var browsableItemClicked : ( MediaItemData ) - > Unit \n - mediaItemFragmentViewModel . playMedia ( clickedItem ) \n + if ( clickedItem . browsable ) { \n + browsableItemClicked ( clickedItem ) \n + } else { \n + mediaItemFragmentViewModel . playMedia ( clickedItem ) \n + } \n + \n - fun newInstance ( mediaId : String ) : MediaItemFragment { \n + fun newInstance ( \n + mediaId : String , \n + browsableItemClicked : ( MediaItemData ) - > Unit \n + ) : MediaItemFragment { \n + \n + this . browsableItemClicked = browsableItemClicked \n app \ src \ main \ java \ com \ example \ android \ uamp \ viewmodels \ MediaItemFragmentViewModel . kt \n + child . isBrowsable , \n",Add support for browsable media items . \n Change - Id : I776338fd9b77567eb853f0da3099fd50ab388014,369
"media \ src \ main \ AndroidManifest . xml \n + < ! - - Declare that UAMP supports Android Auto . - - > \n + < meta - data android : name = "" com . google . android . gms . car . application "" \n + android : resource = "" @ xml / automotive _ app _ desc "" / > \n + \n new file \n media \ src \ main \ res \ xml \ automotive _ app _ desc . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < ! - - \n + ~ Copyright 2018 Google Inc . All rights reserved . \n + ~ \n + ~ Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + ~ you may not use this file except in compliance with the License . \n + ~ You may obtain a copy of the License at \n + ~ \n + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + ~ \n + ~ Unless required by applicable law or agreed to in writing , software \n + ~ distributed under the License is distributed on an "" AS IS "" BASIS , \n + ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + ~ See the License for the specific language governing permissions and \n + ~ limitations under the License . \n + - - > \n + < automotiveApp > \n + < ! - - \n + ~ This lets Android Auto know that UAMP can act as a media app . \n + ~ See : https : / / developer . android . com / training / auto / audio / for more info . \n + - - > \n + < uses name = "" media "" / > \n + < / automotiveApp > \n",Add basic support for Android Auto . \n Change - Id : I79c30eab0d8db7873822bd6945df41b542efca46,369
media \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n - . apply { setSessionActivity ( sessionActivityPendingIntent ) } \n + . apply { \n + setSessionActivity ( sessionActivityPendingIntent ) \n + isActive = true \n + } \n - mediaSession . release ( ) \n + mediaSession . run { \n + isActive = false \n + release ( ) \n + } \n,"Activate MediaSession in UAMP \n Update code to ensure the session is set as "" active "" when the \n service starts , and inactive when the service is terminating . \n Change - Id : I778231524bcccf0cd45d913a9b06925b6659bff0",369
"README . md \n - Google + Community : https : / / plus . google . com / communities / 105153134372062985968 \n - Stack Overflow : http : / / stackoverflow . com / questions / tagged / android \n - If you ' ve found an error in this sample , please file an issue : \n - https : / / github . com / googlesamples / android - UniversalMusicPlayer / issues \n + If you ' ve found an error in this sample , please \n + [ file an issue ] ( https : / / github . com / googlesamples / android - UniversalMusicPlayer / issues ) \n - submitting a pull request through GitHub . Please see CONTRIBUTING . md for more details . \n + submitting a pull request through GitHub . Please see [ CONTRIBUTING . md ] ( CONTRIBUTING . md ) for more \n + details . \n - - - - - \n + - [ Irsen ' s Tale ] ( http : / / freemusicarchive . org / music / Kai _ Engel / Irsens _ Tale / ) by \n + [ Kai Engel ] ( http : / / freemusicarchive . org / music / Kai _ Engel / ) . \n - [ Wake Up ] ( http : / / freemusicarchive . org / music / The _ Kyoto _ Connection / Wake _ Up _ 1957 / ) by \n",Updates to the README . \n - Link CONTRIBUTING . md \n - Add link to Irsen ' s Tale & Kai Engel after including that album \n in the remote JSON . \n Change - Id : Ifa429d7d0df2ecc01765de839c33748399f69d43,369
"new file \n . google \ packaging . yaml \n + # GOOGLE SAMPLE PACKAGING DATA \n + # \n + # This file is used by Google as part of our samples packaging process . \n + # End users may safely ignore this file . It has no relevance to other systems . \n + - - - \n + status : PUBLISHED \n + technologies : [ Android , Android Auto , Android Wear ] \n + categories : [ Getting Started , Media , UI ] \n + languages : [ Kotlin ] \n + solutions : [ Mobile ] \n + \n + github : googlesamples / android - UniversalMusicPlayer \n + \n + level : INTERMEDIATE \n + \n + icon : screenshots / icon - web . png \n + \n + apiRefs : \n + - android : android . support . v4 . media . session . MediaSessionCompat \n + - android : android . support . v4 . media . session . MediaControllerCompat \n + - android : android . support . v4 . media . session . MediaBrowserServiceCompat \n + - android : android . support . v4 . media . MediaBrowserCompat \n + - android : android . support . v4 . media . app . NotificationCompat . MediaStyle \n + - android : com . google . android . exoplayer2 . SimpleExoPlayer \n + - android : com . google . android . exoplayer2 . ext . mediasession . MediaSessionConnector \n + \n + license : apache2 - android \n new file \n screenshots \ icon - web . png \n Binary files / dev / null and b / screenshots / icon - web . png differ \n",Add metadata for launch . \n - Updated language / packages in packaging . yaml \n - Include existing icon for Android Studio \n Change - Id : I0c48bc853fb18e2d044eb8ae8aad67b32b8906d2,369
"build . gradle \n - ext . exoplayer _ version = ' 2 . 8 . 1 ' \n + ext . exoplayer _ version = ' 2 . 8 . 4 ' \n + ext . gms _ strict _ version _ matcher _ version = ' 1 . 0 . 3 ' \n + ext . gradle _ version = ' 3 . 1 . 4 ' \n - ext . kotlin _ version = ' 1 . 2 . 50 ' \n + ext . kotlin _ version = ' 1 . 2 . 61 ' \n - classpath ' com . android . tools . build : gradle : 3 . 1 . 3 ' \n + classpath "" com . android . tools . build : gradle : $ gradle _ version "" \n + classpath "" com . google . android . gms : strict - version - matcher - plugin : $ gms _ strict _ version _ matcher _ version "" \n media \ build . gradle \n - / / customization . If the "" exoplayerRoot "" property is set , all of these modules \n - / / will be included in the project . \n - if ( project . ext . hasProperty ( ' exoplayerRoot ' ) & & project . ext . exoplayerRoot ! = null ) { \n + / / customization . If the "" : exoplayer - library - core "" project is included , we assume \n + / / the others are included as well . \n + if ( findProject ( ' : exoplayer - library - core ' ) ! = null ) { \n media \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + import android . support . v4 . media . MediaMetadataCompat \n - ExoPlayerFactory . newSimpleInstance ( DefaultRenderersFactory ( this ) , \n + ExoPlayerFactory . newSimpleInstance ( \n + DefaultRenderersFactory ( this ) , \n + override fun onMetadataChanged ( metadata : MediaMetadataCompat ? ) { \n + mediaController . playbackState ? . let { updateNotification ( it ) } \n + } \n + \n - val updatedState = state ? . state ? : return \n + state ? . let { updateNotification ( it ) } \n + } \n + \n + private fun updateNotification ( state : PlaybackStateCompat ) { \n + val updatedState = state . state \n + if ( mediaController . metadata = = null ) { \n + return \n + } \n","Minor version updates . \n - Mostly minor version updates to ExoPlayer , Gradle , and Kotlin runtime . \n - Minor updates to fix issues working with a locally built ExoPlayer . \n Change - Id : I17ff7672acb6d1d97fef52f0934b7c0d6d789fab",369
"app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemAdapter . kt \n - import com . example . android . uamp . MediaBrowserViewModel . Companion . EMPTY _ PLAYBACK _ STATE \n app \ src \ main \ res \ drawable \ media _ item _ background . xml \n - ~ Copyright 2017 Google Inc . All rights reserved . \n + ~ Copyright 2018 Google Inc . All rights reserved . \n app \ src \ main \ res \ drawable \ media _ item _ mask . xml \n - ~ Copyright 2017 Google Inc . All rights reserved . \n + ~ Copyright 2018 Google Inc . All rights reserved . \n app \ src \ main \ res \ layout \ fragment _ mediaitem _ list . xml \n + style = "" @ style / MediaItemList "" \n - android : background = "" @ color / mediaListBackground "" \n - android : paddingBottom = "" 2dp "" \n - android : paddingEnd = "" 3dp "" \n - android : paddingStart = "" 2dp "" \n - android : paddingTop = "" 2dp "" \n app \ src \ main \ res \ values \ styles . xml \n + < style name = "" MediaItemList "" > \n + < item name = "" android : background "" > @ color / mediaListBackground < / item > \n + < item name = "" android : paddingBottom "" > 2dp < / item > \n + < ! - - In order to account for optical illusions , \n + make the end padding a bit larger so it visually looks the same . - - > \n + < item name = "" android : paddingEnd "" > 3dp < / item > \n + < item name = "" android : paddingStart "" > 2dp < / item > \n + < item name = "" android : paddingTop "" > 2dp < / item > \n + < / style > \n + \n",Minor fixes . \n - Fixes an incorrect import in MediaItemAdapter \n - Fix copyright year on two new drawables to 2018 \n - Better document list padding \n Change - Id : Ic78b8a9295d204da0a562f0be8238bcb21abf391,369
"media \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + / * * \n + * This is the code that causes UAMP to stop playing when swiping it away from recents . \n + * The choice to do this is app specific . Some apps stop playback , while others allow playback \n + * to continue and allow uses to stop it with the notification . \n + * / \n - stopSelf ( ) \n + \n + / * * \n + * By stopping playback , the player will transition to [ Player . STATE _ IDLE ] . This will \n + * cause a state change in the MediaSession , and ( most importantly ) call \n + * [ MediaControllerCallback . onPlaybackStateChanged ] . Because the playback state will \n + * be reported as [ PlaybackStateCompat . STATE _ NONE ] , the service will first remove \n + * itself as a foreground service , and will then call [ stopSelf ] . \n + * / \n + exoPlayer . stop ( true ) \n - startForeground ( NOW _ PLAYING _ NOTIFICATION , notification ) \n - isForegroundService = true \n + / * * \n + * This may look strange , but the documentation for [ Service . startForeground ] \n + * notes that "" calling this method does * not * put the service in the started \n + * state itself , even though the name sounds like it . "" \n + * / \n + if ( ! isForegroundService ) { \n + startService ( Intent ( applicationContext , this @ MusicService . javaClass ) ) \n + startForeground ( NOW _ PLAYING _ NOTIFICATION , notification ) \n + isForegroundService = true \n + } else if ( notification ! = null ) { \n + notificationManager . notify ( NOW _ PLAYING _ NOTIFICATION , notification ) \n + } \n + isForegroundService = false \n + \n + / / If playback has ended , also stop the service . \n + if ( updatedState = = PlaybackStateCompat . STATE _ NONE ) { \n + stopSelf ( ) \n + } \n - isForegroundService = false \n","Fix GitHub issue # 250 \n MusicService wasn ' t getting started , leading to a situation where the \n service would be killed and the ExoPlayer playback thread would continue \n to play queued songs until it was also killed or it completed the queue . \n This change ensures the service is started when playback begins so that \n the client may unbind without service being killed immediately . \n Change - Id : Ib4a846c2e60d3f0644b0b5843d1815dbd3caef68",369
"media \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + PlaybackStateCompat . ACTION _ STOP or \n + PlaybackStateCompat . ACTION _ STOP or \n + / / These are the actions supported when the player is stopped . \n + private val supportedActionsStopped = \n + PlaybackStateCompat . ACTION _ PLAY _ PAUSE or \n + PlaybackStateCompat . ACTION _ PLAY \n + \n - playback = Playback ( applicationContext ) { playerState - > \n - updateState ( playerState ) \n - } \n + playback = buildPlayback ( ) \n + private fun buildPlayback ( ) : Playback { \n + return Playback ( applicationContext ) { playerState - > \n + updateState ( playerState ) \n + } \n + } \n + \n + PlaybackStateCompat . STATE _ STOPPED - > supportedActionsStopped \n + / / Stop requires a bit of special handling , since the player was released . \n + if ( updateState = = PlaybackStateCompat . STATE _ STOPPED ) { \n + playback = buildPlayback ( ) \n + } \n + \n - override fun onStop ( ) = Unit \n + override fun onStop ( ) { \n + playback . stop ( ) \n + } \n media \ src \ main \ java \ com \ example \ android \ uamp \ media \ Playback . kt \n - class Playback ( val context : Context , val stateUpdates : ( Int ) - > Unit ) { \n - val nothingPlaying = MediaMetadataCompat . Builder ( ) \n + class Playback ( val context : Context , private val stateUpdates : ( Int ) - > Unit ) { \n + private val nothingPlaying = MediaMetadataCompat . Builder ( ) \n - \n - private val exoPlayer : SimpleExoPlayer = \n - ExoPlayerFactory . newSimpleInstance ( DefaultRenderersFactory ( context ) , \n - DefaultTrackSelector ( ) , \n - DefaultLoadControl ( ) ) \n + \n + / / Use lazy initialization of the player so it doesn ' t take up any resources until something \n + / / is about to be played . \n + private val exoPlayer : SimpleExoPlayer by lazy { \n + ExoPlayerFactory . newSimpleInstance ( DefaultRenderersFactory ( context ) , \n + DefaultTrackSelector ( ) , \n + DefaultLoadControl ( ) ) \n + . apply { \n + addListener ( playerListener ) \n + } \n + } \n - this @ Playback . pause ( ) \n - exoPlayer . seekTo ( 0 ) \n + this @ Playback . stop ( ) \n - init { \n - exoPlayer . addListener ( playerListener ) \n - } \n - \n + fun stop ( ) { \n + pause ( ) \n + exoPlayer . release ( ) \n + \n + updatePlaybackState ( PlaybackStateCompat . STATE _ STOPPED ) \n + } \n + \n","Add support for "" stop "" . \n This adds support for a "" stop "" from the transport controls , which \n requests the player to release its resources . \n Change - Id : If8d20d64ebf7b17c109cd5890af59c23bec2a98f",369
"media \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ JavaLangExt . kt \n + import java . nio . charset . Charset \n - get ( ) = URLEncoder . encode ( this ? : "" "" , java . nio . charset . StandardCharsets . UTF _ 8 . toString ( ) ) \n + get ( ) = if ( Charset . isSupported ( "" UTF - 8 "" ) ) { \n + URLEncoder . encode ( this ? : "" "" , "" UTF - 8 "" ) \n + } else { \n + / / If UTF - 8 is not supported , use the default charset . \n + @ Suppress ( "" deprecation "" ) \n + URLEncoder . encode ( this ? : "" "" ) \n + } \n","Fix for Github issue # 233 \n On certain versions of Android , UAMP would throw an IllegalCharsetNameException \n when trying to encode a URL using "" UTF - 8 "" for the character encoding . \n In order to prevent the exception , add a check for UTF - 8 support , and \n if it is not supported , fallback to the default encoding . \n Change - Id : I9aff8fff91eb41c1da013be0e5027d131b5417f4",369
app \ src \ main \ java \ com \ example \ android \ uamp \ viewmodels \ MainActivityViewModel . kt \n + import com . example . android . uamp . media . extensions . isPrepared \n - if ( mediaItem . mediaId = = nowPlaying ? . id ) { \n + val isPrepared = mediaSessionConnection . playbackState . value ? . isPrepared ? : false \n + if ( isPrepared & & mediaItem . mediaId = = nowPlaying ? . id ) { \n media \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ PlaybackStateCompatExt . kt \n + inline val PlaybackStateCompat . isPrepared \n + get ( ) = ( state = = PlaybackStateCompat . STATE _ BUFFERING ) | | \n + ( state = = PlaybackStateCompat . STATE _ PLAYING ) | | \n + ( state = = PlaybackStateCompat . STATE _ PAUSED ) \n + \n,"Fix for # 231 \n This is a temporary fix for an issue where the metadata of the \n currently playing item isn ' t updated when the player is stopped . \n This change just makes sure that , if the player isn ' t "" prepared "" \n ( buffering , playing , or paused ) , it will send ` playFromMediaId ( ) ` \n rather than ` play ( ) ` when selecting an item . \n Change - Id : I35d1ea625c286f67eedad95062980b834443cf4e",369
"build . gradle \n - ext . constraint _ layout _ version = ' 1 . 1 . 2 ' \n - ext . exoplayer _ version = ' 2 . 9 . 0 ' \n - ext . glide _ version = ' 4 . 7 . 1 ' \n + ext . constraint _ layout _ version = ' 1 . 1 . 3 ' \n + ext . exoplayer _ version = ' 2 . 9 . 1 ' \n + ext . glide _ version = ' 4 . 8 . 0 ' \n - classpath "" com . android . tools . build : gradle : 3 . 2 . 0 "" \n + classpath ' com . android . tools . build : gradle : 3 . 2 . 1 ' \n",Update dependency versions . \n Change - Id : If3248300c6277042f18ad44c918aa5b9c4e1978f,369
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ PlaybackStateCompatExt . kt \n + import android . os . SystemClock \n + / * * \n + * Calculates the current playback position based on last update time along with playback \n + * state and speed . \n + * / \n + inline val PlaybackStateCompat . currentPlayBackPosition : Long \n + get ( ) = if ( state = = PlaybackStateCompat . STATE _ PLAYING ) { \n + val timeDelta = SystemClock . elapsedRealtime ( ) - lastPositionUpdateTime \n + ( position + ( timeDelta * playbackSpeed ) ) . toLong ( ) \n + } else { \n + position \n + } \n + \n,"Add currentPlayBackPosition to PlaybackStateCompat \n This adds an extension property to PlaybackStateCompat that calculates \n the current playback position based on playback state , rate , and last \n update time . \n Change - Id : I79189dc6db7ebdc94f107b497d6b00411dc6c6ef",369
"app \ build . gradle \n - implementation "" androidx . legacy : legacy - support - v4 : $ androidx _ version "" \n - implementation "" androidx . recyclerview : recyclerview : $ androidx _ version "" \n + implementation "" androidx . recyclerview : recyclerview : $ recycler _ view _ version "" \n build . gradle \n + androidx _ media _ version = ' 1 . 0 . 1 ' \n + androidx _ app _ compat _ version = ' 1 . 0 . 2 ' \n - exoplayer _ version = ' 2 . 9 . 1 ' \n + exoplayer _ version = ' 2 . 9 . 6 ' \n - androidx _ version = ' 1 . 0 . 0 ' \n - androidx _ app _ compat _ version = ' 1 . 0 . 2 ' \n + recycler _ view _ version = ' 1 . 0 . 0 ' \n common \ build . gradle \n - api "" androidx . legacy : legacy - support - core - ui : $ androidx _ version "" \n - api "" androidx . media : media : $ androidx _ version "" \n + api "" androidx . media : media : $ androidx _ media _ version "" \n common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + import kotlinx . coroutines . ExperimentalCoroutinesApi \n + @ ExperimentalCoroutinesApi \n",Update dependencies . \n - ExoPlayer - > 2 . 9 . 6 \n - Media - > 1 . 0 . 1 \n Added @ ExperimentalCoroutinesApi to [ MusicService . onCreate ] to address a \n warning in Android Studio . \n Change - Id : I42e81b3dad42a9e0341d230bb8bc410da6812b61,369
". google \ packaging . yaml \n - - - \n - technologies : [ Android , Android Auto , Android Wear ] \n + technologies : [ Android , Android Auto , Android Automotive OS , Android Wear ] \n - android : android . support . v4 . media . session . MediaSessionCompat \n - android : android . support . v4 . media . session . MediaControllerCompat \n - - android : android . support . v4 . media . session . MediaBrowserServiceCompat \n + - androidx . media . MediaBrowserServiceCompat \n - android : android . support . v4 . media . MediaBrowserCompat \n - - android : android . support . v4 . media . app . NotificationCompat . MediaStyle \n + - androidx . media . app . NotificationCompat . MediaStyle \n - android : com . google . android . exoplayer2 . SimpleExoPlayer \n - android : com . google . android . exoplayer2 . ext . mediasession . MediaSessionConnector \n",Update metadata \n Update API references to refer to androidx classes . \n Add Android Automotive OS to the tech . \n Change - Id : Ie67b3321fae880c44a083b806973bd1c0b8dea04,369
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ library \ JsonSource . kt \n - val end = System . currentTimeMillis ( ) + 5000 \n - while ( System . currentTimeMillis ( ) < end ) { \n - / / blah \n - } \n - \n,Remove debugging code . \n Change - Id : Ib4ca81bd0d5fbb41931267a4dc2307e16ec42956,369
rename from aae \ src \ main \ java \ LoginActivity . kt \n rename to aae \ src \ main \ java \ com \ example \ aae \ LoginActivity . kt \n - * Copyright 2019 Google Inc . All rights reserved . \n + * Copyright 2019 Google LLC \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - package com . example . android . uamp \n + package com . example . aae \n rename from aae \ src \ main \ java \ SettingsActivity . kt \n rename to aae \ src \ main \ java \ com \ example \ aae \ SettingsActivity . kt \n - * Copyright 2019 Google Inc . All rights reserved . \n + * Copyright 2019 Google LLC \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - package com . example . android . uamp \n + package com . example . aae \n rename from aae \ src \ main \ java \ SettingsFragment . kt \n rename to aae \ src \ main \ java \ com \ example \ aae \ SettingsFragment . kt \n - package com . example . android . uamp \n + package com . example . aae \n,Move AAE code into the aae folder . \n Change - Id : I2f8b1dc31993efba6856f888ad00cc34a0a49505,369
build . gradle \n - androidx _ app _ compat _ version = ' 1 . 0 . 2 ' \n + androidx _ app _ compat _ version = ' 1 . 1 . 0 - alpha04 ' \n - classpath ' com . android . tools . build : gradle : 3 . 3 . 2 ' \n + classpath ' com . android . tools . build : gradle : 3 . 4 . 0 - rc03 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Fri Nov 30 15 : 06 : 19 PST 2018 \n + # Fri Apr 05 13 : 12 : 50 PDT 2019 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 10 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 1 . 1 - all . zip \n,Update to Android Studio 3 . 4 \n Change - Id : I27ed8ae3e638d82f259a9da26e53051718522a8e,369
"build . gradle \n + robolectric _ version = ' 4 . 2 ' \n common \ build . gradle \n + testOptions . unitTests . includeAndroidResources = true \n - androidTestImplementation "" androidx . test : runner : $ test _ runner _ version "" \n + testImplementation "" junit : junit : $ junit _ version "" \n + testImplementation "" org . robolectric : robolectric : $ robolectric _ version "" \n rename from common \ src \ androidTest \ java \ com \ example \ android \ uamp \ media \ library \ MusicSourceTest . kt \n rename to common \ src \ test \ java \ com \ example \ android \ uamp \ media \ library \ MusicSourceTest . kt \n - import androidx . test . runner . AndroidJUnit4 \n - import junit . framework . Assert \n - import org . junit . Before \n + import org . junit . Assert \n + import org . robolectric . RobolectricTestRunner \n - @ RunWith ( AndroidJUnit4 : : class ) \n + @ RunWith ( RobolectricTestRunner : : class ) \n - override suspend fun load ( ) { \n - TODO ( \n - "" not implemented "" \n - ) / / To change body of created functions use File | Settings | File Templates . \n - } \n + override suspend fun load ( ) = Unit \n gradle . properties \n + # Required by Robolectric . \n + android . enableUnitTestBinaryResources = true \n + \n",Convert to Robolectric . \n Change - Id : I3b410c8a7aeb53fa2a6d33860bc1e9d0b7a798e3,369
"app \ src \ main \ java \ com \ example \ android \ uamp \ viewmodels \ MediaItemFragmentViewModel . kt \n - _ mediaItems . postValue ( updateState ( playbackState , metadata ) ) \n + if ( metadata . getString ( MediaMetadataCompat . METADATA _ KEY _ MEDIA _ ID ) ! = null ) { \n + _ mediaItems . postValue ( updateState ( playbackState , metadata ) ) \n + } \n - _ mediaItems . postValue ( updateState ( playbackState , metadata ) ) \n + if ( metadata . getString ( MediaMetadataCompat . METADATA _ KEY _ MEDIA _ ID ) ! = null ) { \n + _ mediaItems . postValue ( updateState ( playbackState , metadata ) ) \n + } \n app \ src \ main \ res \ layout \ fragment _ nowplaying . xml \n - android : id = "" @ + id / albumbArt "" \n + android : id = "" @ + id / albumArt "" \n build . gradle \n - exoplayer _ version = ' 2 . 10 . 0 - alpha1 ' \n + exoplayer _ version = ' 2 . 10 . 0 ' \n",Minor fixes before publish . \n - Fix typo of ' albumArt ' \n - Update to ExoPlayer 2 . 10 . 0 release ( from alpha ) \n Change - Id : Ia7792aabbfc97ee90e8ec13eab2de799b6a578c9,369
"rename from aae \ src \ androidTest \ java \ com \ example \ aae \ ExampleInstrumentedTest . java \n rename to aae \ src \ androidTest \ java \ com \ example \ android \ uamp \ aae \ ExampleInstrumentedTest . java \n - package com . example . aae ; \n + package com . example . android . uamp . aae ; \n aae \ src \ main \ AndroidManifest . xml \n - package = "" com . example . aae "" > \n + package = "" com . example . android . uamp . aae "" > \n rename from aae \ src \ main \ java \ com \ example \ aae \ AaeMusicService . kt \n rename to aae \ src \ main \ java \ com \ example \ android \ uamp \ aae \ AaeMusicService . kt \n - package com . example . aae \n + package com . example . android . uamp . aae \n rename from aae \ src \ main \ java \ com \ example \ aae \ LoginActivity . kt \n rename to aae \ src \ main \ java \ com \ example \ android \ uamp \ aae \ LoginActivity . kt \n - package com . example . aae \n + package com . example . android . uamp . aae \n rename from aae \ src \ main \ java \ com \ example \ aae \ SettingsActivity . kt \n rename to aae \ src \ main \ java \ com \ example \ android \ uamp \ aae \ SettingsActivity . kt \n - package com . example . aae \n + package com . example . android . uamp . aae \n rename from aae \ src \ main \ java \ com \ example \ aae \ SettingsFragment . kt \n rename to aae \ src \ main \ java \ com \ example \ android \ uamp \ aae \ SettingsFragment . kt \n - package com . example . aae \n + package com . example . android . uamp . aae \n rename from aae \ src \ test \ java \ com \ example \ aae \ ExampleUnitTest . java \n rename to aae \ src \ test \ java \ com \ example \ android \ uamp \ aae \ ExampleUnitTest . java \n - package com . example . aae ; \n + package com . example . android . uamp . aae ; \n",Fix AAE package name . \n Change - Id : I67b4e5bc0e65e083cf6b8ef613b7a4de9eccfa38,369
"common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n + import androidx . core . content . ContextCompat \n + notificationManager . notify ( NOW _ PLAYING _ NOTIFICATION , notification ) \n + \n - startService ( Intent ( applicationContext , this @ MusicService . javaClass ) ) \n + ContextCompat . startForegroundService ( \n + applicationContext , \n + Intent ( applicationContext , this @ MusicService . javaClass ) \n + ) \n - } else { \n - notificationManager . notify ( NOW _ PLAYING _ NOTIFICATION , notification ) \n","Minor update to start the service \n It ' s recommended to use ContextCompat . startForegroundService to start a \n foreground service , which works across all API levels . \n Change - Id : Ia1390ee96877bb214d9d02fdb6deb53621134a22",369
app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemAdapter . kt \n - ) : androidx . recyclerview . widget . RecyclerView . ViewHolder ( view ) { \n + ) : RecyclerView . ViewHolder ( view ) { \n app \ src \ main \ java \ com \ example \ android \ uamp \ MediaItemFragment . kt \n + import androidx . fragment . app . Fragment \n - class MediaItemFragment : androidx . fragment . app . Fragment ( ) { \n + class MediaItemFragment : Fragment ( ) { \n common \ src \ main \ java \ com \ example \ android \ uamp \ media \ MusicService . kt \n - class MusicService : androidx . media . MediaBrowserServiceCompat ( ) { \n + class MusicService : MediaBrowserServiceCompat ( ) { \n,"Minor cleanup . \n The "" Convert to AndroidX "" converter in Stuio sometimes puts fully \n qualified class names in the code . Clean those up to use the usual \n naming . \n Change - Id : I5b7fc4d7c75c58e968e2acc7f114e5d0fa4e5609",369
common \ src \ main \ java \ com \ example \ android \ uamp \ media \ extensions \ JavaLangExt . kt \n + import java . util . Locale \n - if ( this = = null & & other = = null ) { \n - true \n - } else if ( this ! = null & & other ! = null ) { \n - toLowerCase ( ) . contains ( other . toLowerCase ( ) ) \n + if ( this ! = null & & other ! = null ) { \n + toLowerCase ( Locale . getDefault ( ) ) . contains ( other . toLowerCase ( Locale . getDefault ( ) ) ) \n - false \n + this = = other \n,Simplify ` containsCaseInsensitive ` \n Fixes # 293,369
"common \ src \ main \ java \ com \ example \ android \ uamp \ media \ PackageValidator . kt \n - private val certificateWhitelist : Map < String , KnownCallerInfo > \n + private val certificateAllowList : Map < String , KnownCallerInfo > \n - certificateWhitelist = buildCertificateWhitelist ( parser ) \n + certificateAllowList = buildCertificateAllowList ( parser ) \n - val isPackageInWhitelist = certificateWhitelist [ callingPackage ] ? . signatures ? . first { \n + val isPackageInAllowList = certificateAllowList [ callingPackage ] ? . signatures ? . first { \n - / / If it ' s one of the apps on the whitelist , allow it . \n - isPackageInWhitelist - > true \n + / / If it ' s one of the apps on the allow list , allow it . \n + isPackageInAllowList - > true \n - * This requests both the signatures ( for checking if an app is on the whitelist ) and \n - * the app ' s permissions , which allow for more flexibility in the whitelist . \n + * This requests both the signatures ( for checking if an app is on the allow list ) and \n + * the app ' s permissions , which allow for more flexibility in the allow list . \n - private fun buildCertificateWhitelist ( parser : XmlResourceParser ) : Map < String , KnownCallerInfo > { \n + private fun buildCertificateAllowList ( parser : XmlResourceParser ) : Map < String , KnownCallerInfo > { \n - val certificateWhitelist = LinkedHashMap < String , KnownCallerInfo > ( ) \n + val certificateAllowList = LinkedHashMap < String , KnownCallerInfo > ( ) \n - val existingCallerInfo = certificateWhitelist [ packageName ] \n + val existingCallerInfo = certificateAllowList [ packageName ] \n - certificateWhitelist [ packageName ] = callerInfo \n + certificateAllowList [ packageName ] = callerInfo \n - return certificateWhitelist \n + return certificateAllowList \n common \ src \ main \ java \ com \ example \ android \ uamp \ media \ library \ BrowseTree . kt \n - * Whether to allow clients which are unknown ( non - whitelisted ) to use search on this \n + * Whether to allow clients which are unknown ( not on the allow listed ) to use search on this \n","Switch UAMP to use a better named "" allow list "" \n To support a more precise meaning and be more inclusive .",369
"app \ src \ main \ AndroidManifest . xml \n + \n + < intent - filter > \n + < action android : name = "" android . media . action . MEDIA _ PLAY _ FROM _ SEARCH "" / > \n + < / intent - filter > \n - < intent - filter > \n - < action android : name = "" android . media . action . MEDIA _ PLAY _ FROM _ SEARCH "" / > \n - < / intent - filter > \n","Fix for voice commands not working \n Moved ` action . MEDIA _ PLAY _ FROM _ SEARCH ` to ` MainActivity ` from \n ` MusicService ` ( Thanks for the hint , @ orcunkobal ! ) \n ( Hopefully ) fixes # 381",369
"buffer \ src \ main \ java \ io \ netty \ buffer \ UnpooledDirectByteBuf . java \n - * A NIO { @ link ByteBuffer } based buffer . It is recommended to use { @ link Unpooled # directBuffer ( int ) } \n - * and { @ link Unpooled # wrappedBuffer ( ByteBuffer ) } instead of calling the \n - * constructor explicitly . \n + * A NIO { @ link ByteBuffer } based buffer . It is recommended to use \n + * { @ link UnpooledByteBufAllocator # directBuffer ( int , int ) } , { @ link Unpooled # directBuffer ( int ) } and \n + * { @ link Unpooled # wrappedBuffer ( ByteBuffer ) } instead of calling the constructor explicitly . \n - protected UnpooledDirectByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n + public UnpooledDirectByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n buffer \ src \ main \ java \ io \ netty \ buffer \ UnpooledHeapByteBuf . java \n - * Big endian Java heap buffer implementation . \n + * Big endian Java heap buffer implementation . It is recommended to use \n + * { @ link UnpooledByteBufAllocator # heapBuffer ( int , int ) } , { @ link Unpooled # buffer ( int ) } and \n + * { @ link Unpooled # wrappedBuffer ( byte [ ] ) } instead of calling the constructor explicitly . \n - protected UnpooledHeapByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n + public UnpooledHeapByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n buffer \ src \ main \ java \ io \ netty \ buffer \ UnpooledUnsafeDirectByteBuf . java \n - * A NIO { @ link ByteBuffer } based buffer . It is recommended to use { @ link Unpooled # directBuffer ( int ) } \n - * and { @ link Unpooled # wrappedBuffer ( ByteBuffer ) } instead of calling the \n - * constructor explicitly . \n + * A NIO { @ link ByteBuffer } based buffer . It is recommended to use \n + * { @ link UnpooledByteBufAllocator # directBuffer ( int , int ) } , { @ link Unpooled # directBuffer ( int ) } and \n + * { @ link Unpooled # wrappedBuffer ( ByteBuffer ) } instead of calling the constructor explicitly . } \n - protected UnpooledUnsafeDirectByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n + public UnpooledUnsafeDirectByteBuf ( ByteBufAllocator alloc , int initialCapacity , int maxCapacity ) { \n","Make UnpooledDirectByteBuf , UnpooledHeapByteBuf and UnpooledUnsafeDirectByteBuf constructors public . \n Motivation : \n The constrcutors a protected atm but the classes are public . We should make the constructors public as well to make it easier to write your own ByteBufAllocator . \n Modifications : \n Change constructors to be public and add some javadocs . \n Result : \n Easier to create own ByteBufAllocator .",381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - ctx , connection ( ) , decoder ( ) . frameListener ( ) , upgrade . upgradeRequest ( ) ) ; \n + ctx , connection ( ) , decoder ( ) . frameListener ( ) , upgrade . upgradeRequest ( ) . retain ( ) ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodecTest . java \n + import io . netty . handler . codec . http . DefaultFullHttpRequest ; \n + import io . netty . handler . codec . http . FullHttpRequest ; \n + import io . netty . handler . codec . http . HttpServerUpgradeHandler ; \n + import io . netty . handler . codec . http . HttpVersion ; \n + import org . mockito . invocation . InvocationOnMock ; \n + import org . mockito . stubbing . Answer ; \n + @ Test \n + public void upgradeEventNoRefCntError ( ) throws Http2Exception { \n + frameListener . onHeadersRead ( http2HandlerCtx , Http2CodecUtil . HTTP _ UPGRADE _ STREAM _ ID , request , 31 , false ) ; \n + \n + final FullHttpRequest request = new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . GET , "" / "" ) ; \n + final HttpServerUpgradeHandler . UpgradeEvent upgradeEvent = mock ( HttpServerUpgradeHandler . UpgradeEvent . class ) ; \n + when ( upgradeEvent . retain ( ) ) . thenAnswer ( new Answer < HttpServerUpgradeHandler . UpgradeEvent > ( ) { \n + @ Override \n + public HttpServerUpgradeHandler . UpgradeEvent answer ( InvocationOnMock invocationOnMock ) throws Throwable { \n + request . retain ( ) ; \n + return upgradeEvent ; \n + } \n + } ) ; \n + when ( upgradeEvent . release ( ) ) . thenAnswer ( new Answer < Boolean > ( ) { \n + @ Override \n + public Boolean answer ( InvocationOnMock invocationOnMock ) throws Throwable { \n + return request . release ( ) ; \n + } \n + } ) ; \n + \n + when ( upgradeEvent . upgradeRequest ( ) ) . thenReturn ( request ) ; \n + channel . pipeline ( ) . fireUserEventTriggered ( upgradeEvent ) ; \n + assertEquals ( 1 , request . refCnt ( ) ) ; \n + } \n + \n new file \n codec - http2 \ src \ test \ resources \ mockito - extensions \ org . mockito . plugins . MockMaker \n + mock - maker - inline \n",Fix reference count issue when using Http2FrameCodec / Http2MultiplexCodec with HttpServerUpgradeHandler \n Motivation : \n When using Http2FrameCodec / Http2MultiplexCodec with HttpServerUpgradeHandler reference count exception will be triggered . \n Modifications : \n - Correctly retain before calling InboundHttpToHttp2Adapter . handle \n - Add unit test \n Result : \n Fixes [ # 7172 ] .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - if ( rejectRemoteInitiatedRenegotiation & & SSL . getHandshakeCount ( ssl ) > 1 ) { \n + / / As rejectRemoteInitiatedRenegotiation ( ) is called in a finally block we also need to check if we shutdown \n + / / the engine before as otherwise SSL . getHandshakeCount ( ssl ) will throw an NPE if the passed in ssl is 0 . \n + / / See https : / / github . com / netty / netty / issues / 7353 \n + if ( rejectRemoteInitiatedRenegotiation & & ! isDestroyed ( ) & & SSL . getHandshakeCount ( ssl ) > 1 ) { \n,Fix possible NPE in ReferenceCountedOpenSslEngine . rejectRemoteInitiatedRenegotiation ( ) \n Motivation : \n ReferenceCountedOpenSslEngine . rejectRemoteInitiatedRenegotiation ( ) is called in a finally block to ensure we always check for renegotiation . The problem here is that sometimes we will already shutdown the engine before we call the method which will lead to an NPE in this case as the ssl pointer was already destroyed . \n Modifications : \n Check that the engine is not destroyed yet before calling SSL . getHandshakeCount ( . . . ) \n Result : \n Fixes [ # 7353 ] .,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ HttpClientCodec . java \n - return true ; \n + / / Just delegate to super method which has all the needed handling . \n + return super . isContentAlwaysEmpty ( msg ) ; \n - / / All responses to the HEAD request getMethod MUST NOT include a \n + / / All responses to the HEAD request method MUST NOT include a \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpClientCodecTest . java \n - import static org . hamcrest . CoreMatchers . instanceOf ; \n + import static org . hamcrest . CoreMatchers . * ; \n - import static org . junit . Assert . assertFalse ; \n - import static org . junit . Assert . assertNotNull ; \n - import static org . junit . Assert . assertNull ; \n - import static org . junit . Assert . assertThat ; \n - import static org . junit . Assert . assertTrue ; \n - import static org . junit . Assert . fail ; \n + import static org . junit . Assert . * ; \n + \n + @ Test \n + public void testWebSocket00Response ( ) { \n + byte [ ] data = ( "" HTTP / 1 . 1 101 WebSocket Protocol Handshake \ r \ n "" + \n + "" Upgrade : WebSocket \ r \ n "" + \n + "" Connection : Upgrade \ r \ n "" + \n + "" Sec - WebSocket - Origin : http : / / localhost : 8080 \ r \ n "" + \n + "" Sec - WebSocket - Location : ws : / / localhost / some / path \ r \ n "" + \n + "" \ r \ n "" + \n + "" 1234567812345678 "" ) . getBytes ( ) ; \n + EmbeddedChannel ch = new EmbeddedChannel ( new HttpClientCodec ( ) ) ; \n + assertTrue ( ch . writeInbound ( Unpooled . wrappedBuffer ( data ) ) ) ; \n + \n + HttpResponse res = ch . readInbound ( ) ; \n + assertThat ( res . protocolVersion ( ) , sameInstance ( HttpVersion . HTTP _ 1 _ 1 ) ) ; \n + assertThat ( res . status ( ) , is ( HttpResponseStatus . SWITCHING _ PROTOCOLS ) ) ; \n + HttpContent content = ch . readInbound ( ) ; \n + assertThat ( content . content ( ) . readableBytes ( ) , is ( 16 ) ) ; \n + content . release ( ) ; \n + \n + assertThat ( ch . finish ( ) , is ( false ) ) ; \n + \n + assertThat ( ch . readInbound ( ) , is ( nullValue ( ) ) ) ; \n + } \n",Correctly handle WebSockets 00 when using HttpClientCodec . \n Motivation : \n 7995afee8f1cb9047709239321d84ccb279fe4d1 introduced a change that broke special handling of WebSockets 00 . \n Modifications : \n Correctly delegate to super method which has special handling for WebSockets 00 . \n Result : \n Fixes [ # 7362 ] .,381
pom . xml \n - < conscrypt . version > 1 . 0 . 0 . RC11 < / conscrypt . version > \n + < conscrypt . version > 1 . 0 . 0 . RC13 < / conscrypt . version > \n,Update to conscrypt 1 . 0 . 0 . CR13 \n Motivation : \n New version on conscrypt was released . \n Modifications : \n Update to latest version \n Result : \n Up to date conscrypt is used .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2RemoteFlowController . java \n - * Note that this only takes into account HTTP / 2 flow control . It does < strong > not < / strong > take into account \n - * the underlying { @ link io . netty . channel . Channel # isWritable ( ) } . \n + * Note that this method respects channel writability . The channel must be writable for this method to \n + * return { @ code true } . \n + * \n - * @ return { @ code true } if if the { @ code stream } has bytes remaining for use in the flow control window . \n - * { @ code false } otherwise . \n + * @ return { @ code true } if the { @ code stream } has bytes remaining for use in the flow control window and the \n + * channel is writable , { @ code false } otherwise . \n",Fix incorrect javadocs in Http2RemoteFlowController \n Motivation : \n The javadocs of Http2RemoteFlowController . isWritable ( . . . ) are incorrect . \n Modifications : \n Update javadocs to reflect reality . \n Result : \n Correct javadocs .,381
pom . xml \n - < asm . version > 6 . 0 _ ALPHA < / asm . version > \n + < asm . version > 6 . 0 _ BETA < / asm . version > \n,asm 6 . 0 _ BETA was released so we should use it when building on java9 \n Motivation : \n We used asm 6 . 0 _ ALPHA when building on java9 as the latest stable release not works with java9 . asm 6 . 0 _ BETA was just released so we should update . \n Modifications : \n Upgrade asm version \n Result : \n Not use ALPHA release anymore,381
"codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodecTest . java \n + import io . netty . handler . codec . http . HttpServerUpgradeHandler . UpgradeEvent ; \n + import io . netty . util . internal . ReflectionUtil ; \n + import org . junit . Assume ; \n - import org . mockito . invocation . InvocationOnMock ; \n - import org . mockito . stubbing . Answer ; \n + import java . lang . reflect . Constructor ; \n - public void upgradeEventNoRefCntError ( ) throws Http2Exception { \n + public void upgradeEventNoRefCntError ( ) throws Exception { \n - final FullHttpRequest request = new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . GET , "" / "" ) ; \n - final HttpServerUpgradeHandler . UpgradeEvent upgradeEvent = mock ( HttpServerUpgradeHandler . UpgradeEvent . class ) ; \n - when ( upgradeEvent . retain ( ) ) . thenAnswer ( new Answer < HttpServerUpgradeHandler . UpgradeEvent > ( ) { \n - @ Override \n - public HttpServerUpgradeHandler . UpgradeEvent answer ( InvocationOnMock invocationOnMock ) throws Throwable { \n - request . retain ( ) ; \n - return upgradeEvent ; \n - } \n - } ) ; \n - when ( upgradeEvent . release ( ) ) . thenAnswer ( new Answer < Boolean > ( ) { \n - @ Override \n - public Boolean answer ( InvocationOnMock invocationOnMock ) throws Throwable { \n - return request . release ( ) ; \n - } \n - } ) ; \n + / / Using reflect as the constructor is package - private and the class is final . \n + Constructor < UpgradeEvent > constructor = \n + UpgradeEvent . class . getDeclaredConstructor ( CharSequence . class , FullHttpRequest . class ) ; \n + \n + / / Check if we could make it accessible which may fail on java9 . \n + Assume . assumeTrue ( ReflectionUtil . trySetAccessible ( constructor ) = = null ) ; \n - when ( upgradeEvent . upgradeRequest ( ) ) . thenReturn ( request ) ; \n + HttpServerUpgradeHandler . UpgradeEvent upgradeEvent = constructor . newInstance ( \n + "" HTTP / 2 "" , new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . GET , "" / "" ) ) ; \n - assertEquals ( 1 , request . refCnt ( ) ) ; \n + assertEquals ( 1 , upgradeEvent . refCnt ( ) ) ; \n deleted file \n codec - http2 \ src \ test \ resources \ mockito - extensions \ org . mockito . plugins . MockMaker \n - mock - maker - inline \n",Ensure the tests complete on java7 and java9 as well . \n Motivation : \n 379ac890f4dbec15d19714711f85455a12112c3f introduced the usage of the inline mock maker . This unfortunally not work on java7 and java9 . \n Modifications : \n Just use reflection to create the event for now . \n Result : \n Netty tests pass again on java7 and java9 as well .,381
"transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollDatagramChannel . java \n - private final List < Object > readBuf = new ArrayList < Object > ( ) ; \n - readBuf . add ( new DatagramPacket ( data , ( InetSocketAddress ) localAddress ( ) , remoteAddress ) ) ; \n + readPending = false ; \n + pipeline . fireChannelRead ( \n + new DatagramPacket ( data , ( InetSocketAddress ) localAddress ( ) , remoteAddress ) ) ; \n + \n - int size = readBuf . size ( ) ; \n - for ( int i = 0 ; i < size ; i + + ) { \n - readPending = false ; \n - pipeline . fireChannelRead ( readBuf . get ( i ) ) ; \n - } \n - readBuf . clear ( ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ KQueueDatagramChannel . java \n - private final List < Object > readBuf = new ArrayList < Object > ( ) ; \n - readBuf . add ( new DatagramPacket ( data , ( InetSocketAddress ) localAddress ( ) , remoteAddress ) ) ; \n + readPending = false ; \n + pipeline . fireChannelRead ( \n + new DatagramPacket ( data , ( InetSocketAddress ) localAddress ( ) , remoteAddress ) ) ; \n + \n - int size = readBuf . size ( ) ; \n - for ( int i = 0 ; i < size ; i + + ) { \n - readPending = false ; \n - pipeline . fireChannelRead ( readBuf . get ( i ) ) ; \n - } \n - readBuf . clear ( ) ; \n",Remove not needed intermediate collection while reading DatagramPackets in native transports \n Motivation : \n We used an intermediate collection to store the read DatagramPackets and only fired these through the pipeline once wewere done with the reading loop . This is not needed and can also increase memory usage . \n Modifications : \n Remove intermediate collection \n Result : \n Less overhead and possible less memory usage during read loop .,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ UnpooledUnsafeNoCleanerDirectByteBuf . java \n - int readerIndex = readerIndex ( ) ; \n - int writerIndex = writerIndex ( ) ; \n + if ( newCapacity = = oldCapacity ) { \n + return this ; \n + } \n + \n + ByteBuffer newBuffer = reallocateDirect ( buffer , newCapacity ) ; \n - if ( newCapacity > oldCapacity ) { \n - ByteBuffer oldBuffer = buffer ; \n - ByteBuffer newBuffer = reallocateDirect ( oldBuffer , newCapacity ) ; \n - setByteBuffer ( newBuffer , false ) ; \n - } else if ( newCapacity < oldCapacity ) { \n - ByteBuffer oldBuffer = buffer ; \n - ByteBuffer newBuffer = allocateDirect ( newCapacity ) ; \n - if ( readerIndex < newCapacity ) { \n - if ( writerIndex > newCapacity ) { \n - writerIndex = newCapacity ; \n - writerIndex ( writerIndex ) ; \n + if ( newCapacity < oldCapacity ) { \n + if ( readerIndex ( ) < newCapacity ) { \n + if ( writerIndex ( ) > newCapacity ) { \n + writerIndex ( newCapacity ) ; \n - oldBuffer . position ( readerIndex ) . limit ( writerIndex ) ; \n - newBuffer . position ( readerIndex ) . limit ( writerIndex ) ; \n - newBuffer . put ( oldBuffer ) ; \n - newBuffer . clear ( ) ; \n - setByteBuffer ( newBuffer , true ) ; \n + setByteBuffer ( newBuffer , false ) ; \n",Also use realloc when shrink the buffer . \n Motivation : \n We should also use realloc when shrink the buffer to eliminate extra allocations / memory copies when possible . \n Modifications : \n Use realloc for expanding and shrinking when possible . \n Result : \n Less memory copies and allocations,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - DefaultHttp2StreamChannel childChannel = new DefaultHttp2StreamChannel ( stream ) ; \n + DefaultHttp2StreamChannel childChannel = new DefaultHttp2StreamChannel ( stream , false ) ; \n - return new DefaultHttp2StreamChannel ( newStream ( ) ) ; \n + return new DefaultHttp2StreamChannel ( newStream ( ) , true ) ; \n + private final boolean outbound ; \n - DefaultHttp2StreamChannel ( Http2FrameStream stream ) { \n + DefaultHttp2StreamChannel ( Http2FrameStream stream , boolean outbound ) { \n + this . outbound = outbound ; \n - / / Add the handler to the pipeline now that we are registered . \n - pipeline ( ) . addLast ( inboundStreamHandler ) ; \n + if ( ! outbound ) { \n + / / Add the handler to the pipeline now that we are registered . \n + pipeline ( ) . addLast ( inboundStreamHandler ) ; \n + } \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecBuilderTest . java \n + import org . junit . Assert ; \n - . handler ( new Http2MultiplexCodecBuilder ( false , new TestChannelInitializer ( ) ) . build ( ) ) ; \n + . handler ( new Http2MultiplexCodecBuilder ( false , new ChannelInitializer < Channel > ( ) { \n + @ Override \n + protected void initChannel ( Channel ch ) throws Exception { \n + Assert . fail ( "" Should not be called for outbound streams "" ) ; \n + } \n + } ) . build ( ) ) ; \n",Not add inboundStreamHandler for outbound streams created by Http2MultiplexCodec . \n Motivation : \n We must not add the inboundStreamHandler for outbound streams creates by Http2MultiplexCodec as the user will specify a handler via Http2StreamChannelBootstrap . \n Modifications : \n - Check if the stream is for outbound and if so not add the inboundStreamHandler to the pipeline \n - Update tests so this is covered . \n Result : \n Fixes [ # 7178 ],381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ AbstractSniHandler . java \n - SslUtils . SSL _ RECORD _ HEADER _ LENGTH ; \n + SslUtils . SSL _ RECORD _ HEADER _ LENGTH ; \n - CharsetUtil . US _ ASCII ) ; \n + CharsetUtil . US _ ASCII ) ; \n - } catch ( Throwable e ) { \n + } catch ( NotSslRecordException e ) { \n + / / Just rethrow as in this case we also closed the channel and this is consistent with SslHandler . \n + throw e ; \n + } catch ( Exception e ) { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniHandlerTest . java \n + @ Test \n + public void testNonSslRecord ( ) throws Exception { \n + SslContext nettyContext = makeSslContext ( provider , false ) ; \n + try { \n + final AtomicReference < SslHandshakeCompletionEvent > evtRef = \n + new AtomicReference < SslHandshakeCompletionEvent > ( ) ; \n + SniHandler handler = new SniHandler ( new DomainNameMappingBuilder < SslContext > ( nettyContext ) . build ( ) ) ; \n + EmbeddedChannel ch = new EmbeddedChannel ( handler , new ChannelInboundHandlerAdapter ( ) { \n + @ Override \n + public void userEventTriggered ( ChannelHandlerContext ctx , Object evt ) throws Exception { \n + if ( evt instanceof SslHandshakeCompletionEvent ) { \n + assertTrue ( evtRef . compareAndSet ( null , ( SslHandshakeCompletionEvent ) evt ) ) ; \n + } \n + } \n + } ) ; \n + \n + try { \n + byte [ ] bytes = new byte [ 1024 ] ; \n + bytes [ 0 ] = SslUtils . SSL _ CONTENT _ TYPE _ ALERT ; \n + \n + try { \n + ch . writeInbound ( Unpooled . wrappedBuffer ( bytes ) ) ; \n + fail ( ) ; \n + } catch ( DecoderException e ) { \n + assertTrue ( e . getCause ( ) instanceof NotSslRecordException ) ; \n + } \n + assertFalse ( ch . finish ( ) ) ; \n + } finally { \n + ch . finishAndReleaseAll ( ) ; \n + } \n + assertTrue ( evtRef . get ( ) . cause ( ) instanceof NotSslRecordException ) ; \n + } finally { \n + releaseAll ( nettyContext ) ; \n + } \n + } \n + \n",Ensure we not try to call ` select ` when the ` AbstractSniHandler ` was already removed from the pipeline . \n Motivation : \n We tried to call ` select ` after we closed the channel ( and so removed all the handlers from the pipeline ) when we detected a non SSL record . This would cause an exception like this : \n ` ` ` \n Caused by : java . util . NoSuchElementException : io . netty . handler . ssl . SniHandler \n at io . netty . channel . DefaultChannelPipeline . getContextOrDie ( DefaultChannelPipeline . java : 1098 ) \n at io . netty . channel . DefaultChannelPipeline . replace ( DefaultChannelPipeline . java : 506 ) \n at io . netty . handler . ssl . SniHandler . replaceHandler ( SniHandler . java : 133 ) \n at io . netty . handler . ssl . SniHandler . onLookupComplete ( SniHandler . java : 113 ) \n at io . netty . handler . ssl . AbstractSniHandler . select ( AbstractSniHandler . java : 225 ) \n at io . netty . handler . ssl . AbstractSniHandler . decode ( AbstractSniHandler . java : 218 ) \n at io . netty . handler . codec . ByteToMessageDecoder . decodeRemovalReentryProtection ( ByteToMessageDecoder . java : 489 ) \n at io . netty . handler . codec . ByteToMessageDecoder . callDecode ( ByteToMessageDecoder . java : 428 ) \n . . . 40 more \n ` ` ` \n Modifications : \n - Ensure we rethrow the NotSslRecordException when detecting it ( and closing the channel ) . This will also ensure we not call ` select ( . . . ) ` \n - Not catch ` Throwable ` but only ` Exception ` \n - Add test case . \n Result : \n Correctly handle the case of an non SSL record .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - / / only log in debug mode as it most likely harmless and latest chrome still trigger \n - / / this all the time . \n - / / \n - / / See https : / / github . com / netty / netty / issues / 1340 \n - String msg = e . getMessage ( ) ; \n - if ( msg = = null | | ! msg . contains ( "" possible truncation attack "" ) ) { \n - logger . debug ( "" { } SSLEngine . closeInbound ( ) raised an exception . "" , ctx . channel ( ) , e ) ; \n + if ( logger . isDebugEnabled ( ) ) { \n + / / only log in debug mode as it most likely harmless and latest chrome still trigger \n + / / this all the time . \n + / / \n + / / See https : / / github . com / netty / netty / issues / 1340 \n + String msg = e . getMessage ( ) ; \n + if ( msg = = null | | ! msg . contains ( "" possible truncation attack "" ) ) { \n + logger . debug ( "" { } SSLEngine . closeInbound ( ) raised an exception . "" , ctx . channel ( ) , e ) ; \n + } \n",Only try to match SSLException message when debug logging is enabled . \n Motivation : \n We only want to log for the particular case when debug logging is enabled so we not need to try to match the message if this is not the case . \n Modifications : \n Guard with logger . isDebugEnabled ( ) \n Result : \n Less overhead when debug logging is not enabled .,381
"codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpResponseEncoderTest . java \n + \n + @ Test \n + public void testEmptyContentChunked ( ) throws Exception { \n + testEmptyContent ( true ) ; \n + } \n + \n + @ Test \n + public void testEmptyContentNotChunked ( ) throws Exception { \n + testEmptyContent ( false ) ; \n + } \n + \n + private static void testEmptyContent ( boolean chunked ) throws Exception { \n + String content = "" netty rocks "" ; \n + ByteBuf contentBuffer = Unpooled . copiedBuffer ( content , CharsetUtil . US _ ASCII ) ; \n + int length = contentBuffer . readableBytes ( ) ; \n + \n + EmbeddedChannel channel = new EmbeddedChannel ( new HttpResponseEncoder ( ) ) ; \n + HttpResponse response = new DefaultHttpResponse ( HttpVersion . HTTP _ 1 _ 1 , HttpResponseStatus . OK ) ; \n + if ( ! chunked ) { \n + HttpUtil . setContentLength ( response , length ) ; \n + } \n + assertTrue ( channel . writeOutbound ( response ) ) ; \n + assertTrue ( channel . writeOutbound ( new DefaultHttpContent ( Unpooled . EMPTY _ BUFFER ) ) ) ; \n + assertTrue ( channel . writeOutbound ( new DefaultLastHttpContent ( contentBuffer ) ) ) ; \n + \n + ByteBuf buffer = channel . readOutbound ( ) ; \n + if ( ! chunked ) { \n + assertEquals ( "" HTTP / 1 . 1 200 OK \ r \ ncontent - length : "" + length + "" \ r \ n \ r \ n "" , \n + buffer . toString ( CharsetUtil . US _ ASCII ) ) ; \n + } else { \n + assertEquals ( "" HTTP / 1 . 1 200 OK \ r \ n \ r \ n "" , buffer . toString ( CharsetUtil . US _ ASCII ) ) ; \n + } \n + buffer . release ( ) ; \n + \n + / / Test writing an empty buffer works when the encoder is not at ST _ INIT . \n + buffer = channel . readOutbound ( ) ; \n + assertEquals ( 0 , buffer . readableBytes ( ) ) ; \n + buffer . release ( ) ; \n + \n + buffer = channel . readOutbound ( ) ; \n + assertEquals ( length , buffer . readableBytes ( ) ) ; \n + buffer . release ( ) ; \n + \n + assertFalse ( channel . finish ( ) ) ; \n + } \n",Add testcases to prove HttpResponseEncoder correctly handles empty content \n Motivation : \n Issue # 6695 states that there is an issue when writing empty content via HttpResponseEncoder . \n Modifications : \n Add two test - cases . \n Result : \n Verified that all works as expected .,381
"transport \ src \ main \ java \ io \ netty \ channel \ DelegatingChannelPromiseNotifier . java \n - this ( delegate , true ) ; \n + this ( delegate , ! ( delegate instanceof VoidChannelPromise ) ) ; \n",Not log notify failure for DelegatingChannelPromiseNotifier when promise is VoidChannelPromise \n Motivation : \n We should not log by default if the promise is a VoidChannelPromise as its try * methods will always return false . \n Modifications : \n Do an instanceof check to determine if we should log or not by default \n Result : \n No more noise in the logs when using a VoidChannelPromise .,381
transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueChannel . java \n + / / We need to take special care of calling finishConnect ( ) if readEOF is true and we not \n + / / fullfilled the connectPromise yet . If we fail to do so the connectPromise will be failed \n + / / with a ClosedChannelException as a close ( ) will happen and so the FD is closed before we \n + / / have a chance to call finishConnect ( ) later on . Calling finishConnect ( ) here will ensure \n + / / we observe the correct exception in case of a connect failure . \n + if ( readEOF & & connectPromise ! = null ) { \n + finishConnect ( ) ; \n + } \n,Fail the connectPromise with the correct exception if the connection is refused when using the native kqueue transport . \n Motivation : \n Due a bug we happen to sometimes fail the connectPromise with a ClosedChannelException when using the kqueue transport and the remote peer refuses the connection . We need to ensure we fail it with the correct exception . \n Modifications : \n Call finishConnect ( ) before calling close ( ) to ensure we preserve the correct exception . \n Result : \n KQueueSocketConnectionAttemptTest . testConnectionRefused will pass always on macOS .,381
"transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollStreamChannel . java \n + readPending = false ; \n - readPending = false ; \n + readPending = false ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueStreamChannel . java \n - readPending = false ; \n + readPending = false ; \n + readPending = false ; \n transport \ src \ main \ java \ io \ netty \ channel \ nio \ AbstractNioByteChannel . java \n - if ( close ) { \n - / / Based upon the Javadocs it is possible that NIO may have spurious wake ups [ 1 ] . In this \n - / / case we should be more cautious and only set readPending to false if data was actually \n - / / read . \n - / / [ 1 ] https : / / docs . oracle . com / javase / 7 / docs / api / java / nio / channels / SelectionKey . html \n - / / That a selection key ' s ready set indicates that its channel is ready for some operation \n - / / category is a hint , but not a guarantee , that an operation in such a category may be \n - / / performed by a thread without causing the thread to block . \n - readPending = false ; \n - } \n transport \ src \ main \ java \ io \ netty \ channel \ oio \ AbstractOioByteChannel . java \n + readPending = false ; \n + / / In OIO we should set readPending to false even if the read was not successful so we can schedule \n + / / another read on the event loop if no reads are done . \n + readPending = false ; \n - readPending = false ; \n + readPending = false ; \n + readPending = false ; \n","Revert "" Set readPending to false when ever a read is done "" \n This reverts commit 413c7c2cd82e09dac481ea52ba2cb88ffcd58624 as it introduced an regression when edge - triggered mode is used which is true for our native transports by default . With 413c7c2cd82e09dac481ea52ba2cb88ffcd58624 included it was possible that we set readPending to false by mistake even if we would be interested in read more .",381
"common \ src \ main \ java \ io \ netty \ util \ internal \ ObjectUtil . java \n - * Checks that the given argument is strictly positive . If it is , throws { @ link IllegalArgumentException } . \n + * Checks that the given argument is strictly positive . If it is not , throws { @ link IllegalArgumentException } . \n - * Checks that the given argument is strictly positive . If it is , throws { @ link IllegalArgumentException } . \n + * Checks that the given argument is strictly positive . If it is not , throws { @ link IllegalArgumentException } . \n - * Checks that the given argument is positive or zero . If it is , throws { @ link IllegalArgumentException } . \n + * Checks that the given argument is positive or zero . If it is not , throws { @ link IllegalArgumentException } . \n - * Checks that the given argument is positive or zero . If it is , throws { @ link IllegalArgumentException } . \n + * Checks that the given argument is positive or zero . If it is not , throws { @ link IllegalArgumentException } . \n","Fix javadocs for ObjectUtil methods . \n Motivation : \n The javadocs for a few methds in ObjectUtil are not correct . \n Modifications : \n Add "" not "" where it was missing . \n Result : \n Fixes [ # 7455 ] .",381
"transport \ src \ main \ java \ io \ netty \ channel \ pool \ FixedChannelPool . java \n + import io . netty . util . internal . ObjectUtil ; \n - \n + static final IllegalStateException POOL _ CLOSED _ ON _ RELEASE _ EXCEPTION = ThrowableUtil . unknownStackTrace ( \n + new IllegalStateException ( "" FixedChannelPooled was closed "" ) , \n + FixedChannelPool . class , "" release ( . . . ) "" ) ; \n + static final IllegalStateException POOL _ CLOSED _ ON _ ACQUIRE _ EXCEPTION = ThrowableUtil . unknownStackTrace ( \n + new IllegalStateException ( "" FixedChannelPooled was closed "" ) , \n + FixedChannelPool . class , "" acquire0 ( . . . ) "" ) ; \n - promise . setFailure ( new IllegalStateException ( "" FixedChannelPooled was closed "" ) ) ; \n + promise . setFailure ( POOL _ CLOSED _ ON _ ACQUIRE _ EXCEPTION ) ; \n + ObjectUtil . checkNotNull ( promise , "" promise "" ) ; \n - promise . setFailure ( new IllegalStateException ( "" FixedChannelPooled was closed "" ) ) ; \n + promise . setFailure ( POOL _ CLOSED _ ON _ RELEASE _ EXCEPTION ) ; \n - return p ; \n + return promise ; \n - originalPromise . setFailure ( new IllegalStateException ( "" FixedChannelPooled was closed "" ) ) ; \n + originalPromise . setFailure ( POOL _ CLOSED _ ON _ ACQUIRE _ EXCEPTION ) ; \n transport \ src \ test \ java \ io \ netty \ channel \ pool \ FixedChannelPoolTest . java \n - pool . release ( channel ) . syncUninterruptibly ( ) ; \n - \n - / / Since the pool is closed . . the release channel should have been closed \n + try { \n + pool . release ( channel ) . syncUninterruptibly ( ) ; \n + fail ( ) ; \n + } catch ( IllegalStateException e ) { \n + assertSame ( FixedChannelPool . POOL _ CLOSED _ ON _ RELEASE _ EXCEPTION , e ) ; \n + } \n + / / Since the pool is closed , the Channel should have been closed as well . \n - \n","Return the correct Future from FixedChannelPool . release ( ) \n Motivation : \n The behaviour of the FixedChannelPool . release was inconsistent with the \n SimpleChannelPool implementation , in that given promise is returned . \n In the FixedChannelPool implementation a new promise was return and \n this meant that the completion of that promise can be different . \n Specifically on releasing a channel to a closed pool , the parameter \n promise is failed with an IllegalStateException but the returned one \n will have been successful ( as it was completed by call to super \n . release ) \n Modification : \n Return the given promise as the result of FixedChannelPool . release \n Result : \n Returned promise will reflect the result of the release operation .",381
transport \ src \ main \ java \ io \ netty \ channel \ AbstractChannel . java \n - @ Deprecated \n,Remove @ deprecation keyword on AbstractUnsafe . ensureOpen ( . . . ) \n Motivation : \n e84567004324c0bfd04b0ca9e1e182ed89394b16 marked AbstractUnsafe . ensureOpen ( . . . ) as deprecated for no reason . \n Modifications : \n Remove ` @ deprecation ` \n Result : \n Remove incorrect annotation,381
"transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n + import io . netty . channel . Channel ; \n + import org . junit . Test ; \n + \n + import java . nio . channels . Selector ; \n + \n + import static org . junit . Assert . * ; \n + \n + @ Test \n + public void testRebuildSelector ( ) throws Exception { \n + EventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + final NioEventLoop loop = ( NioEventLoop ) group . next ( ) ; \n + try { \n + Channel channel = new NioServerSocketChannel ( ) ; \n + loop . register ( channel ) . syncUninterruptibly ( ) ; \n + \n + Selector selector = loop . unwrappedSelector ( ) ; \n + assertSame ( selector , ( ( NioEventLoop ) channel . eventLoop ( ) ) . unwrappedSelector ( ) ) ; \n + assertTrue ( selector . isOpen ( ) ) ; \n + \n + / / Submit to the EventLoop so we are sure its really executed in a non - async manner . \n + loop . submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + loop . rebuildSelector ( ) ; \n + } \n + } ) . syncUninterruptibly ( ) ; \n + \n + Selector newSelector = ( ( NioEventLoop ) channel . eventLoop ( ) ) . unwrappedSelector ( ) ; \n + assertTrue ( newSelector . isOpen ( ) ) ; \n + assertNotSame ( selector , newSelector ) ; \n + assertFalse ( selector . isOpen ( ) ) ; \n + \n + channel . close ( ) . syncUninterruptibly ( ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n",Add testcase to ensure NioEventLoop . rebuildSelector ( ) works correctly . \n Motivation : \n We had recently a report that the issue [ # 6607 ] is still not fixed . \n Modifications : \n Add a testcase to prove the issue is fixed . \n Result : \n More tests .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketConnectTest . java \n + import io . netty . testsuite . util . TestUtils ; \n + import io . netty . util . NetUtil ; \n - sc = sb . bind ( 0 ) . syncUninterruptibly ( ) . channel ( ) ; \n + sc = sb . bind ( NetUtil . LOCALHOST , TestUtils . getFreePort ( ) ) . syncUninterruptibly ( ) . channel ( ) ; \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketMultipleConnectTest . java \n + import io . netty . testsuite . util . TestUtils ; \n + import io . netty . util . NetUtil ; \n - sc = sb . bind ( 0 ) . syncUninterruptibly ( ) . channel ( ) ; \n + sc = sb . bind ( NetUtil . LOCALHOST , TestUtils . getFreePort ( ) ) . syncUninterruptibly ( ) . channel ( ) ; \n transport - native - epoll \ src \ test \ java \ io \ netty \ channel \ epoll \ EpollSpliceTest . java \n + import io . netty . testsuite . util . TestUtils ; \n + import io . netty . util . NetUtil ; \n - import java . net . InetSocketAddress ; \n - final Channel sc = bs . bind ( new InetSocketAddress ( 0 ) ) . syncUninterruptibly ( ) . channel ( ) ; \n + final Channel sc = bs . bind ( NetUtil . LOCALHOST , TestUtils . getFreePort ( ) ) . syncUninterruptibly ( ) . channel ( ) ; \n - Channel pc = bs2 . bind ( new InetSocketAddress ( 0 ) ) . syncUninterruptibly ( ) . channel ( ) ; \n + Channel pc = bs2 . bind ( NetUtil . LOCALHOST , TestUtils . getFreePort ( ) ) . syncUninterruptibly ( ) . channel ( ) ; \n - Channel sc = bs . bind ( new InetSocketAddress ( 0 ) ) . syncUninterruptibly ( ) . channel ( ) ; \n + Channel sc = bs . bind ( NetUtil . LOCALHOST , TestUtils . getFreePort ( ) ) . syncUninterruptibly ( ) . channel ( ) ; \n",Explicit specify hostaddress during tests to ensure testsuite pass on docker ( mac ) \n Motivation : \n When run the current testsuite on docker ( mac ) it will fail a few tests with : \n io . netty . channel . AbstractChannel $ AnnotatedConnectException : connect ( . . ) failed : Cannot assign requested address : / 0 : 0 : 0 : 0 : 0 : 0 : 0 : 0 % 0 : 46607 \n Caused by : java . net . ConnectException : connect ( . . ) failed : Cannot assign requested address \n Modifications : \n Specify host explicit as done in other tests to only use ipv6 when really supported . \n Result : \n Build pass on docker as well,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - private static final int [ ] OPENSSL _ OP _ NO _ PROTOCOLS = new int [ ] { \n + private static final int [ ] OPENSSL _ OP _ NO _ PROTOCOLS = { \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslContext . java \n - * @ see # newHandler ( io . netty . buffer . ByteBufAllocator ) \n + * @ see # newHandler ( ByteBufAllocator ) \n - * @ see # newHandler ( io . netty . buffer . ByteBufAllocator , String , int , boolean ) \n + * @ see # newHandler ( ByteBufAllocator , String , int , boolean ) \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslUtils . java \n - static final String [ ] DEFAULT _ CIPHER _ SUITES = new String [ ] { \n + static final String [ ] DEFAULT _ CIPHER _ SUITES = { \n",Use array initializer expression \n Motivation : \n Code introduced in 6152990073607602b2263109139cf829f3d2f7e4 can be cleaned up and use array initializer expressions . \n Modifications : \n Use array initializer expressions . \n Result : \n Cleaner code .,381
bom \ pom . xml \n - < artifactId > netty - transport - unix - common < / artifactId > \n - < version > 4 . 1 . 13 . Final - SNAPSHOT < / version > \n + < artifactId > netty - transport - native - unix - common < / artifactId > \n + < version > 4 . 1 . 14 . Final - SNAPSHOT < / version > \n - < artifactId > netty - transport - unix - common < / artifactId > \n - < version > 4 . 1 . 13 . Final - SNAPSHOT < / version > \n + < artifactId > netty - transport - native - unix - common < / artifactId > \n + < version > 4 . 1 . 14 . Final - SNAPSHOT < / version > \n,Correct typo in artifactId of dependency in bom pom . xml \n Motivation : \n There was a typo in a dependency in the bom pom . xml which lead to have it specify a non - existing artifact and also so not have the maven release plugin update the version correctly . \n Modifications : \n Rename netty - transport - unix - common to netty - transport - native - unix - common and also fix the version . \n Result : \n Fixes [ # 6979 ],381
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n - netty _ unix _ socket _ setOptionHandleError ( env , errno ) ; \n - / / Something went wrong so close the fd and return here . setOption ( . . . ) itself throws the exception already . \n - close ( fd ) ; \n - return - 1 ; \n + netty _ unix _ socket _ setOptionHandleError ( env , errno ) ; \n + / / Something went wrong so close the fd and return here . setOption ( . . . ) itself throws the exception already . \n + close ( fd ) ; \n + return - 1 ; \n",Use 4 spaces and not 2 spaces ( cleanup of 3d22b24244d4480661a1c17c8d9d67c33f82706b ),381
"codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostRequestEncoderTest . java \n - Charset . forName ( "" UTF - 8 "" ) , - 1 ) ; \n + CharsetUtil . UTF _ 8 , - 1 ) ; \n - Charset . forName ( "" UTF - 8 "" ) , - 1 ) ; \n + CharsetUtil . UTF _ 8 , - 1 ) ; \n - checkNextChunkSize ( encoder , 8096 ) ; \n - checkNextChunkSize ( encoder , 8096 ) ; \n + checkNextChunkSize ( encoder , 8080 ) ; \n + checkNextChunkSize ( encoder , 8080 ) ; \n - assertTrue ( "" Expected end of input is not receive "" , encoder . isEndOfInput ( ) ) ; \n + assertTrue ( "" Expected end of input is not receive "" , encoder . isEndOfInput ( ) ) ; \n - checkNextChunkSize ( encoder , 8096 ) ; \n + checkNextChunkSize ( encoder , 8080 ) ; \n - private static void checkNextChunkSize ( HttpPostRequestEncoder encoder , int expectedSize ) throws Exception { \n + private static void checkNextChunkSize ( HttpPostRequestEncoder encoder , int sizeWithoutDelimiter ) throws Exception { \n + / / 16 bytes as HttpPostRequestEncoder uses Long . toHexString ( . . . ) to generate a hex - string which will be between \n + / / 2 and 16 bytes . \n + / / See https : / / github . com / netty / netty / blob / 4 . 1 / codec - http / src / main / java / io / netty / handler / \n + / / codec / http / multipart / HttpPostRequestEncoder . java # L291 \n + int expectedSizeMin = sizeWithoutDelimiter + 2 ; \n + int expectedSizeMax = sizeWithoutDelimiter + 16 ; \n + \n - assertEquals ( "" Chunk is not "" + expectedSize + "" bytes "" , expectedSize , httpContent . content ( ) . readableBytes ( ) ) ; \n + \n + int readable = httpContent . content ( ) . readableBytes ( ) ; \n + boolean expectedSize = readable > = expectedSizeMin & & readable < = expectedSizeMax ; \n + assertTrue ( "" Chunk size is not in expected range ( "" + expectedSizeMin + "" - "" + expectedSizeMax + "" ) , was : "" \n + + readable , expectedSize ) ; \n",Fix flacky multipart test introduced by 08748344d852a07011be6e74bb5ddc6dcf221c45 . \n Motivation : \n 08748344d852a07011be6e74bb5ddc6dcf221c45 introduced two new tests which did not take into account that the multipart delimiter can be between 2 and 16 bytes long . \n Modifications : \n Take the multipart delimiter length into account . \n Result : \n Fixes [ # 7001 ],381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsServerAddressStreamProvider . java \n - String [ ] servers = dnsUrls . split ( "" "" ) ; \n - for ( String server : servers ) { \n - try { \n - URI uri = new URI ( server ) ; \n - int port = uri . getPort ( ) ; \n - defaultNameServers . add ( SocketUtils . socketAddress ( uri . getHost ( ) , port = = - 1 ? DNS _ PORT : port ) ) ; \n - } catch ( URISyntaxException e ) { \n - logger . debug ( "" Skipping a malformed nameserver URI : { } "" , server , e ) ; \n + / / Only try if not empty as otherwise we will produce an exception \n + if ( dnsUrls ! = null & & ! dnsUrls . isEmpty ( ) ) { \n + String [ ] servers = dnsUrls . split ( "" "" ) ; \n + for ( String server : servers ) { \n + try { \n + URI uri = new URI ( server ) ; \n + String host = new URI ( server ) . getHost ( ) ; \n + \n + if ( host = = null | | host . isEmpty ( ) ) { \n + logger . debug ( \n + "" Skipping a nameserver URI as host portion could not be extracted : { } "" , server ) ; \n + / / If the host portion can not be parsed we should just skip this entry . \n + continue ; \n + } \n + int port = uri . getPort ( ) ; \n + defaultNameServers . add ( SocketUtils . socketAddress ( uri . getHost ( ) , port = = - 1 ? DNS _ PORT : port ) ) ; \n + } catch ( URISyntaxException e ) { \n + logger . debug ( "" Skipping a malformed nameserver URI : { } "" , server , e ) ; \n + } \n",Skip invalid hostnames when construct default dns servers to use . \n Motivation : \n When the hostname portion can not be extracted we should just skip the server as otherwise we will produce and exception when trying to create the InetSocketAddress . \n This was happing when trying to run the test - suite on a system and using java7 : \n java . lang . IllegalArgumentException : hostname can ' t be null \n at java . net . InetSocketAddress . checkHost ( InetSocketAddress . java : 149 ) \n at java . net . InetSocketAddress . < init > ( InetSocketAddress . java : 216 ) \n at io . netty . util . internal . SocketUtils $ 10 . run ( SocketUtils . java : 171 ) \n at io . netty . util . internal . SocketUtils $ 10 . run ( SocketUtils . java : 168 ) \n at java . security . AccessController . doPrivileged ( Native Method ) \n at io . netty . util . internal . SocketUtils . socketAddress ( SocketUtils . java : 168 ) \n at io . netty . resolver . dns . DefaultDnsServerAddressStreamProvider . < clinit > ( DefaultDnsServerAddressStreamProvider . java : 74 ) \n at io . netty . resolver . dns . DnsServerAddressesTest . testDefaultAddresses ( DnsServerAddressesTest . java : 39 ) \n Modifications : \n Skip if hostname can not be extracted . \n Result : \n No more java . lang . ExceptionInInitializerError .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsServerAddressStreamProvider . java \n - defaultNameServers . add ( SocketUtils . socketAddress ( new URI ( server ) . getHost ( ) , DNS _ PORT ) ) ; \n + URI uri = new URI ( server ) ; \n + int port = uri . getPort ( ) ; \n + defaultNameServers . add ( SocketUtils . socketAddress ( uri . getHost ( ) , port = = - 1 ? DNS _ PORT : port ) ) ; \n",Respect DNS port that is specified via JNDI \n Motivation : \n JNDI allows to specify an port so we should respect it . \n Modifications : \n Use the specified port and if none is specifed use 53 . \n Result : \n Correct handling of JNDI configured DNS .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsServerAddressStreamProvider . java \n + import io . netty . util . NetUtil ; \n + import java . net . Inet6Address ; \n - Collections . addAll ( \n - defaultNameServers , \n - SocketUtils . socketAddress ( "" 8 . 8 . 8 . 8 "" , DNS _ PORT ) , \n - SocketUtils . socketAddress ( "" 8 . 8 . 4 . 4 "" , DNS _ PORT ) ) ; \n + / / Depending if IPv6 or IPv4 is used choose the correct DNS servers provided by google : \n + / / https : / / developers . google . com / speed / public - dns / docs / using \n + / / https : / / docs . oracle . com / javase / 7 / docs / api / java / net / doc - files / net - properties . html \n + if ( NetUtil . isIpV6AddressesPreferred ( ) | | \n + ( NetUtil . LOCALHOST instanceof Inet6Address & & ! NetUtil . isIpV4StackPreferred ( ) ) ) { \n + Collections . addAll ( \n + defaultNameServers , \n + SocketUtils . socketAddress ( "" 2001 : 4860 : 4860 : : 8888 "" , DNS _ PORT ) , \n + SocketUtils . socketAddress ( "" 2001 : 4860 : 4860 : : 8844 "" , DNS _ PORT ) ) ; \n + } else { \n + Collections . addAll ( \n + defaultNameServers , \n + SocketUtils . socketAddress ( "" 8 . 8 . 8 . 8 "" , DNS _ PORT ) , \n + SocketUtils . socketAddress ( "" 8 . 8 . 4 . 4 "" , DNS _ PORT ) ) ; \n + } \n",Choose ipv4 or ipv6 google dns servers as default fallback based on the settings for this system / jvm \n Motivation : \n We should not use ipv4 google dns servers if the app is configured to run ipv6 . \n Modifications : \n Use either ipv4 or ipv6 dns servers depending on the system config . \n Result : \n More correct behaviour,381
"transport \ src \ main \ java \ io \ netty \ channel \ DefaultChannelPipeline . java \n + import java . util . concurrent . atomic . AtomicReferenceFieldUpdater ; \n + private static final AtomicReferenceFieldUpdater < DefaultChannelPipeline , MessageSizeEstimator . Handle > ESTIMATOR = \n + AtomicReferenceFieldUpdater . newUpdater ( \n + DefaultChannelPipeline . class , MessageSizeEstimator . Handle . class , "" estimatorHandle "" ) ; \n - private MessageSizeEstimator . Handle estimatorHandle ; \n + private volatile MessageSizeEstimator . Handle estimatorHandle ; \n - if ( estimatorHandle = = null ) { \n - estimatorHandle = channel . config ( ) . getMessageSizeEstimator ( ) . newHandle ( ) ; \n + MessageSizeEstimator . Handle handle = estimatorHandle ; \n + if ( handle = = null ) { \n + handle = channel . config ( ) . getMessageSizeEstimator ( ) . newHandle ( ) ; \n + if ( ! ESTIMATOR . compareAndSet ( this , null , handle ) ) { \n + handle = estimatorHandle ; \n + } \n - return estimatorHandle ; \n + return handle ; \n",DefaultChannelPipeline . estimatorHandle needs to be volatile \n Motivation : \n DefaultChannelPipeline . estimatorHandle needs to be volatile as its accessed from different threads . \n Modifications : \n Make DefaultChannelPipeline . estimatorHandle volatile and correctly init it via CAS \n Result : \n No more race .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2ConnectionHandler . java \n - flush ( ctx ) ; \n - } finally { \n + / / First call channelReadComplete ( . . . ) as this may produce more data that we want to flush \n + } finally { \n + flush ( ctx ) ; \n,First call channelReadComplete ( . . . ) before flush ( . . . ) for better performance \n Motivation : \n In Http2ConnectionHandler we call flush ( . . . ) in channelReadComplete ( . . . ) to ensure we update the flow - controller and write stuff to the remote peer . We should better flip the order and so may be able to pick up more bytes . \n Modifications : \n Change order of calls . \n Result : \n Better performance,381
"example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ frame \ server \ HelloWorldHttp2Handler . java \n + @ Override \n + public void channelReadComplete ( ChannelHandlerContext ctx ) throws Exception { \n + ctx . flush ( ) ; \n + } \n + \n - public void onDataRead ( ChannelHandlerContext ctx , Http2DataFrame data ) throws Exception { \n + private static void onDataRead ( ChannelHandlerContext ctx , Http2DataFrame data ) throws Exception { \n - public void onHeadersRead ( ChannelHandlerContext ctx , Http2HeadersFrame headers ) \n + private static void onHeadersRead ( ChannelHandlerContext ctx , Http2HeadersFrame headers ) \n - ctx . writeAndFlush ( new DefaultHttp2DataFrame ( payload , true ) . streamId ( streamId ) ) ; \n + ctx . write ( new DefaultHttp2DataFrame ( payload , true ) . streamId ( streamId ) ) ; \n example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ multiplex \ server \ HelloWorldHttp2Handler . java \n + @ Override \n + public void channelReadComplete ( ChannelHandlerContext ctx ) throws Exception { \n + ctx . flush ( ) ; \n + } \n + \n - public void onDataRead ( ChannelHandlerContext ctx , Http2DataFrame data ) throws Exception { \n + private static void onDataRead ( ChannelHandlerContext ctx , Http2DataFrame data ) throws Exception { \n - public void onHeadersRead ( ChannelHandlerContext ctx , Http2HeadersFrame headers ) \n + private static void onHeadersRead ( ChannelHandlerContext ctx , Http2HeadersFrame headers ) \n - ctx . writeAndFlush ( new DefaultHttp2DataFrame ( payload , true ) ) ; \n + ctx . write ( new DefaultHttp2DataFrame ( payload , true ) ) ; \n example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ server \ HelloWorldHttp1Handler . java \n - ctx . writeAndFlush ( response ) . addListener ( ChannelFutureListener . CLOSE ) ; \n + ctx . write ( response ) . addListener ( ChannelFutureListener . CLOSE ) ; \n - ctx . writeAndFlush ( response ) ; \n + ctx . write ( response ) ; \n + @ Override \n + public void channelReadComplete ( ChannelHandlerContext ctx ) throws Exception { \n + ctx . flush ( ) ; \n + } \n + \n example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ server \ HelloWorldHttp2Handler . java \n - try { \n - flush ( ctx ) ; \n - } catch ( Throwable cause ) { \n - onError ( ctx , cause ) ; \n - } \n + \n + / / no need to call flush as channelReadComplete ( . . . ) will take care of it . \n",Only flush on channelReadComplete ( . . . ) in http2 hello world examples . \n Motivation : \n In our http1 hello world example we only flush on channelReadComplete ( . . . ) to make better use of gathering writes . We should do the same in http2 . \n Modifications : \n Only flush in channelReadComplete ( . . . ) \n Result : \n Better performance and more consistent examples .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - leak = leakDetection ? leakDetector . track ( this ) : null ; \n + leak = leakDetection ? leakDetector . track ( this ) : null ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngineTest . java \n + import io . netty . handler . ssl . util . InsecureTrustManagerFactory ; \n + import org . junit . Test ; \n + \n + @ Test ( expected = NullPointerException . class ) \n + public void testNotLeakOnException ( ) throws Exception { \n + clientSslCtx = SslContextBuilder . forClient ( ) \n + . trustManager ( InsecureTrustManagerFactory . INSTANCE ) \n + . sslProvider ( sslClientProvider ( ) ) \n + . build ( ) ; \n + \n + clientSslCtx . newEngine ( null ) ; \n + } \n,Fix false - positive leak detection report when ReferenceCountedOpenSslEngine constructor throws . \n Motivation : \n We need to ensure we only create the ResourceLeak when the constructor not throws . \n Modifications : \n Ensure ResourceLeakDetector . track ( . . . ) is only called if the constructor of ReferenceCoundedOpenSslEngine not throws . \n Result : \n No more false - positves .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n + \n + / / Only create the leak after everything else was executed and so ensure we don ' t produce a false - positive for \n + / / the ResourceLeakDetector . \n,Add comment why the ResourceLeak creation is happening as last in the constructor . Followup of c5b5d363601a0d9ae294034c1e68a6de54a0958f,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - this ( server , new DefaultHttp2FrameWriter ( ) , frameLogger , new Http2Settings ( ) ) ; \n + this ( server , new DefaultHttp2FrameWriter ( ) , frameLogger , Http2Settings . defaultSettings ( ) ) ; \n",Ensure Http2FrameCodec uses Http2Settings . defaultSettings ( ) \n Motivation : \n Http2FrameCodec should use Http2Settings . defaultSettings ( ) when no Http2Settings were specified by the user . \n Modifications : \n Replace new Http2Settings ( ) with Http2Settings . defaultSettings ( ) \n Result : \n Use correct Http2Settings by default when using Http2FrameCodec in all cases .,381
transport \ src \ main \ java \ io \ netty \ channel \ socket \ oio \ OioDatagramChannel . java \n + / / Ensure we null out the address which may have been set before . \n + tmpPacket . setAddress ( null ) ; \n + / / Ensure we null out the address which may have been set before . \n + tmpPacket . setAddress ( null ) ; \n,Ensure we null out the previous set InetAddress on java . net . DatagramPacket when using OioDatagramChannel . \n Motivation : \n We need to ensure we always null out ( or set ) the address on the java . net . DatagramPacket when doing read or write operation as the same instance is used across different calls . \n Modifications : \n Null out the address if needed . \n Result : \n Ensure the correct remote address is used when connect / disconnect between calls and also mix these with calls that directly specify the remote address for adatagram packets .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - String osname = SystemPropertyUtil . get ( "" os . name "" , "" "" ) . toLowerCase ( Locale . US ) ; \n + String osname = SystemPropertyUtil . get ( "" os . name "" , "" "" ) . toLowerCase ( Locale . US ) \n + . replaceAll ( "" [ ^ a - z0 - 9 ] + "" , "" "" ) ; \n + System . err . println ( "" osname = "" + osname ) ; \n",Fix regression in detecting macOS / osx platform introduced by bdb0a39c8a01e934de4e0a75b073a0842d92a511,381
"transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ DefaultRxtxChannelConfig . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n rename from transport \ src \ main \ java \ io \ netty \ channel \ local \ PreferHeapByteBufAllocator . java \n rename to transport \ src \ main \ java \ io \ netty \ channel \ PreferHeapByteBufAllocator . java \n - package io . netty . channel . local ; \n + package io . netty . channel ; \n + import io . netty . util . internal . ObjectUtil ; \n + import io . netty . util . internal . UnstableApi ; \n - final class PreferHeapByteBufAllocator implements ByteBufAllocator { \n + @ UnstableApi \n + public final class PreferHeapByteBufAllocator implements ByteBufAllocator { \n - PreferHeapByteBufAllocator ( ByteBufAllocator allocator ) { \n - this . allocator = allocator ; \n + public PreferHeapByteBufAllocator ( ByteBufAllocator allocator ) { \n + this . allocator = ObjectUtil . checkNotNull ( allocator , "" allocator "" ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ local \ LocalChannel . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n transport \ src \ main \ java \ io \ netty \ channel \ local \ LocalServerChannel . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n transport \ src \ main \ java \ io \ netty \ channel \ socket \ oio \ DefaultOioDatagramChannelConfig . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ socket \ oio \ DefaultOioServerSocketChannelConfig . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ socket \ oio \ DefaultOioSocketChannelConfig . java \n + import io . netty . channel . PreferHeapByteBufAllocator ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n + setAllocator ( new PreferHeapByteBufAllocator ( getAllocator ( ) ) ) ; \n",We should prefer heap buffers when using the OIO transport to reduce memory copies . \n Motivation : \n When using the OIO transport we need to act on byte [ ] when writing and reading from / to the underyling Socket . So we should ensure we use heap buffers by default to reduce memory copies . \n Modifications : \n Ensure we prefer heap buffers by default for the OIO transport . \n Result : \n Possible less memory copies .,381
pom . xml \n + < ! - - Needed because of https : / / issues . apache . org / jira / browse / MENFORCER - 275 - - > \n + < enforcer . plugin . version > 3 . 0 . 0 - M1 < / enforcer . plugin . version > \n + < enforcer . plugin . version > 1 . 4 . 1 < / enforcer . plugin . version > \n + < version > $ { enforcer . plugin . version } < / version > \n resolver - dns \ pom . xml \n + < exclusions > \n + < ! - - \n + We need to use commons - lang 2 . 6 to be able to run the tests with java9 \n + See https : / / github . com / apache / bookkeeper / issues / 385 \n + - - > \n + < exclusion > \n + < groupId > commons - lang < / groupId > \n + < artifactId > commons - lang < / artifactId > \n + < / exclusion > \n + < / exclusions > \n + < / dependency > \n + < dependency > \n + < groupId > commons - lang < / groupId > \n + < artifactId > commons - lang < / artifactId > \n + < version > 2 . 6 < / version > \n + < scope > test < / scope > \n,Ensure netty builds with java9 ( build 9 + 181 ) \n Motivation : \n To be able to build with latest java9 release we need to adjust commons - lang version and maven - enforcer - plugin . \n Modifications : \n - Use commons - lang 2 . 6 . 0 \n - Use maven - enforcer - plugin 3 . 0 . 0 . M1 when building with java9 \n Result : \n Netty builds again with latest java9 release,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ ReadOnlyByteBufferBuf . java \n - ByteBuffer dst = ByteBuffer . allocateDirect ( length ) ; \n - dst . put ( src ) ; \n - dst . order ( order ( ) ) ; \n - dst . clear ( ) ; \n - return new UnpooledDirectByteBuf ( alloc ( ) , dst , maxCapacity ( ) ) ; \n + ByteBuf dst = src . isDirect ( ) ? alloc ( ) . directBuffer ( length ) : alloc ( ) . heapBuffer ( length ) ; \n + dst . writeBytes ( src ) ; \n + return dst ; \n buffer \ src \ test \ java \ io \ netty \ buffer \ ReadOnlyByteBufferBufTest . java \n + import io . netty . util . internal . PlatformDependent ; \n + import org . junit . Test ; \n + \n + import static org . junit . Assert . assertEquals ; \n + \n + \n + @ Test \n + public void testCopyDirect ( ) { \n + testCopy ( true ) ; \n + } \n + \n + @ Test \n + public void testCopyHeap ( ) { \n + testCopy ( false ) ; \n + } \n + \n + private static void testCopy ( boolean direct ) { \n + byte [ ] bytes = new byte [ 1024 ] ; \n + PlatformDependent . threadLocalRandom ( ) . nextBytes ( bytes ) ; \n + \n + ByteBuffer nioBuffer = direct ? ByteBuffer . allocateDirect ( bytes . length ) : ByteBuffer . allocate ( bytes . length ) ; \n + nioBuffer . put ( bytes ) . flip ( ) ; \n + \n + ByteBuf buf = new ReadOnlyByteBufferBuf ( UnpooledByteBufAllocator . DEFAULT , nioBuffer . asReadOnlyBuffer ( ) ) ; \n + ByteBuf copy = buf . copy ( ) ; \n + \n + assertEquals ( buf , copy ) ; \n + assertEquals ( buf . alloc ( ) , copy . alloc ( ) ) ; \n + assertEquals ( buf . isDirect ( ) , copy . isDirect ( ) ) ; \n + \n + copy . release ( ) ; \n + buf . release ( ) ; \n + } \n",Use the ByteBufAllocator when copy a ReadOnlyByteBufferBuf and so also be able to release it without the GC when the Cleaner is present . \n Motivation : \n In ReadOnlyByteBufferBuf . copy ( . . . ) we just allocated a ByteBuffer directly and wrapped it . This way it was not possible for us to free the direct memory that was used by the copy without the GC . \n Modifications : \n - Ensure we use the allocator when create the copy and so be able to release direct memory in a timely manner \n - Add unit test \n - Depending on if the to be copied buffer is direct or heap based we also allocate the same type on copy . \n Result : \n Fixes [ # 7103 ] .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSsl . java \n - libNames . add ( "" netty - tcnative - "" + os + ' - ' + arch ) ; \n + libNames . add ( "" netty _ tcnative - "" + os + ' - ' + arch ) ; \n - libNames . add ( "" netty - tcnative - "" + os + ' - ' + arch + "" - fedora "" ) ; \n + libNames . add ( "" netty _ tcnative - "" + os + ' - ' + arch + "" - fedora "" ) ; \n - libNames . add ( "" netty - tcnative "" ) ; \n - / / in Java 8 , statically compiled JNI code is namespaced \n pom . xml \n - < tcnative . version > 2 . 0 . 5 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 6 . Final < / tcnative . version > \n",Update netty - tcnative native library names to use underscores . \n Motivation : \n We recently changed netty - tcnative to use underscores in its native library names . \n Modifications : \n Update code to use underscores when loading native library . \n Result : \n More consistent code .,381
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n + / / Explicitly try to bind to : : 1 to ensure IPV6 can really be used . \n + / / See https : / / github . com / netty / netty / issues / 7021 . \n + struct sockaddr _ in6 addr ; \n + memset ( & addr , 0 , sizeof ( addr ) ) ; \n + addr . sin6 _ family = AF _ INET6 ; \n + addr . sin6 _ addr . s6 _ addr [ 15 ] = 1 ; / * [ : : 1 ] : 0 * / \n + int res = bind ( fd , ( struct sockaddr * ) & addr , sizeof ( addr ) ) ; \n + \n - return AF _ INET6 ; \n + return res = = 0 ? AF _ INET6 : AF _ INET ; \n",More bullet - proof way of detecting if ipv6 is supported or not when using native transport \n Motivation : \n We should try to bind to an ipv6 only socket before we enable ipv6 support in the native transport as it may not work due setup of the platform . \n Modifications : \n Try to bind to : : 1 use IPV6 later on if this works \n Result : \n Fixes [ # 7021 ] .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ApplicationProtocolNegotiator . java \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } \n + @ SuppressWarnings ( "" deprecation "" ) \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkAlpnApplicationProtocolNegotiator . java \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } . \n + @ Deprecated \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkApplicationProtocolNegotiator . java \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } \n + @ Deprecated \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkDefaultApplicationProtocolNegotiator . java \n - import io . netty . buffer . ByteBufAllocator ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkNpnApplicationProtocolNegotiator . java \n - import io . netty . buffer . ByteBufAllocator ; \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } . \n + @ Deprecated \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkSslContext . java \n + @ SuppressWarnings ( "" deprecation "" ) \n + @ SuppressWarnings ( "" deprecation "" ) \n + @ SuppressWarnings ( "" deprecation "" ) \n + @ SuppressWarnings ( "" deprecation "" ) \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslApplicationProtocolNegotiator . java \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } \n + @ Deprecated \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslDefaultApplicationProtocolNegotiator . java \n + * \n + * @ deprecated use { @ link ApplicationProtocolConfig } . \n + @ Deprecated \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslNpnApplicationProtocolNegotiator . java \n - * @ deprecated use { @ link OpenSslDefaultApplicationProtocolNegotiator } \n + * @ deprecated use { @ link ApplicationProtocolConfig } \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - import java . util . ArrayList ; \n + @ SuppressWarnings ( "" deprecation "" ) \n + @ SuppressWarnings ( "" deprecation "" ) \n",Deprecate ApplicationProtocolNegotiator and its implementation as people should use ApplicationProtocolConfig \n Motivation : \n We should deprecate ApplicationProtocolNegotiator as the users should use ApplicationProtocolConfig these days . \n Modifications : \n Add deprecation annotations and javadocs . \n Result : \n Be able to make package - private in next major release .,381
transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioSocketChannelTest . java \n + import io . netty . channel . socket . SocketChannel ; \n + import java . io . IOException ; \n + import java . net . ServerSocket ; \n + \n + @ Test ( timeout = 3000 ) \n + public void testShutdownOutputAndClose ( ) throws IOException { \n + NioEventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + ServerSocket socket = new ServerSocket ( ) ; \n + socket . bind ( new InetSocketAddress ( 0 ) ) ; \n + Socket accepted = null ; \n + try { \n + Bootstrap sb = new Bootstrap ( ) ; \n + sb . group ( group ) . channel ( NioSocketChannel . class ) ; \n + sb . handler ( new ChannelInboundHandlerAdapter ( ) ) ; \n + \n + SocketChannel channel = ( SocketChannel ) sb . connect ( socket . getLocalSocketAddress ( ) ) \n + . syncUninterruptibly ( ) . channel ( ) ; \n + \n + accepted = socket . accept ( ) ; \n + channel . shutdownOutput ( ) . syncUninterruptibly ( ) ; \n + \n + channel . close ( ) . syncUninterruptibly ( ) ; \n + } finally { \n + if ( accepted ! = null ) { \n + try { \n + accepted . close ( ) ; \n + } catch ( IOException ignore ) { \n + / / ignore \n + } \n + } \n + try { \n + socket . close ( ) ; \n + } catch ( IOException ignore ) { \n + / / ignore \n + } \n + group . shutdownGracefully ( ) ; \n + } \n + } \n,Add Unit test for [ # 7143 ],381
"codec - socks \ src \ main \ java \ io \ netty \ handler \ codec \ socksx \ v5 \ DefaultSocks5CommandRequest . java \n - if ( dstPort < = 0 | | dstPort > = 65536 ) { \n - throw new IllegalArgumentException ( "" dstPort : "" + dstPort + "" ( expected : 1 ~ 65535 ) "" ) ; \n + if ( dstPort < 0 | | dstPort > 65535 ) { \n + throw new IllegalArgumentException ( "" dstPort : "" + dstPort + "" ( expected : 0 ~ 65535 ) "" ) ; \n codec - socks \ src \ test \ java \ io \ netty \ handler \ codec \ socksx \ v5 \ DefaultSocks5CommandRequestTest . java \n - "" παράδειγμα . δοκιμήπαράδει "" , 0 ) ; \n + "" παράδειγμα . δοκιμήπαράδει "" , - 1 ) ; \n + \n + new DefaultSocks5CommandRequest ( Socks5CommandType . BIND , Socks5AddressType . DOMAIN , \n + "" παράδειγμα . δοκιμήπαράδει "" , 0 ) ; \n + new DefaultSocks5CommandRequest ( Socks5CommandType . BIND , Socks5AddressType . DOMAIN , \n + "" παράδειγμα . δοκιμήπαράδει "" , 65535 ) ; \n","DefaultSocks5CommandRequest incorrectly rejects SOCKS5 commands with dstPort = 0 \n Motivation : \n According to SOCKS 5 spec , dstPort = 0 is a valid value in case of UDP ASSOCIATE . \n Modifications : \n - Allow 0 as port . \n - Add unit tests . \n Result : \n Fixes [ # 7156 ] .",381
"buffer \ src \ main \ java \ io \ netty \ buffer \ UnpooledByteBufAllocator . java \n + private final boolean noCleaner ; \n + this ( preferDirect , disableLeakDetector , PlatformDependent . useDirectBufferNoCleaner ( ) ) ; \n + } \n + \n + / * * \n + * Create a new instance \n + * \n + * @ param preferDirect { @ code true } if { @ link # buffer ( int ) } should try to allocate a direct buffer rather than \n + * a heap buffer \n + * @ param disableLeakDetector { @ code true } if the leak - detection should be disabled completely for this \n + * allocator . This can be useful if the user just want to depend on the GC to handle \n + * direct buffers when not explicit released . \n + * @ param tryNoCleaner { @ code true } if we should try to use { @ link PlatformDependent # allocateDirectNoCleaner ( int ) } \n + * to allocate direct memory . \n + * / \n + public UnpooledByteBufAllocator ( boolean preferDirect , boolean disableLeakDetector , boolean tryNoCleaner ) { \n + noCleaner = tryNoCleaner & & PlatformDependent . hasUnsafe ( ) \n + & & PlatformDependent . hasDirectBufferNoCleanerConstructor ( ) ; \n - buf = PlatformDependent . useDirectBufferNoCleaner ( ) ? \n - new InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf ( this , initialCapacity , maxCapacity ) : \n + buf = noCleaner ? new InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf ( this , initialCapacity , maxCapacity ) : \n common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + public static boolean hasDirectBufferNoCleanerConstructor ( ) { \n + return PlatformDependent0 . hasDirectBufferNoCleanerConstructor ( ) ; \n + } \n + \n",Allow to construct UnpooledByteBufAllocator that explictly always use sun . misc . Cleaner \n Motivation : \n When the user want to have the direct memory explicitly managed by the GC ( just as java . nio does ) it is useful to be able to construct an UnpooledByteBufAllocator that allows this without the chances to see any memory leak . \n Modifications : \n Allow to explicitly disable the usage of reflection to construct direct ByteBufs and so be sure these will be collected by GC . \n Result : \n More flexible way to use the UnpooledByteBufAllocator .,381
"all \ pom . xml \n - < excludes > io / netty / internal / tcnative / * * , io / netty / example / * * , META - INF / native / libnetty - tcnative * , META - INF / native / include / * * , META - INF / native / * * / * . a < / excludes > \n + < excludes > io / netty / internal / tcnative / * * , io / netty / example / * * , META - INF / native / libnetty _ tcnative * , META - INF / native / include / * * , META - INF / native / * * / * . a < / excludes > \n",Correctly filter out native tcnative lib \n Motivation : \n c93e58c453147ab5b34a708a85530d2372bbac81 changed to use _ for the tcnative lib name but missed to also adjust the filtering . \n Modifications : \n Fix filtering to look for _ \n Result : \n Not include native tcnative lib as expected .,381
transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ package - info . java \n - @ Deprecated \n,Remove @ Deprecated from package - info . java as intellij not likes it,381
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n - ref . close ( ) ; \n + ref . dispose ( ) ; \n - ref . clear ( ) ; \n - \n - if ( ! ref . close ( ) ) { \n + if ( ! ref . dispose ( ) ) { \n + boolean dispose ( ) { \n + clear ( ) ; \n + return allLeaks . remove ( this , LeakEntry . INSTANCE ) ; \n + } \n + \n",Fix regression in reporting leaks introduced by 3c8c7fc7e9c27f87e64aad5bd1df6c58ed8ef36e . \n Motivation : \n 3c8c7fc7e9c27f87e64aad5bd1df6c58ed8ef36e introduced some changes to the ResourceLeakDetector that introduced a regression and so would always log that paranoid leak detection should be enabled even it was already . \n Modifications : \n Correctly not clear the recorded stacktraces when we process the reference queue so we can log these . \n Result : \n ResourceLeakDetector works again as expected .,381
transport - native - epoll \ pom . xml \n - < content > release 6 . 8 < / content > \n + < content > release 6 . 9 < / content > \n,Check for latest centos release version when doing a release \n Motivation : \n We used to check for version 6 . 8 but the latest is 6 . 9 \n Modifications : \n Update version to 6 . 9 in the check . \n Result : \n Be able to cut a release on latest centos version,381
transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollStreamChannel . java \n + if ( close ) { \n + / / There is nothing left to read as we received an EOF . \n + readPending = false ; \n + } \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueStreamChannel . java \n + if ( close ) { \n + / / There is nothing left to read as we received an EOF . \n + readPending = false ; \n + } \n transport \ src \ main \ java \ io \ netty \ channel \ nio \ AbstractNioByteChannel . java \n + if ( close ) { \n + / / There is nothing left to read as we received an EOF . \n + readPending = false ; \n + } \n transport \ src \ main \ java \ io \ netty \ channel \ oio \ AbstractOioByteChannel . java \n + if ( close ) { \n + / / There is nothing left to read as we received an EOF . \n + readPending = false ; \n + } \n,"Set readPending to false when EOF is detected while issue an read \n Motivation : \n We need to set readPending to false when we detect a EOF while issue a read as otherwise we may not unregister from the Selector / Epoll / KQueue and so keep on receving wakeups . \n The important bit is that we may even get a wakeup for a read event but will still will only be able to read 0 bytes from the socket , so we need to be very careful when we clear the readPending . This can happen because we generally using edge - triggered mode for our native transports and because of the nature of edge - triggered we may schedule an read event just to find out there is nothing left to read atm ( because we completely drained the socket on the previous read ) . \n Modifications : \n Set readPending to false when EOF is detected . \n Result : \n Fixes [ # 7255 ] .",381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ HttpRequestEncoder . java \n - if ( uri . lastIndexOf ( SLASH ) < = start ) { \n + if ( uri . lastIndexOf ( SLASH ) < start ) { \n - if ( uri . lastIndexOf ( SLASH , index ) < = start ) { \n + if ( uri . lastIndexOf ( SLASH , index ) < start ) { \n",Only add / to uri if really needed . \n Motivation : \n We not need to include the start index in the check . See https : / / github . com / netty / netty / pull / 6924 # discussion _ r125263918 \n Modifications : \n Change < = to < \n Result : \n More correct code .,381
transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ DefaultRxtxChannelConfig . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ RxtxChannel . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ RxtxChannelConfig . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ RxtxChannelOption . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ RxtxDeviceAddress . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n transport - rxtx \ src \ main \ java \ io \ netty \ channel \ rxtx \ package - info . java \n + * \n + * @ deprecated this transport will be removed in the next major version . \n + @ Deprecated \n,Mark transport - rxtx as @ deprecated \n Motivation : \n transport - rxtx has no tests and there is really no easy way to add some . Beside this this transport is not really well maintained . \n Modifications : \n Mark transport - rxtx as @ deprecated so we can drop it in next major version . \n Result : \n Notify users of plan to drop the transport .,381
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n + @ SuppressWarnings ( "" unchecked "" ) \n + @ SuppressWarnings ( "" unchecked "" ) \n",Add supresswarnings to cleanup 16b1dbdf9244f831aa0cd92d5531d8cb61010b07 . \n Motivation : \n We should add @ SupressWarnings \n Modifications : \n Add annotations . \n Result : \n Less warnings,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n + ByteBuf buf = null ; \n - ByteBuf buf = wrapDataSize > 0 ? \n + buf = wrapDataSize > 0 ? \n + buf = null ; \n + buf = null ; \n + / / Ownership of buffer was not transferred , release it . \n + if ( buf ! = null ) { \n + buf . release ( ) ; \n + } \n",Fix possible leak in SslHandler if wrap ( . . . ) throws . \n Motivation : \n We can end up with a buffer leak if SSLEngine . wrap ( . . . ) throws . \n Modifications : \n Correctly release the ByteBuf if SSLEngine . wrap ( . . . ) throws . \n Result : \n Fixes [ # 7337 ] .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSsl . java \n + String staticLibName = "" netty _ tcnative "" ; \n + \n - libNames . add ( "" netty _ tcnative _ "" + os + ' _ ' + arch ) ; \n + libNames . add ( staticLibName + "" _ "" + os + ' _ ' + arch ) ; \n - libNames . add ( "" netty _ tcnative _ "" + os + ' _ ' + arch + "" _ fedora "" ) ; \n + libNames . add ( staticLibName + "" _ "" + os + ' _ ' + arch + "" _ fedora "" ) ; \n - / / finally the default library . \n - libNames . add ( "" netty _ tcnative "" ) ; \n + libNames . add ( staticLibName + "" _ "" + arch ) ; \n + libNames . add ( staticLibName ) ; \n",Take the architecture into account when loading netty - tcnative \n Motivation : \n We should ensure we only try to load the netty - tcnative version that was compiled for the architecture we are using . \n Modifications : \n Include architecture into native lib name . \n Result : \n Only load native lib if the architecture is supported .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n + if ( ! promise . setUncancellable ( ) ) { \n + return ; \n + } \n - if ( ! isActive ( ) ) { \n + / / After this point its not possible to cancel a write anymore . \n + if ( ! promise . setUncancellable ( ) ) { \n - promise . setFailure ( CLOSED _ CHANNEL _ EXCEPTION ) ; \n - / / After this point its not possible to cancel a write anymore . \n - if ( ! promise . setUncancellable ( ) ) { \n + if ( ! isActive ( ) ) { \n + promise . setFailure ( CLOSED _ CHANNEL _ EXCEPTION ) ; \n,Ensure we call promise . setUncancellable ( ) before trying to process in DefaultHttp2StreamChannel . \n Motivation : \n We should call promise . setUncancellable ( ) in DefaultHttp2StreamChannel . Unsafe impl to detect if the operation was cancelled . \n Modifications : \n Add promise . setUncancellable ( ) calls \n Result : \n More correct handling of cancelled promises,381
"transport - native - epoll \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ epoll _ $ { os . detected . arch } . so ; osname = linux ; processor = $ { os . detected . arch } , * < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ epoll _ $ { os . detected . arch } . so ; osname = Linux ; processor = $ { os . detected . arch } , * < / Bundle - NativeCode > \n transport - native - kqueue \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = darwin , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = darwin , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = OpenBSD , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = darwin , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = FreeBSD , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n",Use the correct osname in the Bundle - NativeCode declaration . \n Motivation : \n We need to ensure we use the correct osname in the Bundle - NativeCode declaration as declared in : \n https : / / www . osgi . org / developer / specifications / reference / \n Modifications : \n Update osname to match the spec . \n Result : \n Correct Bundle - NativeCode entry in the MANIFEST,381
common \ src \ main \ java \ io \ netty \ util \ ThreadDeathWatcher . java \n + / / Set to null to ensure we not create classloader leaks by holds a strong reference to the inherited \n + / / classloader . \n + / / See : \n + / / - https : / / github . com / netty / netty / issues / 7290 \n + / / - https : / / bugs . openjdk . java . net / browse / JDK - 7008595 \n + watcherThread . setContextClassLoader ( null ) ; \n + \n common \ src \ main \ java \ io \ netty \ util \ concurrent \ GlobalEventExecutor . java \n + / / Set to null to ensure we not create classloader leaks by holds a strong reference to the inherited \n + / / classloader . \n + / / See : \n + / / - https : / / github . com / netty / netty / issues / 7290 \n + / / - https : / / bugs . openjdk . java . net / browse / JDK - 7008595 \n + t . setContextClassLoader ( null ) ; \n + \n,Ensure ThreadDeathWatcher and GlobalEventExecutor will not cause classloader leaks . \n Motivation : \n ThreadDeathWatcher and GlobalEventExecutor may create and start a new thread from various other threads and so inherit the classloader . We need to ensure we not inherit to allow recycling the classloader . \n Modifications : \n Use Thread . setContextClassLoader ( null ) to ensure we not hold a strong reference to the classloader and so not leak it . \n Result : \n Fixes [ # 7290 ] .,381
resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsServerAddressStreamProviders . java \n + import io . netty . util . internal . PlatformDependent ; \n - UnixResolverDnsServerAddressStreamProvider . parseSilently ( ) ; \n + / / If on windows just use the DefaultDnsServerAddressStreamProvider . INSTANCE as otherwise \n + / / we will log some error which may be confusing . \n + PlatformDependent . isWindows ( ) ? DefaultDnsServerAddressStreamProvider . INSTANCE : \n + UnixResolverDnsServerAddressStreamProvider . parseSilently ( ) ; \n,Don ' t try to use UnixResolverDnsServerAddressStreamProvider when on Windows . \n Motivation : \n We should not try to use UnixResolverDnsServerAddressStreamProvider when on Windows as it will log some error that will produce noise and may confuse users . \n Modifications : \n Just use DefaultDnsServerAddressStreamProvider if windows is used . \n Result : \n Less noise in the logs . This was reported in vert . x : https : / / github . com / eclipse / vert . x / issues / 2204,381
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n - if ( netty _ unix _ socket _ getOption ( env , fd , IPPROTO _ TCP , TCP _ FASTOPEN _ CONNECT , & optval , sizeof ( optval ) ) = = - 1 ) { \n + int optlen = sizeof ( optval ) ; \n + / / We call getsockopt directly so we can handle ENOPROTOOPT by ourself . \n + if ( getsockopt ( fd , IPPROTO _ TCP , TCP _ FASTOPEN _ CONNECT , & optval , & optlen ) = = - 1 ) { \n + if ( errno = = ENOPROTOOPT ) { \n + / / Not supported by the system , so just return 0 . \n + return 0 ; \n + } \n + netty _ unix _ socket _ getOptionHandleError ( env , errno ) ; \n transport - native - epoll \ src \ test \ java \ io \ netty \ channel \ epoll \ EpollServerSocketChannelConfigTest . java \n + import io . netty . channel . ChannelOption ; \n + import java . util . Map ; \n + \n + @ Test \n + public void getGetOptions ( ) { \n + Map < ChannelOption < ? > , Object > map = ch . config ( ) . getOptions ( ) ; \n + assertFalse ( map . isEmpty ( ) ) ; \n + } \n transport - native - epoll \ src \ test \ java \ io \ netty \ channel \ epoll \ EpollSocketChannelConfigTest . java \n + import io . netty . channel . ChannelOption ; \n + import java . util . Map ; \n + \n + @ Test \n + public void getGetOptions ( ) { \n + Map < ChannelOption < ? > , Object > map = ch . config ( ) . getOptions ( ) ; \n + assertFalse ( map . isEmpty ( ) ) ; \n + } \n transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n - static void netty _ unix _ socket _ getOptionHandleError ( JNIEnv * env , int err ) { \n + void netty _ unix _ socket _ getOptionHandleError ( JNIEnv * env , int err ) { \n transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . h \n + / / These method is sometimes needed if you want to special handle some errno value before throwing an exception . \n + void netty _ unix _ socket _ getOptionHandleError ( JNIEnv * env , int err ) ; \n + \n + \n",EpollSocketChannelConfig . getOptions ( ) must not throw if TCP _ FASTOPEN _ CONNECT is not supported \n Motivation : \n If a user calls EpollSocketChannelConfig . getOptions ( ) and TCP _ FASTOPEN _ CONNECT is not supported we throw an exception . \n Modifications : \n - Just return 0 if ENOPROTOOPT is set . \n - Add testcase \n Result : \n getOptions ( ) works as epxected .,381
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n - int optlen = sizeof ( optval ) ; \n - / / We call getsockopt directly so we can handle ENOPROTOOPT by ourself . \n - if ( getsockopt ( fd , IPPROTO _ TCP , TCP _ FASTOPEN _ CONNECT , & optval , & optlen ) = = - 1 ) { \n + / / We call netty _ unix _ socket _ getOption0 directly so we can handle ENOPROTOOPT by ourself . \n + if ( netty _ unix _ socket _ getOption0 ( fd , IPPROTO _ TCP , TCP _ FASTOPEN _ CONNECT , & optval , sizeof ( optval ) ) = = - 1 ) { \n transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n - static int netty _ unix _ socket _ getOption0 ( jint fd , int level , int optname , void * optval , socklen _ t optlen ) { \n + int netty _ unix _ socket _ getOption0 ( jint fd , int level , int optname , void * optval , socklen _ t optlen ) { \n transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . h \n + int netty _ unix _ socket _ getOption0 ( jint fd , int level , int optname , void * optval , socklen _ t optlen ) ; \n",Not directly call getsockopt but use exported helper function \n Motivation : \n To better isolate OS system calls we should not call getsockopt directly but use our netty _ unix _ socket _ getOption0 function . See is a followup of f115bf5 . \n Modifications : \n Export netty _ unix _ socket _ getOption0 by declaring it in the header file and use it \n Result : \n Better isolation of system calls .,381
common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n + } catch ( NoClassDefFoundError e ) { \n + / / Also catch NoClassDefFoundError in case someone uses for example OSGI and it made \n + / / Unsafe unloadable . \n + return e ; \n,Guard against NoClassDefFoundError when trying to load Unsafe . \n Motivation : \n OSGI and other enviroments may not allow to even load Unsafe which will lead to an NoClassDefFoundError when trying to access it . We should guard against this . \n Modifications : \n Catch NoClassDefFoundError when trying to load Unsafe . \n Result : \n Be able to use netty with a strict OSGI config .,381
"codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpRequestDecoderTest . java \n + import io . netty . handler . codec . TooLongFrameException ; \n + \n + @ Test \n + public void testTooLargeInitialLine ( ) { \n + EmbeddedChannel channel = new EmbeddedChannel ( new HttpRequestDecoder ( 10 , 1024 , 1024 ) ) ; \n + String requestStr = "" GET / some / path HTTP / 1 . 1 \ r \ n "" + \n + "" Host : localhost1 \ r \ n \ r \ n "" ; \n + \n + assertTrue ( channel . writeInbound ( Unpooled . copiedBuffer ( requestStr , CharsetUtil . US _ ASCII ) ) ) ; \n + HttpRequest request = channel . readInbound ( ) ; \n + assertTrue ( request . decoderResult ( ) . isFailure ( ) ) ; \n + assertTrue ( request . decoderResult ( ) . cause ( ) instanceof TooLongFrameException ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n + \n + @ Test \n + public void testTooLargeHeaders ( ) { \n + EmbeddedChannel channel = new EmbeddedChannel ( new HttpRequestDecoder ( 1024 , 10 , 1024 ) ) ; \n + String requestStr = "" GET / some / path HTTP / 1 . 1 \ r \ n "" + \n + "" Host : localhost1 \ r \ n \ r \ n "" ; \n + \n + assertTrue ( channel . writeInbound ( Unpooled . copiedBuffer ( requestStr , CharsetUtil . US _ ASCII ) ) ) ; \n + HttpRequest request = channel . readInbound ( ) ; \n + assertTrue ( request . decoderResult ( ) . isFailure ( ) ) ; \n + assertTrue ( request . decoderResult ( ) . cause ( ) instanceof TooLongFrameException ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n",Add tests for HttpObjectDecoder related to limits \n Motivation : \n HttpObjectDecoder will throw a TooLongFrameException when either the max size for the initial line or the header size was exceeed . We have no tests for this . \n Modifications : \n Add test cases . \n Result : \n More tests .,381
transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollChannel . java \n - ReferenceCountUtil . safeRelease ( holder ) ; \n + ReferenceCountUtil . release ( holder ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueChannel . java \n - ReferenceCountUtil . safeRelease ( holder ) ; \n + ReferenceCountUtil . release ( holder ) ; \n,"Not use safeRelease ( . . . ) but release ( . . . ) to release non - readable holders to ensure we not mask errors . \n Motivation : \n AbstractChannel attempts to "" filter "" messages which are written [ 1 ] . A goal of this process is to copy from heap to direct if necessary . However implementations of this method [ 2 ] [ 3 ] may translate a buffer with 0 readable bytes to EMPTY _ BUFFER . This may mask a user error where an empty buffer is written but already released . \n Modifications : \n Replace safeRelease ( . . . ) with release ( . . . ) to ensure we propagate reference count issues . \n Result : \n Fixes [ # 7383 ]",381
common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n + \n + @ Override \n + protected void onRemoval ( Stack < T > value ) { \n + / / Let us remove the WeakOrderQueue from the WeakHashMap directly if its safe to remove some overhead \n + if ( value . threadRef . get ( ) = = Thread . currentThread ( ) ) { \n + if ( DELAYED _ RECYCLED . isSet ( ) ) { \n + DELAYED _ RECYCLED . get ( ) . remove ( value ) ; \n + } \n + } \n + } \n,Remove WeakOrderedQueue from WeakHashMap when FastThreadLocal value was removed if possible . \n Motivation : \n We should remove the WeakOrderedQueue from the WeakHashMap directly if possible and only depend on the semantics of the WeakHashMap if there is no other way for us to cleanup it . \n Modifications : \n Override onRemoval ( . . . ) to remove the WeakOrderedQueue if possible . \n Result : \n Less overhead and quicker collection of WeakOrderedQueue for some cases .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ CompositeBufferGatheringWriteTest . java \n + import io . netty . channel . ChannelFutureListener ; \n + import java . io . IOException ; \n - final AtomicReference < ByteBuf > clientReceived = new AtomicReference < ByteBuf > ( ) ; \n + final AtomicReference < Object > clientReceived = new AtomicReference < Object > ( ) ; \n - public void channelRead ( ChannelHandlerContext ctx , Object msg ) { \n - ReferenceCountUtil . release ( msg ) ; \n - ctx . writeAndFlush ( newCompositeBuffer ( ctx . alloc ( ) ) ) ; \n + public void channelActive ( ChannelHandlerContext ctx ) throws Exception { \n + ctx . writeAndFlush ( newCompositeBuffer ( ctx . alloc ( ) ) ) \n + . addListener ( ChannelFutureListener . CLOSE ) ; \n - if ( aggregator . readableBytes ( ) = = EXPECTED _ BYTES ) { \n - if ( clientReceived . compareAndSet ( null , aggregator ) ) { \n - latch . countDown ( ) ; \n - } \n - } \n + \n + @ Override \n + public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) throws Exception { \n + / / IOException is fine as it will also close the channel and may just be a connection reset . \n + if ( ! ( cause instanceof IOException ) ) { \n + clientReceived . set ( cause ) ; \n + latch . countDown ( ) ; \n + } \n + } \n + \n + @ Override \n + public void channelInactive ( ChannelHandlerContext ctx ) throws Exception { \n + if ( clientReceived . compareAndSet ( null , aggregator ) ) { \n + try { \n + assertEquals ( EXPECTED _ BYTES , aggregator . readableBytes ( ) ) ; \n + } catch ( Throwable cause ) { \n + aggregator . release ( ) ; \n + aggregator = null ; \n + clientReceived . set ( cause ) ; \n + } finally { \n + latch . countDown ( ) ; \n + } \n + } \n + } \n - clientChannel . writeAndFlush ( expected . retainedSlice ( ) ) ; \n - ByteBuf actual = clientReceived . get ( ) ; \n - assertEquals ( expected , actual ) ; \n - expected . release ( ) ; \n - actual . release ( ) ; \n + Object received = clientReceived . get ( ) ; \n + if ( received instanceof ByteBuf ) { \n + ByteBuf actual = ( ByteBuf ) received ; \n + assertEquals ( expected , actual ) ; \n + expected . release ( ) ; \n + actual . release ( ) ; \n + } else { \n + expected . release ( ) ; \n + throw ( Throwable ) received ; \n + } \n",Fix flacky test introduced by af2f343648f4cb3deca5314174e0e579f9fec846 \n Motivation : \n af2f343648f4cb3deca5314174e0e579f9fec846 introduced a test - case which was flacky due of multiple problems : \n - we called writeAndFlush ( . . . ) in channelRead ( . . . ) and assumed it will only be called once . This is true most of the times but it may be called multile times if the data is fragemented . \n - we didnt guard against the possibility that channelRead ( . . . ) is called with an empty buffer \n Modifications : \n - Call writeAndFlush ( . . . ) in channelActive ( . . . ) so we are sure its only called once and close the channel once we wrote the data \n - only compare the data after we received a close so we are sure there isnt anything extra received \n - check for exception and if we catched one fail the test . \n Result : \n No flacky test anymore and easier to debug issues that accour because of a catched exception .,381
"transport \ src \ main \ java \ io \ netty \ channel \ embedded \ EmbeddedChannel . java \n - import io . netty . util . internal . UnstableApi ; \n - return ( T ) poll ( inboundMessages ) ; \n + T message = ( T ) poll ( inboundMessages ) ; \n + if ( message ! = null ) { \n + ReferenceCountUtil . touch ( message , "" Caller of readInbound ( ) will handle the message from this point "" ) ; \n + } \n + return message ; \n - return ( T ) poll ( outboundMessages ) ; \n + T message = ( T ) poll ( outboundMessages ) ; \n + if ( message ! = null ) { \n + ReferenceCountUtil . touch ( message , "" Caller of readOutbound ( ) will handle the message from this point . "" ) ; \n + } \n + return message ; \n",Add a hint of ownership transfer when calling EmbeddedChannel . read * ( ) methods . \n Motivation : \n As shown in issues it is sometimes hard to understand why a leak was reported when the user just calles EmbeddedChannel . readInbound ( ) / EmbeddedChannel . readOutbound ( ) and drop the message on the floor . \n Modifications : \n Add a hint before handover the message to the user and transfer the ownership . \n Result : \n Easier debugging of leaks caused by EmbeddedChannel . read * ( ) .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketTestPermutation . java \n - static final String BAD _ HOST = SystemPropertyUtil . get ( "" io . netty . testsuite . badHost "" , "" netty . io "" ) ; \n + static final String BAD _ HOST = SystemPropertyUtil . get ( "" io . netty . testsuite . badHost "" , "" 198 . 51 . 100 . 254 "" ) ; \n","Use 198 . 51 . 100 . 254 as BAD _ HOST for tests . \n Motivation : \n At the moment we use netty . io as BAD _ HOST with an port that we know is timing out . This may change in the future so we should better use 198 . 51 . 100 . 254 which is specified as "" for documentation only "" . \n Modifications : \n Replace netty . io with 198 . 51 . 100 . 254 in tests that depend on BAD _ HOST . \n Result : \n More future proof code .",381
"common \ src \ main \ java \ io \ netty \ util \ concurrent \ FastThreadLocal . java \n - final InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap . get ( ) ; \n + InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap . get ( ) ; \n + registerCleaner ( threadLocalMap ) ; \n + return value ; \n + } \n + \n + private void registerCleaner ( final InternalThreadLocalMap threadLocalMap ) { \n - return value ; \n - set ( InternalThreadLocalMap . get ( ) , value ) ; \n + InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap . get ( ) ; \n + boolean alreadySet = threadLocalMap . isIndexedVariableSet ( index ) ; \n + set ( threadLocalMap , value ) ; \n + \n + if ( ! alreadySet ) { \n + registerCleaner ( threadLocalMap ) ; \n + } \n common \ src \ test \ java \ io \ netty \ util \ concurrent \ FastThreadLocalTest . java \n - public void testOnRemoveCalledForFastThreadLocal ( ) throws Exception { \n - testOnRemoveCalled ( true ) ; \n + public void testOnRemoveCalledForFastThreadLocalGet ( ) throws Exception { \n + testOnRemoveCalled ( true , true ) ; \n - public void testOnRemoveCalledForNonFastThreadLocal ( ) throws Exception { \n - testOnRemoveCalled ( false ) ; \n + public void testOnRemoveCalledForNonFastThreadLocalGet ( ) throws Exception { \n + testOnRemoveCalled ( false , true ) ; \n - private static void testOnRemoveCalled ( boolean fastThreadLocal ) throws Exception { \n + @ Test ( timeout = 4000 ) \n + public void testOnRemoveCalledForFastThreadLocalSet ( ) throws Exception { \n + testOnRemoveCalled ( true , false ) ; \n + } \n + \n + @ Test ( timeout = 4000 ) \n + public void testOnRemoveCalledForNonFastThreadLocalSet ( ) throws Exception { \n + testOnRemoveCalled ( false , false ) ; \n + } \n + \n + private static void testOnRemoveCalled ( boolean fastThreadLocal , final boolean callGet ) throws Exception { \n - assertEquals ( Thread . currentThread ( ) . getName ( ) , threadLocal . get ( ) ) ; \n - assertEquals ( Thread . currentThread ( ) . getName ( ) , threadLocal2 . get ( ) ) ; \n + if ( callGet ) { \n + assertEquals ( Thread . currentThread ( ) . getName ( ) , threadLocal . get ( ) ) ; \n + assertEquals ( Thread . currentThread ( ) . getName ( ) , threadLocal2 . get ( ) ) ; \n + } else { \n + threadLocal . set ( Thread . currentThread ( ) . getName ( ) ) ; \n + threadLocal2 . set ( Thread . currentThread ( ) . getName ( ) ) ; \n + } \n",Ensure ObjectCleaner will also be used when FastThreadLocal . set is used . \n Motivation : \n e329ca1 introduced the user of ObjectCleaner in FastThreadLocal but we missed the case to register our cleaner task if FastThreadLocal . set was called only . \n Modifications : \n - Use ObjectCleaner also when FastThreadLocal . set is used . \n - Add test case . \n Result : \n ObjectCleaner is always used .,381
buffer \ src \ main \ java \ io \ netty \ buffer \ ReadOnlyUnsafeDirectByteBuf . java \n + @ Override \n + public boolean hasMemoryAddress ( ) { \n + return true ; \n + } \n + \n + @ Override \n + public long memoryAddress ( ) { \n + return memoryAddress ; \n + } \n + \n buffer \ src \ test \ java \ io \ netty \ buffer \ ReadOnlyDirectByteBufferBufTest . java \n + \n + @ Test \n + public void testMemoryAddress ( ) { \n + ByteBuf buf = buffer ( allocate ( 8 ) . asReadOnlyBuffer ( ) ) ; \n + try { \n + Assert . assertFalse ( buf . hasMemoryAddress ( ) ) ; \n + try { \n + buf . memoryAddress ( ) ; \n + Assert . fail ( ) ; \n + } catch ( UnsupportedOperationException expected ) { \n + / / expected \n + } \n + } finally { \n + buf . release ( ) ; \n + } \n + } \n buffer \ src \ test \ java \ io \ netty \ buffer \ ReadOnlyUnsafeDirectByteBufferBufTest . java \n + import org . junit . Assert ; \n + import org . junit . Test ; \n + \n + @ Test \n + @ Override \n + public void testMemoryAddress ( ) { \n + ByteBuf buf = buffer ( allocate ( 8 ) . asReadOnlyBuffer ( ) ) ; \n + try { \n + Assert . assertTrue ( buf . hasMemoryAddress ( ) ) ; \n + buf . memoryAddress ( ) ; \n + } finally { \n + buf . release ( ) ; \n + } \n + } \n,ReadOnlyUnsafeDirectByteBuf . memoryAddress ( ) should not throw \n Motivation : \n We need the memoryAddress of a direct buffer when using our native transports . For this reason ReadOnlyUnsafeDirectByteBuf . memoryAddress ( ) should not throw . \n Modifications : \n - Correctly override ReadOnlyUnsafeDirectByteBuf . memoryAddress ( ) and hasMemoryAddress ( ) \n - Add test case \n Result : \n Fixes [ # 7672 ] .,381
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ CharSequenceValueConverter . java \n - if ( value instanceof AsciiString ) { \n + if ( value instanceof AsciiString & & value . length ( ) = = 1 ) { \n codec \ src \ test \ java \ io \ netty \ handler \ codec \ CharSequenceValueConverterTest . java \n + import io . netty . util . AsciiString ; \n + @ Test \n + public void testByteFromAsciiString ( ) { \n + assertEquals ( 127 , converter . convertToByte ( AsciiString . of ( "" 127 "" ) ) ) ; \n + } \n + \n + @ Test ( expected = NumberFormatException . class ) \n + public void testByteFromEmptyAsciiString ( ) { \n + converter . convertToByte ( AsciiString . EMPTY _ STRING ) ; \n + } \n + \n",Fix CharSequenceValueConverter . convertToByte implementation for AsciiString ( # 7994 ) \n Motivation : \n The implementation of CharSequenceValueConverter . convertToByte did not correctly handle AsciiString if the length ! = 1 . \n Modifications : \n - Only use fast - path for AsciiString with length of 1 . \n - Add unit tests . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7990,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslHandlerTest . java \n + private static SSLEngine newServerModeSSLEngine ( ) throws NoSuchAlgorithmException { \n + SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n + / / Set the mode before we try to do the handshake as otherwise it may throw an IllegalStateException . \n + / / See : \n + / / - https : / / docs . oracle . com / javase / 10 / docs / api / javax / net / ssl / SSLEngine . html # beginHandshake ( ) \n + / / - http : / / mail . openjdk . java . net / pipermail / security - dev / 2018 - July / 017715 . html \n + engine . setUseClientMode ( false ) ; \n + return engine ; \n + } \n + \n - SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n - engine . setUseClientMode ( false ) ; \n - \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n - SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n - engine . setUseClientMode ( false ) ; \n - \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n - SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n - engine . setUseClientMode ( false ) ; \n - \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n - SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n - engine . setUseClientMode ( false ) ; \n - \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n - SslHandler handler = new SslHandler ( SSLContext . getDefault ( ) . createSSLEngine ( ) ) ; \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n + SslHandler handler = new SslHandler ( engine ) ; \n - SSLEngine engine = SSLContext . getDefault ( ) . createSSLEngine ( ) ; \n + SSLEngine engine = newServerModeSSLEngine ( ) ; \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketSslClientRenegotiateTest . java \n - String renegotiation = clientSslHandler . engine ( ) . getSupportedCipherSuites ( ) [ 0 ] ; \n + String renegotiation = clientSslHandler . engine ( ) . getEnabledCipherSuites ( ) [ 0 ] ; \n + / / Use the first previous enabled ciphersuite and try to renegotiate . \n,"Adjust SSL related tests to be more correct and so pass in the next EA release of java11 . ( # 8162 ) \n Motivation : \n In some of our tests we not correctly init the SSLEngine before trying to perform a handshake which can cause an IllegalStateException . While this not happened in previous java releases it does now on Java11 ( which is "" ok "" as its even mentioned in the api docs ) . Beside this how we selected the ciphersuite to test renegotation was not 100 % safe . \n Modifications : \n - Correctly init SSLEngine before using it \n - Correctly select ciphersuite before testing for renegotation . \n Result : \n More correct tests and also pass on next java11 EA release .",381
"testsuite - shading \ src \ test \ java \ io \ netty \ testsuite \ shading \ ShadingIT . java \n + import org . junit . Ignore ; \n + @ Ignore ( "" Figure out why this sometimes fail on the CI "" ) \n",Disable test as it sometimes fails on the CI \n Motivation : \n Temporary disable test that wwas introduced as part of f60d08fd32b7287f65077f99a88bac645834098f as it sometimes fail on the CI . We need to figure out why it fails there ( can not reproduce so far even on the CI after ssh into it ) . \n Modifications : \n Ignore test . \n Result : \n More stable builds until we figure out the flackyness .,381
transport \ src \ main \ java \ io \ netty \ channel \ nio \ SelectedSelectionKeySet . java \n + @ Override \n + public boolean remove ( Object o ) { \n + return false ; \n + } \n + \n + @ Override \n + public boolean contains ( Object o ) { \n + return false ; \n + } \n + \n transport \ src \ test \ java \ io \ netty \ channel \ nio \ SelectedSelectionKeySetTest . java \n - assertTrue ( set . contains ( mockKey ) ) ; \n - assertTrue ( set . contains ( mockKey2 ) ) ; \n + assertFalse ( set . contains ( mockKey ) ) ; \n + assertFalse ( set . contains ( mockKey2 ) ) ; \n + assertFalse ( set . remove ( mockKey ) ) ; \n - try { \n - set . remove ( mockKey ) ; \n - fail ( ) ; \n - } catch ( UnsupportedOperationException expected ) { \n - / / expected \n - } \n,Correctly implement SelectedSelectionKeySet . remove ( . . . ) / contains ( . . . ) again so it works with the NIO Selector . \n Motivation : \n c1a335446daf5892eab2e134538ba0388162f18b reimplemented remove ( . . . ) and contains ( . . . ) in a way which made it not work anymore when used by the Selector . \n Modifications : \n Partly revert changes in c1a335446daf5892eab2e134538ba0388162f18b . \n Result : \n Works again as expected,381
transport \ src \ main \ java \ io \ netty \ channel \ nio \ SelectedSelectionKeySet . java \n + \n + @ Override \n + public void remove ( ) { \n + throw new UnsupportedOperationException ( ) ; \n + } \n new file \n transport \ test . log \n,Correctly implement SelectedSelectionKeySet . Iterator remove ( ) \n Motivation : \n We need to implement remove ( ) by ourselves to make it work on Java7 as otherwise it will throw an AbstractMethodError . This is a followup of c1a335446daf5892eab2e134538ba0388162f18b . \n Modifications : \n Just implemented remove ( ) \n Result : \n Works on Java7 as well .,381
resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n - if ( cachedEntries = = null | | cachedEntries . isEmpty ( ) ) { \n + if ( cachedEntries = = null ) { \n - assert numEntries > 0 ; \n + if ( numEntries = = 0 ) { \n + return false ; \n + } \n - if ( cachedEntries = = null | | cachedEntries . isEmpty ( ) ) { \n + if ( cachedEntries = = null ) { \n - assert numEntries > 0 ; \n + if ( numEntries = = 0 ) { \n + return false ; \n + } \n,Fix concurrency issue in DnsNameResolver when DefaultDnsCache is used . \n Motivation : \n We need to ensure we only call List . * methods in the synchronized block as the returned List may not be thread - safe . \n Modifications : \n Do not call isEmpty ( ) outside of the synchronized block . \n Result : \n Fixes [ # 7583 ],381
"new file \n docker \ Dockerfile - netty - centos6 \n + FROM centos : 6 \n + MAINTAINER netty @ googlegroups . com \n + ENTRYPOINT / bin / bash \n + \n + ENV SOURCE _ DIR $ HOME / source \n + ENV MAVEN _ VERSION 3 . 5 . 2 \n + ENV JAVA _ VERSION 1 . 8 . 0 \n + \n + RUN mkdir $ SOURCE _ DIR \n + WORKDIR $ SOURCE _ DIR \n + \n + # install dependencies \n + RUN yum install - y \ \n + apr - devel \ \n + autoconf \ \n + automake \ \n + git \ \n + glibc - devel \ \n + java - $ JAVA _ VERSION - openjdk - devel \ \n + libtool \ \n + lksctp - tools \ \n + lsb - core \ \n + make \ \n + openssl - devel \ \n + tar \ \n + wget \n + \n + \n + RUN wget - q http : / / archive . apache . org / dist / maven / maven - 3 / $ MAVEN _ VERSION / binaries / apache - maven - $ MAVEN _ VERSION - bin . tar . gz & & tar xfz apache - maven - $ MAVEN _ VERSION - bin . tar . gz & & mv apache - maven - $ MAVEN _ VERSION / opt / \n + \n + RUN echo ' PATH = / opt / apache - maven - $ MAVEN _ VERSION / bin : $ PATH ' > > ~ / . bashrc \n + RUN echo ' export JAVA _ HOME = "" / usr / lib / jvm / java - $ JAVA _ VERSION / "" ' > > ~ / . bashrc \n + \n + RUN rm - rf $ SOURCE _ DIR \n new file \n docker \ README . md \n + \n + * * Create a docker image * * \n + ` ` ` \n + docker build - f Dockerfile - netty - centos6 . - t netty - centos6 \n + ` ` ` \n + \n + * * Using the image * * \n + \n + ` ` ` \n + cd / path / to / netty / \n + ` ` ` \n + \n + ` ` ` \n + docker run - it - v ~ / . m2 : / root / . m2 - v ~ / . ssh : / root / . ssh - v ~ / . gnupg : / root / . gnupg - v ` pwd ` : / code - w / code netty - centos6 bash \n + ` ` ` \n",Provide a Docker image for reproducible builds \n Motivation : \n It would be good to provide a docker image for people that want to build netty on linux . \n Modifications : \n Add a docker file \n Result : \n People can more easily build netty . Fixes [ # 7585 ] .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2RemoteFlowController . java \n - for ( ; ; ) { \n - FlowControlled frame = pendingWriteQueue . poll ( ) ; \n - if ( frame = = null ) { \n - break ; \n - } \n - writeError ( frame , streamError ( stream . id ( ) , INTERNAL _ ERROR , cause , \n - "" Stream closed before write could take place "" ) ) ; \n + FlowControlled frame = pendingWriteQueue . poll ( ) ; \n + if ( frame ! = null ) { \n + / / Only create exception once and reuse to reduce overhead of filling in the stacktrace . \n + final Http2Exception exception = streamError ( stream . id ( ) , INTERNAL _ ERROR , cause , \n + "" Stream closed before write could take place "" ) ; \n + do { \n + writeError ( frame , exception ) ; \n + frame = pendingWriteQueue . poll ( ) ; \n + } while ( frame ! = null ) ; \n",Reduce overhead of cancel flowcontrolled writes . \n Motivation : \n When we cancel the flowcontrolled writes we did create a new StreamException for each write that was enqueued . Creating Exceptions is very expensive due of filling the stacktrace . \n Modifications : \n Only create the StreamException once and reuse the same for all the flowcontrolled writes ( per stream ) . \n Result : \n Less expensive to cancel flowcontrolled writes .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2ConnectionEncoder . java \n + / / \n + / / This just sets internal stream state which is used elsewhere in the codec and doesn ' t \n + / / necessarily mean the write will complete successfully . \n + \n + if ( ! future . isSuccess ( ) ) { \n + / / Either the future is not done or failed in the meantime . \n + notifyLifecycleManagerOnError ( future , ctx ) ; \n + } \n + / / This just sets internal stream state which is used elsewhere in the codec and doesn ' t \n + / / necessarily mean the write will complete successfully . \n + \n + if ( ! future . isSuccess ( ) ) { \n + / / Either the future is not done or failed in the meantime . \n + notifyLifecycleManagerOnError ( future , ctx ) ; \n + } \n + private void notifyLifecycleManagerOnError ( ChannelFuture future , final ChannelHandlerContext ctx ) { \n + future . addListener ( new ChannelFutureListener ( ) { \n + @ Override \n + public void operationComplete ( ChannelFuture future ) throws Exception { \n + Throwable cause = future . cause ( ) ; \n + if ( cause ! = null ) { \n + lifecycleManager . onError ( ctx , true , cause ) ; \n + } \n + } \n + } ) ; \n + } \n + \n + / / This just sets internal stream state which is used elsewhere in the codec and doesn ' t \n + / / necessarily mean the write will complete successfully . \n - } else { \n - lifecycleManager . onError ( ctx , true , failureCause ) ; \n",Ensure async failures are correctly propagated to Http2LifecycleManager . onError ( . . . ) in all cases . \n Motivation : \n If DefaultHttp2ConnectionEncoder process outbound operation it sometimes missed to call Http2LifecycleManager . onError ( . . . ) when the operation was executed asynchronously . \n Modifications : \n Make best effort to update flags but still ensure failures are propageted to Http2LifecycleManager . onError ( . . . ) in all cases . \n Result : \n More consistent handling of errors .,381
"transport \ src \ main \ java \ io \ netty \ channel \ VoidChannelPromise . java \n - private final boolean fireException ; \n + / / Will be null if we should not propagate exceptions through the pipeline on failure case . \n + private final ChannelFutureListener fireExceptionListener ; \n - public VoidChannelPromise ( Channel channel , boolean fireException ) { \n + public VoidChannelPromise ( final Channel channel , boolean fireException ) { \n - this . fireException = fireException ; \n + if ( fireException ) { \n + fireExceptionListener = new ChannelFutureListener ( ) { \n + @ Override \n + public void operationComplete ( ChannelFuture future ) throws Exception { \n + Throwable cause = future . cause ( ) ; \n + if ( cause ! = null ) { \n + fireException0 ( cause ) ; \n + } \n + } \n + } ; \n + } else { \n + fireExceptionListener = null ; \n + } \n - fireException ( cause ) ; \n + fireException0 ( cause ) ; \n - fireException ( cause ) ; \n + fireException0 ( cause ) ; \n - if ( fireException ) { \n - promise . addListener ( new ChannelFutureListener ( ) { \n - @ Override \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n - if ( ! future . isSuccess ( ) ) { \n - fireException ( future . cause ( ) ) ; \n - } \n - } \n - } ) ; \n + if ( fireExceptionListener ! = null ) { \n + promise . addListener ( fireExceptionListener ) ; \n - private void fireException ( Throwable cause ) { \n + private void fireException0 ( Throwable cause ) { \n - if ( fireException & & channel . isRegistered ( ) ) { \n + if ( fireExceptionListener ! = null & & channel . isRegistered ( ) ) { \n",Reduce object allocation by using same ChannelFutureListener instance . \n Motivation : \n When VoidChannelPromise . unvoid ( ) was called we created a new ChannelFutureListener everytime . This is not needed as its stateless . \n Modifications : \n Reuse the ChannelFutureListener . \n Result : \n Less object allocations,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ ObjectCleaner . java \n - import io . netty . util . internal . logging . InternalLogger ; \n - import io . netty . util . internal . logging . InternalLoggerFactory ; \n + \n + / / Package - private for testing \n + static final String CLEANER _ THREAD _ NAME = ObjectCleaner . class . getSimpleName ( ) + "" Thread "" ; \n - private static final String CLEANER _ THREAD _ NAME = ObjectCleaner . class . getSimpleName ( ) + "" Thread "" ; \n - / / This Thread is not a daemon as it will die once all references to the registered Objects will go away \n - / / and its important to always invoke all cleanup tasks as these may free up direct memory etc . \n - cleanupThread . setDaemon ( false ) ; \n + / / Mark this as a daemon thread to ensure that we the JVM can exit if this is the only thread that is \n + / / running . \n + cleanupThread . setDaemon ( true ) ; \n common \ src \ test \ java \ io \ netty \ util \ internal \ ObjectCleanerTest . java \n + import static org . junit . Assert . assertNotNull ; \n + import static org . junit . Assert . assertTrue ; \n + \n + @ Test ( timeout = 5000 ) \n + public void testCleanerThreadIsDaemon ( ) throws Exception { \n + temporaryObject = new Object ( ) ; \n + ObjectCleaner . register ( temporaryObject , new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + / / NOOP \n + } \n + } ) ; \n + \n + Thread cleanerThread = null ; \n + \n + for ( Thread thread : Thread . getAllStackTraces ( ) . keySet ( ) ) { \n + if ( thread . getName ( ) . equals ( ObjectCleaner . CLEANER _ THREAD _ NAME ) ) { \n + cleanerThread = thread ; \n + break ; \n + } \n + } \n + assertNotNull ( cleanerThread ) ; \n + assertTrue ( cleanerThread . isDaemon ( ) ) ; \n + } \n",ObjectCleanerThread must be a deamon thread to ensure the JVM can always terminate . \n Motivation : \n The ObjectCleanerThread must be a daemon thread as otherwise we may block the JVM from exit . By using a daemon thread we basically give the same garantees as the JVM when it comes to cleanup of resources ( as the GC threads are also daemon threads and the CleanerImpl uses a deamon thread as well in Java9 + ) . \n Modifications : \n Change ObjectCleanThread to be a daemon thread . \n Result : \n JVM shutdown will always be able to complete . Fixed [ # 7617 ] .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - / / TODO : We may be able to optimize when we really need to call flush ( . . . ) during channelReadComplete ( . . . ) \n - / / by checking if this is true and only then call flush ( . . . ) . \n - private boolean flushNeeded ; \n - / / TODO : I think this is not really necessary and we should be able to optimize this in the future by \n - / / checking flushNeeded and only flush if this returns true . \n - @ Override \n - public final void flush ( ChannelHandlerContext ctx ) { \n - flushNeeded = false ; \n - super . flush ( ctx ) ; \n - } \n - \n - flushNeeded | = flushPending ; \n - flushPending = false ; \n,Cleanup Http2MultiplexCodec by removing out - dated TODO \n Motivation : \n Http2MultiplexCodec contains some TODO that is outdated . \n Modifications : \n Remove TODO which is outdated \n Result : \n Cleaner code .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - private boolean flushPending ; \n - / / If we are current channelReadComplete ( . . . ) call we should just mark this Channel with a flush \n - / / pending . We will ensure we trigger ctx . flush ( ) after we processed all Channels later on and \n + / / If we are currently in the channelReadComplete ( . . . ) call we should just ignore the flush . \n + / / We will ensure we trigger ctx . flush ( ) after we processed all Channels later on and \n - if ( inFireChannelReadComplete ) { \n - flushPending = true ; \n - } else { \n + if ( ! inFireChannelReadComplete ) { \n,Remove unused variable in DefaultHttp2StreamChannel \n Motivation : \n We should remove unused variable ( was never read ) . \n Modifications : \n Remove unused variable ( was never read ) . \n Result : \n Cleanup .,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ ByteBufUtil . java \n - decoder . decode ( buf . internalNioBuffer ( index , length ) ) ; \n + decoder . decode ( buf . nioBuffer ( index , length ) ) ; \n - ByteBuf heapBuffer = buf . alloc ( ) . heapBuffer ( length ) ; \n + ByteBuf heapBuffer = buf . alloc ( ) . heapBuffer ( length ) ; \n buffer \ src \ test \ java \ io \ netty \ buffer \ ByteBufUtilTest . java \n + import java . nio . Buffer ; \n + import java . util . ArrayList ; \n + import java . util . List ; \n + import java . util . concurrent . atomic . AtomicInteger ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n + @ Test \n + public void testIsTextMultiThreaded ( ) throws Throwable { \n + final ByteBuf buffer = Unpooled . copiedBuffer ( "" Hello , World ! "" , CharsetUtil . ISO _ 8859 _ 1 ) ; \n + \n + try { \n + final AtomicInteger counter = new AtomicInteger ( 60000 ) ; \n + final AtomicReference < Throwable > errorRef = new AtomicReference < Throwable > ( ) ; \n + List < Thread > threads = new ArrayList < Thread > ( ) ; \n + for ( int i = 0 ; i < 10 ; i + + ) { \n + Thread thread = new Thread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + try { \n + while ( errorRef . get ( ) = = null & & counter . decrementAndGet ( ) > 0 ) { \n + assertTrue ( ByteBufUtil . isText ( buffer , CharsetUtil . ISO _ 8859 _ 1 ) ) ; \n + } \n + } catch ( Throwable cause ) { \n + errorRef . compareAndSet ( null , cause ) ; \n + } \n + } \n + } ) ; \n + threads . add ( thread ) ; \n + } \n + for ( Thread thread : threads ) { \n + thread . start ( ) ; \n + } \n + \n + for ( Thread thread : threads ) { \n + thread . join ( ) ; \n + } \n + \n + Throwable error = errorRef . get ( ) ; \n + if ( error ! = null ) { \n + throw error ; \n + } \n + } finally { \n + buffer . release ( ) ; \n + } \n + } \n",ByteBufUtil . isText method should be safe to be called concurrently \n Motivation : \n ByteBufUtil . isText ( . . . ) may produce unexpected results if called concurrently on the same ByteBuffer . \n Modifications : \n - Don ' t use internalNioBuffer where it is not safe . \n - Add unit test . \n Result : \n ByteBufUtil . isText is thread - safe .,381
buffer \ src \ test \ java \ io \ netty \ buffer \ AbstractByteBufTest . java \n - @ Test ( timeout = 5000 ) \n + @ Test ( timeout = 10000 ) \n - final AtomicInteger counter = new AtomicInteger ( 60000 ) ; \n + final AtomicInteger counter = new AtomicInteger ( 30000 ) ; \n,Increase timeout and decrement number of operations in AbstractByteBufTest . testToStringMultipleThreads \n Motivation : \n We saw some timeouts on the CI when the leak detection is enabled . \n Modifications : \n - Use smaller number of operations in test \n - Increase timeout \n Result : \n CI not times out .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - final SSLEngineResult result = handler . engine . unwrap ( toByteBuffer ( in , readerIndex , len ) , \n + ByteBuffer inNioBuffer = toByteBuffer ( in , readerIndex , len ) ; \n + int position = inNioBuffer . position ( ) ; \n + final SSLEngineResult result = handler . engine . unwrap ( inNioBuffer , \n + \n + / / This is a workaround for a bug in Android 5 . 0 . Android 5 . 0 does not correctly update the \n + / / SSLEngineResult . bytesConsumed ( ) in some cases and just return 0 . \n + / / \n + / / See : \n + / / - https : / / android - review . googlesource . com / c / platform / external / conscrypt / + / 122080 \n + / / - https : / / github . com / netty / netty / issues / 7758 \n + if ( result . bytesConsumed ( ) = = 0 ) { \n + int consumed = inNioBuffer . position ( ) - position ; \n + if ( consumed ! = result . bytesConsumed ( ) ) { \n + / / Create a new SSLEngineResult with the correct bytesConsumed ( ) . \n + return new SSLEngineResult ( \n + result . getStatus ( ) , result . getHandshakeStatus ( ) , consumed , result . bytesProduced ( ) ) ; \n + } \n + } \n",Workaround SSLEngine . unwrap ( . . . ) bug in Android 5 . 0 \n Motivation : \n Android 5 . 0 sometimes not correctly update the bytesConsumed of the SSLEngineResult when consuming data from the input ByteBuffer . This will lead to handshake failures . \n Modifications : \n Add a workaround for Android 5 . 0 \n Result : \n Be able to use netty on Android 5 . 0 by fixing https : / / github . com / netty / netty / issues / 7758 .,381
"common \ src \ main \ java \ io \ netty \ util \ HashedWheelTimer . java \n + \n + / / Guard against overflow . \n + if ( delay > 0 & & deadline < 0 ) { \n + deadline = Long . MAX _ VALUE ; \n + } \n common \ src \ test \ java \ io \ netty \ util \ HashedWheelTimerTest . java \n + @ Test \n + public void testOverflow ( ) throws InterruptedException { \n + final HashedWheelTimer timer = new HashedWheelTimer ( ) ; \n + final CountDownLatch latch = new CountDownLatch ( 1 ) ; \n + Timeout timeout = timer . newTimeout ( new TimerTask ( ) { \n + @ Override \n + public void run ( Timeout timeout ) { \n + latch . countDown ( ) ; \n + } \n + } , Long . MAX _ VALUE , TimeUnit . MILLISECONDS ) ; \n + assertFalse ( latch . await ( 1 , TimeUnit . SECONDS ) ) ; \n + timeout . cancel ( ) ; \n + timer . stop ( ) ; \n + } \n + \n",HashedWheelTimer . newTimeout ( . . . ) may overflow \n Motivation : \n We dont protect from overflow and so the timer may fire too early if a large timeout is used . \n Modifications : \n Add overflow guard and a test . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7760 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - sessionContext ( ) . destroy ( ) ; \n + \n + OpenSslSessionContext context = sessionContext ( ) ; \n + if ( context ! = null ) { \n + context . destroy ( ) ; \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslContextBuilderTest . java \n + import javax . net . ssl . SSLException ; \n + import java . util . Collections ; \n + @ Test ( expected = IllegalArgumentException . class ) \n + public void testInvalidCipherJdk ( ) throws Exception { \n + Assume . assumeTrue ( OpenSsl . isAvailable ( ) ) ; \n + testInvalidCipher ( SslProvider . JDK ) ; \n + } \n + \n + @ Test ( expected = SSLException . class ) \n + public void testInvalidCipherOpenSSL ( ) throws Exception { \n + Assume . assumeTrue ( OpenSsl . isAvailable ( ) ) ; \n + testInvalidCipher ( SslProvider . OPENSSL ) ; \n + } \n + \n + private static void testInvalidCipher ( SslProvider provider ) throws Exception { \n + SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n + SslContextBuilder builder = SslContextBuilder . forClient ( ) \n + . sslProvider ( provider ) \n + . ciphers ( Collections . singleton ( "" SOME _ INVALID _ CIPHER "" ) ) \n + . keyManager ( cert . certificate ( ) , \n + cert . privateKey ( ) ) \n + . trustManager ( cert . certificate ( ) ) ; \n + SslContext context = builder . build ( ) ; \n + context . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + } \n + \n","Fix NPE exception when using invalid cipher during building SslContext . ( # 8171 ) \n Motivation : \n We missed to do a null check before trying to destroy the OpenSslSessionContext , which could lead to a NPE . \n Modifications : \n Add null check and tests . \n Result : \n Fix https : / / github . com / netty / netty / issues / 8170 .",381
common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - DIRECT _ MEMORY _ LIMIT = maxDirectMemory ; \n + DIRECT _ MEMORY _ LIMIT = maxDirectMemory > = 1 ? maxDirectMemory : MAX _ DIRECT _ MEMORY ; \n - return MAX _ DIRECT _ MEMORY ; \n + return DIRECT _ MEMORY _ LIMIT ; \n,PlatformDependent . maxDirectMemory ( ) must respect io . netty . maxDirectMemory ( # 8452 ) \n Motivation : \n In netty we use our own max direct memory limit that can be adjusted by io . netty . maxDirectMemory but we do not take this in acount when maxDirectMemory ( ) is used . That will lead to non optimal configuration of PooledByteBufAllocator in some cases . \n This came up on stackoverflow : \n https : / / stackoverflow . com / questions / 53097133 / why - is - default - num - direct - arena - derived - from - platformdependent - maxdirectmemory \n Modifications : \n Correctly respect io . netty . maxDirectMemory and so configure PooledByteBufAllocator correctly by default . \n Result : \n Correct value for max direct memory .,381
"common \ src \ main \ java \ io \ netty \ util \ HashedWheelTimer . java \n + private static final long MILLISECOND _ NANOS = TimeUnit . MILLISECONDS . toNanos ( 1 ) ; \n - this . tickDuration = unit . toNanos ( tickDuration ) ; \n + long duration = unit . toNanos ( tickDuration ) ; \n - if ( this . tickDuration > = Long . MAX _ VALUE / wheel . length ) { \n + if ( duration > = Long . MAX _ VALUE / wheel . length ) { \n + \n + if ( duration < MILLISECOND _ NANOS ) { \n + if ( logger . isWarnEnabled ( ) ) { \n + logger . warn ( "" Configured tickDuration % d smaller then % d , using 1ms . "" , \n + tickDuration , MILLISECOND _ NANOS ) ; \n + } \n + this . tickDuration = MILLISECOND _ NANOS ; \n + } else { \n + this . tickDuration = duration ; \n + } \n + \n",Make it clear that HashedWheelTimer only support millis . ( # 8322 ) \n Motivation : \n HWT does not support anything smaller then 1ms so we should make it clear that this is the case . \n Modifications : \n Log a warning if < 1ms is used . \n Result : \n Less suprising behaviour .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslContext . java \n - int i = 0 ; \n - for ( ; i < certs . length ; i + + ) { \n - InputStream is = new ByteBufInputStream ( certs [ i ] , true ) ; \n + for ( int i = 0 ; i < certs . length ; i + + ) { \n + InputStream is = new ByteBufInputStream ( certs [ i ] , false ) ; \n - for ( ; i < certs . length ; i + + ) { \n - certs [ i ] . release ( ) ; \n + for ( ByteBuf buf : certs ) { \n + buf . release ( ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslContextTest . java \n + import java . security . cert . CertificateException ; \n + @ Test ( expected = CertificateException . class ) \n + public void test ( ) throws CertificateException { \n + SslContext . toX509Certificates ( new File ( getClass ( ) . getResource ( "" ec _ params _ unsupported . pem "" ) . getFile ( ) ) ) ; \n + } \n + \n new file \n handler \ src \ test \ resources \ io \ netty \ handler \ ssl \ ec _ params _ unsupported . pem \n + - - - - - BEGIN CERTIFICATE - - - - - \n + MIIC8TCCApagAwIBAgIJAOeu9WKx0IutMAoGCCqGSM49BAMCMFkxCzAJBgNVBAYT \n + AkFVMRMwEQYDVQQIDApTb21lLVN0YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRn \n + aXRzIFB0eSBMdGQxEjAQBgNVBAMMCWxvY2FsaG9zdDAeFw0xODExMDEyMDAwMTha \n + Fw0yMDEwMzEyMDAwMThaMFkxCzAJBgNVBAYTAkFVMRMwEQYDVQQIDApTb21lLVN0 \n + YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQxEjAQBgNVBAMM \n + CWxvY2FsaG9zdDCCAUswggEDBgcqhkjOPQIBMIH3AgEBMCwGByqGSM49AQECIQD / \n + / / / / AAAAAQAAAAAAAAAAAAAAAP / / / / / / / / / / / / / / / zBbBCD / / / / / AAAAAQAAAAAA \n + AAAAAAAAAP / / / / / / / / / / / / / / / AQgWsY12Ko6k + ez671VdpiGvGUdBrDMU7D2O848 \n + PifSYEsDFQDEnTYIhucEk2pmeOETnSa3gZ9 + kARBBGsX0fLhLEJH + Lzm5WOkQPJ3 \n + A32BLeszoPShOUXYmMKWT + NC4v4af5uO5 + tKfA + eFivOM1drMV7Oy7ZAaDe / UfUC \n + IQD / / / / / AAAAAP / / / / / / / / / / vOb6racXnoTzucrC / GMlUQIBAQNCAAQ3G / YXF + YE \n + XuASiyC1822n0iNPumHgFplF + 6 / veicKm + mDNA3NA / 1zTRKJOyqpDdMyB9tgFrdV \n + zcHzw7JW + lDpo1MwUTAdBgNVHQ4EFgQUonraQIcnNMppU + GoJ6 + vPbC84pEwHwYD \n + VR0jBBgwFoAUonraQIcnNMppU + GoJ6 + vPbC84pEwDwYDVR0TAQH / BAUwAwEB / zAK \n + BggqhkjOPQQDAgNJADBGAiEAoIkAinhds0VvNtWdi6f + r + U8AA9rUsR1sJBzVOYD \n + ErACIQCMMyfEWW8d4N3q8fpZ / lWTNaionVWeZZHWjseTmafWQg = = \n + - - - - - END CERTIFICATE - - - - - \n",Don ' t double release ByteBuf when parsing of the X509Certificate fails ( # 8457 ) \n Motivation : \n Due a bug in our implementation we tried to release the same ByteBuf two times when we failed to parse the X509Certificate as closing the ByteBufInputStream already closed it . \n Modifications : \n - Don ' t close the ByteBuf when closing the ByteBufInputStream \n - Explicit release all ByteBufs after we are done parsing in a finally block . \n - Add testcase . \n Result : \n Do not produce an IllegalReferenceCountException and throw the correct CertificateException .,381
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ CharSequenceValueConverter . java \n - return ( ( AsciiString ) value ) . parseBoolean ( ) ; \n + AsciiString asciiString = ( AsciiString ) value ; \n + return asciiString . contentEqualsIgnoreCase ( "" true "" ) ; \n + } \n + if ( value . length ( ) ! = 4 ) { \n + return false ; \n codec \ src \ test \ java \ io \ netty \ handler \ codec \ DefaultHeadersTest . java \n + import io . netty . util . AsciiString ; \n + \n + @ Test \n + public void testGetBooleanInvalidValue ( ) { \n + TestDefaultHeaders headers = newInstance ( ) ; \n + headers . set ( "" name1 "" , "" invalid "" ) ; \n + headers . set ( "" name2 "" , new AsciiString ( "" invalid "" ) ) ; \n + headers . set ( "" name3 "" , new StringBuilder ( "" invalid "" ) ) ; \n + \n + assertFalse ( headers . getBoolean ( "" name1 "" , false ) ) ; \n + assertFalse ( headers . getBoolean ( "" name2 "" , false ) ) ; \n + assertFalse ( headers . getBoolean ( "" name3 "" , false ) ) ; \n + } \n + \n + @ Test \n + public void testGetBooleanFalseValue ( ) { \n + TestDefaultHeaders headers = newInstance ( ) ; \n + headers . set ( "" name1 "" , "" false "" ) ; \n + headers . set ( "" name2 "" , new AsciiString ( "" false "" ) ) ; \n + headers . set ( "" name3 "" , new StringBuilder ( "" false "" ) ) ; \n + \n + assertFalse ( headers . getBoolean ( "" name1 "" , true ) ) ; \n + assertFalse ( headers . getBoolean ( "" name2 "" , true ) ) ; \n + assertFalse ( headers . getBoolean ( "" name3 "" , true ) ) ; \n + } \n + \n + @ Test \n + public void testGetBooleanTrueValue ( ) { \n + TestDefaultHeaders headers = newInstance ( ) ; \n + headers . set ( "" name1 "" , "" true "" ) ; \n + headers . set ( "" name2 "" , new AsciiString ( "" true "" ) ) ; \n + headers . set ( "" name3 "" , new StringBuilder ( "" true "" ) ) ; \n + \n + assertTrue ( headers . getBoolean ( "" name1 "" , false ) ) ; \n + assertTrue ( headers . getBoolean ( "" name2 "" , false ) ) ; \n + assertTrue ( headers . getBoolean ( "" name3 "" , false ) ) ; \n + } \n","DefaultHeaders / CharSequenceValueConverter should treat boolean consistently . \n Motivation : \n HttpHeaders . getBoolean should return the same truth value for the same string value , regardless of the underlying type . \n Modifications : \n - Only treat values of true as Boolean . TRUE \n - Add unit tests . \n Result : \n Consistent converting of values for all CharSequence implementations .",381
pom . xml \n - < jetty . alpnAgent . version > 2 . 0 . 6 < / jetty . alpnAgent . version > \n + < jetty . alpnAgent . version > 2 . 0 . 7 < / jetty . alpnAgent . version > \n - server \n,Update jetty - alpn - agent for latest java8 release . \n Motivation : \n We need to update jetty - alpn - agent to support java 1 . 8 . 0 _ 162 while running our tests / examples . \n Modifications : \n Update jetty - alpn - agent to 2 . 0 . 7 \n Result : \n All tests alpn related tests work again on latest java8 version,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolverContext . java \n + \n + / / Check if we need to release the envelope itself . If the query was cancelled the getNow ( ) will \n + / / return null as well as the Future will be failed with a CancellationException . \n + AddressedEnvelope < DnsResponse , InetSocketAddress > result = future . getNow ( ) ; \n + if ( result ! = null ) { \n + result . release ( ) ; \n + } \n",Ensure we always release the AddressEnvelope when doing DNS queries . \n Motivation : \n When we do DNS queries we need to ensure we always release the AddressEnvelope . \n Modifications : \n Also release the AddressEnvelope if the original resolution was done in the meantime and we did not cancel the extra query yet . \n Result : \n Should fix [ # 7713 ],381
transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollStreamChannel . java \n - flush ( ) ; \n + / / Calling flush0 directly to ensure we not try to flush messages that were added via write ( . . . ) in the \n + / / meantime . \n + ( ( AbstractEpollUnsafe ) unsafe ( ) ) . flush0 ( ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueStreamChannel . java \n - flush ( ) ; \n + / / Calling flush0 directly to ensure we not try to flush messages that were added via write ( . . . ) in the \n + / / meantime . \n + ( ( AbstractKQueueUnsafe ) unsafe ( ) ) . flush0 ( ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ nio \ AbstractNioByteChannel . java \n - flush ( ) ; \n + / / Calling flush0 directly to ensure we not try to flush messages that were added via write ( . . . ) in the \n + / / meantime . \n + ( ( AbstractNioUnsafe ) unsafe ( ) ) . flush0 ( ) ; \n,Flush task should not flush messages that were written since last flush attempt . \n Motivation : \n The flush task is currently using flush ( ) which will have the affect of have the flush traverse the whole ChannelPipeline and also flush messages that were written since we gave up flushing . This is not really correct as we should only continue to flush messages that were flushed at the point in time when the flush task was submitted for execution if the user not explicit call flush ( ) by him / herself . \n Modification : \n Call * Unsafe . flush0 ( ) via the flush task which will only continue flushing messages that were marked as flushed before . \n Result : \n More correct behaviour when the flush task is used .,381
testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketGatheringWriteTest . java \n - super . channelInactive ( ctx ) ; \n + super . channelActive ( ctx ) ; \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketSpdyEchoTest . java \n - import io . netty . util . NetUtil ; \n - import java . net . InetSocketAddress ; \n - int port = ( ( InetSocketAddress ) sc . localAddress ( ) ) . getPort ( ) ; \n,Call correct super methods in test . \n Motivation : \n We called the wrong super method in the test and also had a few unused imports . \n Modifications : \n Fix super method call and cleanup . \n Result : \n More correct test and cleanup .,381
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n - free ( nettyClassName ) ; \n - nettyClassName = NULL ; \n + free ( nettyClassName ) ; \n + nettyClassName = NULL ; \n + free ( nettyClassName ) ; \n + nettyClassName = NULL ; \n - datagramSocketAddrMethodId = ( * env ) - > GetMethodID ( env , datagramSocketAddressClass , "" < init > "" , "" ( Ljava / lang / String ; IILio / netty / channel / unix / DatagramSocketAddress ; ) V "" ) ; \n + \n + / / Respect shading . . . \n + char parameters [ 1024 ] = { 0 } ; \n + snprintf ( parameters , sizeof ( parameters ) , "" ( Ljava / lang / String ; IIL % s ; ) V "" , nettyClassName ) ; \n + free ( nettyClassName ) ; \n + nettyClassName = NULL ; \n + \n + datagramSocketAddrMethodId = ( * env ) - > GetMethodID ( env , datagramSocketAddressClass , "" < init > "" , parameters ) ; \n - netty _ unix _ errors _ throwRuntimeException ( env , "" failed to get method ID : DatagramSocketAddress . < init > ( String , int , int , DatagramSocketAddress ) "" ) ; \n + char msg [ 1024 ] = { 0 } ; \n + snprintf ( msg , sizeof ( msg ) , "" failed to get method ID : % s . < init > ( String , int , int , % s ) "" , nettyClassName , nettyClassName ) ; \n + netty _ unix _ errors _ throwRuntimeException ( env , msg ) ; \n",Fix support for shading native libraries which was broken in b818852cdb0ee56ce3cf939e2faa538d519baabd . ( # 8091 ) \n Motivation : \n b818852cdb0ee56ce3cf939e2faa538d519baabd broke support for shading the native libraries in netty as it missed to respect the package prefix that is used when shading . \n Modifications : \n Correctly respect package prefix for constructor argument and include the used classname when logging that we could not find the constructor . \n Result : \n Be able to shade native libraries of netty again .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ logging \ Log4J2Logger . java \n + import java . security . AccessController ; \n + import java . security . PrivilegedAction ; \n + \n + private static final boolean VARARGS _ ONLY ; \n + \n + static { \n + / / Older Log4J2 versions have only log methods that takes the format + varargs . So we should not use \n + / / Log4J2 if the version is too old . \n + / / See https : / / github . com / netty / netty / issues / 8217 \n + VARARGS _ ONLY = AccessController . doPrivileged ( new PrivilegedAction < Boolean > ( ) { \n + @ Override \n + public Boolean run ( ) { \n + try { \n + Logger . class . getMethod ( "" debug "" , String . class , Object . class ) ; \n + return false ; \n + } catch ( NoSuchMethodException ignore ) { \n + / / Log4J2 version too old . \n + return true ; \n + } catch ( SecurityException ignore ) { \n + / / We could not detect the version so we will use Log4J2 if its on the classpath . \n + return false ; \n + } \n + } \n + } ) ; \n + } \n + if ( VARARGS _ ONLY ) { \n + throw new UnsupportedOperationException ( "" Log4J2 version mismatch "" ) ; \n + } \n",Do not fail on runtime when an older version of Log4J2 is on the classpath . ( # 8240 ) \n Motivation : \n At the moment we will just assume the correct version of log4j2 is used when we find it on the classpath . This may lead to an AbstractMethodError at runtime . We should not use log4j2 if the version is not correct . \n Modifications : \n Check on class loading if we can use Log4J2 or not . \n Result : \n Fixes # 8217 .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 16 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 17 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 16 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 17 "" \n",Update to latest openjdk 12 ea release . ( # 8459 ) \n Motivation : \n We should always test against the latest EA release . \n Modifications : \n Update to openjdk 12 ea17 \n Result : \n Test against latest release,381
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n - headUpdater . set ( this , Record . BOTTOM ) ; \n + / / Create a new Record so we always have the creation stacktrace included . \n + headUpdater . set ( this , new Record ( Record . BOTTOM ) ) ; \n",Correctly record creation stacktrace in ResourceLeakDetector . \n Motivation : \n We missed to correctly record the stacktrace of the creation of an ResourceLeak record . This could either have the effect to log the wrote stacktrace for creation or not log a stacktrace at all if the object was dropped on the floor after it was created . \n Modifications : \n Correctly create a Record on creation of the object . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7781 .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamFrameToHttpObjectCodec . java \n - int id = 0 ; / / not really the id \n + Http2FrameStream stream = headersFrame . stream ( ) ; \n + int id = stream = = null ? 0 : stream . id ( ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamFrameToHttpObjectCodecTest . java \n + testDecodeFullResponseHeaders ( false ) ; \n + } \n + \n + @ Test \n + public void testDecodeFullResponseHeadersWithStreamID ( ) throws Exception { \n + testDecodeFullResponseHeaders ( true ) ; \n + } \n + \n + private void testDecodeFullResponseHeaders ( boolean withStreamId ) throws Exception { \n - assertTrue ( ch . writeInbound ( new DefaultHttp2HeadersFrame ( headers , true ) ) ) ; \n + Http2HeadersFrame frame = new DefaultHttp2HeadersFrame ( headers , true ) ; \n + if ( withStreamId ) { \n + frame . stream ( new Http2FrameStream ( ) { \n + @ Override \n + public int id ( ) { \n + return 1 ; \n + } \n + \n + @ Override \n + public Http2Stream . State state ( ) { \n + return Http2Stream . State . OPEN ; \n + } \n + } ) ; \n + } \n + \n + assertTrue ( ch . writeInbound ( frame ) ) ; \n + if ( withStreamId ) { \n + assertEquals ( 1 , \n + ( int ) response . headers ( ) . getInt ( HttpConversionUtil . ExtensionHeaderNames . STREAM _ ID . text ( ) ) ) ; \n + } \n",Correctly include the stream id when convert from Http2HeadersFrame to HttpMessage \n Motivation : \n We did not correctly set the stream id in the headers of HttpMessage when converting a Http2HeadersFrame . This is based on https : / / github . com / netty / netty / pull / 7778 so thanks to @ jprante . \n Modifications : \n - Correctly set the id when possible in the header . \n - Add test case \n Result : \n Correctly include stream id .,381
transport \ src \ main \ java \ io \ netty \ channel \ group \ DefaultChannelGroup . java \n - if ( o instanceof Channel ) { \n - Channel c = ( Channel ) o ; \n - if ( o instanceof ServerChannel ) { \n - return serverChannels . containsValue ( c ) ; \n - } else { \n - return nonServerChannels . containsValue ( c ) ; \n - } \n - } else { \n - return false ; \n + if ( o instanceof ServerChannel ) { \n + return serverChannels . containsValue ( o ) ; \n + } else if ( o instanceof Channel ) { \n + return nonServerChannels . containsValue ( o ) ; \n + return false ; \n,Simplify DefaultChannelGroup . contains ( . . . ) and so remove one instanceof check . \n Motivation : \n DefaultChannelGroup . contains ( . . . ) did one more instanceof check then needed . \n Modifications : \n Simplify contains ( . . . ) and remove one instanceof check . \n Result : \n Simplier and cheaper implementation .,381
"handler \ src \ main \ java \ io \ netty \ handler \ stream \ ChunkedWriteHandler . java \n - try { \n - doFlush ( ctx ) ; \n - } catch ( Exception e ) { \n - if ( logger . isWarnEnabled ( ) ) { \n - logger . warn ( "" Unexpected exception while sending chunks . "" , e ) ; \n - } \n - } \n + resumeTransfer0 ( ctx ) ; \n - try { \n - doFlush ( ctx ) ; \n - } catch ( Exception e ) { \n - if ( logger . isWarnEnabled ( ) ) { \n - logger . warn ( "" Unexpected exception while sending chunks . "" , e ) ; \n - } \n - } \n + resumeTransfer0 ( ctx ) ; \n + private void resumeTransfer0 ( ChannelHandlerContext ctx ) { \n + try { \n + doFlush ( ctx ) ; \n + } catch ( Exception e ) { \n + if ( logger . isWarnEnabled ( ) ) { \n + logger . warn ( "" Unexpected exception while sending chunks . "" , e ) ; \n + } \n + } \n + } \n + \n - private void doFlush ( final ChannelHandlerContext ctx ) throws Exception { \n + private void doFlush ( final ChannelHandlerContext ctx ) { \n - static void closeInput ( ChunkedInput < ? > chunks ) { \n + private static void closeInput ( ChunkedInput < ? > chunks ) { \n - \n - if ( promise instanceof ChannelProgressivePromise ) { \n - / / Now we know what the total is . \n - ( ( ChannelProgressivePromise ) promise ) . tryProgress ( total , total ) ; \n - } \n - \n + progress ( total , total ) ; \n",Remove code duplication in ChunkedWriteHandler \n Motivation : \n We had some code duplication in ChunkedWriteHandler . \n Modifications : \n Factor out duplicated code into private methods and reuse it . \n Result : \n Less code duplication .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslEngineTest . java \n + private static boolean isNpnSupported ( String versionString ) { \n + String [ ] versionStringParts = versionString . split ( "" "" , - 1 ) ; \n + if ( versionStringParts . length = = 2 & & "" LibreSSL "" . equals ( versionStringParts [ 0 ] ) ) { \n + String [ ] versionParts = versionStringParts [ 1 ] . split ( "" \ \ . "" , - 1 ) ; \n + if ( versionParts . length = = 3 ) { \n + int major = Integer . parseInt ( versionParts [ 0 ] ) ; \n + if ( major < 2 ) { \n + return true ; \n + } \n + if ( major > 2 ) { \n + return false ; \n + } \n + int minor = Integer . parseInt ( versionParts [ 1 ] ) ; \n + if ( minor < 6 ) { \n + return true ; \n + } \n + if ( minor > 6 ) { \n + return false ; \n + } \n + int bugfix = Integer . parseInt ( versionParts [ 2 ] ) ; \n + if ( bugfix > 0 ) { \n + return false ; \n + } \n + } \n + } \n + return true ; \n + } \n + String versionString = OpenSsl . versionString ( ) ; \n + assumeTrue ( "" LibreSSL 2 . 6 . 1 removed NPN support , detected "" + versionString , isNpnSupported ( versionString ) ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n - assertEquals ( appProto , expectedApplicationProtocol ) ; \n + assertEquals ( expectedApplicationProtocol , appProto ) ; \n",Skip NPN tests when libressl 2 . 6 . 1 + is used . \n Motivation : \n LibreSSL removed support for NPN in its 2 . 6 . 1 + releases . \n Modifications : \n Skip NPN tests in libressl 2 . 6 . 1 + \n Result : \n Be able to run netty tests against libressl 2 . 6 . 1 + as well .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n + private boolean closeNotify ; \n - / / It ' s important that we do not pass the original ChannelPromise to safeClose ( . . . ) as when flush ( . . . . ) \n - / / throws an Exception it will be propagated to the AbstractChannelHandlerContext which will try \n - / / to fail the promise because of this . This will then fail as it was already completed by safeClose ( . . . ) . \n - / / We create a new ChannelPromise and try to notify the original ChannelPromise \n - / / once it is complete . If we fail to do so we just ignore it as in this case it was failed already \n - / / because of a propagated Exception . \n - / / \n - / / See https : / / github . com / netty / netty / issues / 5931 \n - safeClose ( ctx , closeNotifyPromise , ctx . newPromise ( ) . addListener ( \n - new ChannelPromiseNotifier ( false , promise ) ) ) ; \n + if ( ! closeNotify ) { \n + closeNotify = true ; \n + / / It ' s important that we do not pass the original ChannelPromise to safeClose ( . . . ) as when flush ( . . . . ) \n + / / throws an Exception it will be propagated to the AbstractChannelHandlerContext which will try \n + / / to fail the promise because of this . This will then fail as it was already completed by \n + / / safeClose ( . . . ) . We create a new ChannelPromise and try to notify the original ChannelPromise \n + / / once it is complete . If we fail to do so we just ignore it as in this case it was failed already \n + / / because of a propagated Exception . \n + / / \n + / / See https : / / github . com / netty / netty / issues / 5931 \n + safeClose ( ctx , closeNotifyPromise , ctx . newPromise ( ) . addListener ( \n + new ChannelPromiseNotifier ( false , promise ) ) ) ; \n + } else { \n + / / / We already handling the close _ notify so just attach the promise to the sslClosePromise . \n + sslClosePromise . addListener ( new FutureListener < Channel > ( ) { \n + @ Override \n + public void operationComplete ( Future < Channel > future ) { \n + promise . setSuccess ( ) ; \n + } \n + } ) ; \n + } \n",Ensure we not schedule multiple timeouts for close notify \n Motivation : \n We should only schedule one timeout to wait for the close notify to be done . \n Modifications : \n Keep track of if we already scheduled a timeout for close notify and if so not schedule another one . \n Result : \n No duplicated timeouts .,381
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ filedescriptor . c \n - return - errno ; \n + / / There is really nothing "" sane "" we can do when EINTR was reported on close . So just ignore it and "" assume "" \n + / / everything is fine = = we closed the file descriptor . \n + / / \n + / / For more details see : \n + / / - https : / / bugs . chromium . org / p / chromium / issues / detail ? id = 269623 \n + / / - https : / / lwn . net / Articles / 576478 / \n + if ( errno ! = EINTR ) { \n + return - errno ; \n + } \n",Ignore EINTR on close ( . . . ) as there is nothing sane we can do . \n Motivation : \n If close ( . . . ) reports EINTR there is nothing sane we can do so it makes no sense to even report it . See also : \n https : / / github . com / apple / swift - nio / pull / 217 \n Modifications : \n Just ignore EINTR when calling close ( . . . ) \n Result : \n Less noise in the logs .,381
pom . xml \n - < tcnative . version > 2 . 0 . 7 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 8 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 8 . Final \n Motivation : \n netty - tcnative 2 . 0 . 8 . Final was released . \n Modifications : \n Update to latest netty - tcnative release . \n Result : \n Use latest release of tcnative,381
pom . xml \n - < conscrypt . version > 1 . 0 . 0 < / conscrypt . version > \n + < conscrypt . version > 1 . 0 . 1 < / conscrypt . version > \n,Update to conscrypt 1 . 0 . 1 \n Motivation : \n We should use the latest conscrypt release . \n Modifications : \n Update to 1 . 0 . 1 \n Result : \n Use latest conscrypt,381
"transport \ src \ test \ java \ io \ netty \ channel \ local \ LocalChannelTest . java \n + } else { \n + read = 0 ; \n + \n + @ Override \n + public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) { \n + ctx . fireExceptionCaught ( cause ) ; \n + ctx . close ( ) ; \n + } \n",Fix race in ChannelReadHandler used during LocalChannel testing . ( # 7904 ) \n Motivation : \n ChannelReadHandler is used in tests added via f4d7e8de140048047299808bb7e707c15342b826 . In the handler we verify the number of messages we receive per read ( ) call but missed to sometimes reset the counter which resulted in exceptions . \n Modifications : \n Correctly reset read counter in all cases . \n Result : \n No more unexpected exceptions when running LocalChannel tests .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsCache . java \n + / / Two years are supported by all our EventLoop implementations and so safe to use as maximum . \n + / / See also : https : / / github . com / netty / netty / commit / b47fb817991b42ec8808c7d26538f3f2464e1fa6 \n + private static final int MAX _ SUPPORTED _ TTL _ SECS = ( int ) TimeUnit . DAYS . toSeconds ( 365 * 2 ) ; \n - this ( 0 , Integer . MAX _ VALUE , 0 ) ; \n + this ( 0 , MAX _ SUPPORTED _ TTL _ SECS , 0 ) ; \n - cache0 ( e , Math . max ( minTtl , ( int ) Math . min ( maxTtl , originalTtl ) ) , loop ) ; \n + cache0 ( e , Math . max ( minTtl , Math . min ( MAX _ SUPPORTED _ TTL _ SECS , ( int ) Math . min ( maxTtl , originalTtl ) ) ) , loop ) ; \n - cache0 ( e , negativeTtl , loop ) ; \n + cache0 ( e , Math . min ( MAX _ SUPPORTED _ TTL _ SECS , negativeTtl ) , loop ) ; \n resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DefaultDnsCacheTest . java \n + import io . netty . channel . nio . NioEventLoopGroup ; \n + \n + @ Test \n + public void testExpireWithDifferentTTLs ( ) { \n + testExpireWithTTL0 ( 1 ) ; \n + testExpireWithTTL0 ( 1000 ) ; \n + testExpireWithTTL0 ( 1000000 ) ; \n + } \n + \n + private static void testExpireWithTTL0 ( int days ) { \n + EventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + \n + try { \n + EventLoop loop = group . next ( ) ; \n + final DefaultDnsCache cache = new DefaultDnsCache ( ) ; \n + Assert . assertNotNull ( cache . cache ( "" netty . io "" , null , NetUtil . LOCALHOST , days , loop ) ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n",Enforce sane upper limit for TTL in DefaultDnsCache . ( # 7907 ) \n Motivation : \n In b47fb817991b42ec8808c7d26538f3f2464e1fa6 we limited the max supported delay to match what our internal implementat can support . Because of this it was possible that DefaultDnsCache produced an IllegalArgumentException when it tried to schedule a expiration > 3 years . \n Modifications : \n Limit the max supported TTL to 2 years which is safe for all our EventLoop implementations . \n Result : \n No more exceptions when adding records to the cache with a huge TTL .,381
"resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DefaultDnsCacheTest . java \n + import static org . junit . Assert . assertSame ; \n + \n + @ Test \n + public void testCacheFailed ( ) throws Exception { \n + InetAddress addr1 = InetAddress . getByAddress ( new byte [ ] { 10 , 0 , 0 , 1 } ) ; \n + InetAddress addr2 = InetAddress . getByAddress ( new byte [ ] { 10 , 0 , 0 , 2 } ) ; \n + EventLoopGroup group = new DefaultEventLoopGroup ( 1 ) ; \n + \n + try { \n + EventLoop loop = group . next ( ) ; \n + final DefaultDnsCache cache = new DefaultDnsCache ( 1 , 100 , 100 ) ; \n + cache . cache ( "" netty . io "" , null , addr1 , 10000 , loop ) ; \n + cache . cache ( "" netty . io "" , null , addr2 , 10000 , loop ) ; \n + \n + List < ? extends DnsCacheEntry > entries = cache . get ( "" netty . io "" , null ) ; \n + assertEquals ( 2 , entries . size ( ) ) ; \n + assertEntry ( entries . get ( 0 ) , addr1 ) ; \n + assertEntry ( entries . get ( 1 ) , addr2 ) ; \n + \n + Exception exception = new Exception ( ) ; \n + cache . cache ( "" netty . io "" , null , exception , loop ) ; \n + entries = cache . get ( "" netty . io "" , null ) ; \n + DnsCacheEntry entry = entries . get ( 0 ) ; \n + assertEquals ( 1 , entries . size ( ) ) ; \n + assertSame ( exception , entry . cause ( ) ) ; \n + assertNull ( entry . address ( ) ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n",Add test for caching failed queries in DefaultDnsCache . ( # 7909 ) \n Motivation : \n We had no test that validated the handling of caching failures for DefaultDnsCache . \n Modifications : \n Add testcase . \n Result : \n More tests FTW .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 15 "" \n + java _ version : "" 1 . 11 . 0 - 16 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 15 "" \n + java _ version : "" 1 . 11 . 0 - 16 "" \n",Use java 11 + ea16 ( # 7999 ) \n Motivation : \n Java 11 + ea16 was released . \n Modifications : \n Update to latest version . \n Result : \n Testing with latest java 11 release .,381
pom . xml \n - < conscrypt . version > 1 . 1 . 2 < / conscrypt . version > \n + < conscrypt . version > 1 . 1 . 3 < / conscrypt . version > \n,"Update conscrypt to 1 . 1 . 3 which fixes some NPEs during tests when using conscrypt . ( # 8001 ) \n Motivation : \n When using conscrypt some NPEs were logged , these were fixed in the latest release . \n Modifications : \n Update to conscrypt 1 . 1 . 3 . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7988 .",381
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ LineBasedFrameDecoder . java \n + / / We skip everything in the buffer , we need to set the offset to 0 again . \n + offset = 0 ; \n codec \ src \ test \ java \ io \ netty \ handler \ codec \ LineBasedFrameDecoderTest . java \n + \n + @ Test \n + public void testNotFailFast ( ) throws Exception { \n + EmbeddedChannel ch = new EmbeddedChannel ( new LineBasedFrameDecoder ( 2 , false , false ) ) ; \n + assertFalse ( ch . writeInbound ( wrappedBuffer ( new byte [ ] { 0 , 1 , 2 } ) ) ) ; \n + assertFalse ( ch . writeInbound ( wrappedBuffer ( new byte [ ] { 3 , 4 } ) ) ) ; \n + try { \n + ch . writeInbound ( wrappedBuffer ( new byte [ ] { ' \ n ' } ) ) ; \n + fail ( ) ; \n + } catch ( TooLongFrameException expected ) { \n + / / Expected once we received a full frame . \n + } \n + assertFalse ( ch . writeInbound ( wrappedBuffer ( new byte [ ] { ' 5 ' } ) ) ) ; \n + assertTrue ( ch . writeInbound ( wrappedBuffer ( new byte [ ] { ' \ n ' } ) ) ) ; \n + \n + ByteBuf expected = wrappedBuffer ( new byte [ ] { ' 5 ' , ' \ n ' } ) ; \n + ByteBuf buffer = ch . readInbound ( ) ; \n + assertEquals ( expected , buffer ) ; \n + expected . release ( ) ; \n + buffer . release ( ) ; \n + \n + assertFalse ( ch . finish ( ) ) ; \n + } \n",Correctly reset offset when fail lazy because of too long frame . ( # 8257 ) \n Motivation : \n We need to reset the offset to 0 when we fail lazy because of a too long frame . \n Modifications : \n - Reset offset \n - Add testcase \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8256 .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 19 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 22 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 19 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 22 "" \n pom . xml \n + < ! - - pax - exam does not work on latest Java12 EA 22 build - - > \n + < skipOsgiTestsuite > true < / skipOsgiTestsuite > \n testsuite - osgi \ pom . xml \n - < exam . version > 4 . 9 . 1 < / exam . version > \n + < exam . version > 4 . 13 . 0 < / exam . version > \n",Update to OpenJDK 12 ea22 ( # 8618 ) \n Motivation : \n We should use the latest OpenJDK 12 release when running tests against Java12 . \n Modifications : \n - Update to OpenJDK 12 ea22 . \n - Update pax exam version \n - skip OSGI testsuite on Java12 as it does not work ea22 yet . \n Result : \n Use latest OpenJDK 12 version when running on the CI .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - } finally { \n - / / We need to ensure we release the goAwayFrame . \n - goAwayFrame . release ( ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecTest . java \n - DefaultHttp2GoAwayFrame goAwayFrame = new DefaultHttp2GoAwayFrame ( 1 ) ; \n + DefaultHttp2GoAwayFrame goAwayFrame = \n + new DefaultHttp2GoAwayFrame ( 1 , parentChannel . alloc ( ) . buffer ( ) . writeLong ( 8 ) ) ; \n - assertSame ( parentChannel . readInbound ( ) , goAwayFrame ) ; \n + \n + Http2GoAwayFrame frame = parentChannel . readInbound ( ) ; \n + assertSame ( frame , goAwayFrame ) ; \n + assertTrue ( frame . release ( ) ) ; \n",Fix IllegalReferenceCountException when using Http2MultiplexCodec and a DefaultHttp2GoAwayFrame with a non empty ByteBuffer is received . ( # 7894 ) \n Motivation : \n We incorrectly called frame . release ( ) in onHttp2GoAwayFrame which could lead to IllegalReferenceCountExceptions . The call of release ( ) is inappropriate because the fireChannelRead ( ) in onHttp2Frame ( ) will handle it . \n Modifications : \n - Not call frame . release ( ) \n - Add a unit test \n Result : \n Fxies https : / / github . com / netty / netty / issues / 7892 .,381
transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n - struct sockaddr _ storage daddr ; \n - char cntrlbuf [ 64 ] ; \n - struct iovec iov ; \n - struct msghdr msg ; \n - struct cmsghdr * cmsg ; \n - int readLocalAddr ; \n + # ifdef IP _ RECVORIGDSTADDR \n + struct sockaddr _ storage daddr ; \n + struct iovec iov ; \n + struct cmsghdr * cmsg ; \n + struct msghdr msg ; \n + char cntrlbuf [ 64 ] ; \n + \n + int readLocalAddr ; \n + # endif \n + # ifdef IP _ RECVORIGDSTADDR \n + # endif \n + # ifdef IP _ RECVORIGDSTADDR \n + # endif \n + # ifdef IP _ RECVORIGDSTADDR \n + # endif \n,Add # ifdef statements so the compilation of the native code not fails on MacOS ( # 7895 ) \n Motivation : \n b818852cdb0ee56ce3cf939e2faa538d519baabd added support for IP _ RECVORIGDSTADDR but did not include any # ifdef statements to ensure its usable at all ( which is not the case on MacOS ) . \n Modifications : \n Add # ifdef statements to check for IP _ RECVORIGDSTADDR . \n Result : \n Compilation works again on MacOS .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslHandlerTest . java \n + import io . netty . buffer . UnpooledByteBufAllocator ; \n + \n + @ Test \n + public void testOutboundClosedAfterChannelInactive ( ) throws Exception { \n + SslContext context = SslContextBuilder . forClient ( ) . build ( ) ; \n + SSLEngine engine = context . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + \n + EmbeddedChannel channel = new EmbeddedChannel ( ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + channel . pipeline ( ) . addLast ( new SslHandler ( engine ) ) ; \n + assertFalse ( engine . isOutboundDone ( ) ) ; \n + channel . close ( ) . syncUninterruptibly ( ) ; \n + \n + assertTrue ( engine . isOutboundDone ( ) ) ; \n + } \n,Add testcase for c11b23bbc1f46116407bdc10779c4cace639ee83 \n Motivation : \n c11b23bbc1f46116407bdc10779c4cace639ee83 added a fix for closing the SSLEngine otbound but no test was provided . \n Modifications : \n Add testcase . \n Result : \n More tests .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n - boolean unaligned ; \n + final boolean unaligned ; \n + int version = javaVersion ( ) ; \n + if ( version > = 9 ) { \n + / / Java9 / 10 use all lowercase and later versions all uppercase . \n + String fieldName = version > = 11 ? "" UNALIGNED "" : "" unaligned "" ; \n + / / On Java9 and later we try to directly access the field as we can do this without \n + / / adjust the accessible levels . \n + try { \n + Field unalignedField = bitsClass . getDeclaredField ( fieldName ) ; \n + if ( unalignedField . getType ( ) = = boolean . class ) { \n + long offset = UNSAFE . staticFieldOffset ( unalignedField ) ; \n + Object object = UNSAFE . staticFieldBase ( unalignedField ) ; \n + return UNSAFE . getBoolean ( object , offset ) ; \n + } \n + / / There is something unexpected stored in the field , \n + / / let us fall - back and try to use a reflective method call as last resort . \n + } catch ( NoSuchFieldException ignore ) { \n + / / We did not find the field we expected , move on . \n + } \n + } \n",PlatformDependent0 should be able to better detect if unaligned access is supported on java9 and later . ( # 8255 ) \n Motivation : \n In Java8 and earlier we used reflection to detect if unaligned access is supported . This fails in Java9 and later as we would need to change the accessible level of the method . \n Lucky enough we can use Unsafe directly to read the content of the static field here . \n Modifications : \n Add special handling for detecting if unaligned access is supported on Java9 and later which does not fail due jigsaw . \n Result : \n Better and more correct detection on Java9 and later .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + import java . lang . reflect . Field ; \n + public static void putObject ( Object o , long offset , Object x ) { \n + PlatformDependent0 . putObject ( o , offset , x ) ; \n + } \n + \n + public static long objectFieldOffset ( Field field ) { \n + return PlatformDependent0 . objectFieldOffset ( field ) ; \n + } \n + \n common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n + static void putObject ( Object o , long offset , Object x ) { \n + UNSAFE . putObject ( o , offset , x ) ; \n + } \n + \n transport \ src \ main \ java \ io \ netty \ channel \ nio \ NioEventLoop . java \n - import java . util . concurrent . Callable ; \n - / / ensure the current selector implementation is what we can instrument . \n - ! ( ( Class < ? > ) maybeSelectorImplClass ) . isAssignableFrom ( unwrappedSelector . getClass ( ) ) ) { \n + / / ensure the current selector implementation is what we can instrument . \n + ! ( ( Class < ? > ) maybeSelectorImplClass ) . isAssignableFrom ( unwrappedSelector . getClass ( ) ) ) { \n + if ( PlatformDependent . javaVersion ( ) > = 9 & & PlatformDependent . hasUnsafe ( ) ) { \n + / / Let us try to use sun . misc . Unsafe to replace the SelectionKeySet . \n + / / This allows us to also do this in Java9 + without any extra flags . \n + long selectedKeysFieldOffset = PlatformDependent . objectFieldOffset ( selectedKeysField ) ; \n + long publicSelectedKeysFieldOffset = \n + PlatformDependent . objectFieldOffset ( publicSelectedKeysField ) ; \n + \n + if ( selectedKeysFieldOffset ! = - 1 & & publicSelectedKeysFieldOffset ! = - 1 ) { \n + PlatformDependent . putObject ( \n + unwrappedSelector , selectedKeysFieldOffset , selectedKeySet ) ; \n + PlatformDependent . putObject ( \n + unwrappedSelector , publicSelectedKeysFieldOffset , selectedKeySet ) ; \n + return null ; \n + } \n + / / We could not retrieve the offset , lets try reflection as last - resort . \n + } \n + \n",NioEventLoop should also use our special SelectionKeySet on Java9 and later . ( # 8260 ) \n Motivation : \n In Java8 and earlier we used reflection to replace the used key set if not otherwise told . This does not work on Java9 and later without special flags as its not possible to call setAccessible ( true ) on the Field anymore . \n Modifications : \n - Use Unsafe to instrument the Selector with out special set when sun . misc . Unsafe is present and we are using Java9 + . \n Result : \n NIO transport produce less GC on Java9 and later as well .,381
"microbench \ pom . xml \n + < profile > \n + < id > benchmark - jar < / id > \n + < build > \n + < plugins > \n + < plugin > \n + < groupId > org . apache . maven . plugins < / groupId > \n + < artifactId > maven - shade - plugin < / artifactId > \n + < version > 2 . 2 < / version > \n + < executions > \n + < execution > \n + < phase > package < / phase > \n + < goals > \n + < goal > shade < / goal > \n + < / goals > \n + < configuration > \n + < finalName > microbenchmarks < / finalName > \n + < transformers > \n + < transformer implementation = "" org . apache . maven . plugins . shade . resource . ManifestResourceTransformer "" > \n + < mainClass > org . openjdk . jmh . Main < / mainClass > \n + < / transformer > \n + < / transformers > \n + < filters > \n + < filter > \n + < ! - - \n + Shading signed JARs will fail without this . \n + http : / / stackoverflow . com / questions / 999489 / invalid - signature - file - when - attempting - to - run - a - jar \n + - - > \n + < artifact > * : * < / artifact > \n + < excludes > \n + < exclude > META - INF / * . SF < / exclude > \n + < exclude > META - INF / * . DSA < / exclude > \n + < exclude > META - INF / * . RSA < / exclude > \n + < / excludes > \n + < / filter > \n + < / filters > \n + < / configuration > \n + < / execution > \n + < / executions > \n + < / plugin > \n + < / plugins > \n + < / build > \n + < / profile > \n","Allow to generate a jmh uber jar to run benchmarks easily from cmdline with different arguments . ( # 8264 ) \n Motivation : \n It is sometimes useful to be able to run benchmarks easily from the commandline and passs different arguments / options here . We should support this . \n Modifications : \n Add the benchmark - jar profile which allows to generate such an "" uber - jar "" that can be used directly to run benchmarks as documented at http : / / openjdk . java . net / projects / code - tools / jmh / . \n Result : \n More flexible way to run benchmarks .",381
"microbench \ src \ main \ java \ io \ netty \ microbench \ util \ AbstractMicrobenchmarkBase . java \n - "" - server "" , "" - dsa "" , "" - da "" , "" - ea : io . netty . . . "" , "" - XX : + AggressiveOpts "" , "" - XX : + UseBiasedLocking "" , \n - "" - XX : + UseFastAccessorMethods "" , "" - XX : + OptimizeStringConcat "" , \n + "" - server "" , "" - dsa "" , "" - da "" , "" - ea : io . netty . . . "" , \n",Remove flags when running benchmarks . ( # 8262 ) \n Motivation : \n Some of the flags we used are not supported anymore on more recent JDK versions . We should just remove all of them and only keep what we really need . This may also reflect better what people use in production . \n Modifications : \n Remove some flags when running the benchmarks . \n Result : \n Benchmarks also run with JDK11 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ PemPrivateKey . java \n - ByteBuf encoded = Unpooled . wrappedBuffer ( key . getEncoded ( ) ) ; \n + byte [ ] bytes = key . getEncoded ( ) ; \n + if ( bytes = = null ) { \n + throw new IllegalArgumentException ( key . getClass ( ) . getName ( ) + "" does not support encoding "" ) ; \n + } \n + \n + ByteBuf encoded = Unpooled . wrappedBuffer ( bytes ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ PemEncodedTest . java \n + import java . security . PrivateKey ; \n + import io . netty . buffer . Unpooled ; \n + import io . netty . buffer . UnpooledByteBufAllocator ; \n + @ Test ( expected = IllegalArgumentException . class ) \n + public void testEncodedReturnsNull ( ) throws Exception { \n + PemPrivateKey . toPEM ( UnpooledByteBufAllocator . DEFAULT , true , new PrivateKey ( ) { \n + @ Override \n + public String getAlgorithm ( ) { \n + return null ; \n + } \n + \n + @ Override \n + public String getFormat ( ) { \n + return null ; \n + } \n + \n + @ Override \n + public byte [ ] getEncoded ( ) { \n + return null ; \n + } \n + } ) ; \n + } \n + \n",PemPrivateKey . toPem ( . . . ) should throw IllegalArgumentException when P… ( # 8253 ) \n * PemPrivateKey . toPem ( . . . ) should throw IllegalArgumentException when PrivateKey which does not support encoding is used . \n Motivation : \n At the moment when a PrivateKey is used that does not support encoding we throw a NPE when trying to convert the key . We should better throw an IllegalArgumentException with the details about what key we tried to encode . \n Modifications : \n - Check if PrivateKey . getEncoded ( ) returns null and if so throw an IllegalArgumentException \n - Add unit test . \n Result : \n Better handling of non - supported PrivateKey implementations .,381
"transport \ src \ main \ java \ io \ netty \ channel \ nio \ NioEventLoop . java \n - import java . nio . channels . SelectionKey ; \n + import java . nio . channels . SelectionKey ; \n + \n + if ( inEventLoop ( ) ) { \n + register0 ( ch , interestOps , task ) ; \n + } else { \n + try { \n + / / Offload to the EventLoop as otherwise java . nio . channels . spi . AbstractSelectableChannel . register \n + / / may block for a long time while trying to obtain an internal lock that may be hold while selecting . \n + submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + register0 ( ch , interestOps , task ) ; \n + } \n + } ) . sync ( ) ; \n + } catch ( InterruptedException ignore ) { \n + / / Even if interrupted we did schedule it so just mark the Thread as interrupted . \n + Thread . currentThread ( ) . interrupt ( ) ; \n + } \n + } \n + } \n + \n + private void register0 ( SelectableChannel ch , int interestOps , NioTask < ? > task ) { \n",NioEventLoop . register ( . . . ) should offload to the EventLoop if not alr… ( # 8612 ) \n Motivation : \n java . nio . channels . spi . AbstractSelectableChannel . register ( . . . ) need to obtain multiple locks during execution which may produce a long wait time if we currently select . This lead to multiple CI failures in the past . \n Modifications : \n Ensure the register call takes place on the EventLoop . \n Result : \n No more flacky CI test timeouts .,381
. gitignore \n + \n + * / . unison . * \n,Add docker - sync files to . gitignore,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - String errStr = SSL . getErrorString ( err ) ; \n - \n - handshakeException = new SSLHandshakeException ( errStr ) ; \n + handshakeException = new SSLHandshakeException ( SSL . getErrorString ( err ) ) ; \n + / / We need to clear all errors so we not pick up anything that was left on the stack on the next \n + / / operation . Note that shutdownWithError ( . . . ) will cleanup the stack as well so its only needed here . \n + SSL . clearError ( ) ; \n - throw shutdownWithError ( "" SSL _ read "" , errStr ) ; \n + throw shutdownWithError ( "" SSL _ read "" , SSL . getErrorString ( err ) ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslEngineTest . java \n + import io . netty . internal . tcnative . SSL ; \n + import org . junit . Assert ; \n + @ Override \n + public void tearDown ( ) throws InterruptedException { \n + super . tearDown ( ) ; \n + Assert . assertEquals ( "" SSL error stack not correctly consumed "" , 0 , SSL . getLastErrorNumber ( ) ) ; \n + } \n + \n",Correctly clear the error stack in all cases when using ReferenceCountedOpenSslEngine . ( # 7941 ) \n Motivation : \n We missed to correctly clear the error stack in one case when using the ReferenceCountedOpenSslEngine . Because of this it was possible to pick up an error on an unrelated operation . \n Modifications : \n - Correctly clear the stack \n - Add verification of empty error stack to tests . \n Result : \n Not possible to observe unrelated errors .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslEngineTest . java \n - testWrapWithDifferentSizes ( PROTOCOL _ SSL _ V3 , "" AES128 - SHA "" ) ; \n - testWrapWithDifferentSizes ( PROTOCOL _ SSL _ V3 , "" DES - CBC3 - SHA "" ) ; \n - testWrapWithDifferentSizes ( PROTOCOL _ SSL _ V3 , "" AES256 - SHA "" ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslErrorTest . java \n - verifyException ( unwrappedCause , "" bad "" , promise ) ; \n + / / BoringSSL uses "" expired "" in this case while others use "" bad "" \n + if ( "" BoringSSL "" . equals ( OpenSsl . versionString ( ) ) ) { \n + verifyException ( unwrappedCause , "" expired "" , promise ) ; \n + } else { \n + verifyException ( unwrappedCause , "" bad "" , promise ) ; \n + } \n - verifyException ( unwrappedCause , "" bad "" , promise ) ; \n + / / BoringSSL uses "" expired "" in this case while others use "" bad "" \n + if ( "" BoringSSL "" . equals ( OpenSsl . versionString ( ) ) ) { \n + verifyException ( unwrappedCause , "" expired "" , promise ) ; \n + } else { \n + verifyException ( unwrappedCause , "" bad "" , promise ) ; \n + } \n - promise . setFailure ( new AssertionError ( "" message not contains ' "" + messagePart + "" ' : "" + message ) ) ; \n + Throwable error = new AssertionError ( "" message not contains ' "" + messagePart + "" ' : "" + message ) ; \n + error . initCause ( cause ) ; \n + promise . setFailure ( error ) ; \n",Adjust tests to also pass when using BoringSSL ( # 7946 ) \n Motivation : \n Some of the tests failed when using BoringSSL as some protocol / cipher combinations are not supported and it uses a different alert when the cert is not valid yet . \n Modification : \n - Remove protocol / cipher combos that are not supported by BoringSSL \n - Test for different alert when using BoringSSL \n Result : \n Not test failures when using BoringSSL .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslErrorStackAssertSSLEngine . java \n - return getWrappedEngine ( ) . release ( ) ; \n + return getWrappedEngine ( ) . release ( decrement ) ; \n,Add missing parameter when delegate to SSLEngine . \n Motivation : \n https : / / github . com / netty / netty / pull / 7943 had a bug which caused to not have the argument passed to the delegating method . \n Modifications : \n Add argument to release call . \n Result : \n Correctly delegate method .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n - return newDirectBuffer ( UNSAFE . allocateMemory ( capacity ) , capacity ) ; \n + / / Calling malloc with capacity of 0 may return a null ptr or a memory address that can be used . \n + / / Just use 1 to make it safe to use in all cases : \n + / / See : http : / / pubs . opengroup . org / onlinepubs / 009695399 / functions / malloc . html \n + return newDirectBuffer ( UNSAFE . allocateMemory ( Math . max ( 1 , capacity ) ) , capacity ) ; \n common \ src \ test \ java \ io \ netty \ util \ internal \ PlatformDependentTest . java \n + import java . nio . ByteBuffer ; \n - import static org . junit . Assert . assertEquals ; \n - import static org . junit . Assert . assertFalse ; \n - import static org . junit . Assert . assertNotSame ; \n - import static org . junit . Assert . assertTrue ; \n + import static org . junit . Assert . * ; \n + import static org . junit . Assume . assumeTrue ; \n + \n + @ Test \n + public void testAllocateWithCapacity0 ( ) { \n + assumeTrue ( PlatformDependent . hasDirectBufferNoCleanerConstructor ( ) ) ; \n + ByteBuffer buffer = PlatformDependent . allocateDirectNoCleaner ( 0 ) ; \n + assertNotEquals ( 0 , PlatformDependent . directBufferAddress ( buffer ) ) ; \n + assertEquals ( 0 , buffer . capacity ( ) ) ; \n + PlatformDependent . freeDirectNoCleaner ( buffer ) ; \n + } \n","Guard against calling malloc ( 0 ) when create ByteBuffer . ( # 7948 ) \n Motivation : \n We did not guard against the case of calling malloc ( 0 ) when creating a ByteBuffer without a Cleaner . The problem is that malloc ( 0 ) can have different behaviour , it either return a null - pointer or a valid pointer that you can pass to free . \n The real problem arise if Unsafe . allocateMemory ( 0 ) returns 0 and we use it as the memoryAddress of the ByteBuffer . The problem here is that native libraries test for 0 and handle it as a null - ptr . This is for example true in SSL . bioSetByteBuffer ( . . . ) which would throw a NPE when 0 is used as memoryAddress and so produced errors during SSL usage . \n Modifications : \n - Always allocate 1 byte as minimum ( even if we ask for an empty buffer ) . \n - Add unit test . \n Result : \n No more errors possible because of malloc ( 0 ) .",381
pom . xml \n - < conscrypt . version > 1 . 0 . 1 < / conscrypt . version > \n + < conscrypt . version > 1 . 1 . 2 < / conscrypt . version > \n,Update to conscrypt 1 . 1 . 2 ( # 7949 ) \n Motivation : \n We use latest conscrypt to test against . \n Modifications : \n Update to conscrypt 1 . 1 . 2 \n Result : \n Use latest conscrypt release .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketRstTest . java \n - import io . netty . channel . nio . NioEventLoopGroup ; \n - import io . netty . util . internal . PlatformDependent ; \n - if ( PlatformDependent . javaVersion ( ) > = 11 & & sb . config ( ) . group ( ) instanceof NioEventLoopGroup ) { \n - / / In Java11 calling SocketChannel . close ( ) will also call shutdown ( . . , SHUT _ WR ) before actual closing the \n - / / fd which means we may not see the ECONNRESET at all : ( \n - if ( cause = = null ) { \n - return ; \n - } \n - } \n",Revert workaround in test for Java 11 as it produces a connection - reset as expected now . ( # 7951 ) \n Motivation : \n We added a workaround for Java 11 as it not produced a connect - reset when SO _ LINGER with 0 was set and NIO was used . This was fixed in the latest ea release of Java 11 : \n - http : / / hg . openjdk . java . net / jdk / jdk / rev / ea54197f4fe4 \n - https : / / bugs . openjdk . java . net / browse / JDK - 8203059 \n Modifications : \n Revert workaround . \n Result : \n Test that Java 11 behave the same way as earlier Java versions again .,381
transport \ src \ main \ java \ io \ netty \ channel \ pool \ FixedChannelPool . java \n + import io . netty . util . concurrent . GlobalEventExecutor ; \n - executor . execute ( new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - if ( ! closed ) { \n - closed = true ; \n - for ( ; ; ) { \n - AcquireTask task = pendingAcquireQueue . poll ( ) ; \n - if ( task = = null ) { \n - break ; \n - } \n - ScheduledFuture < ? > f = task . timeoutFuture ; \n - if ( f ! = null ) { \n - f . cancel ( false ) ; \n - } \n - task . promise . setFailure ( new ClosedChannelException ( ) ) ; \n - } \n - acquiredChannelCount = 0 ; \n - pendingAcquireCount = 0 ; \n - FixedChannelPool . super . close ( ) ; \n + if ( executor . inEventLoop ( ) ) { \n + close0 ( ) ; \n + } else { \n + executor . submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + close0 ( ) ; \n + } \n + } ) . awaitUninterruptibly ( ) ; \n + } \n + } \n + \n + private void close0 ( ) { \n + if ( ! closed ) { \n + closed = true ; \n + for ( ; ; ) { \n + AcquireTask task = pendingAcquireQueue . poll ( ) ; \n + if ( task = = null ) { \n + break ; \n + } \n + ScheduledFuture < ? > f = task . timeoutFuture ; \n + if ( f ! = null ) { \n + f . cancel ( false ) ; \n + task . promise . setFailure ( new ClosedChannelException ( ) ) ; \n - } ) ; \n + acquiredChannelCount = 0 ; \n + pendingAcquireCount = 0 ; \n + \n + / / Ensure we dispatch this on another Thread as close0 will be called from the EventExecutor and we need \n + / / to ensure we will not block in a EventExecutor . \n + GlobalEventExecutor . INSTANCE . execute ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + FixedChannelPool . super . close ( ) ; \n + } \n + } ) ; \n + } \n transport \ src \ main \ java \ io \ netty \ channel \ pool \ SimpleChannelPool . java \n - channel . close ( ) ; \n + / / Just ignore any errors that are reported back from close ( ) . \n + channel . close ( ) . awaitUninterruptibly ( ) ; \n,Fixed | SimpleChannelPool . close ( ) should only return after complete . ( # 7927 ) \n Motivation : \n We need to ensure we only return from close ( ) after all work is done as otherwise we may close the EventExecutor before we dispatched everything . \n Modifications : \n Correctly wait on operations to complete before return . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7901 .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelConfig . java \n - * @ deprecated Auto close will be removed in a future release . \n - * \n - * write failure . The default is { @ code false } . \n + * write failure . The default is { @ code true } . \n - @ Deprecated \n - * @ deprecated Auto close will be removed in a future release . \n - * \n - * The default is { @ code false } . \n + * The default is { @ code true } . \n - @ Deprecated \n transport \ src \ main \ java \ io \ netty \ channel \ ChannelOption . java \n - * @ deprecated Auto close will be removed in a future release . \n - * \n - @ Deprecated \n,"AUTO _ CLOSE should not be marked as deprecated . ( # 7967 ) \n Motivation : \n A long time ago we deprecated AUTO _ CLOSE but it turned out this feature is still useful because if a write error is detected there still maybe data to read , and if we close the channel automatically we will lose data \n Modifications : \n - Remove ` @ Deprecated ` tag for AUTO _ CLOSE , setAutoClose ( . . . ) and isAutoClose ( . . . ) \n - Fix javadocs on ChannelConfig to correctly tell the default value of AUTO _ CLOSE . \n Result : \n Less warnings .",381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - / / On z / OS we should not use VM . maxDirectMemory ( ) as it not reflects the correct value . \n + / / When using IBM J9 / Eclipse OpenJ9 we should not use VM . maxDirectMemory ( ) as it not reflects the \n + / / correct value . \n - if ( ! SystemPropertyUtil . get ( "" os . name "" , "" "" ) . toLowerCase ( ) . contains ( "" z / os "" ) ) { \n + String vmName = SystemPropertyUtil . get ( "" java . vm . name "" , "" "" ) . toLowerCase ( ) ; \n + if ( ! vmName . startsWith ( "" ibm j9 "" ) & & \n + / / https : / / github . com / eclipse / openj9 / blob / openj9 - 0 . 8 . 0 / runtime / include / vendor _ version . h # L53 \n + ! vmName . startsWith ( "" eclipse openj9 "" ) ) { \n","Don ' t use VM . maxDirectMemory ( ) on IBM J9 / Eclipse OpenJ9 to retrieve direct memory limit ( # 7966 ) \n Motivation : \n On J9 / OpenJ9 netty initializes this value with 64M , even the direct accessible memory is actually unbounded . \n Modifications : \n Skip usage of VM . maxDirectMemory ( ) on J9 / OpenJ9 \n Result : \n More correct direct memory limit detection . Fixes # 7654 .",381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 14 "" \n + java _ version : "" 1 . 11 . 0 - 15 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 14 "" \n + java _ version : "" 1 . 11 . 0 - 15 "" \n",Use jdk - 11 - ea + 15 when try to build with java11 ( # 7979 ) \n Motivation : \n A new EA build for java 11 is out . \n Modifications : \n Update from ea + 14 to ea + 15 \n Result : \n Use latest ea build,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2UnknownFrame . java \n - public interface Http2UnknownFrame extends Http2Frame , ByteBufHolder { \n + public interface Http2UnknownFrame extends Http2StreamFrame , ByteBufHolder { \n + @ Override \n - / * * \n - * Set the { @ link Http2FrameStream } object for this frame . \n - * / \n + @ Override \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecTest . java \n + @ Test \n + public void writeUnknownFrame ( ) { \n + childChannelInitializer . handler = new ChannelInboundHandlerAdapter ( ) { \n + @ Override \n + public void channelActive ( ChannelHandlerContext ctx ) { \n + ctx . writeAndFlush ( new DefaultHttp2HeadersFrame ( new DefaultHttp2Headers ( ) ) ) ; \n + ctx . writeAndFlush ( new DefaultHttp2UnknownFrame ( ( byte ) 99 , new Http2Flags ( ) ) ) ; \n + ctx . fireChannelActive ( ) ; \n + } \n + } ; \n + \n + Channel childChannel = newOutboundStream ( ) ; \n + assertTrue ( childChannel . isActive ( ) ) ; \n + \n + Http2FrameStream stream = readOutboundHeadersAndAssignId ( ) ; \n + parentChannel . runPendingTasks ( ) ; \n + \n + Http2UnknownFrame frame = parentChannel . readOutbound ( ) ; \n + assertEquals ( stream , frame . stream ( ) ) ; \n + assertEquals ( 99 , frame . frameType ( ) ) ; \n + assertEquals ( new Http2Flags ( ) , frame . flags ( ) ) ; \n + frame . release ( ) ; \n + } \n + \n + @ Test \n + public void readUnkownFrame ( ) { \n + LastInboundHandler inboundHandler = streamActiveAndWriteHeaders ( inboundStream ) ; \n + codec . onHttp2Frame ( new DefaultHttp2UnknownFrame ( ( byte ) 99 , new Http2Flags ( ) ) . stream ( inboundStream ) ) ; \n + codec . onChannelReadComplete ( ) ; \n + \n + / / headers and unknown frame \n + verifyFramesMultiplexedToCorrectChannel ( inboundStream , inboundHandler , 2 ) ; \n + \n + Channel childChannel = newOutboundStream ( ) ; \n + assertTrue ( childChannel . isActive ( ) ) ; \n + } \n + \n",Correctly let Http2UnkownFrame extend HttpStreamFrame and so be usable with Http2MultiplexCodec . ( # 7976 ) \n Motivation : \n This is a followup for # 7860 . In the fix for # 7860 we only partly fixed the problem as Http2UnknownFrame did not correctly extend HttpStreamFrame and so only worked when using the Http2FrameCodec . We need to have it extend HttpStreamFrame as otherwise Http2MultiplexCodec will reject to handle it correctly . \n Modifications : \n - Let Http2UnknownFrame extend HttpStreamFrame \n - Add unit tests for writing and reading Http2UnkownFrame instances when the Http2MultiplexCodec is used . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 7969 .,381
pom . xml \n + < ! - - Ensure the whole stacktrace is preserved when an exception is thrown . See https : / / issues . apache . org / jira / browse / SUREFIRE - 1457 - - > \n + < trimStackTrace > false < / trimStackTrace > \n,Don ' t trim stacktrace for exceptions when running mvn test ( # 7981 ) \n Motivation : \n The maven surefire plugin will trim stacktraces by default which makes these kind of use - less when trying to understand why an test failed because one was thrown . \n Modifications : \n Configure the plugin to not trim the stacktrace . \n Result : \n Easier to debug test - failures .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketHalfClosedTest . java \n + import io . netty . channel . socket . oio . OioSocketChannel ; \n + import io . netty . util . internal . PlatformDependent ; \n - checkPrematureClose ( ) ; \n + checkPrematureClose ( ctx ) ; \n - checkPrematureClose ( ) ; \n + checkPrematureClose ( ctx ) ; \n - private void checkPrematureClose ( ) { \n + private void checkPrematureClose ( ChannelHandlerContext ctx ) { \n - causeRef . set ( new IllegalStateException ( "" leader premature close "" ) ) ; \n - doneLatch . countDown ( ) ; \n + if ( ctx . channel ( ) instanceof OioSocketChannel & & seenOutputShutdown \n + & & PlatformDependent . javaVersion ( ) > = 11 ) { \n + / / If we are using OIO and are using Java11 this is expected atm . \n + / / See http : / / mail . openjdk . java . net / pipermail / net - dev / 2018 - May / 011511 . html . \n + doneLatch . countDown ( ) ; \n + } else { \n + causeRef . set ( new IllegalStateException ( "" leader premature close "" ) ) ; \n + doneLatch . countDown ( ) ; \n + } \n",Ignore some test - flakiness when using Java11 + due outstanding Java11 bug . ( # 7984 ) \n Motivation : \n Java11 disallow draining any remaining bytes from the socket if a write causes a connection reset . This should be completely safe to do . At the moment if a write is causing a connection - reset you basically loose all the pending bytes that are sitting on the socket and are waiting to be read . \n This happens because SocketOutputStream . write ( … ) may call AbstractPlainSocketImpl . setConnectionReset ( … ) . Once this method is called any read ( … ) call will just throw a SocketException without even attempt to read any remaining data . \n This is related : \n - https : / / bugs . openjdk . java . net / browse / JDK - 8199329 \n - http : / / hg . openjdk . java . net / jdk / jdk / rev / 92cca24c8807 \n - http : / / mail . openjdk . java . net / pipermail / net - dev / 2018 - May / 011511 . html \n Modifications : \n Tolarate if remaining bytes could not be read when using OIO . \n Result : \n Be able to build Netty and run testsuite while using Java11,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n - DnsCache authoritativeDnsServerCache , \n + final DnsCache authoritativeDnsServerCache , \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n + public void operationComplete ( ChannelFuture future ) { \n + authoritativeDnsServerCache . clear ( ) ; \n",Also clear the authoritativeDnsServerCache when closing the Channel . ( # 8174 ) \n Motivation : \n At the moment we only clear the resolveCache when the Channel is closed . We should also do the same for the authoritativeDnsServerCache . \n Modifications : \n Add authoritativeDnsServerCache . clear ( ) to the Channel closeFuture . \n Result : \n Correctly clear all caches .,381
microbench \ pom . xml \n - < jmh . version > 1 . 19 < / jmh . version > \n + < jmh . version > 1 . 21 < / jmh . version > \n,Update to jmh 1 . 2 . 1 ( # 8270 ) \n Motivation : \n We should use the latest jmh version which also supports - prof dtraceasm on MacOS . \n Modifications : \n Update to latest jmh version . \n Result : \n Better benchmark / profiling support on MacOS .,381
testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketHalfClosedTest . java \n + import io . netty . util . internal . PlatformDependent ; \n + import org . junit . Assume ; \n + / / This test only works on Linux / BSD / MacOS as we assume some semantics that are not true for Windows . \n + Assume . assumeFalse ( PlatformDependent . isWindows ( ) ) ; \n,Skip test on windows as the semantics we expect are only true on Linux / Unix / BSD / MacOS ( # 8629 ) \n Motivation : \n In the test we assume some semantics on how RST is done that are not true for Windows so we should skip it . \n Modifications : \n Skip test when on windows . \n Result : \n Be able to run testsuite on windows . Fixes https : / / github . com / netty / netty / issues / 8571 .,381
pom . xml \n - < tcnative . version > 2 . 0 . 8 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 9 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 9 . Final which fixes a memory leak ( # 8026 ) \n Motivation : \n netty - tcnative 2 . 0 . 9 . Final was released which fixes a memory leak that can happen if client auth is used via client side . \n Modifications : \n Update to latest netty - tcnative . \n Result : \n No more memory leak .,381
pom . xml \n - < tcnative . version > 2 . 0 . 9 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 10 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 10 . Final as 2 . 0 . 9 . Final did not contain all native libs for boringssl . ( # 8031 ) \n Motivation : \n netty - tcnative 2 . 0 . 9 did not contain all native code for boringssl due a release mistake . \n Modifications : \n Update to 2 . 0 . 10 \n Result : \n Use latest netty - tcnative release .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 16 "" \n + java _ version : "" 1 . 11 . 0 - 18 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 16 "" \n + java _ version : "" 1 . 11 . 0 - 18 "" \n",Use java 11 + ea18 ( # 8034 ) \n Motivation : \n Java 11 + ea18 was released . \n Modifications : \n Update to latest version . \n Result : \n Testing with latest java 11 release .,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketHalfClosedTest . java \n - import io . netty . channel . socket . oio . OioSocketChannel ; \n - import io . netty . util . internal . PlatformDependent ; \n - checkPrematureClose ( ctx ) ; \n + checkPrematureClose ( ) ; \n - checkPrematureClose ( ctx ) ; \n + checkPrematureClose ( ) ; \n - private void checkPrematureClose ( ChannelHandlerContext ctx ) { \n + private void checkPrematureClose ( ) { \n - if ( ctx . channel ( ) instanceof OioSocketChannel & & seenOutputShutdown \n - & & PlatformDependent . javaVersion ( ) > = 11 ) { \n - / / If we are using OIO and are using Java11 this is expected atm . \n - / / See http : / / mail . openjdk . java . net / pipermail / net - dev / 2018 - May / 011511 . html . \n - doneLatch . countDown ( ) ; \n - } else { \n - causeRef . set ( new IllegalStateException ( "" leader premature close "" ) ) ; \n - doneLatch . countDown ( ) ; \n - } \n + causeRef . set ( new IllegalStateException ( "" leader premature close "" ) ) ; \n + doneLatch . countDown ( ) ; \n","Revert "" Ignore some test - flakiness when using Java11 + due outstanding Java11 bug . ( # 7984 ) "" ( # 8035 ) \n Motivation : \n This reverts commit 4b728cd5bc53195bced516f33a1ea0a0def5604e as it was fixes in Java 11 ea + 17 . \n Modification : \n Revert previous added workaround as this is fixed in Java 11 now . \n Result : \n No more workaround for test included .",381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 18 "" \n + java _ version : "" 1 . 11 . 0 - 19 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 18 "" \n + java _ version : "" 1 . 11 . 0 - 19 "" \n",Update to java 11 + ea19 \n Motivation : \n A new java 11 EA version was released . \n Modifications : \n Update to java 11 + ea19 \n Result : \n Use latest java 11 release .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsQueryContext . java \n - public void operationComplete ( Future < ? super Channel > future ) throws Exception { \n + public void operationComplete ( Future < ? super Channel > future ) { \n + / / Remove the id from the manager as we fail the query . \n + parent . queryContextManager . remove ( nameServerAddr ( ) , id ) ; \n + \n",Also remove the id from the DnsQueryContextManager if query fails due parent Channel activation error . \n Motivation : \n Whenever we fail the query we should also remove the id from the DnsQueryContextManager . \n Modifications : \n Remove the id from the DnsQueryContextManager if we fail the query because the channel failed to become active . \n Result : \n More correct code .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSsl . java \n - initializeTcNative ( ) ; \n + String engine = SystemPropertyUtil . get ( "" io . netty . handler . ssl . openssl . engine "" , null ) ; \n + if ( engine = = null ) { \n + logger . debug ( "" Initialize netty - tcnative using engine : ' default ' "" ) ; \n + } else { \n + logger . debug ( "" Initialize netty - tcnative using engine : ' { } ' "" , engine ) ; \n + } \n + initializeTcNative ( engine ) ; \n - private static boolean initializeTcNative ( ) throws Exception { \n - return Library . initialize ( ) ; \n + private static boolean initializeTcNative ( String engine ) throws Exception { \n + return Library . initialize ( "" provided "" , engine ) ; \n",OpenSSL ( and so netty - tcnative ) should allow to use custom engine . ( # 8050 ) \n Motivation : \n OpenSSL allows to use a custom engine for its cryptographic operations . We should allow the user to make use of it if needed . \n See also : https : / / www . openssl . org / docs / man1 . 0 . 2 / crypto / engine . html . \n Modifications : \n Add new system property which can be used to specify the engine to use ( null is the default and will use the build in default impl ) . \n Result : \n More flexible way of using OpenSSL .,381
pom . xml \n - < tcnative . version > 2 . 0 . 11 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 12 . Final < / tcnative . version > \n,"Update to netty - tcnative 2 . 0 . 12 . Final ( # 8073 ) \n Motivation : \n A new version of tcnative was released that allows to use features depending on the runtime version of openssl , which makes it possible to use KeyManagerFactory and hostname verification on newer versions of centos / fedora / rhel and debian / ubuntu without the need to compile again . \n Modifications : \n Update to 2 . 0 . 12 . Final \n Result : \n Use latest version of netty - tcnative to support more features .",381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - final boolean endPointVerificationEnabled = endPointIdentificationAlgorithm ! = null & & \n - ! endPointIdentificationAlgorithm . isEmpty ( ) ; \n - SSL . setHostNameValidation ( ssl , DEFAULT _ HOSTNAME _ VALIDATION _ FLAGS , \n - endPointVerificationEnabled ? getPeerHost ( ) : null ) ; \n + final boolean endPointVerificationEnabled = isEndPointVerificationEnabled ( endPointIdentificationAlgorithm ) ; \n + \n + final boolean wasEndPointVerificationEnabled = \n + isEndPointVerificationEnabled ( this . endPointIdentificationAlgorithm ) ; \n + \n + if ( wasEndPointVerificationEnabled & & ! endPointVerificationEnabled ) { \n + / / Passing in null will disable hostname verification again so only do so if it was enabled before . \n + SSL . setHostNameValidation ( ssl , DEFAULT _ HOSTNAME _ VALIDATION _ FLAGS , null ) ; \n + } else { \n + String host = endPointVerificationEnabled ? getPeerHost ( ) : null ; \n + if ( host ! = null & & ! host . isEmpty ( ) ) { \n + SSL . setHostNameValidation ( ssl , DEFAULT _ HOSTNAME _ VALIDATION _ FLAGS , host ) ; \n + } \n + } \n + private static boolean isEndPointVerificationEnabled ( String endPointIdentificationAlgorithm ) { \n + return endPointIdentificationAlgorithm ! = null & & ! endPointIdentificationAlgorithm . isEmpty ( ) ; \n + } \n + \n",Only try to call SSL . setHostnameValidation ( . . . ) if needed . ( # 8074 ) \n Motivation : \n As the used OpenSSL version may not support hostname validation we should only really call SSL . setHostNameValidation ( . . . ) if we detect that its needed . \n Modifications : \n Only call SSL . setHostNameValidation if it was disabled before and now it needs to be enabled or if it was enabled before and it should be disabled now . \n Result : \n Less risk of an exception when using an OpenSSL version that does not support hostname validation .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n + \n + @ Test \n + public void testWrapDoesNotZeroOutSrc ( ) throws Exception { \n + SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n + \n + clientSslCtx = SslContextBuilder \n + . forClient ( ) \n + . trustManager ( cert . cert ( ) ) \n + . sslProvider ( sslClientProvider ( ) ) \n + . build ( ) ; \n + SSLEngine client = clientSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + \n + serverSslCtx = SslContextBuilder \n + . forServer ( cert . certificate ( ) , cert . privateKey ( ) ) \n + . sslProvider ( sslServerProvider ( ) ) \n + . build ( ) ; \n + SSLEngine server = serverSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + \n + try { \n + ByteBuffer plainServerOut = allocateBuffer ( server . getSession ( ) . getApplicationBufferSize ( ) / 2 ) ; \n + \n + handshake ( client , server ) ; \n + \n + / / Fill the whole buffer and flip it . \n + for ( int i = 0 ; i < plainServerOut . capacity ( ) ; i + + ) { \n + plainServerOut . put ( i , ( byte ) i ) ; \n + } \n + plainServerOut . position ( plainServerOut . capacity ( ) ) ; \n + plainServerOut . flip ( ) ; \n + \n + ByteBuffer encryptedServerToClient = allocateBuffer ( server . getSession ( ) . getPacketBufferSize ( ) ) ; \n + SSLEngineResult result = server . wrap ( plainServerOut , encryptedServerToClient ) ; \n + assertEquals ( SSLEngineResult . Status . OK , result . getStatus ( ) ) ; \n + assertTrue ( result . bytesConsumed ( ) > 0 ) ; \n + \n + for ( int i = 0 ; i < plainServerOut . capacity ( ) ; i + + ) { \n + assertEquals ( ( byte ) i , plainServerOut . get ( i ) ) ; \n + } \n + } finally { \n + cleanupClientSslEngine ( client ) ; \n + cleanupServerSslEngine ( server ) ; \n + cert . delete ( ) ; \n + } \n + } \n",Add test to validate SSLEngine does not zero out src buffer on wrap . ( # 7914 ) \n Motivation : \n We had a bug - report that claimed the src buffer used by OpenSslEngine will be zero out . \n Modifications : \n Add testcase to ensure correct behaviour \n Result : \n Testcase for https : / / github . com / netty / netty / issues / 7753,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ AbstractReferenceCountedByteBuf . java \n - private volatile int refCnt ; \n + private volatile int refCnt = 1 ; \n - refCntUpdater . set ( this , 1 ) ; \n",Directly init refCnt to 1 ( # 8274 ) \n Motivation : \n We should just directly init the refCnt to 1 and not use the AtomicIntegerFieldUpdater . \n Modifications : \n Just assing directly to 1 . \n Result : \n Cleaner code and possible a bit faster as the JVM / JIT may be able to optimize the first store easily .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslX509Certificate . java \n + import javax . security . auth . x500 . X500Principal ; \n + import java . security . Provider ; \n + import java . security . cert . CertificateParsingException ; \n + import java . util . Collection ; \n + import java . util . List ; \n + @ Override \n + public X500Principal getIssuerX500Principal ( ) { \n + return unwrap ( ) . getIssuerX500Principal ( ) ; \n + } \n + \n + @ Override \n + public X500Principal getSubjectX500Principal ( ) { \n + return unwrap ( ) . getSubjectX500Principal ( ) ; \n + } \n + \n + @ Override \n + public List < String > getExtendedKeyUsage ( ) throws CertificateParsingException { \n + return unwrap ( ) . getExtendedKeyUsage ( ) ; \n + } \n + \n + @ Override \n + public Collection < List < ? > > getSubjectAlternativeNames ( ) throws CertificateParsingException { \n + return unwrap ( ) . getSubjectAlternativeNames ( ) ; \n + } \n + \n + @ Override \n + public Collection < List < ? > > getIssuerAlternativeNames ( ) throws CertificateParsingException { \n + return unwrap ( ) . getSubjectAlternativeNames ( ) ; \n + } \n + \n + / / No @ Override annotation as it was only introduced in Java8 . \n + public void verify ( PublicKey key , Provider sigProvider ) \n + throws CertificateException , NoSuchAlgorithmException , InvalidKeyException , SignatureException { \n + unwrap ( ) . verify ( key , sigProvider ) ; \n + } \n + \n pom . xml \n + < ignore > java . security . cert . X509Certificate < / ignore > \n",Override and so delegate all methods in OpenSslX509Certificate ( # 8472 ) \n Motivation : \n We did not override all methods in OpenSslX509Certificate and delegate to the internal 509Certificate . \n Modifications : \n Add missing overrides . \n Result : \n More correct implementation,381
codec \ src \ main \ java \ io \ netty \ handler \ codec \ MessageToMessageDecoder . java \n - * by this encoder . \n + * by this decoder . \n,Fix typo in MessageToMessageDecoder api docs . ( # 8638 ) \n Motivation : \n We had some typo ( most likely caused by copy - and - paste ) in the api docs which should be fixed . \n Modifications : \n Replace encoder by decoder word . \n Result : \n Correct apidocs .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - assert readStatus = = ReadStatus . IN _ PROGRESS ; \n + assert readStatus ! = ReadStatus . IDLE ; \n,Fix incorrect assert in Http2MultiplexCodec caused by 9f9aa1a . ( # 8639 ) \n Motivation : \n 9f9aa1a did some changes related to fixing how we handle ctx . read ( ) in child channel but did incorrectly change some assert . \n Modifications : \n Fix assert to be correct . \n Result : \n Code does not throw an AssertionError due incorrect assert check .,381
"common \ src \ main \ java \ io \ netty \ util \ concurrent \ DefaultPromise . java \n - if ( result instanceof CauseHolder | | result = = SUCCESS ) { \n + if ( result instanceof CauseHolder | | result = = SUCCESS | | result = = UNCANCELLABLE ) { \n common \ src \ test \ java \ io \ netty \ util \ concurrent \ DefaultPromiseTest . java \n - import static org . junit . Assert . assertEquals ; \n - import static org . junit . Assert . assertSame ; \n - import static org . junit . Assert . assertThat ; \n - import static org . junit . Assert . assertTrue ; \n + import static org . junit . Assert . * ; \n + @ Test \n + public void setUncancellableGetNow ( ) { \n + final Promise < String > promise = new DefaultPromise < String > ( ImmediateEventExecutor . INSTANCE ) ; \n + assertNull ( promise . getNow ( ) ) ; \n + assertTrue ( promise . setUncancellable ( ) ) ; \n + assertNull ( promise . getNow ( ) ) ; \n + assertFalse ( promise . isDone ( ) ) ; \n + assertFalse ( promise . isSuccess ( ) ) ; \n + \n + promise . setSuccess ( "" success "" ) ; \n + \n + assertTrue ( promise . isDone ( ) ) ; \n + assertTrue ( promise . isSuccess ( ) ) ; \n + assertEquals ( "" success "" , promise . getNow ( ) ) ; \n + } \n + \n",DefaultPromise . getNow ( ) does not correctly handle DefaultPromise . setUncancellable ( ) ( # 8154 ) \n Motivation : \n We do not correctly check for previous calles of setUncancellable ( ) in getNow ( ) which may result in ClassCastException as we incorrectly return the internally UNCANCELLABLE object and not null if setUncancellable ( ) we as called before . \n Modifications : \n Correctly check for UNCANCELLABLE and add unit test . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8135 .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n - SSLEngine engine = serverSslCtx . newEngine ( ch . alloc ( ) ) ; \n + SSLEngine engine = wrapEngine ( serverSslCtx . newEngine ( ch . alloc ( ) ) ) ; \n - ch . pipeline ( ) . addLast ( new SslHandler ( clientSslCtx . newEngine ( ch . alloc ( ) ) ) ) ; \n + ch . pipeline ( ) . addLast ( new SslHandler ( wrapEngine ( clientSslCtx . newEngine ( ch . alloc ( ) ) ) ) ) ; \n - server = serverSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + server = wrapEngine ( serverSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ) ; \n,Ensure we correctly call wrapEngine ( . . . ) during tests . ( # 8473 ) \n Motivation : \n We should call wrapEngine ( . . . ) in our SSLEngineTest to correctly detect all errors in case of the OpenSSLEngine . \n Modifications : \n Add missing wrapEngine ( . . . ) calls . \n Result : \n More correct tests,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslCertificateException . java \n - if ( ! CertificateVerifier . isValid ( errorCode ) ) { \n + / / Call OpenSsl . isAvailable ( ) to ensure we try to load the native lib as CertificateVerifier . isValid ( . . . ) \n + / / will depend on it . If loading fails we will just skip the validation . \n + if ( OpenSsl . isAvailable ( ) & & ! CertificateVerifier . isValid ( errorCode ) ) { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslCertificateExceptionTest . java \n - import org . junit . BeforeClass ; \n - @ BeforeClass \n - public static void assumeOpenSsl ( ) { \n - Assume . assumeTrue ( OpenSsl . isAvailable ( ) ) ; \n - } \n - \n + Assume . assumeTrue ( OpenSsl . isAvailable ( ) ) ; \n + Assume . assumeTrue ( OpenSsl . isAvailable ( ) ) ; \n + \n + @ Test \n + public void testCanBeInstancedWhenOpenSslIsNotAvailable ( ) { \n + Assume . assumeFalse ( OpenSsl . isAvailable ( ) ) ; \n + new OpenSslCertificateException ( 0 ) ; \n + } \n,We should try to load netty - tcnative before using it in OpenSslCertificateException . ( # 8202 ) \n Motivation : \n In OpenSslCertificateException we should ensure we try to load netty - tcnative before trying to use any class from it as otherwise it may throw an error due missing linking of the native libs . \n Modifications : \n - Ensure we call OpenSsl . isAvailable ( ) before we try to use netty - tcnative for validation \n - Add testcase . \n Result : \n No more errors causing by not loading native libs before trying to use these .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n - / / UNSAFE . copyMemory ( srcAddr , dstAddr , length ) ; \n + / / Manual safe - point polling is only needed prior Java9 : \n + / / See https : / / bugs . openjdk . java . net / browse / JDK - 8149596 \n + if ( javaVersion ( ) < = 8 ) { \n + copyMemoryWithSafePointPolling ( srcAddr , dstAddr , length ) ; \n + } else { \n + UNSAFE . copyMemory ( srcAddr , dstAddr , length ) ; \n + } \n + } \n + \n + private static void copyMemoryWithSafePointPolling ( long srcAddr , long dstAddr , long length ) { \n - / / UNSAFE . copyMemory ( src , srcOffset , dst , dstOffset , length ) ; \n + / / Manual safe - point polling is only needed prior Java9 : \n + / / See https : / / bugs . openjdk . java . net / browse / JDK - 8149596 \n + if ( javaVersion ( ) < = 8 ) { \n + copyMemoryWithSafePointPolling ( src , srcOffset , dst , dstOffset , length ) ; \n + } else { \n + UNSAFE . copyMemory ( src , srcOffset , dst , dstOffset , length ) ; \n + } \n + } \n + \n + private static void copyMemoryWithSafePointPolling ( \n + Object src , long srcOffset , Object dst , long dstOffset , long length ) { \n",Only use manual safepoint polling in PlatformDependent0 . copyMemory ( . . . ) when using java < = 8 ( # 8124 ) \n Motivation : \n Java9 and later does the safepoint polling by itself so there is not need for us to do it . \n Modifications : \n Check for java version before doing manual safepoint polling . \n Result : \n Less custom code and less overhead when using java9 and later . Fixes https : / / github . com / netty / netty / issues / 8122 .,381
pom . xml \n - < tcnative . version > 2 . 0 . 13 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 14 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 14 which does correctly handle shading ( # 8218 ),381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 19 "" \n + java _ version : "" 1 . 11 . 0 - 28 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 19 "" \n + java _ version : "" 1 . 11 . 0 - 28 "" \n",Use Java11 + ea28 during build . ( # 8113 ) \n Motivation : \n We should ensure we use the latest Java11 EA during build to catch any regressions etc . \n Modifications : \n Update from ea19 to ea28 . \n Result : \n Use latest Java11 release .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelConfig . java \n - * @ deprecated Use { @ link MaxMessagesRecvByteBufAllocator } \n + * @ deprecated Use { @ link MaxMessagesRecvByteBufAllocator } and \n + * { @ link MaxMessagesRecvByteBufAllocator # maxMessagesPerRead ( ) } . \n - * @ deprecated Use { @ link MaxMessagesRecvByteBufAllocator } \n + * @ deprecated Use { @ link MaxMessagesRecvByteBufAllocator } and \n + * { @ link MaxMessagesRecvByteBufAllocator # maxMessagesPerRead ( int ) } . \n transport \ src \ main \ java \ io \ netty \ channel \ ChannelOption . java \n + * and { @ link MaxMessagesRecvByteBufAllocator # maxMessagesPerRead ( int ) } . \n,Clarify deprecation docs a bit . ( # 8226 ) \n Motivation : \n It seems to sometimes confuse people what to do to replace setMaxMessagePerRead ( . . . ) . \n Modifications : \n Add some more details to the javadocs about the correct replacement . \n Result : \n Related to https : / / github . com / netty / netty / issues / 8214 .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - private static final boolean DIRECT _ BUFFER _ PREFERRED = \n - UNSAFE _ UNAVAILABILITY _ CAUSE = = null & & ! SystemPropertyUtil . getBoolean ( "" io . netty . noPreferDirect "" , false ) ; \n + private static final boolean DIRECT _ BUFFER _ PREFERRED ; \n - if ( logger . isDebugEnabled ( ) ) { \n - logger . debug ( "" - Dio . netty . noPreferDirect : { } "" , ! DIRECT _ BUFFER _ PREFERRED ) ; \n - } \n + \n + / / We should always prefer direct buffers by default if we can use a Cleaner to release direct buffers . \n + DIRECT _ BUFFER _ PREFERRED = CLEANER ! = NOOP \n + & & ! SystemPropertyUtil . getBoolean ( "" io . netty . noPreferDirect "" , false ) ; \n + if ( logger . isDebugEnabled ( ) ) { \n + logger . debug ( "" - Dio . netty . noPreferDirect : { } "" , ! DIRECT _ BUFFER _ PREFERRED ) ; \n + } \n",We should prefer direct buffers if we can access the cleaner even if sun . misc . Unsafe is not present . ( # 8233 ) \n Motivation : \n We should prefer direct buffers whenever we can use the cleaner even if sun . misc . Unsafe is not present . \n Modifications : \n Correctly prefer direct buffers in all cases . \n Result : \n More correct code .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - throw shutdownWithError ( "" SSL _ write "" ) ; \n + throw shutdownWithError ( "" SSL _ write "" , sslError ) ; \n - private SSLException shutdownWithError ( String operations ) { \n + private SSLException shutdownWithError ( String operations , int sslError ) { \n - return shutdownWithError ( operations , err ) ; \n + return shutdownWithError ( operations , sslError , err ) ; \n - private SSLException shutdownWithError ( String operation , String err ) { \n + private SSLException shutdownWithError ( String operation , int sslError , String err ) { \n - logger . debug ( "" { } failed : OpenSSL error : { } "" , operation , err ) ; \n + logger . debug ( "" { } failed with { } : OpenSSL error : { } "" , operation , sslError , err ) ; \n - return sslReadErrorResult ( SSL . getLastErrorNumber ( ) , bytesConsumed , \n + return sslReadErrorResult ( sslError , SSL . getLastErrorNumber ( ) , bytesConsumed , \n - private SSLEngineResult sslReadErrorResult ( int err , int bytesConsumed , int bytesProduced ) throws SSLException { \n + private SSLEngineResult sslReadErrorResult ( int error , int stackError , int bytesConsumed , int bytesProduced ) \n + throws SSLException { \n - handshakeException = new SSLHandshakeException ( SSL . getErrorString ( err ) ) ; \n + handshakeException = new SSLHandshakeException ( SSL . getErrorString ( stackError ) ) ; \n - throw shutdownWithError ( "" SSL _ read "" , SSL . getErrorString ( err ) ) ; \n + throw shutdownWithError ( "" SSL _ read "" , error , SSL . getErrorString ( stackError ) ) ; \n - throw shutdownWithError ( "" SSL _ do _ handshake "" ) ; \n + throw shutdownWithError ( "" SSL _ do _ handshake "" , sslError ) ; \n",Log more details when shutdown SSL because of an error . ( # 8236 ) \n Motivation : \n We should log a bit more details about why we shutdown the SSL . \n Modifications : \n Add the return value of SSL _ get _ error ( . . . ) as well in debug mode . \n Result : \n More logging to make it easier to understand why an SSL error happened .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - / * \n - * We do not want to log this message if unsafe is explicitly disabled . Do not remove the explicit no unsafe \n - * guard . \n - * / \n - if ( ! hasUnsafe ( ) & & ! isAndroid ( ) & & ! PlatformDependent0 . isExplicitNoUnsafe ( ) ) { \n - logger . info ( \n - "" Your platform does not provide complete low - level API for accessing direct buffers reliably . "" + \n - "" Unless explicitly requested , heap buffer will always be preferred to avoid potential system "" + \n - "" instability . "" ) ; \n - } \n - \n + \n + / * \n + * We do not want to log this message if unsafe is explicitly disabled . Do not remove the explicit no unsafe \n + * guard . \n + * / \n + if ( CLEANER = = NOOP & & ! PlatformDependent0 . isExplicitNoUnsafe ( ) ) { \n + logger . info ( \n + "" Your platform does not provide complete low - level API for accessing direct buffers reliably . "" + \n + "" Unless explicitly requested , heap buffer will always be preferred to avoid potential system "" + \n + "" instability . "" ) ; \n + } \n",Fix log message about using non - direct buffers by default ( # 8235 ) \n Motivation : \n f77891cc1786806630f6c4408d5d37abb1891e7b changed slightly how we detect if we should prefer direct buffers or not but did miss to also take this into account when logging . \n Modifications : \n Fix branch for log message to reflect changes in f77891cc1786806630f6c4408d5d37abb1891e7b . \n Result : \n Correct logging .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - String err = SSL . getLastError ( ) ; \n - return shutdownWithError ( operations , sslError , err ) ; \n + return shutdownWithError ( operations , sslError , SSL . getLastErrorNumber ( ) ) ; \n - private SSLException shutdownWithError ( String operation , int sslError , String err ) { \n + private SSLException shutdownWithError ( String operation , int sslError , int error ) { \n + String errorString = SSL . getErrorString ( error ) ; \n - logger . debug ( "" { } failed with { } : OpenSSL error : { } "" , operation , sslError , err ) ; \n + logger . debug ( "" { } failed with { } : OpenSSL error : { } { } "" , \n + operation , sslError , error , errorString ) ; \n - return new SSLException ( err ) ; \n + return new SSLException ( errorString ) ; \n - return new SSLHandshakeException ( err ) ; \n + return new SSLHandshakeException ( errorString ) ; \n - throw shutdownWithError ( "" SSL _ read "" , error , SSL . getErrorString ( stackError ) ) ; \n + throw shutdownWithError ( "" SSL _ read "" , error , stackError ) ; \n - logger . debug ( "" SSL _ shutdown failed : OpenSSL error : { } "" , SSL . getLastError ( ) ) ; \n + int error = SSL . getLastErrorNumber ( ) ; \n + logger . debug ( "" SSL _ shutdown failed : OpenSSL error : { } { } "" , error , SSL . getErrorString ( error ) ) ; \n",Add more debug informations when log SSL errors . ( # 8241 ) \n Motivation : \n ea626ef8c390dc81c71b3a16521cf591611bc5df added more debug logging but we can even include a bit more . \n Modifications : \n Always log the error number as well . \n Result : \n More informations for debugging SSL errors .,381
pom . xml \n - < tcnative . version > 2 . 0 . 14 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 15 . Final < / tcnative . version > \n,Update to latest netty - tcnative ( # 8246 ) \n Motivation : \n We should use the latest netty - tcnative release which contains a fix to correctly support DH based ciphers when using openssl 1 . 1 . x \n Modifications : \n Update to latest netty - tcnative which has the fix . \n Result : \n Correctly support DH ciphers in all cases . Fixes https : / / github . com / netty / netty / issues / 8165 .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ logging \ AbstractInternalLogger . java \n - private static final String EXCEPTION _ MESSAGE = "" Unexpected exception : "" ; \n + static final String EXCEPTION _ MESSAGE = "" Unexpected exception : "" ; \n common \ src \ main \ java \ io \ netty \ util \ internal \ logging \ Log4J2Logger . java \n + import static io . netty . util . internal . logging . AbstractInternalLogger . EXCEPTION _ MESSAGE ; \n + \n - / * * { @ linkplain AbstractInternalLogger # EXCEPTION _ MESSAGE } * / \n - private static final String EXCEPTION _ MESSAGE = "" Unexpected exception : "" ; \n - \n - protected Level toLevel ( InternalLogLevel level ) { \n + private static Level toLevel ( InternalLogLevel level ) { \n common \ src \ test \ java \ io \ netty \ util \ internal \ logging \ Log4J2LoggerTest . java \n - import java . lang . reflect . Field ; \n - import org . junit . Test ; \n - @ Test \n - public void testEXCEPTION _ MESSAGE ( ) { \n - assertEquals ( getFieldValue ( AbstractInternalLogger . class , "" EXCEPTION _ MESSAGE "" ) , \n - getFieldValue ( Log4J2Logger . class , "" EXCEPTION _ MESSAGE "" ) ) ; \n - } \n - \n - @ SuppressWarnings ( "" unchecked "" ) \n - private static < T > T getFieldValue ( Class < ? > clazz , String fieldName ) { \n - try { \n - Field field = clazz . getDeclaredField ( fieldName ) ; \n - if ( ! field . isAccessible ( ) ) { \n - Assume . assumeThat ( ReflectionUtil . trySetAccessible ( field , true ) , CoreMatchers . nullValue ( ) ) ; \n - } \n - return ( T ) field . get ( AbstractInternalLogger . class ) ; \n - } catch ( ReflectiveOperationException e ) { \n - throw new IllegalStateException ( e ) ; \n - } \n - } \n - \n",Cleanup Log4J2Logger ( # 8245 ) \n Motivation : \n Log4J2Logger had some code - duplication with AbstractInternalLogger \n Modifications : \n Reuse AbstractInternaLogger . EXCEPTION _ MESSAGE in Log4J2Logger and so remove some code - duplication \n Result : \n Less duplicated code .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsCache . java \n - this . minTtl = checkPositiveOrZero ( minTtl , "" minTtl "" ) ; \n - this . maxTtl = checkPositiveOrZero ( maxTtl , "" maxTtl "" ) ; \n + this . minTtl = Math . min ( MAX _ SUPPORTED _ TTL _ SECS , checkPositiveOrZero ( minTtl , "" minTtl "" ) ) ; \n + this . maxTtl = Math . min ( MAX _ SUPPORTED _ TTL _ SECS , checkPositiveOrZero ( maxTtl , "" maxTtl "" ) ) ; \n resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DefaultDnsCacheTest . java \n + @ Test \n + public void testExpireWithToBigMinTTL ( ) { \n + EventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + \n + try { \n + EventLoop loop = group . next ( ) ; \n + final DefaultDnsCache cache = new DefaultDnsCache ( Integer . MAX _ VALUE , Integer . MAX _ VALUE , Integer . MAX _ VALUE ) ; \n + assertNotNull ( cache . cache ( "" netty . io "" , null , NetUtil . LOCALHOST , 100 , loop ) ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n + \n",Enfore upper limit for minTtl when using DefaultCacheEntry . ( # 7920 ) \n Motivation : \n a598c3b69b55f930b91a8265f42d1a3cceb75ddd added a upper limit for ttl but missed to also do the same for minTtl . \n Modifications : \n - Add upper limit for minTtl \n - Add testcase . \n Result : \n No more IllegalArgumentException possible .,381
"transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n + import java . util . concurrent . CountDownLatch ; \n - public void testRebuildSelector ( ) throws Exception { \n + public void testRebuildSelector ( ) { \n + \n + @ Test \n + public void testInterruptEventLoopThread ( ) throws Exception { \n + EventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + final NioEventLoop loop = ( NioEventLoop ) group . next ( ) ; \n + try { \n + Selector selector = loop . unwrappedSelector ( ) ; \n + assertTrue ( selector . isOpen ( ) ) ; \n + \n + loop . submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + / / Interrupt the thread which should not end - up in a busy spin and \n + / / so the selector should not have been rebuild . \n + Thread . currentThread ( ) . interrupt ( ) ; \n + } \n + } ) . syncUninterruptibly ( ) ; \n + \n + assertTrue ( selector . isOpen ( ) ) ; \n + \n + final CountDownLatch latch = new CountDownLatch ( 2 ) ; \n + loop . submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + latch . countDown ( ) ; \n + } \n + } ) . syncUninterruptibly ( ) ; \n + \n + loop . schedule ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + latch . countDown ( ) ; \n + } \n + } , 2 , TimeUnit . SECONDS ) . syncUninterruptibly ( ) ; \n + \n + latch . await ( ) ; \n + \n + assertSame ( selector , loop . unwrappedSelector ( ) ) ; \n + assertTrue ( selector . isOpen ( ) ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n",Add test that we handle thread . interrupt ( ) in NioEventLoop ( # 7917 ) \n Motivation : \n We added some code to guard against thread . interrupt ( ) in NioEventLoop but did not added a test . \n Modifications : \n Add testcase . \n Result : \n Verify that we correctly handle interrupt ( ) .,381
"example \ src \ main \ java \ io \ netty \ example \ http \ helloworld \ HttpHelloWorldServerHandler . java \n - import io . netty . channel . ChannelInboundHandlerAdapter ; \n + import io . netty . channel . SimpleChannelInboundHandler ; \n + import io . netty . handler . codec . http . HttpObject ; \n + \n - public class HttpHelloWorldServerHandler extends ChannelInboundHandlerAdapter { \n + public class HttpHelloWorldServerHandler extends SimpleChannelInboundHandler < HttpObject > { \n - public void channelRead ( ChannelHandlerContext ctx , Object msg ) { \n + public void channelRead0 ( ChannelHandlerContext ctx , HttpObject msg ) { \n",Correctly release inbound data in example . ( # 8105 ) \n Motivation : \n We need to release the inbound data to ensure there are no leaks . \n Modifications : \n Extend SimpleChannelInboundHandler which will release inbound data by default . \n Result : \n No more leaks .,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ PoolThreadCache . java \n + import java . util . concurrent . atomic . AtomicBoolean ; \n + private final AtomicBoolean freed = new AtomicBoolean ( ) ; \n - int numFreed = free ( tinySubPageDirectCaches ) + \n - free ( smallSubPageDirectCaches ) + \n - free ( normalDirectCaches ) + \n - free ( tinySubPageHeapCaches ) + \n - free ( smallSubPageHeapCaches ) + \n - free ( normalHeapCaches ) ; \n - \n - if ( numFreed > 0 & & logger . isDebugEnabled ( ) ) { \n - logger . debug ( "" Freed { } thread - local buffer ( s ) from thread : { } "" , numFreed , Thread . currentThread ( ) . getName ( ) ) ; \n - } \n + / / As free ( ) may be called either by the finalizer or by FastThreadLocal . onRemoval ( . . . ) we need to ensure \n + / / we only call this one time . \n + if ( freed . compareAndSet ( false , true ) ) { \n + int numFreed = free ( tinySubPageDirectCaches ) + \n + free ( smallSubPageDirectCaches ) + \n + free ( normalDirectCaches ) + \n + free ( tinySubPageHeapCaches ) + \n + free ( smallSubPageHeapCaches ) + \n + free ( normalHeapCaches ) ; \n + \n + if ( numFreed > 0 & & logger . isDebugEnabled ( ) ) { \n + logger . debug ( "" Freed { } thread - local buffer ( s ) from thread : { } "" , numFreed , \n + Thread . currentThread ( ) . getName ( ) ) ; \n + } \n - if ( directArena ! = null ) { \n - directArena . numThreadCaches . getAndDecrement ( ) ; \n - } \n + if ( directArena ! = null ) { \n + directArena . numThreadCaches . getAndDecrement ( ) ; \n + } \n - if ( heapArena ! = null ) { \n - heapArena . numThreadCaches . getAndDecrement ( ) ; \n + if ( heapArena ! = null ) { \n + heapArena . numThreadCaches . getAndDecrement ( ) ; \n + } \n",Guard against calling PoolThreadCache . free ( ) multiple times . ( # 8108 ) \n Motivation : \n 5b1fe611a637c362a60b391079fff73b1a4ef912 introduced the usage of a finalizer as last resort for PoolThreadCache . As we may call free ( ) from the FastThreadLocal . onRemoval ( . . . ) and finalize ( ) we need to guard against multiple calls as otherwise we will corrupt internal state ( that is used for metrics ) . \n Modifications : \n Use AtomicBoolean to guard against multiple calls of PoolThreadCache . free ( ) . \n Result : \n No more corruption of internal state caused by calling PoolThreadCache . free ( ) multuple times .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 17 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 19 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 17 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 19 "" \n",Update to openjdk 12ea19 ( # 8487 ) \n Motivation : \n We should test against latest EA releases . \n Modifications : \n Update to openkdk 12ea19 \n Result : \n Use latest openjdk 12 EA build on the CI .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniClientTest . java \n - private static void testSniClient ( SslProvider sslClientProvider , SslProvider sslServerProvider ) throws Exception { \n + private static void testSniClient ( SslProvider sslServerProvider , SslProvider sslClientProvider ) throws Exception { \n - KeyManagerFactory kmf = PlatformDependent . javaVersion ( ) > = 8 ? \n - SniClientJava8TestUtil . newSniX509KeyManagerFactory ( cert , sniHostName ) : \n - SslContext . buildKeyManagerFactory ( \n - new X509Certificate [ ] { cert . cert ( ) } , cert . key ( ) , null , null ) ; \n - \n - final SslContext sslServerContext = SslContextBuilder . forServer ( kmf ) \n - . sslProvider ( sslServerProvider ) . build ( ) ; \n + final SslContext sslServerContext ; \n + if ( ( sslServerProvider = = SslProvider . OPENSSL | | sslServerProvider = = SslProvider . OPENSSL _ REFCNT ) \n + & & ! OpenSsl . useKeyManagerFactory ( ) ) { \n + sslServerContext = SslContextBuilder . forServer ( cert . certificate ( ) , cert . privateKey ( ) ) \n + . sslProvider ( sslServerProvider ) \n + . build ( ) ; \n + } else { \n + / / The used OpenSSL version does support a KeyManagerFactory , so use it . \n + KeyManagerFactory kmf = PlatformDependent . javaVersion ( ) > = 8 ? \n + SniClientJava8TestUtil . newSniX509KeyManagerFactory ( cert , sniHostName ) : \n + SslContext . buildKeyManagerFactory ( \n + new X509Certificate [ ] { cert . cert ( ) } , cert . key ( ) , null , null ) ; \n + \n + sslServerContext = SslContextBuilder . forServer ( kmf ) \n + . sslProvider ( sslServerProvider ) \n + . build ( ) ; \n + } \n","Only use KeyManagerFactory in SniClientTest when supported by OpenSSL version . ( # 8289 ) \n Motivation : \n 6ed7c6c75d458047adc37470697f215e9d7436ea added a test which blindly assumed we can use a KeyManagerFactory all the time . This is only true if have OpenSSL 1 . 0 . 2 or later , which may not be the case . \n Modifications : \n Only use KeyManagerFactory in test if the OpenSSL version does support it . \n Result : \n More robust tests .",381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ExtendedOpenSslSession . java \n + import java . util . Collections ; \n + / / Do not mark as override so we can compile on java8 . \n + public List < byte [ ] > getStatusResponses ( ) { \n + / / Just return an empty list for now until we support it as otherwise we will fail in java9 \n + / / because of their sun . security . ssl . X509TrustManagerImpl class . \n + return Collections . emptyList ( ) ; \n + } \n + \n,Implemented ExtendedOpenSslSession . getStatusResponses ( ) so it not throws an UnsupportedOperationException . ( # 8290 ) \n Motivation : \n 6ed7c6c75d458047adc37470697f215e9d7436ea added support for ExtendedOpenSslSession but we did not override getStatusResponses ( ) . This lead to test failures on java9 . \n Modifications : \n Implement ExtendedOpenSslSession . getStatusResponses ( ) so it just returns an empty list . \n Result : \n Test pass again on Java9 .,381
pom . xml \n - < conscrypt . version > 1 . 1 . 3 < / conscrypt . version > \n + < conscrypt . version > 1 . 3 . 0 < / conscrypt . version > \n,Update to Conscrypt 1 . 3 . 0 ( # 8296 ) \n Motivation : \n Conscrypt 1 . 3 . 0 was just released and adds support for TLSv1 . 3 \n Modifications : \n Update to 1 . 3 . 0 \n Result : \n Use latest conscrypt during build / test .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n + \n + @ Override \n + public List < byte [ ] > getStatusResponses ( ) { \n + byte [ ] ocspResponse = null ; \n + if ( enableOcsp & & clientMode ) { \n + synchronized ( ReferenceCountedOpenSslEngine . this ) { \n + if ( ! isDestroyed ( ) ) { \n + ocspResponse = SSL . getOcspResponse ( ssl ) ; \n + } \n + } \n + } \n + return ocspResponse = = null ? \n + Collections . < byte [ ] > emptyList ( ) : Collections . singletonList ( ocspResponse ) ; \n + } \n,Correctly implement ExtendedSSLSession . getStatusResponses ( ) for ReferenceCountedOpenSslEngine ( # 8297 ) \n Motivation : \n Java9 added getStatusResponses ( ) to ExtendedSSLSession which we should correctly support when possible . \n Modifications : \n Implement the method correctly . \n Result : \n More complete and correct implementation .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ ParameterizedSslHandlerTest . java \n - promise . setSuccess ( null ) ; \n + promise . trySuccess ( null ) ; \n,Cleanup SSL test . ( # 8301 ) \n Motivation : \n I noticed that we had some errors showing up in a test ( which did not fail it tho ) because we tried to full - fill the promise multiples times . \n Modifications : \n Use trySuccess ( . . . ) as we may produce multiple exceptions . \n Result : \n Less errors during test - run .,381
codec \ src \ main \ java \ io \ netty \ handler \ codec \ compression \ JdkZlibEncoder . java \n - while ( ! deflater . needsInput ( ) ) { \n + for ( ; ; ) { \n + if ( deflater . needsInput ( ) ) { \n + / / Consumed everything \n + break ; \n + } else { \n + if ( ! out . isWritable ( ) ) { \n + / / We did not consume everything but the buffer is not writable anymore . Increase the capacity to \n + / / make more room . \n + out . ensureWritable ( out . writerIndex ( ) ) ; \n + } \n + } \n,Ensure we always encode all data in JdkZlibEncoder . ( # 8305 ) \n Motivation : \n In theory our estimation of the needed buffer could be off and so we need to ensure we grow it if there is no space left . \n Modifications : \n Ensure we grow the buffer if there is no space left in there but we still have data to deflate . \n Result : \n Correctly deflate data in all cases .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 28 "" \n + java _ version : "" 1 . 11 . 0 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 - 28 "" \n + java _ version : "" 1 . 11 . 0 "" \n",Update to final Java11 release ( # 8320 ) \n Motivation : \n We should use final Java11 release during builds . \n Modifications : \n Update to final Java11 release \n Result : \n Use latest release .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniClientTest . java \n + import io . netty . util . ReferenceCountUtil ; \n + import io . netty . util . ReferenceCounted ; \n + SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n + SslContext sslServerContext = null ; \n + SslContext sslClientContext = null ; \n + \n - SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n - \n - final SslContext sslServerContext ; \n + final SslContext finalContext = sslServerContext ; \n - return sslServerContext ; \n + return finalContext ; \n - SslContext sslContext = SslContextBuilder . forClient ( ) . trustManager ( tmf ) \n + sslClientContext = SslContextBuilder . forClient ( ) . trustManager ( tmf ) \n - sslContext . newEngine ( ByteBufAllocator . DEFAULT , sniHostName , - 1 ) ) ; \n + sslClientContext . newEngine ( ByteBufAllocator . DEFAULT , sniHostName , - 1 ) ) ; \n + ReferenceCountUtil . release ( sslServerContext ) ; \n + ReferenceCountUtil . release ( sslClientContext ) ; \n + \n + cert . delete ( ) ; \n + \n",Fix leak in SniClientTest . ( # 8324 ) \n Motivation : \n We need to release the ReferenceCountedSslContext to eliminate resource leaks . \n Reported in https : / / garage . netty . io / teamcity / viewLog . html ? buildId = 33353 & buildTypeId = netty _ build _ oraclejdk8 & tab = buildLog # _ focus = 157264 . \n Modifications : \n Call release on the SslContext instances . \n Result : \n No more leaks in tests .,381
pom . xml \n + < ! - - JDK12 - - > \n + < profile > \n + < id > java12 < / id > \n + < activation > \n + < jdk > 12 < / jdk > \n + < / activation > \n + < properties > \n + < ! - - Not use alpn agent as Java11 supports alpn out of the box - - > \n + < argLine . alpnAgent / > \n + < forbiddenapis . skip > true < / forbiddenapis . skip > \n + < ! - - Needed because of https : / / issues . apache . org / jira / browse / MENFORCER - 275 - - > \n + < enforcer . plugin . version > 3 . 0 . 0 - M1 < / enforcer . plugin . version > \n + < ! - - 1 . 4 . x does not work in Java10 + - - > \n + < jboss . marshalling . version > 2 . 0 . 5 . Final < / jboss . marshalling . version > \n + < ! - - This is the minimum supported by Java12 - - > \n + < maven . compiler . source > 1 . 7 < / maven . compiler . source > \n + < maven . compiler . target > 1 . 7 < / maven . compiler . target > \n + < / properties > \n + < / profile > \n + \n,Add profile to be able to compile on java12 ( # 8321 ) \n Motivation : \n First EA releases of Java12 are out we should be able to compile with these and run tests . \n Modifications : \n Add maven profile for java12 . \n Result : \n Be able to use Java12,381
"docker \ docker - compose . centos - 6 . 110 . yaml \n + test - leak : \n + image : netty : centos - 6 - 1 . 10 \n docker \ docker - compose . centos - 6 . 111 . yaml \n + test - leak : \n + image : netty : centos - 6 - 1 . 11 \n + \n docker \ docker - compose . centos - 6 . 18 . yaml \n + test - leak : \n + image : netty : centos - 6 - 1 . 8 \n + \n docker \ docker - compose . centos - 6 . 19 . yaml \n + test - leak : \n + image : netty : centos - 6 - 1 . 9 \n + \n docker \ docker - compose . centos - 7 . 110 . yaml \n + test - leak : \n + image : netty : centos - 7 - 1 . 10 \n + \n docker \ docker - compose . centos - 7 . 111 . yaml \n + test - leak : \n + image : netty : centos - 7 - 1 . 11 \n + \n docker \ docker - compose . centos - 7 . 18 . yaml \n + test - leak : \n + image : netty : centos - 7 - 1 . 8 \n + \n docker \ docker - compose . centos - 7 . 19 . yaml \n + test - leak : \n + image : netty : centos - 7 - 1 . 9 \n + \n docker \ docker - compose . yaml \n - . . : / code \n + test - leak : \n + < < : * common \n + command : / bin / bash - cl "" . / mvnw - Pleak clean install - Dio . netty . testsuite . badHost = netty . io "" \n + \n",Allow to run tests with leak detection enabled . ( # 8323 ) \n Motivation : \n We should add some command to be able to run all tests with leak detection enabled . This will then be used on the CI during PR builds . \n Modifications : \n Add new docker - compose config to run with leak - detection enabled . \n Result : \n Easy way to enable leak detection while running tests via docker .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniClientJava8TestUtil . java \n + import io . netty . util . ReferenceCountUtil ; \n + SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n + SslContext sslServerContext = null ; \n + SslContext sslClientContext = null ; \n + \n - SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n - final SslContext sslServerContext = SslContextBuilder . forServer ( cert . key ( ) , cert . cert ( ) ) \n + sslServerContext = SslContextBuilder . forServer ( cert . key ( ) , cert . cert ( ) ) \n + \n + final SslContext finalContext = sslServerContext ; \n - SslHandler handler = sslServerContext . newHandler ( ch . alloc ( ) ) ; \n + SslHandler handler = finalContext . newHandler ( ch . alloc ( ) ) ; \n - SslContext sslContext = SslContextBuilder . forClient ( ) . trustManager ( InsecureTrustManagerFactory . INSTANCE ) \n + sslClientContext = SslContextBuilder . forClient ( ) . trustManager ( InsecureTrustManagerFactory . INSTANCE ) \n - sslContext . newEngine ( ByteBufAllocator . DEFAULT , sniHost , - 1 ) ) ; \n + sslClientContext . newEngine ( ByteBufAllocator . DEFAULT , sniHost , - 1 ) ) ; \n + \n + ReferenceCountUtil . release ( sslServerContext ) ; \n + ReferenceCountUtil . release ( sslClientContext ) ; \n + \n + cert . delete ( ) ; \n + \n",Fix leak in SniClientJava8TestUtil ( # 8326 ) \n Motivation : \n 4d1458604ab3d378192c6240dd12ea85d1223838 did fix some leaks in SniClientTest but missed the ones in SniClientJava8TestUtil . \n Modifications : \n Correctly release SslContext . \n Result : \n No more leaks in SNI tests .,381
"new file \n docker \ docker - compose . centos - 6 . 112 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - 1 . 12 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 "" \n + \n + test : \n + image : netty : centos - 6 - 1 . 12 \n + \n + test - leak : \n + image : netty : centos - 6 - 1 . 12 \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - 1 . 12 \n + \n + shell : \n + image : netty : centos - 6 - 1 . 12 \n new file \n docker \ docker - compose . centos - 7 . 112 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 7 - 1 . 12 \n + build : \n + args : \n + centos _ version : "" 7 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 "" \n + \n + test : \n + image : netty : centos - 7 - 1 . 12 \n + \n + test - leak : \n + image : netty : centos - 7 - 1 . 12 \n + \n + test - boringssl - static : \n + image : netty : centos - 7 - 1 . 12 \n + \n + shell : \n + image : netty : centos - 7 - 1 . 12 \n",Add docker - compose config to run with Java12 ( # 8327 ) \n Motivation : \n The first EA builds for Java12 are released so we should allow to run with these in our docker - compose setup . \n Modifications : \n Add docker - compose configs for Java12 . \n Result : \n Be able to run easily with Java12 as well .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n - Collections . sort ( nameservers , nameServerComparator ) ; \n - return new SequentialDnsServerAddressStream ( nameservers , 0 ) ; \n + DnsServerAddressStream cached = authoritativeDnsServerCache ( ) . get ( hostname ) ; \n + if ( cached = = null | | cached . size ( ) = = 0 ) { \n + / / If there is no cache hit ( which may be the case for example when a NoopAuthoritativeDnsServerCache \n + / / is used ) , we will just directly use the provided nameservers . \n + Collections . sort ( nameservers , nameServerComparator ) ; \n + return new SequentialDnsServerAddressStream ( nameservers , 0 ) ; \n + } \n + return cached ; \n",Use AuthoritativeDnsServerCache for creating the new redirect stream . ( # 8316 ) \n * Use AuthoritativeDnsServerCache for creating the new redirect stream . \n Motivation : \n At the moment if a user wants to provide custom sorting of the nameservers used for redirects it needs to be implemented in two places . This is more complicated as it needs to be . \n Modifications : \n - Just delegate to the AuthoritativeDnsServerCache always as we fill it before we call newRedirectDnsServerStream anyway . \n Result : \n Easier way for the user to implement custom sorting .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n + import org . junit . Assume ; \n + SslProvider clientProvider = sslClientProvider ( ) ; \n + if ( clientProvider = = SslProvider . OPENSSL | | clientProvider = = SslProvider . OPENSSL _ REFCNT ) { \n + / / Need to check if we support hostname validation in the current used OpenSSL version before running \n + / / the test . \n + Assume . assumeTrue ( OpenSsl . supportsHostnameValidation ( ) ) ; \n + } \n,Check if hostname validation is supported before trying to use in test . ( # 8333 ) \n Motivation : \n a208f6dc7c775ce8d7934f252cd6fa7527643f76 added a testcase which uses hostname validation which may not be supported by OpenSSL depending on the version that is used . We should check first before we try to use it . \n Modifications : \n Add assumeTrue ( . . . ) check to ensure hostname validation is supported before trying to run the test . \n Result : \n No more test - failures on OpenSSL versions < 1 . 0 . 2 .,381
transport - native - unix - common \ src \ main \ java \ io \ netty \ channel \ unix \ IovArray . java \n - } else if ( buf . nioBufferCount ( ) = = 1 ) { \n + } else if ( buf . hasMemoryAddress ( ) & & buf . nioBufferCount ( ) = = 1 ) { \n,IovArray . add ( . . . ) should check if buffer has memory address . \n Motivation : \n We currently not check if the buffer has a memory address and just assume this is the case if the nioBufferCount ( ) = = 1 . \n Modifications : \n - Check hasMemoryAddress ( ) before trying to access it . \n - Add unit case . \n Result : \n More correct and robust code . Related to [ # 7752 ] .,381
"pom . xml \n + < ! - - JDK10 - - > \n + < profile > \n + < id > java10 < / id > \n + < activation > \n + < jdk > 10 < / jdk > \n + < / activation > \n + < properties > \n + < ! - - Not use alpn agent as Java10 supports alpn out of the box - - > \n + < argLine . alpnAgent / > \n + < forbiddenapis . skip > true < / forbiddenapis . skip > \n + < ! - - Needed because of https : / / issues . apache . org / jira / browse / MENFORCER - 275 - - > \n + < enforcer . plugin . version > 3 . 0 . 0 - M1 < / enforcer . plugin . version > \n + < / properties > \n + < / profile > \n + \n - < jboss . marshalling . version > 1 . 4 . 11 . Final < / jboss . marshalling . version > \n + < jboss . marshalling . version > 2 . 0 . 5 . Final < / jboss . marshalling . version > \n - server \n - dsa - da - ea : io . netty . . . \n - - XX : + AggressiveOpts \n - - XX : + TieredCompilation \n - - XX : + UseBiasedLocking \n - - XX : + UseFastAccessorMethods \n - - XX : + OptimizeStringConcat \n - XX : + HeapDumpOnOutOfMemoryError \n - < version > 2 . 7 . 2 < / version > \n + < version > 2 . 18 . 3 < / version > \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketSslClientRenegotiateTest . java \n - String renegotiation = "" SSL _ RSA _ WITH _ 3DES _ EDE _ CBC _ SHA "" ; \n + String renegotiation = clientSslHandler . engine ( ) . getSupportedCipherSuites ( ) [ 0 ] ; \n",Make build pass on Java 10 ( # 7922 ) \n Motivation : \n Java 10 is out so we should be able to build netty with it ( and run the tests ) . \n Modifications : \n - Update Mockito and JBoss Marshalling to support Java 10 \n - Fix unit test to not depend on specific cipher which is not present in Java 10 anymore \n Result : \n Netty builds ( and runs all tests ) when using Java 10,381
"resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DnsNameResolverTest . java \n + import java . util . concurrent . CountDownLatch ; \n + \n + @ Test ( timeout = 2000L ) \n + public void testCachesClearedOnClose ( ) throws Exception { \n + final CountDownLatch resolveLatch = new CountDownLatch ( 1 ) ; \n + final CountDownLatch authoritativeLatch = new CountDownLatch ( 1 ) ; \n + \n + DnsNameResolver resolver = newResolver ( ) . resolveCache ( new DnsCache ( ) { \n + @ Override \n + public void clear ( ) { \n + resolveLatch . countDown ( ) ; \n + } \n + \n + @ Override \n + public boolean clear ( String hostname ) { \n + return false ; \n + } \n + \n + @ Override \n + public List < ? extends DnsCacheEntry > get ( String hostname , DnsRecord [ ] additionals ) { \n + return null ; \n + } \n + \n + @ Override \n + public DnsCacheEntry cache ( \n + String hostname , DnsRecord [ ] additionals , InetAddress address , long originalTtl , EventLoop loop ) { \n + return null ; \n + } \n + \n + @ Override \n + public DnsCacheEntry cache ( \n + String hostname , DnsRecord [ ] additionals , Throwable cause , EventLoop loop ) { \n + return null ; \n + } \n + } ) \n + . authoritativeDnsServerCache ( new DnsCache ( ) { \n + @ Override \n + public void clear ( ) { \n + authoritativeLatch . countDown ( ) ; \n + } \n + \n + @ Override \n + public boolean clear ( String hostname ) { \n + return false ; \n + } \n + \n + @ Override \n + public List < ? extends DnsCacheEntry > get ( String hostname , DnsRecord [ ] additionals ) { \n + return null ; \n + } \n + \n + @ Override \n + public DnsCacheEntry cache ( \n + String hostname , DnsRecord [ ] additionals , InetAddress address , long originalTtl , EventLoop loop ) { \n + return null ; \n + } \n + \n + @ Override \n + public DnsCacheEntry cache ( String hostname , DnsRecord [ ] additionals , Throwable cause , EventLoop loop ) { \n + return null ; \n + } \n + } ) . build ( ) ; \n + \n + resolver . close ( ) ; \n + resolveLatch . await ( ) ; \n + authoritativeLatch . await ( ) ; \n + } \n",Add tests to verify caches are cleared when the resolver is closed . ( # 8186 ) \n Motivation : \n 55fec94592920d8696349fd2956039e87cc53bc7 fixed a bug where we did not correctly clear all caches when the resolver was closed but did not add a testcase . \n Modifications : \n Add testcase . \n Result : \n More tests .,381
"transport \ src \ test \ java \ io \ netty \ channel \ ChannelInitializerTest . java \n + import java . util . concurrent . atomic . AtomicReference ; \n + @ Test \n + public void testInitChannelThrowsRegisterFirst ( ) { \n + testInitChannelThrows ( true ) ; \n + } \n + \n + @ Test \n + public void testInitChannelThrowsRegisterAfter ( ) { \n + testInitChannelThrows ( false ) ; \n + } \n + \n + private void testInitChannelThrows ( boolean registerFirst ) { \n + final Exception exception = new Exception ( ) ; \n + final AtomicReference < Throwable > causeRef = new AtomicReference < Throwable > ( ) ; \n + \n + ChannelPipeline pipeline = new LocalChannel ( ) . pipeline ( ) ; \n + \n + if ( registerFirst ) { \n + group . register ( pipeline . channel ( ) ) . syncUninterruptibly ( ) ; \n + } \n + pipeline . addFirst ( new ChannelInitializer < Channel > ( ) { \n + @ Override \n + protected void initChannel ( Channel ch ) throws Exception { \n + throw exception ; \n + } \n + \n + @ Override \n + public void exceptionCaught ( ChannelHandlerContext ctx , Throwable cause ) throws Exception { \n + causeRef . set ( cause ) ; \n + super . exceptionCaught ( ctx , cause ) ; \n + } \n + } ) ; \n + \n + if ( ! registerFirst ) { \n + group . register ( pipeline . channel ( ) ) . syncUninterruptibly ( ) ; \n + } \n + pipeline . channel ( ) . close ( ) . syncUninterruptibly ( ) ; \n + pipeline . channel ( ) . closeFuture ( ) . syncUninterruptibly ( ) ; \n + \n + assertSame ( exception , causeRef . get ( ) ) ; \n + } \n + \n",Add testcase for ChannelInitializer . initChannel ( . . . ) when throwing an Exception ( # 8188 ) \n Motivation : \n We had a report that the exception may not be correctly propagated . This test shows it is . \n Modifications : \n Add testcase . \n Result : \n Test for https : / / github . com / netty / netty / issues / 8158,381
transport - native - kqueue \ pom . xml \n - < ! - - support for _ _ attribute _ _ ( ( weak _ import ) ) by the linker was added in 10 . 2 so ensure we \n + < ! - - support for _ _ attribute _ _ ( ( weak _ import ) ) by the linker was added in 10 . 2 ( but 10 . 6 is the minimum we can use on 10 . 14 ) so ensure we \n - < arg > MACOSX _ DEPLOYMENT _ TARGET = 10 . 2 < / arg > \n + < arg > MACOSX _ DEPLOYMENT _ TARGET = 10 . 6 < / arg > \n,Use MACOSX _ DEPLOYMENT _ TARGET = 10 . 6 when compile native transport on MacOS ( # 8379 ) \n Motivation : \n MACOSX _ DEPLOYMENT _ TARGET = 10 . 6 needs to be used as everything before is not supported in 10 . 14 anymore . 10 . 6 was released 2009 so this should be a safe thing to do . \n Modifications : \n Use MACOSX _ DEPLOYMENT _ TARGET = 10 . 6 \n Result : \n Be able to compile on MacOS 10 . 14,381
transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n - @ Test ( timeout = 1000 ) \n + @ Test ( timeout = 3000 ) \n,Increase test timeout ( # 8385 ) \n Motivation : \n It has shown that the used test timeout may be too low when the CI is busy . \n Modifications : \n Increase timeout to 3 seconds . \n Result : \n Less false - positives .,381
"docker \ docker - compose . yaml \n - command : / bin / bash - cl "" . / mvnw clean install - Dio . netty . testsuite . badHost = netty . io - Dtcnative . artifactId = netty - tcnative - boringssl - static "" \n + command : / bin / bash - cl "" . / mvnw clean install - Dio . netty . testsuite . badHost = netty . io - Dtcnative . artifactId = netty - tcnative - boringssl - static - Dtcnative . classifier = "" \n","When running our testsuite with netty - tcnative - boringssl - static we should use an empty classifier . ( # 8396 ) \n Motivation : \n We publish an "" uber - jar "" for netty - tcnative - boringssl - static so we should use it when testing against boringssl . \n Modifications : \n Ensure we use empty classifier . \n Result : \n Use uber - jar when testing",381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - SSL . freeSSL ( ssl ) ; \n + / / Call shutdown so we are sure we correctly release all native memory and also guard against the \n + / / case when shutdown ( ) will be called by the finalizer again . If we would call SSL . free ( . . . ) directly \n + / / the finalizer may end up calling it again as we would miss to update the DESTROYED _ UPDATER . \n + shutdown ( ) ; \n + \n,Ensure OpenSslEngine will not try to call SSL _ free multiple times even when constructor throws . ( # 8399 ) \n Motivation : \n When the constructor of OpenSslEngine threw we could end up to self call SSL _ free by ourself and then have the finalizer do the same which may lead to double free - ing and so SIGSEV . \n Modifications : \n Just call shutdown ( ) when the constructor throws and so ensure SSL _ free is guarded correctly in the finalizer . \n Result : \n No more SIGSEV possible .,381
pom . xml \n - < jetty . alpnAgent . version > 2 . 0 . 7 < / jetty . alpnAgent . version > \n + < jetty . alpnAgent . version > 2 . 0 . 8 < / jetty . alpnAgent . version > \n - server \n,Update jetty - alpn - agent version to support latest JDK 8 release . ( # 8402 ) \n Motivation : \n We need to update jetty - alpn - agent to be able to run tests with OpenJDK 8u191 \n Modifications : \n Update to 2 . 0 . 8 \n Result : \n Be able to run tests with latest JDK 8 release .,381
"docker \ docker - compose . centos - 6 . 110 . yaml \n - java _ version : "" 1 . 10 - 0 "" \n + java _ version : "" openjdk @ 1 . 10 . 0 - 2 "" \n docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 "" \n + java _ version : "" openjdk @ 1 . 11 . 0 - 1 "" \n docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 15 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" 1 . 8 "" \n + java _ version : "" 1 . 8 . 192 "" \n docker \ docker - compose . centos - 6 . 19 . yaml \n - java _ version : "" zulu @ 1 . 9 . 0 "" \n + java _ version : "" openjdk @ 1 . 9 . 0 - 4 "" \n docker \ docker - compose . centos - 7 . 110 . yaml \n - java _ version : "" 1 . 10 - 0 "" \n + java _ version : "" openjdk @ 1 . 10 . 0 - 2 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" 1 . 11 . 0 "" \n + java _ version : "" openjdk @ 1 . 11 . 0 - 1 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 15 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" 1 . 8 "" \n + java _ version : "" 1 . 8 . 192 "" \n docker \ docker - compose . centos - 7 . 19 . yaml \n - java _ version : "" zulu @ 1 . 9 . 0 "" \n + java _ version : "" openjdk @ 1 . 9 . 0 - 4 "" \n",Explicit specify java version to use to ensure we rebuild image when java version changes . ( # 8397 ) \n Motivation : \n We should explicit specify the java version to use to ensure docker will rebuild the image once a new java version was released and we specify it . Also we should use openjdk for testing when possible . \n Modifications : \n - Explicit specify the java versions to use \n - Use openjdk when possible . \n Result : \n Ensure latest java versions are used during testing,381
"docker \ docker - compose . yaml \n - command : / bin / bash - cl "" . / mvnw clean install - Dio . netty . testsuite . badHost = netty . io - Dtcnative . artifactId = netty - tcnative - boringssl - static - Dtcnative . classifier = "" \n + command : / bin / bash - cl "" . / mvnw clean install - Dio . netty . testsuite . badHost = netty . io - Dxml . skip = true - Dtcnative . artifactId = netty - tcnative - boringssl - static - Dtcnative . classifier = "" \n testsuite - shading \ pom . xml \n - < nativeTcnativeLib > netty _ tcnative . jnilib < / nativeTcnativeLib > \n + < condition property = "" nativeTcnativeLib "" value = "" netty _ tcnative _ osx _ $ { os . detected . arch } . jnilib "" else = "" netty _ tcnative . jnilib "" > \n + < equals arg1 = "" $ { tcnative . classifier } "" arg2 = "" "" / > \n + < / condition > \n + \n - < nativeTcnativeLib > netty _ tcnative . so < / nativeTcnativeLib > \n + < condition property = "" nativeTcnativeLib "" value = "" netty _ tcnative _ linux _ $ { os . detected . arch } . so "" else = "" netty _ tcnative . so "" > \n + < equals arg1 = "" $ { tcnative . classifier } "" arg2 = "" "" / > \n + < / condition > \n + \n",Fix broken testsuite - shading when using with netty - tcnative - boringssl - static ( # 8404 ) \n Motivation : \n 2109f14c24f90df3f43aee7f3248ac59e6088735 corrected how we run the testsuite with boringssl - static but missed to also adjust the testsuite - shading configuration which lead to test failures . \n Modifications : \n Correctly compose the native lib name when no classifier is used . \n Result : \n Testsuite passes again .,381
pom . xml \n - < version > 1 . 12 < / version > \n + < version > 1 . 18 < / version > \n,Upgrade commons - compress to 2 . 0 . 18 ( # 8416 ) \n Motivation : \n Commons - compress < 2 . 0 . 18 has a security flaw so we should upgrade ( even if we only use it in tests anyway ) . \n Modifications : \n Update to 2 . 0 . 18 \n Result : \n Use latest version .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 15 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 16 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 15 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 16 "" \n","Update to JDK 12 EA16 when running CI jobs against JDK 12 . ( # 8421 ) \n Motivation : \n A new EA release was done , we should always run against the latest . \n Modifications : \n Update to EA 16 . \n Result : \n CI runs with latest EA release for JDK12 .",381
"docker \ docker - compose . yaml \n - command : / bin / bash - cl "" . / mvnw clean install - Dio . netty . testsuite . badHost = netty . io - Dxml . skip = true - Dtcnative . artifactId = netty - tcnative - boringssl - static - Dtcnative . classifier = "" \n + command : / bin / bash - cl "" . / mvnw - P boringssl clean install - Dio . netty . testsuite . badHost = netty . io - Dxml . skip = true "" \n pom . xml \n + < profile > \n + < id > boringssl < / id > \n + < properties > \n + < tcnative . artifactId > netty - tcnative - boringssl - static < / tcnative . artifactId > \n + < tcnative . classifier / > \n + < / properties > \n + < / profile > \n",Add profile to easily run testsuite against netty - tcnative - boringssl - static ( # 8436 ) \n Motivation : \n We should provide an easy way to run our testsuite against netty - tcnative - boringssl - static \n Modifications : \n - Add boringssl profile which can be used to enable usage of netty - tcnative - boringssl - static \n - Make use of the profile in docker - compose \n Result : \n Cleaner and easier way of running testsuite against netty - tcnative - boringssl - static,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n + import java . util . ArrayList ; \n + import javax . net . ssl . SSLSocketFactory ; \n + @ Test \n + public void testInvalidCipher ( ) throws Exception { \n + SelfSignedCertificate cert = new SelfSignedCertificate ( ) ; \n + List < String > cipherList = new ArrayList < String > ( ) ; \n + Collections . addAll ( cipherList , ( ( SSLSocketFactory ) SSLSocketFactory . getDefault ( ) ) . getDefaultCipherSuites ( ) ) ; \n + cipherList . add ( "" InvalidCipher "" ) ; \n + SSLEngine server = null ; \n + try { \n + serverSslCtx = SslContextBuilder . forServer ( cert . key ( ) , cert . cert ( ) ) . sslProvider ( sslClientProvider ( ) ) \n + . ciphers ( cipherList ) . build ( ) ; \n + server = serverSslCtx . newEngine ( UnpooledByteBufAllocator . DEFAULT ) ; \n + fail ( ) ; \n + } catch ( IllegalArgumentException expected ) { \n + / / expected when invalid cipher is used . \n + } catch ( SSLException expected ) { \n + / / expected when invalid cipher is used . \n + } finally { \n + cert . delete ( ) ; \n + cleanupServerSslEngine ( server ) ; \n + } \n + } \n + \n","Add test to verify that invalid ciphers are handled in all SSLEngine implementations correctly . ( # 8443 ) \n Motivation : \n https : / / github . com / netty / netty / issues / 8442 reported that we fail to build a SslContext when an invalid cipher is used with netty - tcnative - boringssl - static , while it worked before . This test verifies that this is now consistent with all other SSLEngine implementations . \n Modifications : \n Add test - case to verify consistent behaviour \n Result : \n More tests to assert consistent behaviour across SSLEngine implementations",381
"transport - native - epoll \ src \ test \ java \ io \ netty \ channel \ epoll \ EpollTest . java \n - import org . junit . Assert ; \n + import io . netty . channel . unix . FileDescriptor ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n + import static org . junit . Assert . assertEquals ; \n + import static org . junit . Assert . assertNull ; \n + import static org . junit . Assert . assertTrue ; \n + \n - Assert . assertTrue ( Epoll . isAvailable ( ) ) ; \n + assertTrue ( Epoll . isAvailable ( ) ) ; \n + } \n + \n + / / Testcase for https : / / github . com / netty / netty / issues / 8444 \n + @ Test ( timeout = 5000 ) \n + public void testEpollWaitWithTimeOutMinusOne ( ) throws Exception { \n + final EpollEventArray eventArray = new EpollEventArray ( 8 ) ; \n + try { \n + final FileDescriptor epoll = Native . newEpollCreate ( ) ; \n + final FileDescriptor timerFd = Native . newTimerFd ( ) ; \n + final FileDescriptor eventfd = Native . newEventFd ( ) ; \n + Native . epollCtlAdd ( epoll . intValue ( ) , timerFd . intValue ( ) , Native . EPOLLIN ) ; \n + Native . epollCtlAdd ( epoll . intValue ( ) , eventfd . intValue ( ) , Native . EPOLLIN ) ; \n + \n + final AtomicReference < Throwable > ref = new AtomicReference < Throwable > ( ) ; \n + Thread t = new Thread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + try { \n + assertEquals ( 1 , Native . epollWait ( epoll , eventArray , timerFd , - 1 , - 1 ) ) ; \n + / / This should have been woken up because of eventfd _ write . \n + assertEquals ( eventfd . intValue ( ) , eventArray . fd ( 0 ) ) ; \n + } catch ( Throwable cause ) { \n + ref . set ( cause ) ; \n + } \n + } \n + } ) ; \n + t . start ( ) ; \n + t . join ( 1000 ) ; \n + assertTrue ( t . isAlive ( ) ) ; \n + Native . eventFdWrite ( eventfd . intValue ( ) , 1 ) ; \n + \n + t . join ( ) ; \n + assertNull ( ref . get ( ) ) ; \n + epoll . close ( ) ; \n + timerFd . close ( ) ; \n + eventfd . close ( ) ; \n + } finally { \n + eventArray . free ( ) ; \n + } \n",Add testcase for epollWait ( . . . ) with negative timerfd values . ( # 8447 ) \n Motivation : \n https : / / github . com / netty / netty / issues / 8444 reports that there is some issue with negative values passed to timerfd _ settime . This test verifies that everything is working as expected . \n Modifications : \n Add testcase . \n Result : \n Test to verify expected behaviour .,381
example \ src \ main \ java \ io \ netty \ example \ memcache \ binary \ MemcacheClientHandler . java \n + res . release ( ) ; \n,Correctly release message in MemcacheClientHandler that is used in the memcache example . ( # 8119 ) \n Motivation : \n MemcacheClientHandler . channelRead ( . . . ) need to release the frame after it prints out its content to not introduce a memory leak . \n Modifications : \n Call release ( ) on the frame . \n Result : \n Example has no leak any more .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelHandler . java \n - * { @ link Channel } ch = e . getChannel ( ) ; \n - * ch . write ( fetchSecret ( ( GetDataMessage ) message ) ) ; \n + * ctx . writeAndFlush ( fetchSecret ( ( GetDataMessage ) message ) ) ; \n - * { @ link Channel } ch = ctx . channel ( ) ; \n - * ch . write ( fetchSecret ( ( GetDataMessage ) o ) ) ; \n + * ctx . writeAndFlush ( fetchSecret ( ( GetDataMessage ) o ) ) ; \n,Fix incorrect code in javadocs of ChannelHandler . ( # 8115 ) \n Motivation : \n Some code that was shown as part of the ChannelHandler javadoc was not 100 % correct and used some constructs that we used in netty 3 . Also we never called flush ( ) in the code which is a bad example for users . \n Modifications : \n - Remove netty 3 code references \n - Replace channel . write ( . . . ) with ctx . writeAndFlush ( . . . ) \n Result : \n More correct code in the javadocs .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ logging \ InternalLoggerFactory . java \n - } catch ( Throwable t1 ) { \n + } catch ( Throwable ignore1 ) { \n - } catch ( Throwable t2 ) { \n - f = JdkLoggerFactory . INSTANCE ; \n - f . newInstance ( name ) . debug ( "" Using java . util . logging as the default logging framework "" ) ; \n + } catch ( Throwable ignore2 ) { \n + try { \n + f = Log4J2LoggerFactory . INSTANCE ; \n + f . newInstance ( name ) . debug ( "" Using Log4J2 as the default logging framework "" ) ; \n + } catch ( Throwable ignore3 ) { \n + f = JdkLoggerFactory . INSTANCE ; \n + f . newInstance ( name ) . debug ( "" Using java . util . logging as the default logging framework "" ) ; \n + } \n",Auto - detect Log4J2 for logging if on the class - path ( # 8109 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 5047 added Log4J2 support but missed to add code to try to auto - detect it . \n Modifications : \n Try to use Log4JLoggerFactory by default . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8107 .,381
"common \ src \ main \ java \ io \ netty \ util \ AsciiString . java \n - final int len = offset + start + length ; \n + final int len = offset + length ; \n common \ src \ test \ java \ io \ netty \ util \ AsciiStringCharacterTest . java \n + \n + @ Test \n + public void testIndexOf ( ) { \n + AsciiString foo = AsciiString . of ( "" This is a test "" ) ; \n + int i1 = foo . indexOf ( ' ' , 0 ) ; \n + assertEquals ( 4 , i1 ) ; \n + int i2 = foo . indexOf ( ' ' , i1 + 1 ) ; \n + assertEquals ( 7 , i2 ) ; \n + int i3 = foo . indexOf ( ' ' , i2 + 1 ) ; \n + assertEquals ( 9 , i3 ) ; \n + assertTrue ( i3 + 1 < foo . length ( ) ) ; \n + int i4 = foo . indexOf ( ' ' , i3 + 1 ) ; \n + assertEquals ( i4 , - 1 ) ; \n + } \n",Fix length calculation in AsciiString . indexOf ( . . . ) and so eliminate ArrayIndexOutOfBoundsException . ( # 8116 ) \n Motivation : \n We incorrectly calculated the length that was used for our for loop in AsciiString . indexOf ( . . . ) . This lead to a possible ArrayIndexOutOfBoundsException . \n Modifications : \n - Not include the start in the length calculation \n - Add unit test . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8112 .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n - final DatagramChannel ch ; \n + final Channel ch ; \n - ch = ( DatagramChannel ) b . register ( ) . channel ( ) ; \n + ChannelFuture future = b . register ( ) ; \n + Throwable cause = future . cause ( ) ; \n + if ( cause ! = null ) { \n + if ( cause instanceof RuntimeException ) { \n + throw ( RuntimeException ) cause ; \n + } \n + if ( cause instanceof Error ) { \n + throw ( Error ) cause ; \n + } \n + throw new IllegalStateException ( "" Unable to create / register Channel "" , cause ) ; \n + } \n + ch = future . channel ( ) ; \n resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DnsNameResolverTest . java \n + \n + @ Test \n + public void testChannelFactoryException ( ) { \n + final IllegalStateException exception = new IllegalStateException ( ) ; \n + try { \n + newResolver ( ) . channelFactory ( new ChannelFactory < DatagramChannel > ( ) { \n + @ Override \n + public DatagramChannel newChannel ( ) { \n + throw exception ; \n + } \n + } ) . build ( ) ; \n + fail ( ) ; \n + } catch ( Exception e ) { \n + assertSame ( exception , e ) ; \n + } \n + } \n",Don ' t cause ClassCastException if registration fails during constructing DnsNameResolver . ( # 8280 ) \n Motivation : \n We should not try to cast the Channel to a DatagramChannel as this will cause a ClassCastException . \n Modifications : \n - Do not cast \n - rethrow from constructor if we detect the registration failed . \n - Add unit test . \n Result : \n Propagate correct exception .,381
"testsuite - shading \ src \ test \ java \ io \ netty \ testsuite \ shading \ ShadingIT . java \n - import org . junit . Ignore ; \n - @ Ignore ( "" Figure out why this sometimes fail on the CI "" ) \n",Enable netty - tcnative shading test again ( # 8492 ) \n Motivation : \n We disabled the test at some point but it should work now without any problems . \n Modifications : \n Remove @ Ignore from test . \n Result : \n Verify shading of netty - tcnative on CI .,381
"common \ src \ main \ java \ io \ netty \ util \ concurrent \ SingleThreadEventExecutor . java \n - if ( isShutdown ( ) & & removeTask ( task ) ) { \n - reject ( ) ; \n + if ( isShutdown ( ) ) { \n + boolean reject = false ; \n + try { \n + if ( removeTask ( task ) ) { \n + reject = true ; \n + } \n + } catch ( UnsupportedOperationException e ) { \n + / / The task queue does not support removal so the best thing we can do is to just move on and \n + / / hope we will be able to pick - up the task before its completely terminated . \n + / / In worst case we will log on termination . \n + } \n + if ( reject ) { \n + reject ( ) ; \n + } \n transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n + import org . hamcrest . core . IsInstanceOf ; \n + import java . util . concurrent . RejectedExecutionException ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n + @ SuppressWarnings ( "" deprecation "" ) \n + @ Test \n + public void testTaskRemovalOnShutdownThrowsNoUnsupportedOperationException ( ) throws Exception { \n + final AtomicReference < Throwable > error = new AtomicReference < Throwable > ( ) ; \n + final Runnable task = new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + / / NOOP \n + } \n + } ; \n + / / Just run often enough to trigger it normally . \n + for ( int i = 0 ; i < 1000 ; i + + ) { \n + NioEventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + final NioEventLoop loop = ( NioEventLoop ) group . next ( ) ; \n + \n + Thread t = new Thread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + try { \n + for ( ; ; ) { \n + loop . execute ( task ) ; \n + } \n + } catch ( Throwable cause ) { \n + error . set ( cause ) ; \n + } \n + } \n + } ) ; \n + t . start ( ) ; \n + group . shutdownNow ( ) ; \n + t . join ( ) ; \n + group . terminationFuture ( ) . syncUninterruptibly ( ) ; \n + assertThat ( error . get ( ) , IsInstanceOf . instanceOf ( RejectedExecutionException . class ) ) ; \n + error . set ( null ) ; \n + } \n + } \n + \n","Nio | Epoll | KqueueEventLoop task execution might throw UnsupportedOperationException on shutdown . ( # 8476 ) \n Motivation : \n There is a racy UnsupportedOperationException instead because the task removal is delegated to MpscChunkedArrayQueue that does not support removal . This happens with SingleThreadEventExecutor that overrides the newTaskQueue to return an MPSC queue instead of the LinkedBlockingQueue returned by the base class such as NioEventLoop , EpollEventLoop and KQueueEventLoop . \n Modifications : \n - Catch the UnsupportedOperationException \n - Add unit test . \n Result : \n Fix # 8475",381
pom . xml \n - < tcnative . version > 2 . 0 . 19 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 20 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 20 . Final ( # 8561 ) \n Motivation : \n Update to netty - tcnative 2 . 0 . 20 . Final which fixed a bug related to retrieving the remote signature algorithms when using BoringSSL . \n Modifications : \n Update netty - tcnative \n Result : \n Be able to correctly detect the remote signature algorithms when using BoringSSL .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - Lock readerLock = ctxLock . readLock ( ) ; \n - readerLock . lock ( ) ; \n - try { \n - return ctx ; \n - } finally { \n - readerLock . unlock ( ) ; \n - } \n + return sslCtxPointer ( ) ; \n - return ctx ; \n + return SSLContext . getSslCtx ( ctx ) ; \n,Return the correct pointer from ReferenceCountedOpenSslContext . context ( ) and sslCtxPointer ( ) ( # 8562 ) \n Motivation : \n We did not return the pointer to SSL _ CTX put to the internal datastructure of tcnative . \n Modifications : \n Return the correct pointer . \n Result : \n Methods work as documented in the javadocs .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsServerAddressStreamProviders . java \n + import java . util . concurrent . TimeUnit ; \n + import java . util . concurrent . atomic . AtomicLong ; \n + \n + / / We use 5 minutes which is the same as what OpenJDK is using in sun . net . dns . ResolverConfigurationImpl . \n + private static final long REFRESH _ INTERVAL = TimeUnit . MINUTES . toNanos ( 5 ) ; \n + \n + new DnsServerAddressStreamProvider ( ) { \n + private volatile DnsServerAddressStreamProvider currentProvider = provider ( ) ; \n + private final AtomicLong lastRefresh = new AtomicLong ( System . nanoTime ( ) ) ; \n + \n + @ Override \n + public DnsServerAddressStream nameServerAddressStream ( String hostname ) { \n + long last = lastRefresh . get ( ) ; \n + DnsServerAddressStreamProvider current = currentProvider ; \n + if ( System . nanoTime ( ) - last > REFRESH _ INTERVAL ) { \n + / / This is slightly racy which means it will be possible still use the old configuration for a small \n + / / amount of time , but that ' s ok . \n + if ( lastRefresh . compareAndSet ( last , System . nanoTime ( ) ) ) { \n + current = currentProvider = provider ( ) ; \n + } \n + } \n + return current . nameServerAddressStream ( hostname ) ; \n + } \n + \n + private DnsServerAddressStreamProvider provider ( ) { \n - PlatformDependent . isWindows ( ) ? DefaultDnsServerAddressStreamProvider . INSTANCE : \n + return PlatformDependent . isWindows ( ) ? DefaultDnsServerAddressStreamProvider . INSTANCE : \n + } \n + } ; \n",Refresh DNS configuration each 5 minutes . ( # 8468 ) \n Motivation : \n We should refresh the DNS configuration each 5 minutes to be able to detect changes done by the user . This is inline with what OpenJDK is doing \n Modifications : \n Refresh config every 5 minutes . \n Result : \n Be able to consume changes made by the user .,381
"transport \ src \ main \ java \ io \ netty \ channel \ nio \ NioEventLoop . java \n - switch ( selectStrategy . calculateStrategy ( selectNowSupplier , hasTasks ( ) ) ) { \n + try { \n + switch ( selectStrategy . calculateStrategy ( selectNowSupplier , hasTasks ( ) ) ) { \n + } \n + } catch ( IOException e ) { \n + / / If we receive an IOException here its because the Selector is messed up . Let ' s rebuild \n + / / the selector and retry . https : / / github . com / netty / netty / issues / 8566 \n + rebuildSelector0 ( ) ; \n + handleLoopException ( e ) ; \n + continue ; \n transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n + import io . netty . channel . SelectStrategy ; \n + import io . netty . channel . SelectStrategyFactory ; \n + import io . netty . util . IntSupplier ; \n + import io . netty . util . concurrent . DefaultThreadFactory ; \n + import java . io . IOException ; \n + import java . nio . channels . spi . SelectorProvider ; \n + @ Test \n + public void testRebuildSelectorOnIOException ( ) { \n + SelectStrategyFactory selectStrategyFactory = new SelectStrategyFactory ( ) { \n + @ Override \n + public SelectStrategy newSelectStrategy ( ) { \n + return new SelectStrategy ( ) { \n + \n + private boolean thrown ; \n + \n + @ Override \n + public int calculateStrategy ( IntSupplier selectSupplier , boolean hasTasks ) throws Exception { \n + if ( ! thrown ) { \n + thrown = true ; \n + throw new IOException ( ) ; \n + } \n + return - 1 ; \n + } \n + } ; \n + } \n + } ; \n + \n + EventLoopGroup group = new NioEventLoopGroup ( 1 , new DefaultThreadFactory ( "" ioPool "" ) , \n + SelectorProvider . provider ( ) , selectStrategyFactory ) ; \n + final NioEventLoop loop = ( NioEventLoop ) group . next ( ) ; \n + try { \n + Channel channel = new NioServerSocketChannel ( ) ; \n + Selector selector = loop . unwrappedSelector ( ) ; \n + \n + loop . register ( channel ) . syncUninterruptibly ( ) ; \n + \n + Selector newSelector = ( ( NioEventLoop ) channel . eventLoop ( ) ) . unwrappedSelector ( ) ; \n + assertTrue ( newSelector . isOpen ( ) ) ; \n + assertNotSame ( selector , newSelector ) ; \n + assertFalse ( selector . isOpen ( ) ) ; \n + \n + channel . close ( ) . syncUninterruptibly ( ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n + \n",Recover from Selector IOException ( # 8569 ) \n Motivation : \n When the Selector throws an IOException during our EventLoop processing we should rebuild it and transfer the registered Channels . At the moment we will continue trying to use it which will never work . \n Modifications : \n - Rebuild Selector when an IOException is thrown during any select * ( . . . ) methods . \n - Add unit test . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8566 .,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniClientJava8TestUtil . java \n - import java . util . Arrays ; \n - if ( session instanceof OpenSslSession & & OpenSsl . isBoringSSL ( ) ) { \n - / / BoringSSL does not support SSL _ get _ sigalgs ( . . . ) \n - / / https : / / boringssl . googlesource . com / boringssl / + / ba16a1e405c617f4179bd780ad15522fb25b0a65 % 5E % 21 / \n - Assert . assertEquals ( 0 , extendedSSLSession . getPeerSupportedSignatureAlgorithms ( ) . length ) ; \n - } else { \n - Assert . assertTrue ( extendedSSLSession . getPeerSupportedSignatureAlgorithms ( ) . length > 0 ) ; \n - } \n + Assert . assertTrue ( extendedSSLSession . getPeerSupportedSignatureAlgorithms ( ) . length > = 0 ) ; \n",Fix test that assumed detection of peer supported algs is not supported in BoringSSL . ( # 8573 ) \n Motivation : \n 0d2e38d5d6db6ed1abdf901230fa524c0f8db14c added supported for detection of peer supported algorithms but we missed to fix the testcase . \n Modifications : \n Fix test - case . \n Result : \n No more failing tests with BoringSSL .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelDuplexHandler . java \n - * Calls { @ link ChannelHandlerContext # close ( ChannelPromise ) } to forward \n + * Calls { @ link ChannelHandlerContext # deregister ( ChannelPromise ) } to forward \n,Fix javadoc to correctly explain how ChannelDuplexHandler . deregister ( . . . ) works . ( # 8577 ) \n Motivation : \n We had an error in the javadoc which was most likely caused by copy and paste . \n Modifications : \n Fix javadoc . \n Result : \n Correct javadoc .,381
"example \ src \ main \ java \ io \ netty \ example \ http \ websocketx \ server \ WebSocketFrameHandler . java \n - import org . slf4j . Logger ; \n - import org . slf4j . LoggerFactory ; \n - private static final Logger logger = LoggerFactory . getLogger ( WebSocketFrameHandler . class ) ; \n - \n - logger . info ( "" { } received { } "" , ctx . channel ( ) , request ) ; \n",Remove transitive dependency on slf4j in example ( # 8582 ) \n Motivation : \n We currently depend on slf4j in an transitive way in one of our classes in the examples . We should not do this . \n Modifications : \n Remove logging in example . \n Result : \n Remove not needed dependency .,381
transport - sctp \ src \ main \ java \ io \ netty \ channel \ sctp \ oio \ package - info . java \n - @ Deprecated \n transport \ src \ main \ java \ io \ netty \ channel \ oio \ package - info . java \n - @ Deprecated \n transport \ src \ main \ java \ io \ netty \ channel \ socket \ oio \ package - info . java \n - @ Deprecated \n,Remove @ Deprecated from package - info . java file ( # 8591 ) \n Motivation : \n 31fd66b617dd6ea5a851e80338263f2866cb4c3d added @ Deprecated to some classes but also to the package - info . java files . IntelliJ does not like to have these annotations on package - info . java \n Modifications : \n Remove annotation from package - info . java \n Result : \n Be able to compile against via IntelliJ,381
"transport \ src \ main \ java \ io \ netty \ channel \ DefaultChannelPipeline . java \n - super ( pipeline , null , HEAD _ NAME , false , true ) ; \n + super ( pipeline , null , HEAD _ NAME , true , true ) ; \n",HeadContext is inbound and outbound ( # 8592 ) \n Motivation : \n Our HeadContext in DefaultChannelPipeline does handle inbound and outbound but we only marked it as outbound . While this does not have any effect in the current code - base it can lead to problems when we change our internals ( this is also how I found the bug ) . \n Modifications : \n Construct HeadContext so it is also marked as handling inbound . \n Result : \n More correct code .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n - for ( ; ; ) { \n - long usedMemory = DIRECT _ MEMORY _ COUNTER . get ( ) ; \n - long newUsedMemory = usedMemory + capacity ; \n - if ( newUsedMemory > DIRECT _ MEMORY _ LIMIT ) { \n - throw new OutOfDirectMemoryError ( "" failed to allocate "" + capacity \n - + "" byte ( s ) of direct memory ( used : "" + usedMemory + "" , max : "" + DIRECT _ MEMORY _ LIMIT + ' ) ' ) ; \n - } \n - if ( DIRECT _ MEMORY _ COUNTER . compareAndSet ( usedMemory , newUsedMemory ) ) { \n - break ; \n - } \n + long newUsedMemory = DIRECT _ MEMORY _ COUNTER . addAndGet ( capacity ) ; \n + if ( newUsedMemory > DIRECT _ MEMORY _ LIMIT ) { \n + DIRECT _ MEMORY _ COUNTER . addAndGet ( - capacity ) ; \n + throw new OutOfDirectMemoryError ( "" failed to allocate "" + capacity \n + + "" byte ( s ) of direct memory ( used : "" + ( newUsedMemory - capacity ) \n + + "" , max : "" + DIRECT _ MEMORY _ LIMIT + ' ) ' ) ; \n","Use addAndGet ( . . . ) as a replacement for compareAndSet ( . . . ) when tracking the direct memory usage . ( # 8596 ) \n Motivation : \n We can change from using compareAndSet to addAndGet , which emits a different CPU instruction on x86 ( CMPXCHG to XADD ) when count direct memory usage . This instruction is cheaper in general and so produce less overhead on the "" happy path "" . If we detect too much memory usage we just rollback the change before throwing the Error . \n Modifications : \n Replace compareAndSet ( . . . ) with addAndGet ( . . . ) \n Result : \n Less overhead when tracking direct memory .",381
pom . xml \n + < ! - - 1 . 4 . x does not work in Java10 + - - > \n + < jboss . marshalling . version > 2 . 0 . 5 . Final < / jboss . marshalling . version > \n - < jboss . marshalling . version > 2 . 0 . 5 . Final < / jboss . marshalling . version > \n + < jboss . marshalling . version > 1 . 4 . 11 . Final < / jboss . marshalling . version > \n,Only use jboss - marshalling when using Java 10 ( # 7929 ) \n Motivation : \n cff87de44cfaa4544360715dc83e5ad1aa2c0bd7 updated jboss - marshalling to 2 . 0 . 5 . Final but this broke the ability to run tests with Java 7 . \n Modifications : \n Only use 2 . 0 . 5 . Final if compiled against Java 10 ( as before 1 . 4 . x works fine ) . \n Result : \n Be able to run tests with Java 7 on the CI .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ UnixResolverDnsServerAddressStreamProvider . java \n - import java . util . Arrays ; \n + import java . util . regex . Pattern ; \n + private static final Pattern SEARCH _ DOMAIN _ PATTERN = Pattern . compile ( "" \ \ s + "" ) ; \n - searchDomains . add ( line . substring ( i ) ) ; \n + / / May contain more then one entry , either seperated by whitespace or tab . \n + / / See https : / / linux . die . net / man / 5 / resolver \n + String [ ] domains = SEARCH _ DOMAIN _ PATTERN . split ( line . substring ( i ) ) ; \n + Collections . addAll ( searchDomains , domains ) ; \n resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ UnixResolverDnsServerAddressStreamProviderTest . java \n + @ Test \n + public void searchDomainsWithMultipleSearchSeperatedByWhitespace ( ) throws IOException { \n + File f = buildFile ( "" search linecorp . local squarecorp . local \ n "" + \n + "" nameserver 127 . 0 . 0 . 2 \ n "" ) ; \n + List < String > domains = UnixResolverDnsServerAddressStreamProvider . parseEtcResolverSearchDomains ( f ) ; \n + assertEquals ( Arrays . asList ( "" linecorp . local "" , "" squarecorp . local "" ) , domains ) ; \n + } \n + \n + @ Test \n + public void searchDomainsWithMultipleSearchSeperatedByTab ( ) throws IOException { \n + File f = buildFile ( "" search linecorp . local \ tsquarecorp . local \ n "" + \n + "" nameserver 127 . 0 . 0 . 2 \ n "" ) ; \n + List < String > domains = UnixResolverDnsServerAddressStreamProvider . parseEtcResolverSearchDomains ( f ) ; \n + assertEquals ( Arrays . asList ( "" linecorp . local "" , "" squarecorp . local "" ) , domains ) ; \n + } \n + \n",Correctly parse / etc / resolv . conf when contain multiple entries for searchdomain . ( # 8351 ) \n Motivation : \n ba594bcf4a62c47810f85c6d28e87367c6903ed4 added a utility to parse searchdomains defined in / etc / resolv . conf but did not correctly handle the case when multiple are defined that are seperated by either whitespace or tab . \n Modifications : \n - Correctly parse multiple entries \n - Add unit test . \n Result : \n Correctly parse multiple searchdomain entries .,381
testsuite - shading \ pom . xml \n + < profile > \n + < id > windows < / id > \n + < activation > \n + < os > \n + < family > windows < / family > \n + < / os > \n + < / activation > \n + < dependencies > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - common < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < / dependency > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - handler < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < / dependency > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > $ { tcnative . artifactId } < / artifactId > \n + < version > $ { tcnative . version } < / version > \n + < classifier > $ { tcnative . classifier } < / classifier > \n + < scope > compile < / scope > \n + < / dependency > \n + < / dependencies > \n + < / profile > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - common < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < / dependency > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - common < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < / dependency > \n testsuite - shading \ src \ test \ java \ io \ netty \ testsuite \ shading \ ShadingIT . java \n + import org . junit . Assume ; \n + / / Skip on windows . \n + Assume . assumeFalse ( PlatformDependent . isWindows ( ) ) ; \n + \n + / / Skip on windows . \n + Assume . assumeFalse ( PlatformDependent . isWindows ( ) ) ; \n + \n,Include correct dependencies for testsuite - shading on windows . ( # 8491 ) \n Motivation : \n We missed to include a profile for windows which means that we did not have the correct dependencies setup . \n Modifications : \n - Add missing profile \n - Add assumeFalse ( . . . ) to ensure we do only test the native transpot shading on non windows platforms . \n - Explicit specify dependency on netty - common \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8489 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - Map < String , Object > values = this . values ; \n - if ( values = = null ) { \n - / / Use size of 2 to keep the memory overhead small \n - values = this . values = new HashMap < String , Object > ( 2 ) ; \n + final Object old ; \n + synchronized ( this ) { \n + Map < String , Object > values = this . values ; \n + if ( values = = null ) { \n + / / Use size of 2 to keep the memory overhead small \n + values = this . values = new HashMap < String , Object > ( 2 ) ; \n + } \n + old = values . put ( name , value ) ; \n - Object old = values . put ( name , value ) ; \n + \n - if ( values = = null ) { \n - return null ; \n + synchronized ( this ) { \n + if ( values = = null ) { \n + return null ; \n + } \n + return values . get ( name ) ; \n - return values . get ( name ) ; \n - Map < String , Object > values = this . values ; \n - if ( values = = null ) { \n - return ; \n + \n + final Object old ; \n + synchronized ( this ) { \n + Map < String , Object > values = this . values ; \n + if ( values = = null ) { \n + return ; \n + } \n + old = values . remove ( name ) ; \n - Object old = values . remove ( name ) ; \n + \n - Map < String , Object > values = this . values ; \n - if ( values = = null | | values . isEmpty ( ) ) { \n - return EmptyArrays . EMPTY _ STRINGS ; \n + synchronized ( this ) { \n + Map < String , Object > values = this . values ; \n + if ( values = = null | | values . isEmpty ( ) ) { \n + return EmptyArrays . EMPTY _ STRINGS ; \n + } \n + return values . keySet ( ) . toArray ( new String [ 0 ] ) ; \n - return values . keySet ( ) . toArray ( new String [ 0 ] ) ; \n",SSLSession . putValue / getValue / removeValue / getValueNames must be thread - safe . ( # 8648 ) \n Motivation : \n SSLSession . putValue / getValue / removeValue / getValueNames must be thread - safe as it may be called from multiple threads . This is also the case in the OpenJDK implementation . \n Modifications : \n Guard with synchronized ( this ) blocks to keep the memory overhead low as we do not expect to have these called frequently . \n Result : \n SSLSession implementation is thread - safe .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2ConnectionHandler . java \n - void channelReadComplete0 ( ChannelHandlerContext ctx ) throws Exception { \n - super . channelReadComplete ( ctx ) ; \n + final void channelReadComplete0 ( ChannelHandlerContext ctx ) { \n + / / Discard bytes of the cumulation buffer if needed . \n + discardSomeReadBytes ( ) ; \n + \n + / / Ensure we never stale the HTTP / 2 Channel . Flow - control is enforced by HTTP / 2 . \n + / / \n + / / See https : / / tools . ietf . org / html / rfc7540 # section - 5 . 2 . 2 \n + if ( ! ctx . channel ( ) . config ( ) . isAutoRead ( ) ) { \n + ctx . read ( ) ; \n + } \n + \n + ctx . fireChannelReadComplete ( ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2ConnectionHandlerTest . java \n + import io . netty . channel . ChannelMetadata ; \n + import io . netty . channel . DefaultChannelConfig ; \n + \n + when ( channel . metadata ( ) ) . thenReturn ( new ChannelMetadata ( false ) ) ; \n + DefaultChannelConfig config = new DefaultChannelConfig ( channel ) ; \n + when ( channel . config ( ) ) . thenReturn ( config ) ; \n + \n + @ Test \n + public void channelReadCompleteCallsReadWhenAutoReadFalse ( ) throws Exception { \n + channel . config ( ) . setAutoRead ( false ) ; \n + handler = newHandler ( ) ; \n + handler . channelReadComplete ( ctx ) ; \n + verify ( ctx , times ( 1 ) ) . read ( ) ; \n + } \n + \n",Explict always call ctx . read ( ) when AUTO _ READ is false and HTTP / 2 is used . ( # 8647 ) \n Motivation : \n We should always call ctx . read ( ) even when AUTO _ READ is false as flow - control is enforced by the HTTP / 2 protocol . \n See also https : / / tools . ietf . org / html / rfc7540 # section - 5 . 2 . 2 . \n We already did this before but not explicit and only did so because of some implementation details of ByteToMessageDecoder . It ' s better to be explicit here to not risk of breakage later on . \n Modifications : \n - Ensure we always call ctx . read ( ) when AUTO _ READ is false \n - Add unit test . \n Result : \n No risk of staling the connection when HTTP / 2 is used .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ JdkOpenSslEngineInteroptTest . java \n + @ Override \n + @ Test \n + public void testSessionAfterHandshakeKeyManagerFactoryMutualAuth ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSessionAfterHandshakeKeyManagerFactoryMutualAuth ( ) ; \n + } \n + \n + @ Override \n + @ Test \n + public void testSessionAfterHandshakeKeyManagerFactory ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSessionAfterHandshakeKeyManagerFactory ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslJdkSslEngineInteroptTest . java \n + @ Override \n + @ Test \n + public void testSessionAfterHandshakeKeyManagerFactoryMutualAuth ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSessionAfterHandshakeKeyManagerFactoryMutualAuth ( ) ; \n + } \n + \n,Skip tests that use KeyManagerFactory if not supported by OpenSSL version / flavor ( # 8662 ) \n Motivation : \n We missed to skip a few tests that depend on the KeyManagerFactory if the used OpenSSL version / flavor not support it . \n Modifications : \n Add missing overrides . \n Result : \n Testsuite also passes for example when using LibreSSL .,381
testsuite - autobahn \ pom . xml \n + < dependencies > \n + < dependency > \n + < groupId > org . python < / groupId > \n + < artifactId > jython - standalone < / artifactId > \n + < version > 2 . 7 . 1 < / version > \n + < / dependency > \n + < / dependencies > \n,"Update to latest stable jython release ( # 8667 ) \n Motivation : \n Using the latest jython release fixes some noise that is produced by an exception that is thrown when jython is terminated . \n Exception in thread "" Jython - Netty - Client - 4 "" Exception in thread "" Jython - Netty - Client - 7 "" Exception in thread "" Jython - Netty - Client - 5 "" java . lang . NoClassDefFoundError : org / python / netty / util / concurrent / DefaultPromise $ 2 \n at org . python . netty . util . concurrent . DefaultPromise . notifyListeners ( DefaultPromise . java : 589 ) \n at org . python . netty . util . concurrent . DefaultPromise . setSuccess ( DefaultPromise . java : 397 ) \n at org . python . netty . util . concurrent . SingleThreadEventExecutor $ 2 . run ( SingleThreadEventExecutor . java : 151 ) \n at java . lang . Thread . run ( Thread . java : 748 ) \n Exception in thread "" Jython - Netty - Client - 8 "" java . lang . NoClassDefFoundError : org / python / netty / util / concurrent / DefaultPromise $ 2 \n at org . python . netty . util . concurrent . DefaultPromise . notifyListeners ( DefaultPromise . java : 589 ) \n at org . python . netty . util . concurrent . DefaultPromise . setSuccess ( DefaultPromise . java : 397 ) \n at org . python . netty . util . concurrent . SingleThreadEventExecutor $ 2 . run ( SingleThreadEventExecutor . java : 151 ) \n at java . lang . Thread . run ( Thread . java : 748 ) \n Exception in thread "" Jython - Netty - Client - 3 "" java . lang . NoClassDefFoundError : org / python / netty / util / concurrent / DefaultPromise $ 2 \n at org . python . netty . util . concurrent . DefaultPromise . notifyListeners ( DefaultPromise . java : 589 ) \n at org . python . netty . util . concurrent . DefaultPromise . setSuccess ( DefaultPromise . java : 397 ) % \n Modification : \n Update to latest stable release . \n Result : \n Less noise during build .",381
testsuite - autobahn \ pom . xml \n - < version > 0 . 1 . 4 < / version > \n + < version > 0 . 1 . 5 < / version > \n,Upgrade to new version of autobahntestsuite maven plugin . ( # 8668 ) \n Motivation : \n A new version was released that fixes a few test - cases to allow more close codes . \n Modifications : \n Upgrade to 0 . 1 . 5 \n Result : \n More compliant testing of websockets .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 22 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 24 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 22 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 24 "" \n",Update to use OpenJDK 12 EA24 when building with Java 12 ( # 8672 ) \n Motivation : \n A new EA build was released for Java 12 . \n Modifications : \n Update to OpenJDK 12 EA24 \n Result : \n Use latest OpenJDK 12 build when building with Java 12,381
common \ src \ main \ java \ io \ netty \ util \ concurrent \ SingleThreadEventExecutor . java \n + / / Lets remove all FastThreadLocals for the Thread as we are about to terminate and notify \n + / / the future . The user may block on the future and once it unblocks the JVM may terminate \n + / / and start unloading classes . \n + / / See https : / / github . com / netty / netty / issues / 6596 . \n + FastThreadLocal . removeAll ( ) ; \n + \n - \n,Call FastThreadLocal . removeAll ( ) before notify termination future of … ( # 8666 ) \n Motivation : \n We should try removing all FastThreadLocals for the Thread before we notify the termination . future . The user may block on the future and once it unblocks the JVM may terminate and start unloading classes . \n Modifications : \n Remove all FastThreadLocals for the Thread before notify termination future . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 6596 .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelHandlerAdapter . java \n + * \n + * @ deprecated is part of { @ link ChannelInboundHandler } \n + @ Deprecated \n,Mark ChannelHandlerAdapter . exceptionCaught ( . . . ) as @ deprecated . ( # 8826 ) \n Motivation : \n 41e03adf249ee9d23938fecf9be980a096710b36 marked ChannelHandler . exceptionCaught ( . . . ) as @ deprecated but missed to also mark ChannelHandlerAdapter . exceptionCaught ( . . . ) as @ deprecated . We should do so as most people extend the base classes and not implement the interfaces directly . \n Modifications : \n Mark ChannelHandlerAdapter . exceptionCaught ( . . . ) as @ deprecated as well . \n Result : \n Mark method as @ deprecated to warn users about its removal .,381
"buffer \ src \ test \ java \ io \ netty \ buffer \ PooledByteBufAllocatorTest . java \n + / / First mark all AllocationThreads to complete their work and then wait until these are complete \n + / / and rethrow if there was any error . \n - t . finish ( ) ; \n + t . markAsFinished ( ) ; \n + } \n + \n + for ( AllocationThread t : threads ) { \n + t . joinAndCheckForError ( ) ; \n - public boolean isFinished ( ) { \n + boolean isFinished ( ) { \n - public void finish ( ) throws Throwable { \n + void markAsFinished ( ) { \n + finish . compareAndSet ( null , Boolean . TRUE ) ; \n + } \n + \n + void joinAndCheckForError ( ) throws Throwable { \n - finish . compareAndSet ( null , Boolean . TRUE ) ; \n - public void checkForError ( ) throws Throwable { \n + void checkForError ( ) throws Throwable { \n common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + private static final boolean IS _ J9 _ JVM = isJ9Jvm0 ( ) ; \n + / * * \n + * Returns { @ code true } if the running JVM is either < a href = "" https : / / developer . ibm . com / javasdk / "" > IBM J9 < / a > or \n + * < a href = "" https : / / www . eclipse . org / openj9 / "" > Eclipse OpenJ9 < / a > , { @ code false } otherwise . \n + * / \n + public static boolean isJ9Jvm ( ) { \n + return IS _ J9 _ JVM ; \n + } \n + \n + private static boolean isJ9Jvm0 ( ) { \n + String vmName = SystemPropertyUtil . get ( "" java . vm . name "" , "" "" ) . toLowerCase ( ) ; \n + return vmName . startsWith ( "" ibm j9 "" ) | | vmName . startsWith ( "" eclipse openj9 "" ) ; \n + } \n + \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ udt \ UDTClientServerConnectionTest . java \n + import io . netty . util . internal . PlatformDependent ; \n + import org . junit . Assume ; \n + Assume . assumeFalse ( "" Not supported on J9 JVM "" , PlatformDependent . isJ9Jvm ( ) ) ; \n + \n",Adjust tests to be able to build / test when using IBM J9 / OpenJ9 ( # 8900 ) \n Motivation : \n We should run a CI job using J9 to ensure netty also works when using different JVMs . \n Modifications : \n - Adjust PooledByteBufAllocatorTest to be able to complete faster when using a JVM which takes longer when joining Threads ( this seems to be the case with J9 ) . \n - Skip UDT tests on J9 as UDT is not supported there . \n Result : \n Be able to run CI against J9 .,381
"new file \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - openj9 - 1 . 11 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 2 "" \n + \n + test : \n + image : netty : centos - 6 - openj9 - 1 . 11 \n + \n + test - leak : \n + image : netty : centos - 6 - openj9 - 1 . 11 \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - openj9 - 1 . 11 \n + \n + shell : \n + image : netty : centos - 6 - openj9 - 1 . 11 \n",Add docker - compose config to run build with OpenJ9 JVM ( # 8903 ) \n Motivation : \n To ensure Netty works on different JVMs we should also run tests on the CI with these . \n Modifications : \n Add docker - compose config to run build with OpenJ9 JVM \n Result : \n Ensure Netty works with different JVMs,381
buffer \ src \ main \ java \ io \ netty \ buffer \ PoolSubpage . java \n - synchronized ( chunk . arena ) { \n - if ( ! this . doNotDestroy ) { \n - doNotDestroy = false ; \n - / / Not used for creating the String . \n - maxNumElems = numAvail = elemSize = - 1 ; \n - } else { \n - doNotDestroy = true ; \n - maxNumElems = this . maxNumElems ; \n - numAvail = this . numAvail ; \n - elemSize = this . elemSize ; \n + if ( chunk = = null ) { \n + / / This is the head so there is no need to synchronize at all as these never change . \n + doNotDestroy = true ; \n + maxNumElems = 0 ; \n + numAvail = 0 ; \n + elemSize = - 1 ; \n + } else { \n + synchronized ( chunk . arena ) { \n + if ( ! this . doNotDestroy ) { \n + doNotDestroy = false ; \n + / / Not used for creating the String . \n + maxNumElems = numAvail = elemSize = - 1 ; \n + } else { \n + doNotDestroy = true ; \n + maxNumElems = this . maxNumElems ; \n + numAvail = this . numAvail ; \n + elemSize = this . elemSize ; \n + } \n + if ( chunk = = null ) { \n + / / It ' s the head . \n + return 0 ; \n + } \n + \n + if ( chunk = = null ) { \n + / / It ' s the head . \n + return 0 ; \n + } \n + \n + if ( chunk = = null ) { \n + / / It ' s the head . \n + return - 1 ; \n + } \n + \n,Fix NPE that was encounter by debugger ( will never happen in real code ) . ( # 8992 ) \n Motivation : \n We synchronize on the chunk . arena when produce the String returned by PoolSubpage . toString ( ) which may raise a NPE when chunk = = null . Chunk = = null for the head of the linked - list and so a NPE may raised by a debugger . This NPE can never happen in real code tho as we never access toString ( ) of the head . \n Modifications : \n Add null checks and so fix the possible NPE \n Result : \n No NPE when using a debugger and inspect the PooledByteBufAllocator .,381
"common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n + private final int ratioMask ; \n + private int handleRecycleCount ; \n + ratioMask = 0 ; \n + ratioMask = stack . ratioMask ; \n + / / While we also enforce the recycling ratio one we transfer objects from the WeakOrderQueue to the Stack \n + / / we better should enforce it as well early . Missing to do so may let the WeakOrderQueue grow very fast \n + / / without control if the Stack \n + if ( ( + + handleRecycleCount & ratioMask ) ! = 0 ) { \n + / / Drop the item to prevent recycling to aggressive . \n + return ; \n + } \n + \n + \n common \ src \ test \ java \ io \ netty \ util \ RecyclerTest . java \n + \n - assertSame ( recycler . get ( ) , o ) ; \n - assertNotSame ( recycler . get ( ) , o2 ) ; \n + / / As we use a ratioMask of 2 we should see o2 as the first object that could recycled from a different thread . \n + assertSame ( recycler . get ( ) , o2 ) ; \n + assertNotSame ( recycler . get ( ) , o ) ; \n",Enforce ratioMask also for WeakOrderQueue ( # 9727 ) \n Motivation : \n At the moment we only enfore ratioMask for the Stack which means that we only guard against recycle burts when recycled from the same Thread . We should also enforce the ratioMask in the WeakOrderQueue so we also guard against the bursts when recycle from other threads . \n Modifications : \n - Keep counter in WeakOrderQueue to enforce ratioMask as well \n - Adjust unit test \n Result : \n Better guard against recycle bursts which could pollute the heap unnecessary .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 24 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 27 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 24 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 - 27 "" \n",Use OpenJDK 12 EA 27 when running CI jobs for JDK 12 . ( # 8715 ) \n Motivation : \n A new EA release was done for OpenJDK12 . \n Modifications : \n Use OpenJDK12 EA 27 when running CI jobs for JDK 12 . \n Result : \n Test against latest OpenJDK 12 EA build .,381
"transport \ src \ main \ java \ io \ netty \ channel \ ReflectiveChannelFactory . java \n + import io . netty . util . internal . ObjectUtil ; \n + import java . lang . reflect . Constructor ; \n + \n - private final Class < ? extends T > clazz ; \n + private final Constructor < ? extends T > constructor ; \n - if ( clazz = = null ) { \n - throw new NullPointerException ( "" clazz "" ) ; \n + ObjectUtil . checkNotNull ( clazz , "" clazz "" ) ; \n + try { \n + this . constructor = clazz . getConstructor ( ) ; \n + } catch ( NoSuchMethodException e ) { \n + throw new IllegalArgumentException ( "" Class "" + StringUtil . simpleClassName ( clazz ) + \n + "" does not have a public non - arg constructor "" , e ) ; \n - this . clazz = clazz ; \n - return clazz . getConstructor ( ) . newInstance ( ) ; \n + return constructor . newInstance ( ) ; \n - throw new ChannelException ( "" Unable to create Channel from class "" + clazz , t ) ; \n + throw new ChannelException ( "" Unable to create Channel from class "" + constructor . getDeclaringClass ( ) , t ) ; \n - return StringUtil . simpleClassName ( clazz ) + "" . class "" ; \n + return StringUtil . simpleClassName ( ReflectiveChannelFactory . class ) + \n + ' ( ' + StringUtil . simpleClassName ( constructor . getDeclaringClass ( ) ) + "" . class ) "" ; \n",Access the Constructor of the Channel in the constructor of ReflectiveChannelFactory . ( # 8718 ) \n Motivation : \n We should access the Constructor of the passed in class in the Constructor of ReflectiveChannelFactory only to reduce the overhead but also fail - fast . \n Modifications : \n Access the Constructor early . \n Result : \n Fails fast and less performance overhead .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" openjdk @ 1 . 11 . 0 - 1 "" \n + java _ version : "" openjdk @ 1 . 11 . 0 - 2 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" 1 . 8 . 192 "" \n + java _ version : "" 1 . 8 . 202 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" openjdk @ 1 . 11 . 0 - 1 "" \n + java _ version : "" openjdk @ 1 . 11 . 0 - 2 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" 1 . 8 . 192 "" \n + java _ version : "" 1 . 8 . 202 "" \n",Update to latest JDK8 and JDK11 releases ( # 8725 ) \n Motivation : \n We should always build with the latest JDK releases . \n Modifications : \n Update JDK8 and JDK11 versions to the latest . \n Result : \n Run CI jobs on the latest JDK release .,381
pom . xml \n + < ! - - pax - exam does not work on latest Java11 build - - > \n + < skipOsgiTestsuite > true < / skipOsgiTestsuite > \n,Skip osgi testsuite on JDK11 . ( # 8733 ) \n Motivation : \n Since the updating to OpenJDK 11 . 0 . 2 the OSGI testsuite fails . We should dissable it until there is a version of the used plugins that works with this OpenJDK version . \n Modifications : \n Skip osgi testsuite when using JDK11 . \n Result : \n Build pass again with JDK11 .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsResolveContext . java \n + \n + / / Try with the next server if is not authoritative for the domain . \n + / / \n + / / From https : / / tools . ietf . org / html / rfc1035 : \n + / / \n + / / RCODE Response code - this 4 bit field is set as part of \n + / / responses . The values have the following \n + / / interpretation : \n + / / \n + / / . . . . \n + / / . . . . \n + / / \n + / / 3 Name Error - Meaningful only for \n + / / responses from an authoritative name \n + / / server , this code signifies that the \n + / / domain name referenced in the query does \n + / / not exist . \n + / / . . . . \n + / / . . . . \n + if ( ! res . isAuthoritativeAnswer ( ) ) { \n + query ( nameServerAddrStream , nameServerAddrStreamIndex + 1 , question , \n + newDnsQueryLifecycleObserver ( question ) , true , promise , null ) ; \n + } \n resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DnsNameResolverTest . java \n - . resolvedAddressTypes ( ResolvedAddressTypes . IPV6 _ PREFERRED ) \n + . resolvedAddressTypes ( ResolvedAddressTypes . IPV4 _ ONLY ) \n - assertEquals ( 2 , lifecycleObserverFactory . observers . size ( ) ) ; \n + assertEquals ( 1 , lifecycleObserverFactory . observers . size ( ) ) ; \n - observer = lifecycleObserverFactory . observers . poll ( ) ; \n - assertEquals ( 2 , observer . events . size ( ) ) ; \n - writtenEvent = ( QueryWrittenEvent ) observer . events . poll ( ) ; \n - assertEquals ( dnsServer1 . localAddress ( ) , writtenEvent . dnsServerAddress ) ; \n - failedEvent = ( QueryFailedEvent ) observer . events . poll ( ) ; \n - \n",Only handle NXDOMAIN as failure when nameserver is authoritive or no other nameservers are left . ( # 8731 ) \n Motivation : \n When using multiple nameservers and a nameserver respond with NXDOMAIN we should only fail the query if the nameserver in question is authoritive or no nameservers are left to try . \n Modifications : \n - Try next nameserver if NXDOMAIN was returned but the nameserver is not authoritive \n - Adjust testcase to respect correct behaviour . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8261,381
"transport \ src \ test \ java \ io \ netty \ channel \ ChannelOutboundBufferTest . java \n + final CountDownLatch handlerRemovedLatch = new CountDownLatch ( 1 ) ; \n - ch . pipeline ( ) . addLast ( executor , new ChannelOutboundHandlerAdapter ( ) { \n + ch . pipeline ( ) . addLast ( executor , "" handler "" , new ChannelOutboundHandlerAdapter ( ) { \n - public void handlerAdded ( ChannelHandlerContext ctx ) throws Exception { \n + public void handlerAdded ( ChannelHandlerContext ctx ) { \n + \n + @ Override \n + public void handlerRemoved ( ChannelHandlerContext ctx ) { \n + handlerRemovedLatch . countDown ( ) ; \n + } \n + while ( executor . pendingTasks ( ) ! = 0 ) { \n + / / Wait until there is no more pending task left . \n + Thread . sleep ( 10 ) ; \n + } \n + \n + ch . pipeline ( ) . remove ( "" handler "" ) ; \n + \n + / / Ensure we do not try to shutdown the executor before we handled everything for the Channel . Otherwise \n + / / the Executor may reject when the Channel tries to add a task to it . \n + handlerRemovedLatch . await ( ) ; \n + \n + \n",Fix racy ChannelOutboundBuffer . testWriteTaskRejected test . ( # 8735 ) \n Motivation : \n testWriteTaskRejected was racy as we did not ensure we dispatched all events to the executor before shutting it down . \n Modifications : \n Add a latch to ensure we dispatched everything . \n Result : \n Fix racy test that failed sometimes before .,381
transport \ src \ test \ java \ io \ netty \ channel \ ChannelInitializerTest . java \n - public void channelUnregistered ( ChannelHandlerContext ctx ) { \n + public void handlerRemoved ( ChannelHandlerContext ctx ) { \n + / / Wait until the handler is removed from the pipeline and so no more events are handled by it . \n,Fix flaky ChannelInitializerTest . testChannelInitializerEventExecutor ( ) ( # 8738 ) \n Motivation : \n testChannelInitializerEventExecutor ( ) did sometimes fail as we sometimes miss to count down the latch . This can happen when we remove the handler from the pipeline before channelUnregistered ( . . . ) was called for it . \n Modifications : \n Countdown the latch in handlerRemoved ( . . . ) . \n Result : \n Fix flaky test .,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ AppendableCharSequence . java \n + if ( start = = end ) { \n + / / If start and end index is the same we need to return an empty sequence to conform to the interface . \n + / / As our expanding logic depends on the fact that we have a char [ ] with length > 0 we need to construct \n + / / an instance for which this is true . \n + return new AppendableCharSequence ( Math . min ( 16 , chars . length ) ) ; \n + } \n common \ src \ test \ java \ io \ netty \ util \ internal \ AppendableCharSequenceTest . java \n + @ Test \n + public void testEmptySubSequence ( ) { \n + AppendableCharSequence master = new AppendableCharSequence ( 26 ) ; \n + master . append ( "" abcdefghijlkmonpqrstuvwxyz "" ) ; \n + AppendableCharSequence sub = master . subSequence ( 0 , 0 ) ; \n + assertEquals ( 0 , sub . length ( ) ) ; \n + sub . append ( ' b ' ) ; \n + assertEquals ( ' b ' , sub . charAt ( 0 ) ) ; \n + } \n + \n",Fix AppendableCharSequence . subSequence ( . . . ) where start = = end . ( # 8798 ) \n Motivation : \n To conform to the CharSequence interface we need to return an empty CharSequence when start = = end index and a subSequence is requested . \n Modifications : \n - Correctly handle the case where start = = end \n - Add unit test \n Result : \n Fix https : / / github . com / netty / netty / issues / 8796 .,381
"transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ NativeDatagramPacketArray . java \n + \n + / / We share one IovArray for all NativeDatagramPackets to reduce memory overhead . This will allow us to write \n + / / up to IOV _ MAX iovec across all messages in one sendmmsg ( . . . ) call . \n + private final IovArray iovArray = new IovArray ( ) ; \n + / / We already filled up to UIO _ MAX _ IOV messages . This is the max allowed per sendmmsg ( . . . ) call , we will \n + / / try again later . \n - if ( ! p . init ( content , recipient ) ) { \n + \n + int offset = iovArray . count ( ) ; \n + if ( ! iovArray . add ( content ) ) { \n + / / Not enough space to hold the whole content , we will try again later . \n + p . init ( iovArray . memoryAddress ( offset ) , iovArray . count ( ) - offset , recipient ) ; \n + this . iovArray . clear ( ) ; \n - / / Release all packets \n - for ( NativeDatagramPacket datagramPacket : packets ) { \n - datagramPacket . release ( ) ; \n - } \n + iovArray . release ( ) ; \n - / / Each NativeDatagramPackets holds a IovArray which is used for gathering writes . \n - / / This is ok as NativeDatagramPacketArray is always obtained from an EpollEventLoop \n - / / field so the memory needed is quite small anyway . \n - private final IovArray array = new IovArray ( ) ; \n - private void release ( ) { \n - array . release ( ) ; \n - } \n - \n - / * * \n - * Init this instance and return { @ code true } if the init was successful . \n - * / \n - private boolean init ( ByteBuf buf , InetSocketAddress recipient ) { \n - array . clear ( ) ; \n - if ( ! array . add ( buf ) ) { \n - return false ; \n - } \n - / / always start from offset 0 \n - memoryAddress = array . memoryAddress ( 0 ) ; \n - count = array . count ( ) ; \n + private void init ( long memoryAddress , int count , InetSocketAddress recipient ) { \n + this . memoryAddress = memoryAddress ; \n + this . count = count ; \n - return true ; \n",Reduce direct memory overhead per EpollEventLoop when using EpollDatagramChannel ( # 8825 ) \n Motivation : \n When using a linux distribution that supports sendmmsg ( . . . ) we allocated enough direct memory per EpollEventLoop to be able to write IOV _ MAX number of iovecs per message that can be written per sendmmsg . \n The number of messages that can be written per sendmmsg ( . . . ) call is limited by UIO _ MAX _ IOV . \n In practice this resulted in an allocation of 16MB direct memory per EpollEventLoop instance that stayed allocated until the EpollEventLoop was shutdown which happens as part of the shutdown of the enclosing EpollEVentLoopGroup . \n This resulted in quite some heavy direct memory usage in practice even when in practice we have very slim changes to ever need all of the memory . \n Modification : \n Adjust NativeDatagramPacketArray to share one IovArray instance across all NativeDatagramPacket instances it holds . This limits the max number of iovecs we can write across all messages to IOV _ MAX per sendmmsg ( . . . ) call . \n This in practice will still be enough to allow us to write multiple messages with one syscall while keep the memory overhead to a minimum . \n Result : \n Smaller direct memory footprint per EpollEventLoop when using EpollDatagramChannel on distributions that support sendmmsg ( . . . ) . \n Fixes https : / / github . com / netty / netty / issues / 8814,381
"transport \ src \ main \ java \ io \ netty \ channel \ ChannelHandler . java \n - * @ deprecated is part of { @ link ChannelInboundHandler } \n + * @ deprecated if you want to handle this event you should implement { @ link ChannelInboundHandler } and \n + * implement the method there . \n transport \ src \ main \ java \ io \ netty \ channel \ ChannelInboundHandlerAdapter . java \n + @ SuppressWarnings ( "" deprecation "" ) \n","Add @ SupressWarnings ( "" deprecation "" ) to ChannelInboundHandlerAdapter and clarify deprecation in ChannelHandler ( # 9001 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 8826 added @ Deprecated to the exceptionCaught ( . . . ) method but we missed to add @ SupressWarnings ( . . . ) to it ' s sub - types . Beside this we can make the deprecated docs a bit more clear . \n Modifications : \n - Add @ SupressWarnings ( "" deprecated "" ) \n - Clarify docs . \n Result : \n Less warnings and more clear deprecated docs .",381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerHandshaker00 . java \n - ByteBuf input = Unpooled . buffer ( 16 ) ; \n + ByteBuf input = Unpooled . wrappedBuffer ( new byte [ 16 ] ) . setIndex ( 0 , 0 ) ; \n",Do not depend on the implementation detail of Unpooled . buffer ( int ) when accessing backing array . ( # 8865 ) \n Motivation : \n We should not depend on the implementation detail of Unpooled . buffer ( int ) to allocate the exact size of backing byte [ ] as depending on the implementation it may return a buffer with a bigger backing array . \n Modifications : \n Explicit allocate the byte [ ] and wrap it in the ByteBuf . This way we are sure that ByteBuf . array ( ) returns an byte [ ] which has the exact length and content we expect . \n Result : \n More correct and safe usage of ByteBuf . array ( ),381
"transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueChannel . java \n - try { \n - if ( isRegistered ( ) ) { \n - / / The FD will be closed , which should take care of deleting any associated events from kqueue , but \n - / / since we rely upon jniSelfRef to be consistent we make sure that we clear this reference out for \n - / / all events which are pending in kqueue to avoid referencing a deleted pointer at a later time . \n - \n - / / Need to check if we are on the EventLoop as doClose ( ) may be triggered by the GlobalEventExecutor \n - / / if SO _ LINGER is used . \n - / / \n - / / See https : / / github . com / netty / netty / issues / 7159 \n - EventLoop loop = eventLoop ( ) ; \n - if ( loop . inEventLoop ( ) ) { \n - doDeregister ( ) ; \n - } else { \n - loop . execute ( new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - try { \n - doDeregister ( ) ; \n - } catch ( Throwable cause ) { \n - pipeline ( ) . fireExceptionCaught ( cause ) ; \n - } \n - } \n - } ) ; \n - } \n - } \n - } finally { \n - socket . close ( ) ; \n - } \n + socket . close ( ) ; \n",Don ' t deregister Channel as part of closing it when using native kqueue transport ( # 8881 ) \n Motivation : \n In https : / / github . com / netty / netty / pull / 8665 we changed how we handle the registration of Channels to KQueue but missed to removed some code which would deregister the Channel before it actual closed the underlying socket . This could lead to have events triggered still while not have a mapping to the Channel anymore . \n Modifications : \n Remove deregister call during socket closure . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8849 .,381
"common \ src \ test \ templates \ io \ netty \ util \ collection \ KObjectHashMapTest . template \n + \n + @ Test \n + public void valuesIteratorRemove ( ) { \n + Value v1 = new Value ( "" v1 "" ) ; \n + Value v2 = new Value ( "" v2 "" ) ; \n + Value v3 = new Value ( "" v3 "" ) ; \n + map . put ( ( @ k @ ) 1 , v1 ) ; \n + map . put ( ( @ k @ ) 2 , v2 ) ; \n + map . put ( ( @ k @ ) 3 , v3 ) ; \n + \n + Iterator < Value > it = map . values ( ) . iterator ( ) ; \n + \n + assertSame ( v1 , it . next ( ) ) ; \n + assertSame ( v2 , it . next ( ) ) ; \n + it . remove ( ) ; \n + \n + assertSame ( v3 , it . next ( ) ) ; \n + assertFalse ( it . hasNext ( ) ) ; \n + \n + assertEquals ( 2 , map . size ( ) ) ; \n + assertSame ( v1 , map . get ( ( @ k @ ) 1 ) ) ; \n + assertNull ( map . get ( ( @ k @ ) 2 ) ) ; \n + assertSame ( v3 , map . get ( ( @ k @ ) 3 ) ) ; \n + \n + it = map . values ( ) . iterator ( ) ; \n + \n + assertSame ( v1 , it . next ( ) ) ; \n + assertSame ( v3 , it . next ( ) ) ; \n + assertFalse ( it . hasNext ( ) ) ; \n + } \n",Add test for Iterator . remove ( ) on KObjectHashMap . values ( ) . iterator ( ) ( # 8891 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 8866 added support for calling Iterator . remove ( ) but did not add a testcase . \n Modifications : \n Add testcase to ensure removal works . \n Result : \n Better test - coverage .,381
"docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 27 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 "" \n docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 3 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 9 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 - 27 "" \n + java _ version : "" openjdk @ 1 . 12 . 0 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 3 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 9 "" \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n - assertEquals ( SSLEngineResult . HandshakeStatus . NEED _ UNWRAP , result . getHandshakeStatus ( ) ) ; \n + if ( PlatformDependent . javaVersion ( ) > = 12 & & sslClientProvider ( ) = = SslProvider . JDK ) { \n + / / This is a workaround for a possible JDK12 + bug . \n + / / \n + / / See http : / / mail . openjdk . java . net / pipermail / security - dev / 2019 - February / 019406 . html . \n + assertEquals ( SSLEngineResult . HandshakeStatus . NOT _ HANDSHAKING , result . getHandshakeStatus ( ) ) ; \n + } else { \n + assertEquals ( SSLEngineResult . HandshakeStatus . NEED _ UNWRAP , result . getHandshakeStatus ( ) ) ; \n + } \n",Update JDK12 and 13 to latest EA releases . ( # 8809 ) \n Motivation : \n We use outdated EA releases when building and testing with JDK 12 and 13 . \n Modifications : \n - Update versions . \n - Add workaround for possible JDK12 + bug . \n Result : \n Use latest releases,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - switch ( result . getHandshakeStatus ( ) ) { \n + HandshakeStatus status = result . getHandshakeStatus ( ) ; \n + switch ( status ) { \n - if ( result . bytesProduced ( ) = = 0 ) { \n + if ( result . bytesProduced ( ) = = 0 & & status ! = HandshakeStatus . NEED _ TASK ) { \n - if ( status = = Status . BUFFER _ UNDERFLOW | | consumed = = 0 & & produced = = 0 ) { \n + if ( status = = Status . BUFFER _ UNDERFLOW | | \n + / / If we processed NEED _ TASK we should try again even we did not consume or produce anything . \n + handshakeStatus ! = HandshakeStatus . NEED _ TASK & & consumed = = 0 & & produced = = 0 ) { \n + if ( inUnwrap ) { \n + / / If we were in the unwrap call when the task was processed we should also try to unwrap \n + / / non app data first as there may not anything left in the inbound buffer to process . \n + unwrapNonAppData ( ctx ) ; \n + } \n - wrapNonAppData ( ctx , inUnwrap ) ; \n + if ( ! wrapNonAppData ( ctx , false ) & & inUnwrap ) { \n + / / The handshake finished in wrapNonAppData ( . . . ) , we need to try call \n + / / unwrapNonAppData ( . . . ) as we may have some alert that we should read . \n + / / \n + / / This mimics what we would do when we are calling this method while in unwrap ( . . . ) . \n + unwrapNonAppData ( ctx ) ; \n + } \n + \n + / / Flush now as we may have written some data as part of the wrap call . \n + forceFlush ( ctx ) ; \n - / / Flush now as we may have written some data as part of the wrap call . \n - forceFlush ( ctx ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n - assertTrue ( sendChannel . writeAndFlush ( message ) . await ( 50 , TimeUnit . SECONDS ) ) ; \n + assertTrue ( sendChannel . writeAndFlush ( message ) . await ( 5 , TimeUnit . SECONDS ) ) ; \n","Correctly resume wrap / unwrap when SslTask execution completes ( # 8899 ) \n Motivation : \n fa6a8cb09c9679468a6c2d912ddfbbe885ee0c08 introduced correct dispatching of delegated tasks for SSLEngine but did not correctly handle some cases for resuming wrap / unwrap after the task was executed . This could lead to stales , which showed up during tests when running with Java11 and BoringSSL . \n Modifications : \n - Correctly resume wrap / unwrap in all cases . \n - Fix timeout value which was changed in previous commit by mistake . \n Result : \n No more stales after task execution .",381
codec \ src \ main \ java \ io \ netty \ handler \ codec \ ByteToMessageDecoder . java \n - \n + numReads = 0 ; \n + ctx . fireChannelReadComplete ( ) ; \n - \n - numReads = 0 ; \n - ctx . fireChannelReadComplete ( ) ; \n,"ByteToMessageDecoder . handlerRemoved ( . . . ) should only call fireChannelReadComplete ( ) if fireChannelRead ( . . . ) was called before ( # 9211 ) \n Motivation : \n At the moment ByteToMessageDecoder always calls fireChannelReadComplete ( ) when the handler is removed from the pipeline and the cumulation buffer is not null . We should only call it when we also call fireChannelRead ( . . . ) , which only happens if the cumulation buffer is not null and readable . \n Modifications : \n Only call fireChannelReadComplete ( ) if fireChannelRead ( . . . ) is called before during removal of the handler . \n Result : \n More correct semantics",381
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ DatagramPacketEncoder . java \n - & & envelope . sender ( ) instanceof InetSocketAddress \n + & & ( envelope . sender ( ) instanceof InetSocketAddress | | envelope . sender ( ) = = null ) \n codec \ src \ test \ java \ io \ netty \ handler \ codec \ DatagramPacketEncoderTest . java \n + testEncode ( false ) ; \n + } \n + \n + @ Test \n + public void testEncodeWithSenderIsNull ( ) { \n + testEncode ( true ) ; \n + } \n + \n + private void testEncode ( boolean senderIsNull ) { \n - InetSocketAddress sender = SocketUtils . socketAddress ( "" 127 . 0 . 0 . 1 "" , 20000 ) ; \n + InetSocketAddress sender = senderIsNull ? null : SocketUtils . socketAddress ( "" 127 . 0 . 0 . 1 "" , 20000 ) ; \n",Allow null sender when using DatagramPacketEncoder ( # 9204 ) \n Motivation : \n It is valid to use null as sender so we should support it when DatagramPacketEncoder checks if it supports the message . \n Modifications : \n - Add null check \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9199 .,381
transport - native - epoll \ pom . xml \n - < ! - - Needed by the native transport as we need the memoryAddress of the ByteBuffer - - > \n - < argLine . java9 . extras > - - add - exports java . base / sun . security . x509 = ALL - UNNAMED - - add - opens = java . base / java . nio = ALL - UNNAMED < / argLine . java9 . extras > \n + < ! - - Needed as we use SelfSignedCertificate in our tests - - > \n + < argLine . java9 . extras > - - add - exports java . base / sun . security . x509 = ALL - UNNAMED < / argLine . java9 . extras > \n transport - native - kqueue \ pom . xml \n - < ! - - Needed by the native transport as we need the memoryAddress of the ByteBuffer - - > \n - < argLine . java9 . extras > - - add - exports java . base / sun . security . x509 = ALL - UNNAMED - - add - opens = java . base / java . nio = ALL - UNNAMED < / argLine . java9 . extras > \n + < ! - - Needed as we use SelfSignedCertificate in our tests - - > \n + < argLine . java9 . extras > - - add - exports java . base / sun . security . x509 = ALL - UNNAMED < / argLine . java9 . extras > \n,Remove - - add - opens = java . base / java . nio = ALL - UNNAMED when running tests as it is not needed anymore since a long time ( # 8934 ) \n Motivation : \n At some point we needed - - add - opens = java . base / java . nio = ALL - UNNAMED to run our native tests but this is not true anymore . \n Modifications : \n Remove - - add - opens = java . base / java . nio = ALL - UNNAMED when running native tests . \n Result : \n Remove obsolate jvm arg .,381
pom . xml \n + < argLine . java9 . extras / > \n + < ! - - Export some stuff which is used during our tests - - > \n + < argLine . java9 > - - illegal - access = deny $ { argLine . java9 . extras } < / argLine . java9 > \n + < argLine . java9 . extras / > \n + < ! - - Export some stuff which is used during our tests - - > \n + < argLine . java9 > - - illegal - access = deny $ { argLine . java9 . extras } < / argLine . java9 > \n + < argLine . java9 . extras / > \n + < ! - - Export some stuff which is used during our tests - - > \n + < argLine . java9 > - - illegal - access = deny - - add - modules java . xml . bind $ { argLine . java9 . extras } < / argLine . java9 > \n - < argLine . java9 > - - add - modules java . xml . bind $ { argLine . java9 . extras } < / argLine . java9 > \n + < argLine . java9 > - - illegal - access = deny - - add - modules java . xml . bind $ { argLine . java9 . extras } < / argLine . java9 > \n,Fail build when Illegal reflective access is detected ( # 8933 ) \n Motivation : \n We want to make the experience as smooth as possible for our users when using Java9 + and so should ensure we do not produce any ' Illegal reflective access ' errors when using netty . \n Modifications : \n Add jvmArgs when running our tests that will deny reflective access and so will fail the build at the end due not be able to load some classes . \n Result : \n Ensure we do not produce any illegal refelctive access errors when using java9 +,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ NativeLibraryLoader . java \n - "" { } cannot be loaded from java . libary . path , "" \n + "" { } cannot be loaded from java . library . path , "" \n + "" now trying export to - Dio . netty . native . workdir : { } "" , name , WORKDIR , ex ) ; \n",Fix typo in NativeLibraryLoader debug log message ( # 8947 ) \n Motivation : \n We had a typo in NativeLibraryLoader debug log message which could misslead the user . \n Modifications : \n Fix typo to correctly state java . library . path \n Result : \n Correct and less confusing log message,381
"new file \n docker \ docker - sync - compose . centos - 6 . 18 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - 1 . 8 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + java _ version : "" 1 . 8 . 202 "" \n + \n + test : \n + image : netty : centos - 6 - 1 . 8 \n + volumes : \n + - code - sync : / code : nocopy \n + \n + test - leak : \n + image : netty : centos - 6 - 1 . 8 \n + volumes : \n + - code - sync : / code : nocopy \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - 1 . 8 \n + volumes : \n + - code - sync : / code : nocopy \n + \n + shell : \n + image : netty : centos - 6 - 1 . 8 \n + volumes : \n + - code - sync : / code : nocopy \n + \n + volumes : \n + code - sync : \n + external : true \n new file \n docker \ docker - sync . centos - 6 . 18 . yaml \n + version : "" 2 "" \n + \n + compose - dev - file - path : ' docker - sync - compose . centos - 6 . 18 . yaml ' \n + \n + syncs : \n + # IMPORTANT : ensure this name is unique and does not match your other application container name \n + code - sync : # tip : add - sync and you keep consistent names as a convention \n + src : ' . . / ' \n",Add docker - sync config to step up docker - usage on macOS . ( # 8948 ) \n Motivation : \n docker - sync . io helps to speed up docker FS access on macOS and so make builds there a lot faster . We should add some config to help users use it . \n Modifications : \n Add docker - sync configs for centos - 6 . 18 which is what we use for releases . \n Result : \n Faster builds via docker and when using macOS possible .,381
common \ src \ main \ java \ io \ netty \ util \ concurrent \ GlobalEventExecutor . java \n - public final class GlobalEventExecutor extends AbstractScheduledEventExecutor { \n + public final class GlobalEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor { \n,Let GlobalEventExecutor implement OrderedEventExecutor ( # 8952 ) \n Motivation : \n GlobalEventExecutor does already provide all guarantees of OrderedEventExecutor so it should implement it . \n Modifications : \n Let GlobalEventExecutor implement OrderedEventExecutor . \n Result : \n Make it more clear how execution order is handled in GlobalEventExecutor .,381
. gitignore \n + \n + # exclude docker - sync stuff \n + . docker - sync \n + * / . docker - sync \n,Add . gitignore for docker - sync stuff \n Motivation : \n df8b9d3fb9348cbcffd246331c5441f2f25bec64 added config files for docker - sync but missed to add a gitignore for . docker - sync \n Modifications : \n Add . docker - sync to gitignore \n Result : \n Ignore . docker - sync directory,381
deleted file \n transport \ test . log \n,Remove test . log file that was commited by mistake . \n Motivation : \n We commit a test . log file by mistake . \n Modifications : \n Remove the file . \n Result : \n Cleanup repo .,381
"common \ src \ main \ java \ io \ netty \ util \ concurrent \ FastThreadLocal . java \n - V value = initialize ( threadLocalMap ) ; \n - registerCleaner ( threadLocalMap ) ; \n - return value ; \n - } \n - \n - private void registerCleaner ( final InternalThreadLocalMap threadLocalMap ) { \n - Thread current = Thread . currentThread ( ) ; \n - if ( FastThreadLocalThread . willCleanupFastThreadLocals ( current ) | | threadLocalMap . isCleanerFlagSet ( index ) ) { \n - return ; \n - } \n - \n - threadLocalMap . setCleanerFlag ( index ) ; \n - \n - / / TODO : We need to find a better way to handle this . \n - / * \n - / / We will need to ensure we will trigger remove ( InternalThreadLocalMap ) so everything will be released \n - / / and FastThreadLocal . onRemoval ( . . . ) will be called . \n - ObjectCleaner . register ( current , new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - remove ( threadLocalMap ) ; \n - \n - / / It ' s fine to not call InternalThreadLocalMap . remove ( ) here as this will only be triggered once \n - / / the Thread is collected by GC . In this case the ThreadLocal will be gone away already . \n - } \n - } ) ; \n - * / \n + return initialize ( threadLocalMap ) ; \n - if ( setKnownNotUnset ( threadLocalMap , value ) ) { \n - registerCleaner ( threadLocalMap ) ; \n - } \n + setKnownNotUnset ( threadLocalMap , value ) ; \n - private boolean setKnownNotUnset ( InternalThreadLocalMap threadLocalMap , V value ) { \n + private void setKnownNotUnset ( InternalThreadLocalMap threadLocalMap , V value ) { \n - return true ; \n - return false ; \n",Remove old internal code that is not used anymore after removing usage of ObjectCleaner ( # 8956 ) \n Motivation : \n We dont use ObjectCleaner in our FastThreadLocal anymore so we also dont need to take special care to store it there anymore . \n Modifications : \n Remove code that is not needed anymore . \n Result : \n Code cleanup .,381
pom . xml \n - < netty . build . version > 23 < / netty . build . version > \n + < netty . build . version > 24 < / netty . build . version > \n,Update to new netty - build version to be able to correctly detect copyright header in property files . ( # 8967 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 8963 adds property files which contains a netty copyright header but our old checkstyle regex did not correct detect these . \n Modifications : \n Update to new netty - build which contains an updated regex . \n Result : \n Be able to correctly detect copyright headers in property files .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" openjdk @ 1 . 11 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 2 "" \n docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 "" \n + java _ version : "" zulu @ 1 . 12 . 0 "" \n docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 9 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 13 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" 1 . 8 . 202 "" \n + java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n docker \ docker - compose . centos - 6 . 19 . yaml \n - java _ version : "" openjdk @ 1 . 9 . 0 - 4 "" \n + java _ version : "" zulu @ 1 . 9 . 0 - 7 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" openjdk @ 1 . 11 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 2 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" openjdk @ 1 . 12 . 0 "" \n + java _ version : "" zulu @ 1 . 12 . 0 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 9 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 13 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" 1 . 8 . 202 "" \n + java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n docker \ docker - compose . centos - 7 . 19 . yaml \n - java _ version : "" openjdk @ 1 . 9 . 0 - 4 "" \n + java _ version : "" openjdk @ 1 . 9 . 0 - 7 "" \n",Update to latest JDK releases in our CI ( # 8969 ) \n Motivation : \n We should use the latest JDK release on our CI \n Modifications : \n Update all versions . \n Result : \n Test on latest JDK versions on our CI,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslErrorTest . java \n - message . toLowerCase ( Locale . UK ) . contains ( "" certificate unknown "" ) ) { \n + message . toLowerCase ( Locale . UK ) . contains ( "" unknown "" ) ) { \n",Correctly detect exeception cause when using BoringSSL in SslErrorTest ( # 8970 ) \n Motivation : \n e9ce5048dfdfed32df28e46fae6e766d8fd6d734 added a testcase to ensure we correctly send the alert in all cases but did use a too strict message matching which did not work for BoringSSL as it not uses whitespaces but underscores . \n Modifications : \n Make the message matching less strict . \n Result : \n Test pass also when using BoringSSL .,381
"docker \ docker - sync - compose . centos - 6 . 18 . yaml \n - java _ version : "" 1 . 8 . 202 "" \n + java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n",Also use adoptjdk builds when using docker - sync ( # 8971 ) \n Motivation : \n We recently changed the docker config to use adoptjdk builds but missed to include the docker - sync related files . \n Modifications : \n Use adoptjdk there as well . \n Result : \n More conistent usage of JDK versions .,381
example \ src \ main \ java \ io \ netty \ example \ http \ upload \ HttpUploadServerHandler . java \n - private boolean readingChunks ; \n - \n - readingChunks = HttpUtil . isTransferEncodingChunked ( request ) ; \n + boolean readingChunks = HttpUtil . isTransferEncodingChunked ( request ) ; \n - readingChunks = true ; \n - readingChunks = false ; \n,Cleanup example to use local variable . ( # 8976 ) \n Motivation : \n We can just use a local variable in HttpUploadServerHandler and so make the example code a bit cleaner . \n Modifications : \n Use local variable . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8892 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslClientContext . java \n - import javax . net . ssl . SSLHandshakeException ; \n - SSLHandshakeException e = new SSLHandshakeException ( "" General OpenSslEngine problem "" ) ; \n - e . initCause ( cause ) ; \n - assert engine . handshakeException = = null ; \n - engine . handshakeException = e ; \n + engine . initHandshakeException ( cause ) ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - SSLHandshakeException e = new SSLHandshakeException ( "" General OpenSslEngine problem "" ) ; \n - e . initCause ( cause ) ; \n - assert engine . handshakeException = = null ; \n - engine . handshakeException = e ; \n + engine . initHandshakeException ( cause ) ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - \n - / / This is package - private as we set it from OpenSslContext if an exception is thrown during \n - / / the verification step . \n - SSLHandshakeException handshakeException ; \n + private Throwable handshakeException ; \n - SSLHandshakeException exception = handshakeException ; \n + Throwable exception = handshakeException ; \n - throw exception ; \n + if ( exception instanceof SSLHandshakeException ) { \n + throw ( SSLHandshakeException ) exception ; \n + } \n + SSLHandshakeException e = new SSLHandshakeException ( "" General OpenSslEngine problem "" ) ; \n + e . initCause ( exception ) ; \n + throw e ; \n + } \n + \n + / * * \n + * Should be called if the handshake will be failed due a callback that throws an exception . \n + * This cause will then be used to give more details as part of the { @ link SSLHandshakeException } . \n + * / \n + final void initHandshakeException ( Throwable cause ) { \n + assert handshakeException = = null ; \n + handshakeException = cause ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslServerContext . java \n - import javax . net . ssl . SSLHandshakeException ; \n - SSLHandshakeException e = new SSLHandshakeException ( "" General OpenSslEngine problem "" ) ; \n - e . initCause ( cause ) ; \n - assert engine . handshakeException = = null ; \n - engine . handshakeException = e ; \n + engine . initHandshakeException ( cause ) ; \n","Consolidate creation of SslHandshakeException when caused by a callback that is used in the native SSL implementation . ( # 8979 ) \n Motivation : \n We have multiple places where we store the exception that was produced by a callback in ReferenceCountedOpenSslEngine , and so have a lot of code - duplication . \n Modifications : \n - Consolidate code into a package - private method that is called from the callbacks if needed \n Result : \n Less code - duplication and cleaner code .",381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2FrameWriter . java \n - } while ( headerBlock . isReadable ( ) ) ; \n + } while ( headerBlock . isReadable ( ) ) ; \n pom . xml \n - < netty . build . version > 24 < / netty . build . version > \n + < netty . build . version > 25 < / netty . build . version > \n + < dependency > \n + < groupId > com . puppycrawl . tools < / groupId > \n + < artifactId > checkstyle < / artifactId > \n + < version > 8 . 18 < / version > \n + < / dependency > \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ Native . java \n - private static native int epollCtlAdd0 ( int efd , final int fd , final int flags ) ; \n + private static native int epollCtlAdd0 ( int efd , int fd , int flags ) ; \n - private static native int epollCtlMod0 ( int efd , final int fd , final int flags ) ; \n + private static native int epollCtlMod0 ( int efd , int fd , int flags ) ; \n - private static native int epollCtlDel0 ( int efd , final int fd ) ; \n + private static native int epollCtlDel0 ( int efd , int fd ) ; \n",Upgrade to new netty - build and com . puppycrawl . tools 8 . 18 ( # 8980 ) \n Motivation : \n com . puppycrawl . tools checkstyle < 8 . 18 was reported to contain a possible security flaw . We should upgrade . \n Modifications : \n - Upgrade netty - build and checkstyle . \n - Fix checkstyle errors \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8968 .,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 13 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 14 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 13 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 14 "" \n",Update to latest openjdk13 EA release ( # 8990 ) \n Motivation : \n A new openjdk13 EA release is out . \n Modifications : \n Update openjdk13 version . \n Result : \n Run build on CI with latest openjdk13 EA build,381
"common \ src \ main \ java \ io \ netty \ util \ concurrent \ PromiseCombiner . java \n + ObjectUtil . checkNotNull ( aggregatePromise , "" aggregatePromise "" ) ; \n - this . aggregatePromise = ObjectUtil . checkNotNull ( aggregatePromise , "" aggregatePromise "" ) ; \n + this . aggregatePromise = aggregatePromise ; \n common \ src \ test \ java \ io \ netty \ util \ concurrent \ PromiseCombinerTest . java \n + import org . junit . Assert ; \n + @ Test \n + public void testNullArgument ( ) { \n + try { \n + combiner . finish ( null ) ; \n + Assert . fail ( ) ; \n + } catch ( NullPointerException expected ) { \n + / / expected \n + } \n + combiner . finish ( p1 ) ; \n + verify ( p1 ) . trySuccess ( null ) ; \n + } \n + \n","Don ' t update state of PromiseCombiner when finish ( null ) is called ( # 8843 ) \n Motivation : \n When we fail a call to PromiseCombiner . finish ( . . . ) because of a null argument we must not update the internal state before throwing . \n Modifications : \n - First do the null check and only after we validated that the argument is not null update the internal state \n - Add test case . \n Modifications : \n Do not mess up internal state of PromiseCombiner when finish ( . . . ) is called with a null argument . \n Result : \n After your change , what will change .",381
transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n + import org . junit . Ignore ; \n + @ Ignore \n,Mark flaky test as @ Ignore ( # 9010 ) \n Motivation : \n 0a0da67f43354473af9861407749d02fe62e8f6c introduced a testcase which is flacky . We need to fix it and enable it again . \n Modifications : \n Mark flaky test as ignore . \n Result : \n No flaky build anymore .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2ServerUpgradeCodec . java \n - connectionHandler . onHttpServerUpgrade ( settings ) ; \n + / / Add also all extra handlers as these may handle events / messages produced by the connectionHandler . \n + / / See https : / / github . com / netty / netty / issues / 9314 \n + if ( handlers ! = null ) { \n + final String name = ctx . pipeline ( ) . context ( connectionHandler ) . name ( ) ; \n + for ( int i = handlers . length - 1 ; i > = 0 ; i - - ) { \n + ctx . pipeline ( ) . addAfter ( name , null , handlers [ i ] ) ; \n + } \n + } \n + connectionHandler . onHttpServerUpgrade ( settings ) ; \n - return ; \n - } \n - \n - if ( handlers ! = null ) { \n - final String name = ctx . pipeline ( ) . context ( connectionHandler ) . name ( ) ; \n - for ( int i = handlers . length - 1 ; i > = 0 ; i - - ) { \n - ctx . pipeline ( ) . addAfter ( name , null , handlers [ i ] ) ; \n - } \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2ServerUpgradeCodecTest . java \n + channel . writeInbound ( Http2CodecUtil . connectionPrefaceBuf ( ) ) ; \n + Http2FrameInboundWriter writer = new Http2FrameInboundWriter ( channel ) ; \n + writer . writeInboundSettings ( new Http2Settings ( ) ) ; \n + writer . writeInboundRstStream ( Http2CodecUtil . HTTP _ UPGRADE _ STREAM _ ID , Http2Error . CANCEL . code ( ) ) ; \n + \n + ByteBuf buf = channel . readOutbound ( ) ; \n + assertNotNull ( buf ) ; \n + buf . release ( ) ; \n + \n",Correctly handle http2 upgrades when Http2FrameCodec is used together… ( # 9318 ) \n Motivation : \n In the latest release we introduced Http2MultiplexHandler as a replacement of Http2MultiplexCodec . This did split the frame parsing from the multiplexing to allow a more flexible way to handle frames and to make the code cleaner . Unfortunally we did miss to special handle this in Http2ServerUpgradeCodec and so did not correctly add Http2MultiplexHandler to the pipeline before calling Http2FrameCodec . onHttpServerUpgrade ( . . . ) . This did lead to the situation that we did not correctly receive the event on the Http2MultiplexHandler and so did not correctly created the Http2StreamChannel for the upgrade stream . Because of this we ended up with an NPE if a frame was dispatched to the upgrade stream later on . \n Modifications : \n - Correctly add Http2MultiplexHandler to the pipeline before calling Http2FrameCodec . onHttpServerUpgrade ( . . . ) \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9314 .,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostStandardRequestDecoder . java \n + import io . netty . util . internal . PlatformDependent ; \n - } catch ( HttpPostRequestDecoder . ErrorDataDecoderException e ) { \n + } catch ( Throwable e ) { \n - throw e ; \n + PlatformDependent . throwException ( e ) ; \n + } catch ( IllegalArgumentException e ) { \n + / / error while decoding \n + undecodedChunk . readerIndex ( firstpos ) ; \n + throw new ErrorDataDecoderException ( e ) ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostRequestDecoderTest . java \n + @ Test ( expected = HttpPostRequestDecoder . ErrorDataDecoderException . class ) \n + public void testNotLeakDirectBufferWhenWrapIllegalArgumentException ( ) { \n + testNotLeakWhenWrapIllegalArgumentException ( Unpooled . directBuffer ( ) ) ; \n + } \n + \n + @ Test ( expected = HttpPostRequestDecoder . ErrorDataDecoderException . class ) \n + public void testNotLeakHeapBufferWhenWrapIllegalArgumentException ( ) { \n + testNotLeakWhenWrapIllegalArgumentException ( Unpooled . buffer ( ) ) ; \n + } \n + \n + private static void testNotLeakWhenWrapIllegalArgumentException ( ByteBuf buf ) { \n + buf . writeCharSequence ( "" = = "" , CharsetUtil . US _ ASCII ) ; \n + FullHttpRequest request = new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . POST , "" / "" , buf ) ; \n + try { \n + new HttpPostStandardRequestDecoder ( request ) ; \n + } finally { \n + assertTrue ( request . release ( ) ) ; \n + } \n + } \n + \n","Prevent any leaks when HttpPostStandardRequestDecoder constructor throws ( # 9837 ) \n Motivation : \n HttpPostStandardRequestDecoder may throw multiple different exceptions in the constructor which could lead to memory leaks . We need to guard against this by explicit catch all of them and rethrow after we released any allocated memory . \n Modifications : \n - Catch , destroy and rethrow in any case \n - Ensure we correctly wrap IllegalArgumentExceptions \n - Add unit tests \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9829",381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n + import java . net . NetworkInterface ; \n + import java . net . SocketException ; \n + import java . util . Enumeration ; \n - if ( NetUtil . isIpV4StackPreferred ( ) ) { \n + if ( NetUtil . isIpV4StackPreferred ( ) | | ! anyInterfaceSupportsIpV6 ( ) ) { \n + / * * \n + * Returns { @ code true } if any { @ link NetworkInterface } supports { @ code IPv6 } , { @ code false } otherwise . \n + * / \n + private static boolean anyInterfaceSupportsIpV6 ( ) { \n + try { \n + Enumeration < NetworkInterface > interfaces = NetworkInterface . getNetworkInterfaces ( ) ; \n + while ( interfaces . hasMoreElements ( ) ) { \n + NetworkInterface iface = interfaces . nextElement ( ) ; \n + Enumeration < InetAddress > addresses = iface . getInetAddresses ( ) ; \n + while ( addresses . hasMoreElements ( ) ) { \n + if ( addresses . nextElement ( ) instanceof Inet6Address ) { \n + return true ; \n + } \n + } \n + } \n + } catch ( SocketException e ) { \n + logger . debug ( "" Unable to detect if any interface supports IPv6 , assuming IPv4 - only "" , e ) ; \n + / / ignore \n + } \n + return false ; \n + } \n + \n",Use ResolvedAddressTypes . IPV4 _ ONLY in DnsNameResolver by default if n… ( # 9048 ) \n Motivation : \n To closely mimic what the JDK does we should not try to resolve AAAA records if the system itself does not support IPv6 at all as it is impossible to connect to this addresses later on . In this case we need to use ResolvedAddressTypes . IPV4 _ ONLY . \n Modifications : \n Add static method to detect if IPv6 is supported and if not use ResolvedAddressTypes . IPV4 _ ONLY . \n Result : \n More consistent behaviour between JDK and our resolver implementation .,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsResolveContext . java \n - this . ttl = min ( ttl , ttl ) ; \n + this . ttl = min ( this . ttl , ttl ) ; \n",Correctly calculate ttl for AuthoritativeNameServer when update existing records ( # 9051 ) \n Motivation : \n We did not correctly calculate the new ttl as we did forget to add ` this . ` \n Modifications : \n Add . this and so correctly calculate the TTL \n Result : \n Use correct TTL for authoritative nameservers when updating these .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - return OpenSslX509TrustManagerWrapper . wrapIfNeeded ( ( X509TrustManager ) m ) ; \n + if ( PlatformDependent . javaVersion ( ) > = 7 ) { \n + return OpenSslX509TrustManagerWrapper . wrapIfNeeded ( ( X509TrustManager ) m ) ; \n + } \n + return ( X509TrustManager ) m ; \n,Only try to use OpenSslX509TrustManagerWrapper when using Java 7 + ( # 9065 ) \n Motivation : \n We should only try to use OpenSslX509TrustManagerWrapper when using Java 7 + as otherwise it fail to init in it ' s static block as X509ExtendedTrustManager was only introduced in Java7 \n Modifications : \n Only call OpenSslX509TrustManagerWrapper if we use Java7 + \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9064 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslPrivateKeyMethod . java \n - * @ return the signed data \n + * @ return the signed data ( must not be { @ code null } ) \n - * @ return the decrypted data \n + * @ return the decrypted data ( must not be { @ code null } ) \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n + import java . security . SignatureException ; \n - return keyMethod . sign ( engine , signatureAlgorithm , digest ) ; \n + return verifyResult ( keyMethod . sign ( engine , signatureAlgorithm , digest ) ) ; \n - return keyMethod . decrypt ( engine , input ) ; \n + return verifyResult ( keyMethod . decrypt ( engine , input ) ) ; \n + \n + private static byte [ ] verifyResult ( byte [ ] result ) throws SignatureException { \n + if ( result = = null ) { \n + throw new SignatureException ( ) ; \n + } \n + return result ; \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslPrivateKeyMethodTest . java \n - public void testPrivateKeyMethodFails ( ) throws Exception { \n + public void testPrivateKeyMethodFailsBecauseOfException ( ) throws Exception { \n + testPrivateKeyMethodFails ( false ) ; \n + } \n + \n + @ Test \n + public void testPrivateKeyMethodFailsBecauseOfNull ( ) throws Exception { \n + testPrivateKeyMethodFails ( true ) ; \n + } \n + private void testPrivateKeyMethodFails ( final boolean returnNull ) throws Exception { \n + if ( returnNull ) { \n + return null ; \n + } \n",Throw SignatureException if OpenSslPrivateKeyMethod . * return null to prevent segfault ( # 9100 ) \n Motivation : \n While OpenSslPrivateKeyMethod . * should never return null we should still guard against it to prevent any possible segfault . \n Modifications : \n - Throw SignatureException if null is returned \n - Add unit test \n Result : \n No segfault when user returns null .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 3 "" \n docker \ docker - compose . centos - 6 . 112 . yaml \n - java _ version : "" zulu @ 1 . 12 . 0 "" \n + java _ version : "" adopt @ 1 . 12 . 0 - 1 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 2 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 3 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 3 "" \n docker \ docker - compose . centos - 7 . 112 . yaml \n - java _ version : "" zulu @ 1 . 12 . 0 "" \n + java _ version : "" adopt @ 1 . 12 . 0 - 1 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n docker \ docker - sync - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 202 - 08 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n",Update to latest java releases ( # 9101 ) \n Motivation : \n There were new releases of various Java versions . \n Modifications : \n Adjust used java versions of the latest releases and so use these on our CI \n Result : \n Use latest java versions on our CI .,381
"common \ src \ test \ java \ io \ netty \ util \ concurrent \ GlobalEventExecutorTest . java \n - @ Test \n + @ Test ( timeout = 5000 ) \n - Thread . sleep ( 1500 ) ; \n - \n - / / Ensure the thread stopped itself after running the task . \n - assertThat ( thread . isAlive ( ) , is ( false ) ) ; \n + thread . join ( ) ; \n - Thread . sleep ( 1500 ) ; \n + thread . join ( ) ; \n - / / Ensure the thread stopped itself after running the task . \n - assertThat ( thread . isAlive ( ) , is ( false ) ) ; \n - @ Test \n + @ Test ( timeout = 5000 ) \n - Thread . sleep ( 1500 ) ; \n - \n - / / Now it should be stopped . \n - assertThat ( thread . isAlive ( ) , is ( false ) ) ; \n + thread . join ( ) ; \n",Fix flaky GlobalEventExecutorTest . * ( # 9074 ) \n Motivation : \n In GlobalEventExecutorTest we used Thread . sleep ( . . . ) which can produce flaky results ( as seen on the CI ) . We should use another alternative during tests . \n Modifications : \n Replace Thread . sleep ( . . . ) with join ( ) \n Result : \n No more flaky GlobalEventExecutor tests .,381
"new file \n docker \ docker - compose . centos - 6 . graalvm1 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - 1 . 8 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + java _ version : "" graalvm @ 1 . 0 . 0 - 16 "" \n + \n + test : \n + image : netty : centos - 6 - 1 . 8 \n + \n + test - leak : \n + image : netty : centos - 6 - 1 . 8 \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - 1 . 8 \n + \n + shell : \n + image : netty : centos - 6 - 1 . 8 \n",Add docker - compose file to compile / test with graalvm ( # 9072 ) \n Motivation : \n We should try to compile / test with graalvm as well . \n Modifications : \n Add docker - compose file for graalvm \n Result : \n Be able to also compile / test with graalvm,381
pom . xml \n + < forbiddenapis . skip > true < / forbiddenapis . skip > \n + < testJvm / > \n - < testJavaHome > $ { env . JAVA _ HOME } < / testJavaHome > \n + < testJavaHome > $ { java . home } < / testJavaHome > \n + < testJvm > $ { testJavaHome } / bin / java < / testJvm > \n - < jvm > $ { testJavaHome } / bin / java < / jvm > \n + < jvm > $ { testJvm } < / jvm > \n,Adjust pom . xml to be able to build with graalvm ( # 9107 ) \n Motivation : \n When trying to use graalvm and build netty we currently fail because our build configuration is not compatible with it . \n Modification : \n - Skip plugins that are not supported when graal is used \n - Correctly configure surefire plugin for graal so it not produces a NPE \n Result : \n We can build and test with graalvm .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n + import java . io . IOException ; \n - if ( error instanceof ClosedChannelException ) { \n + / / To make it more consistent with AbstractChannel we handle all IOExceptions here . \n + if ( error instanceof IOException ) { \n + / / TODO : Once Http2StreamChannel extends DuplexChannel we should call shutdownOutput ( . . . ) \n,Http2MultiplexCodec . DefaultHttp2StreamChannel should handle ChannelConfig . isAutoClose ( ) in a consistent way as AbstractChannel ( # 9108 ) \n Motivation : \n Http2MultiplexCodec . DefaultHttp2StreamChannel currently only act on ClosedChannelException exceptions when checking for isAutoClose ( ) . We should widen the scope here to IOException to be more consistent with AbstractChannel . \n Modifications : \n Replace instanceof ClosedChannelException with instanceof IOException \n Result : \n More consistent handling of isAutoClose ( ),381
all \ pom . xml \n + < ! - - Just include the classes for the other platform so these are at least present in the netty - all artifact - - > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - transport - native - kqueue < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n + < ! - - Just include the classes for the other platform so these are at least present in the netty - all artifact - - > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - transport - native - epoll < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n + < ! - - Just include the classes for the other platform so these are at least present in the netty - all artifact - - > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - transport - native - epoll < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n + < ! - - Just include the classes for the other platform so these are at least present in the netty - all artifact - - > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - transport - native - epoll < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n,Always include classes from all native transports no matter on which platfrom netty - all is build ( # 9111 ) \n Motivation : \n While building netty - all we should always include all classes for native transports no matter if the native part can be build or not . This was it is easier to test locally with a installed snapshot of netty - all when the code that uses it does enable a specific native transport depending on if the native bits can be loaded or not . \n Modifications : \n Always include classes of native transports no matter on which platfrom we build . When a release is done we ensure we include the native bits by using the uber - staging profile . \n Result : \n Easier testing with netty - all snapshots .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - return new SSLHandshakeException ( errorString ) ; \n + \n + SSLHandshakeException exception = new SSLHandshakeException ( errorString ) ; \n + / / If we have a handshakeException stored already we should include it as well to help the user debug things . \n + if ( handshakeException ! = null ) { \n + exception . initCause ( handshakeException ) ; \n + handshakeException = null ; \n + } \n + return exception ; \n,Always include initial handshake exception when throwing SslHandshakeException ( # 9008 ) \n Motivation : \n A callback may already have stored a initial handshake exception in ReferenceCountedOpenSslEngine so we should include it when throwing a SslHandshakeException to ensure the user has all the infos when debugging . \n Modifications : \n Include initial handshake exception \n Result : \n Include all erros when throwing the SslHandshakeException .,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelOption . java \n + * \n + * @ deprecated use { @ link # valueOf ( String ) } . \n + @ Deprecated \n,Deprecate ChannelOption . newInstance ( . . . ) ( # 8997 ) \n Motivation : \n Deprecate ChannelOption . newInstance ( . . . ) as it is not used . \n Modifications : \n Deprecate ChannelOption . newInstance ( . . . ) as valueOf ( . . . ) should be used as a replacement . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8983 .,381
pom . xml \n - < tcnative . version > 2 . 0 . 27 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 28 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 28 . Final ( # 9846 ) \n Motivation : \n netty - tcnative 2 . 0 . 28 . Final was released \n Modifications : \n Update to latest version \n Result : \n Use latest version of netty - tcnative,381
transport - native - epoll \ src \ main \ c \ netty _ epoll _ native . c \n + / / Only support SYS _ recvmmsg for _ _ x86 _ 64 _ _ / _ _ i386 _ _ for now \n + # if defined ( _ _ x86 _ 64 _ _ ) \n + / / See https : / / github . com / torvalds / linux / blob / v5 . 4 / arch / x86 / entry / syscalls / syscall _ 64 . tbl \n + # elif defined ( _ _ i386 _ _ ) \n + / / See https : / / github . com / torvalds / linux / blob / v5 . 4 / arch / x86 / entry / syscalls / syscall _ 32 . tbl \n + # define SYS _ recvmmsg 337 \n + # else \n + # define SYS _ recvmmsg - 1 \n + # endif / / SYS _ recvmmsg \n + / / Only support SYS _ sendmmsg for _ _ x86 _ 64 _ _ / _ _ i386 _ _ for now \n + # if defined ( _ _ x86 _ 64 _ _ ) \n + / / See https : / / github . com / torvalds / linux / blob / v5 . 4 / arch / x86 / entry / syscalls / syscall _ 64 . tbl \n + # elif defined ( _ _ i386 _ _ ) \n + / / See https : / / github . com / torvalds / linux / blob / v5 . 4 / arch / x86 / entry / syscalls / syscall _ 32 . tbl \n + # define SYS _ sendmmsg 345 \n + # else \n + # define SYS _ sendmmsg - 1 \n + # endif / / SYS _ sendmmsg \n + if ( SYS _ sendmmsg = = - 1 ) { \n + return JNI _ FALSE ; \n + } \n + if ( SYS _ recvmmsg = = - 1 ) { \n + return JNI _ FALSE ; \n + } \n,"Correctly take architecture into account when define syscalls for recvmmsg and sendmmsg usage ( # 9844 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 9797 changed the code for recvmmsg and sendmmsg to use the syscalls directly to remvove the dependency on newer GLIBC versions . Unfortunally it made the assumption that the syscall numbers are the same for different architectures , which is not the case . \n Thanks to @ jayv for pointing it out \n Modifications : \n Add # if , # elif and # else declarations to ensure we pick the correct syscall number ( or not support if if the architecture is not supported atm ) . \n Result : \n Pick the correct syscall number depending on the architecture .",381
common \ pom . xml \n + < createSourcesJar > true < / createSourcesJar > \n + < shadeSourcesContent > true < / shadeSourcesContent > \n pom . xml \n - < version > 3 . 0 . 1 < / version > \n + < version > 3 . 2 . 0 < / version > \n - < ! - - \n - ~ This workaround prevents Maven from executing the ' generate - sources ' phase twice . \n - ~ See http : / / jira . codehaus . org / browse / MSOURCES - 13 \n - ~ and http : / / blog . peterlynch . ca / 2010 / 05 / maven - how - to - prevent - generate - sources . html \n - - - > \n - < phase > invalid < / phase > \n - < goals > \n - < goal > jar < / goal > \n - < / goals > \n - < / execution > \n - < execution > \n - < id > attach - sources - no - fork < / id > \n - < phase > package < / phase > \n + < phase > prepare - package < / phase > \n + < phase > prepare - package < / phase > \n - < version > 3 . 1 . 0 < / version > \n + < version > 3 . 2 . 1 < / version > \n,Include JCTools sources for shaded classes in the sources jar ( # 9838 ) \n Motivation : \n We should include the shaded sources for JCTools in our sources jar to make it easier to debug . \n Modifications : \n - Adjust plugin configuration to execute plugins in correct order \n - Update source plugin \n - Add configuration for shade plugin to generate source jar content \n Result : \n Fixes https : / / github . com / netty / netty / issues / 6640 .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ ConscryptOpenSslEngineInteropTest . java \n + @ Override \n + @ Test \n + public void testSessionAfterHandshakeKeyManagerFactory ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSessionAfterHandshakeKeyManagerFactory ( ) ; \n + } \n + \n + @ Override \n + @ Test \n + public void testSupportedSignatureAlgorithms ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSupportedSignatureAlgorithms ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ JdkOpenSslEngineInteroptTest . java \n + @ Override \n + @ Test \n + public void testSupportedSignatureAlgorithms ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSupportedSignatureAlgorithms ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslConscryptSslEngineInteropTest . java \n + @ Override \n + @ Test \n + public void testSupportedSignatureAlgorithms ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSupportedSignatureAlgorithms ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslEngineTest . java \n + @ Override \n + @ Test \n + public void testSupportedSignatureAlgorithms ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSupportedSignatureAlgorithms ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslJdkSslEngineInteroptTest . java \n + @ Override \n + @ Test \n + public void testSupportedSignatureAlgorithms ( ) throws Exception { \n + checkShouldUseKeyManagerFactory ( ) ; \n + super . testSupportedSignatureAlgorithms ( ) ; \n + } \n + \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslPrivateKeyMethodTest . java \n + import static io . netty . handler . ssl . OpenSslTestUtils . checkShouldUseKeyManagerFactory ; \n + checkShouldUseKeyManagerFactory ( ) ; \n + \n,Add missing assume checks to skip tests if KeyManagerFactory can not be used ( # 9148 ) \n Motivation : \n Depending on what OpenSSL library version we use / system property that is set we need to skip tests that use KeyManagerFactory . \n Modifications : \n Add missing assume checks for tests that use KeyManagerFactory . \n Result : \n All tests pass even if KeyManagerFactory is not supported,381
resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DefaultDnsServerAddressStreamProvider . java \n - if ( defaultNameServers . isEmpty ( ) ) { \n + / / Only try when using Java8 and lower as otherwise it will produce : \n + / / WARNING : Illegal reflective access by io . netty . resolver . dns . DefaultDnsServerAddressStreamProvider \n + if ( PlatformDependent . javaVersion ( ) < 9 & & defaultNameServers . isEmpty ( ) ) { \n,Only try to use reflection to access default nameservers when using Java8 and lower ( # 9157 ) \n Motivation : \n We should only try to use reflection to access default nameservers when using Java8 and lower as otherwise we will produce an Illegal reflective access warning like : \n WARNING : Illegal reflective access by io . netty . resolver . dns . DefaultDnsServerAddressStreamProvider \n Modifications : \n Add Java version check before try to use reflective access . \n Result : \n No more warning when Java9 + is used .,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 14 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 21 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 14 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 21 "" \n",Update to latest JDK13 EA release ( # 9166 ) \n Motivation : \n We should use the latest EA release when trying to compile with JDK13 . \n Modifications : \n Update to latest release \n Result : \n Test with latest release on the CI,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSsl . java \n - useKeyManagerFactory = AccessController . doPrivileged ( new PrivilegedAction < Boolean > ( ) { \n - @ Override \n - public Boolean run ( ) { \n - return SystemPropertyUtil . getBoolean ( \n - "" io . netty . handler . ssl . openssl . useKeyManagerFactory "" , true ) ; \n + boolean propertySet = SystemPropertyUtil . contains ( \n + "" io . netty . handler . ssl . openssl . useKeyManagerFactory "" ) ; \n + if ( ! IS _ BORINGSSL ) { \n + useKeyManagerFactory = SystemPropertyUtil . getBoolean ( \n + "" io . netty . handler . ssl . openssl . useKeyManagerFactory "" , true ) ; \n + \n + if ( propertySet ) { \n + logger . info ( "" System property "" + \n + "" ' io . netty . handler . ssl . openssl . useKeyManagerFactory ' "" + \n + "" is deprecated and so will be ignored in the future "" ) ; \n - } ) ; \n + } else { \n + if ( propertySet ) { \n + logger . info ( "" System property "" + \n + "" ' io . netty . handler . ssl . openssl . useKeyManagerFactory ' "" + \n + "" is deprecated and will be ignored when using BoringSSL "" ) ; \n + } \n + } \n",Log deprecation info message when using ' io . netty . handler . ssl . openssl . useKeyManagerFactory ' and ignore it when using BoringSSL ( # 9162 ) \n Motivation : \n When we added support for KeyManagerFactory we also allowed to disable it to make the change less risky . This was done years ago and so there is really no need to use the property anyway . \n Unfortunally due a change in netty - tcnative it is even not supported anymore when using BoringSSL . \n Modifications : \n - Log an info message to tell users that ' io . netty . handler . ssl . openssl . useKeyManagerFactory ' is deprecated when it is used \n - Ignore ' io . netty . handler . ssl . openssl . useKeyManagerFactory ' when BoringSSL is used . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9147 .,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketClientProtocolHandshakeHandler . java \n - import io . netty . util . concurrent . ScheduledFuture ; \n - import io . netty . util . internal . ThrowableUtil ; \n - private static final WebSocketHandshakeException HANDSHAKE _ TIMED _ OUT _ EXCEPTION = ThrowableUtil . unknownStackTrace ( \n - new WebSocketHandshakeException ( "" handshake timed out "" ) , \n - WebSocketClientProtocolHandshakeHandler . class , \n - "" channelActive ( . . . ) "" ) ; \n - if ( localHandshakePromise . tryFailure ( HANDSHAKE _ TIMED _ OUT _ EXCEPTION ) ) { \n + if ( localHandshakePromise . tryFailure ( new WebSocketHandshakeException ( "" handshake timed out "" ) ) ) { \n codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandshakeHandler . java \n - import io . netty . util . concurrent . ScheduledFuture ; \n - import io . netty . util . internal . ThrowableUtil ; \n - private static final WebSocketHandshakeException HANDSHAKE _ TIMED _ OUT _ EXCEPTION = ThrowableUtil . unknownStackTrace ( \n - new WebSocketHandshakeException ( "" handshake timed out "" ) , \n - WebSocketServerProtocolHandshakeHandler . class , \n - "" channelRead ( . . . ) "" ) ; \n - if ( localHandshakePromise . tryFailure ( HANDSHAKE _ TIMED _ OUT _ EXCEPTION ) ) { \n + if ( ! localHandshakePromise . isDone ( ) & & \n + localHandshakePromise . tryFailure ( new WebSocketHandshakeException ( "" handshake timed out "" ) ) ) { \n",Do not use static exceptions for websocket handshake timeout ( # 9174 ) \n Motivation : \n f17bfd0f64189d91302fbdd15103788bf9eabaa2 removed the usage of static exception instances to reduce the risk of OOME due addSupressed calls . We should do the same for exceptions used to signal handshake timeouts . \n Modifications : \n Do not use static instances \n Result : \n No risk of OOME due addSuppressed calls,381
"transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollDatagramChannel . java \n - final InternetProtocolFamily family ; \n - this ( null ) ; \n + this ( ( InternetProtocolFamily ) null ) ; \n - super ( family = = null ? \n + this ( family = = null ? \n - this . family = internetProtocolFamily ( family ) ; \n - config = new EpollDatagramChannelConfig ( this ) ; \n - } \n - \n - private static InternetProtocolFamily internetProtocolFamily ( InternetProtocolFamily family ) { \n - if ( family = = null ) { \n - return Socket . isIPv6Preferred ( ) ? InternetProtocolFamily . IPv6 : InternetProtocolFamily . IPv4 ; \n - } \n - return family ; \n - this ( new LinuxSocket ( fd ) , null ) ; \n + this ( new LinuxSocket ( fd ) ) ; \n - private EpollDatagramChannel ( LinuxSocket fd , InternetProtocolFamily family ) { \n + private EpollDatagramChannel ( LinuxSocket fd ) { \n - this . family = internetProtocolFamily ( family ) ; \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollDatagramChannelConfig . java \n - datagramChannel . socket . setNetworkInterface ( networkInterface , datagramChannel . family ) ; \n + datagramChannel . socket . setNetworkInterface ( networkInterface ) ; \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ LinuxSocket . java \n + private InternetProtocolFamily family ( ) { \n + return ipv6 ? InternetProtocolFamily . IPv6 : InternetProtocolFamily . IPv4 ; \n + } \n + \n - void setNetworkInterface ( NetworkInterface netInterface , InternetProtocolFamily family ) throws IOException { \n - InetAddress address = deriveInetAddress ( netInterface , family = = InternetProtocolFamily . IPv6 ) ; \n - if ( address . equals ( family = = InternetProtocolFamily . IPv4 ? INET _ ANY : INET6 _ ANY ) ) { \n - throw new IOException ( "" NetworkInterface does not support "" + family ) ; \n + void setNetworkInterface ( NetworkInterface netInterface ) throws IOException { \n + InetAddress address = deriveInetAddress ( netInterface , family ( ) = = InternetProtocolFamily . IPv6 ) ; \n + if ( address . equals ( family ( ) = = InternetProtocolFamily . IPv4 ? INET _ ANY : INET6 _ ANY ) ) { \n + throw new IOException ( "" NetworkInterface does not support "" + family ( ) ) ; \n",Correctly detect InternetProtocolFamily when EpollDatagramChannel is created with existing FileDescriptor ( # 9185 ) \n Motivation : \n When EpollDatagramChannel is created with an existing FileDescriptor we should detect the correct InternetProtocolFamily . \n Modifications : \n Obtain the InternetProtocolFamily from the given FD \n Result : \n Use correct InternetProtocolFamily when EpollDatagramChannel is created via existing FileDescriptor,381
"example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ client \ Http2ClientInitializer . java \n + import io . netty . handler . codec . http . HttpHeaderNames ; \n + import java . net . InetSocketAddress ; \n + \n + \n + \n + / / Set HOST header as the remote peer may require it . \n + InetSocketAddress remote = ( InetSocketAddress ) ctx . channel ( ) . remoteAddress ( ) ; \n + String hostString = remote . getHostString ( ) ; \n + if ( hostString = = null ) { \n + hostString = remote . getAddress ( ) . getHostAddress ( ) ; \n + } \n + upgradeRequest . headers ( ) . set ( HttpHeaderNames . HOST , hostString + ' : ' + remote . getPort ( ) ) ; \n + \n","Set the HOST header in Http2ClientInitializer when trying to start an upgrade request ( # 9177 ) \n Motivation : \n The io . netty . example . http2 . helloworld . client . Http2Client example should work in the h2c ( HTTP2 cleartext - non - TLS ) mode , which is the default for this example unless you set a - Dssl VM param . As we do not set the HOST header some servers do reject the upgrade request . \n Modifications : \n Set the HOST header \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9115 .",381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n + private final ChannelFutureListener bufferedStreamsListener = new ChannelFutureListener ( ) { \n + @ Override \n + public void operationComplete ( ChannelFuture future ) throws Exception { \n + numBufferedStreams - - ; \n + } \n + } ; \n - / / TODO ( buchgr ) : Once Http2FrameStream and Http2Stream are merged this is no longer necessary . \n - final ChannelPromise writePromise = ctx . newPromise ( ) ; \n - \n - headersFrame . isEndStream ( ) , writePromise ) ; \n - if ( writePromise . isDone ( ) ) { \n - notifyHeaderWritePromise ( writePromise , promise ) ; \n - } else { \n + headersFrame . isEndStream ( ) , promise ) ; \n + if ( ! promise . isDone ( ) ) { \n - \n - writePromise . addListener ( new ChannelFutureListener ( ) { \n - @ Override \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n - numBufferedStreams - - ; \n - \n - notifyHeaderWritePromise ( future , promise ) ; \n - } \n - } ) ; \n + promise . addListener ( bufferedStreamsListener ) ; \n - private static void notifyHeaderWritePromise ( ChannelFuture future , ChannelPromise promise ) { \n - Throwable cause = future . cause ( ) ; \n - if ( cause = = null ) { \n - promise . setSuccess ( ) ; \n - } else { \n - promise . setFailure ( cause ) ; \n - } \n - } \n - \n - void onHttp2UnknownStreamError ( @ SuppressWarnings ( "" unused "" ) ChannelHandlerContext ctx , Throwable cause , \n + private void onHttp2UnknownStreamError ( @ SuppressWarnings ( "" unused "" ) ChannelHandlerContext ctx , Throwable cause , \n - void onUpgradeEvent ( ChannelHandlerContext ctx , UpgradeEvent evt ) { \n + private void onUpgradeEvent ( ChannelHandlerContext ctx , UpgradeEvent evt ) { \n - void onHttp2StreamWritabilityChanged ( ChannelHandlerContext ctx , Http2FrameStream stream , \n + private void onHttp2StreamWritabilityChanged ( ChannelHandlerContext ctx , Http2FrameStream stream , \n",Reduce object creation on Http2FrameCodec ( # 9333 ) \n Motivation : \n We don ' t need the extra ChannelPromise when writing headers anymore in Http2FrameCodec . This also means we cal re - use a ChannelFutureListener and so not need to create new instances all the time . \n Modifications : \n - Just pass the original ChannelPromise when writing headers \n - Reuse the ChannelFutureListener \n Result : \n Two less objects created when writing headers for an not - yet created stream .,381
"codec \ src \ test \ java \ io \ netty \ handler \ codec \ compression \ SnappyFrameDecoderTest . java \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - 0x80 , 0x05 , 0x00 , 0x00 , ' n ' , ' e ' , ' t ' , ' t ' , ' y ' \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - 0x7f , 0x05 , 0x00 , 0x00 , ' n ' , ' e ' , ' t ' , ' t ' , ' y ' \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertTrue ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertTrue ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertFalse ( channel . writeInbound ( in ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n - channel . writeInbound ( in ) ; \n + assertTrue ( channel . writeInbound ( in ) ) ; \n + ByteBuf expected = Unpooled . wrappedBuffer ( new byte [ ] { ' n ' , ' e ' , ' t ' , ' t ' , ' y ' } ) ; \n + ByteBuf actual = channel . readInbound ( ) ; \n + assertEquals ( expected , actual ) ; \n + \n + expected . release ( ) ; \n + actual . release ( ) ; \n + assertFalse ( channel . finish ( ) ) ; \n",Correctly close ` EmbeddedChannel ` and release buffers in ` SnappyFrameDecoderTest ` ( # 9851 ) \n Motivation : \n We did not correctly close the ` EmbeddedChannel ` which would lead to not have ` handlerRemoved ( . . . ) ` called . This can lead to leaks . Beside this we also did not correctly consume produced data which could also show up as a leak . \n Modifications : \n - Always call ` EmbeddedChannel . finish ( ) ` \n - Ensure we consume all produced data and release it \n Result : \n No more leaks in test . This showed up in https : / / github . com / netty / netty / pull / 9850 # issuecomment - 562504863 .,381
resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DnsNameResolverTest . java \n - import static java . util . Collections . singletonMap ; \n + Socket socket = null ; \n - Socket socket = serverSocket . accept ( ) ; \n + socket = serverSocket . accept ( ) ; \n - socket . close ( ) ; \n + if ( socket ! = null ) { \n + socket . close ( ) ; \n + } \n,Fix flaky DnsNameResolverTest . testTruncatedWithTcpFallback ( # 9262 ) \n Motivation : \n testTruncatedWithTcpFallback was flacky as we may end up closing the socket before we could read all data . We should only close the socket after we succesfully read all data . \n Modifications : \n Move socket . close ( ) to finally block \n Result : \n Fix flaky test and so make the CI more stable again .,381
handler \ src \ main \ java \ io \ netty \ handler \ flow \ FlowControlHandler . java \n - return queue . isEmpty ( ) ; \n + return queue = = null | | queue . isEmpty ( ) ; \n - if ( queue . isEmpty ( ) & & consumed > 0 ) { \n - ctx . fireChannelReadComplete ( ) ; \n + if ( queue . isEmpty ( ) ) { \n + queue . recycle ( ) ; \n + queue = null ; \n + \n + if ( consumed > 0 ) { \n + ctx . fireChannelReadComplete ( ) ; \n + } \n,Recycle RecyclableArrayDeque as fast as possible in FlowControlHandler ( # 9263 ) \n Motivation : \n FlowControlHandler does use a recyclable ArrayDeque internally but only recycles it when the channel is closed . We should better recycle it once it is empty . \n Modifications : \n Recycle the deque as fast as possible \n Result : \n Less RecyclableArrayDeque instances .,381
"example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ frame \ server \ Http2ServerInitializer . java \n - ChannelHandlerContext thisCtx = pipeline . context ( this ) ; \n - pipeline . addAfter ( thisCtx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n + pipeline . addAfter ( ctx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ multiplex \ server \ Http2ServerInitializer . java \n - ChannelHandlerContext thisCtx = pipeline . context ( this ) ; \n - pipeline . addAfter ( thisCtx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n + pipeline . addAfter ( ctx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n example \ src \ main \ java \ io \ netty \ example \ http2 \ helloworld \ server \ Http2ServerInitializer . java \n - ChannelHandlerContext thisCtx = pipeline . context ( this ) ; \n - pipeline . addAfter ( thisCtx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n + pipeline . addAfter ( ctx . name ( ) , null , new HelloWorldHttp1Handler ( "" Direct . No Upgrade Attempted . "" ) ) ; \n",Cleanup http2 example code to make clear it is fine to just use ctx directly . ( # 9276 ) \n Motivation : \n In our example we did use pipeline . context ( this ) to obtain the context of the handler while it was already passed in via ctx . This could confuse users and give the impression that the context is no the same . \n Modifications : \n Just use ctx directly . \n Result : \n Fix confusion in example code . This was brought up on stackoverflow : \n https : / / stackoverflow . com / questions / 56711128 / when - is - a - channelhandlercontext - handed - to - a - channelhandler - not - that - channelhandl,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ EmptyByteBuf . java \n - return null ; \n + return StringUtil . EMPTY _ STRING ; \n buffer \ src \ test \ java \ io \ netty \ buffer \ EmptyByteBufTest . java \n + import io . netty . util . CharsetUtil ; \n + \n + @ Test \n + public void testGetCharSequence ( ) { \n + EmptyByteBuf empty = new EmptyByteBuf ( UnpooledByteBufAllocator . DEFAULT ) ; \n + assertEquals ( "" "" , empty . readCharSequence ( 0 , CharsetUtil . US _ ASCII ) ) ; \n + } \n + \n","EmptyByteBuf . getCharSequence ( 0 , . . . ) must return empty String ( # 9272 ) \n Motivation : \n At the moment EmptyByteBuf . getCharSequence ( 0 , . . . ) will return null while it must return a "" "" . \n Modifications : \n - Let EmptyByteBuf . getCharSequence ( 0 , . . . ) return "" "" \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9271 .",381
transport \ src \ test \ java \ io \ netty \ channel \ pool \ FixedChannelPoolTest . java \n + import io . netty . channel . ChannelPromise ; \n + final ChannelPromise closePromise = sc . newPromise ( ) ; \n - sc . close ( ) . syncUninterruptibly ( ) ; \n + sc . close ( closePromise ) . syncUninterruptibly ( ) ; \n + closePromise . awaitUninterruptibly ( ) ; \n,Ensure sc . close ( ) is executed before FixedChannelPoolTest . testCloseAsync ( ) returns ( # 9298 ) \n Motivation : \n We observed some test - failues sometimes in the CI which happened if sc . close ( ) was not completed before the next test did run . If this happened we would fail the bind ( . . . ) as the LocalAddress was still in use . \n Modifications : \n Await the close before return \n Result : \n Fixes race in testsuite which resulted in FixedChannelPoolTest . testAcquireNewConnection to fail if FixedChannelPoolTest . testCloseAsync ( ) did run before it .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodecBuilder . java \n + @ Override \n + public Http2FrameCodecBuilder autoAckSettingsFrame ( boolean autoAckSettings ) { \n + return super . autoAckSettingsFrame ( autoAckSettings ) ; \n + } \n + \n,Http2FrameCodecBuilder . autoAckSettingsFrame ( . . . ) must be public ( # 9295 ) \n Motivation : \n b3dba317d797e21cc253bb6ad6776307297f612e added AbstractHttp2ConnectionBuilder . autoAckSettingsFrame ( . . . ) as protected method and made it public for Http2MultiplexCodecBuilder . Unfortunally it did miss to also make it public in Http2FrameCodecBuilder \n Modifications : \n Correctly override autoAckSettingsFrame in Http2FrameCodecBuilder and so make it usable when building Http2FrameCodec . \n Result : \n Be able to also configure autoAckSettingsFrame when Http2FrameCodec is used .,381
"transport - native - unix - common \ src \ main \ c \ netty _ unix _ socket . c \n + / / We use 16 bytes as this allows us to fit ipv6 , ipv4 and ipv4 mapped ipv6 addresses in the array . \n + jbyte addressBytes [ 16 ] ; \n - / / Use GetPrimitiveArrayCritical and ReleasePrimitiveArrayCritical to signal the VM that we really would like \n - / / to not do a memory copy here . This is ok as we not do any blocking action here anyway . \n - / / This is important as the VM may suspend GC for the time ! \n - jbyte * addressBytes = ( * env ) - > GetPrimitiveArrayCritical ( env , address , 0 ) ; \n - if ( addressBytes = = NULL ) { \n - / / No memory left ? ! ? ! ? \n - netty _ unix _ errors _ throwOutOfMemoryError ( env ) ; \n + int len = ( * env ) - > GetArrayLength ( env , address ) ; \n + \n + if ( len > 16 ) { \n + / / This should never happen but let ' s guard against it anyway . \n + \n + / / We use GetByteArrayRegion ( . . . ) and copy into a small stack allocated buffer and NOT GetPrimitiveArrayCritical ( . . . ) \n + / / as there are still multiple GCLocker related bugs which are not fixed yet . \n + / / \n + / / For example : \n + / / https : / / bugs . openjdk . java . net / browse / JDK - 8048556 \n + / / https : / / bugs . openjdk . java . net / browse / JDK - 8057573 \n + / / https : / / bugs . openjdk . java . net / browse / JDK - 8057586 \n + ( * env ) - > GetByteArrayRegion ( env , address , 0 , len , addressBytes ) ; \n + \n - \n - ( * env ) - > ReleasePrimitiveArrayCritical ( env , address , addressBytes , JNI _ ABORT ) ; \n",Do not use GetPrimitiveArrayCritical ( . . . ) due multiple not - fixed bugs… ( # 8921 ) \n * Do not use GetPrimitiveArrayCritical ( . . . ) due multiple not - fixed bugs related to GCLocker \n Motivation : \n GetPrimitiveArrayCritical ( . . . ) may cause multiple not - fixed bugs related to the GCLocker while there is little gain for our use - case . We should just use GetByteArrayRegion ( . . . ) and copy into a small on - stack buffer . \n See also : \n - https : / / shipilev . net / jvm / anatomy - quarks / 9 - jni - critical - gclocker / # _ g1 \n - https : / / bugs . openjdk . java . net / browse / JDK - 8048556 \n - https : / / bugs . openjdk . java . net / browse / JDK - 8057573 \n - https : / / bugs . openjdk . java . net / browse / JDK - 8057586 \n Special thanks to @ jayv @ shipilev @ apangin for the pointers . \n Modifications : \n Replace GetPrimitiveArrayCritical ( . . . ) with GetByteArrayRegion ( . . . ) \n Result : \n Less risks hitting GCLocker related bugs .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslCachingKeyMaterialProvider . java \n + private final int maxCachedEntries ; \n + private volatile boolean full ; \n - OpenSslCachingKeyMaterialProvider ( X509KeyManager keyManager , String password ) { \n + OpenSslCachingKeyMaterialProvider ( X509KeyManager keyManager , String password , int maxCachedEntries ) { \n + this . maxCachedEntries = maxCachedEntries ; \n + if ( full ) { \n + return material ; \n + } \n + if ( cache . size ( ) > maxCachedEntries ) { \n + full = true ; \n + / / Do not cache . . . \n + return material ; \n + } \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslCachingX509KeyManagerFactory . java \n + import io . netty . util . internal . ObjectUtil ; \n + \n + private final int maxCachedEntries ; \n + \n + this ( factory , 1024 ) ; \n + } \n + \n + public OpenSslCachingX509KeyManagerFactory ( final KeyManagerFactory factory , int maxCachedEntries ) { \n + this . maxCachedEntries = ObjectUtil . checkPositive ( maxCachedEntries , "" maxCachedEntries "" ) ; \n + } \n + \n + OpenSslCachingKeyMaterialProvider newProvider ( String password ) { \n + return new OpenSslCachingKeyMaterialProvider ( \n + ReferenceCountedOpenSslContext . chooseX509KeyManager ( getKeyManagers ( ) ) , password , maxCachedEntries ) ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - X509KeyManager keyManager = chooseX509KeyManager ( factory . getKeyManagers ( ) ) ; \n - return new OpenSslCachingKeyMaterialProvider ( keyManager , password ) ; \n + return ( ( OpenSslCachingX509KeyManagerFactory ) factory ) . newProvider ( password ) ; \n - return new OpenSslKeyMaterialProvider ( keyManager , password ) ; \n + return new OpenSslKeyMaterialProvider ( chooseX509KeyManager ( factory . getKeyManagers ( ) ) , password ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslCachingKeyMaterialProviderTest . java \n - factory . getKeyManagers ( ) ) , password ) ; \n + factory . getKeyManagers ( ) ) , password , Integer . MAX _ VALUE ) ; \n",At the moment the cache provided by OpenSslCachingKeyMaterialProvider… ( # 9759 ) \n Motivation : \n At the moment te cache is not bound and so lead to huge memory consumpation . We should ensure its bound by default . \n Modifications : \n Ensure cache is bound \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9747 .,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslCachingX509KeyManagerFactory . java \n + import javax . net . ssl . X509ExtendedKeyManager ; \n - OpenSslCachingKeyMaterialProvider newProvider ( String password ) { \n + OpenSslKeyMaterialProvider newProvider ( String password ) { \n + X509KeyManager keyManager = ReferenceCountedOpenSslContext . chooseX509KeyManager ( getKeyManagers ( ) ) ; \n + if ( "" sun . security . ssl . X509KeyManagerImpl "" . equals ( keyManager . getClass ( ) . getName ( ) ) ) { \n + / / Don ' t do caching if X509KeyManagerImpl is used as the returned aliases are not stable and will change \n + / / between invocations . \n + return new OpenSslKeyMaterialProvider ( keyManager , password ) ; \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslCachingKeyMaterialProviderTest . java \n + import org . hamcrest . CoreMatchers ; \n + \n + @ Test \n + public void testCacheForSunX509 ( ) throws Exception { \n + OpenSslCachingX509KeyManagerFactory factory = new OpenSslCachingX509KeyManagerFactory ( \n + super . newKeyManagerFactory ( "" SunX509 "" ) ) ; \n + OpenSslKeyMaterialProvider provider = factory . newProvider ( PASSWORD ) ; \n + assertThat ( provider , \n + CoreMatchers . < OpenSslKeyMaterialProvider > instanceOf ( OpenSslCachingKeyMaterialProvider . class ) ) ; \n + } \n + \n + @ Test \n + public void testNotCacheForX509 ( ) throws Exception { \n + OpenSslCachingX509KeyManagerFactory factory = new OpenSslCachingX509KeyManagerFactory ( \n + super . newKeyManagerFactory ( "" PKIX "" ) ) ; \n + OpenSslKeyMaterialProvider provider = factory . newProvider ( PASSWORD ) ; \n + assertThat ( provider , CoreMatchers . not ( \n + CoreMatchers . < OpenSslKeyMaterialProvider > instanceOf ( OpenSslCachingKeyMaterialProvider . class ) ) ) ; \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslKeyMaterialProviderTest . java \n + return newKeyManagerFactory ( KeyManagerFactory . getDefaultAlgorithm ( ) ) ; \n + } \n + \n + protected KeyManagerFactory newKeyManagerFactory ( String algorithm ) throws Exception { \n - KeyManagerFactory . getInstance ( KeyManagerFactory . getDefaultAlgorithm ( ) ) ; \n + KeyManagerFactory . getInstance ( algorithm ) ; \n","Don ' t cache key material if sun . security . ssl . X509KeyManagerImpl is used ( # 9762 ) \n Motivation : \n sun . security . ssl . X509KeyManagerImpl will not use "" stable "" aliases and so aliases may be changed during invocations . This means caching is useless . Because of this we should disable the cache if its used . \n Modifications : \n - Disable caching if sun . security . ssl . X509KeyManagerImpl is used \n - Add tests \n Result : \n More protection against https : / / github . com / netty / netty / issues / 9747 .",381
pom . xml \n - < tcnative . version > 2 . 0 . 26 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 27 . Final < / tcnative . version > \n,Update to latest netty - tcnative release ( # 9763 ) \n Motivation : \n There is a new netty - tcnative release . We should use it . \n Modifications : \n Update to 2 . 0 . 27 \n Result : \n Use latest netty - tcnative release,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamChannelBootstrap . java \n - @ SuppressWarnings ( "" unchecked "" ) \n + / * * \n + * Open a new { @ link Http2StreamChannel } to use . \n + * @ return the { @ link Future } that will be notified once the channel was opened successfully or it failed . \n + * / \n + / * * \n + * Open a new { @ link Http2StreamChannel } to use and notifies the given { @ link Promise } . \n + * @ return the { @ link Future } that will be notified once the channel was opened successfully or it failed . \n + * / \n + @ SuppressWarnings ( "" deprecation "" ) \n + / * * \n + * @ deprecated should not be used directly . Use { @ link # open ( ) } or { @ link # open ( Promise ) } \n + * / \n + @ Deprecated \n - setChannelOptions ( channel , options , logger ) ; \n + setChannelOptions ( channel , options ) ; \n - Channel channel , Map < ChannelOption < ? > , Object > options , InternalLogger logger ) { \n + Channel channel , Map < ChannelOption < ? > , Object > options ) { \n - setChannelOption ( channel , e . getKey ( ) , e . getValue ( ) , logger ) ; \n + setChannelOption ( channel , e . getKey ( ) , e . getValue ( ) ) ; \n - Channel channel , ChannelOption < ? > option , Object value , InternalLogger logger ) { \n + Channel channel , ChannelOption < ? > option , Object value ) { \n",Add deprecation to Http2StreamChannelBootstrap . open0 ( . . . ) as it was marked as public by mistake ( # 9372 ) \n Motivation : \n Mark Http2StreamChannelBootstrap . open0 ( . . . ) as deprecated as the user should not use it . It was marked as public by mistake . \n Modifications : \n Add deprecation warning . \n Result : \n User will be aware the method should not be used directly .,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n + public void operationComplete ( ChannelFuture future ) { \n + @ Override \n + public void onHttpClientUpgrade ( ) throws Http2Exception { \n + super . onHttpClientUpgrade ( ) ; \n + / / Now make a new Http2FrameStream , set it ' s underlying Http2Stream , and initialize it . \n + newStream ( ) . setStreamAndProperty ( streamKey , connection ( ) . stream ( HTTP _ UPGRADE _ STREAM _ ID ) ) ; \n + } \n + \n - Http2FrameStream stream2 = stream . getProperty ( streamKey ) ; \n - if ( stream2 ! = null ) { \n - onHttp2StreamStateChanged ( ctx , stream2 ) ; \n - } \n + onHttp2StreamStateChanged0 ( stream ) ; \n + onHttp2StreamStateChanged0 ( stream ) ; \n + } \n + \n + private void onHttp2StreamStateChanged0 ( Http2Stream stream ) { \n codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - / / Now make a new FrameStream , set it ' s underlying Http2Stream , and initialize it . \n - DefaultHttp2FrameStream codecStream = newStream ( ) ; \n - codecStream . setStreamAndProperty ( streamKey , connection ( ) . stream ( HTTP _ UPGRADE _ STREAM _ ID ) ) ; \n - onHttp2UpgradeStreamInitialized ( ctx , codecStream ) ; \n + case HALF _ CLOSED _ LOCAL : \n + if ( stream . id ( ) = = HTTP _ UPGRADE _ STREAM _ ID ) { \n + onHttp2UpgradeStreamInitialized ( ctx , s ) ; \n + } \n + break ; \n",Move responsibility for creating upgrade stream to Http2FrameCodec ( # 9360 ) \n Motivation : \n The Http2FrameCodec should be responsible to create the upgrade stream . \n Modifications : \n Move code to create stream to Http2FrameCodec \n Result : \n More correct responsibility,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 21 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 28 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 21 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 - 28 "" \n",Use latest OpenJDK13 EA release ( # 9378 ) \n Motivation : \n A new EA release for OpenJDK13 was released \n Modifications : \n Update EA version \n Result : \n Use latest OpenJDK 13 EA on ci,381
"docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n docker \ docker - sync - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 03 "" \n + java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n",Update to adopt @ 1 . 8 . 212 - 04 ( # 9384 ) \n Motivation : \n We should use latest jdk 1 . 8 release \n Modifications : \n Update to adopt @ 1 . 8 . 212 - 04 \n Result : \n Use latest jdk 1 . 8 on ci,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamChannelBootstrap . java \n + / / Cache the ChannelHandlerContext to speed up open ( . . . ) operations . \n + private volatile ChannelHandlerContext multiplexCtx ; \n + \n - ChannelHandlerContext ctx = channel . pipeline ( ) . context ( Http2MultiplexCodec . class ) ; \n - if ( ctx = = null ) { \n - ctx = channel . pipeline ( ) . context ( Http2MultiplexHandler . class ) ; \n - } \n - if ( ctx = = null ) { \n - if ( channel . isActive ( ) ) { \n - promise . setFailure ( new IllegalStateException ( StringUtil . simpleClassName ( Http2MultiplexCodec . class ) + \n - "" must be in the ChannelPipeline of Channel "" + channel ) ) ; \n - } else { \n - promise . setFailure ( new ClosedChannelException ( ) ) ; \n - } \n - } else { \n + try { \n + ChannelHandlerContext ctx = findCtx ( ) ; \n + } catch ( Throwable cause ) { \n + promise . setFailure ( cause ) ; \n + private ChannelHandlerContext findCtx ( ) throws ClosedChannelException { \n + / / First try to use cached context and if this not work lets try to lookup the context . \n + ChannelHandlerContext ctx = this . multiplexCtx ; \n + if ( ctx ! = null & & ! ctx . isRemoved ( ) ) { \n + return ctx ; \n + } \n + ChannelPipeline pipeline = channel . pipeline ( ) ; \n + ctx = pipeline . context ( Http2MultiplexCodec . class ) ; \n + if ( ctx = = null ) { \n + ctx = pipeline . context ( Http2MultiplexHandler . class ) ; \n + } \n + if ( ctx = = null ) { \n + if ( channel . isActive ( ) ) { \n + throw new IllegalStateException ( StringUtil . simpleClassName ( Http2MultiplexCodec . class ) + "" or "" \n + + StringUtil . simpleClassName ( Http2MultiplexHandler . class ) \n + + "" must be in the ChannelPipeline of Channel "" + channel ) ; \n + } else { \n + throw new ClosedChannelException ( ) ; \n + } \n + } \n + this . multiplexCtx = ctx ; \n + return ctx ; \n + } \n + \n - * / \n + * / \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n + public void operationComplete ( ChannelFuture future ) { \n - private void init ( Channel channel ) throws Exception { \n + private void init ( Channel channel ) { \n",Cache the ChannelHandlerContext used in Http2StreamChannelBootstrap ( # 9382 ) \n Motivation : \n At the moment we lookup the ChannelHandlerContext used in Http2StreamChannelBootstrap each time the open ( . . . ) method is invoked . This is not needed and we can just cache it for later usage . \n Modifications : \n Cache ChannelHandlerContext in volatile field . \n Result : \n Speed up open ( . . . ) method implementation when called multiple times,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 3 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 4 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n + java _ version : "" adopt @ 1 . 8 . 222 - 10 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 3 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 4 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 3 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 4 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n + java _ version : "" adopt @ 1 . 8 . 222 - 10 "" \n docker \ docker - sync - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 212 - 04 "" \n + java _ version : "" adopt @ 1 . 8 . 222 - 10 "" \n",Update java versions ( # 9393 ) \n Motivation : \n There were new openjdk releases \n Modifications : \n Update releases to latest \n Result : \n Use latest openjdk versions on CI,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - Http2FrameStream stream2 = newStream ( ) . setStreamAndProperty ( streamKey , stream ) ; \n + DefaultHttp2FrameStream stream2 = newStream ( ) . setStreamAndProperty ( streamKey , stream ) ; \n - Http2FrameStream stream2 = stream . getProperty ( streamKey ) ; \n + DefaultHttp2FrameStream stream2 = stream . getProperty ( streamKey ) ; \n - private void onHttp2StreamWritabilityChanged ( ChannelHandlerContext ctx , Http2FrameStream stream , \n + private void onHttp2StreamWritabilityChanged ( ChannelHandlerContext ctx , DefaultHttp2FrameStream stream , \n - ctx . fireUserEventTriggered ( Http2FrameStreamEvent . writabilityChanged ( stream ) ) ; \n + ctx . fireUserEventTriggered ( stream . writabilityChanged ) ; \n - void onHttp2StreamStateChanged ( ChannelHandlerContext ctx , Http2FrameStream stream ) { \n - ctx . fireUserEventTriggered ( Http2FrameStreamEvent . stateChanged ( stream ) ) ; \n + void onHttp2StreamStateChanged ( ChannelHandlerContext ctx , DefaultHttp2FrameStream stream ) { \n + ctx . fireUserEventTriggered ( stream . stateChanged ) ; \n - Http2FrameStream frameStream = stream . getProperty ( streamKey ) ; \n + DefaultHttp2FrameStream frameStream = stream . getProperty ( streamKey ) ; \n + final Http2FrameStreamEvent stateChanged = Http2FrameStreamEvent . stateChanged ( this ) ; \n + final Http2FrameStreamEvent writabilityChanged = Http2FrameStreamEvent . writabilityChanged ( this ) ; \n + \n codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodec . java \n - final void onHttp2StreamStateChanged ( ChannelHandlerContext ctx , Http2FrameStream stream ) { \n - DefaultHttp2FrameStream s = ( DefaultHttp2FrameStream ) stream ; \n + final void onHttp2StreamStateChanged ( ChannelHandlerContext ctx , DefaultHttp2FrameStream stream ) { \n - onHttp2UpgradeStreamInitialized ( ctx , s ) ; \n + onHttp2UpgradeStreamInitialized ( ctx , stream ) ; \n - if ( s . attachment ! = null ) { \n + if ( stream . attachment ! = null ) { \n - new Http2MultiplexCodecStreamChannel ( s , inboundStreamHandler ) ) ; \n + new Http2MultiplexCodecStreamChannel ( stream , inboundStreamHandler ) ) ; \n - AbstractHttp2StreamChannel channel = ( AbstractHttp2StreamChannel ) s . attachment ; \n + AbstractHttp2StreamChannel channel = ( AbstractHttp2StreamChannel ) stream . attachment ; \n",Reuse Http2FrameStreamEvent instances to reduce GC pressure ( # 9392 ) \n Motivation : \n We can easily reuse the Http2FrameStreamEvent instances and so reduce GC pressure as there may be multiple events per streams over the life - time . \n Modifications : \n Reuse instances \n Result : \n Less allocations,381
pom . xml \n - < tcnative . artifactId > netty - tcnative - boringssl - static < / tcnative . artifactId > \n + < tcnative . artifactId > netty - tcnative < / tcnative . artifactId > \n,Revert back to depend on netty - tcnative \n Motivation : \n 4079189f6bd3e2c26ec443f24a204ffe144f1ada changed the dependency to netty - tcnative - borinssl - static but it should still be netty - tcnative . \n Modifications : \n Change back to netty - tcnative \n Result : \n Correct dependency is used,381
"codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpObjectAggregatorTest . java \n + import static org . junit . Assert . assertArrayEquals ; \n + assertThat ( response , instanceOf ( LastHttpContent . class ) ) ; \n + ReferenceCountUtil . release ( response ) ; \n + \n + \n + try { \n + embedder . writeInbound ( new DefaultHttpContent ( Unpooled . EMPTY _ BUFFER ) ) ; \n + fail ( ) ; \n + } catch ( Exception e ) { \n + assertThat ( e , instanceOf ( ClosedChannelException . class ) ) ; \n + / / expected \n + } \n + assertFalse ( embedder . writeInbound ( new DefaultHttpContent ( Unpooled . copiedBuffer ( new byte [ 8 ] ) ) ) ) ; \n + assertFalse ( embedder . writeInbound ( new DefaultHttpContent ( Unpooled . copiedBuffer ( new byte [ 8 ] ) ) ) ) ; \n + \n + / / Now start a new message and ensure we will not reject it again . \n + HttpRequest message2 = new DefaultHttpRequest ( HttpVersion . HTTP _ 1 _ 0 , HttpMethod . PUT , "" http : / / localhost "" ) ; \n + HttpUtil . setContentLength ( message , 2 ) ; \n + \n + assertFalse ( embedder . writeInbound ( message2 ) ) ; \n + assertNull ( embedder . readOutbound ( ) ) ; \n + assertFalse ( embedder . writeInbound ( new DefaultHttpContent ( Unpooled . copiedBuffer ( new byte [ ] { 1 } ) ) ) ) ; \n + assertNull ( embedder . readOutbound ( ) ) ; \n + assertTrue ( embedder . writeInbound ( new DefaultLastHttpContent ( Unpooled . copiedBuffer ( new byte [ ] { 2 } ) ) ) ) ; \n + assertNull ( embedder . readOutbound ( ) ) ; \n + \n + FullHttpRequest request = embedder . readInbound ( ) ; \n + assertEquals ( message2 . protocolVersion ( ) , request . protocolVersion ( ) ) ; \n + assertEquals ( message2 . method ( ) , request . method ( ) ) ; \n + assertEquals ( message2 . uri ( ) , request . uri ( ) ) ; \n + assertEquals ( 2 , HttpUtil . getContentLength ( request ) ) ; \n + \n + byte [ ] actual = new byte [ request . content ( ) . readableBytes ( ) ] ; \n + request . content ( ) . readBytes ( actual ) ; \n + assertArrayEquals ( new byte [ ] { 1 , 2 } , actual ) ; \n + request . release ( ) ; \n + \n + assertFalse ( embedder . finish ( ) ) ; \n codec \ src \ main \ java \ io \ netty \ handler \ codec \ MessageAggregator . java \n - aggregating = false ; \n",Correctly discard messages after oversized message is detected . ( # 9015 ) \n Motivation : \n 32563bfcc129ef9332f175c277e4f6b59fd37d8c introduced a regression in which we did now not longer discard the messages after we handled an oversized message . \n Modifications : \n - Do not set aggregating to false after handleOversizedMessage is called \n - Adjust unit tests to verify the behaviour is correct again . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9007 .,381
"transport \ src \ main \ java \ io \ netty \ channel \ embedded \ EmbeddedChannel . java \n + ChannelHandler . . . handlers ) { \n + this ( null , channelId , register , hasDisconnect , handlers ) ; \n + } \n + \n + / * * \n + * Create a new instance with the channel ID set to the given ID and the pipeline \n + * initialized with the specified handlers . \n + * \n + * @ param parent the parent { @ link Channel } of this { @ link EmbeddedChannel } . \n + * @ param channelId the { @ link ChannelId } that will be used to identify this channel \n + * @ param register { @ code true } if this { @ link Channel } is registered to the { @ link EventLoop } in the \n + * constructor . If { @ code false } the user will need to call { @ link # register ( ) } . \n + * @ param hasDisconnect { @ code false } if this { @ link Channel } will delegate { @ link # disconnect ( ) } \n + * to { @ link # close ( ) } , { @ link false } otherwise . \n + * @ param handlers the { @ link ChannelHandler } s which will be add in the { @ link ChannelPipeline } \n + * / \n + public EmbeddedChannel ( Channel parent , ChannelId channelId , boolean register , boolean hasDisconnect , \n - super ( null , channelId ) ; \n + super ( parent , channelId ) ; \n transport \ src \ test \ java \ io \ netty \ channel \ embedded \ EmbeddedChannelTest . java \n + @ Test \n + public void testParent ( ) { \n + EmbeddedChannel parent = new EmbeddedChannel ( ) ; \n + EmbeddedChannel channel = new EmbeddedChannel ( parent , EmbeddedChannelId . INSTANCE , true , false ) ; \n + assertSame ( parent , channel . parent ( ) ) ; \n + assertNull ( parent . parent ( ) ) ; \n + \n + assertFalse ( channel . finish ( ) ) ; \n + assertFalse ( parent . finish ( ) ) ; \n + } \n + \n",Allow to set parent Channel when constructing EmbeddedChannel ( # 9230 ) \n Motivation : \n Sometimes it is beneficial to be able to set a parent Channel in EmbeddedChannel if the handler that should be tested depend on the parent . \n Modifications : \n - Add another constructor which allows to specify a parent \n - Add unit tests \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9228 .,381
docker \ docker - compose . yaml \n - - ~ / . ssh : / root / . ssh \n - - ~ / . gnupg : / root / . gnupg \n - - . . : / code \n + - ~ / . ssh : / root / . ssh : delegated \n + - ~ / . gnupg : / root / . gnupg : delegated \n + - . . : / code : delegated \n - SANOTYPE _ USER \n - SANOTYPE _ PASSWORD \n - - ~ / . ssh : / root / . ssh \n - - ~ / . gnupg : / root / . gnupg \n - - . . : / code \n - - ~ / . m2 : / root / . m2 \n + - ~ / . ssh : / root / . ssh : delegated \n + - ~ / . gnupg : / root / . gnupg : delegated \n + - . . : / code : delegated \n + - ~ / . m2 : / root / . m2 : delegated \n,Use delegated docker mount option to speedup builds ( # 9441 ) \n Motivation : \n As we use the docker files for the CI we should use the delegated mount option to speed up builds . \n See https : / / docs . docker . com / docker - for - mac / osxfs - caching / # delegated \n Modifications : \n Use delegated mount option \n Result : \n Faster builds when using docker,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - public final void userEventTriggered ( ChannelHandlerContext ctx , Object evt ) throws Exception { \n + public final void userEventTriggered ( final ChannelHandlerContext ctx , final Object evt ) throws Exception { \n + \n + / / We schedule this on the EventExecutor to allow to have any extra handlers added to the pipeline \n + / / before we pass the event to the next handler . This is needed as the event may be called from within \n + / / handlerAdded ( . . . ) which will be run before other handlers will be added to the pipeline . \n + ctx . executor ( ) . execute ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + ctx . fireUserEventTriggered ( evt ) ; \n + } \n + } ) ; \n - return ; \n + } else { \n + ctx . fireUserEventTriggered ( evt ) ; \n - super . userEventTriggered ( ctx , evt ) ; \n",Delay Http2ConnectionPrefaceAndSettingsFrameWrittenEvent by one EventLoop tick when using the Http2FrameCodec ( # 9442 ) \n Motivation : \n We should delay the firing of the Http2ConnectionPrefaceAndSettingsFrameWrittenEvent by one EventLoop tick when using the Http2FrameCodec to ensure all handlers are added to the pipeline before the event is passed through it . \n This is needed to workaround a race that could happen when the preface is send in handlerAdded ( . . . ) but a later handler wants to act on the event . \n Modifications : \n Offload firing of the event to the EventExecutor . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9432 .,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 28 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 - 28 "" \n + java _ version : "" openjdk @ 1 . 13 . 0 "" \n",Use OpenJDK13 RC ( # 9457 ) \n Motivation : \n The first release canidate for OpenJDK13 was released . \n Modifications : \n Update version . \n Result : \n Use latest OpenJDK13 release,381
"codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2ControlFrameLimitEncoderTest . java \n + import java . util . ArrayDeque ; \n + import java . util . Queue ; \n + \n + private Queue < ChannelPromise > goAwayPromises = new ArrayDeque < ChannelPromise > ( ) ; \n + \n - return handlePromise ( invocationOnMock , 4 ) ; \n + ChannelPromise promise = invocationOnMock . getArgument ( 4 ) ; \n + goAwayPromises . offer ( promise ) ; \n + return promise ; \n + \n + / / Notify all goAway ChannelPromise instances now as these will also release the retained ByteBuf for the \n + / / debugData . \n + for ( ; ; ) { \n + ChannelPromise promise = goAwayPromises . poll ( ) ; \n + if ( promise = = null ) { \n + break ; \n + } \n + promise . setSuccess ( ) ; \n + } \n - private static void assertWriteFailure ( ChannelFuture future ) { \n - Http2Exception exception = ( Http2Exception ) future . cause ( ) ; \n - assertEquals ( ShutdownHint . HARD _ SHUTDOWN , exception . shutdownHint ( ) ) ; \n - assertEquals ( Http2Error . ENHANCE _ YOUR _ CALM , exception . error ( ) ) ; \n - } \n - \n",Fix ByteBuf leak in Http2ControlFrameLimitEncoderTest ( # 9466 ) \n Motivation : \n We recently introduced Http2ControlFrameLimitEncoderTest which did not correctly notify the goAway promises and so leaked buffers . \n Modifications : \n Correctly notify all promises and so release the debug data . \n Result : \n Fixes leak in HTTP2 test,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketClientHandshakerFactory . java \n - maxFramePayloadLength , true , false , - 1 ) ; \n + maxFramePayloadLength , performMasking , allowMaskMismatch , - 1 ) ; \n",Correctly respect mask parameters in all WebSocketClientHandshakerFactory # newHandshaker ( . . . ) methods ( # 9464 ) \n Motivation : \n We did not correctly pass the mask parameters in all cases . \n Modifications : \n Correctly pass on parameters \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9463 .,381
resolver - dns \ src \ test \ java \ io \ netty \ resolver \ dns \ DnsNameResolverTest . java \n - Socket socket = null ; \n + serverSocket . setReuseAddress ( true ) ; \n - socket = serverSocket . accept ( ) ; \n + Socket socket = serverSocket . accept ( ) ; \n - socket . getOutputStream ( ) . close ( ) ; \n + / / Let ' s wait until we received the envelope before closing the socket . \n + envelopeFuture . syncUninterruptibly ( ) ; \n + \n + socket . close ( ) ; \n + serverSocket . close ( ) ; \n - if ( socket ! = null ) { \n - socket . close ( ) ; \n - } \n - if ( serverSocket ! = null ) { \n - serverSocket . close ( ) ; \n - } \n,DnsNameResolverTest . testTruncated0 ( . . . ) should only close socket once envelope is received ( # 9469 ) \n Motivation : \n We should only ever close the underlying tcp socket once we received the envelope to ensure we never race in the test . \n Modifications : \n - Only close socket once we received the envelope \n - Set REUSE _ ADDR \n Result : \n More robust test,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2EmptyDataFrameConnectionDecoder . java \n - Http2EmptyDataFrameConnectionDecoder ( Http2ConnectionDecoder delegate , int maxConsecutiveEmptyFrames ) { \n + Http2EmptyDataFrameConnectionDecoder ( Http2ConnectionDecoder delegate , int maxConsecutiveEmptyFrames ) { \n + \n + @ Override \n + public Http2FrameListener frameListener ( ) { \n + Http2FrameListener frameListener = frameListener0 ( ) ; \n + / / Unwrap the original Http2FrameListener as we add this decoder under the hood . \n + if ( frameListener instanceof Http2EmptyDataFrameListener ) { \n + return ( ( Http2EmptyDataFrameListener ) frameListener ) . listener ; \n + } \n + return frameListener ; \n + } \n + \n + / / Package - private for testing \n + Http2FrameListener frameListener0 ( ) { \n + return super . frameListener ( ) ; \n + } \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2EmptyDataFrameConnectionDecoderTest . java \n - assertThat ( decoder . frameListener ( ) , CoreMatchers . instanceOf ( Http2EmptyDataFrameListener . class ) ) ; \n + assertThat ( decoder . frameListener ( ) , \n + CoreMatchers . not ( CoreMatchers . instanceOf ( Http2EmptyDataFrameListener . class ) ) ) ; \n + assertThat ( decoder . frameListener0 ( ) , CoreMatchers . instanceOf ( Http2EmptyDataFrameListener . class ) ) ; \n",Http2EmptyDataFrameConnectionDecoder . frameListener ( ) should return unwrapped Http2FrameListener ( # 9467 ) \n Motivation : \n As we decorate the Http2FrameListener under the covers we should ensure the user can still access the original Http2FrameListener . \n Modifications : \n - Unwrap the Http2FrameListener in frameListener ( ) \n - Add unit test \n Result : \n Less suprises for users .,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ AbstractHttp2StreamChannel . java \n + updateLocalWindowIfNeeded ( ) ; \n + \n - updateLocalWindowIfNeeded ( ) ; \n - \n,HTTP2 : Update local flow - controller on Channel . read ( ) if needed ( # 9400 ) \n Motivation : \n We should better update the flow - controller on Channel . read ( ) to reduce overhead and memory overhead . \n See https : / / github . com / netty / netty / pull / 9390 # issuecomment - 513008269 \n Modifications : \n Move updateLocalWindowIfNeeded ( ) to doBeginRead ( ) \n Result : \n Reduce memory overhead,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandshakeHandler . java \n + / / Ensure we set the handshaker and replace this handler before we \n + / / trigger the actual handshake . Otherwise we may receive websocket bytes in this handler \n + / / before we had a chance to replace it . \n + / / \n + / / See https : / / github . com / netty / netty / issues / 9471 . \n + WebSocketServerProtocolHandler . setHandshaker ( ctx . channel ( ) , handshaker ) ; \n + ctx . pipeline ( ) . replace ( this , "" WS403Responder "" , \n + WebSocketServerProtocolHandler . forbiddenHttpRequestResponder ( ) ) ; \n + \n - WebSocketServerProtocolHandler . setHandshaker ( ctx . channel ( ) , handshaker ) ; \n - ctx . pipeline ( ) . replace ( this , "" WS403Responder "" , \n - WebSocketServerProtocolHandler . forbiddenHttpRequestResponder ( ) ) ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandlerTest . java \n + @ Test \n + public void testWebSocketServerProtocolHandshakeHandlerReplacedBeforeHandshake ( ) throws Exception { \n + EmbeddedChannel ch = createChannel ( new MockOutboundHandler ( ) ) ; \n + ChannelHandlerContext handshakerCtx = ch . pipeline ( ) . context ( WebSocketServerProtocolHandshakeHandler . class ) ; \n + ch . pipeline ( ) . addLast ( new ChannelInboundHandlerAdapter ( ) { \n + @ Override \n + public void userEventTriggered ( ChannelHandlerContext ctx , Object evt ) throws Exception { \n + if ( evt instanceof WebSocketServerProtocolHandler . HandshakeComplete ) { \n + / / We should have removed the handler already . \n + assertNull ( ctx . pipeline ( ) . context ( WebSocketServerProtocolHandshakeHandler . class ) ) ; \n + } \n + } \n + } ) ; \n + writeUpgradeRequest ( ch ) ; \n + \n + FullHttpResponse response = responses . remove ( ) ; \n + assertEquals ( SWITCHING _ PROTOCOLS , response . status ( ) ) ; \n + response . release ( ) ; \n + assertNotNull ( WebSocketServerProtocolHandler . getHandshaker ( handshakerCtx . channel ( ) ) ) ; \n + assertFalse ( ch . finish ( ) ) ; \n + } \n + \n",Ensure we replace WebSocketServerProtocolHandshakeHandler before doing the handshake ( # 9472 ) \n Motivation : \n We need to ensure we replace WebSocketServerProtocolHandshakeHandler before doing the actual handshake as the handshake itself may complete directly and so forward pending bytes through the pipeline . \n Modifications : \n Replace the handler before doing the actual handshake . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9471 .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ AmazonCorrettoSslEngineTest . java \n + \n + @ Override \n + protected boolean mySetupMutualAuthServerIsValidException ( Throwable cause ) { \n + / / TODO ( scott ) : work around for a JDK issue . The exception should be SSLHandshakeException . \n + return super . mySetupMutualAuthServerIsValidException ( cause ) | | causedBySSLException ( cause ) ; \n + } \n,Use same JDK SSL test workaround when using ACCP as when just using the JDK SSL implementation ( # 9490 ) \n Motivation : \n 14607979f6db074247d764cc4583461bcd298719 added tests for using ACCP but did miss to use the same unwrapping technique of exceptions as JdkSslEngineTest . This can lead to test - failures on specific JDK versions \n Modifications : \n Add the same unwrapping code \n Result : \n No more test failures,381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n - / / This code on Java 9 + yields a warning about illegal reflective access that will be denied in \n - / / a future release . There doesn ' t seem to be a better way to get search domains for Windows yet . \n - Class < ? > configClass = Class . forName ( "" sun . net . dns . ResolverConfiguration "" ) ; \n - Method open = configClass . getMethod ( "" open "" ) ; \n - Method nameservers = configClass . getMethod ( "" searchlist "" ) ; \n - Object instance = open . invoke ( null ) ; \n - \n - return ( List < String > ) nameservers . invoke ( instance ) ; \n + / / Only try if not using Java9 and later \n + / / See https : / / github . com / netty / netty / issues / 9500 \n + if ( PlatformDependent . javaVersion ( ) < 9 ) { \n + / / This code on Java 9 + yields a warning about illegal reflective access that will be denied in \n + / / a future release . There doesn ' t seem to be a better way to get search domains for Windows yet . \n + Class < ? > configClass = Class . forName ( "" sun . net . dns . ResolverConfiguration "" ) ; \n + Method open = configClass . getMethod ( "" open "" ) ; \n + Method nameservers = configClass . getMethod ( "" searchlist "" ) ; \n + Object instance = open . invoke ( null ) ; \n + \n + return ( List < String > ) nameservers . invoke ( instance ) ; \n + } \n + return Collections . emptyList ( ) ; \n",Do not try to retrieve domain search list via reflection hack on windows when using Java9 and later ( # 9511 ) \n Motivation : \n We currently try to access the the domain search list via reflection on windows which will print a illegal access warning when using Java9 and later . \n Modifications : \n Add a guard against the used java version . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9500 .,381
"all \ pom . xml \n - < includes > io / netty / * * , META - INF / native / * * < / includes > \n + < includes > io / netty / * * , META - INF / native / * * , META - INF / native - image / * * < / includes > \n",Include native - image properties in the netty - all jar ( # 9518 ) \n Motivation : \n We need to also include the native - image configuration files in the netty all jar to be able to use it with GraalVM native . \n Modifications : \n Add files in META - INF / native - image as well \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9514,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostStandardRequestDecoder . java \n - if ( request instanceof HttpContent ) { \n - / / Offer automatically if the given request is als type of HttpContent \n - / / See # 1089 \n - offer ( ( HttpContent ) request ) ; \n - } else { \n - undecodedChunk = buffer ( ) ; \n - parseBody ( ) ; \n + try { \n + if ( request instanceof HttpContent ) { \n + / / Offer automatically if the given request is als type of HttpContent \n + / / See # 1089 \n + offer ( ( HttpContent ) request ) ; \n + } else { \n + undecodedChunk = buffer ( ) ; \n + parseBody ( ) ; \n + } \n + } catch ( HttpPostRequestDecoder . ErrorDataDecoderException e ) { \n + destroy ( ) ; \n + throw e ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostRequestDecoderTest . java \n + \n + @ Test ( expected = HttpPostRequestDecoder . ErrorDataDecoderException . class ) \n + public void testNotLeak ( ) { \n + FullHttpRequest request = new DefaultFullHttpRequest ( HttpVersion . HTTP _ 1 _ 1 , HttpMethod . POST , "" / "" , \n + Unpooled . copiedBuffer ( "" a = 1 & & b = 2 "" , CharsetUtil . US _ ASCII ) ) ; \n + try { \n + new HttpPostStandardRequestDecoder ( request ) ; \n + } finally { \n + assertTrue ( request . release ( ) ) ; \n + } \n + } \n",HttpPostStandardRequestDecoder leaks memory when constructor throws ErrorDataDecoderException . ( # 9517 ) \n Motivation : \n Currently when HttpPostStandardRequestDecoder throws a ErrorDataDecoderException during construction we leak memory . We need to ensure all is released correctly . \n Modifications : \n - Call destroy ( ) if parseBody ( ) throws and rethrow the ErrorDataDecoderException \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9513 .,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslPrivateKeyMethodTest . java \n - GROUP . shutdownGracefully ( ) ; \n - CERT . delete ( ) ; \n - EXECUTOR . shutdown ( ) ; \n + if ( OpenSsl . isBoringSSL ( ) ) { \n + GROUP . shutdownGracefully ( ) ; \n + CERT . delete ( ) ; \n + EXECUTOR . shutdown ( ) ; \n + } \n,Fix NPE in OpenSslPrivateKeyMethodTest . destroy ( ) when BoringSSL is not used \n Motivation : \n 4079189f6bd3e2c26ec443f24a204ffe144f1ada introduced OpenSslPrivateKeyMethodTest which will only be run when BoringSSL is used . As the assumeTrue ( . . . ) also guards the init of the static fields we need to ensure we only try to destroy these if BoringSSL is used as otherwise it will produce a NPE . \n Modifications : \n Check if BoringSSL is used before trying to destroy the resources . \n Result : \n No more NPE when BoringSSL is not used .,381
"codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2ConnectionRoundtripTest . java \n - final Http2Headers headers = dummyHeaders ( ) ; \n - runInChannel ( clientChannel , new Http2Runnable ( ) { \n - @ Override \n - public void run ( ) throws Http2Exception { \n - http2Client . encoder ( ) . writeHeaders ( ctx ( ) , streamId , headers , CONNECTION _ STREAM _ ID , \n - DEFAULT _ PRIORITY _ WEIGHT , false , 0 , false , newPromise ( ) ) ; \n - http2Client . encoder ( ) . writeRstStream ( ctx ( ) , streamId , Http2Error . CANCEL . code ( ) , newPromise ( ) ) ; \n - http2Client . flush ( ctx ( ) ) ; \n - } \n - } ) ; \n - \n + final Http2Headers headers = dummyHeaders ( ) ; \n + runInChannel ( clientChannel , new Http2Runnable ( ) { \n + @ Override \n + public void run ( ) throws Http2Exception { \n + http2Client . encoder ( ) . writeHeaders ( ctx ( ) , streamId , headers , CONNECTION _ STREAM _ ID , \n + DEFAULT _ PRIORITY _ WEIGHT , false , 0 , false , newPromise ( ) ) ; \n + http2Client . encoder ( ) . writeRstStream ( ctx ( ) , streamId , Http2Error . CANCEL . code ( ) , newPromise ( ) ) ; \n + http2Client . flush ( ctx ( ) ) ; \n + } \n + } ) ; \n + \n",Ensure we finish setup mock before we use it in Http2ConnectionRoundtripTest . headersWriteForPeerStreamWhichWasResetShouldNotGoAway ( # 9645 ) \n Motivation : \n We did dispatch the client code before we did finish setup the mock and so may end up with org . mockito . exceptions . misusing . UnfinishedStubbingException if the connect happens quickly enough . \n See https : / / ci . netty . io / job / netty - centos6 - java8 - prb / 1637 / testReport / junit / io . netty . handler . codec . http2 / Http2ConnectionRoundtripTest / headersWriteForPeerStreamWhichWasResetShouldNotGoAway / \n Modifications : \n First finish setup the mock and the dispatch . \n Result : \n Fix flacky test,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 0 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" openjdk @ 1 . 13 . 0 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 0 "" \n",Use adopt @ 1 . 13 . 0 - 0 when building with Java 13 ( # 9641 ) \n Motivation : \n We should use adaptjdk 13 and not oracle openjdk 13 when building with Java 13 \n Modifications : \n Use adopt @ 1 . 13 . 0 - 0 \n Result : \n More consistent java vendor usage,381
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetectorFactory . java \n - import java . security . AccessController ; \n - import java . security . PrivilegedAction ; \n - customLeakDetector = AccessController . doPrivileged ( new PrivilegedAction < String > ( ) { \n - @ Override \n - public String run ( ) { \n - return SystemPropertyUtil . get ( "" io . netty . customResourceLeakDetector "" ) ; \n - } \n - } ) ; \n + customLeakDetector = SystemPropertyUtil . get ( "" io . netty . customResourceLeakDetector "" ) ; \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslContext . java \n - import java . security . AccessController ; \n - import java . security . PrivilegedAction ; \n - private static final int DEFAULT _ BIO _ NON _ APPLICATION _ BUFFER _ SIZE = \n - AccessController . doPrivileged ( new PrivilegedAction < Integer > ( ) { \n - @ Override \n - public Integer run ( ) { \n - return Math . max ( 1 , \n - SystemPropertyUtil . getInt ( "" io . netty . handler . ssl . openssl . bioNonApplicationBufferSize "" , \n - 2048 ) ) ; \n - } \n - } ) ; \n + private static final int DEFAULT _ BIO _ NON _ APPLICATION _ BUFFER _ SIZE = Math . max ( 1 , \n + SystemPropertyUtil . getInt ( "" io . netty . handler . ssl . openssl . bioNonApplicationBufferSize "" , \n + 2048 ) ) ; \n - String dhKeySize = AccessController . doPrivileged ( new PrivilegedAction < String > ( ) { \n - @ Override \n - public String run ( ) { \n - return SystemPropertyUtil . get ( "" jdk . tls . ephemeralDHKeySize "" ) ; \n - } \n - } ) ; \n + String dhKeySize = SystemPropertyUtil . get ( "" jdk . tls . ephemeralDHKeySize "" ) ; \n",No need to explicit use the AccessController when SystemPropertyUtil is used ( # 9577 ) \n Motivation : \n SystemPropertyUtil already uses the AccessController internally so not need to wrap its usage with AccessController as well . \n Modifications : \n Remove explicit AccessController usage when SystemPropertyUtil is used . \n Result : \n Code cleanup,381
testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ DatagramUnicastTest . java \n + assertNotNull ( cc . localAddress ( ) ) ; \n + assertNotNull ( cc . remoteAddress ( ) ) ; \n + \n + assertNotNull ( cc . localAddress ( ) ) ; \n + assertNull ( cc . remoteAddress ( ) ) ; \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollChannel . java \n + void resetCachedAddresses ( ) { \n + local = socket . localAddress ( ) ; \n + remote = socket . remoteAddress ( ) ; \n + } \n + \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollDatagramChannel . java \n + resetCachedAddresses ( ) ; \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueChannel . java \n + void resetCachedAddresses ( ) { \n + local = socket . localAddress ( ) ; \n + remote = socket . remoteAddress ( ) ; \n + } \n + \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ KQueueDatagramChannel . java \n + resetCachedAddresses ( ) ; \n transport \ src \ main \ java \ io \ netty \ channel \ AbstractChannel . java \n + / / Reset remoteAddress and localAddress \n + remoteAddress = null ; \n + localAddress = null ; \n,Correctly reset cached local and remote address when disconnect ( ) is called ( # 9545 ) \n Motivation : \n We should correctly reset the cached local and remote address when a Channel . disconnect ( ) is called and the channel has a notion of disconnect vs close ( for example DatagramChannel implementations ) . \n Modifications : \n - Correctly reset cached kicak abd remote address \n - Update testcase to cover it and so ensure all transports work in a consistent way \n Result : \n Correctly handle disconnect ( ),381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslEngineTest . java \n + import javax . net . ssl . SSLEngineResult . HandshakeStatus ; \n + import static org . junit . Assert . assertNotEquals ; \n + private static void runTasksIfNeeded ( SSLEngine engine ) { \n + if ( engine . getHandshakeStatus ( ) = = HandshakeStatus . NEED _ TASK ) { \n + for ( ; ; ) { \n + Runnable task = engine . getDelegatedTask ( ) ; \n + if ( task = = null ) { \n + assertNotEquals ( HandshakeStatus . NEED _ TASK , engine . getHandshakeStatus ( ) ) ; \n + break ; \n + } \n + task . run ( ) ; \n + } \n + } \n + } \n + \n + runTasksIfNeeded ( clientEngine ) ; \n + runTasksIfNeeded ( serverEngine ) ; \n + \n + runTasksIfNeeded ( clientEngine ) ; \n + runTasksIfNeeded ( serverEngine ) ; \n + \n - byte [ ] serverRandom = SSL . getServerRandom ( ( ( OpenSslEngine ) serverEngine ) . sslPointer ( ) ) ; \n - byte [ ] clientRandom = SSL . getClientRandom ( ( ( OpenSslEngine ) clientEngine ) . sslPointer ( ) ) ; \n - byte [ ] serverMasterKey = SSL . getMasterKey ( ( ( OpenSslEngine ) serverEngine ) . sslPointer ( ) ) ; \n - byte [ ] clientMasterKey = SSL . getMasterKey ( ( ( OpenSslEngine ) clientEngine ) . sslPointer ( ) ) ; \n + byte [ ] serverRandom = SSL . getServerRandom ( unwrapEngine ( serverEngine ) . sslPointer ( ) ) ; \n + byte [ ] clientRandom = SSL . getClientRandom ( unwrapEngine ( clientEngine ) . sslPointer ( ) ) ; \n + byte [ ] serverMasterKey = SSL . getMasterKey ( unwrapEngine ( serverEngine ) . sslPointer ( ) ) ; \n + byte [ ] clientMasterKey = SSL . getMasterKey ( unwrapEngine ( clientEngine ) . sslPointer ( ) ) ; \n - ( ( OpenSslContext ) context ) . setUseTasks ( useTasks ) ; \n + if ( context instanceof OpenSslContext ) { \n + ( ( OpenSslContext ) context ) . setUseTasks ( useTasks ) ; \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngineTest . java \n - ( ( ReferenceCountedOpenSslContext ) context ) . setUseTasks ( useTasks ) ; \n + if ( context instanceof ReferenceCountedOpenSslContext ) { \n + ( ( ReferenceCountedOpenSslContext ) context ) . setUseTasks ( useTasks ) ; \n + } \n","Fix * SslEngineTest to not throw ClassCastException and pass in all cases ( # 9588 ) \n Motivation : \n Due some bug we did endup with ClassCastExceptions in some cases . Beside this we also did not correctly handle the case when ReferenceCountedOpenSslEngineTest did produce tasks to run in on test . \n Modifications : \n - Correctly unwrap the engine before to fix ClassCastExceptions \n - Run delegated tasks when needed . \n Result : \n All tests pass with different OpenSSL implementations ( OpenSSL , BoringSSL etc )",381
pom . xml \n - < tcnative . version > 2 . 0 . 25 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 26 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 26 . Final ( # 9589 ) \n Motivation : \n We just released a new version of netty - tcnative . \n Modifications : \n Bump up to netty - tcnative 2 . 0 . 26 . Final \n Result : \n Use latest netty - tcnative release,381
"transport - native - kqueue \ src \ main \ c \ netty _ kqueue _ bsdsocket . c \n - static jclass stringCls = NULL ; \n + static jclass stringClass = NULL ; \n - jobjectArray resultArray = ( * env ) - > NewObjectArray ( env , 2 , stringCls , NULL ) ; \n + jobjectArray resultArray = ( * env ) - > NewObjectArray ( env , 2 , stringClass , NULL ) ; \n - stringCls = ( * env ) - > FindClass ( env , "" java / lang / String "" ) ; \n + jclass stringCls = ( * env ) - > FindClass ( env , "" java / lang / String "" ) ; \n + if ( ( stringClass = ( * env ) - > NewGlobalRef ( env , stringCls ) ) = = NULL ) { \n + / / out - of - memory ! \n + netty _ unix _ errors _ throwOutOfMemoryError ( env ) ; \n + return JNI _ ERR ; \n + } \n + if ( stringClass ! = NULL ) { \n + ( * env ) - > DeleteGlobalRef ( env , stringClass ) ; \n + stringClass = NULL ; \n + } \n",We need to use NewGloblRef when caching jclass instances ( # 9595 ) \n Motivation : \n It is not safe to cache a jclass without obtaining a global reference via NewGlobalRef . \n Modifications : \n Correctly use NewGlobalRef ( . . . ) before caching \n Result : \n Correctly cache jclass instance,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodecBuilder . java \n - new DefaultHttp2HeadersDecoder ( true ) : \n - new DefaultHttp2HeadersDecoder ( true , maxHeaderListSize ) ) ; \n + new DefaultHttp2HeadersDecoder ( isValidateHeaders ( ) ) : \n + new DefaultHttp2HeadersDecoder ( isValidateHeaders ( ) , maxHeaderListSize ) ) ; \n codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2MultiplexCodecBuilder . java \n - new DefaultHttp2HeadersDecoder ( true ) : \n - new DefaultHttp2HeadersDecoder ( true , maxHeaderListSize ) ) ; \n + new DefaultHttp2HeadersDecoder ( isValidateHeaders ( ) ) : \n + new DefaultHttp2HeadersDecoder ( isValidateHeaders ( ) , maxHeaderListSize ) ) ; \n",Correctly take Http2FrameCodecBuilder . isValidateHeaders ( ) into account when creating a Http2FrameCodec from an existing Http2FrameWriter . ( # 9600 ) \n Motivation : \n We did miss to take Http2FrameCodecBuilder . isValidateHeaders ( ) into account when a Http2FrameWriter was set on the builder and always assumed validation should be enabled . \n Modifications : \n Remove hardcode value and use configured value \n Result : \n Http2FrameCodecBuilder . isValidateHeaders ( ) is respected in all cases,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ HttpToHttp2ConnectionHandler . java \n - release = false ; \n + release = false ; \n,We should only disable releasing of the message once writeData ( . . . ) was called successfully ( # 9610 ) \n Motivation : \n At the moment we set release to false before we call writeData ( . . . ) . This could let to the sitatuation that we will miss to release the message if writeData ( . . . ) throws . We should set release to false after we called writeData ( . . . ) to ensure the ownership of the buffer is correctly transferred . \n Modifications : \n - Set release to false after writeData ( . . . ) was successfully called only \n Result : \n No possibility for a buffer leak,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ InboundHttp2ToHttpAdapter . java \n - import io . netty . buffer . Unpooled ; \n - public FullHttpMessage copyIfNeeded ( FullHttpMessage msg ) { \n + public FullHttpMessage copyIfNeeded ( ByteBufAllocator allocator , FullHttpMessage msg ) { \n - FullHttpRequest copy = ( ( FullHttpRequest ) msg ) . replace ( Unpooled . buffer ( 0 ) ) ; \n + FullHttpRequest copy = ( ( FullHttpRequest ) msg ) . replace ( allocator . buffer ( 0 ) ) ; \n - final FullHttpMessage copy = endOfStream ? null : sendDetector . copyIfNeeded ( msg ) ; \n + final FullHttpMessage copy = endOfStream ? null : sendDetector . copyIfNeeded ( ctx . alloc ( ) , msg ) ; \n + * @ param allocator The { @ link ByteBufAllocator } that can be used to allocate \n - FullHttpMessage copyIfNeeded ( FullHttpMessage msg ) ; \n + FullHttpMessage copyIfNeeded ( ByteBufAllocator allocator , FullHttpMessage msg ) ; \n","Use configured ByteBufAllocator in InboundHttp2ToHttpAdapter ( # 9611 ) \n Motivation : \n At the moment we use Unpooled . buffer ( . . . ) in InboundHttp2ToHttpAdapter when we need to do a copy of the message . We should better use the configured ByteBufAllocator for the Channel \n Modifications : \n Change internal interface to also take the ByteBufAllocator as argument and use it when we need to allocate a ByteBuf . \n Result : \n Use the "" correct "" ByteBufAllocator in InboundHttp2ToHttpAdapter in all cases",381
. gitignore \n + \n + # exclude vscode files \n + . vscode / \n + * . factorypath \n,"Add vscode specific files / directory to . gitignore ( # 9652 ) \n Motivation : \n We should not commit vscode specific files , so at it to gitignore \n Modifications : \n Add files to . gitignore \n Result : \n Correctly ignore ide related files",381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniHandlerTest . java \n + assertEquals ( 1 , ( ( ReferenceCountedOpenSslContext ) sslContext ) . refCnt ( ) ) ; \n + assertEquals ( 2 , ( ( ReferenceCountedOpenSslContext ) sslContext ) . refCnt ( ) ) ; \n - / / Notice how the server ' s SslContext refCnt is 1 \n - assertEquals ( 1 , ( ( ReferenceCounted ) sslServerContext ) . refCnt ( ) ) ; \n + / / Notice how the server ' s SslContext refCnt is 2 as it is incremented when the SSLEngine is created \n + / / and only decremented once it is destroyed . \n + assertEquals ( 2 , ( ( ReferenceCounted ) sslServerContext ) . refCnt ( ) ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslHandlerTest . java \n + assertEquals ( 1 , ( ( ReferenceCounted ) sslContext ) . refCnt ( ) ) ; \n - assertEquals ( 1 , ( ( ReferenceCounted ) sslContext ) . refCnt ( ) ) ; \n + assertEquals ( 2 , ( ( ReferenceCounted ) sslContext ) . refCnt ( ) ) ; \n",Fix SSL tests that use SslProvider . OPENSSL _ REFCNT ( # 9649 ) \n Motivation : \n 031c2e2e8899d037228a492a458ccd194eb8df9c introduced some change to reduce the risk of have the ` ReferenceCountedOpenSslContext ` be destroyed while the ` ReferenceCountedSslEngine ` is still in us . Unfortunaly it missed to adjust a few tests which make assumptions about the refCnt of the context . \n Modifications : \n Adjust tests to take new semenatics into acount . \n Result : \n No more tests failures,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - import java . util . concurrent . atomic . AtomicIntegerFieldUpdater ; \n - private static final AtomicIntegerFieldUpdater < ReferenceCountedOpenSslEngine > DESTROYED _ UPDATER = \n - AtomicIntegerFieldUpdater . newUpdater ( ReferenceCountedOpenSslEngine . class , "" destroyed "" ) ; \n - \n - private volatile int destroyed ; \n + private volatile boolean destroyed ; \n - / / case when shutdown ( ) will be called by the finalizer again . If we would call SSL . free ( . . . ) directly \n - / / the finalizer may end up calling it again as we would miss to update the DESTROYED _ UPDATER . \n + / / case when shutdown ( ) will be called by the finalizer again . \n - if ( DESTROYED _ UPDATER . compareAndSet ( this , 0 , 1 ) ) { \n + if ( ! destroyed ) { \n + destroyed = true ; \n - return destroyed ! = 0 ; \n + return destroyed ; \n",Remove usage of AtomicIntegerFieldUpdater in ReferenceCountedOpenSslE… ( # 9653 ) \n Motivation : \n There is not need to use a CAS as everything is synchronized anyway . We can simplify the code a bit by not using it . \n Modifications : \n - Just remove the CAS operation \n - Change from int to boolean \n Result : \n Code cleanup,381
codec \ src \ main \ java \ io \ netty \ handler \ codec \ ByteToMessageDecoder . java \n - ByteBuf bytes = buf . readBytes ( readable ) ; \n - buf . release ( ) ; \n - ctx . fireChannelRead ( bytes ) ; \n + ctx . fireChannelRead ( buf ) ; \n,Eliminate unnessary copy of ByteBuf on ByteToMessageDecoder removal ( # 9662 ) \n Motivation : \n At the moment we do a ByteBuf . readBytes ( . . . ) on removal of the ByteToMessageDecoder if there are any bytes left and forward the returned ByteBuf to the next handler in the pipeline . This is not really needed as we can just forward the cumulation buffer directly and so eliminate the extra memory copy \n Modifications : \n Just forward the cumulation buffer directly on removal of the ByteToMessageDecoder \n Result : \n Less memory copies,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2FrameCodec . java \n - private final ChannelFutureListener bufferedStreamsListener = new ChannelFutureListener ( ) { \n - @ Override \n - public void operationComplete ( ChannelFuture future ) { \n - numBufferedStreams - - ; \n - } \n - } ; \n - / / Clean up the stream being initialized if writing the headers fails . \n - promise . addListener ( new ChannelFutureListener ( ) { \n - @ Override \n - public void operationComplete ( ChannelFuture channelFuture ) { \n - if ( ! channelFuture . isSuccess ( ) ) { \n - frameStreamToInitializeMap . remove ( streamId ) ; \n - } \n - } \n - } ) ; \n - \n - promise . addListener ( bufferedStreamsListener ) ; \n + / / Clean up the stream being initialized if writing the headers fails and also \n + / / decrement the number of buffered streams . \n + promise . addListener ( new ChannelFutureListener ( ) { \n + @ Override \n + public void operationComplete ( ChannelFuture channelFuture ) { \n + numBufferedStreams - - ; \n + \n + handleHeaderFuture ( channelFuture , streamId ) ; \n + } \n + } ) ; \n + } else { \n + handleHeaderFuture ( promise , streamId ) ; \n + private void handleHeaderFuture ( ChannelFuture channelFuture , int streamId ) { \n + if ( ! channelFuture . isSuccess ( ) ) { \n + frameStreamToInitializeMap . remove ( streamId ) ; \n + } \n + } \n + \n","Try to reduce GC produced while writing headers ( # 9682 ) \n Motivation : \n bbc34d0eda38efb4a6364561e9ac1d2319682694 introduced correct handling of "" in process "" setup of streams but there is some room for improvements . Often the writeHeaders ( . . . ) is completed directly which means there is not need to create the extra listener object . \n Modifications : \n - Only create the listener if we really need too . \n Result : \n Less GC",381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslContext . java \n + import io . netty . util . AttributeMap ; \n + import io . netty . util . DefaultAttributeMap ; \n + private final AttributeMap attributes = new DefaultAttributeMap ( ) ; \n + / * * \n + * Returns the { @ link AttributeMap } that belongs to this { @ link SslContext } . \n + * / \n + public final AttributeMap attributes ( ) { \n + return attributes ; \n + } \n + \n,Add ability to set attributes on a SslContext ( # 9654 ) \n Motivation : \n Sometimes it is useful to be able to set attributes on a SslContext . \n Modifications : \n Add new method that will return a AttributeMap that is tied to a SslContext instance \n Result : \n Fixes https : / / github . com / netty / netty / issues / 6542 .,381
common \ src \ main \ java \ io \ netty \ util \ HashedWheelTimer . java \n + if ( sleepTimeMs = = 0 ) { \n + sleepTimeMs = 1 ; \n + } \n,Guard against busy spinning in HashedWheelTimer when using windows and a tickDuration of 1 ( # 9714 ) \n Motivation : \n We do not correct guard against the gact that when applying our workaround for windows we may end up with a 0 sleep period . In this case we should just sleep for 1 ms . \n Modifications : \n Guard agains the case when our calculation will produce 0 as sleep time on windows \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9710 .,381
transport - blockhound - tests \ pom . xml \n - < version > 4 . 1 . 43 . Final - SNAPSHOT < / version > \n + < version > 4 . 1 . 44 . Final - SNAPSHOT < / version > \n,Fix version of transport - blockhound - tests introduced in f4b536edcbb97f20f1b7b0ad848e7cf9657d9d33,381
"codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ Http2HeadersValidatorTest . java \n - expectedException . expectMessage ( "" Connection - speficic headers like [ connection ] must not be used with HTTP "" ) ; \n + expectedException . expectMessage ( "" Connection - specific headers like [ connection ] must not be used with HTTP "" ) ; \n",Fix typo in test which did introduce a failing test after ffc3b2da72c09bb17fd1eb284e1b59bb4ed23b2a,381
"docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 222 - 10 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 232 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 222 - 10 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 232 "" \n",Update to latest jdk8 release ( # 9717 ) \n Motivation : \n We should use latest jdk8 release to build on CI \n Modifications : \n Update to latest adoptjdk release \n Result : \n Use latest jdk8,381
resolver - dns - native - macos \ pom . xml \n - < version > 4 . 1 . 42 . Final - SNAPSHOT < / version > \n + < version > 4 . 1 . 44 . Final - SNAPSHOT < / version > \n,Fix version for resolver - dns - native - macos introduced by 939e928312f1099373582f9811817a6226550987,381
common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n + if ( maxDelayedQueues = = 0 ) { \n + / / We don ' t support recycling across threads and should just drop the item on the floor . \n + return ; \n + } \n,Don ' t pollute FastThreadLocal for Threads with WeakHashMap if maxDelayedQueues = = 0 ( # 9722 ) \n Motivation : \n If maxDelayedQueues = = 0 we should never put any WeakHashMap into the FastThreadLocal for a Thread . \n Modifications : \n Check if maxDelayedQueues = = 0 and if so return directly . This will ensure we never call FastThreadLocal . initialValue ( ) in this case \n Result : \n Less overhead / memory usage when maxDelayedQueues = = 0,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2Headers . java \n - * Sets the { @ link PseudoHeaderName # METHOD } header or { @ code null } if there is no such header \n + * Sets the { @ link PseudoHeaderName # METHOD } header \n,"Fix Http2Headers . method ( . . . ) javadocs ( # 9718 ) \n Motivation : \n The javadocs of Http2Headers . method ( . . . ) are incorrect , we should fix these . \n Modifications : \n Correct javadocs \n Result : \n Fixes https : / / github . com / netty / netty / issues / 8068 .",381
common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n + / / As we already set the element [ size ] to null we also need to store the updated size before we do \n + / / any validation . Otherwise we may see a null value when later try to pop again without a new element \n + / / added before . \n + this . size = size ; \n + \n - this . size = size ; \n,Correctly update size of the Stack before doing any validation in Recycler ( # 9731 ) \n Motivation : \n We null out the element in the array after we decrement the current size of the Stack but not directly write back the updated size to the stored field . This is problematic as we do some validation before we write it back and so may never do so if the validation fails . This then later can lead to have null objects returned where not expected \n Modifications : \n Update size directly after null out object \n Result : \n No more unexpected null value possible,381
common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n - / / This act as a place holder for the head Link but also will reclaim space once finalized . \n - / / / TODO : In the future when we move to Java9 + we should use java . lang . ref . Cleaner . \n - @ Override \n - protected void finalize ( ) throws Throwable { \n - try { \n - super . finalize ( ) ; \n - } finally { \n - Link head = link ; \n - link = null ; \n - while ( head ! = null ) { \n - reclaimSpace ( LINK _ CAPACITY ) ; \n - Link next = head . next ; \n - / / Unlink to help GC and guard against GC nepotism . \n - head . next = null ; \n - head = next ; \n - } \n + / * * \n + * Reclaim all used space and also unlink the nodes to prevent GC nepotism . \n + * / \n + void reclaimAllSpaceAndUnlink ( ) { \n + Link head = link ; \n + link = null ; \n + int reclaimSpace = 0 ; \n + while ( head ! = null ) { \n + reclaimSpace + = LINK _ CAPACITY ; \n + Link next = head . next ; \n + / / Unlink to help GC and guard against GC nepotism . \n + head . next = null ; \n + head = next ; \n + } \n + if ( reclaimSpace ! = 0 ) { \n + reclaimSpace ( reclaimSpace ) ; \n + void reclaimAllSpaceAndUnlink ( ) { \n + head . reclaimAllSpaceAndUnlink ( ) ; \n + this . next = null ; \n + } \n + \n + / / Ensure we reclaim all space before dropping the WeakOrderQueue to be GC ' ed . \n + cursor . reclaimAllSpaceAndUnlink ( ) ; \n,Remove usage of finalizer in Recycler ( # 9726 ) \n Motivation : \n We currently use a finalizer to ensure we correctly return the reserved back to the Stack but this is not really needed as we can ensure we return it when needed before dropping the WeakOrderQueue \n Modifications : \n Use explicit method call to ensure we return the reserved space back before dropping the object \n Result : \n Less finalizer usage and so less work for the GC,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 4 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 5 "" \n docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 0 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 1 "" \n docker \ docker - compose . centos - 6 . graalvm1 . yaml \n - java _ version : "" graalvm @ 19 . 1 . 1 "" \n + java _ version : "" graalvm @ 19 . 2 . 1 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 4 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 5 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 4 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 5 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 0 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 1 "" \n",Upgrade various JDK flavors / version in our docker - compose files ( # 9737 ) \n Motivation : \n We should always test with the latest JDK versions on our CI . \n Modifications : \n Update versions \n Result : \n Use latest JDK versions on our CI,381
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n + netty _ unix _ errors _ throwChannelExceptionError ( env , "" Could not init sockaddr "" ) ; \n",netty _ epoll _ linuxsocket _ setTcpMd5Sig should throw ChannelException when not able to init sockaddr ( # 9029 ) \n Motivation : \n When netty _ epoll _ linuxsocket _ setTcpMd5Sig fails to init the sockaddr we should throw an exception and not silently return . \n Modifications : \n Throw exception if init of sockaddr fails . \n Result : \n Correctly report back error to user .,381
transport \ src \ main \ java \ io \ netty \ channel \ socket \ nio \ NioServerSocketChannel . java \n - return javaChannel ( ) . socket ( ) . isBound ( ) ; \n + / / As java . nio . ServerSocketChannel . isBound ( ) will continue to return true even after the channel was closed \n + / / we will also need to check if it is open . \n + return isOpen ( ) & & javaChannel ( ) . socket ( ) . isBound ( ) ; \n transport \ src \ test \ java \ io \ netty \ channel \ socket \ nio \ NioServerSocketChannelTest . java \n + import io . netty . channel . Channel ; \n + import io . netty . channel . ChannelFuture ; \n + @ Test \n + public void testIsActiveFalseAfterClose ( ) { \n + NioServerSocketChannel serverSocketChannel = new NioServerSocketChannel ( ) ; \n + EventLoopGroup group = new NioEventLoopGroup ( 1 ) ; \n + try { \n + group . register ( serverSocketChannel ) . syncUninterruptibly ( ) ; \n + Channel channel = serverSocketChannel . bind ( new InetSocketAddress ( 0 ) ) . syncUninterruptibly ( ) . channel ( ) ; \n + Assert . assertTrue ( channel . isActive ( ) ) ; \n + Assert . assertTrue ( channel . isOpen ( ) ) ; \n + channel . close ( ) . syncUninterruptibly ( ) ; \n + Assert . assertFalse ( channel . isOpen ( ) ) ; \n + Assert . assertFalse ( channel . isActive ( ) ) ; \n + } finally { \n + group . shutdownGracefully ( ) ; \n + } \n + } \n + \n,NioServerSocketChannel . isActive ( ) must return false after close ( ) completes . ( # 9030 ) \n Motivation : \n When a Channel was closed its isActive ( ) method must return false . \n Modifications : \n First check for isOpen ( ) before isBound ( ) as isBound ( ) will continue to return true even after the underyling fd was closed . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9026 .,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ HttpObjectDecoder . java \n + if ( nameEnd = = length ) { \n + / / There was no colon present at all . \n + throw new IllegalArgumentException ( "" No colon found "" ) ; \n + } \n + \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ HttpRequestDecoderTest . java \n + \n + @ Test \n + public void testHeaderWithNoValueAndMissingColon ( ) { \n + EmbeddedChannel channel = new EmbeddedChannel ( new HttpRequestDecoder ( ) ) ; \n + String requestStr = "" GET / some / path HTTP / 1 . 1 \ r \ n "" + \n + "" Content - Length : 0 \ r \ n "" + \n + "" Host : \ r \ n "" + \n + "" netty . io \ r \ n \ r \ n "" ; \n + \n + assertTrue ( channel . writeInbound ( Unpooled . copiedBuffer ( requestStr , CharsetUtil . US _ ASCII ) ) ) ; \n + HttpRequest request = channel . readInbound ( ) ; \n + System . err . println ( request . headers ( ) . names ( ) . toString ( ) ) ; \n + assertTrue ( request . decoderResult ( ) . isFailure ( ) ) ; \n + assertTrue ( request . decoderResult ( ) . cause ( ) instanceof IllegalArgumentException ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n","Detect missing colon when parsing http headers with no value ( # 9871 ) \n Motivation : \n Technical speaking its valid to have http headers with no values so we should support it . That said we need to detect if these are "" generated "" because of an "" invalid "" fold . \n Modifications : \n - Detect if a colon is missing when parsing headers . \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9866",381
. mvn \ wrapper \ maven - wrapper . properties \n - distributionUrl = https : / / repo1 . maven . org / maven2 / org / apache / maven / apache - maven / 3 . 5 . 2 / apache - maven - 3 . 5 . 2 - bin . zip \n + distributionUrl = https : / / repo1 . maven . org / maven2 / org / apache / maven / apache - maven / 3 . 6 . 2 / apache - maven - 3 . 6 . 2 - bin . zip \n,Update to latest recommended maven version ( # 9785 ) \n Motivation : \n Latest recommended maven version is 3 . 6 . 2 so we should use it \n Modifications : \n Update from 3 . 5 . 2 to 3 . 6 . 2 \n Result : \n Use latest recommended maven version,381
pom . xml \n - < property > \n - < name > os . detected . arch < / name > \n - < value > ! x86 _ 64 < / value > \n - < / property > \n + < os > \n + < arch > ! x86 _ 64 < / arch > \n + < / os > \n,Correctly only active not _ x86 _ 64 profile when using a non x86 _ 64 platform ( # 9805 ) \n Motivation : \n 21720e4a7865b77d252a4263271663d7ed462440 introduced a change which aimed to enable the not _ x86 _ 64 profile when building on a x86 _ 64 platform . Unfortunaly it made an assemption which not holds true and so the profile was already enabled . This lead to the situation that native SSL tests were skipped if non boringssl impl was used . \n Modifications : \n Fix profile activation to work as expected \n Result : \n Correctly run aal native SSL tests,381
codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ extensions \ compression \ DeflateDecoder . java \n - if ( decoder . finish ( ) ) { \n - for ( ; ; ) { \n - ByteBuf buf = decoder . readOutbound ( ) ; \n - if ( buf = = null ) { \n - break ; \n - } \n - / / Release the buffer \n - buf . release ( ) ; \n - } \n - } \n + decoder . finishAndReleaseAll ( ) ; \n codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ extensions \ compression \ DeflateEncoder . java \n - if ( encoder . finish ( ) ) { \n - for ( ; ; ) { \n - ByteBuf buf = encoder . readOutbound ( ) ; \n - if ( buf = = null ) { \n - break ; \n - } \n - / / Release the buffer \n - buf . release ( ) ; \n - } \n - } \n + encoder . finishAndReleaseAll ( ) ; \n,Simplify Deflate * implementations by using EmbeddedChannel . finishAndReleaseAll ( ) ( # 9808 ) \n Motivation : \n We can simplify the code by just using finishAndReleaseAll ( ) \n Modifications : \n Remove some code and simplify \n Result : \n Cleaner code,381
. mvn \ wrapper \ maven - wrapper . properties \n - distributionUrl = https : / / repo1 . maven . org / maven2 / org / apache / maven / apache - maven / 3 . 6 . 2 / apache - maven - 3 . 6 . 2 - bin . zip \n + distributionUrl = https : / / repo1 . maven . org / maven2 / org / apache / maven / apache - maven / 3 . 6 . 3 / apache - maven - 3 . 6 . 3 - bin . zip \n,Use latest maven release ( # 9820 ) \n Motivation : \n Apache Maven 3 . 6 . 3 was released \n Modifications : \n Update to latest version \n Result : \n Use latest version to build,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2LocalFlowController . java \n + import io . netty . handler . codec . http2 . Http2Stream . State ; \n - if ( endOfStream | | initialStreamWindowSize < = 0 ) { \n + if ( endOfStream | | initialStreamWindowSize < = 0 | | \n + / / If the stream is already closed there is no need to try to write a window update for it . \n + isClosed ( stream ) ) { \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2LocalFlowControllerTest . java \n + import static org . junit . Assert . assertNull ; \n + import io . netty . handler . codec . http2 . Http2Stream . State ; \n + @ Test \n + public void windowUpdateShouldNotBeSentAfterStreamIsClosedForUnconsumedBytes ( ) throws Http2Exception { \n + int dataSize = ( int ) ( DEFAULT _ WINDOW _ SIZE * DEFAULT _ WINDOW _ UPDATE _ RATIO ) + 1 ; \n + \n + / / Don ' t set end - of - stream on the frame as we want to verify that we not return the unconsumed bytes in this \n + / / case once the stream was closed , \n + receiveFlowControlledFrame ( STREAM _ ID , dataSize , 0 , false ) ; \n + verifyWindowUpdateNotSent ( CONNECTION _ STREAM _ ID ) ; \n + verifyWindowUpdateNotSent ( STREAM _ ID ) ; \n + \n + / / Close the stream \n + Http2Stream stream = connection . stream ( STREAM _ ID ) ; \n + stream . close ( ) ; \n + assertEquals ( State . CLOSED , stream . state ( ) ) ; \n + assertNull ( connection . stream ( STREAM _ ID ) ) ; \n + \n + / / The window update for the connection should made it through but not the update for the already closed \n + / / stream \n + verifyWindowUpdateSent ( CONNECTION _ STREAM _ ID , dataSize ) ; \n + verifyWindowUpdateNotSent ( STREAM _ ID ) ; \n + } \n + \n",Don ' t send window update frame for unconsumed bytes when stream is already closed ( # 9816 ) \n Motivation : \n At the moment we send a window update frame for the connection + stream when a stream is closed and there are unconsumed bytes left . While we need to do this for the connection it makes no sense to write a window update frame for the stream itself as it is already closed \n Modifications : \n - Don ' t write the window update frame for the stream when the stream is closed \n - Add unit test \n Result : \n Don ' t write the window frame for closed streams,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ CompressorHttp2ConnectionEncoder . java \n - if ( compressor . finish ( ) ) { \n - for ( ; ; ) { \n - final ByteBuf buf = compressor . readOutbound ( ) ; \n - if ( buf = = null ) { \n - break ; \n - } \n - \n - buf . release ( ) ; \n - } \n - } \n + compressor . finishAndReleaseAll ( ) ; \n,Use EmbeddedChannel . finishAndReleaseAll ( ) to remove boiler - plate code ( # 9824 ) \n Motivation : \n We can make use of EmbeddedChannel . finishAndReleaseAll ( ) and so remove some code \n Modifications : \n Use finishAndReleaseAll ( ) \n Result : \n Less code to maintain,381
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n - netty _ unix _ errors _ throwChannelExceptionError ( env , "" Could not init sockaddr "" ) ; \n + netty _ unix _ errors _ throwIOException ( env , "" Could not init sockaddr "" ) ; \n - netty _ unix _ errors _ throwChannelExceptionErrorNo ( env , "" setsockopt ( ) failed : "" , errno ) ; \n + netty _ unix _ errors _ throwIOExceptionErrorNo ( env , "" setsockopt ( ) failed : "" , errno ) ; \n",Throw IOException ( not ChannelException ) if netty _ epoll _ linuxsocket _ setTcpMd5Sig fails ( # 9039 ) \n Motivation : \n At the moment we throw a ChannelException if netty _ epoll _ linuxsocket _ setTcpMd5Sig fails . This is inconsistent with other methods which throw a IOException . \n Modifications : \n Throw IOException \n Result : \n More correct and consistent exception usage in epoll transport,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ DatagramMulticastIPv6Test . java \n + import org . junit . Ignore ; \n + @ Ignore ( "" Fails on some systems "" ) \n + @ Override \n + public void testMulticast ( ) throws Throwable { \n + super . testMulticast ( ) ; \n + } \n + \n testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ DatagramMulticastTest . java \n - import java . net . SocketAddress ; \n",Ignore ipv6 multicast test that was added in 778ff2057eb5e585097155ab9b23a3813e57d5cd for now \n Motivation : \n The multicast ipv6 test fails on some systems . As I just added it let me ignore it for now while investigating . \n Modifications : \n Add @ ignore \n Result : \n Stable testsuite while investigate,381
pom . xml \n - < tcnative . version > 2 . 0 . 24 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 25 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 25 . Final to fix possible segfault when openssl < 1 . 0 . 2 and gcc is used . ( # 9038 ) \n Motivation : \n We should update to netty - tcnative 2 . 0 . 25 . Final as it fixes a possible segfault on systems that use openssl < 1 . 0 . 2 and for which we compiled with gcc . \n See https : / / github . com / netty / netty - tcnative / pull / 457 \n Modifications : \n Update netty - tcnative \n Result : \n No more segfault possible .,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslX509TrustManagerWrapper . java \n + throw new CertificateException ( ) ; \n + throw new CertificateException ( ) ; \n,Make validation tools more happy by not have TrustManager impl just accept ( # 9041 ) \n Motivation : \n Seems like some analyzer / validation tools scan code to detect if it may produce some security risk because of just blindly accept certificates . Such a tool did tag our code because we have such an implementation ( which then is actually never be used ) . We should just change the impl to not do this as it does not matter for us and it makes such tools happier . \n Modifications : \n Throw CertificateException \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9032,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + private static final boolean IS _ IVKVM _ DOT _ NET = isIkvmDotNet0 ( ) ; \n + \n + if ( isIkvmDotNet ( ) ) { \n + logger . debug ( "" sun . misc . Unsafe : unavailable ( IKVM . NET ) "" ) ; \n + return new UnsupportedOperationException ( "" sun . misc . Unsafe : unavailable ( IKVM . NET ) "" ) ; \n + } \n + \n + / * * \n + * Returns { @ code true } if the running JVM is < a href = "" https : / / www . ikvm . net "" > IKVM . NET < / a > , { @ code false } otherwise . \n + * / \n + public static boolean isIkvmDotNet ( ) { \n + return IS _ IVKVM _ DOT _ NET ; \n + } \n + \n + private static boolean isIkvmDotNet0 ( ) { \n + String vmName = SystemPropertyUtil . get ( "" java . vm . name "" , "" "" ) . toUpperCase ( Locale . US ) ; \n + return vmName . equals ( "" IKVM . NET "" ) ; \n + } \n + \n","Don ' t use sun . misc . Unsafe when IKVM . NET is used ( # 9042 ) \n Motivation : \n IKVM . NET seems to ship a bug sun . misc . Unsafe class , for this reason we should better disable our sun . misc . Unsafe usage when we detect IKVM . NET is used . \n Modifications : \n Check if IKVM . NET is used and if so do not use sun . misc . Unsafe by default . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9035 and https : / / github . com / netty / netty / issues / 8916 .",381
pom . xml \n - < version > 1 . 18 < / version > \n + < version > 1 . 19 < / version > \n,Update commons - compress dependency ( # 9657 ) \n Motivation : \n We should use the latest commons - compress release to fix CVE - 2019 - 12402 ( even it is only a test dependency ) \n Modifications : \n Update commons - compress to 1 . 19 \n Result : \n Fix security alert,381
"buffer \ src \ test \ java \ io \ netty \ buffer \ SimpleLeakAwareCompositeByteBufTest . java \n + import io . netty . util . ByteProcessor ; \n + import org . hamcrest . CoreMatchers ; \n + import static org . junit . Assert . assertEquals ; \n + import static org . junit . Assert . assertThat ; \n + @ Test \n + public void forEachByteUnderLeakDetectionShouldNotThrowException ( ) { \n + CompositeByteBuf buf = ( CompositeByteBuf ) newBuffer ( 8 ) ; \n + assertThat ( buf , CoreMatchers . instanceOf ( SimpleLeakAwareCompositeByteBuf . class ) ) ; \n + CompositeByteBuf comp = ( CompositeByteBuf ) newBuffer ( 8 ) ; \n + assertThat ( comp , CoreMatchers . instanceOf ( SimpleLeakAwareCompositeByteBuf . class ) ) ; \n + \n + ByteBuf inner = comp . alloc ( ) . directBuffer ( 1 ) . writeByte ( 0 ) ; \n + comp . addComponent ( true , inner ) ; \n + buf . addComponent ( true , comp ) ; \n + \n + assertEquals ( - 1 , buf . forEachByte ( new ByteProcessor ( ) { \n + @ Override \n + public boolean process ( byte value ) { \n + return true ; \n + } \n + } ) ) ; \n + assertTrue ( buf . release ( ) ) ; \n + } \n + \n",Add unit test for leak aware CompositeByteBuf that proves that there is no NPE ( # 9875 ) \n Motivation : \n https : / / github . com / netty / netty / issues / 9873 reported a NPE in previous version of netty . We should add a unit test to verify there is no more NPE \n Modifications : \n Add a unit test \n Result : \n Prove that https : / / github . com / netty / netty / issues / 9873 is fixed,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ cookie \ ClientCookieEncoder . java \n - private static final Comparator < Cookie > COOKIE _ COMPARATOR = new Comparator < Cookie > ( ) { \n + / / package - private for testing only . \n + static final Comparator < Cookie > COOKIE _ COMPARATOR = new Comparator < Cookie > ( ) { \n - int diff = len2 - len1 ; \n - if ( diff ! = 0 ) { \n - return diff ; \n - } \n + \n - return 0 ; \n + return len2 - len1 ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ cookie \ ClientCookieEncoderTest . java \n + \n + @ Test \n + public void testComparatorForSamePathLength ( ) { \n + Cookie cookie = new DefaultCookie ( "" test "" , "" value "" ) ; \n + cookie . setPath ( "" 1 "" ) ; \n + \n + Cookie cookie2 = new DefaultCookie ( "" test "" , "" value "" ) ; \n + cookie2 . setPath ( "" 2 "" ) ; \n + \n + assertEquals ( 0 , ClientCookieEncoder . COOKIE _ COMPARATOR . compare ( cookie , cookie2 ) ) ; \n + assertEquals ( 0 , ClientCookieEncoder . COOKIE _ COMPARATOR . compare ( cookie2 , cookie ) ) ; \n + } \n",Add testcase for internal used Comparator in ClientCookieEncoder ( # 9897 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 9883 added a bug - fix for the Comparator in ClientCookieEncoder but did not add a testcase . \n Modifications : \n - Add testcase \n - Simplify code \n Result : \n Include a test to ensure we not regress .,381
handler \ src \ main \ java \ io \ netty \ handler \ stream \ ChunkedWriteHandler . java \n - private PendingWrite currentWrite ; \n - PendingWrite currentWrite = this . currentWrite ; \n - \n - if ( this . currentWrite = = null ) { \n - currentWrite = queue . poll ( ) ; \n - } else { \n - this . currentWrite = null ; \n - } \n + PendingWrite currentWrite = queue . poll ( ) ; \n - if ( currentWrite = = null ) { \n - currentWrite = queue . poll ( ) ; \n - } \n + final PendingWrite currentWrite = queue . peek ( ) ; \n - this . currentWrite = null ; \n + queue . remove ( ) ; \n - final PendingWrite currentWrite = this . currentWrite ; \n - this . currentWrite = null ; \n + queue . remove ( ) ; \n - this . currentWrite = null ; \n + queue . remove ( ) ; \n - this . currentWrite = null ; \n + queue . remove ( ) ; \n,Remove extra field from ChunkedWriteHandler to make it less error - prone ( # 9958 ) \n Motivation : \n At the moment we use an extra field in ChunedWriteHandler to hold the current write . This is not needed and makes sense even more error - prone . We can just peek in the queue . \n Modifications : \n Use Queue . peek ( ) to keep track of current write \n Result : \n Less error - prone code,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 5 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 6 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 5 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 6 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 5 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 6 "" \n",Use latest java 11 version when building via docker ( # 9968 ) \n Motivation : \n We should update the used java11 version when building via docker to the latest release \n Modifications : \n Update to 1 . 11 . 0 - 6 \n Result : \n Use latest java11 version,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandler . java \n - import io . netty . channel . ChannelHandler ; \n - import io . netty . channel . ChannelInboundHandlerAdapter ; \n - import io . netty . handler . codec . http . FullHttpRequest ; \n - \n - static ChannelHandler forbiddenHttpRequestResponder ( ) { \n - return new ChannelInboundHandlerAdapter ( ) { \n - @ Override \n - public void channelRead ( ChannelHandlerContext ctx , Object msg ) throws Exception { \n - if ( msg instanceof FullHttpRequest ) { \n - ( ( FullHttpRequest ) msg ) . release ( ) ; \n - FullHttpResponse response = \n - new DefaultFullHttpResponse ( HTTP _ 1 _ 1 , HttpResponseStatus . FORBIDDEN , ctx . alloc ( ) . buffer ( 0 ) ) ; \n - ctx . channel ( ) . writeAndFlush ( response ) ; \n - } else { \n - ctx . fireChannelRead ( msg ) ; \n - } \n - } \n - } ; \n - } \n codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandshakeHandler . java \n - public void handlerAdded ( ChannelHandlerContext ctx ) throws Exception { \n + public void handlerAdded ( ChannelHandlerContext ctx ) { \n - ctx . pipeline ( ) . replace ( this , "" WS403Responder "" , \n - WebSocketServerProtocolHandler . forbiddenHttpRequestResponder ( ) ) ; \n + ctx . pipeline ( ) . remove ( this ) ; \n - public void operationComplete ( ChannelFuture future ) throws Exception { \n + public void operationComplete ( ChannelFuture future ) { \n - public void operationComplete ( Future < Void > f ) throws Exception { \n + public void operationComplete ( Future < Void > f ) { \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketServerProtocolHandlerTest . java \n - @ Test \n - public void testSubsequentHttpRequestsAfterUpgradeShouldReturn403 ( ) { \n - EmbeddedChannel ch = createChannel ( ) ; \n - \n - writeUpgradeRequest ( ch ) ; \n - \n - FullHttpResponse response = responses . remove ( ) ; \n - assertEquals ( SWITCHING _ PROTOCOLS , response . status ( ) ) ; \n - response . release ( ) ; \n - \n - ch . writeInbound ( new DefaultFullHttpRequest ( HTTP _ 1 _ 1 , HttpMethod . GET , "" / test "" ) ) ; \n - response = responses . remove ( ) ; \n - assertEquals ( FORBIDDEN , response . status ( ) ) ; \n - response . release ( ) ; \n - assertFalse ( ch . finish ( ) ) ; \n - } \n - \n",Remove usage of forbiddenHttpRequestResponder ( # 9941 ) \n Motivation : \n At the moment we add a handler which will respond with 403 forbidden if a websocket handshake is in progress ( and after ) . This makes not much sense as it is unexpected to have a remote peer to send another http request when the handshake was started . In this case it is much better to let the websocket decoder bail out . \n Modifications : \n Remove usage of forbiddenHttpRequestResponder \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9913,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - case NEED _ WRAP : \n - finishWrap ( ctx , out , promise , inUnwrap , false ) ; \n + case NEED _ WRAP : { \n + ChannelPromise p = promise ; \n + \n + / / Null out the promise so it is not reused in the finally block in the cause of \n + / / finishWrap ( . . . ) throwing . \n - out = null ; \n + final ByteBuf b ; \n + \n + if ( out . isReadable ( ) ) { \n + / / There is something in the out buffer . Ensure we null it out so it is not re - used . \n + b = out ; \n + out = null ; \n + } else { \n + / / If out is not readable we can re - use it and so save an extra allocation \n + b = null ; \n + } \n + finishWrap ( ctx , b , p , inUnwrap , false ) ; \n + } \n","SslHandler . wrap ( . . . ) must ensure it not loose the original exception when finishWrap ( . . . ) fails ( # 9974 ) \n Motivation : \n When SslHandler . finishWrap throws an exception , ensure that the promise and buf is not reused to avoid throwing IllegalArgumentException or IllegalReferenceCountException which causes the original exception to be lost . \n Modification : \n The change ensures that the values for the promise and bytebuf are nulled before calling finishWrap so that it will not be called again with the same arguments . \n Result : \n Fixes # 9971 . \n Co - authored - by : Norman Maurer < norman _ maurer @ apple . com > \n Co - authored - by : Antony T Curtis < atcurtis @ gmail . com >",381
"docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 232 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 242 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 232 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 242 "" \n","Update to java8 - 242 ( # 9978 ) \n Motivation : \n A new java 8 version was released , lets use it \n Modifications : \n Update to java8 - 242 \n Result : \n Use latest java8 version",381
"common \ src \ main \ resources \ META - INF \ native - image \ io . netty \ common \ native - image . properties \n - Args = - - initialize - at - run - time = io . netty . util . AbstractReferenceCounted , io . netty . util . concurrent . GlobalEventExecutor , io . netty . util . concurrent . ImmediateEventExecutor , io . netty . util . concurrent . ScheduledFutureTask \n + Args = - - initialize - at - run - time = io . netty . util . AbstractReferenceCounted , io . netty . util . concurrent . GlobalEventExecutor , io . netty . util . concurrent . ImmediateEventExecutor , io . netty . util . concurrent . ScheduledFutureTask , io . netty . util . internal . ThreadLocalRandom \n",Initialize ThreadLocalRandom at runtime to improve GraalVM support ( # 9977 ) \n Motivation : \n We need to initialize ThreadLocalRandom at runtime as it uses System . nanoTime ( ) in a static block to init the seed . \n Modifications : \n Add io . netty . util . internal . ThreadLocalRandom to properties file \n Result : \n Better support for GraalVM,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n - / / Workaround for possible JDK 14 regression . \n - / / See http : / / mail . openjdk . java . net / pipermail / security - dev / 2020 - March / 021488 . html \n + / / Workaround for JDK 14 regression . \n + / / See https : / / bugs . openjdk . java . net / browse / JDK - 8242008 \n,Update link for JDK14 regression to point to the actual bugreport,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ CompositeByteBuf . java \n + private static void checkForOverflow ( int capacity , int readableBytes ) { \n + if ( capacity + readableBytes < 0 ) { \n + throw new IllegalArgumentException ( "" Can ' t increase by "" + readableBytes + "" as capacity ( "" + capacity + "" ) "" + \n + "" would overflow "" + Integer . MAX _ VALUE ) ; \n + } \n + } \n + \n - if ( capacity ( ) + readableBytes < 0 ) { \n - throw new IllegalArgumentException ( "" Can ' t increase by "" + readableBytes ) ; \n - } \n + checkForOverflow ( capacity ( ) , readableBytes ) ; \n - if ( capacity + readableBytes < 0 ) { \n - throw new IllegalArgumentException ( "" Can ' t increase by "" + readableBytes ) ; \n - } \n + checkForOverflow ( capacity , readableBytes ) ; \n",Include more details if we throw an IllegalArgumentException because of overflow ( # 10330 ) \n Motivation : \n We should include as much details as possible when throwing an IllegalArgumentException because of overflow in CompositeByteBuf \n Modifications : \n Add more details and factor out check into a static method to share code \n Result : \n Make it more clear why an operations failed,381
codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ rtsp \ RtspDecoderTest . java \n - System . out . println ( res2 ) ; \n,Remove System . out . println ( . . . ) in test ( # 10024 ) \n Motivation : \n We did had some System . out . println ( . . . ) call in a test which seems to be some left - over from debugging . \n Modifications : \n Remove System . out . println ( . . . ) \n Result : \n Code cleanup,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniHandlerTest . java \n - / / When the channel is closed the SslHandler will write an empty buffer to the channel . \n - ByteBuf buf = ch . readOutbound ( ) ; \n - if ( buf ! = null ) { \n - assertFalse ( buf . isReadable ( ) ) ; \n + / / Consume all the outbound data that may be produced by the SSLEngine . \n + for ( ; ; ) { \n + ByteBuf buf = ch . readOutbound ( ) ; \n + if ( buf = = null ) { \n + break ; \n + } \n,Don ' t depend on implementation details of SSLEngine in SniHandlerTest ( # 10037 ) \n Motivation : \n In SniHandlerTest we depended on implementation details of the SSLEngine . We should better not doing this \n Modifications : \n Just release all outbound data \n Result : \n Dont depend on implementation details,381
"codec - dns \ src \ main \ java \ io \ netty \ handler \ codec \ dns \ AbstractDnsRecord . java \n + import io . netty . util . internal . PlatformDependent ; \n - this . name = appendTrailingDot ( IDN . toASCII ( checkNotNull ( name , "" name "" ) ) ) ; \n + this . name = appendTrailingDot ( IDNtoASCII ( name ) ) ; \n + private static String IDNtoASCII ( String name ) { \n + checkNotNull ( name , "" name "" ) ; \n + if ( PlatformDependent . isAndroid ( ) & & DefaultDnsRecordDecoder . ROOT . equals ( name ) ) { \n + / / Prior Android 10 there was a bug that did not correctly parse "" . "" . \n + / / \n + / / See https : / / github . com / netty / netty / issues / 10034 \n + return name ; \n + } \n + return IDN . toASCII ( name ) ; \n + } \n + \n","Workaround Android bug that cause AbstractDnsRecord to throw when the name is only a ROOT label ( # 10039 ) \n Motivation : \n Having only the ROOT label ( "" . "" ) as the name is valid , but Android 9 and prior does not correctly handle the case . We should add a workaround for it . \n Modifications : \n Detect if we are on Android and if so check if the name is the ROOT label and if so just return the name without trying to convert it \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10034",381
pom . xml \n - < tcnative . version > 2 . 0 . 28 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 29 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 29 . Final ( # 10044 ) \n Motivation : \n A new release of netty - tcnative is out \n Modifications : \n Update to latest version \n Result : \n Use latest netty - tcnative,381
"transport \ src \ main \ java \ io \ netty \ channel \ group \ DefaultChannelGroup . java \n - Map < Channel , ChannelFuture > futures = new LinkedHashMap < Channel , ChannelFuture > ( size ( ) ) ; \n + Map < Channel , ChannelFuture > futures = new LinkedHashMap < Channel , ChannelFuture > ( nonServerChannels . size ( ) ) ; \n - Map < Channel , ChannelFuture > futures = new LinkedHashMap < Channel , ChannelFuture > ( size ( ) ) ; \n + Map < Channel , ChannelFuture > futures = new LinkedHashMap < Channel , ChannelFuture > ( nonServerChannels . size ( ) ) ; \n",Correctly calculate the initial size of the LinkedHashMap during DefaultChannelGroup . write * ( # 10055 ) \n Motivation : \n We should not include the number of ServerChannel that are part of the DefaultChannelGroup when specify the initial size of the LinkedHashMap \n Modifications : \n Only use the number of the non ServerChannel \n Result : \n Reduce memory - footprint,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ SocketUtils . java \n + import java . util . Collections ; \n + private static final Enumeration < Object > EMPTY = Collections . enumeration ( Collections . emptyList ( ) ) ; \n + \n + @ SuppressWarnings ( "" unchecked "" ) \n + private static < T > Enumeration < T > empty ( ) { \n + return ( Enumeration < T > ) EMPTY ; \n + } \n + \n - return AccessController . doPrivileged ( new PrivilegedAction < Enumeration < InetAddress > > ( ) { \n + Enumeration < InetAddress > addresses = \n + AccessController . doPrivileged ( new PrivilegedAction < Enumeration < InetAddress > > ( ) { \n + / / Android seems to sometimes return null even if this is not a valid return value by the api docs . \n + / / Just return an empty Enumeration in this case . \n + / / See https : / / github . com / netty / netty / issues / 10045 \n + if ( addresses = = null ) { \n + return empty ( ) ; \n + } \n + return addresses ; \n",NetworkInterface . getByInetAddress ( ) may return null on Android platform ( # 10056 ) \n Motivation : \n NetworkInterface . getByInetAddress ( ) may return null on Android . This is incorrect by the API but still happens . To help our users we should provide a workaround \n Modifications : \n Just return an empty Enumeration when null is returned . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10045,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - SSLException exception = new SSLException ( "" handshake timed out "" ) ; \n + SSLException exception = \n + new SslHandshakeTimeoutException ( "" handshake timed out after "" + handshakeTimeoutMillis + "" ms "" ) ; \n new file \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandshakeTimeoutException . java \n + / * \n + * Copyright 2020 The Netty Project \n + * \n + * The Netty Project licenses this file to you under the Apache License , \n + * version 2 . 0 ( the "" License "" ) ; you may not use this file except in compliance \n + * with the License . You may obtain a copy of the License at : \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , WITHOUT \n + * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the \n + * License for the specific language governing permissions and limitations \n + * under the License . \n + * / \n + package io . netty . handler . ssl ; \n + \n + import javax . net . ssl . SSLHandshakeException ; \n + \n + / * * \n + * { @ link SSLHandshakeException } that is used when a handshake failed due a configured timeout . \n + * / \n + public final class SslHandshakeTimeoutException extends SSLHandshakeException { \n + \n + SslHandshakeTimeoutException ( String reason ) { \n + super ( reason ) ; \n + } \n + } \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslHandlerTest . java \n - @ Test ( expected = SSLException . class , timeout = 3000 ) \n + @ Test ( expected = SslHandshakeTimeoutException . class , timeout = 3000 ) \n - @ Test ( expected = SSLException . class , timeout = 3000 ) \n + @ Test ( expected = SslHandshakeTimeoutException . class , timeout = 3000 ) \n",Add SslHandshakeTimeoutException and use it for handshake timeouts ( # 10062 ) \n Motivation : \n Often it is useful to be able to detect different sorts of SSL errors that cause the handshake to fail . To make this easier we should throw and explicit exception type for handshake timeouts . \n Modifications : \n - Add SslHandshakeTimeoutException ( which extends SSLHandshakeException ) and use it for handshake timeouts \n - Adjust testcases \n Result : \n Easier to detect that handshake failed because of a timeout,381
common \ src \ main \ java \ io \ netty \ util \ concurrent \ PromiseTask . java \n - @ Override \n - public final boolean isCancelled ( ) { \n - return task = = CANCELLED | | super . isCancelled ( ) ; \n - } \n - \n,PromiseTask . isCancelled performs an unsynchronized read ( # 10066 ) \n Motivation : \n PromiseTask . isCancelled performs an unsynchronized read and so may trigger race - detectors . As this was just done for a small optimization which should not really make a lot of difference we should just remove it . \n Modifications : \n Remove unsynchronized read optimization \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10026 .,381
pom . xml \n - < netty . build . version > 25 < / netty . build . version > \n + < netty . build . version > 26 < / netty . build . version > \n - < version > 3 . 0 . 0 < / version > \n + < version > 3 . 1 . 0 < / version > \n - < version > 8 . 18 < / version > \n + < version > 8 . 29 < / version > \n,Update checkstyle to 8 . 29 and netty - build to 26 ( # 9990 ) \n Motivation : \n A new checkstyle version was released which fixes a security vulnerability . \n Modifications : \n - Update to latest checkstyle version \n - Update netty - build to latest version to be compatible with latest checkstyle version \n Result : \n No more security vulnerability caused by checkstyle during build,381
"transport - blockhound - tests \ src \ test \ java \ io \ netty \ util \ internal \ NettyBlockHoundIntegrationTest . java \n - import static org . junit . Assert . assertNotNull ; \n + String tlsVersion = "" TLSv1 . 2 "" ; \n - . sslProvider ( SslProvider . JDK ) . build ( ) ; \n + . sslProvider ( SslProvider . JDK ) . protocols ( tlsVersion ) . build ( ) ; \n - . sslProvider ( SslProvider . JDK ) . build ( ) ; \n + . sslProvider ( SslProvider . JDK ) . protocols ( tlsVersion ) . build ( ) ; \n",Hardcode TLS version used during blockhound tests ( # 10162 ) \n Motivation : \n Different versions of the JDK use different TLS versions by default . We should define the versions explicit \n Modifications : \n Explicit specify TLSv1 . 2 \n Result : \n Blockhound tests pass on JDK14 as well,381
pom . xml \n - < tcnative . version > 2 . 0 . 29 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 30 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 30 . Final to fix small memory leak ( # 10118 ) \n Motivation : \n A new netty - tcnative version was just released which fixes a small memory leak . \n Modifications : \n Update to 2 . 0 . 30 . Final \n Result : \n Small memory leak fixed,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 1 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n new file \n docker \ docker - compose . centos - 6 . 114 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - 1 . 14 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + java _ version : "" adopt @ 1 . 14 . 0 - 0 "" \n + \n + test : \n + image : netty : centos - 6 - 1 . 14 \n + \n + test - leak : \n + image : netty : centos - 6 - 1 . 14 \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - 1 . 14 \n + \n + shell : \n + image : netty : centos - 6 - 1 . 14 \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 1 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n new file \n docker \ docker - compose . centos - 7 . 114 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 7 - 1 . 14 \n + build : \n + args : \n + centos _ version : "" 7 "" \n + java _ version : "" @ 1 . 14 . 0 - 0 "" \n + \n + test : \n + image : netty : centos - 7 - 1 . 14 \n + \n + test - leak : \n + image : netty : centos - 7 - 1 . 14 \n + \n + test - boringssl - static : \n + image : netty : centos - 7 - 1 . 14 \n + \n + shell : \n + image : netty : centos - 7 - 1 . 14 \n",Add JDK 14 and update JDK 13 for builds ( # 10136 ) \n Motivation : \n JDK 14 was released so we should include it in our build matrix . Beside this there was also a JDK 13 update \n Modifications : \n - Add docker - compose files for JDK 14 \n - Update JDK 13 version \n Result : \n Build with JDK 14 as well and use latest JDK 13 release,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslHandlerTest . java \n - assertThat ( cause , CoreMatchers . < Throwable > instanceOf ( SSLException . class ) ) ; \n - assertThat ( cause . getMessage ( ) , containsString ( "" timed out "" ) ) ; \n + assertThat ( cause , CoreMatchers . < Throwable > instanceOf ( SslHandshakeTimeoutException . class ) ) ; \n - assertThat ( cause , CoreMatchers . < Throwable > instanceOf ( SSLException . class ) ) ; \n - assertThat ( cause . getMessage ( ) , containsString ( "" timed out "" ) ) ; \n + assertThat ( cause , CoreMatchers . < Throwable > instanceOf ( SslHandshakeTimeoutException . class ) ) ; \n",Update test to directly check for SslHandshakeTimeoutException ( # 10339 ) \n Motivation : \n 9b7e091 added a special SSLHandshakeException sub - class to signal handshake timeouts but we missed to update a testcase to directly assert the type of the exception . \n Modifications : \n Assert directly that SslHandshakeTimeoutException is used \n Result : \n Test cleanup,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 8 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 9 "" \n docker \ docker - compose . centos - 6 . 115 . yaml \n - java _ version : "" zulu @ 1 . 15 . 0 - 0 "" \n + java _ version : "" zulu @ 1 . 15 . 0 - 1 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 265 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 272 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 7 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 9 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 8 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 9 "" \n docker \ docker - compose . centos - 7 . 115 . yaml \n - java _ version : "" adopt @ 1 . 15 . 0 - 0 "" \n + java _ version : "" adopt @ 1 . 15 . 0 - 1 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 265 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 272 "" \n",Update to latest java 8 / 11 / 15 versions ( # 10774 ) \n Motivation : \n There were new releases of java . \n Modifications : \n Update java versions so we use the latest on the CI \n Result : \n Use latest releases,381
pom . xml \n - < version > 1 . 54 < / version > \n + < version > 1 . 65 < / version > \n,Update Bouncycastle dependency ( # 10185 ) \n Motivation : \n We should update our optional bouncycastle dependency to ensure we use the latest which has all the security fixes \n Modifications : \n Update bouncycastle version \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10184,381
transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ Native . java \n + import java . nio . channels . Selector ; \n + Selector selector = null ; \n + try { \n + / / We call Selector . open ( ) as this will under the hood cause IOUtil to be loaded . \n + / / This is a workaround for a possible classloader deadlock that could happen otherwise : \n + / / \n + / / See https : / / github . com / netty / netty / issues / 10187 \n + selector = Selector . open ( ) ; \n + } catch ( IOException ignore ) { \n + / / Just ignore \n + } \n + } finally { \n + try { \n + if ( selector ! = null ) { \n + selector . close ( ) ; \n + } \n + } catch ( IOException ignore ) { \n + / / Just ignore \n + } \n,Add workaround for possible classloader deadlock when trying to load JNI code ( # 10190 ) \n Motivation : \n netty _ epoll _ linuxsocket _ JNI _ OnLoad ( . . . ) may produce a deadlock with another thread that will load IOUtil in a static block . This seems to be a JDK bug which is not yet fixed . To workaround this we force IOUtil to be loaded from without java code before init the JNI code \n Modifications : \n Use Selector . open ( ) as a workaround to load IOUtil \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10187,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ JdkAlpnApplicationProtocolNegotiator . java \n - throw new RuntimeException ( "" Unable to wrap SSLEngine of type "" + engine . getClass ( ) . getName ( ) ) ; \n + throw new UnsupportedOperationException ( "" ALPN not supported . Unable to wrap SSLEngine of type ' "" \n + + engine . getClass ( ) . getName ( ) + "" ' ) "" ) ; \n",Clarify exception message when ALPN is not supported ( # 10155 ) \n Motivation : \n We should provide more informations when ALPN is not supported and a user tries to use it . \n Modifications : \n - Use UnsupportedOperationException \n Result : \n Easier to debug ALPN problems,381
codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2ConnectionHandler . java \n + private boolean closed ; \n + / / We need to guard against multiple calls as the timeout may trigger close ( ) first and then it will be \n + / / triggered again because of operationComplete ( . . . ) is called . \n + if ( closed ) { \n + / / This only happens if we also scheduled a timeout task . \n + assert timeoutTask ! = null ; \n + return ; \n + } \n + closed = true ; \n,HTTP2 : Guard against multiple ctx . close ( . . . ) calls with the same ChannelPromise ( # 10201 ) \n Motivation : \n Http2ConnectionHandler may call ctx . close ( . . . ) with the same promise instance multiple times if the timeout for gracefulShutdown elapse and the listener itself is notified . This can cause problems as other handlers in the pipeline may queue these promises and try to notify these later via setSuccess ( ) or setFailure ( . . . ) which will then throw an IllegalStateException if the promise was notified already \n Modification : \n - Add boolean flag to ensure doClose ( ) will only try to call ctx . close ( . . . ) one time \n Result : \n Don ' t call ctx . close ( . . . ) with the same promise multiple times when gradefulShutdown timeout elapses .,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ Unpooled . java \n + import io . netty . util . CharsetUtil ; \n - \n + if ( CharsetUtil . UTF _ 8 . equals ( charset ) ) { \n + return copiedBufferUtf8 ( string ) ; \n + } \n + if ( CharsetUtil . US _ ASCII . equals ( charset ) ) { \n + return copiedBufferAscii ( string ) ; \n + } \n + private static ByteBuf copiedBufferUtf8 ( CharSequence string ) { \n + boolean release = true ; \n + / / Mimic the same behavior as other copiedBuffer implementations . \n + ByteBuf buffer = ALLOC . heapBuffer ( ByteBufUtil . utf8Bytes ( string ) ) ; \n + try { \n + ByteBufUtil . writeUtf8 ( buffer , string ) ; \n + release = false ; \n + return buffer ; \n + } finally { \n + if ( release ) { \n + buffer . release ( ) ; \n + } \n + } \n + } \n + \n + private static ByteBuf copiedBufferAscii ( CharSequence string ) { \n + boolean release = true ; \n + / / Mimic the same behavior as other copiedBuffer implementations . \n + ByteBuf buffer = ALLOC . heapBuffer ( string . length ( ) ) ; \n + try { \n + ByteBufUtil . writeAscii ( buffer , string ) ; \n + release = false ; \n + return buffer ; \n + } finally { \n + if ( release ) { \n + buffer . release ( ) ; \n + } \n + } \n + } \n + \n buffer \ src \ test \ java \ io \ netty \ buffer \ UnpooledTest . java \n + import io . netty . util . CharsetUtil ; \n + import java . nio . charset . Charset ; \n + @ Test \n + public void testCopiedBufferUtf8 ( ) { \n + testCopiedBufferCharSequence ( "" Some UTF _ 8 like äÄ∏ŒŒ "" , CharsetUtil . UTF _ 8 ) ; \n + } \n + \n + @ Test \n + public void testCopiedBufferAscii ( ) { \n + testCopiedBufferCharSequence ( "" Some US _ ASCII "" , CharsetUtil . US _ ASCII ) ; \n + } \n + \n + @ Test \n + public void testCopiedBufferSomeOtherCharset ( ) { \n + testCopiedBufferCharSequence ( "" Some ISO _ 8859 _ 1 "" , CharsetUtil . ISO _ 8859 _ 1 ) ; \n + } \n + \n + private static void testCopiedBufferCharSequence ( CharSequence sequence , Charset charset ) { \n + ByteBuf copied = copiedBuffer ( sequence , charset ) ; \n + try { \n + assertEquals ( sequence , copied . toString ( charset ) ) ; \n + } finally { \n + copied . release ( ) ; \n + } \n + } \n + \n","Add fastpath implementation for Unpooled . copiedBuffer ( CharSequence , Charset ) when UTF - 8 or US - ASCII is used ( # 10206 ) \n Motivation : \n We can make use of our optimized implementations for UTF - 8 and US - ASCII if the user request a copy of a sequence for these charsets \n Modifications : \n - Add fastpath implementation \n - Add unit tests \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10205",381
"resolver - dns \ src \ main \ java \ io \ netty \ resolver \ dns \ DnsNameResolver . java \n + import io . netty . handler . codec . CorruptedFrameException ; \n - logger . warn ( "" { } Received a DNS response with an unknown ID : { } "" , ch , queryId ) ; \n + logger . debug ( "" Received a DNS response with an unknown ID : UDP [ { } : { } ] "" , ch , queryId ) ; \n - logger . debug ( "" { } Unable to fallback to TCP [ { } ] "" , queryId , future . cause ( ) ) ; \n + logger . debug ( "" Unable to fallback to TCP [ { } ] "" , queryId , future . cause ( ) ) ; \n - tcpCtx . tryFailure ( "" Received TCP response with unexpected ID "" , null , false ) ; \n - logger . warn ( "" { } Received a DNS response with an unexpected ID : { } "" , \n + tcpCtx . tryFailure ( "" Received TCP DNS response with unexpected ID "" , null , false ) ; \n + logger . debug ( "" Received a DNS response with an unexpected ID : TCP [ { } : { } ] "" , \n - logger . warn ( "" { } Unexpected exception : "" , ctx . channel ( ) , cause ) ; \n + if ( cause instanceof CorruptedFrameException ) { \n + logger . debug ( "" Unable to decode DNS response : UDP [ { } ] "" , ctx . channel ( ) , cause ) ; \n + } else { \n + logger . warn ( "" Unexpected exception : UDP [ { } ] "" , ctx . channel ( ) , cause ) ; \n + } \n",Don ' t log with warn level in the DnsNameResolver in most cases ( # 10225 ) \n Motivation : \n We should only log with warn level if something really critical happens as otherwise we may spam logs and confuse the user . \n Modifications : \n - Change log level to debug for most cases \n Result : \n Less noisy logging,381
codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ multipart \ HttpPostMultipartRequestDecoder . java \n + ByteBuf line = buffer ( 64 ) ; \n - ByteBuf line = buffer ( 64 ) ; \n - \n + } finally { \n + line . release ( ) ; \n + ByteBuf line = buffer ( 64 ) ; \n - ByteBuf line = buffer ( 64 ) ; \n - \n + } finally { \n + line . release ( ) ; \n,Fix memory leak in HttpPostMultipartRequestDecoder ( # 10227 ) \n Motivation : \n We need to release all ByteBufs that we allocate to prevent leaks . We missed to release the ByteBufs that are used to aggregate in two cases \n Modifications : \n Add release ( ) calls \n Result : \n No more memory leak in HttpPostMultipartRequestDecoder,381
codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ rtsp \ RtspDecoderTest . java \n - System . out . println ( res1 ) ; \n,Remove some debugging cruft ( # 10229 ) \n Motivation : \n RtspDecoderTest did include a println ( . . . ) call which was a left over from debugging . \n Modifications : \n Remove println ( . . . ) \n Result : \n Cleanup,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ JdkSslClientContextTest . java \n - protected SslContext newServerContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n + protected SslContext newSslContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ JdkSslServerContextTest . java \n - protected SslContext newServerContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n + protected SslContext newSslContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslClientContextTest . java \n - protected SslContext newServerContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n + protected SslContext newSslContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ OpenSslServerContextTest . java \n - protected SslContext newServerContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n + protected SslContext newSslContext ( File crtFile , File keyFile , String pass ) throws SSLException { \n handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SslContextTest . java \n - public void testSslServerWithEncryptedPrivateKey ( ) throws SSLException { \n + public void testSslContextWithEncryptedPrivateKey ( ) throws SSLException { \n - newServerContext ( crtFile , keyFile , "" 12345 "" ) ; \n + newSslContext ( crtFile , keyFile , "" 12345 "" ) ; \n - public void testSslServerWithEncryptedPrivateKey2 ( ) throws SSLException { \n + public void testSslContextWithEncryptedPrivateKey2 ( ) throws SSLException { \n - newServerContext ( crtFile , keyFile , "" 12345 "" ) ; \n + newSslContext ( crtFile , keyFile , "" 12345 "" ) ; \n - public void testSslServerWithUnencryptedPrivateKey ( ) throws SSLException { \n + public void testSslContextWithUnencryptedPrivateKey ( ) throws SSLException { \n - newServerContext ( crtFile , keyFile , null ) ; \n + newSslContext ( crtFile , keyFile , null ) ; \n - public void testSslServerWithUnencryptedPrivateKeyEmptyPass ( ) throws SSLException { \n + public void testSslContextWithUnencryptedPrivateKeyEmptyPass ( ) throws SSLException { \n - newServerContext ( crtFile , keyFile , "" "" ) ; \n + newSslContext ( crtFile , keyFile , "" "" ) ; \n - SslContext sslContext = newServerContext ( crtFile , keyFile , null ) ; \n + SslContext sslContext = newSslContext ( crtFile , keyFile , null ) ; \n - public void test ( ) throws CertificateException { \n + public void testUnsupportedParams ( ) throws CertificateException { \n - protected abstract SslContext newServerContext ( File crtFile , File keyFile , String pass ) throws SSLException ; \n + protected abstract SslContext newSslContext ( File crtFile , File keyFile , String pass ) throws SSLException ; \n",Rename testmethods to make these more clear ( # 10231 ) \n Motivation : \n The currently used method names don ' t make a lot of sense . \n Modifications : \n Rename to cleanup \n Result : \n Cleanup,381
all \ pom . xml \n - < version > 19 < / version > \n - < exclusions > \n - < ! - - Use version 7 . 3 until a new netty - build release is out - - > \n - < ! - - See https : / / issues . apache . org / jira / browse / JXR - 133 - - > \n - < exclusion > \n - < groupId > com . puppycrawl . tools < / groupId > \n - < artifactId > checkstyle < / artifactId > \n - < / exclusion > \n - < / exclusions > \n - < / dependency > \n - < dependency > \n - < groupId > com . puppycrawl . tools < / groupId > \n - < artifactId > checkstyle < / artifactId > \n - < version > 7 . 3 < / version > \n + < version > $ { netty . build . version } < / version > \n,Use latest checkstyle version for all artifact as well . ( # 9993 ) \n Motivation : \n 42aa7f0c58375c6fcdc9a3ed26b431999c63c6c7 did update the checkstyle version but missed that we declared it explicitly in the all artifact as well . \n Modifications : \n Remove explicit definition in the all artifact . \n Result : \n Use latest checkstyle version everywhere .,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ PooledByteBufAllocator . java \n - DEFAULT _ CACHE _ TRIM _ INTERVAL _ MILLIS = SystemPropertyUtil . getLong ( \n - "" io . netty . allocation . cacheTrimIntervalMillis "" , 0 ) ; \n + if ( SystemPropertyUtil . contains ( "" io . netty . allocation . cacheTrimIntervalMillis "" ) ) { \n + logger . warn ( "" - Dio . netty . allocation . cacheTrimIntervalMillis is deprecated , "" + \n + "" use - Dio . netty . allocator . cacheTrimIntervalMillis "" ) ; \n + \n + if ( SystemPropertyUtil . contains ( "" io . netty . allocator . cacheTrimIntervalMillis "" ) ) { \n + / / Both system properties are specified . Use the non - deprecated one . \n + DEFAULT _ CACHE _ TRIM _ INTERVAL _ MILLIS = SystemPropertyUtil . getLong ( \n + "" io . netty . allocator . cacheTrimIntervalMillis "" , 0 ) ; \n + } else { \n + DEFAULT _ CACHE _ TRIM _ INTERVAL _ MILLIS = SystemPropertyUtil . getLong ( \n + "" io . netty . allocation . cacheTrimIntervalMillis "" , 0 ) ; \n + } \n + } else { \n + DEFAULT _ CACHE _ TRIM _ INTERVAL _ MILLIS = SystemPropertyUtil . getLong ( \n + "" io . netty . allocator . cacheTrimIntervalMillis "" , 0 ) ; \n + } \n",Use correct system property name in PooledByteBufAllocator ( io . netty . allocator . cacheTrimIntervalMillis ) ( # 9994 ) \n Motivation : \n We had a typo in the system property name that was used to lookup the cache trime interval . We should ensure we use the correct naming when lookup the property \n Modifications : \n - Support the old and the new ( correct ) naming of the property when configure the cache trim interval . \n - Log something if someone uses the old ( deprecated ) name \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9981,381
codec \ src \ main \ java \ io \ netty \ handler \ codec \ ProtocolDetectionResult . java \n - private static final ProtocolDetectionResult NEEDS _ MORE _ DATE = \n + private static final ProtocolDetectionResult NEEDS _ MORE _ DATA = \n - return NEEDS _ MORE _ DATE ; \n + return NEEDS _ MORE _ DATA ; \n,"Update ProtocolDetectionResult to fix typo ( # 10086 ) \n Motivation : \n Correct a typo . \n Modification : \n Changed a name of a private constant variable , ' NEEDS _ MORE _ DATE ' to ' NEEDS _ MORE _ DATA ' \n Result : \n Cleanup",381
common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n - import java . util . concurrent . ConcurrentMap ; \n - private static final class TraceRecord extends Throwable { \n + private static class TraceRecord extends Throwable { \n - private static final TraceRecord BOTTOM = new TraceRecord ( ) ; \n + private static final TraceRecord BOTTOM = new TraceRecord ( ) { \n + private static final long serialVersionUID = 7396077602074694571L ; \n + \n + / / Override fillInStackTrace ( ) so we not populate the backtrace via a native call and so leak the \n + / / Classloader . \n + / / See https : / / github . com / netty / netty / pull / 10691 \n + @ Override \n + public Throwable fillInStackTrace ( ) { \n + return this ; \n + } \n + } ; \n,Ensure we don ' t leak the ClassLoader in the backtrace of TrackRecord . BOTTOM ( # 10839 ) \n Motivation : \n We need to ensure we override fillInStacktrace ( ) when we store exceptions in static fields to not leak the Classloader in the backtrace . \n Came up in https : / / github . com / netty / netty / pull / 10691 # issuecomment - 738331186 . Thanks to @ amir - shalem for notice this one . \n Modifications : \n - Add overrides of fillInStracktrace in TrackRecord . BOTTOM \n Result : \n Related fix to https : / / github . com / netty / netty / pull / 10686,381
"docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 3 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 3 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n",Use correct JDK 13 version ( # 10276 ) \n Motivation : \n We had a typo in the JDK 13 version to use . \n Modifications : \n Use the correct version string \n Result : \n Be able to run CI with JDK13 again,381
all \ pom . xml \n - < classifier > linux - aarch _ 64 < / classifier > \n + < classifier > linux - aarch64 < / classifier > \n - < classifier > linux - aarch _ 64 < / classifier > \n + < classifier > linux - aarch64 < / classifier > \n,Fix classifier for aarch64 ( # 10279 ) \n Motivation : \n The defined classifier for aarch64 was not correct \n Modifications : \n Fix classifier \n Result : \n Be able to correctly include the aarch64 native libs,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslClientContext . java \n + import io . netty . util . internal . SystemPropertyUtil ; \n + private static final boolean ENABLE _ SESSION _ TICKET = \n + SystemPropertyUtil . getBoolean ( "" jdk . tls . client . enableSessionTicketExtension "" , false ) ; \n + if ( ENABLE _ SESSION _ TICKET ) { \n + sessionContext . setTicketKeys ( ) ; \n + } \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslServerContext . java \n + import io . netty . util . internal . SystemPropertyUtil ; \n + private static final boolean ENABLE _ SESSION _ TICKET = \n + SystemPropertyUtil . getBoolean ( "" jdk . tls . server . enableSessionTicketExtension "" , false ) ; \n + \n + if ( ENABLE _ SESSION _ TICKET ) { \n + sessionContext . setTicketKeys ( ) ; \n + } \n",Respect jdk . tls . client . enableSessionTicketExtension and jdk . tls . server . enableSessionTicketExtension when using native SSL impl ( # 10296 ) \n Motivation : \n We should respect jdk . tls . client . enableSessionTicketExtension and jdk . tls . server . enableSessionTicketExtension when using the native SSL implementation as well to make the usage of it easier and more consistent . These properties were introduced by JDK13 : \n https : / / seanjmullan . org / blog / 2019 / 08 / 05 / jdk13 \n Modifications : \n Check if the properties are set to true and if so enable tickets \n Result : \n Easier to enable tickets and be more consistent,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - SSL . setVerify ( ssl , verifyMode , depth ) ; \n + if ( ! isDestroyed ( ) ) { \n + SSL . setVerify ( ssl , verifyMode , depth ) ; \n + } \n - switch ( mode ) { \n - case NONE : \n - SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ NONE , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n - break ; \n - case REQUIRE : \n - SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ REQUIRED , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n - break ; \n - case OPTIONAL : \n - SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ OPTIONAL , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n - break ; \n - default : \n - throw new Error ( mode . toString ( ) ) ; \n + if ( ! isDestroyed ( ) ) { \n + switch ( mode ) { \n + case NONE : \n + SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ NONE , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n + break ; \n + case REQUIRE : \n + SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ REQUIRED , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n + break ; \n + case OPTIONAL : \n + SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ OPTIONAL , ReferenceCountedOpenSslContext . VERIFY _ DEPTH ) ; \n + break ; \n + default : \n + throw new Error ( mode . toString ( ) ) ; \n + } \n + boolean isDestroyed = isDestroyed ( ) ; \n - if ( ! isDestroyed ( ) ) { \n + if ( ! isDestroyed ) { \n - final boolean endPointVerificationEnabled = isEndPointVerificationEnabled ( endPointIdentificationAlgorithm ) ; \n - \n - / / If the user asks for hostname verification we must ensure we verify the peer . \n - / / If the user disables hostname verification we leave it up to the user to change the mode manually . \n - if ( clientMode & & endPointVerificationEnabled ) { \n - SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ REQUIRED , - 1 ) ; \n + if ( ! isDestroyed ) { \n + / / If the user asks for hostname verification we must ensure we verify the peer . \n + / / If the user disables hostname verification we leave it up to the user to change the mode manually . \n + if ( clientMode & & isEndPointVerificationEnabled ( endPointIdentificationAlgorithm ) ) { \n + SSL . setVerify ( ssl , SSL . SSL _ CVERIFY _ REQUIRED , - 1 ) ; \n + } \n - \n",Check if SSL pointer was freed before using it in RefereceCountedOpenSslEngine in all cases ( # 10299 ) \n Motivation : \n To ensure we not crash in all cases we should better check that the SSL pointer was not freed before using it . \n Modifications : \n Add missing ` isDestroyed ( ) ` checks \n Result : \n Ensure we not crash due usage of freed pointer .,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ multipart \ AbstractDiskHttpData . java \n - ByteBuffer byteBuffer = buffer . nioBufferCount ( ) = = 1 ? buffer . nioBuffer ( ) : buffer . copy ( ) . nioBuffer ( ) ; \n - while ( written < localsize ) { \n - written + = fileChannel . write ( byteBuffer ) ; \n - } \n + buffer . getBytes ( buffer . readerIndex ( ) , fileChannel , fileChannel . position ( ) , localsize ) ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ multipart \ DiskFileUploadTest . java \n + import io . netty . buffer . ByteBufUtil ; \n + @ Test \n + public void testAddContentFromByteBuf ( ) throws Exception { \n + testAddContentFromByteBuf0 ( false ) ; \n + } \n + \n + @ Test \n + public void testAddContentFromCompositeByteBuf ( ) throws Exception { \n + testAddContentFromByteBuf0 ( true ) ; \n + } \n + \n + private static void testAddContentFromByteBuf0 ( boolean composite ) throws Exception { \n + DiskFileUpload f1 = new DiskFileUpload ( "" file3 "" , "" file3 "" , "" application / json "" , null , null , 0 ) ; \n + try { \n + byte [ ] bytes = new byte [ 4096 ] ; \n + PlatformDependent . threadLocalRandom ( ) . nextBytes ( bytes ) ; \n + \n + final ByteBuf buffer ; \n + \n + if ( composite ) { \n + buffer = Unpooled . compositeBuffer ( ) \n + . addComponent ( true , Unpooled . wrappedBuffer ( bytes , 0 , bytes . length / 2 ) ) \n + . addComponent ( true , Unpooled . wrappedBuffer ( bytes , bytes . length / 2 , bytes . length / 2 ) ) ; \n + } else { \n + buffer = Unpooled . wrappedBuffer ( bytes ) ; \n + } \n + f1 . addContent ( buffer , true ) ; \n + ByteBuf buf = f1 . getByteBuf ( ) ; \n + assertEquals ( buf . readerIndex ( ) , 0 ) ; \n + assertEquals ( buf . writerIndex ( ) , bytes . length ) ; \n + assertArrayEquals ( bytes , ByteBufUtil . getBytes ( buf ) ) ; \n + } finally { \n + / / release the ByteBuf \n + f1 . delete ( ) ; \n + } \n + } \n + \n",Fix memory leak in AbstractDiskHttpData when CompositeByteBuf is used ( # 10360 ) \n Motivation : \n AbstractDiskHttpData may cause a memory leak when a CompositeByteBuf is used . This happened because we may call copy ( ) but actually never release the newly created ByteBuf . \n Modifications : \n - Remove copy ( ) call and just use ByteBuf . getBytes ( . . . ) which will internally handle the writing to the FileChannel without any extra copies that need to be released later on . \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10354,381
transport \ src \ main \ java \ io \ netty \ channel \ ChannelPipeline . java \n + import io . netty . util . concurrent . UnorderedThreadPoolEventExecutor ; \n + * Be aware that while using { @ link DefaultEventLoopGroup } will offload the operation from the { @ link EventLoop } it will \n + * still process tasks in a serial fashion per { @ link ChannelHandlerContext } and so guarantee ordering . Due the ordering \n + * it may still become a bottle - neck . If ordering is not a requirement for your use - case you may want to consider using \n + * { @ link UnorderedThreadPoolEventExecutor } to maximize the parallelism of the task execution . \n + * \n,Expand ChannelPipeline javadocs to cover UnorderedThreadPoolEventExecutor ( # 10361 ) \n Motivation : \n Seems like some users are suprised by the behaviour of DefaultEventExecutor when used within the ChannelPipeline . We should clarify the semantics and also mention UnordedThreadPoolEventExecutor which may be more inline with their expectations \n Modifications : \n Add javadocs section about UnorderedThreadPoolEventExecutor and expand details for DefaultEventExecutor \n Result : \n Clarify sematics,381
"handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SSLEngineTest . java \n + boolean cTOsHasRemaining ; \n + boolean sTOcHasRemaining ; \n + \n + cTOsHasRemaining = cTOs . hasRemaining ( ) ; \n + sTOcHasRemaining = sTOc . hasRemaining ( ) ; \n + \n - } while ( ! clientHandshakeFinished | | ! serverHandshakeFinished ) ; \n + } while ( ! clientHandshakeFinished | | ! serverHandshakeFinished | | \n + / / We need to ensure we feed all the data to the engine to not end up with a corrupted state . \n + / / This is especially important with TLS1 . 3 which may produce sessions after the "" main handshake "" is \n + / / done \n + cTOsHasRemaining | | sTOcHasRemaining ) ; \n","Ensure we feed all data to the SSLEngine during handshaking in our tests ( # 10373 ) \n Motivation : \n Due a bug in our test we may dropped data on the floor which are generated during handshaking ( or slightly after ) . This could lead to corrupt state in the engine itself and so fail tests . This is especially true for TLS1 . 3 which generates the sessions on the server after the "" actual handshake "" is done . \n Modifications : \n Contine with wrap / unwrap until all data was consumed \n Result : \n Correctly feed all data to the engine during testing",381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslX509TrustManagerWrapper . java \n + import java . security . NoSuchProviderException ; \n - private static SSLContext newSSLContext ( ) throws NoSuchAlgorithmException { \n - return SSLContext . getInstance ( "" TLS "" ) ; \n + private static SSLContext newSSLContext ( ) throws NoSuchAlgorithmException , NoSuchProviderException { \n + / / As this depends on the implementation detail we should explicit select the correct provider . \n + / / See https : / / github . com / netty / netty / issues / 10374 \n + return SSLContext . getInstance ( "" TLS "" , "" SunJSSE "" ) ; \n - / / This should never happen as we did the same in the static \n + / / This should never happen as we did the same in the static block \n - / / This should never happen as we did the same in the static \n + / / This should never happen as we did the same in the static block \n + / / before . \n + PlatformDependent . throwException ( e ) ; \n + } catch ( NoSuchProviderException e ) { \n + / / This should never happen as we did the same in the static block \n",X509TrustManager with OPENSSL provider is not wrapped with hostname verification if Conscrypt is inserted in the first place ( # 10375 ) \n Motivation : \n Modifications : \n Directly specify the provider which is used to create the SSLContext \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10374,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ Http2StreamChannelBootstrap . java \n + import java . util . LinkedHashMap ; \n - private final Map < ChannelOption < ? > , Object > options = new ConcurrentHashMap < ChannelOption < ? > , Object > ( ) ; \n + / / The order in which ChannelOptions are applied is important they may depend on each other for validation \n + / / purposes . \n + private final Map < ChannelOption < ? > , Object > options = new LinkedHashMap < ChannelOption < ? > , Object > ( ) ; \n - if ( value = = null ) { \n - options . remove ( option ) ; \n - } else { \n - options . put ( option , value ) ; \n + \n + synchronized ( options ) { \n + if ( value = = null ) { \n + options . remove ( option ) ; \n + } else { \n + options . put ( option , value ) ; \n + } \n - setChannelOptions ( channel , options . entrySet ( ) . toArray ( EMPTY _ OPTION _ ARRAY ) ) ; \n + final Map . Entry < ChannelOption < ? > , Object > [ ] optionArray ; \n + synchronized ( options ) { \n + optionArray = options . entrySet ( ) . toArray ( EMPTY _ OPTION _ ARRAY ) ; \n + } \n + \n + setChannelOptions ( channel , optionArray ) ; \n",Ensure ChannelOptions are applied in the same order as configured in Http2StreamChannelBootstrap ( # 9998 ) ( # 10001 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 9848 changed how we handled ChannelOptions internally to use a ConcurrentHashMap . This unfortunally had the side - effect that the ordering may be affected and not stable anymore . Here the problem is that sometimes we do validation based on two different ChannelOptions ( for example we validate high and low watermarks against each other ) . Thus even if the user specified the options in the same order we may fail to configure them . \n Modifications : \n - Use again a LinkedHashMap to preserve order \n Result : \n Apply ChannelOptions in correct and expected order,381
"codec - http \ src \ main \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketProtocolHandler . java \n + import io . netty . channel . ChannelPromiseNotifier ; \n - return ; \n - } \n - if ( msg instanceof CloseWebSocketFrame ) { \n - promise = promise . unvoid ( ) ; \n - closeSent = promise ; \n + } else if ( msg instanceof CloseWebSocketFrame ) { \n + closeSent = promise . unvoid ( ) ; \n + ctx . write ( msg ) . addListener ( new ChannelPromiseNotifier ( false , closeSent ) ) ; \n + } else { \n + ctx . write ( msg , promise ) ; \n - ctx . write ( msg , promise ) ; \n codec - http \ src \ test \ java \ io \ netty \ handler \ codec \ http \ websocketx \ WebSocketProtocolHandlerTest . java \n + import io . netty . channel . ChannelFuture ; \n + import io . netty . channel . ChannelHandlerContext ; \n + import io . netty . channel . ChannelOutboundHandlerAdapter ; \n + import io . netty . channel . ChannelPromise ; \n + import io . netty . util . ReferenceCountUtil ; \n + import org . hamcrest . Matchers ; \n + import java . util . concurrent . atomic . AtomicReference ; \n + \n + @ Test \n + public void testTimeout ( ) throws Exception { \n + final AtomicReference < ChannelPromise > ref = new AtomicReference < ChannelPromise > ( ) ; \n + WebSocketProtocolHandler handler = new WebSocketProtocolHandler ( \n + false , WebSocketCloseStatus . NORMAL _ CLOSURE , 1 ) { } ; \n + EmbeddedChannel channel = new EmbeddedChannel ( new ChannelOutboundHandlerAdapter ( ) { \n + @ Override \n + public void write ( ChannelHandlerContext ctx , Object msg , ChannelPromise promise ) { \n + ref . set ( promise ) ; \n + ReferenceCountUtil . release ( msg ) ; \n + } \n + } , handler ) ; \n + \n + ChannelFuture future = channel . writeAndFlush ( new CloseWebSocketFrame ( ) ) ; \n + ChannelHandlerContext ctx = channel . pipeline ( ) . context ( WebSocketProtocolHandler . class ) ; \n + handler . close ( ctx , ctx . newPromise ( ) ) ; \n + \n + do { \n + Thread . sleep ( 10 ) ; \n + channel . runPendingTasks ( ) ; \n + } while ( ! future . isDone ( ) ) ; \n + \n + assertThat ( future . cause ( ) , Matchers . instanceOf ( WebSocketHandshakeException . class ) ) ; \n + assertFalse ( ref . get ( ) . isDone ( ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n + \n",Don ' t reuse ChannelPromise in WebSocketProtocolHandler ( # 10248 ) \n Motivation : \n We cant reuse the ChannelPromise as it will cause an error when trying to ful - fill it multiple times . \n Modifications : \n - Use a new promise and chain it with the old one \n - Add unit test \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10240,381
all \ pom . xml \n - < classifier > linux - aarch64 < / classifier > \n + < classifier > linux - aarch _ 64 < / classifier > \n - < classifier > linux - aarch64 < / classifier > \n + < classifier > linux - aarch _ 64 < / classifier > \n docker \ README . md \n - docker - compose - f docker / docker - compose . yaml run cross - compile - aarch64 \n + docker - compose - f docker / docker - compose . yaml run cross - compile - aarch64 - build \n docker \ docker - compose . yaml \n - cross - compile - aarch64 : \n + cross - compile - aarch64 - shell : \n + image : netty : cross _ compile _ aarch64 \n + depends _ on : [ cross - compile - aarch64 - runtime - setup ] \n + volumes : \n + - ~ / . ssh : / root / . ssh : delegated \n + - ~ / . gnupg : / root / . gnupg : delegated \n + - . . : / code : delegated \n + - ~ / . m2 : / root / . m2 : delegated \n + entrypoint : / bin / bash \n + working _ dir : / code \n + \n + cross - compile - aarch64 - build : \n transport - native - epoll \ pom . xml \n - < jni . classifier > $ { os . detected . name } - aarch64 < / jni . classifier > \n + < ! - - use aarch _ 64 as this is also what os . detected . arch will use on an aarch64 system - - > \n + < jni . classifier > $ { os . detected . name } - aarch _ 64 < / jni . classifier > \n transport - native - unix - common \ pom . xml \n - < jni . classifier > $ { os . detected . name } - aarch64 < / jni . classifier > \n + < ! - - use aarch _ 64 as this is also what os . detected . arch will use on an aarch64 system - - > \n + < jni . classifier > $ { os . detected . name } - aarch _ 64 < / jni . classifier > \n,Use aarch _ 64 in a consistent way ( # 10845 ) \n Motivation : \n We should use aarch _ 64 in our classifier / jni libname on aarch64 as os . detected . arch uses the name . Being non consistent ( especially across our different projects ) already gave us a lot of trouble in the past . \n Let ' s fix this once for all . \n Modifications : \n Use aarch _ 64 \n Result : \n More consistent classifier usage on aarch64,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslClientContext . java \n - if ( ENABLE _ SESSION _ TICKET ) { \n - sessionContext . setTicketKeys ( ) ; \n - } \n + if ( ENABLE _ SESSION _ TICKET ) { \n + context . setTicketKeys ( ) ; \n + } \n,jdk . tls . client . enableSessionTicketExtension must be respected by OPENSSL and OPENSSL _ REFCNT SslProviders ( # 10401 ) \n Motivation : \n jdk . tls . client . enableSessionTicketExtension property must be respect by OPENSSL and OPENSSL _ REFCNT SslProvider to ensure a consistent behavior . Due a bug this was not the case and it only worked for OPENSSL _ REFCNT but not for OPENSSL . \n Modifications : \n Move the property check into static method that is used by both \n Result : \n Correctly respect jdk . tls . client . enableSessionTicketExtension,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ PoolArena . java \n + final boolean needsNormalAllocation ; \n - if ( s ! = head ) { \n + needsNormalAllocation = s = = head ; \n + if ( ! needsNormalAllocation ) { \n - incSmallAllocation ( ) ; \n - return ; \n - synchronized ( this ) { \n - allocateNormal ( buf , reqCapacity , sizeIdx , cache ) ; \n + if ( needsNormalAllocation ) { \n + synchronized ( this ) { \n + allocateNormal ( buf , reqCapacity , sizeIdx , cache ) ; \n + } \n + \n",Reduce the scope of synchronized block in PoolArena ( # 10410 ) \n Motivation : \n We shouldn ' t call incSmallAllocation ( ) in a synchronized block as its backed by a concurrent datastructure \n Modifications : \n Move call of incSmallAllocation ( ) out of synchronized block \n Result : \n Minimize scope of synchronized block,381
"pom . xml \n - < version > 1 . 0 . 1 . RELEASE < / version > \n + < version > 1 . 0 . 2 . RELEASE < / version > \n transport - blockhound - tests \ src \ test \ java \ io \ netty \ util \ internal \ NettyBlockHoundIntegrationTest . java \n + import org . hamcrest . Matchers ; \n + import reactor . blockhound . BlockingOperationError ; \n + import static org . junit . Assert . assertThat ; \n - Throwable throwable = e . getCause ( ) ; \n - assertNotNull ( "" An exception was thrown "" , throwable ) ; \n - assertTrue ( "" Blocking call was reported "" , throwable . getMessage ( ) . contains ( "" Blocking call "" ) ) ; \n + assertThat ( e . getCause ( ) , Matchers . instanceOf ( BlockingOperationError . class ) ) ; \n",Update to Blockhound 1 . 0 . 2 ( # 10007 ) \n Motivation : \n A new version of blockhound was released today \n Modifications : \n Upgrade to latest blockhound version \n Result : \n Use latest blockhound release,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ FixedCompositeByteBuf . java \n - direct = false ; \n + direct = Unpooled . EMPTY _ BUFFER . isDirect ( ) ; \n buffer \ src \ test \ java \ io \ netty \ buffer \ FixedCompositeByteBufTest . java \n - public void testHasArrayWhenEmpty ( ) { \n + public void testHasArrayWhenEmptyAndIsDirect ( ) { \n + assertEquals ( EMPTY _ BUFFER . isDirect ( ) , buf . isDirect ( ) ) ; \n + assertEquals ( EMPTY _ BUFFER . memoryAddress ( ) , buf . memoryAddress ( ) ) ; \n",FixedCompositeByteBuf . isDirect ( ) may return wrong value when constructed with empty array ( # 10005 ) \n Motivation : \n FixedCompositeByteBuf . isDirect ( ) should return the same value as EMPTY _ BUFFER . isDirect ( ) when constructed via an empty array \n Modifications : \n - Return correct value when constructed via empty array . \n - Add unit test \n Result : \n FixedCompositeByteBuf . isDirect ( ) returns correct value,381
pom . xml \n - < netty . build . version > 26 < / netty . build . version > \n + < netty . build . version > 28 < / netty . build . version > \n - < artifactId > netty - build < / artifactId > \n + < artifactId > netty - build - common < / artifactId > \n - < artifactId > netty - build < / artifactId > \n + < artifactId > netty - build - common < / artifactId > \n - < artifactId > netty - build < / artifactId > \n + < artifactId > netty - build - common < / artifactId > \n,Update netty - build version ( # 10780 ) \n Motivation : \n We recently released a new netty - build version and changed the artifact name \n Modifications : \n Update version and artifact name \n Result : \n Use latest version,381
pom . xml \n - < tcnative . version > 2 . 0 . 34 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 35 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 35 . Final ( # 10850 ) \n Motivation : \n There was a new netty - tcnative release \n Modifications : \n Update to 2 . 0 . 35 . Final \n Result : \n Use latest release,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - SSL . setMode ( ssl , SSL . getMode ( ssl ) | SSL . SSL _ MODE _ ENABLE _ PARTIAL _ WRITE ) ; \n + SSL . setMode ( ssl , SSL . getMode ( ssl ) | SSL . SSL _ MODE _ ENABLE _ PARTIAL _ WRITE \n + | SSL . SSL _ MODE _ ENABLE _ FALSE _ START ) ; \n pom . xml \n - < tcnative . version > 2 . 0 . 31 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 33 . Final < / tcnative . version > \n",Enable SSL _ MODE _ ENABLE _ FALSE _ START if jdkCompatibilityMode is false ( # 10407 ) \n Motivation : \n To reduce latency and RTTs we should use TLS False Start when jdkCompatibilityMode is not required and its supported \n Modifications : \n Use SSL _ MODE _ ENABLE _ FALSE _ START when jdkCompatibilityMode is false \n Result : \n Less RTTs and so lower latency when TLS False Start is supported,381
pom . xml \n - < tcnative . version > 2 . 0 . 33 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 34 . Final < / tcnative . version > \n,Update netty - tcnative to 2 . 0 . 34 . Final ( # 10494 ) \n Motivation : \n A new netty - tcative was released \n Modifications : \n Update to latest version \n Result : \n Use latest version,381
common \ src \ main \ java \ io \ netty \ util \ concurrent \ NonStickyEventExecutorGroup . java \n - try { \n - executor . execute ( this ) ; \n - } catch ( Throwable e ) { \n - / / Not reset the state as some other Runnable may be added to the queue already in the meantime . \n - tasks . remove ( command ) ; \n - PlatformDependent . throwException ( e ) ; \n - } \n + executor . execute ( this ) ; \n,Don ' t try to remove the task when the underlying executor fails the execution of self ( # 10505 ) \n Motivation : \n It makes no sense to remove the task when the underlying executor fails as we may be able to pick it up later . Beside this the used Queue doesnt support remove ( . . . ) and so will throw . \n Modifications : \n Remove the queue . remove ( . . . ) call \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10501 .,381
testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketSslGreetingTest . java \n + import io . netty . util . internal . PlatformDependent ; \n + } catch ( UnsupportedOperationException e ) { \n + / / Starting from Java15 this method throws UnsupportedOperationException as it was \n + / / deprecated before and getPeerCertificates ( ) should be used \n + if ( PlatformDependent . javaVersion ( ) < 15 ) { \n + throw e ; \n + } \n,"Adjust testsuite to pass on JDK15 + ( # 10511 ) \n Motivation : \n JDK15 is about to be released as GA , we should ensure netty works and builds on it . SSLSession # getPeerCertificateChain ( ) throws UnsupportedOperationException in JDK15 and later as it was deprecated before and people should use SSLSession # getPeerCertificates ( ) . We need to account for that in our tests \n Modifications : \n - Catch UnsupportedOperationException in our testsuite and ignore it when on JDK15 + while rethrowing it otherwise . \n Result : \n Testsuite passes on JDK15 +",381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n + if ( bytesProduced > 0 ) { \n + / / If we produced something we should report this back and let the user call \n + / / wrap again . \n + return newResult ( NEED _ WRAP , bytesConsumed , bytesProduced ) ; \n + } \n",Correctly return NEED _ WRAP if we produced some data even if we could not consume any during SSLEngine . wrap ( . . . ) ( # 10396 ) \n Motivation : \n At the moment we may report BUFFER _ OVERFLOW when wrap ( . . . ) fails to consume data but still prodce some . This is not correct and we should better report NEED _ WRAP as we already have produced some data ( for example tickets ) . This way the user will try again without increasing the buffer size which is more correct and may reduce the number of allocations \n Modifications : \n Return NEED _ WRAP when we produced some data but not consumed any . \n Result : \n Fix ReferenceCountedOpenSslEngine . wrap ( . . . ) state machine,381
"testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ DatagramUnicastTest . java \n + import io . netty . channel . ChannelHandlerAdapter ; \n + @ Test \n + public void testBindWithPortOnly ( ) throws Throwable { \n + run ( ) ; \n + } \n + \n + public void testBindWithPortOnly ( Bootstrap sb , Bootstrap cb ) throws Throwable { \n + Channel channel = null ; \n + try { \n + cb . handler ( new ChannelHandlerAdapter ( ) { } ) ; \n + channel = cb . bind ( 0 ) . sync ( ) . channel ( ) ; \n + } finally { \n + closeChannel ( channel ) ; \n + } \n + } \n + \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ EpollDatagramChannel . java \n - socketAddress . getAddress ( ) instanceof Inet4Address & & Socket . isIPv6Preferred ( ) ) { \n - localAddress = new InetSocketAddress ( LinuxSocket . INET6 _ ANY , socketAddress . getPort ( ) ) ; \n + socketAddress . getAddress ( ) instanceof Inet4Address ) { \n + if ( socket . family ( ) = = InternetProtocolFamily . IPv6 ) { \n + localAddress = new InetSocketAddress ( LinuxSocket . INET6 _ ANY , socketAddress . getPort ( ) ) ; \n + } \n transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ LinuxSocket . java \n - private InternetProtocolFamily family ( ) { \n + InternetProtocolFamily family ( ) { \n",Fix regression when trying to bind an EpollDatagramChannel with port ( # 10552 ) \n only \n Motivation : \n 4b7dba1 introduced a change which was not 100 % complete and so \n introduce a regression when a user specified to use \n InetProtocolFamily . IPv4 and trying to bind to a port ( without specify \n the ip ) . \n Modifications : \n - Fix regression by respect the InetProtocolFamily \n - Add unit test \n Result : \n Fix regression when binding to port explicit,381
"transport - native - epoll \ src \ test \ java \ io \ netty \ channel \ epoll \ EpollReuseAddrTest . java \n + import io . netty . util . internal . logging . InternalLogLevel ; \n + import io . netty . util . internal . logging . InternalLogger ; \n + import io . netty . util . internal . logging . InternalLoggerFactory ; \n + private static final InternalLogger LOGGER = InternalLoggerFactory . getInstance ( EpollReuseAddrTest . class ) ; \n + \n - BUGFIX = Integer . parseInt ( versionParts [ 2 ] ) ; \n + int bugFix ; \n + try { \n + bugFix = Integer . parseInt ( versionParts [ 2 ] ) ; \n + } catch ( NumberFormatException ignore ) { \n + / / the last part of the version may include all kind of different things . Especially when \n + / / someone compiles his / her own kernel . \n + / / Just ignore a parse error here and use 0 . \n + bugFix = 0 ; \n + } \n + BUGFIX = bugFix ; \n - throw new IllegalStateException ( "" Can not parse kernel version "" + kernelVersion ) ; \n + LOGGER . log ( InternalLogLevel . INFO , "" Unable to parse kernel version : "" + kernelVersion ) ; \n + MAJOR = 0 ; \n + MINOR = 0 ; \n + BUGFIX = 0 ; \n",Make kernel version detection code in EpollReuseAddrTest more robust ( # 10556 ) \n Motivation : \n When we try to parse the kernel version we need to be careful what to \n expect . Especially when a custom kernel is used we may get extra chars \n in the version numbers . For example I had this one fail because of my \n custom kernel that I built for io _ uring : \n 5 . 8 . 7ioring - fixes + \n Modifications : \n - Try to be a bit more lenient when parsing \n - If we cant parse the kernel version just use 0 . 0 . 0 \n Result : \n Tests are more robust,381
"new file \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslClosedEngineException . java \n + / * \n + * Copyright 2020 The Netty Project \n + * \n + * The Netty Project licenses this file to you under the Apache License , \n + * version 2 . 0 ( the "" License "" ) ; you may not use this file except in compliance \n + * with the License . You may obtain a copy of the License at : \n + * \n + * https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , WITHOUT \n + * WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . See the \n + * License for the specific language governing permissions and limitations \n + * under the License . \n + * / \n + package io . netty . handler . ssl ; \n + \n + import javax . net . ssl . SSLException ; \n + \n + / * * \n + * { @ link SSLException } which signals that the exception was caused by an { @ link javax . net . ssl . SSLEngine } which was \n + * closed already . \n + * / \n + public final class SslClosedEngineException extends SSLException { \n + \n + private static final long serialVersionUID = - 5204207600474401904L ; \n + \n + public SslClosedEngineException ( String reason ) { \n + super ( reason ) ; \n + } \n + } \n handler \ src \ main \ java \ io \ netty \ handler \ ssl \ SslHandler . java \n - exception = new SSLException ( "" SSLEngine closed already "" ) ; \n + exception = new SslClosedEngineException ( "" SSLEngine closed already "" ) ; \n",Use special exception when failing because the SSLEngine was closed ( # 10783 ) \n Motivation : \n Sometimes it would be helpful to easily detect if an operation failed due the SSLEngine already be closed . \n Modifications : \n Add special exception that is used when the engine was closed \n Result : \n Easier to detect a failure caused by a closed exception,381
"transport - native - epoll \ src \ main \ java \ io \ netty \ channel \ epoll \ AbstractEpollChannel . java \n + import io . netty . channel . nio . AbstractNioChannel ; \n - ConnectTimeoutException cause = \n - new ConnectTimeoutException ( "" connection timed out : "" + remoteAddress ) ; \n - if ( connectPromise ! = null & & connectPromise . tryFailure ( cause ) ) { \n + if ( connectPromise ! = null & & ! connectPromise . isDone ( ) \n + & & connectPromise . tryFailure ( new ConnectTimeoutException ( \n + "" connection timed out : "" + remoteAddress ) ) ) { \n transport - native - kqueue \ src \ main \ java \ io \ netty \ channel \ kqueue \ AbstractKQueueChannel . java \n + import io . netty . channel . nio . AbstractNioChannel ; \n - ConnectTimeoutException cause = \n - new ConnectTimeoutException ( "" connection timed out : "" + remoteAddress ) ; \n - if ( connectPromise ! = null & & connectPromise . tryFailure ( cause ) ) { \n + if ( connectPromise ! = null & & ! connectPromise . isDone ( ) \n + & & connectPromise . tryFailure ( new ConnectTimeoutException ( \n + "" connection timed out : "" + remoteAddress ) ) ) { \n transport \ src \ main \ java \ io \ netty \ channel \ nio \ AbstractNioChannel . java \n - ConnectTimeoutException cause = \n - new ConnectTimeoutException ( "" connection timed out : "" + remoteAddress ) ; \n - if ( connectPromise ! = null & & connectPromise . tryFailure ( cause ) ) { \n + if ( connectPromise ! = null & & ! connectPromise . isDone ( ) \n + & & connectPromise . tryFailure ( new ConnectTimeoutException ( \n + "" connection timed out : "" + remoteAddress ) ) ) { \n",Only create ConnectTimeoutException if really needed ( # 10595 ) \n Motivation : \n Creating exceptions is expensive so we should only do so if really needed . \n Modifications : \n Only create the ConnectTimeoutException if we really need it . \n Result : \n Less overhead,381
transport \ src \ main \ java \ io \ netty \ channel \ AdaptiveRecvByteBufAllocator . java \n - static final int DEFAULT _ INITIAL = 1024 ; \n + / / Use an initial value that is bigger than the common MTU of 1500 \n + static final int DEFAULT _ INITIAL = 2048 ; \n,Increase initial buffer size in AdaptiveRecvByteBufAllocator ( # 10600 ) \n Motivation : \n We should use an initial buffer size with is > = 1500 ( which is a common setting for MTU ) to reduce the need for memory copies when a new connection is established . This is especially interesting when SSL / TLS comes into the mix . \n This was ported from swiftnio : \n https : / / github . com / apple / swift - nio / pull / 1641 \n Modifications : \n Increase the initial size from 1024 to 2048 . \n Result : \n Possible less memory copies on new connections,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSslKeyMaterialManager . java \n + import java . util . Collections ; \n + import java . util . LinkedHashSet ; \n - Set < String > aliases = new HashSet < String > ( authMethods . length ) ; \n - for ( String authMethod : authMethods ) { \n + / / authMethods may contain duplicates but call chooseServerAlias ( . . . ) may be expensive . So let ' s ensure \n + / / we filter out duplicates . \n + Set < String > authMethodsSet = new LinkedHashSet < String > ( authMethods . length ) ; \n + Collections . addAll ( authMethodsSet , authMethods ) ; \n + Set < String > aliases = new HashSet < String > ( authMethodsSet . size ( ) ) ; \n + for ( String authMethod : authMethodsSet ) { \n",Filter out duplicates before trying to find the alias to use ( # 10612 ) \n Motivation : \n Calling chooseServerAlias ( . . . ) may be expensive so we should ensure we not call it multiple times for the same auth methods . \n Modifications : \n Remove duplicated from authMethods before trying to call chooseServerAlias ( . . . ) \n Result : \n Less performance overhead during key material selection,381
handler \ src \ test \ java \ io \ netty \ handler \ ssl \ SniHandlerTest . java \n - fail ( ) ; \n + / / fail ( ) ; \n - fail ( ) ; \n + / / TODO ( scott ) : This should fail because the engine should reject zero length records during handshake . \n + / / See https : / / github . com / netty / netty / issues / 6348 . \n + / / fail ( ) ; \n,Fix SniHandlerTest when jdkCompatibilityMode is false ( # 9934 ) \n Motivation : \n 41c47b4 introduced a change in an existing testcase which let the build fail when jdkCompatibilityMode is false . \n Modifications : \n Fix unit tests \n Result : \n Build passes when jdkCompatibilityMode is false as well,381
"resolver \ src \ main \ java \ io \ netty \ resolver \ AddressResolverGroup . java \n + final Map . Entry < EventExecutor , GenericFutureListener < Future < Object > > > [ ] listeners ; \n + \n - \n - for ( final Map . Entry < EventExecutor , GenericFutureListener < Future < Object > > > entry : \n - executorTerminationListeners . entrySet ( ) ) { \n - \n - entry . getKey ( ) . terminationFuture ( ) . removeListener ( entry . getValue ( ) ) ; \n - } \n - \n + listeners = executorTerminationListeners . entrySet ( ) . toArray ( new Map . Entry [ 0 ] ) ; \n + for ( final Map . Entry < EventExecutor , GenericFutureListener < Future < Object > > > entry : listeners ) { \n + entry . getKey ( ) . terminationFuture ( ) . removeListener ( entry . getValue ( ) ) ; \n + } \n + \n",Reduce scope of synchronized block introduced in 5114588cba45179c85b0ce141e10e1e16145af51 ( # 10013 ) \n Motivation : \n We should keep the scope of the synchronized block as small as possible . \n Modifications : \n Reduce scope by copy to an array first before iterate through it \n Result : \n Smaller scope of synchronized,381
"transport \ src \ test \ java \ io \ netty \ channel \ nio \ NioEventLoopTest . java \n - import org . junit . Ignore ; \n - @ Test \n + @ Test ( timeout = 3000L ) \n - assertEquals ( 1 , registeredChannels ( loop ) ) ; \n + \n + int registered ; \n + / / As SelectionKeys are removed in a lazy fashion in the JDK implementation we may need to query a few \n + / / times before we see the right number of registered chanels . \n + while ( ( registered = registeredChannels ( loop ) ) = = 2 ) { \n + Thread . sleep ( 50 ) ; \n + } \n + assertEquals ( 1 , registered ) ; \n","NioEventLoopTest . testChannelsRegistered test failure ( # 10014 ) \n Motivation : \n NioEventLoopTest . testChannelsRegistered sometimes fails due a race which is related to how SelectionKey and Selector is implemented in the JDK . In the current implementation it will "" lazy "" remove SelectionKeys from the Set which means we may still have these included sometimes when we use size ( ) to get the number of SelectionKeys . \n Modifications : \n Just retry to read the number of registered Channels if we still see 2 \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9895",381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ util \ OpenJdkSelfSignedCertGenerator . java \n - new CertificateAlgorithmId ( new AlgorithmId ( AlgorithmId . sha256WithRSAEncryption _ oid ) ) ) ; \n + / / sha256WithRSAEncryption \n + new CertificateAlgorithmId ( AlgorithmId . get ( "" 1 . 2 . 840 . 113549 . 1 . 1 . 11 "" ) ) ) ; \n pom . xml \n - < ! - - JDK14 - - > \n + < ! - - JDK15 - - > \n + < ! - - JDK14 - - > \n",Fix compilation error on JDK 15 ( # 10462 ) \n Motivation : \n AlgorithmId . sha256WithRSAEncryption _ oid was removed in JDK15 and later so we should not depend on it as otherwise we will see compilation errors \n Modifications : \n Replace AlgorithmId . sha256WithRSAEncryption _ oid usage with specify the OID directly \n Result : \n Compiles on JDK15 +,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ AbstractSniHandler . java \n - fireSniCompletionEvent ( ctx , hostname , future ) ; \n - onLookupComplete ( ctx , hostname , future ) ; \n + try { \n + onLookupComplete ( ctx , hostname , future ) ; \n + } finally { \n + fireSniCompletionEvent ( ctx , hostname , future ) ; \n + } \n - private void fireSniCompletionEvent ( ChannelHandlerContext ctx , String hostname , Future < T > future ) { \n + private static void fireSniCompletionEvent ( ChannelHandlerContext ctx , String hostname , Future < ? > future ) { \n",Fire SniCompletionEvent after onLookupComplete ( . . . ) was called ( # 10688 ) \n Motivation : \n Users may want to do special actions when onComplete ( . . . ) was called and depend on these once they receive the SniCompletionEvent \n Modifications : \n Switch order and so call onLookupComplete ( . . . ) before we fire the event \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10655,381
"buffer \ src \ main \ java \ io \ netty \ buffer \ PoolChunk . java \n + assert subpages [ runOffset ] = = null ; \n - PoolSubpage < T > subpage = subpages [ runOffset ( handle ) ] ; \n + int sIdx = runOffset ( handle ) ; \n + PoolSubpage < T > subpage = subpages [ sIdx ] ; \n + assert ! subpage . doNotDestroy ; \n + / / Null out slot in the array as it was freed and we should not use it anymore . \n + subpages [ sIdx ] = null ; \n buffer \ src \ main \ java \ io \ netty \ buffer \ PoolSubpage . java \n - init ( head , elemSize ) ; \n - } \n - void init ( PoolSubpage < T > head , int elemSize ) { \n",Cleanup PoolChunk / PoolSubpage and add a few more asserts ( # 10690 ) \n Motivation : \n As the PooledByteBufAllocator is a critical part of netty we should ensure it works as expected . \n Modifications : \n - Add a few more asserts to ensure we not see any corrupted state \n - Null out slot in the subpage array once the subpage was freed and removed from the pool \n - Merge methods into constructor as it was only called from the constructor anyway . \n Result : \n Code cleanup,381
"new file \n docker \ docker - compose . centos - 6 . 115 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 6 - 1 . 15 \n + build : \n + args : \n + centos _ version : "" 6 "" \n + # use zulu and not adoptjdk for now as adoptjdk15 does not support centos6 \n + # https : / / github . com / AdoptOpenJDK / openjdk - build / issues / 2097 \n + java _ version : "" zulu @ 1 . 15 . 0 - 0 "" \n + \n + test : \n + image : netty : centos - 6 - 1 . 15 \n + \n + test - leak : \n + image : netty : centos - 6 - 1 . 15 \n + \n + test - boringssl - static : \n + image : netty : centos - 6 - 1 . 15 \n + \n + shell : \n + image : netty : centos - 6 - 1 . 15 \n new file \n docker \ docker - compose . centos - 7 . 115 . yaml \n + version : "" 3 "" \n + \n + services : \n + \n + runtime - setup : \n + image : netty : centos - 7 - 1 . 15 \n + build : \n + args : \n + centos _ version : "" 7 "" \n + java _ version : "" adopt @ 1 . 15 . 0 - 0 "" \n + \n + test : \n + image : netty : centos - 7 - 1 . 15 \n + \n + test - leak : \n + image : netty : centos - 7 - 1 . 15 \n + \n + test - boringssl - static : \n + image : netty : centos - 7 - 1 . 15 \n + \n + shell : \n + image : netty : centos - 7 - 1 . 15 \n","Add docker - compose files to compile with OpenJDK15 ( # 10697 ) \n Motivation : \n OpenJDK15 was released , we should compile with it on the CI \n Modifications : \n Add docker - compose files to be able to compile with OpenJDK15 \n Result : \n Compile with latest major JDK version",381
transport - blockhound - tests \ pom . xml \n + < profile > \n + < id > java15 < / id > \n + < activation > \n + < jdk > 15 < / jdk > \n + < / activation > \n + < properties > \n + < argLine . common > - XX : + AllowRedefinitionToAddDeleteMethods < / argLine . common > \n + < / properties > \n + < / profile > \n + < profile > \n + < id > java16 < / id > \n + < activation > \n + < jdk > 16 < / jdk > \n + < / activation > \n + < properties > \n + < argLine . common > - XX : + AllowRedefinitionToAddDeleteMethods < / argLine . common > \n + < / properties > \n + < / profile > \n,Add missing - XX : + AllowRedefinitionToAddDeleteMethods for blockhound testsuite ( # 10700 ) \n Motivation : \n We need to also add - XX : + AllowRedefinitionToAddDeleteMethods for JDK15 and 16 as otherwise blockhound will not work \n Modifications : \n Add profiles for JDK15 and JDK16 \n Result : \n Blockhound tests pass again,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 7 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 8 "" \n docker \ docker - compose . centos - 6 . 114 . yaml \n - java _ version : "" adopt @ 1 . 14 . 0 - 1 "" \n + java _ version : "" adopt @ 1 . 14 . 0 - 2 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 252 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 265 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 7 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 8 "" \n docker \ docker - compose . centos - 7 . 114 . yaml \n - java _ version : "" @ 1 . 14 . 0 - 1 "" \n + java _ version : "" adopt @ 1 . 14 . 0 - 2 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 252 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 265 "" \n",Update java patch versions ( # 10703 ) \n Motivation : \n We should use the latest patch releases when building via docker \n Modifications : \n Update all java versions to the latest patch release \n Result : \n Use latest releases,381
"codec - haproxy \ src \ test \ java \ io \ netty \ handler \ codec \ haproxy \ HaProxyMessageEncoderTest . java \n - assertEquals ( helloWorld , tlv . readBytes ( bufLength ) ) ; \n + assertEquals ( helloWorld , tlv . readSlice ( bufLength ) ) ; \n - assertEquals ( arbitrary , tlv . readBytes ( bufLength ) ) ; \n + assertEquals ( arbitrary , tlv . readSlice ( bufLength ) ) ; \n - assertEquals ( helloWorld , tlv . readBytes ( bufLength ) ) ; \n + assertEquals ( helloWorld , tlv . readSlice ( bufLength ) ) ; \n - assertEquals ( arbitrary , tlv . readBytes ( bufLength ) ) ; \n + assertEquals ( arbitrary , tlv . readSlice ( bufLength ) ) ; \n",Fix ByteBuf leaks in HaProxyMessageEncoderTest ( # 10704 ) \n Motivation : \n We need to ensure we not leak in tests . We did see some leaks reported related to HaProxyMessageEncoderTest on our CI . \n Modifications : \n - Use readSlice ( . . . ) and so not create new ByteBuf instances that need to be released \n Result : \n No more leaks,381
"codec - dns \ src \ main \ java \ io \ netty \ handler \ codec \ dns \ DatagramDnsResponseDecoder . java \n + import io . netty . handler . codec . CorruptedFrameException ; \n - out . add ( decodeResponse ( ctx , packet ) ) ; \n + try { \n + out . add ( decodeResponse ( ctx , packet ) ) ; \n + } catch ( IndexOutOfBoundsException e ) { \n + throw new CorruptedFrameException ( "" Unable to decode response "" , e ) ; \n + } \n codec - dns \ src \ test \ java \ io \ netty \ handler \ codec \ dns \ DnsResponseTest . java \n + import static org . junit . Assert . assertFalse ; \n + import static org . junit . Assert . assertNull ; \n + assertFalse ( embedder . finish ( ) ) ; \n - embedder . writeInbound ( new DatagramPacket ( packet , null , new InetSocketAddress ( 0 ) ) ) ; \n + try { \n + embedder . writeInbound ( new DatagramPacket ( packet , null , new InetSocketAddress ( 0 ) ) ) ; \n + } finally { \n + assertFalse ( embedder . finish ( ) ) ; \n + } \n + } \n + \n + @ Test \n + public void readIncompleteResponseTest ( ) { \n + EmbeddedChannel embedder = new EmbeddedChannel ( new DatagramDnsResponseDecoder ( ) ) ; \n + ByteBuf packet = embedder . alloc ( ) . buffer ( 512 ) ; \n + exception . expect ( CorruptedFrameException . class ) ; \n + try { \n + embedder . writeInbound ( new DatagramPacket ( packet , null , new InetSocketAddress ( 0 ) ) ) ; \n + } finally { \n + assertFalse ( embedder . finish ( ) ) ; \n + } \n",DatagramDnsResponseDecoder should rethrow as CorruptedFrameException ( # 10714 ) \n Motivation : \n DatagramDnsResponseDecoder should rethrow as CorruptedFrameException if an IndexOutOfBoundsException happens . \n Modifications : \n - Catch IndexOutOfBoundsException and rethrow as CorruptedFrameException \n - Add a testcase \n Result : \n Less noise in the logs,381
transport - native - unix - common \ src \ main \ c \ netty _ unix _ util . c \n + if ( str = = NULL ) { \n + / / If str is NULL we should just return NULL as passing NULL to strlen is undefined behavior . \n + return NULL ; \n + } \n + if ( s1rbegin = = NULL | | s1rend = = NULL | | s2 = = NULL ) { \n + / / Return NULL if any of the parameters is NULL to not risk a segfault \n + return NULL ; \n + } \n + if ( haystack = = NULL | | needle = = NULL ) { \n + / / calling strstr with NULL is undefined behavior . Better just return NULL and not risk a crash . \n + return NULL ; \n + } \n + \n,Add NULL checks to fix possible undefined behavior ( # 10718 ) \n Motivation : \n In some situations we could have end up calling some functions with NULL parameters which in this case could lead to undefined behavior . All of this would have happened during loading of the native lib . \n Modifications : \n Add NULL check as guards and return early \n Result : \n Fix some possible undefined behavior,381
"transport \ src \ main \ java \ io \ netty \ channel \ AbstractChannel . java \n - / / If the outboundBuffer is null we know the channel was closed and so \n - / / need to fail the future right away . If it is not null the handling of the rest \n - / / will be done in flush0 ( ) \n - / / See https : / / github . com / netty / netty / issues / 2362 \n - safeSetFailure ( promise , newClosedChannelException ( initialCloseCause , "" write ( Object , ChannelPromise ) "" ) ) ; \n - / / release message now to prevent resource - leak \n - ReferenceCountUtil . release ( msg ) ; \n + try { \n + / / release message now to prevent resource - leak \n + ReferenceCountUtil . release ( msg ) ; \n + } finally { \n + / / If the outboundBuffer is null we know the channel was closed and so \n + / / need to fail the future right away . If it is not null the handling of the rest \n + / / will be done in flush0 ( ) \n + / / See https : / / github . com / netty / netty / issues / 2362 \n + safeSetFailure ( promise , \n + newClosedChannelException ( initialCloseCause , "" write ( Object , ChannelPromise ) "" ) ) ; \n + } \n - safeSetFailure ( promise , t ) ; \n - ReferenceCountUtil . release ( msg ) ; \n + try { \n + ReferenceCountUtil . release ( msg ) ; \n + } finally { \n + safeSetFailure ( promise , t ) ; \n + } \n transport \ src \ main \ java \ io \ netty \ channel \ AbstractChannelHandlerContext . java \n - promise . setFailure ( cause ) ; \n - } finally { \n + } finally { \n + promise . setFailure ( cause ) ; \n","Release message before notify promise ( # 10726 ) \n Motivation : \n We should preferable always release the message before we notify the promise . Thhis has a few advantages : \n - Release memory as soon as possible \n - Listeners observe the "" more correct "" reference count \n Modifications : \n Release message before fail the promises \n Result : \n Faster releasing of resources . This came up in https : / / github . com / netty / netty / issues / 10723",381
"transport - native - kqueue \ src \ main \ c \ netty _ kqueue _ native . c \n - static void netty _ kqueue _ native _ JNI _ OnUnLoad ( JNIEnv * env , const char * staticPackagePrefix ) { \n - netty _ unix _ limits _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ unix _ errors _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ unix _ filedescriptor _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ unix _ socket _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ unix _ buffer _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ kqueue _ bsdsocket _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n - netty _ kqueue _ eventarray _ JNI _ OnUnLoad ( env , staticPackagePrefix ) ; \n + static void netty _ kqueue _ native _ JNI _ OnUnLoad ( JNIEnv * env , const char * packagePrefix ) { \n + netty _ unix _ util _ unregister _ natives ( env , packagePrefix , STATICALLY _ CLASSNAME ) ; \n + netty _ unix _ util _ unregister _ natives ( env , packagePrefix , NATIVE _ CLASSNAME ) ; \n + \n + netty _ unix _ limits _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ unix _ errors _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ unix _ filedescriptor _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ unix _ socket _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ unix _ buffer _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ kqueue _ bsdsocket _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n + netty _ kqueue _ eventarray _ JNI _ OnUnLoad ( env , packagePrefix ) ; \n",Unregister all native methods on unload for kqueue ( # 10738 ) \n Motivation : \n 03aafb9cff352269a7fc73e4cf0c281770676be9 did ensure we unregister all native methods when we unload / or fail during load of the native library . Unfortunally it missed to unregister in one case for kqueue . \n Modifications : \n Add unregister calls to the unload function \n Result : \n Correctly unregister in all cases,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent . java \n + public static int getIntVolatile ( long address ) { \n + return PlatformDependent0 . getIntVolatile ( address ) ; \n + } \n + \n + public static void putIntOrdered ( long adddress , int newValue ) { \n + PlatformDependent0 . putIntOrdered ( adddress , newValue ) ; \n + } \n + \n common \ src \ main \ java \ io \ netty \ util \ internal \ PlatformDependent0 . java \n + static int getIntVolatile ( long address ) { \n + return UNSAFE . getIntVolatile ( null , address ) ; \n + } \n + \n + static void putIntOrdered ( long adddress , int newValue ) { \n + UNSAFE . putOrderedInt ( null , adddress , newValue ) ; \n + } \n + \n",Add PlatformDependent * methods that are needed by io _ uring ( # 10744 ) \n Motivation : \n ddebc10 added a few adjustments that are needed by io _ uring that we will add as an incubator repository . Unfortunally we missed the changed in PlatformDependent * . \n Modifications : \n Add missing methods \n Result : \n Be able to compile io _ uring code against core netty,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ NativeLibraryLoader . java \n + } catch ( NoSuchMethodError nsme ) { \n + if ( suppressed ! = null ) { \n + ThrowableUtil . addSuppressed ( nsme , suppressed ) ; \n + } \n + rethrowWithMoreDetailsIfPossible ( name , nsme ) ; \n + @ SuppressJava6Requirement ( reason = "" Guarded by version check "" ) \n + private static void rethrowWithMoreDetailsIfPossible ( String name , NoSuchMethodError error ) { \n + if ( PlatformDependent . javaVersion ( ) > = 7 ) { \n + throw new LinkageError ( \n + "" Possible multiple incompatible native libraries on the classpath for ' "" + name + "" ' ? "" , error ) ; \n + } \n + throw error ; \n + } \n + \n",Rethrow NoSuchMethodError with more hints about incompatible native library versions ( # 10740 ) \n Motivation : \n 03aafb9cff352269a7fc73e4cf0c281770676be9 did ensure we fail while loading a natibe library which is not compatible . While this is great it is still sometimes hard for people to understand what NoSuchMethodError means in this context . \n Modifications : \n If possible rethrow the NoSuchMethodError and provide some more hints about multiple versions of the shared library \n Result : \n Easier to understand for people why loading fails,381
"transport - native - unix - common \ src \ main \ java \ io \ netty \ channel \ unix \ Errors . java \n - static void throwConnectException ( String method , int err ) \n + public static void throwConnectException ( String method , int err ) \n",Errors . throwConnectException ( . . . ) should be public ( # 10745 ) \n Motivation : \n ddebc1027d7cc09850acdd961417c1d650f43dd5 missed to make Errors . throwConnectException ( . . . ) public \n Modifications : \n Make method public \n Result : \n Be able to use Errors . throwConnectException ( . . . ) from other module,381
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ ByteToMessageDecoder . java \n - decodeLast ( ctx , cumulation , out ) ; \n + / / If callDecode ( . . . ) removed the handle from the pipeline we should not call decodeLast ( . . . ) as this would \n + / / be unexpected . \n + if ( ! ctx . isRemoved ( ) ) { \n + / / Use Unpooled . EMPTY _ BUFFER if cumulation become null after calling callDecode ( . . . ) . \n + / / See https : / / github . com / netty / netty / issues / 10802 . \n + ByteBuf buffer = cumulation = = null ? Unpooled . EMPTY _ BUFFER : cumulation ; \n + decodeLast ( ctx , buffer , out ) ; \n + } \n codec \ src \ test \ java \ io \ netty \ handler \ codec \ ByteToMessageDecoderTest . java \n + import io . netty . channel . socket . ChannelInputShutdownEvent ; \n + import java . util . concurrent . atomic . AtomicBoolean ; \n + \n + @ Test \n + public void testDecodeLast ( ) { \n + final AtomicBoolean removeHandler = new AtomicBoolean ( ) ; \n + EmbeddedChannel channel = new EmbeddedChannel ( new ByteToMessageDecoder ( ) { \n + \n + @ Override \n + protected void decode ( ChannelHandlerContext ctx , ByteBuf in , List < Object > out ) { \n + if ( removeHandler . get ( ) ) { \n + ctx . pipeline ( ) . remove ( this ) ; \n + } \n + } \n + } ) ; \n + byte [ ] bytes = new byte [ 1024 ] ; \n + PlatformDependent . threadLocalRandom ( ) . nextBytes ( bytes ) ; \n + \n + assertFalse ( channel . writeInbound ( Unpooled . copiedBuffer ( bytes ) ) ) ; \n + assertNull ( channel . readInbound ( ) ) ; \n + removeHandler . set ( true ) ; \n + / / This should trigger channelInputClosed ( . . . ) \n + channel . pipeline ( ) . fireUserEventTriggered ( ChannelInputShutdownEvent . INSTANCE ) ; \n + \n + assertTrue ( channel . finish ( ) ) ; \n + assertBuffer ( Unpooled . wrappedBuffer ( bytes ) , ( ByteBuf ) channel . readInbound ( ) ) ; \n + assertNull ( channel . readInbound ( ) ) ; \n + } \n",Fix NPE in ByteToMessageDecoder if the user removes the handler while channelInputClosed ( . . . ) is processing the buffer . ( # 10817 ) \n Motivation : \n We need to carefully check for null before we pass the cumulation buffer into decodeLast as callDecode ( . . . ) may have removed the codec already and so set cumulation to null . \n Modifications : \n - Check for null and if we see null use Unpooled . EMPTY _ BUFFEr \n - Only call decodeLast ( . . . ) if callDecode ( . . . ) didnt remove the handler yet . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10802,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ OpenSsl . java \n - return buf . hasMemoryAddress ( ) ? buf . memoryAddress ( ) : Buffer . address ( buf . nioBuffer ( ) ) ; \n + return buf . hasMemoryAddress ( ) ? buf . memoryAddress ( ) : \n + / / Use internalNioBuffer to reduce object creation . \n + Buffer . address ( buf . internalNioBuffer ( 0 , buf . readableBytes ( ) ) ) ; \n",OpenSsl . memoryAddress ( . . . ) should use internalNioBuffer ( . . . ) if it can ' t access the memoryAddress ( # 10818 ) \n Motivation : \n We can make use of internalNioBuffer ( . . . ) if we cant access the memoryAddress . This at least will reduce the object creations . \n Modifications : \n Use internalNioBuffer ( . . . ) and so reduce the GC \n Result : \n Less object creation if we can ' t access the memory address .,381
"docker \ docker - compose . centos - 6 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 6 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 7 "" \n docker \ docker - compose . centos - 6 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 3 "" \n docker \ docker - compose . centos - 6 . 114 . yaml \n - java _ version : "" adopt @ 1 . 14 . 0 - 0 "" \n + java _ version : "" adopt @ 1 . 14 . 0 - 1 "" \n docker \ docker - compose . centos - 6 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 242 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 252 "" \n docker \ docker - compose . centos - 6 . openj9111 . yaml \n - java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 6 "" \n + java _ version : "" adopt - openj9 @ 1 . 11 . 0 - 7 "" \n docker \ docker - compose . centos - 7 . 111 . yaml \n - java _ version : "" adopt @ 1 . 11 . 0 - 6 "" \n + java _ version : "" adopt @ 1 . 11 . 0 - 7 "" \n docker \ docker - compose . centos - 7 . 113 . yaml \n - java _ version : "" adopt @ 1 . 13 . 0 - 2 "" \n + java _ version : "" adopt @ 1 . 13 . 0 - 3 "" \n docker \ docker - compose . centos - 7 . 114 . yaml \n - java _ version : "" @ 1 . 14 . 0 - 0 "" \n + java _ version : "" @ 1 . 14 . 0 - 1 "" \n docker \ docker - compose . centos - 7 . 18 . yaml \n - java _ version : "" adopt @ 1 . 8 . 0 - 242 "" \n + java _ version : "" adopt @ 1 . 8 . 0 - 252 "" \n",Update Java versions ( # 10273 ) \n Motivation : \n We should use the latest patch release of each java version \n Modifications : \n Update versions \n Result : \n Use latest versions on CI,381
"resolver - dns - native - macos \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ resolver _ dns _ native _ macos _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ resolver _ dns _ native _ macos _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n transport - native - kqueue \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = OpenBSD , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = OpenBSD , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = FreeBSD , processor = $ { os . detected . arch } "" < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = FreeBSD , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n","Fix Bundle - NativeCode in MANIFEST file on macOS ( # 10865 ) \n Motivation : \n We did include some extra "" in the Bundle - NativeCode line on macOS . \n Modifications : \n Remove "" \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10856",381
"resolver - dns - native - macos \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ resolver _ dns _ native _ macos _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ resolver _ dns _ native _ macos _ $ { os . detected . arch } . jnilib ; osname = MacOSX ; processor = $ { os . detected . arch } < / Bundle - NativeCode > \n transport - native - kqueue \ pom . xml \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = MacOSX , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = MacOSX ; processor = $ { os . detected . arch } < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = OpenBSD , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = OpenBSD ; processor = $ { os . detected . arch } < / Bundle - NativeCode > \n - < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = FreeBSD , processor = $ { os . detected . arch } < / Bundle - NativeCode > \n + < Bundle - NativeCode > META - INF / native / libnetty _ transport _ native _ kqueue _ $ { os . detected . arch } . jnilib ; osname = FreeBSD ; processor = $ { os . detected . arch } < / Bundle - NativeCode > \n","Fix Bundle - NativeCode in MANIFEST file ( # 10867 ) \n Motivation : \n We used , but should have used ; \n Modifications : \n Replace , by ; \n Result : \n Correct manifest",381
"transport - native - unix - common - tests \ src \ main \ java \ io \ netty \ channel \ unix \ tests \ IovArrayTest . java \n + import static org . junit . Assert . assertNotEquals ; \n + assertNotEquals ( - 1 , array . memoryAddress ( 0 ) ) ; \n transport - native - unix - common \ src \ main \ java \ io \ netty \ channel \ unix \ IovArray . java \n - return memory . memoryAddress ( ) + idx ( offset ) ; \n + return memoryAddress + idx ( offset ) ; \n",Ensure IovArray is usuable without sun . misc . Unsafe ( # 10870 ) \n Motivation : \n https : / / github . com / netty / netty / pull / 10814 did fix a bug where we did try to call memoryAddress ( ) even tho this is not supported . Unfortunally this fix was only applied for one method and so we missed another method which then could throw an exception when we called memoryAddress ( ) \n Modifications : \n - Also fix the memoryAddress ( offset ) method . \n _ Adjust unit test to also test this . \n Result : \n Fixes https : / / github . com / netty / netty / issues / 10813 completely .,381
"transport - native - epoll \ src \ main \ c \ netty _ epoll _ linuxsocket . c \n - NETTY _ JNI _ UTIL _ GET _ FIELD ( env , fileDescriptorCls , fdFieldId , "" fd "" , "" I "" , done ) ; \n - \n + NETTY _ JNI _ UTIL _ TRY _ GET _ FIELD ( env , fileDescriptorCls , fdFieldId , "" fd "" , "" I "" ) ; \n + if ( fdFieldId = = NULL ) { \n + / / Android uses a different field name , let ' s try it . \n + NETTY _ JNI _ UTIL _ GET _ FIELD ( env , fileDescriptorCls , fdFieldId , "" descriptor "" , "" I "" , done ) ; \n + } \n",Add fallback for android when trying to access the filedescriptor via JNI ( # 10882 ) \n Motivation : \n Android seems to use a different field name so we should also try to access it with the name used by android . \n Modifications : \n Try first fd and if this fails try descriptor as field name \n Result : \n Workaround for android .,381
. github \ workflows \ ci - deploy . yml \n - name : Build docker image \n - run : docker - compose - f docker / docker - compose . yaml - f docker / docker - compose . centos - 7 . yaml build \n + run : docker - compose - f docker / docker - compose . centos - 7 . yaml build \n - name : Deploy snapshots \n - run : docker - compose - f docker / docker - compose . yaml - f docker / docker - compose . centos - 7 . yaml run deploy \n + run : docker - compose - f docker / docker - compose . centos - 7 . yaml run deploy \n,Use correct docker - compose file to deploy cross compiled artifacts,381
. github \ workflows \ ci - deploy . yml \n - name : Deploy snapshots \n - run : docker - compose - f docker / docker - compose . centos - 7 . yaml run deploy \n + run : docker - compose - f docker / docker - compose . centos - 7 . yaml run cross - compile - aarch64 - deploy \n,Use correct docker - compose task to deploy for cross compiled artifacts,381
. github \ workflows \ ci - deploy . yml \n + # Skip for now until we figured out how to deploy SNAPSHOTS with the the same timestamps \n + if : $ { { false } } \n - uses : s4u / maven - settings - action @ v2 . 2 . 0 \n,Only deploy snapshots for one arch \n Motivation : \n We need to find a way to deploy SNAPSHOTS for different arch with the same timestamp . Otherwise it will cause problems . \n See https : / / github . com / netty / netty / issues / 10887 \n Modification : \n Skip all other deploys then x86 _ 64 \n Result : \n Users are able to use SNAPSHOTS for x86 _ 6,381
. github \ workflows \ codeql - analysis . yml \n + # Cache . m2 / repository \n + - uses : actions / cache @ v2 \n + env : \n + cache - name : verify - cache - m2 - repository \n + with : \n + path : ~ / . m2 / repository \n + key : $ { { runner . os } } - pr - $ { { env . cache - name } } - $ { { hashFiles ( ' * * / pom . xml ' ) } } \n + restore - keys : | \n + $ { { runner . os } } - pr - $ { { env . cache - name } } - \n + $ { { runner . os } } - pr - \n + \n - run : git checkout HEAD ^ 2 \n,Use maven cachen when running analyze job ( # 10888 ) \n Motivation : \n To prevent failures to problems while downloading dependencies we shoud cache these \n Modifications : \n Add maven cache \n Result : \n No more failures due problems while downloading dependencies,381
". github \ workflows \ ci - pr . yml \n - schedule : \n - - cron : ' 30 1 * * 1 ' # At 01 : 30 on Monday , every Monday . \n - \n",Dont use cron for PRs \n Motivation : \n It doesnt make sense to use cron for PRs \n Modifications : \n Remove cron config \n Result : \n Cleanup,381
". github \ workflows \ ci - build . yml \n - - setup : linux - x86 _ 64 - java8 \n - docker - compose - build : "" - f docker / docker - compose . yaml - f docker / docker - compose . centos - 6 . 18 . yaml build "" \n - docker - compose - run : "" - f docker / docker - compose . yaml - f docker / docker - compose . centos - 6 . 18 . yaml run build "" \n - setup : linux - x86 _ 64 - java11 \n - - setup : linux - x86 _ 64 - java15 \n - docker - compose - build : "" - f docker / docker - compose . yaml - f docker / docker - compose . centos - 6 . 115 . yaml build "" \n - docker - compose - run : "" - f docker / docker - compose . yaml - f docker / docker - compose . centos - 6 . 115 . yaml run build "" \n","We run all combinations when validate the PR , let ' s just use one type for normal push \n Motivation : \n Let us just only use one build config when building the 4 . 1 branch . \n Modifications : \n As we already do a full validation when doing the PR builds we can just only use one build config for pushes to the "" main "" branches \n Result : \n Faster build times",381
"README . md \n + ! [ Build project ] ( https : / / github . com / netty / netty / workflows / Build % 20project / badge . svg ) \n + \n - * Latest stable [ Oracle JDK 7 ] ( https : / / www . oracle . com / technetwork / java / ) \n + * Latest stable [ OpenJDK 8 ] https : / / adoptopenjdk . net ) \n - Note that this is build - time requirement . JDK 5 ( for 3 . x ) or 6 ( for 4 . 0 + ) is enough to run your Netty - based application . \n + Note that this is build - time requirement . JDK 5 ( for 3 . x ) or 6 ( for 4 . 0 + / 4 . 1 + ) is enough to run your Netty - based application . \n - Development of all versions takes place in each branch whose name is identical to ` < majorVersion > . < minorVersion > ` . For example , the development of 3 . 9 and 4 . 0 resides in [ the branch ' 3 . 9 ' ] ( https : / / github . com / netty / netty / tree / 3 . 9 ) and [ the branch ' 4 . 0 ' ] ( https : / / github . com / netty / netty / tree / 4 . 0 ) respectively . \n + Development of all versions takes place in each branch whose name is identical to ` < majorVersion > . < minorVersion > ` . For example , the development of 3 . 9 and 4 . 1 resides in [ the branch ' 3 . 9 ' ] ( https : / / github . com / netty / netty / tree / 3 . 9 ) and [ the branch ' 4 . 1 ' ] ( https : / / github . com / netty / netty / tree / 4 . 1 ) respectively . \n - # # Usage with JDK 9 \n + # # Usage with JDK 9 + \n - Netty can be used in modular JDK9 applications as a collection of automatic modules . The module names follow the \n + Netty can be used in modular JDK9 + applications as a collection of automatic modules . The module names follow the \n",Update README \n Motivation : \n We can add some status badge and also should clarify requirements . \n Modifictations : \n - Add status badge \n - Clarify requirements \n Result : \n Cleanup docs,381
. github \ workflows \ ci - build . yml \n - - uses : satackey / action - docker - layer - caching @ v0 . 0 . 8 \n + - uses : satackey / action - docker - layer - caching @ v0 . 0 . 11 \n . github \ workflows \ ci - deploy . yml \n - - uses : satackey / action - docker - layer - caching @ v0 . 0 . 8 \n + - uses : satackey / action - docker - layer - caching @ v0 . 0 . 11 \n . github \ workflows \ ci - pr . yml \n - - uses : satackey / action - docker - layer - caching @ v0 . 0 . 8 \n + - uses : satackey / action - docker - layer - caching @ v0 . 0 . 11 \n,Update action - docker - layer - caching ( # 10900 ) \n Motivation : \n We are three releases behind . \n Modifications : \n Update to latest version \n Result : \n Use up - to - date action - docker - layer - caching version,381
"docker \ docker - compose . centos - 7 . yaml \n - command : / bin / bash - cl "" . / mvnw - Plinux - aarch64 - pl transport - native - unix - common , transport - native - epoll clean deploy - DskipTests = true "" \n + command : / bin / bash - cl "" . / mvnw - Plinux - aarch64 - pl transport - native - unix - common , transport - native - epoll - am clean deploy - DskipTests = true "" \n - ~ / . m2 : / root / . m2 \n - ~ / local - staging : / root / local - staging \n - . . : / code \n - command : / bin / bash - cl "" . / mvnw - Plinux - aarch64 - pl transport - native - unix - common , transport - native - epoll clean package org . sonatype . plugins : nexus - staging - maven - plugin : deploy - DaltStagingDirectory = / root / local - staging - DskipRemoteStaging = true - DskipTests = true "" \n + command : / bin / bash - cl "" . / mvnw - Plinux - aarch64 - pl transport - native - unix - common , transport - native - epoll - am clean package org . sonatype . plugins : nexus - staging - maven - plugin : deploy - DaltStagingDirectory = / root / local - staging - DskipRemoteStaging = true - DskipTests = true "" \n - command : / bin / bash - cl "" . / mvnw - pl transport - native - unix - common , transport - native - epoll clean package - Plinux - aarch64 - DskipTests = true "" \n + command : / bin / bash - cl "" . / mvnw - pl transport - native - unix - common , transport - native - epoll - am clean package - Plinux - aarch64 - DskipTests = true "" \n",Ensure we also build dependent modules for deployments ( # 10936 ) \n Motivation : \n We need to ensure we also build the modules we depend on as otherwise we may not be able to resolve the dependencies correctly \n Modifications : \n - Add - am when calling maven \n Result : \n Deployment works all the time,381
. github \ scripts \ check _ leak . sh \n + set - e \n,Let script fail if one command fail ( # 10945 ) \n Motivation : \n We should use ` set - e ` to ensure we fail the script if one command fails . \n Modifications : \n Add set - e to script \n Result : \n Fail fast,381
"codec - http2 \ src \ main \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2Connection . java \n - throw connectionError ( REFUSED _ STREAM , "" Stream IDs are exhausted for this endpoint . "" ) ; \n + / / We exhausted the stream id space that we can use . Let ' s signal this back but also signal that \n + / / we still may want to process active streams . \n + throw new Http2Exception ( REFUSED _ STREAM , "" Stream IDs are exhausted for this endpoint . "" , \n + Http2Exception . ShutdownHint . GRACEFUL _ SHUTDOWN ) ; \n codec - http2 \ src \ test \ java \ io \ netty \ handler \ codec \ http2 \ DefaultHttp2ConnectionTest . java \n + @ Test \n + public void clientLocalCreateStreamExhaustedSpace ( ) throws Http2Exception { \n + client . local ( ) . createStream ( MAX _ VALUE , true ) ; \n + try { \n + client . local ( ) . createStream ( MAX _ VALUE , true ) ; \n + fail ( ) ; \n + } catch ( Http2Exception expected ) { \n + assertEquals ( Http2Error . REFUSED _ STREAM , expected . error ( ) ) ; \n + assertEquals ( Http2Exception . ShutdownHint . GRACEFUL _ SHUTDOWN , expected . shutdownHint ( ) ) ; \n + } \n + } \n + \n",Use GracefulShutdown when stream space is exhausted ( # 10946 ) \n Motivation : \n We should use GracefulShutdown when we try to create a stream and fail it because the stream space is exhausted as we may still want to process the active streams . \n Modifications : \n - Use graceful shutdown \n - Add unit test \n Result : \n More graceful handling of stream creation failure due stream space exhaustation,381
"common \ src \ main \ java \ io \ netty \ util \ internal \ NativeLibraryLoader . java \n - logger . debug ( "" Unable to load the library ' { } ' , trying next name . . . "" , name , t ) ; \n + \n - if ( logger . isDebugEnabled ( ) ) { \n - logger . debug ( \n - "" { } cannot be loaded from java . library . path , "" \n - + "" now trying export to - Dio . netty . native . workdir : { } "" , name , WORKDIR , ex ) ; \n - } \n - logger . debug ( "" Unable to load the library ' { } ' , trying other loading mechanism . "" , name , e ) ; \n - logger . debug ( "" Unable to load the library ' { } ' , trying other loading mechanism . "" , name , e ) ; \n",Make native loading logging less confusing ( # 10944 ) \n Motivation : \n We produced a lot of noise during loading native libraries as we always included the stacktrace if we could not load by one mechanism . We should better just not include the stacktrace in the debugging logging if one mechanism fails . We will log all the stacks anyway when all of the mechanisms fail . \n Modifications : \n Make logging less aggressive \n Result : \n Less confusing behaviour for the end - user,381
handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n + / / These method will override the method defined by Java 8u251 and later . As we may compile with an earlier \n + / / java8 version we don ' t use @ Override annotations here . \n + public String getApplicationProtocol ( ) { \n + return applicationProtocol ; \n + } \n + \n + / / These method will override the method defined by Java 8u251 and later . As we may compile with an earlier \n + / / java8 version we don ' t use @ Override annotations here . \n + public String getHandshakeApplicationProtocol ( ) { \n + return applicationProtocol ; \n + } \n + \n,Override ALPN methods on ReferenceCountedOpenSslEngine ( # 10954 ) \n Motivation : \n We should override the get * ApplicationProtocol ( ) methods in ReferenceCountedOpenSslEngine to make it easier for users to obtain the selected application protocol \n Modifications : \n Add missing overrides \n Result : \n Easier for the user to get the selected application protocol ( if any ),381
. github \ workflows \ ci - build . yml \n - name : Build project without leak detection \n + - name : $ { { matrix . setup } } test - report \n + uses : scacap / action - surefire - report @ v1 \n + with : \n + github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + \n - uses : actions / upload - artifact @ v2 \n . github \ workflows \ ci - pr . yml \n - name : Build project with leak detection \n + - name : $ { { matrix . setup } } test - report \n + uses : scacap / action - surefire - report @ v1 \n + with : \n + github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + \n - name : Checking for detected leak \n,Use action to report unit test errors ( # 10966 ) \n Motivation : \n To make it easier to understand why the build fails lets use an action that will report which unit test failed \n Modifications : \n - Replace custom script with action - surefire - report \n Result : \n Easier to understand test failures,381
all \ pom . xml \n - < classifier > osx - x86 _ 64 < / classifier > \n + < version > $ { project . version } < / version > \n + < classifier > $ { jni . classifier } < / classifier > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - resolver - dns - native - macos < / artifactId > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > netty - resolver - dns - native - macos < / artifactId > \n + < scope > compile < / scope > \n + < optional > true < / optional > \n + < / dependency > \n,Update dependency declaration in all pom . xml ( # 10967 ) \n Motivation : \n We did have the architecture hardcoded in the dependency which is not correct as this will let the build fail on Applie Silicion ( m1 ) . Also we did miss some dependencies on other BSDs \n Modifications : \n - Fix classifier \n - Add missing dependencies \n Result : \n Be able to build on Apple Silicon ( m1 ),381
"new file \n . github \ scripts \ check _ build _ result . sh \n + # ! / bin / bash \n + set - e \n + \n + if [ "" $ # "" - ne 1 ] ; then \n + echo "" Expected build log as argument "" \n + exit 1 \n + fi \n + \n + if grep - q ' BUILD FAILURE ' $ 1 ; then \n + echo "" Build failure detected , please inspect build log "" \n + exit 1 \n + else \n + echo "" Build successful "" \n + exit 0 \n + fi \n . github \ workflows \ ci - build . yml \n - name : Build project without leak detection \n - run : docker - compose $ { { matrix . docker - compose - run } } \n + run : docker - compose $ { { matrix . docker - compose - run } } | tee build . output \n - - name : $ { { matrix . setup } } test - report \n - uses : scacap / action - surefire - report @ v1 \n - with : \n - github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + - name : Checking for test failures \n + run : . / . github / scripts / check _ build _ result . sh build . output \n - uses : actions / upload - artifact @ v2 \n . github \ workflows \ ci - pr . yml \n - name : Build project with leak detection \n - - name : $ { { matrix . setup } } test - report \n - uses : scacap / action - surefire - report @ v1 \n - with : \n - github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + - name : Checking for test failures \n + run : . / . github / scripts / check _ build _ result . sh build - leak . output \n - name : Checking for detected leak \n",Use custom script to check for build failures ( # 10968 ) \n Motivation : \n It turns out we can ' t use the action to check for build failures as it can ' t be used when a PR is done from a fork . Let ' s just use our simple script . \n Modifications : \n - Replace action with custom script \n Result : \n Builds for PRs that are done via forks work again .,381
testsuite \ src \ main \ java \ io \ netty \ testsuite \ transport \ socket \ SocketShutdownOutputBySelfTest . java \n + import org . junit . Ignore ; \n + @ Ignore \n,Ignore SocketShutdownOutputBySelfTest . testWriteAfterShutdownOutputNoWritabilityChange ( # 10970 ) \n Motivation : \n The testWriteAfterShutdownOutputNoWritabilityChange ( ) failed a few times on the CI randomly . Let ' s skip it for now while we investigate and see if there is anything we can do to make the test less flaky on the CI . \n Modifications : \n Add @ Ignore on the testWriteAfterShutdownOutputNoWritabilityChange method \n Result : \n Less flaky CI,381
"resolver - dns - native - macos \ src \ main \ c \ netty _ resolver _ dns _ macos . c \n - \n + if ( config = = NULL ) { \n + goto error ; \n + } \n + if ( resolver = = NULL ) { \n + goto error ; \n + } \n - jbyteArray address = netty _ unix _ socket _ createInetSocketAddressArray ( env , ( const struct sockaddr _ storage * ) resolver - > nameserver [ a ] ) ; \n + const struct sockaddr _ storage * addr = ( const struct sockaddr _ storage * ) resolver - > nameserver [ a ] ; \n + if ( addr = = NULL ) { \n + goto error ; \n + } \n + jbyteArray address = netty _ unix _ socket _ createInetSocketAddressArray ( env , addr ) ; \n - jstring search = ( * env ) - > NewStringUTF ( env , resolver - > search [ a ] ) ; \n + char * s = resolver - > search [ a ] ; \n + if ( s = = NULL ) { \n + goto error ; \n + } \n + jstring search = ( * env ) - > NewStringUTF ( env , s ) ; \n - dns _ configuration _ free ( config ) ; \n + if ( config ! = NULL ) { \n + dns _ configuration _ free ( config ) ; \n + } \n",Fix possible SEGV when using native dns resolver on macos ( # 10971 ) \n Motivation : \n We should add some more NULL checks to ensure we not SEGV in some cases \n Modifications : \n Add more NULL checks \n Result : \n More robust implementation,381
"handler \ src \ main \ java \ io \ netty \ handler \ ssl \ ReferenceCountedOpenSslEngine . java \n - SSL . setMode ( ssl , SSL . getMode ( ssl ) | SSL . SSL _ MODE _ ENABLE _ PARTIAL _ WRITE \n - | SSL . SSL _ MODE _ ENABLE _ FALSE _ START ) ; \n + SSL . setMode ( ssl , SSL . getMode ( ssl ) | SSL . SSL _ MODE _ ENABLE _ PARTIAL _ WRITE ) ; \n","Revert "" Enable SSL _ MODE _ ENABLE _ FALSE _ START if jdkCompatibilityMode is false ( # 10407 ) "" ( # 10980 ) \n Motivation : \n TLS _ FALSE _ START slightly changes the "" flow "" during handshake which may cause suprises for the end - user . We should better disable it by default again and later add a way to enable it for the user . \n Modification : \n This reverts commit 514d349e1fa5a057e815a5f3ac6a7e3f3aa19784 . \n Result : \n Restore "" old flow "" during TLS handshakes .",381
"scripts \ finish _ release . sh \n + if git tag | grep - q "" $ 2 "" ; then \n + echo "" Tag $ 2 already exists "" \n + exit 1 \n + fi \n + \n",Fail the the finish _ release . sh script if the tag already exists locally \n Motivation : \n We should fail the script if the tag already exists locally to ensure we really deploy the right code \n Modifications : \n Check if the tag already exists and if so print an error and exit \n Result : \n No risks to deploy wrong code as part of the release,381
"scripts \ finish _ release . sh \n + . / mvnw org . sonatype . plugins : nexus - staging - maven - plugin : rc - close org . sonatype . plugins : nexus - staging - maven - plugin : rc - release - DstagingRepositoryId = "" $ 1 "" - DnexusUrl = https : / / oss . sonatype . org - DserverId = sonatype - nexus - staging - DskipTests = true \n + \n",Close and release the staging repository at the end \n Motivation : \n We can just close and release the staging repository at the end and so remove the extra manual steps \n Modification : \n Execute extra goals for close and release \n Result : \n Less manual actions needed for release,381
"new file \n scripts \ list _ staged _ release . sh \n + # ! / bin / bash \n + set - e \n + \n + RC _ LIST = $ ( mvn org . sonatype . plugins : nexus - staging - maven - plugin : rc - list - DserverId = sonatype - nexus - staging - DnexusUrl = https : / / oss . sonatype . org | grep - A 2 "" \ [ INFO \ ] ID State Description "" ) \n + STAGED = $ ( echo "" $ RC _ LIST "" | grep ' OPEN ' | cut - f 2 - d ' ' ) \n + echo "" $ STAGED "" \n",Add script which list staged releases \n Motivation : \n When finish the release process we need to give the id of the staged release . Let ' s add a script for that \n Modifications : \n Add script which allows to show all staged releases \n Result : \n No need to login into sonatype anymore,381
"scripts \ finish _ release . sh \n - . / mvnw org . sonatype . plugins : nexus - staging - maven - plugin : rc - close org . sonatype . plugins : nexus - staging - maven - plugin : rc - release - DstagingRepositoryId = "" $ 1 "" - DnexusUrl = https : / / oss . sonatype . org - DserverId = sonatype - nexus - staging - DskipTests = true \n + . / mvnw org . sonatype . plugins : nexus - staging - maven - plugin : rc - close org . sonatype . plugins : nexus - staging - maven - plugin : rc - release - DstagingRepositoryId = "" $ 1 "" - DnexusUrl = https : / / oss . sonatype . org - DserverId = sonatype - nexus - staging - DskipTests = true - DstagingProgressTimeoutMinutes = 10 \n",Update timeout to 10 minutes \n Motivation : \n We should use a higher timeout as sometimes the verification process in oss . sonatype . org is very slow . \n Modifications : \n Bump up timeout to 10 minutes \n Result : \n Less likely to see timeouts,381
"new file \n . github \ workflows \ ci - pr - reports . yml \n + name : PR Reports \n + on : \n + workflow _ run : \n + workflows : [ "" Build PR "" ] \n + types : \n + - completed \n + jobs : \n + tests : \n + runs - on : ubuntu - latest \n + strategy : \n + matrix : \n + include : \n + - setup : linux - x86 _ 64 - java8 \n + - setup : linux - x86 _ 64 - java11 \n + - setup : linux - x86 _ 64 - java15 \n + - setup : linux - x86 _ 64 - java11 - boringssl \n + steps : \n + - name : Download Artifacts \n + uses : dawidd6 / action - download - artifact @ v2 . 11 . 0 \n + with : \n + github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + workflow : $ { { github . event . workflow _ run . workflow _ id } } \n + commit : $ { { github . event . workflow _ run . head _ commit . id } } \n + # File location set in ci - pr . yml and must be coordinated . \n + name : test - results - $ { { matrix . setup } } \n + - name : Publish Test Report \n + uses : scacap / action - surefire - report @ v1 . 0 . 7 \n + with : \n + github _ token : $ { { secrets . GITHUB _ TOKEN } } \n + report _ paths : ' * * / target / surefire - reports / TEST - * . xml ' \n + commit : $ { { github . event . workflow _ run . head _ commit . id } } \n + check _ name : test reports \n . github \ workflows \ ci - pr . yml \n - name : $ { { matrix . setup } } \n + name : $ { { matrix . setup } } build \n - uses : actions / checkout @ v2 \n - name : Checking for detected leak \n + - name : Upload Test Results \n + if : always ( ) \n + uses : actions / upload - artifact @ v2 \n + with : \n + name : test - results - $ { { matrix . setup } } \n + path : ' * * / target / surefire - reports / TEST - * . xml ' \n + \n - uses : actions / upload - artifact @ v2 \n",Publish test results after PR run ( # 11002 ) \n Motivation : \n To make it easier to understand why a build failed let us publish the rest results \n Modifications : \n Use a new workflow to be able to publish the test reports \n Result : \n Easier to understand why a PR did fail,381
pom . xml \n - < osmaven . version > 1 . 6 . 2 < / osmaven . version > \n + < osmaven . version > 1 . 7 . 0 < / osmaven . version > \n,Update to latest os - maven - plugin ( # 11003 ) \n Motivation : \n A new version of the os - maven - plugin was released \n Modifications : \n Update to latest version \n Result : \n Use latest version,381
docker \ Dockerfile . centos6 \n - ARG java _ version = 1 . 8 \n + ARG java _ version = adopt @ 1 . 8 . 0 - 272 \n,Update the java version that is used in the docker file ( # 11007 ) \n Motivation : \n Jabba does not contain version 1 . 8 anymore \n Modifications : \n Use some java version that exists \n Result : \n Builder the docker image from scratch work again,381
"handler \ src \ test \ java \ io \ netty \ handler \ traffic \ FileRegionThrottleTest . java \n + import org . junit . Ignore ; \n + @ Ignore ( "" This test is flaky , need more investigation "" ) \n",Disable flaky test ( # 11017 ) \n Motivation : \n The testGlobalWriteThrottle is flaky and failed our build multiple times now . Lets disable it for now until we had time to investigate \n Modifications : \n Disable flaky test \n Result : \n Less failures during build,381
pom . xml \n - < tcnative . version > 2 . 0 . 35 . Final < / tcnative . version > \n + < tcnative . version > 2 . 0 . 36 . Final < / tcnative . version > \n,Update to netty - tcnative 2 . 0 . 36 . Final ( # 10923 ) \n Motivation : \n Update to latest netty - tcnative release \n Modifications : \n Update version \n Result : \n Use latest version,381
React \ Fabric \ Mounting \ ComponentViews \ Image \ RCTImageComponentView . mm \n - auto instrumentation = std : : static _ pointer _ cast < RCTImageInstrumentationProxy const > ( \n - data . getImageRequest ( ) . getSharedImageInstrumentation ( ) ) ; \n - if ( instrumentation ) { \n - instrumentation - > trackNativeImageView ( self ) ; \n - } \n,Stop logging for Fabric from FBReactStreamingImageLoader \n Summary : Changelog : [ Internal ] Stop logging for Fabric from FBReactStreamingImageLoader \n Reviewed By : fkgozali \n Differential Revision : D23172395 \n fbshipit - source - id : d9fc4e82958d2f88ff91bddeb385fe3073cd8f1e,388
"React \ Fabric \ Mounting \ ComponentViews \ Image \ RCTImageComponentView . mm \n + # import < React / RCTConversions . h > \n - # import "" RCTConversions . h "" \n - # import "" RCTFabricComponentsPlugins . h "" \n - \n + # ifdef _ _ cplusplus \n + extern "" C "" { \n + # endif \n + \n + / / Can ' t the import generated Plugin . h because plugins are not in this BUCK target \n + Class < RCTComponentViewProtocol > RCTImageCls ( void ) ; \n + \n + # ifdef _ _ cplusplus \n + } \n + # endif \n + \n React \ Fabric \ Mounting \ ComponentViews \ RCTFabricComponentsPlugins . h \n - Class < RCTComponentViewProtocol > RCTImageCls ( void ) _ _ attribute _ _ ( ( used ) ) ; \n React \ Fabric \ Mounting \ ComponentViews \ RCTFabricComponentsPlugins . mm \n - { "" Image "" , RCTImageCls } , \n React \ Fabric \ Mounting \ ComponentViews \ View \ RCTViewComponentView . mm \n + # import < React / RCTConversions . h > \n - # import "" RCTConversions . h "" \n - # import "" RCTFabricComponentsPlugins . h "" \n - \n + # ifdef _ _ cplusplus \n + extern "" C "" { \n + # endif \n + \n + / / Can ' t the import generated Plugin . h because plugins are not in this BUCK target \n + Class < RCTComponentViewProtocol > RCTViewCls ( void ) ; \n + \n + # ifdef _ _ cplusplus \n + } \n + # endif \n + \n",Create internal Fabric subclass of RCTImageComponentView \n Summary : Changelog : [ Internal ] Create internal Fabric subclass of RCTImageComponentView \n Reviewed By : sammy - SC \n Differential Revision : D23211115 \n fbshipit - source - id : 0e756de3f3e555bf212dc88dfc8c32930ac85132,388
React \ Fabric \ Mounting \ ComponentViews \ View \ RCTViewComponentView . mm \n + - ( BOOL ) shouldGroupAccessibilityChildren \n + { \n + return YES ; \n + } \n + \n - ( NSArray < UIAccessibilityCustomAction * > * ) accessibilityCustomActions \n,"Group accessible views using the view hierarchy \n Summary : In iOS when a parent UIView returns YES on [ shouldGroupAccessibilityChildren ] ( https : / / developer . apple . com / documentation / objectivec / nsobject / 1615143 - shouldgroupaccessibilitychildren ) , VoiceOver groups together the accessible children of the parent view , regardless of their position on screen . In iOS this defaults to NO . \n Reviewed By : sammy - SC \n Differential Revision : D23844265 \n fbshipit - source - id : eb99bf0873ccfd9fb196f8f7b6eafe055f6ae810",388
"Libraries \ Image \ Image . ios . js \n + / / number params like rootTag cannot be nullable before TurboModules is available \n - rootTag , \n + rootTag ? rootTag : 0 , \n Libraries \ Image \ NativeImageLoaderIOS . js \n + prefetchImageWithMetadata ? : ( \n - rootTag ? : ? number , \n + rootTag : number , \n + queryCache : ( uris : Array < string > ) = > Promise < Object > ; \n Libraries \ Image \ RCTImageLoader . mm \n - [ self prefetchImageWithMetadata : uri queryRootName : nil rootTag : nil resolve : resolve reject : reject ] ; \n + [ self prefetchImageWithMetadata : uri queryRootName : nil rootTag : 0 resolve : resolve reject : reject ] ; \n - rootTag : ( NSNumber * ) rootTag \n + rootTag : ( double ) rootTag \n - . surfaceId = [ rootTag intValue ] , \n + . surfaceId = ( int ) rootTag , \n",Fix prefetchImageWithMetadata redbox in AMA \n Reviewed By : RSNara \n Differential Revision : D24837264 \n fbshipit - source - id : b2aeef2c051fa15c06cf2eb6350c152b722196c2,388
Libraries \ Image \ RCTImageLoader . mm \n + static BOOL ( ^ getImagePerfInstrumentationForFabricEnabled ) ( ) = ( ^ BOOL ( ) { \n + return NO ; \n + } ) ; \n + \n + BOOL RCTGetImageLoadingPerfInstrumentationForFabricEnabled ( ) { \n + return getImagePerfInstrumentationForFabricEnabled ( ) ; \n + } \n + \n + void RCTSetImageLoadingPerfInstrumentationForFabricEnabledBlock ( BOOL ( ^ getMobileConfigEnabled ) ( ) ) { \n + getImagePerfInstrumentationForFabricEnabled = getMobileConfigEnabled ; \n + } \n + \n Libraries \ Image \ RCTImageLoaderWithAttributionProtocol . h \n + RCT _ EXTERN BOOL RCTGetImageLoadingPerfInstrumentationForFabricEnabled ( ) ; \n + RCT _ EXTERN void RCTSetImageLoadingPerfInstrumentationForFabricEnabledBlock ( BOOL ( ^ getEnabled ) ( ) ) ; \n + \n,Set MobileConfig for Fabric logging in FBReactModule \n Summary : Changelog : [ RN ] [ iOS ] Allow gate to be set for Fabric logging from the React Module \n Reviewed By : fkgozali \n Differential Revision : D24256546 \n fbshipit - source - id : 7b290efb9abd3035559f743e6e5b6701e02053e1,388
"ReactCommon \ react \ renderer \ imagemanager \ platform \ ios \ RCTImageManager . mm \n + NSURLRequest * request = NSURLRequestFromImageSource ( imageSource ) ; \n + BOOL hasModuleName = [ self - > _ imageLoader respondsToSelector : @ selector ( loaderModuleNameForRequestUrl : ) ] ; \n + NSString * moduleName = hasModuleName ? [ self - > _ imageLoader loaderModuleNameForRequestUrl : request . URL ] : nil ; \n + std : : string moduleCString = \n + std : : string ( [ moduleName UTF8String ] , [ moduleName lengthOfBytesUsingEncoding : NSUTF8StringEncoding ] ) ; \n + telemetry - > setLoaderModuleName ( moduleCString ) ; \n + \n - NSURLRequest * request = NSURLRequestFromImageSource ( imageSource ) ; \n - \n - BOOL hasModuleName = [ self - > _ imageLoader respondsToSelector : @ selector ( loaderModuleNameForRequestUrl : ) ] ; \n - NSString * moduleName = hasModuleName ? [ self - > _ imageLoader loaderModuleNameForRequestUrl : request . URL ] : nil ; \n - std : : string moduleCString = \n - std : : string ( [ moduleName UTF8String ] , [ moduleName lengthOfBytesUsingEncoding : NSUTF8StringEncoding ] ) ; \n - telemetry - > setLoaderModuleName ( moduleCString ) ; \n - \n",Fix : Set image loader module name synchronously \n Summary : Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D24290066 \n fbshipit - source - id : e2bad9ed8c126c7b49356bc7a2c1114160149fd3,388
"Libraries \ Image \ RCTImageLoader . mm \n + std : : mutex _ loadersMutex ; \n - / / Get loaders , sorted in reverse priority order ( highest priority first ) \n - \n - if ( _ loadersProvider ) { \n - _ loaders = _ loadersProvider ( ) ; \n - } else { \n - RCTAssert ( _ bridge , @ "" Trying to find RCTImageURLLoaders and bridge not set . "" ) ; \n - _ loaders = [ _ bridge modulesConformingToProtocol : @ protocol ( RCTImageURLLoader ) ] ; \n - } \n - \n - _ loaders = [ _ loaders sortedArrayUsingComparator : ^ NSComparisonResult ( id < RCTImageURLLoader > a , id < RCTImageURLLoader > b ) { \n - float priorityA = [ a respondsToSelector : @ selector ( loaderPriority ) ] ? [ a loaderPriority ] : 0 ; \n - float priorityB = [ b respondsToSelector : @ selector ( loaderPriority ) ] ? [ b loaderPriority ] : 0 ; \n - if ( priorityA > priorityB ) { \n - return NSOrderedAscending ; \n - } else if ( priorityA < priorityB ) { \n - return NSOrderedDescending ; \n + std : : unique _ lock < std : : mutex > guard ( _ loadersMutex ) ; \n + if ( ! _ loaders ) { \n + \n + / / Get loaders , sorted in reverse priority order ( highest priority first ) \n + if ( _ loadersProvider ) { \n + _ loaders = _ loadersProvider ( ) ; \n - return NSOrderedSame ; \n + RCTAssert ( _ bridge , @ "" Trying to find RCTImageURLLoaders and bridge not set . "" ) ; \n + _ loaders = [ _ bridge modulesConformingToProtocol : @ protocol ( RCTImageURLLoader ) ] ; \n - } ] ; \n + \n + _ loaders = [ _ loaders sortedArrayUsingComparator : ^ NSComparisonResult ( id < RCTImageURLLoader > a , id < RCTImageURLLoader > b ) { \n + float priorityA = [ a respondsToSelector : @ selector ( loaderPriority ) ] ? [ a loaderPriority ] : 0 ; \n + float priorityB = [ b respondsToSelector : @ selector ( loaderPriority ) ] ? [ b loaderPriority ] : 0 ; \n + if ( priorityA > priorityB ) { \n + return NSOrderedAscending ; \n + } else if ( priorityA < priorityB ) { \n + return NSOrderedDescending ; \n + } else { \n + return NSOrderedSame ; \n + } \n + } ] ; \n + } \n","Synchronize RCTImageLoader loaders initialization \n Summary : \n The method ` imageURLLoaderForURL ` can be called from multiple threads . This adds a mutex to make sure that _ loaders is initialized with a non - nil value only once . \n We ' ll only lock this mutex at one point in time as long as ` _ loadersProvider ( ) ` gives a value , so the mutex doesn ' t affect performance . \n Changelog : [ iOS ] [ Fixed ] Synchronize RCTImageLoader loaders initialization \n Reviewed By : fkgozali \n Differential Revision : D24513083 \n fbshipit - source - id : b89ef8a82729eda508162b01f7fdaa8a291f40d0",388
"ReactCommon \ react \ renderer \ components \ image \ ImageProps . cpp \n - convertRawProp ( rawProps , "" tintColor "" , sourceProps . tintColor , { } ) ) { } \n + convertRawProp ( rawProps , "" tintColor "" , sourceProps . tintColor , { } ) ) , \n + internal _ analyticTag ( convertRawProp ( \n + rawProps , \n + "" internal _ analyticTag "" , \n + sourceProps . internal _ analyticTag , \n + { } ) ) { } \n ReactCommon \ react \ renderer \ components \ image \ ImageProps . h \n + const std : : string internal _ analyticTag { } ; \n",7 / 7 Log attribution context from the image component \n Summary : Changelog : [ Internal ] Log attribution context from the Fabric image component \n Reviewed By : fkgozali \n Differential Revision : D23547930 \n fbshipit - source - id : 125f34dac85ff6ac52a798bb1a36394436cb2c0f,388
ReactCommon \ react \ renderer \ imagemanager \ ImageTelemetry . cpp \n + void ImageTelemetry : : willRequestUrl ( ) { \n + assert ( willRequestUrlTime _ = = kTelemetryUndefinedTimePoint ) ; \n + willRequestUrlTime _ = telemetryTimePointNow ( ) ; \n + } \n + \n + TelemetryTimePoint ImageTelemetry : : getWillRequestUrlTime ( ) const { \n + assert ( willRequestUrlTime _ ! = kTelemetryUndefinedTimePoint ) ; \n + return willRequestUrlTime _ ; \n + } \n + \n ReactCommon \ react \ renderer \ imagemanager \ ImageTelemetry . h \n + # include < react / utils / Telemetry . h > \n + / * \n + * Signaling \n + * / \n + void willRequestUrl ( ) ; \n + \n + / * \n + * Reading \n + * / \n + TelemetryTimePoint getWillRequestUrlTime ( ) const ; \n + \n + TelemetryTimePoint willRequestUrlTime _ { kTelemetryUndefinedTimePoint } ; \n + \n ReactCommon \ react \ renderer \ imagemanager \ platform \ ios \ RCTImageManager . mm \n + telemetry - > willRequestUrl ( ) ; \n,5 / 6 Log image - requested QPL point for Fabric images \n Summary : \n Changelog : [ Internal ] Log image - requested QPL point for Fabric images \n * See D23450649 for the full lifecycle \n Reviewed By : fkgozali \n Differential Revision : D23448179 \n fbshipit - source - id : 0a78dae2d4f1e6322bbeee3574b10abe1efb30ef,388
React \ Fabric \ Mounting \ ComponentViews \ Image \ RCTImageComponentView . h \n + # import < React / RCTImageResponseDelegate . h > \n - @ interface RCTImageComponentView : RCTViewComponentView { \n + @ interface RCTImageComponentView : RCTViewComponentView < RCTImageResponseDelegate > { \n React \ Fabric \ Mounting \ ComponentViews \ Image \ RCTImageComponentView . mm \n - # import < React / RCTImageResponseDelegate . h > \n - @ interface RCTImageComponentView ( ) < RCTImageResponseDelegate > \n + @ interface RCTImageComponentView ( ) \n,4 / 6 Log view - appear and view - disappear for Fabric image logging \n Reviewed By : fkgozali \n Differential Revision : D23447863 \n fbshipit - source - id : db16d97034a8d4ba6fcd08da5068039450f3c57b,388
ReactCommon \ react \ renderer \ imagemanager \ ImageTelemetry . cpp \n - void ImageTelemetry : : willRequestUrl ( ) { \n - assert ( willRequestUrlTime _ = = kTelemetryUndefinedTimePoint ) ; \n - willRequestUrlTime _ = telemetryTimePointNow ( ) ; \n - } \n - \n - assert ( willRequestUrlTime _ ! = kTelemetryUndefinedTimePoint ) ; \n ReactCommon \ react \ renderer \ imagemanager \ ImageTelemetry . h \n + * where the willRequestUrlTime is the time at ImageTelemetry ' s creation . \n - ImageTelemetry ( SurfaceId const surfaceId ) : surfaceId _ ( surfaceId ) { } \n + ImageTelemetry ( SurfaceId const surfaceId ) : surfaceId _ ( surfaceId ) { \n + willRequestUrlTime _ = telemetryTimePointNow ( ) ; \n + } \n - / * \n - * Signaling \n - * / \n - void willRequestUrl ( ) ; \n - \n - / * \n - * Reading \n - * / \n - TelemetryTimePoint willRequestUrlTime _ { kTelemetryUndefinedTimePoint } ; \n + TelemetryTimePoint willRequestUrlTime _ ; \n ReactCommon \ react \ renderer \ imagemanager \ platform \ ios \ RCTImageManager . mm \n - telemetry - > willRequestUrl ( ) ; \n,Do not log image if it fails lifecycle assert in getWillRequestUrlTime \n Reviewed By : sammy - SC \n Differential Revision : D24990452 \n fbshipit - source - id : ce4d5ec9e3cf237c6edbd17368f2dcf3aecbec2b,388
"Libraries \ Components \ TextInput \ RCTMultilineTextInputNativeComponent . js \n + import RCTTextInputViewConfig from ' . / RCTTextInputViewConfig ' ; \n + const ReactNativeViewConfigRegistry = require ( ' . . / . . / Renderer / shims / ReactNativeViewConfigRegistry ' ) ; \n - const SinglelineTextInputNativeComponent : HostComponent < mixed > = requireNativeComponent < mixed > ( \n - ' RCTMultilineTextInputView ' , \n - ) ; \n + let MultilineTextInputNativeComponent ; \n + if ( global . RN $ Bridgeless ) { \n + ReactNativeViewConfigRegistry . register ( ' RCTMultilineTextInputView ' , ( ) = > { \n + return RCTTextInputViewConfig ; \n + } ) ; \n + MultilineTextInputNativeComponent = ' RCTMultilineTextInputView ' ; \n + } else { \n + MultilineTextInputNativeComponent = requireNativeComponent < mixed > ( \n + ' RCTMultilineTextInputView ' , \n + ) ; \n + } \n - export default SinglelineTextInputNativeComponent ; \n + / / flowlint - next - line unclear - type : off \n + export default ( ( MultilineTextInputNativeComponent : any ) : HostComponent < mixed > ) ; \n Libraries \ Components \ TextInput \ RCTSingelineTextInputNativeComponent . js \n - import RCTSinglelineTextInputViewConfig from ' . / RCTSinglelineTextInputViewConfig ' ; \n + import RCTTextInputViewConfig from ' . / RCTTextInputViewConfig ' ; \n - return RCTSinglelineTextInputViewConfig ; \n + return RCTTextInputViewConfig ; \n rename from Libraries \ Components \ TextInput \ RCTSinglelineTextInputViewConfig . js \n rename to Libraries \ Components \ TextInput \ RCTTextInputViewConfig . js \n - const RCTSinglelineTextInputViewConfig = { \n + const RCTTextInputViewConfig = { \n - module . exports = ( RCTSinglelineTextInputViewConfig : ViewConfig ) ; \n + module . exports = ( RCTTextInputViewConfig : ViewConfig ) ; \n",Add ViewConfig for MultilineTextInput \n Differential Revision : D26463558 \n fbshipit - source - id : fe73e60f9a03d865bc9deab59260321072151e22,388
React \ CoreModules \ RCTAlertController . h \n - ( void ) show : ( BOOL ) animated completion : ( void ( ^ ) ( void ) ) completion ; \n + - ( void ) hide ; \n - @ end \n + @ end \n React \ CoreModules \ RCTAlertController . m \n + - ( void ) hide \n + { \n + _ alertWindow = nil ; \n + } \n + \n React \ CoreModules \ RCTAlertManager . mm \n + [ weakAlertController hide ] ; \n + [ weakAlertController hide ] ; \n + [ weakAlertController hide ] ; \n,"Fix retain cycle in RCTAlertController \n Summary : \n ` RCTAlertController ` creates a new window , and presents itself in that window . \n RCTAlertController strongly retains the window , and the window strongly retains RCTAlertController when presenting it . \n This adds a new method to break that cycle once alert is dismissed . \n Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D25312413 \n fbshipit - source - id : e4048922aa697eb42c4c149827bac61bc7bc5528",398
React \ Views \ ScrollView \ RCTScrollView . m \n - _ customRefreshControl . scrollView = self ; \n + if ( [ _ customRefreshControl respondsToSelector : @ selector ( setScrollView : ) ] ) { \n + _ customRefreshControl . scrollView = self ; \n + } \n,Fix refresh control redbox \n Summary : Changelog : [ Internal ] \n Reviewed By : Vince0613 \n Differential Revision : D22989945 \n fbshipit - source - id : 735da1cf103b2465663ecb6abfd49e512aff9a1e,398
"React \ Base \ RCTEventDispatcher . h \n + @ protocol RCTJSDispatcherModule \n + \n + @ property ( nonatomic , copy ) void ( ^ dispatchToJSThread ) ( dispatch _ block _ t block ) ; \n + \n + @ end \n + \n React \ Base \ RCTJSInvokerModule . h \n - @ property ( nonatomic , copy , nonnull ) void ( ^ invokeJS ) ( NSString * module , NSString * method , NSArray * args ) ; \n + @ optional \n + @ property ( nonatomic , copy ) void ( ^ invokeJS ) ( NSString * module , NSString * method , NSArray * args ) ; \n + @ property ( nonatomic , copy ) void ( ^ invokeJSWithModuleDotMethod ) ( NSString * moduleDotMethod , NSArray * args ) ; \n React \ Modules \ RCTEventEmitter . h \n - @ property ( nonatomic , copy , nonnull ) void ( ^ invokeJS ) ( NSString * module , NSString * method , NSArray * args ) ; \n","Workarounds for two bridge methods : dispatchToJSThread and enqueueJSCall : \n Summary : \n To get ` RCTNativeAnimatedModule ` working bridgeless , I need to get ` RCTEventDispatcher ` working bridgeless . \n To get ` RCTEventDispatcher ` working bridgeless , I need to support 2 new bridge methods : \n - ` - ( void ) enqueueJSCall : ( NSString * ) moduleDotMethod args : ( NSArray * ) args ` \n - ` - ( void ) dispatchBlock : ( dispatch _ block _ t ) block queue : ( dispatch _ queue _ t ) queue ; ` \n For ( 1 ) I copied the bridge impl exactly . For ( 2 ) , the bridge only dispatches to JS thread , else uses ` dispatch _ async ` . I only added support for dispatching to JS thread , callers can ` dispatch _ async ` themselves if they want to . \n Changelog : [ Internal ] \n Differential Revision : D22962292 \n fbshipit - source - id : e34d15aee72f80dffcaa945bfda05ea415f66df7",398
Libraries \ Animated \ src \ NativeAnimatedHelper . js \n - const STYLES _ WHITELIST = { \n + const SUPPORTED _ STYLES = { \n - const TRANSFORM _ WHITELIST = { \n + const SUPPORTED _ TRANSFORMS = { \n - STYLES _ WHITELIST [ prop ] = true ; \n + SUPPORTED _ STYLES [ prop ] = true ; \n - TRANSFORM _ WHITELIST [ prop ] = true ; \n + SUPPORTED _ TRANSFORMS [ prop ] = true ; \n - if ( ! TRANSFORM _ WHITELIST . hasOwnProperty ( config . property ) ) { \n + if ( ! SUPPORTED _ TRANSFORMS . hasOwnProperty ( config . property ) ) { \n - if ( ! STYLES _ WHITELIST . hasOwnProperty ( key ) ) { \n + if ( ! SUPPORTED _ STYLES . hasOwnProperty ( key ) ) { \n,"Use more inclusive language in Animated \n Summary : \n This appears to be the only usage of whitelist / blacklist in react - native - github , let ' s use some more inclusive language . \n Changelog : [ JS ] [ Internal ] \n Reviewed By : kacieb \n Differential Revision : D22539431 \n fbshipit - source - id : 21d4cd54a5a2a676996ccec7b02ef15c421efee1",398
"Libraries \ Image \ RCTUIImageViewAnimated . m \n - / / displayLink . frameInterval ( < iOS 10 ) - - # of frames that must pass before each displayDidRefresh . After iOS 10 , when this is set to 2 , preferredFramesPerSecond becomes 30 fps . \n - NSTimeInterval durationToNextRefresh ; \n - if ( @ available ( iOS 10 . 0 , * ) ) { \n - durationToNextRefresh = displayLink . targetTimestamp - displayLink . timestamp ; \n - } else { \n - durationToNextRefresh = displayLink . duration * displayLink . frameInterval ; \n - } \n + NSTimeInterval durationToNextRefresh = displayLink . targetTimestamp - displayLink . timestamp ; \n Libraries \ Text \ TextInput \ RCTBaseTextInputView . m \n - BOOL shouldHaveInputAccesoryView ; \n - if ( @ available ( iOS 10 . 0 , * ) ) { \n - shouldHaveInputAccesoryView = \n + BOOL shouldHaveInputAccesoryView = \n - } else { \n - shouldHaveInputAccesoryView = \n - ( \n - keyboardType = = UIKeyboardTypeNumberPad | | \n - keyboardType = = UIKeyboardTypePhonePad | | \n - keyboardType = = UIKeyboardTypeDecimalPad \n - ) & & \n - textInputView . returnKeyType = = UIReturnKeyDone ; \n - } \n React \ Fabric \ Mounting \ ComponentViews \ TextInput \ RCTTextInputComponentView . mm \n - if ( @ available ( iOS 10 . 0 , * ) ) { \n - _ backedTextInputView . textContentType = RCTUITextContentTypeFromString ( newTextInputProps . traits . textContentType ) ; \n - } \n + _ backedTextInputView . textContentType = RCTUITextContentTypeFromString ( newTextInputProps . traits . textContentType ) ; \n React \ Fabric \ Mounting \ ComponentViews \ TextInput \ RCTTextInputUtils . mm \n - \n - if ( @ available ( iOS 10 . 0 , * ) ) { \n - toTextInput . textContentType = fromTextInput . textContentType ; \n - } \n + toTextInput . textContentType = fromTextInput . textContentType ; \n - if ( @ available ( iOS 10 . 0 , * ) ) { \n - return UIKeyboardTypeASCIICapableNumberPad ; \n - } else { \n - return UIKeyboardTypeNumberPad ; \n - } \n + return UIKeyboardTypeASCIICapableNumberPad ; \n","Hardcode @ available ( iOS 10 ) to YES \n Summary : \n RN removed support for iOS 9 last year , therefore iOS10 + is always available . \n Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D22655069 \n fbshipit - source - id : 77e85e0403ea7ea0febc8766c10bb6f94ea417ad",398
"React \ Base \ RCTBridge . h \n - / * * \n - * This notification fires every time the bridge has finished loading an additional JS bundle . \n - * / \n - RCT _ EXTERN NSString * const RCTAdditionalJavaScriptDidLoadNotification ; \n - \n React \ Base \ RCTBridge . m \n - NSString * const RCTAdditionalJavaScriptDidLoadNotification = @ "" RCTAdditionalJavaScriptDidLoadNotification "" ; \n React \ CxxBridge \ RCTCxxBridge . mm \n - [ [ NSNotificationCenter defaultCenter ] \n - postNotificationName : RCTAdditionalJavaScriptDidLoadNotification \n - object : self - > _ parentBridge \n - userInfo : @ { @ "" bridge "" : self } ] ; \n","Delete unused RCTAdditionalJavaScriptDidLoadNotification \n Summary : \n This notification was never used , I ' d rather not have someone start relying on it , and need to figure out how to migrate them in bridgeless mode . \n Changelog : [ Internal ] \n Reviewed By : cpojer , RSNara \n Differential Revision : D22513602 \n fbshipit - source - id : 80b179af8408abc6646a73380b4a66cade3f75f2",398
"React \ Fabric \ Surface \ RCTFabricSurface . h \n - * Just initialized Surface object starts automatically , there is no need \n - * to call ` start ` explicitly . Surface also stops itself on deallocation \n - * automatically . \n + * Surface stops itself on deallocation automatically . \n","Fix misleading comment in RCTFabricSurface API \n Summary : \n Using RCTFabricSurface in bridgeless mode , this comment seems incorrect to me . \n ` [ _ surface start ] ` needs to be called after initialization , or else the stage and ` SurfacePresenter ` registration never happen . \n Maybe this comment used to be true , but it is misleading with the current implementation . \n Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D22800934 \n fbshipit - source - id : c396cbd3fc1749b8e7ab571c9e7bc05cd352fc14",398
"Libraries \ Components \ AppleTV \ NativeTVNavigationEventEmitter . js \n + removeListeners : ( count : number ) = > void ; \n - export default ( TurboModuleRegistry . get < Spec > ( \n - ' TVNavigationEventEmitter ' , \n - ) : ? Spec ) ; \n + let NativeModule : ? Spec = null ; \n + \n + const wrapperModule = { \n + addListener ( eventName : string ) { \n + if ( NativeModule = = null ) { \n + NativeModule = TurboModuleRegistry . get < Spec > ( ' TVNavigationEventEmitter ' ) ; \n + } \n + NativeModule & & NativeModule . addListener ( eventName ) ; \n + } , \n + \n + removeListeners ( count : number ) { \n + if ( NativeModule = = null ) { \n + NativeModule = TurboModuleRegistry . get < Spec > ( ' TVNavigationEventEmitter ' ) ; \n + } \n + NativeModule & & NativeModule . removeListeners ( count ) ; \n + } , \n + } ; \n + \n + export default wrapperModule ; \n","Lazily create NativeTVNavigationEventEmitter \n Summary : \n Every single RN iOS application is initializing this native module on first bundle load , regardless if it is used or not . This wrapperModule makes it lazy . \n Changelog : [ Internal ] \n Reviewed By : TheSavior \n Differential Revision : D23175668 \n fbshipit - source - id : 0424a62d6c0b4fe7d5ce95f6c96e641a03b5fb2c",398
React \ CoreModules \ RCTKeyboardObserver . mm \n - ( void ) EVENT : ( NSNotification * ) notification \ \n - if ( ! self . bridge ) { \ \n + if ( ! self . bridge & & ! self . invokeJS ) { \ \n,"Bridgeless support for RCTKeyboardObserver \n Summary : \n RCTKeyboardObserver only uses the bridge to avoid sending events during a reload . See D6573855 ( https : / / github . com / facebook / react - native / commit / d9c658566a14ce8767d87435264997aa18dd08e4 ) for reference . \n In bridgeless mode , the bridge is expected to always be nil , as the module uses ` invokeJS ` block to send events instead . \n Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D23176990 \n fbshipit - source - id : 7946c9c2684d7d9ea0a606bad375309a5530a719",398
"Libraries \ NativeAnimation \ RCTNativeAnimatedModule . mm \n + # import < React / RCTLog . h > \n + / * \n + * This selector should only be invoked in bridgeless mode , which is not compatible with this non turbo module . \n + * / \n + - ( void ) setSurfacePresenter : ( id < RCTSurfacePresenterStub > ) surfacePresenter \n + { \n + RCTLogWarn ( @ "" setSurfacePresenter should only be invoked in RCTNativeAnimatedTurboModule "" ) ; \n + } \n + \n Libraries \ NativeAnimation \ RCTNativeAnimatedTurboModule . mm \n + / * \n + * In bridgeless mode , ` setBridge ` is never called during initializtion . Instead this selector is invoked via \n + * BridgelessTurboModuleSetup . \n + * / \n + - ( void ) setSurfacePresenter : ( id < RCTSurfacePresenterStub > ) surfacePresenter \n + { \n + _ surfacePresenter = surfacePresenter ; \n + _ nodesManager = [ [ RCTNativeAnimatedNodesManager alloc ] initWithBridge : self . bridge surfacePresenter : _ surfacePresenter ] ; \n + [ _ surfacePresenter addObserver : self ] ; \n + } \n + \n",Pass RCTSurfacePresenter into RCTNativeAnimatedNodesManager in bridgeless \n Summary : \n This diff ties the stack together . It completes the long chain of RCTSurfacePresenter ownership : \n ` FBReactModule ` - > ` RCTNativeAnimatedTurboModule ` ( this diff and D23272746 ) \n ` RCTNativeAnimatedTurboModule ` - > ` RCTNativeAnimatedNodesManager ` ( this diff ) \n ` RCTNativeAnimatedNodesManager ` - > ` RCTPropsAnimatedNode ` ( D23272735 ) \n It completes animations working without the bridge . \n Changelog : [ Internal ] \n Differential Revision : D23272755 \n fbshipit - source - id : 137f7ff89993a2cb644bd67869eb685afcec4068,398
Libraries \ NativeAnimation \ RCTNativeAnimatedModule . mm \n + + ( BOOL ) requiresMainQueueSetup \n + { \n + return NO ; \n + } \n + \n + - ( instancetype ) init \n + { \n + if ( self = [ super init ] ) { \n + _ operations = [ NSMutableArray new ] ; \n + _ preOperations = [ NSMutableArray new ] ; \n + _ animIdIsManagedByFabric = [ NSMutableDictionary new ] ; \n + } \n + return self ; \n + } \n + \n - ( void ) invalidate \n - ( void ) setBridge : ( RCTBridge * ) bridge \n - \n - _ operations = [ NSMutableArray new ] ; \n - _ preOperations = [ NSMutableArray new ] ; \n - _ animIdIsManagedByFabric = [ NSMutableDictionary new ] ; \n - \n Libraries \ NativeAnimation \ RCTNativeAnimatedTurboModule . mm \n + # import < RCTTypeSafety / RCTConvertHelpers . h > \n - # import < RCTTypeSafety / RCTConvertHelpers . h > \n - \n + + ( BOOL ) requiresMainQueueSetup \n + { \n + return NO ; \n + } \n + \n + - ( instancetype ) init \n + { \n + if ( self = [ super init ] ) { \n + _ operations = [ NSMutableArray new ] ; \n + _ preOperations = [ NSMutableArray new ] ; \n + _ animIdIsManagedByFabric = [ NSMutableDictionary new ] ; \n + } \n + return self ; \n + } \n + \n - ( void ) invalidate \n - ( void ) setBridge : ( RCTBridge * ) bridge \n - \n - _ operations = [ NSMutableArray new ] ; \n - _ preOperations = [ NSMutableArray new ] ; \n - _ animIdIsManagedByFabric = [ NSMutableDictionary new ] ; \n - \n,Create init method for RCTNativeAnimatedModule and it ' s TM fork \n Summary : \n The animated native module relies on ` setBridge ` to perform generic setup which doesn ' t rely on the bridge at all . This diff refactors that setup code to an ` init ` function . \n Changelog : [ Internal ] \n Differential Revision : D23272427 \n fbshipit - source - id : 0c9c5522c9044283f4db25360010465ff42aba25,398
React \ Base \ RCTEventDispatcher . m \n - } else { \n + } else if ( _ dispatchToJSThread ) { \n,"Fix RCTEventDispatcher Crash \n Summary : \n This crash was introduced in D22962320 ( https : / / github . com / facebook / react - native / commit / ffdfbbec08b1afb1970d2cfe75a78a203d4a79a4 ) , which landed 8 / 17 and went into 8 / 23 cut . I plan to pick this diff into that release . \n I can ' t repro this , but there must be a scenario ( in bridged mode ) , where we try to flush event queue while bridge is tearing down . I plan to consider this scenario going forward . \n Changelog : [ Internal ] \n Reviewed By : JoshuaGross \n Differential Revision : D23306445 \n fbshipit - source - id : 285d4b94a17423c3b08d83e7041c4ee04b7e6d0c",398
"Libraries \ NativeAnimation \ Nodes \ RCTPropsAnimatedNode . m \n - # import "" RCTPropsAnimatedNode . h "" \n + # import < React / RCTPropsAnimatedNode . h > \n","Fix CircleCI breakage in RCTPropsAnimatedNode ( # 29800 ) \n Summary : \n Pull Request resolved : https : / / github . com / facebook / react - native / pull / 29800 \n I changed this line in D23272735 ( https : / / github . com / facebook / react - native / commit / 700960c9f1a27a12d703b4f0a17673690799f019 ) , to conform to normal ObjC semantics : impl files can import their header by file name . \n I forgot that their ' s some special linking logic happening in this directory that doesn ' t allow for this import type . \n This diff just reverts one line to fix CircleCI builds . \n Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D23399893 \n fbshipit - source - id : 976199c659522effd632aaeb38616d0d6c962f1f",398
"React \ CoreModules \ RCTDeviceInfo . mm \n + CGSize iPhone12ScreenSize = CGSizeMake ( 1170 , 2532 ) ; \n + CGSize iPhone12MiniScreenSize = CGSizeMake ( 1080 , 2340 ) ; \n + CGSize iPhone12ProMaxScreenSize = CGSizeMake ( 1284 , 2778 ) ; \n - CGSizeEqualToSize ( screenSize , iPhoneXMaxScreenSize ) | | CGSizeEqualToSize ( screenSize , iPhoneXRScreenSize ) ; \n + CGSizeEqualToSize ( screenSize , iPhoneXMaxScreenSize ) | | CGSizeEqualToSize ( screenSize , iPhoneXRScreenSize ) | | \n + CGSizeEqualToSize ( screenSize , iPhone12ScreenSize ) | | CGSizeEqualToSize ( screenSize , iPhone12MiniScreenSize ) | | \n + CGSizeEqualToSize ( screenSize , iPhone12ProMaxScreenSize ) ; \n + ; \n",Fix isIPhoneX check for > = iPhone12 \n Summary : \n Grabbed sizes from https : / / ios - resolution . com / \n Some alternative ways we could do this : \n https : / / stackoverflow . com / questions / 52402477 / ios - detect - if - the - device - is - iphone - x - family - frameless \n https : / / stackoverflow . com / questions / 11197509 / how - to - get - device - make - and - model - on - ios \n Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D25408465 \n fbshipit - source - id : 597f185fecfd7f146036dabfaf9a802328307cab,398
"React \ Views \ RCTDatePicker . m \n + \n + if ( @ available ( iOS 14 , * ) ) { \n + self . preferredDatePickerStyle = UIDatePickerStyleWheels ; \n + } \n","Workaround for Date Picker in iOS14 \n Summary : \n iOS14 has introduced new styles for date picker . The default new calendar style breaks the old spinner type style . \n This is a workaround to keep the spinner style as a default , until the calendar style is properly supported . According to [ this github comment ] ( https : / / github . com / react - native - community / datetimepicker / issues / 285 ) it works well . \n This will fix DatePicker for both Fabric and Paper , since Fabric uses the interop layer to render it . \n Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D23935328 \n fbshipit - source - id : 1a7fadba274e0537f0ac4ced60e23e7c809d57dc",398
"Libraries \ Components \ Picker \ RCTPickerNativeComponent . js \n + const ReactNativeViewConfigRegistry = require ( ' . . / . . / Renderer / shims / ReactNativeViewConfigRegistry ' ) ; \n + import RCTPickerViewConfig from ' . / RCTPickerViewConfig ' ; \n - const RCTPickerNativeComponent : ComponentType = requireNativeComponent < NativeProps > ( \n - ' RCTPicker ' , \n - ) ; \n + let RCTPickerNativeComponent ; \n + if ( global . RN $ Bridgeless ) { \n + ReactNativeViewConfigRegistry . register ( ' RCTPicker ' , ( ) = > { \n + return RCTPickerViewConfig ; \n + } ) ; \n + RCTPickerNativeComponent = ' RCTPicker ' ; \n + } else { \n + RCTPickerNativeComponent = requireNativeComponent < NativeProps > ( ' RCTPicker ' ) ; \n + } \n - export default RCTPickerNativeComponent ; \n + / / flowlint - next - line unclear - type : off \n + export default ( ( RCTPickerNativeComponent : any ) : HostComponent < NativeProps > ) ; \n new file \n Libraries \ Components \ Picker \ RCTPickerViewConfig . js \n + / * * \n + * Copyright ( c ) Facebook , Inc . and its affiliates . \n + * \n + * This source code is licensed under the MIT license found in the \n + * LICENSE file in the root directory of this source tree . \n + * \n + * @ flow strict - local \n + * @ format \n + * / \n + \n + ' use strict ' ; \n + \n + import ReactNativeViewViewConfig from ' . . / . . / Components / View / ReactNativeViewViewConfig ' ; \n + import type { ReactNativeBaseComponentViewConfig } from ' . . / . . / Renderer / shims / ReactNativeTypes ' ; \n + \n + const RCTPickerViewConfig = { \n + uiViewClassName : ' RCTPicker ' , \n + bubblingEventTypes : { \n + topChange : { \n + phasedRegistrationNames : { \n + bubbled : ' onChange ' , \n + captured : ' onChangeCapture ' , \n + } , \n + } , \n + } , \n + directEventTypes : { } , \n + validAttributes : { \n + . . . ReactNativeViewViewConfig . validAttributes , \n + color : { process : require ( ' . . / . . / StyleSheet / processColor ' ) } , \n + fontFamily : true , \n + fontSize : true , \n + fontStyle : true , \n + fontWeight : true , \n + items : true , \n + onChange : true , \n + selectedIndex : true , \n + textAlign : true , \n + } , \n + } ; \n + \n + module . exports = ( RCTPickerViewConfig : ReactNativeBaseComponentViewConfig < > ) ; \n",RCTPicker handwritten view config \n Summary : This completes the Picker stack . Use a handwritten view config to avoid calling ` requireNativeComponent ` in Bridgeless mode . \n Differential Revision : D23663596 \n fbshipit - source - id : 5d0811014fd6f66956803a1db5fee8fd1119d5bc,398
"Libraries \ Components \ Picker \ PickerIOS . ios . js \n - value : ? ( number | string ) , \n + value : ? string , \n - selectedValue : ? ( number | string ) , \n + selectedValue : ? string , \n - value ? : ? ( number | string ) , \n + value ? : ? string , \n Libraries \ Components \ Picker \ RCTPickerNativeComponent . js \n - value : ? ( number | string ) , \n + value : ? string , \n",Remove type union in PickeriOS / PickerNativeComponent \n Summary : \n This builds on the last diff to remove type a type union from Picker . This diff focuses on Picker internals . \n Changelog : [ JS ] Remove type union in PickeriOS / PickerNativeComponent \n Reviewed By : sammy - SC \n Differential Revision : D24254615 \n fbshipit - source - id : f788a2e123135c1e8b9909870c40f53b2dea0227,398
"Libraries \ Components \ Picker \ Picker . js \n - * this item is selected . Can be a string or an integer . \n + * this item is selected . \n - value ? : ? ( number | string ) , \n + value ? : ? string , \n - * Value matching value of one of the items . Can be a string or an integer . \n + * Value matching value of one of the items . \n - selectedValue ? : ? ( number | string ) , \n + selectedValue ? : ? string , \n packages \ rn - tester \ js \ examples \ Modal \ ModalExample . js \n - selectedSupportedOrientation : 0 , \n + selectedSupportedOrientation : ' 0 ' , \n - this . state . selectedSupportedOrientation \n + Number ( this . state . selectedSupportedOrientation ) \n - < Item label = "" Portrait "" value = { 0 } / > \n - < Item label = "" Landscape "" value = { 1 } / > \n - < Item label = "" Landscape left "" value = { 2 } / > \n - < Item label = "" Portrait and landscape right "" value = { 3 } / > \n - < Item label = "" Portrait and landscape "" value = { 4 } / > \n - < Item label = "" Default supportedOrientations "" value = { 5 } / > \n + < Item label = "" Portrait "" value = { ' 0 ' } / > \n + < Item label = "" Landscape "" value = { ' 1 ' } / > \n + < Item label = "" Landscape left "" value = { ' 2 ' } / > \n + < Item label = "" Portrait and landscape right "" value = { ' 3 ' } / > \n + < Item label = "" Portrait and landscape "" value = { ' 4 ' } / > \n + < Item label = "" Default supportedOrientations "" value = { ' 5 ' } / > \n","Remove type union in Picker . js \n Summary : \n Flow type unions don ' t play well with Fabric components . This diff removes a union in ` Picker . js ` and fixes all the flow errors . \n Before this diff , all these surfaces would crash with the new Fabric Picker impl , because the impl asserts that this field is a string . \n Reviewed By : sammy - SC \n Differential Revision : D24236317 \n fbshipit - source - id : 6e646c84fcd16658aaabe5e93507f5f33b346a65",398
"React \ Fabric \ Mounting \ ComponentViews \ Picker \ RCTPickerComponentView . mm \n + # import < React / RCTLog . h > \n + bool needsToReload = false ; \n + needsToReload = true ; \n + [ self setSelectedIndex ] ; \n + needsToReload = true ; \n + if ( needsToReload ) { \n + [ _ pickerView reloadAllComponents ] ; \n + } \n + \n - / / TODO ( T75217510 ) - Handle Native Commands \n + - ( void ) handleCommand : ( const NSString * ) commandName args : ( const NSArray * ) args \n + { \n + if ( [ commandName isEqualToString : @ "" setNativeSelectedIndex "" ] & & [ args objectAtIndex : 0 ] ) { \n + NSNumber * selectedIndex = [ args objectAtIndex : 0 ] ; \n + if ( _ selectedIndex ! = selectedIndex . integerValue ) { \n + [ self setSelectedIndex ] ; \n + } \n + } else { \n + RCTLogWarn ( @ "" Attempting to send unknown command to Picker component : % @ "" , commandName ) ; \n + } \n + } \n + \n + - ( void ) setSelectedIndex \n + { \n + BOOL animated = _ selectedIndex ! = NSNotFound ; / / Don ' t animate the initial value . \n + [ _ pickerView selectRow : _ selectedIndex inComponent : 0 animated : animated ] ; \n + } \n + \n - ( NSInteger ) numberOfComponentsInPickerView : ( _ _ unused UIPickerView * ) pickerView \n",Fabric Picker Native Command support \n Summary : \n This adds support for a controlled ` < Picker / > ` component . \n Changelog : [ iOS ] [ Fabric ] Fabric Picker support \n Reviewed By : sammy - SC \n Differential Revision : D24005475 \n fbshipit - source - id : c50e9918f74f6ef5cdfbfe67cb6c132c12d64916,398
"React \ Fabric \ Mounting \ ComponentViews \ Picker \ RCTPickerComponentView . mm \n + # import < react / renderer / components / iospicker / PickerEventEmitter . h > \n - / / TODO ( T75217510 ) - Handle and test onChange , something like : \n - / / [ _ pickerView addTarget : self action : @ selector ( onChange : ) forControlEvents : UIControlEventValueChanged ] ; \n - - ( void ) onChange : ( UISwitch * ) sender \n - { \n - / / TODO ( T75217510 ) - Handle and test onChange \n - } \n - \n - ; \n - ( CGFloat ) pickerView : ( _ _ unused UIPickerView * ) pickerView rowHeightForComponent : ( NSInteger ) _ _ unused component \n - / / TODO ( T75217510 ) - Handle and test onChange \n + PickerEventEmitter : : PickerIOSChangeEvent event = { . newValue = _ items [ row ] . value , . newIndex = ( int ) row } ; \n + if ( _ eventEmitter ) { \n + std : : static _ pointer _ cast < PickerEventEmitter const > ( _ eventEmitter ) - > onChange ( event ) ; \n + } \n new file \n ReactCommon \ react \ renderer \ components \ picker \ iospicker \ PickerEventEmitter . cpp \n + / * \n + * Copyright ( c ) Facebook , Inc . and its affiliates . \n + * \n + * This source code is licensed under the MIT license found in the \n + * LICENSE file in the root directory of this source tree . \n + * / \n + \n + # include "" PickerEventEmitter . h "" \n + \n + namespace facebook { \n + namespace react { \n + \n + void PickerEventEmitter : : onChange ( PickerIOSChangeEvent event ) const { \n + dispatchEvent ( "" change "" , [ event = std : : move ( event ) ] ( jsi : : Runtime & runtime ) { \n + auto payload = jsi : : Object ( runtime ) ; \n + payload . setProperty ( runtime , "" newValue "" , event . newValue ) ; \n + payload . setProperty ( runtime , "" newIndex "" , event . newIndex ) ; \n + return payload ; \n + } ) ; \n + } \n + \n + } / / namespace react \n + } / / namespace facebook \n ReactCommon \ react \ renderer \ components \ picker \ iospicker \ PickerEventEmitter . h \n + \n + struct PickerIOSChangeEvent { \n + std : : string newValue ; \n + int newIndex ; \n + } ; \n + \n + void onChange ( PickerIOSChangeEvent event ) const ; \n",Fabric Picker onChange event \n Summary : \n Implements ` onChange ` prop for ` < Picker / > ` . \n Changelog : [ iOS ] [ Fabric ] Fabric Picker support \n Reviewed By : sammy - SC \n Differential Revision : D23975689 \n fbshipit - source - id : 7aa81c203d420a8971e4309911a41ecfd377a318,398
"React \ Fabric \ Mounting \ ComponentViews \ Picker \ RCTPickerComponentView . mm \n - / / TODO ( T75217510 ) - This should be something like RCTUIColorFromSharedColor ( _ items [ row ] . textColor ) ? : _ textColor ; \n - label . textColor = [ UIColor blackColor ] ; \n + label . textColor = RCTUIColorFromSharedColor ( _ items [ row ] . textColor ) ? : _ textColor ; \n ReactCommon \ react \ renderer \ components \ picker \ iospicker \ conversions . h \n - auto array = ( folly : : dynamic ) value ; \n - for ( auto itr = array . begin ( ) ; itr ! = array . end ( ) ; + + itr ) { \n - / / TODO ( T75217510 ) - Use the itr to create the item instead of using these \n - / / dummy values . \n - struct PickerItemsStruct item = { \n - . label = "" LOL "" , . value = "" LOL2 "" , . textColor = 0 } ; \n + assert ( value . hasType < std : : vector < RawValue > > ( ) ) ; \n + auto array = ( std : : vector < RawValue > ) value ; \n + items . reserve ( array . size ( ) ) ; \n + \n + for ( auto const & val : array ) { \n + bool check = val . hasType < better : : map < std : : string , RawValue > > ( ) ; \n + assert ( check ) ; \n + auto map = ( better : : map < std : : string , RawValue > ) val ; \n + PickerItemsStruct item ; \n + \n + if ( map . find ( "" label "" ) ! = map . end ( ) ) { \n + assert ( map . at ( "" label "" ) . hasType < std : : string > ( ) ) ; \n + item . label = ( std : : string ) map . at ( "" label "" ) ; \n + } \n + if ( map . find ( "" value "" ) ! = map . end ( ) ) { \n + assert ( map . at ( "" value "" ) . hasType < std : : string > ( ) ) ; \n + item . value = ( std : : string ) map . at ( "" value "" ) ; \n + } \n + if ( map . find ( "" textColor "" ) ! = map . end ( ) ) { \n + assert ( map . at ( "" textColor "" ) . hasType < int > ( ) ) ; \n + item . textColor = ( int ) map . at ( "" textColor "" ) ; \n + } \n",Fabric picker item parsing \n Summary : \n This builds on previous diff to properly parse ` < Picker . Item / > ` into a cpp struct . \n This fixes the dummy text and text color TODOs . \n Changelog : [ iOS ] [ Fabric ] Fabric Picker support \n Reviewed By : sammy - SC \n Differential Revision : D23964557 \n fbshipit - source - id : f42c6c9cf410bfc5e66ff078645b6378548481de,398
React \ CoreModules \ RCTEventDispatcher . mm \n - } else { \n + } else if ( _ invokeJS ) { \n - } else { \n + } else if ( _ invokeJS ) { \n - } else { \n + } else if ( _ invokeJSWithModuleDotMethod ) { \n,"Fix crash in RCTEventEmitter \n Summary : \n According to the crash , RCTEventEmitter is being asked to emit events before RN is set up { emoji : 1f928 } . Neither the bridge , nor bridgeless mode is ready to send events . \n In this scenario , drop the events on the floor instead of crashing . \n Changelog : [ Internal ] \n Reviewed By : naftaly \n Differential Revision : D24634701 \n fbshipit - source - id : 933e5dfd15e5ee7c2215489305c71de46e78a9e5",398
"React \ Base \ RCTPerformanceLogger . h \n + RCTPLReactInstanceInit , \n React \ Base \ RCTPerformanceLogger . m \n + @ "" ReactInstanceInit "" , \n ReactCommon \ cxxreact \ ReactMarker . h \n - REGISTER _ JS _ SEGMENT _ STOP \n + REGISTER _ JS _ SEGMENT _ STOP , \n + REACT _ INSTANCE _ INIT _ START , \n + REACT _ INSTANCE _ INIT _ STOP \n",Add new ReactMarkers for bridgeless mode [ 1 / n ] \n Summary : \n These are new markers that will be placed around initializing an RCTInstance . \n Changelog : [ Internal ] \n Reviewed By : sammy - SC \n Differential Revision : D24607905 \n fbshipit - source - id : 8e83a2476e2ae878c523217aeb5a3b4bfc5bf911,398
"ReactCommon \ react \ nativemodule \ core \ platform \ ios \ RCTTurboModuleManager . mm \n - ( id < RCTTurboModule > ) provideRCTTurboModule : ( const char * ) moduleName \n + if ( strncmp ( "" RCT "" , moduleName , 3 ) = = 0 ) { \n + moduleName = [ [ [ NSString stringWithUTF8String : moduleName ] substringFromIndex : 3 ] UTF8String ] ; \n + } \n + \n","Strip RCT prefix in TurbooduleManager \n Summary : \n This is a followup to the issue described in D25477044 , basically the TM cache can get messed up if ` TurboModuleManager ` is asked for "" RCTNetworking "" vs "" Networking "" . This solves that issue globally . \n Changelog : [ Internal ] \n Reviewed By : RSNara \n Differential Revision : D25480624 \n fbshipit - source - id : 2024560eadbcf58cdc3d7d5675b4120aa2fa2582",398
"Libraries \ Blob \ RCTBlobManager . mm \n - RCTNetworking * const networking = _ bridge ? _ bridge . networking : [ _ turboModuleRegistry moduleForName : "" RCTNetworking "" ] ; \n + RCTNetworking * const networking = _ bridge ? _ bridge . networking : [ _ turboModuleRegistry moduleForName : "" Networking "" ] ; \n Libraries \ Image \ RCTImageLoader . mm \n - & & ! [ _ turboModuleRegistry moduleForName : "" RCTNetworking "" ] ) { \n + & & ! [ _ turboModuleRegistry moduleForName : "" Networking "" ] ) { \n - networking = [ _ turboModuleRegistry moduleForName : "" RCTNetworking "" ] ; \n + networking = [ _ turboModuleRegistry moduleForName : "" Networking "" ] ; \n","Fix duplicate Networking module bug \n Summary : \n While investigating a bridgeless networking issue , I noticed something very peculiar . * * Two * * networking turbo modules are built and used in bridgeless mode . Upon debugging , I realized that each of them have a different ` TurboModuleHolder ` . The reason is the following : \n 1 . In JS , the module ' s name is [ Networking ] ( https : / / fburl . com / diffusion / f2xu4wie ) \n 2 . In ObjC , we call the module "" RCTNetworking "" ( examples in this diff ) \n 3 . Both scenarios end up creating the correct Turbo Module : [ RCTNetworking ] ( https : / / www . internalfb . com / intern / diffusion / FBS / browsefile / master / xplat / js / react - native - github / Libraries / Network / RCTNetworking . mm ? link _ ref = search ) , but the ` TurboModuleHolder ` doesn ' t know that "" RCTNetworking "" and "" Networking "" are the same . Any other modules accessed this way will have the same issue . \n An alternative solution would be to tell ` TurboModuleHolder ` to strip the ` RCT ` suffix , which would solve the problem globally . RSNara thoughts ? \n Changelog : [ Internal ] \n Reviewed By : RSNara \n Differential Revision : D25477044 \n fbshipit - source - id : 02219de578ef4d19e579110e4242883a30cefcd6",398
"React \ Fabric \ Surface \ RCTFabricSurface . h \n - ( BOOL ) start ; \n - ( BOOL ) stop ; \n + / * * \n + * EXPERIMENTAL \n + * Reset ' s the Surface to it ' s initial stage . \n + * It uses the passed in surface presenter , and whatever else was passed in init . \n + * / \n + - ( void ) resetWithSurfacePresenter : ( RCTSurfacePresenter * ) surfacePresenter ; \n + \n React \ Fabric \ Surface \ RCTFabricSurface . mm \n + - ( void ) resetWithSurfacePresenter : ( RCTSurfacePresenter * ) surfacePresenter \n + { \n + _ surfacePresenter = surfacePresenter ; \n + _ stage = RCTSurfaceStageSurfaceDidInitialize ; \n + _ view = nil ; \n + } \n + \n - ( BOOL ) start \n","Add reset method to RCTFabricSurface [ 2 / N ] \n Summary : \n This method allows a surface to re - render from scratch , without having to delete and reinstantiate the surface . \n Changelog : [ iOS ] Added reset method to RCTFabricSurface to help with reloads \n Reviewed By : RSNara \n Differential Revision : D25000509 \n fbshipit - source - id : f74170aa78cc84491ad2679f130ed3c8965bbe34",398
"ReactCommon \ react \ renderer \ components \ legacyviewmanagerinterop \ RCTLegacyViewManagerInteropCoordinator . mm \n - InterceptorBlock block = [ strongSelf - > _ eventInterceptors objectForKey : reactTag ] ; \n - if ( block ) { \n - block ( std : : string ( [ RCTNormalizeInputEventName ( eventName ) UTF8String ] ) , convertIdToFollyDynamic ( event ? : @ { } ) ) ; \n + if ( strongSelf ) { \n + InterceptorBlock block = [ strongSelf - > _ eventInterceptors objectForKey : reactTag ] ; \n + if ( block ) { \n + block ( std : : string ( [ RCTNormalizeInputEventName ( eventName ) UTF8String ] ) , convertIdToFollyDynamic ( event ? : @ { } ) ) ; \n + } \n","Fix crash in RCTLegacyViewManagerInteropCoordinator \n Summary : \n Like the task mentions ` strongSelf - > _ eventInterceptors ` was crashing , probably because the coordinator was cleaned up before this block ran . \n Check to make sure self is still valid before attempting to access any instance variables . \n Changelog : [ Internal ] \n Reviewed By : fkgozali \n Differential Revision : D25073812 \n fbshipit - source - id : cdf666f2ac028b5523097f15ff51fbae9f9ffbd8",398
"React \ CoreModules \ RCTDeviceInfo . mm \n + @ synthesize turboModuleRegistry = _ turboModuleRegistry ; \n - _ currentInterfaceDimensions = RCTExportedDimensions ( _ bridge ) ; \n + _ currentInterfaceDimensions = RCTExportedDimensions ( _ bridge , _ turboModuleRegistry ) ; \n - static NSDictionary * RCTExportedDimensions ( RCTBridge * bridge ) \n + static NSDictionary * RCTExportedDimensions ( RCTBridge * bridge , id < RCTTurboModuleRegistry > turboModuleRegistry ) \n - RCTAssert ( bridge , @ "" Bridge must not be ` nil ` . "" ) ; \n - RCTDimensions dimensions = RCTGetDimensions ( bridge . accessibilityManager . multiplier ? : 1 . 0 ) ; \n + RCTDimensions dimensions ; \n + if ( bridge ) { \n + dimensions = RCTGetDimensions ( bridge . accessibilityManager . multiplier ? : 1 . 0 ) ; \n + } else if ( turboModuleRegistry ) { \n + dimensions = RCTGetDimensions ( \n + ( ( RCTAccessibilityManager * ) [ turboModuleRegistry moduleForName : "" RCTAccessibilityManager "" ] ) . multiplier ? : 1 . 0 ) ; \n + } else { \n + RCTAssert ( false , @ "" Bridge or TurboModuleRegistry must be set to properly init dimensions . "" ) ; \n + } \n - @ "" Dimensions "" : RCTExportedDimensions ( self - > _ bridge ) , \n + @ "" Dimensions "" : RCTExportedDimensions ( self - > _ bridge , self - > _ turboModuleRegistry ) , \n - [ bridge . eventDispatcher sendDeviceEventWithName : @ "" didUpdateDimensions "" body : RCTExportedDimensions ( bridge ) ] ; \n + [ bridge . eventDispatcher sendDeviceEventWithName : @ "" didUpdateDimensions "" \n + body : RCTExportedDimensions ( bridge , self - > _ turboModuleRegistry ) ] ; \n - [ _ bridge . eventDispatcher sendDeviceEventWithName : @ "" didUpdateDimensions "" body : RCTExportedDimensions ( _ bridge ) ] ; \n + [ _ bridge . eventDispatcher sendDeviceEventWithName : @ "" didUpdateDimensions "" \n + body : RCTExportedDimensions ( _ bridge , _ turboModuleRegistry ) ] ; \n - ( void ) _ interfaceFrameDidChange \n - NSDictionary * nextInterfaceDimensions = RCTExportedDimensions ( _ bridge ) ; \n + NSDictionary * nextInterfaceDimensions = RCTExportedDimensions ( _ bridge , _ turboModuleRegistry ) ; \n","Fix new RCTDeviceInfo assert to work in bridgeless mode \n Summary : \n shergin added a new assert to dimensions calculations in D24038911 ( https : / / github . com / facebook / react - native / commit / e85372298109abf258d5154e2a28bc6496fb9529 ) . This crashes in bridgeless mode b / c no bridge . \n This diff uses ` turboModuleRegistry ` as a bridge workaround . The registry is a [ weak property ] ( https : / / www . fburl . com / diffusion / sunv3bx9 ) so retain cycles shouldn ' t be an issue here , let me know if that ' s incorrect . \n As a nice bonus , this fixes dynamic font sizing in bridgeless mode . It was broken before since it relied on the bridge . \n Changelog : [ Internal ] \n Reviewed By : ejanzer \n Differential Revision : D24256338 \n fbshipit - source - id : 141d36239ac6a6e9e87ca96eea7aeec56729095d",398
"ReactCommon \ react \ nativemodule \ core \ platform \ ios \ RCTTurboModule . mm \n - throw std : : runtime _ error ( "" Tried to resolve a promise more than once . "" ) ; \n + RCTLogWarn ( @ "" Tried to resolve a promise more than once . "" ) ; \n + return ; \n","Downgrade TurboModule crash to warning \n Summary : \n This is to address a UBN blocking FBiOSv300 rollout . A TM is attempting to invoke a promise more than once and crashing . We can ' t find the TM , so downgrading this to a warning to unblock the release . \n Plan going forward : \n - Replace this with some better logging to try and identify the culprit module . \n Changelog : [ Internal ] \n Reviewed By : RSNara \n Differential Revision : D25539676 \n fbshipit - source - id : 5b75b71110eaa393378049de6e0d9a77e6328831",398
"tools \ build _ defs \ oss \ rn _ defs . bzl \n - kwargs . setdefault ( "" target _ sdk _ version "" , "" 10 . 0 "" ) \n + kwargs . setdefault ( "" target _ sdk _ version "" , "" 11 . 0 "" ) \n",Make rn _ xplat _ cxx _ library and rn _ apple _ library target iOS 11 \n Summary : \n This forces individual RN libraries to target SDK 11 + \n Changelog : [ iOS ] Make rn _ xplat _ cxx _ library and rn _ apple _ library target iOS 11 \n Reviewed By : shergin \n Differential Revision : D26179411 \n fbshipit - source - id : 898201943164ff8e53924eee5ca877103bf0f62a,398
"README . md \n - React Native apps may target iOS 10 . 0 and Android 4 . 1 ( API 16 ) or newer . You may use Windows , macOS , or Linux as your development operating system , though building and running iOS apps is limited to macOS . Tools like [ Expo ] ( https : / / expo . io ) can be used to work around this . \n + React Native apps may target iOS 11 . 0 and Android 5 . 0 ( API 21 ) or newer . You may use Windows , macOS , or Linux as your development operating system , though building and running iOS apps is limited to macOS . Tools like [ Expo ] ( https : / / expo . io ) can be used to work around this . \n",Bump min supported iOS / Android version to 11 / 19 \n Summary : Changelog : [ iOS ] [ Android ] Bumped min supported iOS / Android version in README to reflect reality \n Reviewed By : fkgozali \n Differential Revision : D25917083 \n fbshipit - source - id : 2061b25a8b47f9ebedb922b85fe3edd3646338f2,398
Libraries \ Network \ RCTNetworking . mm \n + + ( BOOL ) requiresMainQueueSetup \n + { \n + return YES ; \n + } \n + \n - ( instancetype ) init \n,"Fix RCTNetworking yellow box \n Summary : \n Since ` RCTNetworking ` overrides init , it requires main queue setup . Native module infra currently throw a yellowbox if a module forgets it . \n This diff fixes that . \n { F361182429 } \n Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D25962402 \n fbshipit - source - id : d847117cbfe0a191dc1882898711693c6fda68cd",398
"React \ CoreModules \ RCTDevMenu . mm \n - ( void ) showOnShake \n - [ self show ] ; \n + for ( UIWindow * window in [ RCTSharedApplication ( ) windows ] ) { \n + NSString * recursiveDescription = [ window valueForKey : @ "" recursiveDescription "" ] ; \n + if ( [ recursiveDescription containsString : @ "" RCTView "" ] ) { \n + [ self show ] ; \n + return ; \n + } \n + } \n",Only show DevMenu on shake if RCTView is visible \n Summary : Changelog : [ iOS ] Only show Dev Menu on shake if RN view is visible \n Reviewed By : fkgozali \n Differential Revision : D26138659 \n fbshipit - source - id : e2db287728675c7ead5fcbf569ed591638e2187e,398
"React \ CoreModules \ RCTDevSettings . mm \n + [ [ NSNotificationCenter defaultCenter ] addObserver : self \n + selector : @ selector ( jsLoaded : ) \n + name : @ "" RCTInstanceDidLoadBundle "" \n + object : nil ] ; \n - [ self . bridge enqueueJSCall : @ "" HMRClient "" method : @ "" enable "" args : @ [ ] completion : NULL ] ; \n + if ( self . bridge ) { \n + [ self . bridge enqueueJSCall : @ "" HMRClient "" method : @ "" enable "" args : @ [ ] completion : NULL ] ; \n + } else if ( self . invokeJS ) { \n + self . invokeJS ( @ "" HMRClient "" , @ "" enable "" , @ [ ] ) ; \n + } \n - [ self . bridge enqueueJSCall : @ "" HMRClient "" method : @ "" disable "" args : @ [ ] completion : NULL ] ; \n + if ( self . bridge ) { \n + [ self . bridge enqueueJSCall : @ "" HMRClient "" method : @ "" disable "" args : @ [ ] completion : NULL ] ; \n + } else if ( self . invokeJS ) { \n + self . invokeJS ( @ "" HMRClient "" , @ "" disable "" , @ [ ] ) ; \n + } \n - ( void ) jsLoaded : ( NSNotification * ) notification \n - if ( notification . userInfo [ @ "" bridge "" ] ! = self . bridge ) { \n + / / In bridge mode , the bridge that sent the notif must be the same as the one stored in this module . \n + / / In bridgless mode , we don ' t care about this . \n + if ( [ notification . name isEqualToString : RCTJavaScriptDidLoadNotification ] & & \n + notification . userInfo [ @ "" bridge "" ] ! = self . bridge ) { \n",Fix fast refresh settings in RN Dev Menu \n Summary : \n Changelog : [ Internal ] \n This moves enabling / disabling fast refresh off of ` bridge . enqueueJSCall ` in bridgeless mode . \n Reviewed By : sammy - SC \n Differential Revision : D26290378 \n fbshipit - source - id : ed8a3389b9812cedf7181971656dacd98ff7ecfd,398
"React \ CoreModules \ RCTDevSettings . mm \n + # import < React / RCTBundleHolderModule . h > \n + # import < React / RCTDevMenu . h > \n - # import < React / RCTDevMenu . h > \n - \n - @ interface RCTDevSettings ( ) < RCTBridgeModule , RCTInvalidating , NativeDevSettingsSpec > { \n + @ interface RCTDevSettings ( ) < RCTBridgeModule , RCTInvalidating , NativeDevSettingsSpec , RCTBundleHolderModule > { \n + @ synthesize bundleURL = _ bundleURL ; \n + \n - ( instancetype ) init \n - ( BOOL ) isHotLoadingAvailable \n - return self . bridge . bundleURL & & ! self . bridge . bundleURL . fileURL ; / / Only works when running from server \n + if ( self . bridge . bundleURL ) { \n + return ! self . bridge . bundleURL . fileURL ; / / Only works when running from server \n + } else if ( self . bundleURL ) { \n + return ! self . bundleURL . fileURL ; \n + } \n + return NO ; \n",Make RCTDevSettings conform to RCTBundleHolderModule \n Summary : \n Changelog : [ Internal ] \n This diff allows ` RCTDevSettings ` to access bundleURL directly instead of relying on the bridge . \n Reviewed By : RSNara \n Differential Revision : D26289592 \n fbshipit - source - id : e22e583e51323bfe66f6e424d9f47edf71b1ed9f,398
"new file \n React \ Base \ RCTBundleHolderModule . h \n + / * \n + * Copyright ( c ) Facebook , Inc . and its affiliates . \n + * \n + * This source code is licensed under the MIT license found in the \n + * LICENSE file in the root directory of this source tree . \n + * / \n + \n + / * * \n + * This protocol should be adopted when a turbo module needs to access the currently loaded JS bundle URL . \n + * In bridge - less React Native , it is a replacement for bridge . bundleURL . \n + * / \n + @ protocol RCTBundleHolderModule \n + \n + @ property ( nonatomic , strong , readwrite ) NSURL * bundleURL ; \n + \n + @ end \n","Introducting RCTBundleHolderModule ( name pending ) \n Summary : \n Changelog : [ Internal ] \n Problem : \n The Bridge holds and exposes the bundle URL for native modules to inspect via ` bridge . bundleURL ` . \n Solution : \n This follows the same pattern we ' ve been using for attaching objects to native modules : declare a protocol with the required object , attach that object during module init . \n Differential Revision : D26289581 \n fbshipit - source - id : 35ae83912e392be84f55c8d056c8da15ba75060f",398
Libraries \ Core \ setUpDeveloperTools . js \n - / / TODO ( T45803484 ) Enable devtools for bridgeless RN \n - if ( ! global . RN $ Bridgeless ) { \n + / / TODO ( T45803484 ) Enable devtools for bridgeless RN Android . \n + if ( ! global . RN $ Bridgeless | | Platform . OS = = = ' ios ' ) { \n,"Enable dev tools setup in bridgeless mode \n Summary : \n Changelog : [ Internal ] \n I ' m trying to get Fast refresh working in bridgeless mode . I need the ` require ( ' . / setUpReactRefresh ' ) ; ` line to be executed to do so . \n I ' m not sure why this was commented out in the first place , it seems to be working fine in FBiOS / FB4A . \n Reviewed By : p - sun \n Differential Revision : D26289573 \n fbshipit - source - id : 6151f781c31e3aadaebfeb759d3eb776e8b525cc",398
"React \ CoreModules \ RCTDevSettings . mm \n + # if RCT _ ENABLE _ INSPECTOR \n + / / In bridgeless mode , ` setBridge ` is not called , so dev server connection \n + / / must be kicked off here . \n + - ( void ) setBundleURL : ( NSURL * ) bundleURL \n + { \n + _ bundleURL = bundleURL ; \n + [ RCTInspectorDevServerHelper connectWithBundleURL : _ bundleURL ] ; \n + } \n + # endif \n + \n - ( void ) setBridge : ( RCTBridge * ) bridge \n",Connect to RCTInspectorDevServerHelper in bridgeless mode \n Summary : Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D26623985 \n fbshipit - source - id : 98aff018adc0e9aca517d8faebd20fe98e9b708b,398
React \ CoreModules \ RCTDevLoadingView . mm \n - # import < React / RCTModalHostViewController . h > \n + - ( instancetype ) init \n + { \n + if ( self = [ super init ] ) { \n + [ [ NSNotificationCenter defaultCenter ] addObserver : self \n + selector : @ selector ( hide ) \n + name : RCTJavaScriptDidLoadNotification \n + object : nil ] ; \n + [ [ NSNotificationCenter defaultCenter ] addObserver : self \n + selector : @ selector ( hide ) \n + name : RCTJavaScriptDidFailToLoadNotification \n + object : nil ] ; \n + } \n + return self ; \n + } \n + \n + ( void ) setEnabled : ( BOOL ) enabled \n - [ [ NSNotificationCenter defaultCenter ] addObserver : self \n - selector : @ selector ( hide ) \n - name : RCTJavaScriptDidLoadNotification \n - object : nil ] ; \n - [ [ NSNotificationCenter defaultCenter ] addObserver : self \n - selector : @ selector ( hide ) \n - name : RCTJavaScriptDidFailToLoadNotification \n - object : nil ] ; \n - \n,"Refactor notification subscriptions in RCTDevLoadingView \n Summary : \n In bridegless mode , ` setBridge ` is never called on native modules . This diff refactors out some setup logic into the module ' s init method . \n Changelog : [ Internal ] \n Reviewed By : RSNara \n Differential Revision : D26211620 \n fbshipit - source - id : 7a9910198852dea5ac679762aa93dfea6fc47d70",398
"React \ CoreModules \ RCTDevMenu . mm \n + # import < React / RCTJSInvokerModule . h > \n - @ interface RCTDevMenu ( ) < RCTBridgeModule , RCTInvalidating , NativeDevMenuSpec > \n + @ interface RCTDevMenu ( ) < RCTBridgeModule , RCTInvalidating , NativeDevMenuSpec , RCTJSInvokerModule > \n + @ synthesize invokeJS = _ invokeJS ; \n - if ( _ actionSheet | | ! _ bridge | | RCTRunningInAppExtension ( ) ) { \n + if ( _ actionSheet | | RCTRunningInAppExtension ( ) ) { \n - [ _ bridge enqueueJSCall : @ "" RCTNativeAppEventEmitter "" method : @ "" emit "" args : @ [ @ "" RCTDevMenuShown "" ] completion : NULL ] ; \n + if ( _ bridge ) { \n + [ _ bridge enqueueJSCall : @ "" RCTNativeAppEventEmitter "" method : @ "" emit "" args : @ [ @ "" RCTDevMenuShown "" ] completion : NULL ] ; \n + } else { \n + _ invokeJS ( @ "" RCTNativeAppEventEmitter "" , @ "" emit "" , @ [ @ "" RCTDevMenuShown "" ] ) ; \n + } \n - ( RCTDevMenuAlertActionHandler ) alertActionHandlerForDevItem : ( RCTDevMenuItem * _ _ nullable ) item \n","Basic bridgeless support for RCTDevMenu \n Summary : \n Changelog : [ Internal ] \n This removes a couple dependencies on bridge in dev menu native module . So far reloading works , will get inspector and other options working in follow ups . \n Reviewed By : sammy - SC \n Differential Revision : D26240391 \n fbshipit - source - id : 7c9d585f4efa6cc9db995ef8a33865831bc8d526",398
"React \ CoreModules \ RCTDevMenu . mm \n - if ( devSettings . isLiveReloadAvailable ) { \n - [ items addObject : [ RCTDevMenuItem \n - buttonItemWithTitleBlock : ^ NSString * { \n - return devSettings . isDebuggingRemotely ? @ "" Systrace Unavailable "" \n - : devSettings . isProfilingEnabled ? @ "" Stop Systrace "" \n - : @ "" Start Systrace "" ; \n - } \n - handler : ^ { \n - if ( devSettings . isDebuggingRemotely ) { \n - UIAlertController * alertController = \n - [ UIAlertController alertControllerWithTitle : @ "" Systrace Unavailable "" \n - message : @ "" Stop debugging to enable Systrace . "" \n - preferredStyle : UIAlertControllerStyleAlert ] ; \n - _ _ weak _ _ typeof _ _ ( alertController ) weakAlertController = alertController ; \n - [ alertController \n - addAction : [ UIAlertAction actionWithTitle : @ "" OK "" \n - style : UIAlertActionStyleDefault \n - handler : ^ ( _ _ unused UIAlertAction * action ) { \n - [ weakAlertController \n - dismissViewControllerAnimated : YES \n - completion : nil ] ; \n - } ] ] ; \n - [ RCTPresentedViewController ( ) presentViewController : alertController \n - animated : YES \n - completion : NULL ] ; \n - } else { \n - devSettings . isProfilingEnabled = ! devSettings . isProfilingEnabled ; \n - } \n - } ] ] ; \n - / / "" Live reload "" which refreshes on every edit was removed in favor of "" Fast Refresh "" . \n - / / While native code for "" Live reload "" is still there , please don ' t add the option back . \n - / / See D15958697 for more context . \n - } \n - \n React \ CoreModules \ RCTDevSettings . h \n - ( instancetype ) initWithDataSource : ( id < RCTDevSettingsDataSource > ) dataSource ; \n - @ property ( nonatomic , readonly ) BOOL isLiveReloadAvailable ; \n","Cleanup - remove isLiveReloadAvailable \n Summary : \n Live reload was removed as a user facing feature in 2019 in favour of fast refresh . The native code was left in case "" automation "" relied on it . I ' m quite sure no automation is using this dev feature . Remember , the dev feature made it so that hitting save in a text editor auto reloaded in metro . \n Cleanup the native implementation . \n Changelog : [ Internal ] \n Reviewed By : sammy - SC \n Differential Revision : D26239628 \n fbshipit - source - id : 7f61c7204727bb2d739600a459f69c72842265c5",398
React \ CoreModules \ RCTDevMenu . mm \n - \n - / / Reset the old debugger setting so no one gets stuck . \n - / / TODO : Remove in a few weeks . \n - if ( devSettings . isDebuggingRemotely ) { \n - devSettings . isDebuggingRemotely = false ; \n - } \n,Cleanup - remove isDebuggingRemotely failsafe \n Summary : \n IIUC ` isDebuggingRemotely ` will never be set when ` isDeviceDebuggingAvailable ` is true . This was just a failsafe so that noone was trapped in an intermediate state . \n Changelog : [ Internal ] \n Reviewed By : sammy - SC \n Differential Revision : D26239570 \n fbshipit - source - id : 8db6b022a0ea581216a1fa97b9d41f5ab6160562,398
"ReactCommon \ jsi \ BUCK \n - # TODO ( T55502220 ) : Remove when iOS 9 . 0 deprecation is complete everywhere . \n - fbobjc _ target _ sdk _ version = "" 9 . 0 "" , \n","Delete iOS9 BUCK workarounds \n Summary : \n Changelog : [ Internal ] \n According to D19411886 ( https : / / github . com / facebook / react - native / commit / 30491a208513451efa6c2a62a116c61b21363a22 ) , there were some deps that required a couple targets to stay at iOS9 : \n - ` / / fbobjc / Libraries / FBGraphQLQuery : FBGraphQLQuery - - > / / xplat / js / react - native - github : RCTCxxUtilsApple ` \n - ` / / fbobjc / Libraries / NativeTemplateKit : NativeTemplateKitJSExecutorPlugin - - > / / xplat / js / react - native - github / ReactCommon / jsi : JSCRuntimeApple ` \n These targets seem to build after this diff , so I guess they ' ve been pushed past iOS9 . \n Reviewed By : fkgozali \n Differential Revision : D25692640 \n fbshipit - source - id : 1ce94a452090032ef316a3daa79885a7c58d6eac",398
packages \ rn - tester \ RNTesterPods . xcodeproj \ project . pbxproj \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n template \ ios \ HelloWorld . xcodeproj \ project . pbxproj \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n - IPHONEOS _ DEPLOYMENT _ TARGET = 10 . 0 ; \n + IPHONEOS _ DEPLOYMENT _ TARGET = 11 . 0 ; \n,iOS / tvOS 10 . 0 = = > 11 . 0 in . xcodeproj \n Summary : \n Changelog : [ iOS ] Remove iOS10 / tvOS10 suppport \n Similar to D19269953 ( https : / / github . com / facebook / react - native / commit / 829a2237d270c03c80467eb6c2b5b18c87135a45 ) for iOS9 deprecation \n Reviewed By : fkgozali \n Differential Revision : D25805856 \n fbshipit - source - id : 328f426a492c563b1632223be2b48c8d3ca04756,398
React \ Fabric \ Surface \ RCTFabricSurface . mm \n - ( void ) resetWithSurfacePresenter : ( RCTSurfacePresenter * ) surfacePresenter \n - _ surfacePresenter = surfacePresenter ; \n + _ surfacePresenter = surfacePresenter ; \n + [ _ surfacePresenter registerSurface : self ] ; \n - ( void ) dealloc \n,Fix CMD + R reloading in bridgeless mode \n Summary : Changelog : [ Internal ] \n Reviewed By : shergin \n Differential Revision : D26412253 \n fbshipit - source - id : 6be41120f598bbac841a6b42fafe3bb47e3f8a46,398
"packages \ Shell \ tests \ src \ com \ android \ shell \ BugreportReceiverTest . java \n - intent . setPackage ( "" com . android . shell "" ) ; \n - intent . setFlags ( Intent . FLAG _ RECEIVER _ FOREGROUND ) ; \n - mContext . sendBroadcast ( intent ) ; \n + / / Ideally , we should invoke BugreportRequestedReceiver by sending \n + / / INTENT _ BUGREPORT _ REQUESTED . But the intent has been protected broadcast by the system \n + / / starting from S . \n + new BugreportRequestedReceiver ( ) . onReceive ( mContext , intent ) ; \n","Fixes BugreportReceiverTest failed \n Instead of sending INTENT _ BUGREPORT _ REQUESTED , invoke \n BugreportRequestedReceiver instance directly . \n Bug : 174832302 \n Bug : 175287931 \n Test : atest BugreportReceiverTest \n Change - Id : I99a052d74b71d503a655a769064a74246da150e5 \n Merged - In : I99a052d74b71d503a655a769064a74246da150e5",417
core \ api \ current . txt \n - field public static final int GET _ INTENT _ FILTERS = 32 ; / / 0x20 \n + field @ Deprecated public static final int GET _ INTENT _ FILTERS = 32 ; / / 0x20 \n core \ java \ android \ content \ pm \ PackageManager . java \n + * \n + * @ deprecated The platform does not support getting { @ link IntentFilter } s for the package . \n + @ Deprecated \n,Deprecates GET _ INTENT _ FILTERS in the PackageManager \n This constant has never been used . The platform does not support \n getting intent filters for the package . \n Bug : 73780749 \n Bug : 171597154 \n Test : Build \n Change - Id : I907077b2a07e4a88aa8994ed3c25991b6d1172b4 \n Merged - In : I907077b2a07e4a88aa8994ed3c25991b6d1172b4,417
"packages \ Shell \ src \ com \ android \ shell \ BugreportProgressService . java \n + if ( mInfo . bugreportFile . length ( ) = = 0 ) { \n + Log . e ( TAG , "" Bugreport file empty . File path = "" + mInfo . bugreportFile ) ; \n + onError ( BUGREPORT _ ERROR _ RUNTIME ) ; \n + return ; \n + } \n - if ( mInfo . bugreportFile . length ( ) = = 0 ) { \n - Log . e ( TAG , "" Bugreport file empty . File path = "" + bugreportFilePath ) ; \n - return ; \n - } \n packages \ Shell \ tests \ src \ com \ android \ shell \ BugreportReceiverTest . java \n + @ Test \n + public void testBugreportFinished _ withEmptyBugreportFile ( ) throws Exception { \n + sendBugreportStarted ( ) ; \n + \n + IoUtils . closeQuietly ( mBugreportFd ) ; \n + mBugreportFd = null ; \n + sendBugreportFinished ( ) ; \n + \n + assertServiceNotRunning ( ) ; \n + } \n + \n - writeZipFile ( mBugreportFd , BUGREPORT _ FILE , BUGREPORT _ CONTENT ) ; \n + if ( mBugreportFd ! = null ) { \n + writeZipFile ( mBugreportFd , BUGREPORT _ FILE , BUGREPORT _ CONTENT ) ; \n + } \n",Fixes an error handling in BugreportProgressService \n Calls onError function when bugreport is finished and file is empty . \n Bug : 174314124 \n Bug : 175287931 \n Test : atest BugreportReceiverTest \n Change - Id : I4542568fd2d2ad1c75c7c3b223accca4995938a3 \n Merged - In : I4542568fd2d2ad1c75c7c3b223accca4995938a3,417
"packages \ Shell \ src \ com \ android \ shell \ BugreportProgressService . java \n + synchronized ( mLock ) { \n + if ( info . bugreportFile . exists ( ) ) { \n + Log . e ( TAG , "" Failed to start bugreport generation , the requested bugreport file "" \n + + info . bugreportFile + "" already exists "" ) ; \n + return ; \n + } \n + info . createBugreportFile ( ) ; \n + } \n + "" bugreport parcel file descriptor is null . "" ) ; \n + info . createScreenshotFile ( mBugreportsDir ) ; \n - createBugreportFile ( bugreportsDir ) ; \n - createScreenshotFile ( bugreportsDir ) ; \n + this . bugreportFile = new File ( bugreportsDir , getFileName ( this , "" . zip "" ) ) ; \n - void createBugreportFile ( File bugreportsDir ) { \n - bugreportFile = new File ( bugreportsDir , getFileName ( this , "" . zip "" ) ) ; \n + void createBugreportFile ( ) { \n packages \ Shell \ tests \ src \ com \ android \ shell \ BugreportReceiverTest . java \n + import static org . mockito . Mockito . times ; \n + @ Test \n + public void testBugreportRequestTwice _ oneStartBugreportInvoked ( ) throws Exception { \n + sendBugreportStarted ( ) ; \n + new BugreportRequestedReceiver ( ) . onReceive ( mContext , \n + new Intent ( INTENT _ BUGREPORT _ REQUESTED ) ) ; \n + getInstrumentation ( ) . waitForIdleSync ( ) ; \n + \n + verify ( mMockIDumpstate , times ( 1 ) ) . startBugreport ( anyInt ( ) , any ( ) , any ( ) , any ( ) , \n + anyInt ( ) , any ( ) , anyBoolean ( ) ) ; \n + sendBugreportFinished ( ) ; \n + } \n + \n","Returns immediately if the bugreport file already exists \n There ' s a case that BugreportProgressService is invoked twice quickly , \n and both services create the same bugreport file name . The later one \n may delete current running bugreport file in its clean function , \n when it detects another bugreport is running . \n Bug : 174314124 \n Bug : 175287931 \n Test : atest BugreportReceiverTest \n Change - Id : I5e1802c5912f4414f1ad3b8bdaf7c7420332b9d6 \n Merged - In : I5e1802c5912f4414f1ad3b8bdaf7c7420332b9d6",417
packages \ Shell \ src \ com \ android \ shell \ BugreportProgressService . java \n + . setOnlyAlertOnce ( false ) \n + . setOnlyAlertOnce ( true ) \n,Do not buzzing for each progress of bugreport notification \n Only alert bugreport notification at the begining and end . \n Bug : 146135200 \n Bug : 175287931 \n Test : Manually changing the notification settings to default \n from silent . \n Change - Id : Ie955266ad8a7a27a9dc74743e276b5e9c7a2d6fb \n Merged - In : Ie955266ad8a7a27a9dc74743e276b5e9c7a2d6fb,417
packages \ Shell \ src \ com \ android \ shell \ BugreportProgressService . java \n + shareTitle = in . readString ( ) ; \n + lastProgress . set ( in . readInt ( ) ) ; \n + addingDetailsToZip = in . readBoolean ( ) ; \n + addedDetailsToZip = in . readBoolean ( ) ; \n - shareTitle = in . readString ( ) ; \n + dest . writeString ( shareTitle ) ; \n + dest . writeInt ( lastProgress . intValue ( ) ) ; \n + dest . writeBoolean ( addingDetailsToZip ) ; \n + dest . writeBoolean ( addedDetailsToZip ) ; \n - dest . writeString ( shareTitle ) ; \n,Fix missing fields when parceling the BugreportInfo \n Shell app exception resulted from two missing fields in BugreportInfo \n when it ' s parceling . Application ran into the duplicate logic to send \n notification and start foreground service then caused the exception . \n Bug : 176624074 \n Test : Request a bugreport ; kill the com . android . shell ; \ \n tap the share notification \n Change - Id : Ia80f5e77f5486addf9ea7822f566c3fd7d75f42a,417
"library \ src \ main \ java \ com \ bumptech \ glide \ Glide . java \n - throw new IllegalStateException ( "" Cannot create cache directory structure for "" + result ) ; \n + / / File wasn ' t able to create a directory , or the result exists but not a directory \n + return null ; \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ engine \ cache \ DiskLruCacheWrapper . java \n + / / TODO calling twice with different arguments makes it return the cache for the same directory , it ' s public ! \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ model \ StreamEncoder . java \n - if ( Log . isLoggable ( TAG , Log . ERROR ) ) { \n - Log . v ( TAG , "" Failed to encode data onto the OutputStream "" , e ) ; \n + if ( Log . isLoggable ( TAG , Log . WARN ) ) { \n + Log . w ( TAG , "" Failed to encode data onto the OutputStream "" , e ) ; \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ gif \ GifFrameManager . java \n + if ( transformation = = null ) { \n + throw new NullPointerException ( "" Transformation must not be null "" ) ; \n + } \n + \n + this . frameResourceDecoder = new GifFrameResourceDecoder ( bitmapPool ) ; \n - calculator = new MemorySizeCalculator ( context ) ; \n - frameLoader = new GifFrameModelLoader ( ) ; \n - frameResourceDecoder = new GifFrameResourceDecoder ( bitmapPool ) ; \n - sourceEncoder = NullEncoder . get ( ) ; \n - if ( transformation = = null ) { \n - throw new NullPointerException ( "" Transformation must not be null "" ) ; \n - } \n + this . calculator = new MemorySizeCalculator ( context ) ; \n + this . frameLoader = new GifFrameModelLoader ( ) ; \n + this . sourceEncoder = NullEncoder . get ( ) ; \n - cacheDecoder = new FileToStreamDecoder < Bitmap > ( new StreamBitmapDecoder ( context ) ) ; \n - encoder = new BitmapEncoder ( ) ; \n + this . cacheDecoder = new FileToStreamDecoder < Bitmap > ( new StreamBitmapDecoder ( context ) ) ; \n + this . encoder = new BitmapEncoder ( ) ; \n - cacheDecoder = NullDecoder . get ( ) ; \n - encoder = NullResourceEncoder . get ( ) ; \n + this . cacheDecoder = NullDecoder . get ( ) ; \n + this . encoder = NullResourceEncoder . get ( ) ; \n","Review fixes , removed tabs , changed ordering in GifFrameManager to match args",424
"checkstyle _ suppressions . xml \n - < suppress files = "" . * / library / src / androidTest / . * "" checks = "" [ a - zA - Z0 - 9 ] * "" / > \n + < suppress files = "" . * [ / \ \ ] library [ / \ \ ] src [ / \ \ ] androidTest [ / \ \ ] . * "" checks = "" [ a - zA - Z0 - 9 ] * "" / > \n integration \ okhttp \ src \ main \ java \ com \ bumptech \ glide \ integration \ okhttp \ OkHttpStreamFetcher . java \n - * An { @ link DataFetcher } that uses an { @ link com . squareup . okhttp . OkHttpClient } to load an { @ link InputStream } for \n - * an { @ link GlideUrl } . \n + * Fetches an { @ link InputStream } using the okhttp library . \n library \ src \ androidTest \ java \ com \ bumptech \ glide \ load \ engine \ cache \ DiskLruCacheWrapperTest . java \n + import static junit . framework . Assert . assertEquals ; \n + / / @ org . junit . Ignore \n + / / on windows it will fail because new FileOutputStream keeps to lock \n + / / @ org . junit . Ignore \n + / / on windows it will fail because new FileOutputStream keeps to lock \n - return true ; \n + return true ; \n - is . read ( result ) ; \n + assertEquals ( length , is . read ( result ) ) ; \n library \ src \ androidTest \ java \ com \ bumptech \ glide \ load \ model \ stream \ StringLoaderTest . java \n + import com . bumptech . glide . tests . Util ; \n + \n + import static org . junit . Assume . assumeTrue ; \n + / / TODO on windows it will fail with schema being the drive letter ( C : \ . . . - > C ) \n + assumeTrue ( ! Util . isWindows ( ) ) ; \n library \ src \ androidTest \ java \ com \ bumptech \ glide \ tests \ Util . java \n + \n + public static boolean isWindows ( ) { \n + return System . getProperty ( "" os . name "" ) . startsWith ( "" Windows "" ) ; \n + } \n + \n",Make library compile / test / checkstyle on Windows ( @ Ignore in comments where needed ),424
"checkstyle _ suppressions . xml \n - < suppress files = "" . * [ / \ \ ] library [ / \ \ ] src [ / \ \ ] androidTest [ / \ \ ] . * "" checks = "" [ a - zA - Z0 - 9 ] * "" / > \n + < suppress files = "" . * [ / \ \ ] library [ / \ \ ] src [ / \ \ ] androidTest [ / \ \ ] . * "" checks = "" Javadoc . * "" / > \n library \ src \ androidTest \ java \ com \ bumptech \ glide \ load \ resource \ gifbitmap \ GifBitmapWrapperTransformationTest . java \n - String expectedId = "" asdfas "" ; \n + String expectedId = "" testID "" ; \n + BitmapPool pool = mock ( BitmapPool . class ) ; \n - assertEquals ( expectedId , new GifBitmapWrapperTransformation ( mock ( BitmapPool . class ) , bitmapTransformation ) . getId \n - ( ) ) ; \n + GifBitmapWrapperTransformation transformation = new GifBitmapWrapperTransformation ( pool , bitmapTransformation ) ; \n + \n + assertEquals ( expectedId , transformation . getId ( ) ) ; \n library \ src \ androidTest \ java \ com \ bumptech \ glide \ load \ resource \ transcode \ GlideBitmapDrawableTranscoderTest . java \n + import org . junit . Before ; \n + private GlideBitmapDrawableTranscoder transcoder ; \n + \n + @ Before \n + public void setUp ( ) { \n + transcoder = new GlideBitmapDrawableTranscoder ( Robolectric . application . getResources ( ) , mock ( BitmapPool . class ) ) ; \n + } \n + \n + @ Test \n + public void testHasValidId ( ) { \n + Util . assertClassHasValidId ( GlideBitmapDrawableTranscoder . class , transcoder . getId ( ) ) ; \n + } \n - GlideBitmapDrawableTranscoder transcoder = new GlideBitmapDrawableTranscoder ( Robolectric . application . getResources ( ) , \n - mock ( BitmapPool . class ) ) ; \n - \n - @ Test \n - public void testHasValidId ( ) { \n - Util . assertClassHasValidId ( GlideBitmapDrawableTranscoder . class , \n - new GlideBitmapDrawableTranscoder ( Robolectric . application . getResources ( ) , mock ( BitmapPool . class ) ) . getId ( ) ) ; \n - } \n",Suppress less checkstyle checks in tests ( no need for javadocs ) \n and fix the errors .,424
. gitignore \n - library / local . properties \n - samples / flickr / local . properties \n - * * / local . properties \n + * * local . properties \n,Clean up . gitignore re : local . properties,424
"library \ src \ main \ java \ com \ bumptech \ glide \ load \ ResourceDecoder . java \n - * \n - * Note - The width and height arguments are hints only , there is no requirement that the decoded resource \n - * exactly match the given dimensions . A typical use case would be to use the target dimensions to determine \n + * The { @ code source } is managed by the caller , there ' s no need to close it . \n + * The returned { @ link Resource } will be { @ link Resource # recycle ( ) released } when the engine sees fit . \n + * < / p > \n + * < p > \n + * Note - The { @ code width } and { @ code height } arguments are hints only , \n + * there is no requirement that the decoded resource exactly match the given dimensions . \n + * A typical use case would be to use the target dimensions to determine \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ data \ ByteArrayFetcher . java \n - / / Do nothing . \n + / / Do nothing . It ' s safe to leave a ByteArrayInputStream open . \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ data \ DataFetcher . java \n - * \n + * @ see # cleanup ( ) where the data retuned will be cleaned up \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ model \ ImageVideoModelLoader . java \n + \n + @ SuppressWarnings ( "" resource "" ) \n + / / @ see ModelLoader . loadData \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ bitmap \ BitmapDecoder . java \n - * @ param resource The resource to decode . \n + * @ param resource The resource to decode , managed by the caller , no need to clean it up . \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ file \ FileToStreamDecoder . java \n - \n - \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ gif \ GifFrameModelLoader . java \n - / / Do nothing . \n + / / Do nothing . GifDecoder reads from an arbitrary InputStream , the caller will close that stream . \n",Add more comments to indicate resource ( Closeable ) ownership .,424
"build . gradle \n + \n + gradle . projectsEvaluated { \n + tasks . withType ( JavaCompile ) { \n + if ( ! name . contains ( ' Test ' ) ) { \n + options . compilerArgs < < ' - Xlint : unchecked ' < < ' - Xlint : deprecation ' \n + } \n + } \n + } \n library \ src \ main \ java \ com \ bumptech \ glide \ GenericRequestBuilder . java \n - private GenericRequestBuilder < ModelType , DataType , ResourceType , TranscodeType > \n - thumbnailRequestBuilder ; \n + private GenericRequestBuilder < ModelType , DataType , ResourceType , TranscodeType > thumbnailRequestBuilder ; \n library \ src \ main \ java \ com \ bumptech \ glide \ GenericTranscodeRequest . java \n + @ SuppressWarnings ( "" unchecked "" ) \n + private static < Z , R > ResourceTranscoder < Z , R > getUnitTranscoder ( ) { \n + return ( ResourceTranscoder < Z , R > ) UnitTranscoder . get ( ) ; \n + } \n + \n - transcoder = ( ResourceTranscoder < Z , R > ) UnitTranscoder . get ( ) ; \n + transcoder = getUnitTranscoder ( ) ; \n library \ src \ main \ java \ com \ bumptech \ glide \ load \ engine \ cache \ LruResourceCache . java \n - protected void onItemEvicted ( Key key , Resource < ? > item ) { \n + protected void onItemEvicted ( Key key , Resource < ? > item ) { \n library \ src \ main \ java \ com \ bumptech \ glide \ request \ GenericRequest . java \n - R result = ( R ) received ; \n + R result = ( R ) received ; \n",Enable further checks ( in gradle ) for non - test code .,424
library \ src \ main \ java \ com \ bumptech \ glide \ request \ target \ BitmapImageViewTarget . java \n - private final ImageView view ; \n - \n - this . view = view ; \n library \ src \ main \ java \ com \ bumptech \ glide \ request \ target \ GlideDrawableImageViewTarget . java \n - private final ImageView view ; \n - this . view = view ; \n,Remove redundant fields exiting in super as well ( with same type ) .,424
gradle . properties \n - ANDROID _ GRADLE _ VERSION = 1 . 0 . 0 \n + ANDROID _ GRADLE _ VERSION = 1 . 2 . 2 \n - ROBOLECTRIC _ GRADLE _ VERSION = 0 . 14 . 0 \n + ROBOLECTRIC _ GRADLE _ VERSION = 1 . 0 . 1 \n - JUNIT _ VERSION = 4 . 11 \n - MOCKITO _ VERSION = 1 . 9 . 5 \n + JUNIT _ VERSION = 4 . 12 \n + MOCKITO _ VERSION = 1 . 10 . 19 \n gradle \ wrapper \ gradle - wrapper . properties \n - # Sat Dec 20 22 : 55 : 19 PST 2014 \n + # Thu Apr 30 12 : 21 : 55 CEST 2015 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 2 - bin . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 3 - all . zip \n integration \ volley \ build . gradle \n - apply plugin : ' robolectric ' \n + apply plugin : ' org . robolectric ' \n library \ build . gradle \n - apply plugin : ' robolectric ' \n + apply plugin : ' org . robolectric ' \n - findbugsTestDebug { \n - enabled = false \n - } \n - \n - check . dependsOn ( ' findbugs ' ) \n + tasks . check . dependsOn ( tasks . findbugs ) \n - pmdTestDebug { \n - enabled = false \n - } \n - \n - check . dependsOn ( ' pmd ' ) \n + tasks . check . dependsOn ( tasks . pmd ) \n third _ party \ gif _ decoder \ build . gradle \n - apply plugin : ' robolectric ' \n + apply plugin : ' org . robolectric ' \n,Upgrade build utility versions to latest \n Robolectric 1 . 0 . 0 got rid of the * TestDebug tasks,424
README . md \n - < type > aar < / type > \n - - - - - - - \n + - - - - - \n,Remove aar qualifier since Glide is distributed as jar . Fixes # 638,424
library \ src \ main \ java \ com \ bumptech \ glide \ load \ resource \ gif \ ByteBufferGifDecoder . java \n - this . context = context ; \n + this . context = context . getApplicationContext ( ) ; \n,Forward port PR # 1281 : Use application Context in GifResourceDecoder,424
"third _ party \ gif _ decoder \ src \ main \ java \ com \ bumptech \ glide \ gifdecoder \ GifHeader . java \n - / / TODO : this is set both during reading the header and while decoding frames . . . \n third _ party \ gif _ decoder \ src \ main \ java \ com \ bumptech \ glide \ gifdecoder \ StandardGifDecoder . java \n + / / Maximum size is 256 , see GifHeaderParser . readColorTable \n + / / Private color table that can be modified if needed \n + private final int [ ] pct = new int [ 256 ] ; \n - final int savedBgColor = header . bgColor ; \n - \n - if ( currentFrame . lct = = null ) { \n - act = header . gct ; \n - } else { \n - act = currentFrame . lct ; \n - if ( header . bgIndex = = currentFrame . transIndex ) { \n - header . bgColor = 0 ; \n - } \n - } \n - \n - int save = 0 ; \n - if ( currentFrame . transparency ) { \n - save = act [ currentFrame . transIndex ] ; \n - / / Set transparent color if specified . \n - act [ currentFrame . transIndex ] = 0 ; \n - } \n + act = currentFrame . lct ! = null ? currentFrame . lct : header . gct ; \n - / / Transfer pixel data to image . \n - Bitmap result = setPixels ( currentFrame , previousFrame ) ; \n - \n - act [ currentFrame . transIndex ] = save ; \n + / / Prepare local copy of color table ( "" pct = act "" ) , see # 1068 \n + System . arraycopy ( act , 0 , pct , 0 , act . length ) ; \n + / / Forget about act reference from shared header object , use copied version \n + act = pct ; \n + / / Set transparent color if specified . \n + act [ currentFrame . transIndex ] = 0 ; \n - header . bgColor = savedBgColor ; \n - return result ; \n + / / Transfer pixel data to image . \n + return setPixels ( currentFrame , previousFrame ) ; \n + if ( currentFrame . lct ! = null & & header . bgIndex = = currentFrame . transIndex ) { \n + c = 0 ; \n + } \n",Forward port PR # 1090 : Fix thread - unsafe behaviours in GifDecoder,424
"third _ party \ gif _ decoder \ src \ main \ java \ com \ bumptech \ glide \ gifdecoder \ StandardGifDecoder . java \n - Arrays . fill ( dest , c ) ; \n + / / The area used by the graphic must be restored to the background color . \n + int downsampledIH = previousFrame . ih / sampleSize ; \n + int downsampledIY = previousFrame . iy / sampleSize ; \n + int downsampledIW = previousFrame . iw / sampleSize ; \n + int downsampledIX = previousFrame . ix / sampleSize ; \n + int topLeft = downsampledIY * downsampledWidth + downsampledIX ; \n + int bottomLeft = topLeft + downsampledIH * downsampledWidth ; \n + for ( int left = topLeft ; left < bottomLeft ; left + = downsampledWidth ) { \n + int right = left + downsampledIW ; \n + for ( int pointer = left ; pointer < right ; pointer + + ) { \n + dest [ pointer ] = c ; \n + } \n + } \n",Forward port PR # 1093 : Fill only the area that was modified by the previous GIF frame on dispose background,424
"new file \n src \ test \ java \ spark \ util \ ResourceUtilsTest . java \n + package spark . util ; \n + \n + import static org . junit . Assert . assertEquals ; \n + \n + import java . io . File ; \n + import java . io . FileNotFoundException ; \n + import java . net . MalformedURLException ; \n + import java . net . URISyntaxException ; \n + import java . net . URL ; \n + \n + import org . junit . Test ; \n + \n + import spark . utils . ResourceUtils ; \n + \n + public class ResourceUtilsTest { \n + \n + @ Test ( expected = FileNotFoundException . class ) \n + public void testGetFile _ whenURLProtocolIsNotFile _ thenThrowFileNotFoundException ( ) throws MalformedURLException , FileNotFoundException { \n + URL url = new URL ( "" http : / / example . com / "" ) ; \n + ResourceUtils . getFile ( url , "" Some description "" ) ; \n + } \n + \n + @ Test \n + public void testGetFile _ whenURLProtocolIsFile _ thenReturnFileObject ( ) throws MalformedURLException , FileNotFoundException , URISyntaxException { \n + URL url = new URL ( "" file : / / public / file . txt "" ) ; \n + File file = ResourceUtils . getFile ( url , "" Some description "" ) ; \n + assertEquals ( file , new File ( ResourceUtils . toURI ( url ) . getSchemeSpecificPart ( ) ) ) ; \n + } \n + \n + } \n",UTS - 193 - Add test cases for the method ResourceUtils . getFile,426
src \ test \ java \ spark \ resource \ ClassPathResourceHandlerTest . java \n - public void testGetResource _ whenResourcePathExists _ andGetFileFromResourceThrowsException _ thenReturnNull ( ) throws Exception { \n + public void testGetResource _ whenResourcePathExists _ andResourceThrowsException _ thenReturnNull ( ) throws Exception { \n,UTS - 193 - Change the name of a test method,426
"new file \n src \ test \ java \ spark \ route \ SimpleRouteMatcherTest . java \n + package spark . route ; \n + \n + import java . util . List ; \n + \n + import org . junit . Test ; \n + import org . powermock . reflect . Whitebox ; \n + import static org . junit . Assert . * ; \n + \n + public class SimpleRouteMatcherTest { \n + \n + @ Test \n + public void testParseValidateAddRoute _ whenHttpMethodIsValid _ thenAddRoute ( ) { \n + String route = "" get ' / hello ' "" ; \n + String acceptType = "" * / * "" ; \n + Object target = new Object ( ) ; \n + \n + RouteEntry expectedRouteEntry = new RouteEntry ( ) ; \n + expectedRouteEntry . acceptedType = acceptType ; \n + expectedRouteEntry . httpMethod = HttpMethod . get ; \n + expectedRouteEntry . path = "" / hello "" ; \n + expectedRouteEntry . target = target ; \n + \n + SimpleRouteMatcher simpleRouteMatcher = new SimpleRouteMatcher ( ) ; \n + simpleRouteMatcher . parseValidateAddRoute ( route , acceptType , target ) ; \n + \n + List < RouteEntry > routes = Whitebox . getInternalState ( simpleRouteMatcher , "" routes "" ) ; \n + assertEquals ( routes . size ( ) , 1 ) ; \n + assertEquals ( routes . get ( 0 ) . acceptedType , expectedRouteEntry . acceptedType ) ; \n + assertEquals ( routes . get ( 0 ) . httpMethod , expectedRouteEntry . httpMethod ) ; \n + assertEquals ( routes . get ( 0 ) . path , expectedRouteEntry . path ) ; \n + assertEquals ( routes . get ( 0 ) . target , expectedRouteEntry . target ) ; \n + } \n + \n + @ Test \n + public void testParseValidateAddRoute _ whenHttpMethodIsInvalid _ thenDoNotAddRoute ( ) { \n + String route = "" test ' / hello ' "" ; \n + String acceptType = "" * / * "" ; \n + Object target = new Object ( ) ; \n + \n + SimpleRouteMatcher simpleRouteMatcher = new SimpleRouteMatcher ( ) ; \n + simpleRouteMatcher . parseValidateAddRoute ( route , acceptType , target ) ; \n + \n + List < RouteEntry > routes = Whitebox . getInternalState ( simpleRouteMatcher , "" routes "" ) ; \n + assertEquals ( routes . size ( ) , 0 ) ; \n + } \n + } \n",UTS - 193 - Add test cases for the method SimpleRouteMatcher . parseValidateAddRoute,426
"src \ test \ java \ spark \ resource \ ClassPathResourceHandlerTest . java \n - assertNull ( classPathResourceHandler . getResource ( "" / folder "" ) ) ; \n + assertNull ( "" Should return null because the resource path doesn ' t point to a file "" , classPathResourceHandler . getResource ( "" / folder "" ) ) ; \n - assertNull ( classPathResourceHandler . getResource ( "" / folder "" ) ) ; \n + assertNull ( "" Should return null because the resource path doesn ' t exists "" , classPathResourceHandler . getResource ( "" / folder "" ) ) ; \n src \ test \ java \ spark \ resource \ ExternalResourceHandlerTest . java \n + import org . junit . Rule ; \n + import org . junit . rules . ExpectedException ; \n - assertNull ( externalResourceHandler . getResource ( "" / folder "" ) ) ; \n + assertNull ( "" Should return null because the resource path doesn ' t point to a file "" , externalResourceHandler . getResource ( "" / folder "" ) ) ; \n - assertNull ( externalResourceHandler . getResource ( "" / folder "" ) ) ; \n + assertNull ( "" Should return null because the resource path doesn ' t exists "" , externalResourceHandler . getResource ( "" / folder "" ) ) ; \n src \ test \ java \ spark \ util \ ResourceUtilsTest . java \n + import org . junit . Rule ; \n + import org . junit . rules . ExpectedException ; \n - @ Test ( expected = FileNotFoundException . class ) \n + @ Rule \n + public ExpectedException thrown = ExpectedException . none ( ) ; \n + \n + @ Test \n + thrown . expect ( FileNotFoundException . class ) ; \n + thrown . expectMessage ( "" My File Path cannot be resolved to absolute file path "" + \n + "" because it does not reside in the file system : http : / / example . com / "" ) ; \n - ResourceUtils . getFile ( url , "" Some description "" ) ; \n + ResourceUtils . getFile ( url , "" My File Path "" ) ; \n",UTS - 193 - Add missing assert messages and exception expected messages,426
"new file \n src \ test \ java \ spark \ ExceptionMapperTest . java \n + package spark ; \n + \n + import org . junit . Test ; \n + import org . powermock . reflect . Whitebox ; \n + import static org . junit . Assert . assertEquals ; \n + \n + public class ExceptionMapperTest { \n + \n + \n + @ Test \n + public void testGetInstance _ whenDefaultInstanceIsNull ( ) { \n + ExceptionMapper exceptionMapper = null ; \n + Whitebox . setInternalState ( ExceptionMapper . class , "" defaultInstance "" , exceptionMapper ) ; \n + exceptionMapper = ExceptionMapper . getInstance ( ) ; \n + assertEquals ( "" Should be equals because ExceptionMapper is a singleton "" , Whitebox . getInternalState ( ExceptionMapper . class , "" defaultInstance "" ) , exceptionMapper ) ; \n + } \n + \n + @ Test \n + public void testGetInstance _ whenDefaultInstanceIsNotNull ( ) { \n + ExceptionMapper . getInstance ( ) ; \n + ExceptionMapper exceptionMapper = ExceptionMapper . getInstance ( ) ; \n + assertEquals ( "" Should be equals because ExceptionMapper is a singleton "" , Whitebox . getInternalState ( ExceptionMapper . class , "" defaultInstance "" ) , exceptionMapper ) ; \n + } \n + } \n",UTS - 194 - Add test cases for the method ExceptionMapper . getInstance,426
src \ test \ java \ spark \ staticfiles \ StaticFilesTest . java \n + / / given \n + \n + / / then \n + / / given \n + \n + / / then \n + / / given \n + \n + / / then \n,UTS - 197 - Add comments to indicate sections in the test methods,426
"new file \n src \ test \ java \ spark \ SparkInstanceTest . java \n + package spark ; \n + \n + import static org . mockito . Matchers . any ; \n + import static org . mockito . Mockito . mock ; \n + import static org . mockito . Mockito . verify ; \n + import static org . mockito . Mockito . when ; \n + \n + import java . util . Map ; \n + import java . util . Optional ; \n + import java . util . concurrent . CountDownLatch ; \n + \n + import org . junit . Test ; \n + import org . junit . runner . RunWith ; \n + import org . powermock . api . mockito . PowerMockito ; \n + import org . powermock . core . classloader . annotations . PrepareForTest ; \n + import org . powermock . modules . junit4 . PowerMockRunner ; \n + \n + import spark . ssl . SslStores ; \n + import spark . webserver . SparkServerFactory ; \n + \n + @ RunWith ( PowerMockRunner . class ) \n + @ PrepareForTest ( SparkServerFactory . class ) \n + public class SparkInstanceTest { \n + \n + @ Test \n + public void testInit ( ) { \n + / / given \n + SparkInstance sparkInstance = new SparkInstance ( ) ; \n + PowerMockito . mockStatic ( SparkServerFactory . class ) ; \n + SparkServer serverMock = mock ( SparkServer . class ) ; \n + \n + / / when \n + when ( SparkServerFactory . create ( any ( boolean . class ) ) ) . thenReturn ( serverMock ) ; \n + \n + / / then \n + sparkInstance . init ( ) ; \n + verify ( serverMock ) . ignite ( any ( String . class ) , any ( int . class ) , any ( SslStores . class ) , any ( CountDownLatch . class ) , \n + any ( int . class ) , any ( int . class ) , any ( int . class ) , any ( Map . class ) , any ( Optional . class ) ) ; \n + } \n + } \n",UTS - 197 - Add test cases for the method SparkInstance . init ( ),426
AndroidAnnotations \ functional - test - 1 - 5 \ src \ main \ java \ org \ androidannotations \ test15 \ ThreadActivity . java \n + import android . os . SystemClock ; \n - / * wait a random delay to increase the probability of wrong order if buggy * / \n - try { \n - / * wait between 0 and 20 milliseconds * / \n - Thread . sleep ( new Random ( ) . nextInt ( 20 ) ) ; \n - } catch ( InterruptedException e ) { } \n - \n + / * wait a random delay ( between 0 and 20 milliseconds ) to increase the \n + * probability of wrong order if buggy * / \n + SystemClock . sleep ( new Random ( ) . nextInt ( 20 ) ) ; \n,Use SystemClock . sleep ( ) \n Avoid try / catch InterruptedException of Thread . sleep ( ) .,428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ helper \ APTCodeModelHelper . java \n + public JTryBlock surroundWithTryCatch ( EBeanHolder holder , JBlock block , JBlock content , String exceptionMessage ) { \n + Classes classes = holder . classes ( ) ; \n + JTryBlock tryBlock = block . _ try ( ) ; \n + tryBlock . body ( ) . add ( content ) ; \n + JCatchBlock catchBlock = tryBlock . _ catch ( classes . RUNTIME _ EXCEPTION ) ; \n + JVar exceptionParam = catchBlock . param ( "" e "" ) ; \n + JInvocation errorInvoke = classes . LOG . staticInvoke ( "" e "" ) ; \n + errorInvoke . arg ( holder . generatedClass . name ( ) ) ; \n + errorInvoke . arg ( exceptionMessage ) ; \n + errorInvoke . arg ( exceptionParam ) ; \n + catchBlock . body ( ) . add ( errorInvoke ) ; \n + return tryBlock ; \n + } \n + \n - JTryBlock runTry = runMethodBody . _ try ( ) ; \n - runTry . body ( ) . add ( previousMethodBody ) ; \n - \n - JCatchBlock runCatch = runTry . _ catch ( classes . RUNTIME _ EXCEPTION ) ; \n - JVar exceptionParam = runCatch . param ( "" e "" ) ; \n - \n - JInvocation errorInvoke = classes . LOG . staticInvoke ( "" e "" ) ; \n - \n - errorInvoke . arg ( holder . generatedClass . name ( ) ) ; \n - errorInvoke . arg ( "" A runtime exception was thrown while executing code in a runnable "" ) ; \n - errorInvoke . arg ( exceptionParam ) ; \n + surroundWithTryCatch ( holder , runMethodBody , previousMethodBody , "" A runtime exception was thrown while executing code in a runnable "" ) ; \n - runCatch . body ( ) . add ( errorInvoke ) ; \n","Factorize surround with try / catch generation \n Extract the surround - with - try - catch part of the anonymous Runnable \n generation , in order to reuse it for generating other anonymous classes .",428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ processing \ BackgroundProcessor . java \n + import org . androidannotations . api . BackgroundExecutor . Task ; \n + import com . sun . codemodel . JBlock ; \n + import com . sun . codemodel . JMod ; \n - JDefinedClass anonymousRunnableClass = helper . createDelegatingAnonymousRunnableClass ( holder , delegatingMethod ) ; \n + JBlock previousMethodBody = helper . removeBody ( delegatingMethod ) ; \n - { \n - / / Execute Runnable \n - Background annotation = element . getAnnotation ( Background . class ) ; \n - int delay = annotation . delay ( ) ; \n - String serial = annotation . serial ( ) ; \n + JDefinedClass anonymousTaskClass = codeModel . anonymousClass ( Task . class ) ; \n - JClass backgroundExecutorClass = holder . refClass ( BackgroundExecutor . class ) ; \n - JInvocation executeCall ; \n + JMethod executeMethod = anonymousTaskClass . method ( JMod . PUBLIC , codeModel . VOID , "" execute "" ) ; \n + executeMethod . annotate ( Override . class ) ; \n - executeCall = backgroundExecutorClass . staticInvoke ( "" execute "" ) . arg ( _ new ( anonymousRunnableClass ) ) . arg ( lit ( delay ) ) . arg ( lit ( serial ) ) ; \n + JBlock runMethodBody = executeMethod . body ( ) ; \n + helper . surroundWithTryCatch ( holder , runMethodBody , previousMethodBody , "" A runtime exception was thrown while executing code in a background task "" ) ; \n - delegatingMethod . body ( ) . add ( executeCall ) ; \n + Background annotation = element . getAnnotation ( Background . class ) ; \n + String id = annotation . id ( ) ; \n + int delay = annotation . delay ( ) ; \n - } \n + JClass backgroundExecutorClass = holder . refClass ( BackgroundExecutor . class ) ; \n + JInvocation newTask = _ new ( anonymousTaskClass ) . arg ( lit ( id ) ) . arg ( lit ( delay ) ) ; \n + JInvocation executeCall = backgroundExecutorClass . staticInvoke ( "" execute "" ) . arg ( newTask ) ; \n + delegatingMethod . body ( ) . add ( executeCall ) ; \n","Directly generate Task instantiation \n Instead of create a new Runnable instance which will be wrapped by a \n Task instance , directly create a Task ( which is a Runnable ) .",428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n + import android . util . Log ; \n + \n + private static final String TAG = "" BackgroundExecutor "" ; \n + \n - if ( task . id ! = null & & future = = null ) { \n - throw new IllegalArgumentException ( "" The executor set does not support task cancellation "" ) ; \n - } \n + } else if ( task . executionAsked ) { \n + Log . w ( TAG , "" A task with id "" + task . id + "" cannot be cancelled ( the executor set does not support it ) "" ) ; \n","Do not fail if cancellation is not supported \n If the executor is replaced by another not supporting cancellation ( not \n extending ExecutorService ) , it failed the first time a task with a \n non - null id was requested . \n Now , it just warns during cancellation .",428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n - future = ( ( ScheduledExecutorService ) executor ) . schedule ( runnable , delay , TimeUnit . MILLISECONDS ) ; \n + ScheduledExecutorService scheduledExecutorService = ( ScheduledExecutorService ) executor ; \n + future = scheduledExecutorService . schedule ( runnable , delay , TimeUnit . MILLISECONDS ) ; \n - future = ( ( ExecutorService ) executor ) . submit ( runnable ) ; \n + ExecutorService executorService = ( ExecutorService ) executor ; \n + future = executorService . submit ( runnable ) ; \n",Cast into a local variable before dereferencing \n https : / / github . com / rom1v / androidannotations / commit / 879f196e4fcfd647ad0b674827ca22ef51459953 # commitcomment - 3261065,428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n - / * no serial , no delay : execute now * / \n",Remove useless comment \n https : / / github . com / rom1v / androidannotations / commit / 879f196e4fcfd647ad0b674827ca22ef51459953 # commitcomment - 3261070,428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n - private long targetTime ; / * in milliseconds since epoch * / \n + private long targetTimeMillis ; / * since epoch * / \n - targetTime = System . currentTimeMillis ( ) + delay ; \n + targetTimeMillis = System . currentTimeMillis ( ) + delay ; \n - next . delay = Math . max ( 0 , ( int ) ( targetTime - System . currentTimeMillis ( ) ) ) ; \n + next . delay = Math . max ( 0 , ( int ) ( targetTimeMillis - System . currentTimeMillis ( ) ) ) ; \n",Refactor targetTime - > targetTimeMillis \n https : / / github . com / rom1v / androidannotations / commit / 879f196e4fcfd647ad0b674827ca22ef51459953 # commitcomment - 3260958,428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n - future = directExecute ( task , task . delay ) ; \n + future = directExecute ( task , task . remainingDelay ) ; \n - private int delay ; \n + private int remainingDelay ; \n - this . delay = delay ; \n + remainingDelay = delay ; \n - if ( next . delay ! = 0 ) { \n - / * compute remaining delay * / \n - next . delay = Math . max ( 0 , ( int ) ( targetTimeMillis - System . currentTimeMillis ( ) ) ) ; \n + if ( next . remainingDelay ! = 0 ) { \n + / * the delay may not have elapsed yet * / \n + next . remainingDelay = Math . max ( 0 , ( int ) ( targetTimeMillis - System . currentTimeMillis ( ) ) ) ; \n",Refactor delay - > remainingDelay \n https : / / github . com / rom1v / androidannotations / commit / 879f196e4fcfd647ad0b674827ca22ef51459953 # commitcomment - 3261105,428
"AndroidAnnotations \ androidannotations - api \ src \ main \ java \ org \ androidannotations \ annotations \ Background . java \n - String id ( ) default "" "" ; / * used for task cancellation * / \n + / * * \n + * Identifier for task cancellation . \n + * \n + * To cancel all tasks having a specified background id : \n + * \n + * < pre > \n + * boolean mayInterruptIfRunning = true ; \n + * BackgroundExecutor . cancelAll ( & quot ; my _ background _ id & quot ; , mayInterruptIfRunning ) ; \n + * < / pre > \n + * * / \n + String id ( ) default "" "" ; \n - int delay ( ) default 0 ; / * in milliseconds * / \n + / * * Minimum delay , in milliseconds , before the background task is executed . * / \n + int delay ( ) default 0 ; \n + / * * \n + * Serial execution group . \n + * \n + * All background tasks having the same < code > serial < / code > will be executed \n + * sequentially . \n + * * / \n",Javadoc for @ Background annotation \n https : / / github . com / excilys / androidannotations / pull / 564 / files # r4329001,428
"AndroidAnnotations \ androidannotations \ src \ main \ java \ org \ androidannotations \ api \ BackgroundExecutor . java \n + import java . util . concurrent . atomic . AtomicBoolean ; \n - tasks . remove ( i ) ; \n + if ( ! task . managed . getAndSet ( true ) ) { \n + / * \n + * the task has been submitted to the executor , but its \n + * execution has not started yet , so that its run ( ) \n + * method will never call postExecute ( ) \n + * / \n + task . postExecute ( ) ; \n + } \n + } else { \n + / * this task has not been submitted to the executor * / \n + tasks . remove ( i ) ; \n + / * \n + * A task can be cancelled after it has been submitted to the executor \n + * but before its run ( ) method is called . In that case , run ( ) will never \n + * be called , hence neither will postExecute ( ) : the tasks with the same \n + * serial identifier ( if any ) will never be submitted . \n + * \n + * Therefore , cancelAll ( ) * must * call postExecute ( ) if run ( ) is not \n + * started . \n + * \n + * This flag guarantees that either cancelAll ( ) or run ( ) manages this \n + * task post execution , but not both . \n + * / \n + private AtomicBoolean managed = new AtomicBoolean ( ) ; \n + \n + if ( managed . getAndSet ( true ) ) { \n + / * cancelled and postExecute ( ) already called * / \n + return ; \n + } \n + \n","Serialized @ Background task cancellation bugfix \n If a serialized @ Background task was cancelled after it had been \n submitted to the executor but before its run ( ) method was called , then \n the following tasks with the same serial identifier were not executed . \n Issue reported here : \n https : / / github . com / excilys / androidannotations / pull / 579 # issuecomment - 19173978 \n Detected by ThreadActivityTest # cancellableSerializedBackgroundTasks ( ) \n ( but not always due to the race condition )",428
"build - common \ test \ org \ jetbrains \ kotlin \ incremental \ testingUtils \ BuildLogFinder . kt \n - private val isScopeExpansionEnabled : Boolean = false \n + private val isScopeExpansionEnabled : Boolean = false , \n + private val isKlibEnabled : Boolean = false \n + private const val KLIB _ LOG = "" klib - build . log "" \n + isKlibEnabled & & KLIB _ LOG in files - > KLIB _ LOG \n compiler \ incremental - compilation - impl \ test \ org \ jetbrains \ kotlin \ incremental \ AbstractIncrementalJsKlibCompilerRunnerTest . kt \n - get ( ) = super . buildLogFinder . copy ( isJsIrEnabled = true ) \n + get ( ) = super . buildLogFinder . copy ( isJsIrEnabled = true , isKlibEnabled = true ) \n",[ KLIB IC ] Support special klib - build . log in IC test infrastructure,429
"compiler \ incremental - compilation - impl \ src \ org \ jetbrains \ kotlin \ incremental \ multiproject \ ModulesApiHistory . kt \n + extension . equals ( "" klib "" , ignoreCase = true ) - > { \n + / / TODO : shouldn ' t jars and klibs be tracked separately ? \n + / / TODO : what to do with ` in - directory ` klib ? \n + jarFiles . add ( file ) \n + } \n",[ KLIB ] Take into account * . klib rebuild similar to * . jar \n Fix multi - module incremental compilation . Fix allows to trigger klib \n rebuild when dependency changed .,429
"compiler \ incremental - compilation - impl \ test \ org \ jetbrains \ kotlin \ incremental \ AbstractIncrementalJsKlibCompilerRunnerTest . kt \n + import org . jetbrains . kotlin . library . KLIB _ FILE _ EXTENSION \n - outputFile = File ( destinationDir , "" $ { testDir . name } . klib "" ) . path \n - sourceMap = true \n - / / Don ' t zip klib content since date on files affect the md5 checksum we compute to check whether output files identical \n - irProduceKlibDir = true \n + outputFile = File ( destinationDir , "" $ { testDir . name } . $ KLIB _ FILE _ EXTENSION "" ) . path \n + sourceMap = false \n + irProduceKlibDir = false \n + irProduceKlibFile = true \n",[ KLIB IC ] Produce . klib file instead of directory in test \n - disable sourcemaps \n - clean up comment,429
"compiler \ tests - against - klib \ tests \ org \ jetbrains \ kotlin \ codegen \ ir \ AbstractIrCompileKotlinAgainstKlibTest . kt \n - klibName = Paths . get ( outputDir . toString ( ) , wholeFile . name . toString ( ) . removeSuffix ( "" . kt "" ) ) . toString ( ) \n + klibName = Paths . get ( outputDir . toString ( ) , wholeFile . name . toString ( ) . replace ( "" . kt "" , "" . klib "" ) ) . toString ( ) \n",[ JVM IR ] Fix jvm test runner,429
"kotlin - native \ backend . native \ compiler \ ir \ backend . native \ src \ org \ jetbrains \ kotlin \ backend \ konan \ Context . kt \n - override val lateinitNullableFields = mutableMapOf < IrField , IrField > ( ) \n kotlin - native \ backend . native \ compiler \ ir \ backend . native \ src \ org \ jetbrains \ kotlin \ backend \ konan \ KonanBackendContext . kt \n - override val transformedFunction : MutableMap < IrFunctionSymbol , IrSimpleFunctionSymbol > \n - get ( ) = TODO ( "" not implemented "" ) \n",[ IR BE ] Drop unused members in backend context ( K / N part ) \n ( cherry picked from commit cad57e996db7b9d933855bbd91a623a0f8f34003 ),429
"compiler \ cli \ cli - js - klib \ src \ GenerateJsIrKlib . kt \n - dependencies , messageCollectorLogger ( MessageCollector . NONE ) \n + dependencies , emptyList ( ) , messageCollectorLogger ( MessageCollector . NONE ) \n compiler \ cli \ cli - js \ src \ org \ jetbrains \ kotlin \ cli \ js \ K2JsIrCompiler . kt \n + configuration [ JSConfigurationKeys . REPOSITORIES ] ? : emptyList ( ) , \n compiler \ ir \ serialization . js \ src \ org \ jetbrains \ kotlin \ ir \ backend \ js \ JsLibraryResolver . kt \n - fun jsResolveLibraries ( libraries : List < String > , logger : Logger ) : KotlinLibraryResolveResult { \n + fun jsResolveLibraries ( libraries : List < String > , repositories : Collection < String > , logger : Logger ) : KotlinLibraryResolveResult { \n - repositories = emptyList ( ) , \n + repositories = repositories . toList ( ) , \n js \ js . frontend \ src \ org \ jetbrains \ kotlin \ js \ config \ JSConfigurationKeys . java \n + import java . util . Collection ; \n + \n + public static final CompilerConfigurationKey < Collection < String > > REPOSITORIES = \n + CompilerConfigurationKey . create ( "" set up additional repository paths "" ) ; \n js \ js . tests \ test \ org \ jetbrains \ kotlin \ js \ test \ ApiTest . kt \n - jsResolveLibraries ( listOf ( File ( fullRuntimeKlib ) . absolutePath ) , messageCollectorLogger ( MessageCollector . NONE ) ) \n + jsResolveLibraries ( listOf ( File ( fullRuntimeKlib ) . absolutePath ) , emptyList ( ) , messageCollectorLogger ( MessageCollector . NONE ) ) \n js \ js . tests \ test \ org \ jetbrains \ kotlin \ js \ test \ BasicIrBoxTest . kt \n - val resolvedLibraries = jsResolveLibraries ( allKlibPaths , messageCollectorLogger ( MessageCollector . NONE ) ) \n + val resolvedLibraries = jsResolveLibraries ( allKlibPaths , emptyList ( ) , messageCollectorLogger ( MessageCollector . NONE ) ) \n plugins \ scripting \ scripting - compiler \ src \ org \ jetbrains \ kotlin \ scripting \ repl \ js \ JsReplUtils . kt \n + emptyList ( ) , \n",[ JS IR ] Support additional repositories in CLI ( compiler part ),429
"compiler \ cli \ cli - common \ src \ org \ jetbrains \ kotlin \ cli \ common \ arguments \ K2JSCompilerArguments . kt \n + @ Argument ( \n + value = "" - Xrepositories "" , \n + valueDescription = "" < path > "" , \n + description = "" Paths to additional places where libraries could be found "" \n + ) \n + var repositries : String ? by NullableStringFreezableVar ( null ) \n + \n compiler \ cli \ cli - js \ src \ org \ jetbrains \ kotlin \ cli \ js \ K2JsIrCompiler . kt \n + val repositories : List < String > = configureLibraries ( arguments . repositries ) \n + configuration . put ( JSConfigurationKeys . REPOSITORIES , repositories ) \n compiler \ testData \ cli \ js \ jsExtraHelp . out \n - Xir - property - lazy - initialization \n - Xmetadata - only Generate * . meta . js and * . kjsm files only \n + - Xrepositories = < path > Paths to additional places where libraries could be found \n - Xtyped - arrays Translate primitive arrays to JS typed arrays \n - Xwasm Use experimental WebAssembly compiler backend \n - Xallow - kotlin - package Allow compiling code in package ' kotlin ' and allow not requiring kotlin . stdlib in module - info \n",[ JS IR ] Support additional repositories in CLI ( cli part ),429
"compiler \ util - klib \ src \ org \ jetbrains \ kotlin \ library \ impl \ KotlinLibraryImpl . kt \n - IrLibrary by ir \n + IrLibrary by ir { \n + override fun toString ( ) : String { \n + return "" [ Klib : $ { base . libraryFile . name } , file : $ { base . libraryFile . path } ] "" \n + } \n + } \n",[ KLIB ] Improve klib debugging implementing ` KotlinLibrary . toString ( ) `,429
"kotlin - native \ Interop \ StubGenerator \ src \ main \ kotlin \ org \ jetbrains \ kotlin \ native \ interop \ gen \ jvm \ InteropLibraryCreation . kt \n + import kotlinx . metadata . KmModuleFragment \n + import kotlinx . metadata . klib . fqName \n + import kotlinx . metadata . klib . className \n - import kotlinx . metadata . klib . className \n - import kotlinx . metadata . klib . fqName \n + import org . jetbrains . kotlin . konan . library . impl . KonanLibraryLayoutForWriter \n - import org . jetbrains . kotlin . util . removeSuffixIfPresent \n - val outputPathWithoutExtension = outputPath . removeSuffixIfPresent ( "" . klib "" ) \n + val libFile = File ( outputPath ) \n + val unzippedDir = if ( nopack ) libFile else org . jetbrains . kotlin . konan . file . createTempDir ( moduleName ) \n + val layout = KonanLibraryLayoutForWriter ( libFile , unzippedDir , target ) \n - File ( outputPathWithoutExtension ) , \n - shortName = shortName \n + shortName = shortName , \n + layout = layout \n kotlin - native \ shared \ src \ library \ kotlin \ org \ jetbrains \ kotlin \ konan \ library \ impl \ KonanLibraryWriterImpl . kt \n - override val libDir : File , \n + libFile : File , \n + unzippedDir : File , \n - ) : KonanLibraryLayout , KotlinLibraryLayoutForWriter ( libDir ) \n + ) : KonanLibraryLayout , KotlinLibraryLayoutForWriter ( libFile , unzippedDir ) \n - libDir : File , \n - val layout : KonanLibraryLayoutForWriter = KonanLibraryLayoutForWriter ( libDir , target ) , \n + val layout : KonanLibraryLayoutForWriter , \n + val libFile = File ( output ) \n + val unzippedDir = if ( nopack ) libFile else org . jetbrains . kotlin . konan . file . createTempDir ( moduleName ) \n + val layout = KonanLibraryLayoutForWriter ( libFile , unzippedDir , target ) \n - File ( output ) , \n - shortName \n + shortName , \n + layout \n",[ KLIB ] Adapt new klib io API in K / N \n ( cherry picked from commit 70fabb6a9db83db5f5b26b54f2656655316ea31c ),429
"kotlin - native \ backend . native \ compiler \ ir \ backend . native \ src \ org \ jetbrains \ kotlin \ backend \ konan \ OutputFiles . kt \n + fun klibOutputFileName ( isPacked : Boolean ) : String = \n + if ( isPacked ) "" $ outputName $ suffix "" else outputName \n + \n",Add ` klibOutputFileName ( . . ) ` into ` OutputFiles . kt ` \n ( cherry picked from commit c4511b8b6b8e75f0d7b3f33007da3a75923bd61b ),429
"kotlin - native \ klib \ src \ main \ kotlin \ org \ jetbrains \ kotlin \ cli \ klib \ main . kt \n - import org . jetbrains . kotlin . library . KLIB _ FILE _ EXTENSION _ WITH _ DOT \n + import org . jetbrains . kotlin . library . KLIB _ FILE _ EXTENSION _ WITH _ DOT \n + import org . jetbrains . kotlin . util . removeSuffixIfPresent \n - class Library ( val name : String , val requestedRepository : String ? , val target : String ) { \n + class Library ( val libraryNameOrPath : String , val requestedRepository : String ? , val target : String ) { \n - val library = libraryInRepoOrCurrentDir ( repository , name ) \n + val library = libraryInRepoOrCurrentDir ( repository , libraryNameOrPath ) \n - Library ( File ( name ) . name . removeSuffix ( KLIB _ FILE _ EXTENSION _ WITH _ DOT ) , requestedRepository , target ) . remove ( true ) \n + val libraryTrueName = File ( libraryNameOrPath ) . name . removeSuffixIfPresent ( KLIB _ FILE _ EXTENSION _ WITH _ DOT ) \n + val library = libraryInCurrentDir ( libraryNameOrPath ) \n + \n + val installLibDir = File ( repository , libraryTrueName ) \n - val library = libraryInCurrentDir ( name ) \n - val newLibDir = File ( repository , library . libraryFile . name . removeSuffix ( KLIB _ FILE _ EXTENSION _ WITH _ DOT ) ) \n + if ( installLibDir . exists ) installLibDir . deleteRecursively ( ) \n - library . libraryFile . unpackZippedKonanLibraryTo ( newLibDir ) \n + library . libraryFile . unpackZippedKonanLibraryTo ( installLibDir ) \n - val library = libraryInRepo ( repository , name ) \n - if ( blind ) warn ( "" Removing The previously installed $ name from $ repository . "" ) \n + val library = libraryInRepo ( repository , libraryNameOrPath ) \n + if ( blind ) warn ( "" Removing The previously installed $ libraryNameOrPath from $ repository . "" ) \n - val library = libraryInRepoOrCurrentDir ( repository , name ) \n + val library = libraryInRepoOrCurrentDir ( repository , libraryNameOrPath ) \n",Fix klib install gradle task \n ( cherry picked from commit a36abd282efab4568fceb92f8102e13fcac359fd ),429
"kotlin - native \ backend . native \ compiler \ ir \ backend . native \ src \ org \ jetbrains \ kotlin \ backend \ konan \ CompilerOutput . kt \n - val output = context . config . outputFiles . outputName \n + val nopack = config . getBoolean ( KonanConfigKeys . NOPACK ) \n + val output = context . config . outputFiles . klibOutputFileName ( ! nopack ) \n - val nopack = config . getBoolean ( KonanConfigKeys . NOPACK ) \n + if ( ! nopack ) { \n + val suffix = context . config . outputFiles . produce . suffix ( target ) \n + if ( ! output . endsWith ( suffix ) ) { \n + error ( "" please specify correct output : packed : $ { ! nopack } , $ output $ suffix "" ) \n + } \n + } \n + \n",Fix konan klib output setup \n ( cherry picked from commit c75b32ed1a4b8de2801bfece680b6ef7778b6dd5 ),429
compiler \ util - klib \ src \ org \ jetbrains \ kotlin \ library \ impl \ KotlinLibraryWriterImpl . kt \n - val klibFile = libraryLayout . libFile \n + val klibFile = libraryLayout . libFile . canonicalFile \n,[ KLIB ] Fix klib IO when accessing parent file,429
"compiler \ cli \ cli - js \ src \ org \ jetbrains \ kotlin \ cli \ js \ K2JsIrCompiler . kt \n - try { \n - generateKLib ( \n - project = config . project , \n - files = sourcesFiles , \n - analyzer = AnalyzerWithCompilerReport ( config . configuration ) , \n - configuration = config . configuration , \n - allDependencies = resolvedLibraries , \n - friendDependencies = friendDependencies , \n - irFactory = PersistentIrFactory , \n - outputKlibPath = outputFile . path , \n - nopack = arguments . irProduceKlibDir \n - ) \n - } catch ( e : JsIrCompilationError ) { \n - return COMPILATION _ ERROR \n - } \n + generateKLib ( \n + project = config . project , \n + files = sourcesFiles , \n + analyzer = AnalyzerWithCompilerReport ( config . configuration ) , \n + configuration = config . configuration , \n + allDependencies = resolvedLibraries , \n + friendDependencies = friendDependencies , \n + irFactory = PersistentIrFactory , \n + outputKlibPath = outputFile . path , \n + nopack = arguments . irProduceKlibDir \n + ) \n - val compiledModule = try { \n - compile ( \n - projectJs , \n - mainModule , \n - AnalyzerWithCompilerReport ( config . configuration ) , \n - config . configuration , \n - phaseConfig , \n - allDependencies = resolvedLibraries , \n - friendDependencies = friendDependencies , \n - mainArguments = mainCallArguments , \n - generateFullJs = ! arguments . irDce , \n - generateDceJs = arguments . irDce , \n - dceDriven = arguments . irDceDriven , \n - multiModule = arguments . irPerModule , \n - relativeRequirePath = true , \n - propertyLazyInitialization = arguments . irPropertyLazyInitialization , \n - ) \n - } catch ( e : JsIrCompilationError ) { \n - return COMPILATION _ ERROR \n - } \n + val compiledModule = compile ( \n + projectJs , \n + mainModule , \n + AnalyzerWithCompilerReport ( config . configuration ) , \n + config . configuration , \n + phaseConfig , \n + allDependencies = resolvedLibraries , \n + friendDependencies = friendDependencies , \n + mainArguments = mainCallArguments , \n + generateFullJs = ! arguments . irDce , \n + generateDceJs = arguments . irDce , \n + dceDriven = arguments . irDceDriven , \n + multiModule = arguments . irPerModule , \n + relativeRequirePath = true , \n + propertyLazyInitialization = arguments . irPropertyLazyInitialization , \n + ) \n compiler \ ir \ serialization . js \ src \ org \ jetbrains \ kotlin \ ir \ backend \ js \ klib . kt \n - object JsIrCompilationError : Throwable ( ) \n - \n - throw JsIrCompilationError \n + throw AnalysisResult . CompilationErrorException ( ) \n",[ JS IR ] Commonize CLI error reporting \n Use general ` AnalysisResult . CompilationErrorException ` instead of \n custom JsIrCompilationError to indicate about unsuccessful compilation \n - Drop JsIrCompilationError,429
"compiler \ util - klib \ src \ org \ jetbrains \ kotlin \ library \ impl \ KotlinLibraryImpl . kt \n - override fun toString ( ) : String { \n - return "" [ Klib : $ { base . libraryFile . name } , file : $ { base . libraryFile . path } ] "" \n + override fun toString ( ) : String = buildString { \n + append ( "" name "" ) \n + append ( base . libraryName ) \n + append ( "" , "" ) \n + append ( "" file : "" ) \n + append ( base . libraryFile . path ) \n + append ( "" , "" ) \n + append ( "" version : "" ) \n + append ( base . versions ) \n + if ( isInterop ) { \n + append ( "" , interop : true , "" ) \n + append ( "" native targets : "" ) \n + nativeTargets . joinTo ( this , "" , "" , "" { "" , "" } "" ) \n + } \n + append ( ' ) ' ) \n",[ KLIB ] Make ` KotlinLibraryImpl ` printable,429
"compiler \ ir \ serialization . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ serialization \ IncrementalCompilationSupport . kt \n + override fun toString ( ) : String = "" Incremental Cache Klib "" \n + \n compiler \ ir \ serialization . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ serialization \ KotlinIrLinker . kt \n + \n + override fun toString ( ) : String = klib . toString ( ) \n",[ KLIB ] Make ` IrModuleDeserializer ` ' s printable,429
"new file \n compiler \ ir \ ir . tree \ src \ org \ jetbrains \ kotlin \ ir \ util \ IrMessageLogger . kt \n + / * \n + * Copyright 2010 - 2021 JetBrains s . r . o . and Kotlin Programming Language contributors . \n + * Use of this source code is governed by the Apache 2 . 0 license that can be found in the license / LICENSE . txt file . \n + * / \n + \n + package org . jetbrains . kotlin . ir . util \n + \n + import org . jetbrains . kotlin . config . CompilerConfigurationKey \n + \n + interface IrMessageLogger { \n + \n + enum class Severity { \n + INFO , WARNING , ERROR \n + } \n + \n + data class Location ( val filePath : String , val line : Int , val column : Int ) \n + \n + fun report ( severity : Severity , message : String , location : Location ? ) \n + \n + object None : IrMessageLogger { \n + override fun report ( severity : Severity , message : String , location : Location ? ) { } \n + } \n + \n + companion object { \n + @ JvmStatic \n + val IR _ MESSAGE _ LOGGER = CompilerConfigurationKey < IrMessageLogger > ( "" ir message logger "" ) \n + } \n + } \n",[ IR ] Add ` IrMessageLogger ` interface for diagnostic reporting from IR,429
"new file \n compiler \ ir \ ir . tree \ src \ org \ jetbrains \ kotlin \ ir \ linkage \ KotlinIrLinkerInternalException . kt \n + / * \n + * Copyright 2010 - 2021 JetBrains s . r . o . and Kotlin Programming Language contributors . \n + * Use of this source code is governed by the Apache 2 . 0 license that can be found in the license / LICENSE . txt file . \n + * / \n + \n + package org . jetbrains . kotlin . ir . linkage \n + \n + object KotlinIrLinkerInternalException : Exception ( "" Kotlin IR Linker exception "" ) \n compiler \ ir \ ir . tree \ src \ org \ jetbrains \ kotlin \ ir \ util \ ExternalDependenciesGenerator . kt \n + import org . jetbrains . kotlin . analyzer . AnalysisResult \n + import org . jetbrains . kotlin . ir . linkage . KotlinIrLinkerInternalException \n - do { \n - prevUnbound = unbound \n - unbound = symbolTable . allUnbound \n + try { \n + do { \n + prevUnbound = unbound \n + unbound = symbolTable . allUnbound \n - for ( symbol in unbound ) { \n - / / Symbol could get bound as a side effect of deserializing other symbols . \n - if ( ! symbol . isBound ) { \n - irProviders . getDeclaration ( symbol ) \n + for ( symbol in unbound ) { \n + / / Symbol could get bound as a side effect of deserializing other symbols . \n + if ( ! symbol . isBound ) { \n + irProviders . getDeclaration ( symbol ) \n + } \n - } \n - / / We wait for the unbound to stabilize on fake overrides . \n - } while ( unbound ! = prevUnbound ) \n + / / We wait for the unbound to stabilize on fake overrides . \n + } while ( unbound ! = prevUnbound ) \n + } catch ( ex : KotlinIrLinkerInternalException ) { \n + throw AnalysisResult . CompilationErrorException ( ) \n + } \n",[ KLIB ] Handle linkage error \n Do not crash compiler with ugly stacktrace in case of misconfiguration . \n Report relatively friendly diagnostic message instead,429
"compiler \ cli \ src \ org \ jetbrains \ kotlin \ cli \ common \ CLICompiler . kt \n + import org . jetbrains . kotlin . ir . util . IrMessageLogger \n - import java . util . ArrayList \n + import java . util . * \n + configuration . put ( IrMessageLogger . IR _ MESSAGE _ LOGGER , IrMessageCollector ( collector ) ) \n + \n new file \n compiler \ cli \ src \ org \ jetbrains \ kotlin \ cli \ common \ messages \ IrMessageCollector . kt \n + / * \n + * Copyright 2010 - 2021 JetBrains s . r . o . and Kotlin Programming Language contributors . \n + * Use of this source code is governed by the Apache 2 . 0 license that can be found in the license / LICENSE . txt file . \n + * / \n + \n + package org . jetbrains . kotlin . cli . common . messages \n + \n + import org . jetbrains . kotlin . ir . util . IrMessageLogger \n + \n + class IrMessageCollector ( private val messageCollector : MessageCollector ) : IrMessageLogger { \n + override fun report ( severity : IrMessageLogger . Severity , message : String , location : IrMessageLogger . Location ? ) { \n + messageCollector . report ( severityToCLISeverity ( severity ) , message , locationToCLILocation ( location ) ) \n + } \n + \n + companion object { \n + private fun severityToCLISeverity ( severity : IrMessageLogger . Severity ) : CompilerMessageSeverity { \n + return when ( severity ) { \n + IrMessageLogger . Severity . INFO - > CompilerMessageSeverity . INFO \n + IrMessageLogger . Severity . WARNING - > CompilerMessageSeverity . WARNING \n + IrMessageLogger . Severity . ERROR - > CompilerMessageSeverity . ERROR \n + } \n + } \n + \n + private fun locationToCLILocation ( location : IrMessageLogger . Location ? ) : CompilerMessageLocation ? { \n + return location ? . run { \n + CompilerMessageLocation . Companion . create ( filePath , line , column , null ) \n + } \n + } \n + } \n + } \n",[ CLI ] Provide ` MessageCollector ` based logger for IR from CLI,429
"compiler \ ir \ backend . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ extensions \ IrPluginContext . kt \n + import org . jetbrains . kotlin . ir . util . IrMessageLogger \n + / * * \n + * Returns a logger instance to post diagnostic messages from plugin \n + * \n + * @ param pluginId the unique plugin ID to make it easy to distinguish in log \n + * @ return the logger associated with specified ID \n + * / \n + fun createDiagnosticReporter ( pluginId : String ) : IrMessageLogger \n + \n compiler \ ir \ backend . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ extensions \ IrPluginContextImpl . kt \n + import org . jetbrains . kotlin . ir . util . IrMessageLogger \n + private val diagnosticReporter : IrMessageLogger , \n + override fun createDiagnosticReporter ( pluginId : String ) : IrMessageLogger { \n + return object : IrMessageLogger { \n + override fun report ( \n + severity : IrMessageLogger . Severity , \n + message : String , \n + location : IrMessageLogger . Location ? \n + ) { \n + diagnosticReporter . report ( severity , "" [ Plugin $ pluginId ] $ message "" , location ) \n + } \n + } \n + } \n + \n compiler \ ir \ backend . jvm \ src \ org \ jetbrains \ kotlin \ backend \ jvm \ JvmIrCodegenFactory . kt \n - import org . jetbrains . kotlin . ir . backend . jvm . serialization . EmptyLoggingContext \n compiler \ ir \ serialization . js \ src \ org \ jetbrains \ kotlin \ ir \ backend \ js \ klib . kt \n - import org . jetbrains . kotlin . backend . common . LoggingContext \n - linker = irLinker \n + linker = irLinker , \n + messageLogger \n",[ Plugin API ] Provide diagnostic API for IR plugins,429
"kotlin - native \ backend . native \ compiler \ ir \ backend . native \ src \ org \ jetbrains \ kotlin \ backend \ konan \ PsiToIr . kt \n + import org . jetbrains . kotlin . name . Name \n + override fun resolveBySignatureInModule ( signature : IdSignature , kind : IrDeserializer . TopLevelSymbolKind , moduleName : Name ) : IrSymbol { \n + error ( "" Should not be called "" ) \n + } \n",[ Plugin API ] Corresponding fox to K / N for # KT - 44100 \n ( cherry picked from commit 3141c0dfc6bcc6583f0a370a1ebb511bf5ec5731 ),429
"compiler \ ir \ serialization . common \ src \ org \ jetbrains \ kotlin \ backend \ common \ serialization \ KotlinIrLinker . kt \n - return moduleDeserializer . deserializeIrSymbol ( signature , topLevelKindToSymbolKind ( kind ) ) \n + return moduleDeserializer . deserializeIrSymbol ( signature , topLevelKindToSymbolKind ( kind ) ) . also { \n + deserializeAllReachableTopLevels ( ) \n + } \n",[ Plugin API ] Fix missed call in ` resolveBySignatureInModule `,429
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ RowExpressionCompiler . java \n + import java . util . HashMap ; \n - ImmutableMap . Builder < LambdaDefinitionExpression , LambdaBytecodeGenerator . CompiledLambda > newCompiledLambdaMap = ImmutableMap . builder ( ) ; \n - newCompiledLambdaMap . putAll ( compiledLambdaMap ) ; \n - newCompiledLambdaMap . putAll ( generateMethodsForLambda ( classDefinition , callSiteBinder , cachedInstanceBinder , function , metadata , sqlFunctionProperties , "" sql "" ) ) ; \n + / / When we inline the input parameters , if the parameter contains lambda , that lambda has already been pre - compiled and exist in compiledLambdaMap . When we pre - compile the function \n + / / it would be compiled again . Do not put these in the new map in this case . \n + Map < LambdaDefinitionExpression , LambdaBytecodeGenerator . CompiledLambda > newCompiledLambdaMap = new HashMap < > ( compiledLambdaMap ) ; \n + generateMethodsForLambda ( classDefinition , callSiteBinder , cachedInstanceBinder , function , metadata , sqlFunctionProperties , "" sql "" ) \n + . forEach ( newCompiledLambdaMap : : putIfAbsent ) ; \n - RowExpressionCompiler newRowExpressionCompiler = new RowExpressionCompiler ( classDefinition , callSiteBinder , cachedInstanceBinder , fieldReferenceCompiler , metadata , sqlFunctionProperties , newCompiledLambdaMap . build ( ) ) ; \n + RowExpressionCompiler newRowExpressionCompiler = new RowExpressionCompiler ( classDefinition , callSiteBinder , cachedInstanceBinder , fieldReferenceCompiler , metadata , sqlFunctionProperties , ImmutableMap . copyOf ( newCompiledLambdaMap ) ) ; \n",Make SQL function work for input parameters with lambda,432
"deleted file \n presto - main \ src \ main \ java \ com \ facebook \ presto \ metadata \ StaticFunctionNamespaceFactory . java \n - / * \n - * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - * you may not use this file except in compliance with the License . \n - * You may obtain a copy of the License at \n - * \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - * \n - * Unless required by applicable law or agreed to in writing , software \n - * distributed under the License is distributed on an "" AS IS "" BASIS , \n - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - * See the License for the specific language governing permissions and \n - * limitations under the License . \n - * / \n - package com . facebook . presto . metadata ; \n - \n - public class StaticFunctionNamespaceFactory \n - implements FunctionNamespaceFactory \n - { \n - @ Override \n - public String getName ( ) \n - { \n - return "" $ static "" ; \n - } \n - \n - @ Override \n - public FunctionHandleResolver getHandleResolver ( ) \n - { \n - return new StaticFunctionNamespaceHandleResolver ( ) ; \n - } \n - } \n",Remove StaticFunctionNamespaceFactory \n StaticFunctionNamespace will be handled separately . It won ' t need to be \n dynamically registered nor will it be used to support dynamic namespaces \n so the factory is not necessary .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n + public static final String OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE = "" optimize _ full _ outer _ join _ with _ coalesce "" ; \n + false ) , \n + booleanProperty ( \n + OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE , \n + "" optimize partition properties for queries using COALESCE + FULL OUTER JOIN "" , \n + featuresConfig . isOptimizeFullOuterJoinWithCoalesce ( ) , \n + \n + public static boolean isOptimizeFullOuterJoinWithCoalesce ( Session session ) \n + { \n + return session . getSystemProperty ( OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE , Boolean . class ) ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n + private boolean optimizeFullOuterJoinWithCoalesce = true ; \n + \n + @ Config ( "" optimizer . optimize - full - outer - join - with - coalesce "" ) \n + public FeaturesConfig setOptimizeFullOuterJoinWithCoalesce ( boolean optimizeFullOuterJoinWithCoalesce ) \n + { \n + this . optimizeFullOuterJoinWithCoalesce = optimizeFullOuterJoinWithCoalesce ; \n + return this ; \n + } \n + \n + public Boolean isOptimizeFullOuterJoinWithCoalesce ( ) \n + { \n + return this . optimizeFullOuterJoinWithCoalesce ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PropertyDerivations . java \n + import static com . facebook . presto . SystemSessionProperties . isOptimizeFullOuterJoinWithCoalesce ; \n - if ( probeProperties . getNodePartitioning ( ) . isPresent ( ) & & buildProperties . getNodePartitioning ( ) . isPresent ( ) ) { \n + if ( isOptimizeFullOuterJoinWithCoalesce ( session ) & & probeProperties . getNodePartitioning ( ) . isPresent ( ) & & buildProperties . getNodePartitioning ( ) . isPresent ( ) ) { \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n - . setConcurrentWritesToPartitionedTableEnabled ( true ) ) ; \n + . setConcurrentWritesToPartitionedTableEnabled ( true ) \n + . setOptimizeFullOuterJoinWithCoalesce ( true ) ) ; \n + . put ( "" optimizer . optimize - full - outer - join - with - coalesce "" , "" false "" ) \n - . setConcurrentWritesToPartitionedTableEnabled ( false ) ; \n + . setConcurrentWritesToPartitionedTableEnabled ( false ) \n + . setOptimizeFullOuterJoinWithCoalesce ( false ) ; \n",Add a session property optimize _ full _ outer _ join _ with _ coalesce,432
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ ExpressionInterpreter . java \n - for ( int i = 0 ; i < argumentValues . size ( ) ; i + + ) { \n - Object value = argumentValues . get ( i ) ; \n - if ( value = = null & & ! functionMetadata . isCalledOnNullInput ( ) ) { \n - return null ; \n + if ( ! functionMetadata . isCalledOnNullInput ( ) ) { \n + for ( int i = 0 ; i < argumentValues . size ( ) ; i + + ) { \n + Object value = argumentValues . get ( i ) ; \n + if ( value = = null ) { \n + return null ; \n + } \n,Check call convention once in ExpressionInterpreter . visitFunctionCall,432
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ RowExpressionInterpreter . java \n - FunctionHandle functionHandle = node . getFunctionHandle ( ) ; \n - FunctionMetadata functionMetadata = metadata . getFunctionManager ( ) . getFunctionMetadata ( node . getFunctionHandle ( ) ) ; \n - if ( value = = null & & ! functionMetadata . isCalledOnNullInput ( ) ) { \n - return null ; \n - } \n + FunctionHandle functionHandle = node . getFunctionHandle ( ) ; \n + FunctionMetadata functionMetadata = metadata . getFunctionManager ( ) . getFunctionMetadata ( node . getFunctionHandle ( ) ) ; \n + if ( ! functionMetadata . isCalledOnNullInput ( ) ) { \n + for ( Object value : argumentValues ) { \n + if ( value = = null ) { \n + return null ; \n + } \n + } \n + } \n + \n,Check call convention once in RowExpressionInterpreter . visitCall,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ HashBuilderOperator . java \n + / / Why not index . getEstimatedSize . toBytes ( ) ? Because we are adding a calculation for the expected size of the PagesHash we will build soon \n + int numPositions = index . getPositionCount ( ) ; \n + long estimatedSizeAfterBuild = index . getEstimatedSize ( ) . toBytes ( ) + PagesHash . getEstimatedAdditionalSize ( numPositions ) ; \n + \n - localRevocableMemoryContext . setBytes ( index . getEstimatedSize ( ) . toBytes ( ) ) ; \n + localRevocableMemoryContext . setBytes ( estimatedSizeAfterBuild ) ; \n - if ( ! localUserMemoryContext . trySetBytes ( index . getEstimatedSize ( ) . toBytes ( ) ) ) { \n + if ( ! localUserMemoryContext . trySetBytes ( estimatedSizeAfterBuild ) ) { \n - localUserMemoryContext . setBytes ( index . getEstimatedSize ( ) . toBytes ( ) ) ; \n + localUserMemoryContext . setBytes ( index . getEstimatedSize ( ) . toBytes ( ) + PagesHash . getEstimatedAdditionalSize ( numPositions ) ) ; \n - / / reserve memory for the lookup source \n - long estimatedSizeAfterBuild = index . getEstimatedSize ( ) . toBytes ( ) + PagesHash . getEstimatedAdditionalSize ( index . getPositionCount ( ) ) ; \n - if ( spillEnabled ) { \n - localRevocableMemoryContext . setBytes ( estimatedSizeAfterBuild ) ; \n - } \n - else { \n - localUserMemoryContext . setBytes ( estimatedSizeAfterBuild ) ; \n - } \n - \n - / / reserve memory for the lookup source \n - long estimatedSizeAfterBuild = index . getEstimatedSize ( ) . toBytes ( ) + PagesHash . getEstimatedAdditionalSize ( index . getPositionCount ( ) ) ; \n - localUserMemoryContext . setBytes ( estimatedSizeAfterBuild ) ; \n - \n presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ TestHashBuilderOperator . java \n - assertEquals ( estimatedFootprintBefore , 46147728 ) ; \n + assertEquals ( estimatedFootprintBefore , 59656384 ) ; \n - assertEquals ( estimatedFootprintBefore , 37887616 ) ; \n + assertEquals ( estimatedFootprintBefore , 51396272 ) ; \n","Revert "" Do not overcommit memory in HashBuilderOperator "" \n This reverts commit fcd6f04d84887d9b51013353567f509d3efcf01e .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ relational \ SqlFunctionUtils . java \n - . map ( VariableReferenceExpression : : getName ) \n + . map ( Optional : : ofNullable ) \n + . map ( variable - > variable . map ( VariableReferenceExpression : : getName ) ) \n - public static RowExpression bindFunctionArguments ( RowExpression function , List < String > argumentNames , List < RowExpression > argumentValues ) \n + public static RowExpression bindFunctionArguments ( RowExpression function , List < Optional < String > > argumentNames , List < RowExpression > argumentValues ) \n - argumentBindings . put ( argumentNames . get ( i ) , argumentValues . get ( i ) ) ; \n + if ( argumentNames . get ( i ) . isPresent ( ) ) { \n + argumentBindings . put ( argumentNames . get ( i ) . get ( ) , argumentValues . get ( i ) ) ; \n + } \n",Fix SQL function compilation failure \n RowExpression compilation for SQL function could fail when the input \n is not referenced in function body .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ RowExpressionCompiler . java \n + import static com . facebook . presto . spi . relation . SpecialFormExpression . Form . IS _ NULL ; \n + import static com . facebook . presto . spi . relation . SpecialFormExpression . Form . OR ; \n + import static com . facebook . presto . spi . type . BooleanType . BOOLEAN ; \n + BytecodeGeneratorContext generatorContext ; \n - BytecodeGeneratorContext generatorContext = new BytecodeGeneratorContext ( \n + generatorContext = new BytecodeGeneratorContext ( \n - return new RowExpressionCompiler ( classDefinition , callSiteBinder , cachedInstanceBinder , fieldReferenceCompiler , metadata , sqlFunctionProperties , newCompiledLambdaMap . build ( ) ) . compile ( \n - function , \n + RowExpressionCompiler newRowExpressionCompiler = new RowExpressionCompiler ( classDefinition , callSiteBinder , cachedInstanceBinder , fieldReferenceCompiler , metadata , sqlFunctionProperties , newCompiledLambdaMap . build ( ) ) ; \n + / / If called on null input , directly use the generated bytecode \n + if ( functionMetadata . isCalledOnNullInput ( ) | | call . getArguments ( ) . isEmpty ( ) ) { \n + return newRowExpressionCompiler . compile ( \n + function , \n + context . getScope ( ) , \n + context . getOutputBlockVariable ( ) , \n + context . getLambdaInterface ( ) ) ; \n + } \n + \n + / / If returns null on null input , generate if ( any input is null , null , generated bytecode ) \n + generatorContext = new BytecodeGeneratorContext ( \n + newRowExpressionCompiler , \n - context . getOutputBlockVariable ( ) , \n - context . getLambdaInterface ( ) ) ; \n + callSiteBinder , \n + cachedInstanceBinder , \n + functionManager ) ; \n + \n + return ( new IfCodeGenerator ( ) ) . generateExpression ( \n + generatorContext , \n + call . getType ( ) , \n + ImmutableList . of ( \n + call . getArguments ( ) . stream ( ) \n + . map ( argument - > new SpecialFormExpression ( IS _ NULL , BOOLEAN , argument ) ) \n + . reduce ( ( a , b ) - > new SpecialFormExpression ( OR , BOOLEAN , a , b ) ) . get ( ) , \n + new ConstantExpression ( null , call . getType ( ) ) , \n + function ) , \n + context . getOutputBlockVariable ( ) ) ; \n",Respect null - call clause in SQL function execution,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ scalar \ ArrayPositionFunction . java \n + import static com . google . common . base . Verify . verify ; \n - checkNotIndeterminate ( result ) ; \n + verify ( result ! = null , "" Array element should not be null "" ) ; \n - checkNotIndeterminate ( result ) ; \n + verify ( result ! = null , "" Array element should not be null "" ) ; \n - checkNotIndeterminate ( result ) ; \n + verify ( result ! = null , "" Array element should not be null "" ) ; \n - checkNotIndeterminate ( result ) ; \n + verify ( result ! = null , "" Array element should not be nul "" ) ; \n - checkNotIndeterminate ( result ) ; \n + if ( result = = null ) { \n + throw new PrestoException ( NOT _ SUPPORTED , "" array _ position does not support elements of complex types that contain null "" ) ; \n + } \n - \n - private static void checkNotIndeterminate ( Boolean equalsResult ) \n - { \n - if ( equalsResult = = null ) { \n - throw new PrestoException ( NOT _ SUPPORTED , "" array _ position does not support arrays with elements that are null or contain null "" ) ; \n - } \n - } \n",Minor refactor of array _ position \n * Remove redundant logic to check null on equal method invocation \n * Clarify error message,432
"presto - thrift - connector - api \ pom . xml \n - < dependency > \n - < groupId > com . facebook . presto < / groupId > \n - < artifactId > presto - main < / artifactId > \n - < scope > test < / scope > \n - < / dependency > \n - \n presto - thrift - connector - api \ src \ test \ java \ com \ facebook \ presto \ connector \ thrift \ api \ TestReadWrite . java \n - import com . facebook . presto . operator . index . PageRecordSet ; \n + import com . facebook . presto . spi . InMemoryRecordSet ; \n + import static com . facebook . presto . spi . type . TypeUtils . readNativeValue ; \n - PageRecordSet inputRecordSet = new PageRecordSet ( types , new Page ( blocks . toArray ( new Block [ blocks . size ( ) ] ) ) ) ; \n + ImmutableList . Builder < List < Object > > recordSet = ImmutableList . builder ( ) ; \n + for ( int i = 0 ; i < records ; i + + ) { \n + List < Object > record = new ArrayList < > ( ) ; \n + for ( int j = 0 ; j < types . size ( ) ; j + + ) { \n + record . add ( readNativeValue ( types . get ( j ) , blocks . get ( j ) , i ) ) ; \n + } \n + recordSet . add ( record ) ; \n + } \n + InMemoryRecordSet inputRecordSet = new InMemoryRecordSet ( types , recordSet . build ( ) ) ; \n",Remove presto - thrift - connector - spi to presto - main,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ StatementAnalyzer . java \n + import java . util . Iterator ; \n - int field = 0 ; \n + Iterator < Field > visibleFieldsIterator = queryDescriptor . getVisibleFields ( ) . iterator ( ) ; \n - Field inputField = queryDescriptor . getFieldByIndex ( field ) ; \n + Field inputField = visibleFieldsIterator . next ( ) ; \n - \n - field + + ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ RelationPlanner . java \n - List < VariableReferenceExpression > oldVariables = plan . getFieldMappings ( ) ; \n - RelationType oldDescriptor = plan . getDescriptor ( ) . withOnlyVisibleFields ( ) ; \n - verify ( targetColumnTypes . length = = oldVariables . size ( ) ) ; \n + RelationType oldRelation = plan . getDescriptor ( ) ; \n + List < VariableReferenceExpression > oldVisibleVariables = oldRelation . getVisibleFields ( ) . stream ( ) \n + . map ( oldRelation : : indexOf ) \n + . map ( plan . getFieldMappings ( ) : : get ) \n + . collect ( toImmutableList ( ) ) ; \n + RelationType oldRelationWithVisibleFields = plan . getDescriptor ( ) . withOnlyVisibleFields ( ) ; \n + verify ( targetColumnTypes . length = = oldVisibleVariables . size ( ) ) ; \n - VariableReferenceExpression inputVariable = oldVariables . get ( i ) ; \n + VariableReferenceExpression inputVariable = oldVisibleVariables . get ( i ) ; \n - Field oldField = oldDescriptor . getFieldByIndex ( i ) ; \n + Field oldField = oldRelationWithVisibleFields . getFieldByIndex ( i ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n + assertQuerySucceeds ( "" WITH t ( x , y , z ) AS ( TABLE region ) SELECT * FROM t "" ) ; \n","Fix named query output does not match column list \n When the named query is a TABLE , as in \n WITH t ( x ) AS ( TABLE qualifiedName ) \n the scope of TABLE will include invisible fields . In RelationPlanner : : addCoercion , the function \n only adds coercion for visible fields . However , when it does ` verify ` , it verifies against all field \n count of the sub query , causing VerifyException when table ` qualifiedName ` has invisible columns . \n Change the code to only look at visible fields instead . \n Also in StatementAnalyzer : : visitTable , the named query should only map column names to visible fields .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n - private boolean colocatedJoinsEnabled ; \n + private boolean colocatedJoinsEnabled = true ; \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n - . setColocatedJoinsEnabled ( false ) \n + . setColocatedJoinsEnabled ( true ) \n - . put ( "" colocated - joins - enabled "" , "" true "" ) \n + . put ( "" colocated - joins - enabled "" , "" false "" ) \n - . setColocatedJoinsEnabled ( true ) \n + . setColocatedJoinsEnabled ( false ) \n",Change default value for colocated _ join to true,432
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ ExpressionInterpreter . java \n + import static java . util . stream . Collectors . toList ; \n - . collect ( Collectors . toList ( ) ) ; \n + . collect ( toList ( ) ) ; \n - . collect ( toImmutableList ( ) ) ; \n + . collect ( toList ( ) ) ; \n,"Fix NullPointerExpression in ExpressionInterpreter : : visitBindExpression \n ImmutableList : : toImmutableList does not allow null input . However , null \n is generally a valid return value when process Expression in ExpressionInterpreter . \n Use Collector . toList ( ) instead .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ PageFunctionCompiler . java \n + import com . facebook . airlift . log . Logger ; \n + private static Logger log = Logger . get ( PageFunctionCompiler . class ) ; \n + \n + if ( log . isDebugEnabled ( ) ) { \n + log . debug ( "" Extracted % d common sub - expressions "" , commonSubExpressions . size ( ) ) ; \n + commonSubExpressions . entrySet ( ) . forEach ( entry - > log . debug ( "" \ t % s = % s "" , entry . getValue ( ) , entry . getKey ( ) ) ) ; \n + log . debug ( "" Rewrote % d projections : % s "" , projections . size ( ) , Joiner . on ( "" , "" ) . join ( projections ) ) ; \n + } \n + if ( log . isDebugEnabled ( ) ) { \n + log . debug ( "" Extracted % d common sub - expressions "" , commonSubExpressions . size ( ) ) ; \n + commonSubExpressions . entrySet ( ) . forEach ( entry - > log . debug ( "" \ t % s = % s "" , entry . getValue ( ) , entry . getKey ( ) ) ) ; \n + log . debug ( "" Rewrote filter : % s "" , filter ) ; \n + } \n",Add extracted common sub - expression to debug level logging,432
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ CommonSubExpressionRewriter . java \n + import static com . facebook . presto . spi . relation . SpecialFormExpression . Form . BIND ; \n - if ( specialForm . getForm ( ) ! = WHEN ) { \n + if ( specialForm . getForm ( ) ! = WHEN & & specialForm . getForm ( ) ! = BIND ) { \n + / / BIND returns a function type rather than a value type \n,Skip BIND in common sub - expression extraction \n BIND returns a function type rather than a value type so it ' s not \n suitable for common sub - expression optimization .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n - public static final String OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE = "" optimize _ full _ outer _ join _ with _ coalesce "" ; \n - booleanProperty ( \n - OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE , \n - "" optimize partition properties for queries using COALESCE + FULL OUTER JOIN "" , \n - featuresConfig . isOptimizeFullOuterJoinWithCoalesce ( ) , \n - false ) , \n - public static boolean isOptimizeFullOuterJoinWithCoalesce ( Session session ) \n - { \n - return session . getSystemProperty ( OPTIMIZE _ FULL _ OUTER _ JOIN _ WITH _ COALESCE , Boolean . class ) ; \n - } \n - \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n - private boolean optimizeFullOuterJoinWithCoalesce = true ; \n - @ Config ( "" optimizer . optimize - full - outer - join - with - coalesce "" ) \n - public FeaturesConfig setOptimizeFullOuterJoinWithCoalesce ( boolean optimizeFullOuterJoinWithCoalesce ) \n - { \n - this . optimizeFullOuterJoinWithCoalesce = optimizeFullOuterJoinWithCoalesce ; \n - return this ; \n - } \n - \n - public Boolean isOptimizeFullOuterJoinWithCoalesce ( ) \n - { \n - return this . optimizeFullOuterJoinWithCoalesce ; \n - } \n - \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PropertyDerivations . java \n - import static com . facebook . presto . SystemSessionProperties . isOptimizeFullOuterJoinWithCoalesce ; \n - if ( isOptimizeFullOuterJoinWithCoalesce ( session ) & & \n - probeProperties . getNodePartitioning ( ) . isPresent ( ) & & \n + if ( probeProperties . getNodePartitioning ( ) . isPresent ( ) & & \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n - . setOptimizeFullOuterJoinWithCoalesce ( true ) \n - . put ( "" optimizer . optimize - full - outer - join - with - coalesce "" , "" false "" ) \n - . setOptimizeFullOuterJoinWithCoalesce ( false ) \n",Remove unnecessary config and session property \n optimizer . optimize - full - outer - join - with - coalesce and the corresponding session \n propoerty optimize _ full _ outer _ join _ with _ coalesce are no longer needed as the \n feature is already fully rolled out and enable it is always more beneficial when \n it could be applied .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ CommonSubExpressionRewriter . java \n + j = i + 1 ; \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ gen \ TestCommonSubExpressionRewritter . java \n - expressions = ImmutableList . of ( rowExpression ( "" x + y "" ) , rowExpression ( "" x + y + x * 2 "" ) , rowExpression ( "" y * 2 "" ) , rowExpression ( "" x * 2 "" ) , rowExpression ( "" x + y * 2 "" ) ) ; \n + expressions = ImmutableList . of ( rowExpression ( "" x + y "" ) , rowExpression ( "" x * 2 "" ) , rowExpression ( "" x + y + x * 2 "" ) , rowExpression ( "" y * 2 "" ) , rowExpression ( "" x + y * 2 "" ) ) ; \n",Fixing a bug in common sub expression partitioning \n The previous implementation could group expressions differently with different order or exprsesions .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ CommonSubExpressionRewriter . java \n + if ( ! cseByLevel . containsKey ( i ) ) { \n + continue ; \n + } \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ gen \ TestCommonSubExpressionRewritter . java \n - . put ( "" add $ cse _ 0 "" , BIGINT ) . build ( ) ) ; \n + . put ( "" add $ cse _ 0 "" , BIGINT ) \n + . put ( "" expr $ cse "" , BIGINT ) . build ( ) ) ; \n + @ Test \n + void testCollectCSEByLevelCaseStatement ( ) \n + { \n + List < RowExpression > expressions = ImmutableList . of ( rowExpression ( "" 1 + CASE WHEN x = 1 THEN y + z WHEN x = 2 THEN z * 2 END "" ) , rowExpression ( "" 2 + CASE WHEN x = 1 THEN y + z WHEN x = 2 THEN z * 2 END "" ) ) ; \n + Map < Integer , Map < RowExpression , VariableReferenceExpression > > cseByLevel = collectCSEByLevel ( expressions ) ; \n + assertEquals ( cseByLevel , ImmutableMap . of ( 3 , ImmutableMap . of ( rowExpression ( "" CASE WHEN x = 1 THEN y + z WHEN x = 2 THEN z * 2 END "" ) , rowExpression ( "" \ "" expr $ cse \ "" "" ) ) ) ) ; \n + } \n + \n","Fix NPE in CommonSubExpressionRewriter triggered by CASE - WHEN expression \n We do not collect common sub - exprssion for WHEN expression because we do not \n have separate code generator for it . As a result , there might be missing levels \n in cseByLevel map .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ PageFunctionCompiler . java \n - type ( void . class ) , \n + type ( cseFields . resultType ) , \n - \n - body . append ( thisVariable ) \n - . append ( cseCompiler . compile ( cse , scope , Optional . empty ( ) ) ) \n - . append ( boxPrimitiveIfNecessary ( scope , type ) ) \n - . putField ( cseFields . resultField ) \n - . append ( thisVariable . setField ( cseFields . evaluatedField , constantBoolean ( true ) ) ) \n - . ret ( ) ; \n + IfStatement ifStatement = new IfStatement ( ) \n + . condition ( thisVariable . getField ( cseFields . evaluatedField ) ) \n + . ifFalse ( new BytecodeBlock ( ) \n + . append ( thisVariable ) \n + . append ( cseCompiler . compile ( cse , scope , Optional . empty ( ) ) ) \n + . append ( boxPrimitiveIfNecessary ( scope , type ) ) \n + . putField ( cseFields . resultField ) \n + . append ( thisVariable . setField ( cseFields . evaluatedField , constantBoolean ( true ) ) ) ) ; \n + \n + body . append ( ifStatement ) \n + . append ( thisVariable ) \n + . getField ( cseFields . resultField ) \n + . retObject ( ) ; \n - IfStatement ifStatement = new IfStatement ( ) \n - . condition ( thisVariable . getField ( fields . evaluatedField ) ) \n - . ifFalse ( new BytecodeBlock ( ) \n - . append ( thisVariable . invoke ( fields . methodName , void . class , context . getVariable ( "" properties "" ) , context . getVariable ( "" page "" ) , context . getVariable ( "" position "" ) ) ) ) ; \n - . append ( ifStatement ) \n - . append ( thisVariable . getField ( fields . resultField ) ) \n + . append ( thisVariable . invoke ( fields . methodName , fields . resultType , context . getVariable ( "" properties "" ) , context . getVariable ( "" page "" ) , context . getVariable ( "" position "" ) ) ) \n",Change common sub - expression methods to return result,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ PageFunctionCompiler . java \n - expressionsWithPositionBuilder . put ( projections . get ( i ) , i ) ; \n + expressionsWithPositionBuilder . put ( projection , i ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ PlanOptimizers . java \n - new SimplifyRowExpressions ( metadata ) . rules ( ) ) ; \n + ImmutableSet . < Rule < ? > > builder ( ) \n + . addAll ( new SimplifyRowExpressions ( metadata ) . rules ( ) ) \n + . add ( new PruneRedundantProjectionAssignments ( ) ) \n + . build ( ) ) ; \n - ImmutableSet . of ( new RemoveRedundantIdentityProjections ( ) ) ) ) ; \n + ImmutableSet . of ( new RemoveRedundantIdentityProjections ( ) , new PruneRedundantProjectionAssignments ( ) ) ) ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n + assertQuery ( \n + "" SELECT x , filter ( x , v - > date ( v ) BETWEEN date ' 2020 - 01 - 01 ' AND date ' 2020 - 06 - 30 ' ) , filter ( x , v - > date ( v ) BETWEEN date ' 2020 - 01 - 01 ' AND date _ add ( ' day ' , 2 , date ' 2020 - 06 - 28 ' ) ) FROM ( VALUES ( array [ ' 2020 - 03 - 01 ' , ' 2020 - 07 - 01 ' ] ) ) t ( x ) "" , \n + "" SELECT array [ ' 2020 - 03 - 01 ' , ' 2020 - 07 - 01 ' ] , array [ ' 2020 - 03 - 01 ' ] , array [ ' 2020 - 03 - 01 ' ] "" ) ; \n",Run PruneRedundantProjectionAssignments after RowExpression change \n We could potentially introduce new redundant projection assignments after \n RowExpression optimizations . So invoke PruneRedundantProjectionAssignments \n after these optimizations . \n * Run PruneRedundantProjectionAssignments after SimplifyRowExpressions \n * Run PruneRedundantProjectionAssignments after connector optimizer rules,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ iterative \ rule \ PruneRedundantProjectionAssignments . java \n + import com . facebook . presto . spi . relation . ConstantExpression ; \n - . collect ( Collectors . partitioningBy ( entry - > entry . getValue ( ) instanceof VariableReferenceExpression ) ) ; \n + . collect ( Collectors . partitioningBy ( entry - > entry . getValue ( ) instanceof VariableReferenceExpression | | entry . getValue ( ) instanceof ConstantExpression ) ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n - public void testRedundantLambda ( ) \n + public void testRedundantProjection ( ) \n + assertQuerySucceeds ( \n + "" SELECT DISTINCT null AS a , NULL AS b , orderstatus FROM ( SELECT orderstatus FROM orders GROUP BY orderstatus ) "" ) ; \n","Do not prune duplicate ConstantExpression \n We added PruneRedundantProjectionAssignments to eliminate duplicate projections \n so PageFunctionCompiler would not need to handle compiling duplicate \n projections . This should only apply to expressions that are not \n InputReferenceExpression ( which maps to VariableReferenceExpression at planning ) \n or ConstantExpression , because those are compiled differently . So it ' s safe to \n avoid prune ConstantExpression here .",432
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ relation \ LambdaDefinitionExpression . java \n - return format ( "" % s . % s ( % s ) "" , call . getFunctionHandle ( ) . getFunctionNamespace ( ) , call . getDisplayName ( ) , String . join ( "" , "" , call . getArguments ( ) . stream ( ) . map ( e - > e . accept ( this , null ) ) . collect ( Collectors . toList ( ) ) ) ) ; \n + return format ( "" % s . % s ( % s ) : % s "" , call . getFunctionHandle ( ) . getFunctionNamespace ( ) , call . getDisplayName ( ) , String . join ( "" , "" , call . getArguments ( ) . stream ( ) . map ( e - > e . accept ( this , null ) ) . collect ( Collectors . toList ( ) ) ) , call . getType ( ) ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n + @ Test \n + public void testTryLambdaWithCast ( ) \n + { \n + assertQuery ( \n + "" SELECT IF ( TRY ( CAST ( a AS INT ) ) IN ( 1 , 5 ) , TRY ( CAST ( b AS DOUBLE ) ) , 0 . 0 ) FROM ( VALUES ( varchar ' 1 ' , varchar ' 2 . 1 ' ) , ( varchar ' 5 ' , varchar ' 3 . 4 ' ) ) t ( a , b ) "" , \n + "" VALUES 2 . 1 , 3 . 4 "" ) ; \n + } \n + \n",Handle CAST in canonicalized LambdaDefinitionExpression \n Include CallExpression return type in canonicalized LambdaDefinitionExpression \n so CAST with same input type would not be mistakenly canonicalized .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ CursorProcessorCompiler . java \n - generateFilterMethod ( sqlFunctionProperties , classDefinition , callSiteBinder , cachedInstanceBinder , compiledLambdaMap , filter , cseFields ) ; \n + RowExpressionCompiler compiler = new RowExpressionCompiler ( \n + classDefinition , \n + callSiteBinder , \n + cachedInstanceBinder , \n + fieldReferenceCompiler ( cseFields ) , \n + metadata , \n + sqlFunctionProperties , \n + compiledLambdaMap ) ; \n + \n + generateFilterMethod ( classDefinition , compiler , filter ) ; \n - generateProjectMethod ( sqlFunctionProperties , classDefinition , callSiteBinder , cachedInstanceBinder , compiledLambdaMap , methodName , projections . get ( i ) , cseFields ) ; \n + generateProjectMethod ( classDefinition , compiler , methodName , projections . get ( i ) ) ; \n - SqlFunctionProperties sqlFunctionProperties , \n - CallSiteBinder callSiteBinder , \n - CachedInstanceBinder cachedInstanceBinder , \n - Map < LambdaDefinitionExpression , CompiledLambda > compiledLambdaMap , \n - RowExpression filter , \n - Map < VariableReferenceExpression , CommonSubExpressionFields > cseFields ) \n + RowExpressionCompiler compiler , \n + RowExpression filter ) \n - RowExpressionCompiler compiler = new RowExpressionCompiler ( \n - classDefinition , \n - callSiteBinder , \n - cachedInstanceBinder , \n - fieldReferenceCompiler ( cseFields ) , \n - metadata , \n - sqlFunctionProperties , \n - compiledLambdaMap ) ; \n - SqlFunctionProperties sqlFunctionProperties , \n - CallSiteBinder callSiteBinder , \n - CachedInstanceBinder cachedInstanceBinder , \n - Map < LambdaDefinitionExpression , CompiledLambda > compiledLambdaMap , \n + RowExpressionCompiler compiler , \n - RowExpression projection , \n - Map < VariableReferenceExpression , CommonSubExpressionFields > cseFields ) \n + RowExpression projection ) \n - RowExpressionCompiler compiler = new RowExpressionCompiler ( \n - classDefinition , \n - callSiteBinder , \n - cachedInstanceBinder , \n - fieldReferenceCompiler ( cseFields ) , \n - metadata , \n - sqlFunctionProperties , \n - compiledLambdaMap ) ; \n","Use the same RowExpressionCompiler in CursorProcessorCompiler \n In CursorProcessorCompiler , we created new RowExpressionCompiler when compiling \n every expression . Now that RowExpressionCompiler is no longer stateless \n ( compiledLambdaMap needs to be updated ) , this becomes problematic . Conceptually , \n RowExpressionCompiler is adding methods to a generated class , and all codegen \n related to the same generated class should use the same RowExpressionCompiler . \n Modify the code accordingly .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ PlanFragmenter . java \n + import com . facebook . presto . spi . plan . ProjectNode . Locality ; \n - return new ProjectNode ( idAllocator . getNextId ( ) , source , assignments . build ( ) ) ; \n + return new ProjectNode ( idAllocator . getNextId ( ) , source , assignments . build ( ) , Locality . LOCAL ) ; \n","Fix ProjectNode locality in PlanFragmenter \n The default Locality when not specified is UNKNOWN , which should be illegal \n after planning . We have a plan sanity check rule to make sure no ProjectNode \n has Locality UNKOWN . Unfortunately this code is added after plan sanity check \n so we didn ' t catch the error .",432
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ relation \ LambdaDefinitionExpression . java \n + import com . facebook . presto . common . block . Block ; \n + if ( literal . getValue ( ) instanceof Block ) { \n + return format ( "" % d "" , literal . hashCode ( ) ) ; \n + } \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n + @ Test \n + public void testMapTransformKeys ( ) \n + { \n + assertQuery ( \n + "" SELECT \ n "" + \n + "" MAP _ KEYS ( TRANSFORM _ KEYS ( features , ( k , v ) - > MAP ( ARRAY [ 1 , 2 ] , ARRAY [ 10 , 20 ] ) [ k ] ) ) as k1 , \ n "" + \n + "" MAP _ KEYS ( TRANSFORM _ KEYS ( features , ( k , v ) - > MAP ( ARRAY [ 1 , 2 ] , ARRAY [ 30 , 40 ] ) [ k ] ) ) as k2 \ n "" + \n + "" FROM ( SELECT MAP ( ARRAY [ 1 ] , ARRAY [ 1 ] ) as features ) "" , \n + "" VALUES ( ( 10 ) , ( 30 ) ) "" ) ; \n + } \n + \n","Fix LambdaDefinitionExpression canonicalization \n When canonicalize the body of the LambdaDefinitionExpression , we might encouter \n Block type constant . Block . toString implementation is not unqiue with respect \n to the uniqueness of the oject value . So change to use hashCode instead .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ RelationPlanner . java \n - Expression expression = Coercer . addCoercions ( row , analysis ) ; \n - expression = ExpressionTreeRewriter . rewriteWith ( new ParameterRewriter ( analysis . getParameters ( ) , analysis ) , expression ) ; \n - \n - expression = ExpressionTreeRewriter . rewriteWith ( new ExpressionRewriter < Void > ( ) { \n + Expression expression = ExpressionTreeRewriter . rewriteWith ( new ExpressionRewriter < Void > ( ) { \n - } , expression ) ; \n + } , row ) ; \n + expression = Coercer . addCoercions ( expression , analysis ) ; \n + expression = ExpressionTreeRewriter . rewriteWith ( new ParameterRewriter ( analysis . getParameters ( ) , analysis ) , expression ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n + \n + / / Dereference in VALUES node \n + assertQuery ( "" SELECT v FROM ( VALUES ( ARRAY [ CAST ( ROW ( 2 , ' a ' ) AS ROW ( int _ field BIGINT , str _ field VARCHAR ) ) ] [ 1 ] . str _ field ) ) AS t ( v ) "" , "" SELECT ' a ' "" ) ; \n","Fix IllegalArgumentException in RelationPlanner \n in RelationPlanner , when we process values node , we would add coercions for \n type only coercion expression . This could change the expression , which does \n not exist in the analysis . For Enum literals , we want to rewrite the \n dereference to enum literal . Previously this is done after the coercion rewrite . \n Thus if the original expression has type only coercions , we could get \n IllegalArgumentException when trying to get the type of the node . Moving the \n dereference to enum rewrite before the coercion should solve this problem .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ gen \ LambdaBytecodeGenerator . java \n - int counter = 0 ; \n + int counter = existingCompiledLambdas . size ( ) ; \n presto - tests \ src \ test \ java \ com \ facebook \ presto \ tests \ TestSqlFunctions . java \n + . setExtraProperties ( ImmutableMap . of ( "" inline - sql - functions "" , "" false "" ) ) \n + @ Test \n + void testSqlFunctionsWithLambda ( ) \n + { \n + assertQuerySucceeds ( "" CREATE FUNCTION testing . test . lambda1 ( x array < int > ) RETURNS int RETURN reduce ( x , 0 , ( s , a ) - > s + a , s - > s ) "" ) ; \n + assertQuerySucceeds ( "" CREATE FUNCTION testing . test . lambda2 ( x array < int > ) RETURNS int RETURN reduce ( x , 0 , ( s , a ) - > if ( a > 0 , s + a , s ) , s - > s ) "" ) ; \n + assertQuerySucceeds ( "" CREATE FUNCTION testing . test . lambda3 ( x array < int > ) RETURNS int RETURN reduce ( x , 0 , ( s , a ) - > if ( a < 0 , s + a , s ) , s - > s ) "" ) ; \n + assertQuery ( "" SELECT testing . test . lambda1 ( array _ union ( x , y ) ) , testing . test . lambda2 ( array _ union ( x , y ) ) , testing . test . lambda3 ( array _ union ( x , y ) ) FROM ( VALUES ( array [ 3 , 5 , 0 , - 4 , - 7 ] , array [ - 1 , 0 , 1 ] ) ) t ( x , y ) "" , "" SELECT - 3 , 9 , - 12 "" ) ; \n + } \n + \n","Fix compiler error in LambdaBytecodeGenerator \n When there are lambda expressions from different SQL functions , and they are \n compiled into the same class due to CSE , we need to make sure the generated \n function names are always unique .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ metadata \ FunctionAndTypeManager . java \n - this . builtInTypeRegistry = new TypeRegistry ( types , featuresConfig ) ; \n - builtInTypeRegistry . setFunctionManager ( this ) ; \n + this . builtInTypeRegistry = new TypeRegistry ( types , featuresConfig , this ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ type \ TypeRegistry . java \n - private FunctionAndTypeManager functionAndTypeManager ; \n + private final FunctionAndTypeManager functionAndTypeManager ; \n - public TypeRegistry ( Set < Type > types , FeaturesConfig featuresConfig ) \n + public TypeRegistry ( Set < Type > types , FeaturesConfig featuresConfig , FunctionAndTypeManager functionAndTypeManager ) \n + this . functionAndTypeManager = requireNonNull ( functionAndTypeManager , "" functionAndTypeManager is null "" ) ; \n - public void setFunctionManager ( FunctionAndTypeManager functionAndTypeManager ) \n - { \n - checkState ( this . functionAndTypeManager = = null , "" TypeRegistry can only be associated with a single FunctionManager "" ) ; \n - this . functionAndTypeManager = requireNonNull ( functionAndTypeManager , "" functionManager is null "" ) ; \n - } \n - \n",Remove setFunctionAndTypeManager from TypeRegistry \n Move FunctionAndTypeManager to constructor,432
"presto - docs \ src \ main \ sphinx \ release . rst \n + release / release - 0 . 243 . 2 \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 238 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced in this release . For more details , go to : issue : ` 15424 ` . \n + \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 239 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced since 0 . 238 . For more details , go to : issue : ` 15424 ` . \n + \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 240 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced since 0 . 238 . For more details , go to : issue : ` 15424 ` . \n + \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 241 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced since 0 . 238 . For more details , go to : issue : ` 15424 ` . \n + \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 242 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced since 0 . 238 . For more details , go to : issue : ` 15424 ` . \n + \n new file \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 243 . 2 . rst \n + = = = = = = = = = = = = = = = \n + Release 0 . 243 . 2 \n + = = = = = = = = = = = = = = = \n + \n + General Changes \n + - - - - - - - - - - - - - - - \n + * Fix LambdaDefinitionExpression canonicalization to correctly canonicalize Block constant ( : issue : ` 15424 ` ) . \n presto - docs \ src \ main \ sphinx \ release \ release - 0 . 243 . rst \n + . . warning : : \n + There is a bug in LambdaDefinitionExpression canonicalization introduced since 0 . 238 . For more details , go to : issue : ` 15424 ` . \n + \n",Add release note for 0 . 243 . 2,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ metadata \ FunctionAndTypeManager . java \n - return QualifiedObjectName . valueOf ( name . getOriginalParts ( ) . get ( 0 ) , name . getOriginalParts ( ) . get ( 1 ) , name . getOriginalParts ( ) . get ( 2 ) ) ; \n + return QualifiedObjectName . valueOf ( name . getParts ( ) . get ( 0 ) , name . getParts ( ) . get ( 1 ) , name . getParts ( ) . get ( 2 ) ) ; \n presto - tests \ src \ test \ java \ com \ facebook \ presto \ tests \ TestSqlFunctions . java \n - assertQuerySucceeds ( "" CREATE FUNCTION testing . test . tan ( x int ) RETURNS double RETURN sin ( x ) / cos ( x ) "" ) ; \n + assertQuerySucceeds ( "" CREATE FUNCTION TESTING . TEST . TAN ( x int ) RETURNS double RETURN sin ( x ) / cos ( x ) "" ) ; \n",Fix QualifiedObjectName instantiation in FunctionAndTypeManager \n QualifiedObjectName expect catalog and schema to be lowercase . \n Use QualifiedName . parts instead of QualifiedName . originalParts when \n instantiating the object in FunctionAndTypeManager .,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ metadata \ BuiltInTypeAndFunctionNamespaceManager . java \n - / / Manually register UNKNOWN type without a verifyTypeClass call since it is a special type that can not be used by functions \n - this . types . put ( UNKNOWN . getTypeSignature ( ) , UNKNOWN ) ; \n - \n + addType ( UNKNOWN ) ; \n",Register UNKNOWN type same way as other types,432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ util \ CompilerUtils . java \n - String className = baseName \n + String className = baseName . length ( ) > 100 ? baseName . substring ( 0 , 100 ) : baseName \n + "" _ "" + suffix . orElseGet ( ( ) - > Instant . now ( ) . atZone ( UTC ) . format ( TIMESTAMP _ FORMAT ) ) \n + "" _ "" + CLASS _ ID . incrementAndGet ( ) ; \n","Limit the codegen class name length \n We use the function signature as class name for codegened classes . \n When ROW types are used , sometimes the name gets extremely long . Since \n we use an AtomicLong as part of the generated class name we should be \n able to guarantee uniqueness without using the full name . So truncate \n at 100 characters .",432
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ aggregation \ AggregationUtils . java \n - sb . append ( CaseFormat . LOWER _ CAMEL . to ( CaseFormat . UPPER _ CAMEL , outputType . toString ( ) ) ) ; \n + sb . append ( CaseFormat . LOWER _ CAMEL . to ( CaseFormat . UPPER _ CAMEL , getAbbreviatedTypeName ( outputType ) ) ) ; \n - sb . append ( CaseFormat . LOWER _ CAMEL . to ( CaseFormat . UPPER _ CAMEL , inputType . toString ( ) ) ) ; \n + sb . append ( CaseFormat . LOWER _ CAMEL . to ( CaseFormat . UPPER _ CAMEL , getAbbreviatedTypeName ( inputType ) ) ) ; \n + private static String getAbbreviatedTypeName ( TypeSignature type ) \n + { \n + String typeName = type . toString ( ) ; \n + if ( typeName . length ( ) > 10 ) { \n + return typeName . substring ( 0 , 10 ) ; \n + } \n + return typeName ; \n + } \n + \n",Generate shorter aggregation function names \n We use return type an input types when generating aggregation function names . \n This could make the name really long ( tens of KB ) when complex ROW types are \n used . This would waste memory and make the generated name unreadable . So only \n keep the first 10 characters of each type parameter when generating the name .,432
"new file \n library \ res \ . nofile \n deleted file \n library \ res \ layout \ main . xml \n - < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n - < LinearLayout xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n - android : layout _ width = "" fill _ parent "" \n - android : layout _ height = "" fill _ parent "" \n - android : orientation = "" vertical "" > \n - \n - < TextView \n - android : layout _ width = "" fill _ parent "" \n - android : layout _ height = "" wrap _ content "" \n - android : text = "" Hello World , ACTIVITY _ ENTRY _ NAME "" / > \n - \n - < / LinearLayout > \n deleted file \n library \ res \ values \ strings . xml \n - < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n - < resources > \n - < string name = "" app _ name "" > ACTIVITY _ ENTRY _ NAME < / string > \n - < / resources > \n",no need for the dummy files to compile,479
"new file \n library \ res \ . nofile \n deleted file \n library \ res \ layout \ main . xml \n - < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n - < LinearLayout xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n - android : layout _ width = "" fill _ parent "" \n - android : layout _ height = "" fill _ parent "" \n - android : orientation = "" vertical "" > \n - \n - < TextView \n - android : layout _ width = "" fill _ parent "" \n - android : layout _ height = "" wrap _ content "" \n - android : text = "" Hello World , ACTIVITY _ ENTRY _ NAME "" / > \n - \n - < / LinearLayout > \n deleted file \n library \ res \ values \ strings . xml \n - < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n - < resources > \n - < string name = "" app _ name "" > ACTIVITY _ ENTRY _ NAME < / string > \n - < / resources > \n",no need for the dummy files to compile,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + if ( null ! = mGestureDetector ) { \n + mGestureDetector . setOnDoubleTapListener ( null ) ; \n + } \n + \n + if ( null ! = mImageView . get ( ) ) { \n + mImageView . get ( ) . setOnTouchListener ( null ) ; \n + } \n + \n,unset listeners on cleanup to avoid events coming asynchronously,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + if ( null ! = mGestureDetector ) { \n + mGestureDetector . setOnDoubleTapListener ( null ) ; \n + } \n + \n + if ( null ! = mImageView . get ( ) ) { \n + mImageView . get ( ) . setOnTouchListener ( null ) ; \n + } \n + \n,unset listeners on cleanup to avoid events coming asynchronously,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + @ Override \n,@ Override is always a good indication in the code,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + @ Override \n,@ Override is always a good indication in the code,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n - ViewTreeObserver viewTreeObserver = ( mImageView = = null | | mImageView . get ( ) = = null ) ? null \n - : mImageView . get ( ) . getViewTreeObserver ( ) ; \n - if ( null ! = viewTreeObserver & & viewTreeObserver . isAlive ( ) ) { \n - viewTreeObserver . removeGlobalOnLayoutListener ( this ) ; \n - } \n - viewTreeObserver = null ; \n + if ( null = = mImageView ) { \n + return ; / / cleanup already done \n + } \n + \n + ViewTreeObserver viewTreeObserver = ( mImageView = = null | | mImageView . get ( ) = = null ) ? null : mImageView . get ( ) . getViewTreeObserver ( ) ; \n + if ( null ! = viewTreeObserver & & viewTreeObserver . isAlive ( ) ) { \n + viewTreeObserver . removeGlobalOnLayoutListener ( this ) ; \n + } \n + viewTreeObserver = null ; \n,"avoid doing cleanup twice , fixes a crash when null mImageView is called",479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + if ( null = = mImageView ) { \n + return ; / / cleanup already done \n + } \n + \n,"avoid doing cleanup twice , fixes a crash when null mImageView is called",479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + \n + / / make sure a pending fling runnable won ' t be run \n + cancelFling ( ) ; \n,the posted fling runnable may also be executed when it shouldn ' t,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + \n + / / make sure a pending fling runnable won ' t be run \n + cancelFling ( ) ; \n,the posted fling runnable may also be executed when it shouldn ' t,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + if ( mScroller . isFinished ( ) ) { \n + return ; / / remaining post that should not be handled \n + } \n + \n library \ src \ uk \ co \ senab \ photoview \ ScrollerProxy . java \n + public abstract boolean isFinished ( ) ; \n + \n + \n + @ Override \n + public boolean isFinished ( ) { \n + return mScroller . isFinished ( ) ; \n + } \n + public boolean isFinished ( ) { \n + return mScroller . isFinished ( ) ; \n + } \n + \n,the post ( Runnable ) may remain as a crash in PhotoViewAttacher sometimes occur after the cancel,479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n + if ( mScroller . isFinished ( ) ) { \n + return ; / / remaining post that should not be handled \n + } \n + \n library \ src \ uk \ co \ senab \ photoview \ ScrollerProxy . java \n + public abstract boolean isFinished ( ) ; \n + \n + \n + @ Override \n + public boolean isFinished ( ) { \n + return mScroller . isFinished ( ) ; \n + } \n + public boolean isFinished ( ) { \n + return mScroller . isFinished ( ) ; \n + } \n + \n,the post ( Runnable ) may remain as a crash in PhotoViewAttacher sometimes occur after the cancel,479
okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Spdy3 . java \n - if ( numberOfPairs < 0 ) { \n + if ( ( numberOfPairs * 2 ) < 0 ) { \n,the numberOfPairs may not be negative when numberOfPairs * 2 is negative,479
okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Spdy3 . java \n + } catch ( OutOfMemoryError e ) { \n + throw new IOException ( e . getMessage ( ) ) ; \n,"When invalid sizes are used to initialize the ArrayList , don ' t crash with an uncaught exception",479
"okhttp - protocols \ src \ main \ java \ com \ squareup \ okhttp \ internal \ spdy \ Spdy3 . java \n - if ( ( numberOfPairs * 2 ) < 0 ) { \n + if ( numberOfPairs < 0 ) { \n + if ( numberOfPairs > 1024 ) { \n + Logger . getLogger ( getClass ( ) . getName ( ) ) . warning ( "" numberOfPairs > 1024 : "" + numberOfPairs ) ; \n + throw ioException ( "" numberOfPairs > 1024 "" ) ; \n + } \n - } catch ( OutOfMemoryError e ) { \n - throw new IOException ( e . getMessage ( ) ) ; \n","safer check for invalid values , without catching OOM",479
"library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n - private ViewTreeObserver mViewTreeObserver ; \n - mViewTreeObserver = imageView . getViewTreeObserver ( ) ; \n - mViewTreeObserver . addOnGlobalLayoutListener ( this ) ; \n + imageView . getViewTreeObserver ( ) . addOnGlobalLayoutListener ( this ) ; \n - if ( null ! = mImageView ) { \n - mImageView . get ( ) . getViewTreeObserver ( ) . removeGlobalOnLayoutListener ( this ) ; \n - } \n - mViewTreeObserver = null ; \n + ViewTreeObserver viewTreeObserver = ( mImageView = = null | | mImageView . get ( ) = = null ) ? null \n + : mImageView . get ( ) . getViewTreeObserver ( ) ; \n + if ( null ! = viewTreeObserver & & viewTreeObserver . isAlive ( ) ) { \n + viewTreeObserver . removeGlobalOnLayoutListener ( this ) ; \n + } \n + viewTreeObserver = null ; \n - mBaseMatrix . postTranslate ( ( viewWidth - drawableWidth ) / 2F , ( viewHeight - drawableHeight ) / 2F ) ; \n + mBaseMatrix . postTranslate ( ( viewWidth - drawableWidth ) / 2F , \n + ( viewHeight - drawableHeight ) / 2F ) ; \n",don ' t keep the ViewObserver as it may not be alive when we need to remove our view \n ( otherwise it crashes when the PhotoView is in a Fragment in a ViewPager and the page is no longer kept ),479
library \ src \ uk \ co \ senab \ photoview \ PhotoViewAttacher . java \n - private ViewTreeObserver mViewTreeObserver ; \n - mViewTreeObserver = imageView . getViewTreeObserver ( ) ; \n - mViewTreeObserver . addOnGlobalLayoutListener ( this ) ; \n + imageView . getViewTreeObserver ( ) . addOnGlobalLayoutListener ( this ) ; \n - if ( null ! = mViewTreeObserver & & mViewTreeObserver . isAlive ( ) ) { \n - mViewTreeObserver . removeGlobalOnLayoutListener ( this ) ; \n + ViewTreeObserver viewTreeObserver = ( mImageView = = null | | mImageView . get ( ) = = null ) ? null : mImageView . get ( ) . getViewTreeObserver ( ) ; \n + if ( null ! = viewTreeObserver & & viewTreeObserver . isAlive ( ) ) { \n + viewTreeObserver . removeGlobalOnLayoutListener ( this ) ; \n - mViewTreeObserver = null ; \n + viewTreeObserver = null ; \n,don ' t keep the ViewObserver as it may not be alive when we need to remove our view \n ( otherwise it crashes when the PhotoView is in a Fragment in a ViewPager and the page is no longer kept ),479
"src \ clj \ clojure \ core . clj \n - Same as ( when ( seq xs ) ( let [ x ( first xs ) ] body ) ) "" \n + Roughly the same as ( when ( seq xs ) ( let [ x ( first xs ) ] body ) ) but xs is evaluated only once "" \n - ` ( when ( seq ~ xs ) \n - ( let [ ~ x ( first ~ xs ) ] \n - ~ @ body ) ) ) ) \n + ` ( when - let [ xs # ( seq ~ xs ) ] \n + ( let [ ~ x ( first xs # ) ] \n + ~ @ body ) ) ) ) \n",avoid double evaluation in when - first \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,480
src \ clj \ clojure \ main . clj \n + * default - data - reader - fn * * default - data - reader - fn * \n,make * default - data - reader - fn * set \ ! - able in REPL \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,480
"src \ clj \ clojure \ core . clj \n - at the root of the classpath . Each such file must contain pairs of \n - symbols , like this : \n + at the root of the classpath . Each such file must contain a literal \n + map of symbols , like this : \n - foo / bar my . project . foo / bar \n - foo / baz my . prjoect / baz \n + { foo / bar my . project . foo / bar \n + foo / baz my . project / baz } \n",CLJ - 973 doc for * data - readers * \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,480
src \ clj \ clojure \ core _ proxy . clj \n - ( valAt ( [ k ] ( v k ) ) \n + ( valAt ( [ k ] ( when ( contains ? pmap k ) ( v k ) ) ) \n test \ clojure \ test _ clojure \ java _ interop . clj \n + ( : missing b ) nil \n + ( : missing b : default ) : default \n + ( get b : missing ) nil \n + ( get b : missing : default ) : default \n + \n,CLJ - 844 NPE calling keyword on map from bean \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,480
src \ clj \ clojure \ core . clj \n - ( let [ i ( . getInterfaces c ) \n + ( let [ i ( seq ( . getInterfaces c ) ) \n - ( not - empty \n - ( if s ( cons s i ) i ) ) ) ) ) \n + ( if s ( cons s i ) i ) ) ) ) \n test \ clojure \ test _ clojure \ java _ interop . clj \n + ( bases java . util . Collection ) \n + ( list java . lang . Iterable ) \n + ( bases java . lang . Object ) \n + nil \n + ( bases java . lang . Comparable ) \n + nil \n,"bases should return a seq , not a Java array \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >",480
"src \ clj \ clojure \ instant . clj \n - after first validting that those arguments are in range and otherwise \n + after first validating that those arguments are in range and otherwise \n - "" Construct a java . util . Calendar , which preserves , preserving the timezone \n + "" Construct a java . util . Calendar , preserving the timezone \n - milliseconds since the epoch , GMT . "" \n + milliseconds since the epoch , UTC . "" \n",typo fixes \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,480
src \ clj \ clojure \ genclass . clj \n - It ' s return value is ignored . \n + Its return value is ignored . \n,It ' s just a small typo \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,480
"src \ clj \ clojure \ core _ print . clj \n + ( defn print - simple [ o , ^ Writer w ] \n + ( print - meta o w ) \n + ( . write w ( str o ) ) ) \n + \n - ( print - method ( vary - meta o # ( dissoc % : type ) ) w ) ) \n + ( if ( instance ? clojure . lang . IObj o ) \n + ( print - method ( vary - meta o # ( dissoc % : type ) ) w ) \n + ( print - simple o w ) ) ) \n - ( defn print - simple [ o , ^ Writer w ] \n - ( print - meta o w ) \n - ( . write w ( str o ) ) ) \n - \n test \ clojure \ test _ clojure \ printer . clj \n - "" hi "" ) ) \n + "" hi "" ) ) \n + \n + ( def ^ { : foo : anything } var - with - meta 42 ) \n + ( def ^ { : type : anything } var - with - type 666 ) \n + \n + ( deftest print - var \n + ( are [ x s ] ( = s ( pr - str x ) ) \n + # ' pr - str "" # ' clojure . core / pr - str "" \n + # ' var - with - meta "" # ' clojure . test - clojure . printer / var - with - meta "" \n + # ' var - with - type "" # ' clojure . test - clojure . printer / var - with - type "" ) ) \n + \n + ( deftest print - meta \n + ( are [ x s ] ( binding [ * print - meta * true ] \n + ( let [ pstr ( pr - str x ) ] \n + ( and ( . endsWith pstr s ) \n + ( . startsWith pstr "" ^ "" ) \n + ( . contains pstr ( pr - str ( meta x ) ) ) ) ) ) \n + # ' pr - str "" # ' clojure . core / pr - str "" \n + # ' var - with - meta "" # ' clojure . test - clojure . printer / var - with - meta "" \n + # ' var - with - type "" # ' clojure . test - clojure . printer / var - with - type "" ) ) \n + \n",CLJ - 1039 tolerate misleading : type metadata on var when printing \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,480
"src \ clj \ clojure \ pprint \ pretty _ writer . clj \n - ( p - write - char this x ) ) ) ) \n + ( p - write - char this x ) ) ) \n + ( [ x off len ] \n + ( . write this ( subs ( str x ) off ( + off len ) ) ) ) ) \n test \ clojure \ test _ clojure \ pprint \ test _ pretty . clj \n + ( deftest test - pprint - calendar \n + ( let [ calendar ( doto ( java . util . GregorianCalendar . 2014 3 29 14 0 0 ) \n + ( . setTimeZone ( java . util . TimeZone / getTimeZone "" GMT "" ) ) ) \n + calendar - str ( with - out - str ( pprint calendar ) ) ] \n + ( is ( = calendar - str "" # inst \ "" 2014 - 04 - 29T14 : 00 : 00 . 000 + 00 : 00 \ "" \ n "" ) \n + "" calendar object pretty prints "" ) ) ) \n + \n",CLJ - 1390 pprint GregorianCalendar \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,480
"src \ jvm \ clojure \ lang \ PersistentList . java \n + public String toString ( ) { \n + return "" ( ) "" ; \n + } \n + \n test \ clojure \ test _ clojure \ string . clj \n + \n + ( deftest empty - collections \n + ( is ( = "" ( ) "" ( str ( ) ) ) ) \n + ( is ( = "" { } "" ( str { } ) ) ) \n + ( is ( = "" [ ] "" ( str [ ] ) ) ) ) \n",CLJ - 1653 - toString ( ) for EmptyList \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,480
"src \ clj \ clojure \ core _ deftype . clj \n - : load - ns - if true , importing the record class will cause the \n - namespace in which the record was defined to be loaded . \n + : load - ns - if true , importing the type class will cause the \n + namespace in which the type was defined to be loaded . \n",deftype docstring typo \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,480
"src \ jvm \ clojure \ lang \ Compiler . java \n + for ( java . lang . reflect . Method m : c . getMethods ( ) ) \n + if ( fieldName . equals ( m . getName ( ) ) & & ( Modifier . isStatic ( m . getModifiers ( ) ) ) ) \n + throw new IllegalArgumentException ( "" No matching method "" + \n + fieldName + \n + "" found taking 0 args for "" + \n + c ) ; \n - throw new IllegalArgumentException ( "" No matching method : "" + methodName ) ; \n + throw new IllegalArgumentException ( "" No matching method "" + methodName + "" found taking "" \n + + args . count ( ) + "" args for "" + c ) ; \n src \ jvm \ clojure \ lang \ Reflector . java \n - private static String noMethodReport ( String methodName , Object target ) { \n - return "" No matching method found : "" + methodName \n + private static String noMethodReport ( String methodName , Object target , Object [ ] args ) { \n + return "" No matching method "" + methodName + "" found taking "" + args . length + "" args "" \n + ( target = = null ? "" "" : "" for "" + target . getClass ( ) ) ; \n - throw new IllegalArgumentException ( noMethodReport ( methodName , target ) ) ; \n + throw new IllegalArgumentException ( noMethodReport ( methodName , target , args ) ) ; \n - throw new IllegalArgumentException ( noMethodReport ( methodName , target ) ) ; \n + throw new IllegalArgumentException ( noMethodReport ( methodName , target , args ) ) ; \n test \ clojure \ test _ clojure \ errors . clj \n + ( deftest compile - error - examples \n + ( are [ form errtype re ] ( thrown - with - msg ? errtype re ( eval form ) ) \n + ' ( Long / parseLong ) Exception # "" No matching method . * taking 0 args "" \n + ' ( Long / parseLong : a : b : c ) Exception # "" No matching method . * taking 3 args "" \n + ' ( . jump "" foo "" 1 ) Exception # "" No matching method . * taking 1 arg "" ) ) \n + \n",better error messages : \n - report zero - arg static invoke as a method arity error instead of a field error when a method with some other exists \n - report needed arity when a method is not found \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,483
src \ jvm \ clojure \ lang \ PersistentHashSet . java \n - PersistentHashSet ret = EMPTY ; \n + ITransientSet ret = ( ITransientSet ) EMPTY . asTransient ( ) ; \n - ret = ( PersistentHashSet ) ret . cons ( init [ i ] ) ; \n + ret = ( ITransientSet ) ret . conj ( init [ i ] ) ; \n - return ret ; \n + return ( PersistentHashSet ) ret . persistent ( ) ; \n - PersistentHashSet ret = EMPTY ; \n + ITransientSet ret = ( ITransientSet ) EMPTY . asTransient ( ) ; \n - ret = ( PersistentHashSet ) ret . cons ( key ) ; \n + ret = ( ITransientSet ) ret . conj ( key ) ; \n + + i ; \n - return ret ; \n + return ( PersistentHashSet ) ret . persistent ( ) ; \n - PersistentHashSet ret = EMPTY ; \n + ITransientSet ret = ( ITransientSet ) EMPTY . asTransient ( ) ; \n - ret = ( PersistentHashSet ) ret . cons ( items . first ( ) ) ; \n + ret = ( ITransientSet ) ret . conj ( items . first ( ) ) ; \n - return ret ; \n + return ( PersistentHashSet ) ret . persistent ( ) ; \n,CLJ - 1384 : Use transients in PersistentHashSet . createWithCheck \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,483
"src \ jvm \ clojure \ lang \ Compiler . java \n - \n - String basename = ( enclosingMethod ! = null ? \n - enclosingMethod . objx . name \n - : ( munge ( currentNS ( ) . name . name ) ) ) + "" $ "" ; \n - \n - Symbol nm = null ; \n - \n - if ( RT . second ( form ) instanceof Symbol ) { \n - nm = ( Symbol ) RT . second ( form ) ; \n - if ( name = = null ) \n - name = nm . name + "" _ _ "" + RT . nextID ( ) ; \n - else \n - name + = "" _ _ "" + nm . name + "" _ _ "" + RT . nextID ( ) ; \n - } else { \n - if ( name = = null ) \n - name = "" fn _ _ "" + RT . nextID ( ) ; \n - else if ( enclosingMethod ! = null ) \n - name + = "" _ _ "" + RT . nextID ( ) ; \n - } \n - \n - String simpleName = munge ( name ) . replace ( "" . "" , "" _ DOT _ "" ) ; \n - \n + String basename = enclosingMethod ! = null ? \n + ( enclosingMethod . objx . name + "" $ "" ) \n + : / / "" clojure . fns . "" + \n + ( munge ( currentNS ( ) . name . name ) + "" $ "" ) ; \n + if ( RT . second ( form ) instanceof Symbol ) \n + name = ( ( Symbol ) RT . second ( form ) ) . name ; \n + String simpleName = name ! = null ? \n + ( munge ( name ) . replace ( "" . "" , "" _ DOT _ "" ) \n + + ( enclosingMethod ! = null ? "" _ _ "" + RT . nextID ( ) : "" "" ) ) \n + : ( "" fn "" \n + + "" _ _ "" + RT . nextID ( ) ) ; \n - if ( nm ! = null ) \n + if ( RT . second ( form ) instanceof Symbol ) \n + Symbol nm = ( Symbol ) RT . second ( form ) ; \n","Revert "" Fix CLJ - 1330 : make top - level named functions classnames don ' t clash with def ' ed function classnames "" \n This reverts commit f149260c14a75367dc9eba91cbe9b78110113566 .",483
"src \ clj \ clojure \ core . clj \n - ( defn - already - compiled ? [ lib ] \n - ( let [ path ( subs ( root - resource lib ) 1 ) \n - clj - path ( str path "" . clj "" ) \n - class - path ( str path "" _ _ init . class "" ) \n - loader ( clojure . lang . RT / baseLoader ) \n - compiled - file ( java . io . File . ( str * compile - path * "" / "" class - path ) ) \n - clj - url ( . getResource loader clj - path ) ] \n - ( or ( and ( . exists compiled - file ) \n - ( or ( nil ? clj - url ) \n - ( > ( clojure . lang . RT / lastModified ( - > compiled - file . toURI . toURL ) class - path ) \n - ( clojure . lang . RT / lastModified clj - url clj - path ) ) ) ) \n - ( . getResource loader class - path ) ) ) ) \n - \n - loaded ( and ( contains ? @ * loaded - libs * lib ) \n - ( or ( not * compile - files * ) \n - ( already - compiled ? lib ) ) ) \n + loaded ( contains ? @ * loaded - libs * lib ) \n","Revert "" CLJ - 1544 force reloading of namespaces during AOT compilation "" \n This reverts commit e5a104e894ed82f244d69513918d570cee5df67d .",483
test \ clojure \ test _ clojure \ vectors . clj \n + ( is ( = [ 1 2 ] ( vec ( first { 1 2 } ) ) ) ) \n,test for CLJ - 1637 \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >,483
src \ clj \ clojure \ spec \ test . clj \n - ( let [ spec ( s / get - spec v ) \n - { : keys [ raw wrapped ] } ( get @ instrumented - vars v ) \n - current @ v \n - to - wrap ( if ( = wrapped current ) raw current ) \n - ospec ( or ( instrument - choose - spec spec s opts ) \n + ( when - not ( - > v meta : macro ) \n + ( let [ spec ( s / get - spec v ) \n + { : keys [ raw wrapped ] } ( get @ instrumented - vars v ) \n + current @ v \n + to - wrap ( if ( = wrapped current ) raw current ) \n + ospec ( or ( instrument - choose - spec spec s opts ) \n - ofn ( instrument - choose - fn to - wrap ospec s opts ) \n - checked ( spec - checking - fn v ofn ospec ) ] \n - ( alter - var - root v ( constantly checked ) ) \n - ( swap ! instrumented - vars assoc v { : raw to - wrap : wrapped checked } ) ) \n - ( - > sym v ) ) ) \n + ofn ( instrument - choose - fn to - wrap ospec s opts ) \n + checked ( spec - checking - fn v ofn ospec ) ] \n + ( alter - var - root v ( constantly checked ) ) \n + ( swap ! instrumented - vars assoc v { : raw to - wrap : wrapped checked } ) \n + ( - > sym v ) ) ) ) ) \n - ( let [ f ( or f ( when v @ v ) ) \n - re - inst ? ( and v ( seq ( unstrument s ) ) true ) ] \n + ( let [ re - inst ? ( and v ( seq ( unstrument s ) ) true ) \n + f ( or f ( when v @ v ) ) ] \n,"don’t instrument macros , use uninstrumented fn under test \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >",483
"src \ clj \ clojure \ core . clj \n + ( load "" spec "" ) \n + \n src \ jvm \ clojure \ lang \ Compiler . java \n + ISeq args = RT . cons ( form , RT . cons ( Compiler . LOCAL _ ENV . get ( ) , form . next ( ) ) ) ; \n - return v . applyTo ( RT . cons ( form , RT . cons ( LOCAL _ ENV . get ( ) , form . next ( ) ) ) ) ; \n + final Namespace checkns = Namespace . find ( Symbol . intern ( "" clojure . spec "" ) ) ; \n + if ( checkns ! = null ) \n + { \n + final Var check = Var . find ( Symbol . intern ( "" clojure . spec / macroexpand - check "" ) ) ; \n + if ( ( check ! = null ) & & ( check . isBound ( ) ) ) \n + check . applyTo ( RT . cons ( v , RT . list ( args ) ) ) ; \n + } \n + Symbol . intern ( "" clojure . spec "" ) ; \n + } \n + catch ( IllegalArgumentException e ) \n + { \n + throw new CompilerException ( ( String ) SOURCE _ PATH . deref ( ) , lineDeref ( ) , columnDeref ( ) , e ) ; \n + } \n + try \n + { \n + return v . applyTo ( args ) ; \n - } \n - else \n + } else \n",check specs on macroexpand \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >,483
src \ clj \ clojure \ spec \ test . clj \n - ( assoc - in ret [ : shrunk : result ] shrunk - explain ) ) ) ) \n + ( assoc - in ret [ : shrunk : result ] shrunk - explain ) \n + ret ) ) ) \n,fix test reporting \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >,483
src \ clj \ clojure \ spec \ test . clj \n - [ { : keys [ s f spec ] } { : keys [ result - callback ] : as opts } ] \n - ( cond \n - ( nil ? f ) \n - { : type : no - fn : sym s : spec spec } \n - \n - ( : args spec ) \n - ( let [ tcret ( check - fn f spec opts ) ] \n - ( make - test - result s spec tcret ) ) \n - \n - : default \n - { : type : no - argspec : sym s : spec spec } ) ) \n + [ { : keys [ s f v spec ] } { : keys [ result - callback ] : as opts } ] \n + ( when v ( unstrument s ) ) \n + ( try \n + ( cond \n + ( nil ? f ) \n + { : type : no - fn : sym s : spec spec } \n + \n + ( : args spec ) \n + ( let [ tcret ( check - fn f spec opts ) ] \n + ( make - test - result s spec tcret ) ) \n + \n + : default \n + { : type : no - argspec : sym s : spec spec } ) \n + ( finally \n + ( when v ( instrument s ) ) ) ) ) \n - : f ( when v @ v ) \n + : v v \n,unstrument var under test for duration of test \n Signed - off - by : Stuart Halloway < stu @ cognitect . com > \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >,483
"src \ clj \ clojure \ core _ print . clj \n + ( defn StackTraceElement - > vec \n + "" Constructs a data representation for a StackTraceElement "" \n + { : added "" 1 . 9 "" } \n + [ ^ StackTraceElement o ] \n + [ ( symbol ( . getClassName o ) ) ( symbol ( . getMethodName o ) ) ( . getFileName o ) ( . getLineNumber o ) ] ) \n + \n - ( let [ m { : type ( class t ) \n + ( let [ m { : type ( symbol ( . getName ( class t ) ) ) \n - : at ( get ( . getStackTrace t ) 0 ) } \n + : at ( StackTraceElement - > vec ( get ( . getStackTrace t ) 0 ) ) } \n - : trace ( vec ( . getStackTrace ^ Throwable ( or root o ) ) ) } \n + : trace ( vec ( map StackTraceElement - > vec \n + ( . getStackTrace ^ Throwable ( or root o ) ) ) ) } \n test \ clojure \ test _ clojure \ printer . clj \n - ( defn ^ : private ednize - stack - trace - element \n - [ ^ StackTraceElement ste ] \n - [ ( symbol ( . getClassName ste ) ) \n - ( symbol ( . getMethodName ste ) ) \n - ( . getFileName ste ) \n - ( . getLineNumber ste ) ] ) \n - \n - ( defn ^ : private ednize - throwable - data \n - [ throwable - data ] \n - ( - > throwable - data \n - ( update : via ( fn [ vias ] \n - ( map ( fn [ via ] \n - ( - > via \n - ( update : type # ( symbol ( . getName % ) ) ) \n - ( update : at ednize - stack - trace - element ) ) ) \n - vias ) ) ) \n - ( update : trace # ( map ednize - stack - trace - element % ) ) ) ) \n - \n - ( are [ e ] ( = ( - > e Throwable - > map ednize - throwable - data ) \n + ( are [ e ] ( = ( - > e Throwable - > map ) \n + \n + \n",make StackTraceElement into data \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >,483
src \ clj \ clojure \ spec \ test . clj \n - ( nil ? f ) \n + ( or ( nil ? f ) ( some - > v meta : macro ) ) \n,fix guard in check - 1 \n Signed - off - by : Rich Hickey < richhickey @ gmail . com >,483
src \ jvm \ clojure \ lang \ Compiler . java \n - catch ( IllegalArgumentException e ) \n + catch ( Exception e ) \n,CLJ - 2128 spec failure during macroexpand should wrap in compiler exception with location info,483
"src \ clj \ clojure \ reflect \ java . clj \n - ( require ' [ clojure . set : as set ] \n + ( require ' [ clojure . datafy : refer ( datafy ) ] \n + ' [ clojure . set : as set ] \n - ( - > ( typename t ) \n - ( str / replace "" [ ] "" "" < > "" ) \n - ( symbol ) ) ) \n + ( cond - > \n + ( - > ( typename t ) \n + ( str / replace "" [ ] "" "" < > "" ) \n + ( symbol ) ) \n + ( class ? t ) ( with - meta { ' clojure . core . protocols / datafy \n + ( fn [ _ ] ( datafy t ) ) } ) ) ) \n + ( defn - typeref - > class \n + [ typeref classloader ] \n + ( if ( class ? typeref ) \n + typeref \n + ( clojure . lang . RT / classForName ( typename typeref ) false classloader ) ) ) \n + \n - ( let [ cls ( clojure . lang . RT / classForName ( typename typeref ) false classloader ) ] \n + ( let [ cls ( typeref - > class typeref classloader ) ] \n","CLJ - 2429 datafy JavaReflector , fix do - reflect for arrays and primitives \n Signed - off - by : Stuart Halloway < stu @ cognitect . com >",483
"src \ clj \ clojure \ core . clj \n + ( defn requiring - resolve \n + "" Resolves namespace - qualified sym per ' resolve ' . If initial resolve \n + fails , attempts to require sym ' s namespace and retries . "" \n + { : added "" 1 . 10 "" } \n + [ sym ] \n + ( if ( qualified - symbol ? sym ) \n + ( or ( resolve sym ) \n + ( do ( - > sym namespace symbol require ) \n + ( resolve sym ) ) ) \n + ( throw ( IllegalArgumentException . ( str "" Not a qualified symbol : "" sym ) ) ) ) ) \n + \n src \ clj \ clojure \ datafy . clj \n - ( : require [ clojure . core . protocols : as p ] \n - [ clojure . reflect : as refl ] ) ) \n + ( : require [ clojure . core . protocols : as p ] ) ) \n - ( let [ { : keys [ members ] : as ret } ( refl / reflect c ) ] \n - ( assoc ret : name ( - > c . getName symbol ) : members ( - > > members ( group - by : name ) sortmap ) ) ) ) ) \n + ( let [ { : keys [ members ] : as ret } ( ( requiring - resolve ' clojure . reflect / reflect ) c ) ] \n + ( assoc ret : name ( - > c . getName symbol ) : members ( - > > members ( group - by : name ) sortmap ) ) ) ) ) \n","CLJ - 2432 lazy require reflect in datafy , add requiring - resolve",483
pom . xml \n - < version > 1 . 11 . 0 - master - SNAPSHOT < / version > \n + < version > 1 . 10 . 2 - master - SNAPSHOT < / version > \n - < version > 0 . 2 . 176 < / version > \n + < version > 0 . 2 . 187 < / version > \n,"latest spec , prep for 1 . 10 . 2",483
src \ clj \ clojure \ core . clj \n - ( let [ locklocal # lockee # ] \n - ( monitor - enter locklocal # ) \n - ( try \n - ~ @ body \n - ( finally \n - ( monitor - exit locklocal # ) ) ) ) ) ) ) \n + ( monitor - enter lockee # ) \n + ~ @ body \n + ( finally \n + ( monitor - exit lockee # ) ) ) ) ) \n,"Revert "" CLJ - 1472 - Ensure monitor object is on stack so its easier to analyze in the face of locals clearing "" \n This reverts commit 989a3b98d468e57e489a11e765f256eab90ec417 .",483
"deleted file \n library \ res \ values - large \ defaults . xml \n - < ! - - \n - Copyright 2011 The Android Open Source Project \n - \n - Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - you may not use this file except in compliance with the License . \n - You may obtain a copy of the License at \n - \n - http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - \n - Unless required by applicable law or agreed to in writing , software \n - distributed under the License is distributed on an "" AS IS "" BASIS , \n - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - See the License for the specific language governing permissions and \n - limitations under the License . \n - - - > \n - \n - < resources > \n - \n - < bool name = "" isTablet "" > true < / bool > \n - \n - < / resources > \n deleted file \n library \ res \ values \ defaults . xml \n - < ! - - \n - Copyright 2011 The Android Open Source Project \n - \n - Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - you may not use this file except in compliance with the License . \n - You may obtain a copy of the License at \n - \n - http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - \n - Unless required by applicable law or agreed to in writing , software \n - distributed under the License is distributed on an "" AS IS "" BASIS , \n - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - See the License for the specific language governing permissions and \n - limitations under the License . \n - - - > \n - \n - < resources > \n - \n - < bool name = "" isTablet "" > false < / bool > \n - \n - < / resources > \n",Remove unused defaults . xml files from values and values - large . \n We don ' t need these XML files anymore because we are not using a tablet boolean to resize our SlidingMenu view .,499
"library \ src \ com \ slidingmenu \ lib \ CustomViewAbove . java \n - import android . graphics . Bitmap ; \n - import android . graphics . Canvas ; \n - import android . graphics . Color ; \n - import android . graphics . Paint ; \n + import android . graphics . * ; \n + / * * \n + * Pads our content window so that it fits within the system windows . \n + * @ param insets The insets by which we need to offset our view . \n + * @ return True since we handled the padding change . \n + * / \n + @ Override \n + protected boolean fitSystemWindows ( Rect insets ) { \n + \n + if ( mContent ! = null ) { \n + int leftPadding = mContent . getPaddingLeft ( ) + insets . left ; \n + int rightPadding = mContent . getPaddingRight ( ) + insets . right ; \n + int topPadding = mContent . getPaddingTop ( ) + insets . top ; \n + int bottomPadding = mContent . getPaddingBottom ( ) + insets . bottom ; \n + mContent . setPadding ( leftPadding , topPadding , rightPadding , bottomPadding ) ; \n + return true ; \n + } \n + \n + return super . fitSystemWindows ( insets ) ; \n + } \n + \n library \ src \ com \ slidingmenu \ lib \ SlidingMenu . java \n + private boolean mSlidingEnabled ; \n + \n - RelativeLayout . LayoutParams params = ( ( RelativeLayout . LayoutParams ) mViewBehind . getLayoutParams ( ) ) ; \n - int bottom = params . bottomMargin ; \n - int left = params . leftMargin ; \n - int right = params . rightMargin ; \n - params . setMargins ( left , insets . top , right , bottom ) ; \n + \n + int leftPadding = getPaddingLeft ( ) + insets . left ; \n + int rightPadding = getPaddingRight ( ) + insets . right ; \n + int topPadding = getPaddingTop ( ) + insets . top ; \n + int bottomPadding = getPaddingBottom ( ) + insets . bottom ; \n + this . setPadding ( leftPadding , topPadding , rightPadding , bottomPadding ) ; \n + \n","Fixing the bugs in the SlidingMenu fitSystemWindow code . We only need to take care of the content view , not everything else .",499
library \ src \ com \ slidingmenu \ lib \ SlidingMenu . java \n - if ( b ) { \n + boolean isTablet = getResources ( ) . getBoolean ( R . bool . isTablet ) ; \n + if ( b & & ! isTablet ) { \n,"We need to check if the device is a tablet , because the status bar could be at the bottom . \n Simply add a check in setFitsSysWindows to see if the device we ' re running on is a tablet .",499
library \ src \ com \ slidingmenu \ lib \ SlidingMenu . java \n - if ( b ) { \n + boolean isTablet = getResources ( ) . getBoolean ( R . bool . isTablet ) ; \n + if ( b & & ! isTablet ) { \n,"We need to check if the device is a tablet , because the status bar could be at the top . \n Simply add a check in setFitsSysWindows to see if the device we ' re running on is a tablet .",499
example \ project . properties \n - target = android - 14 \n + target = Google Inc . : Google APIs : 16 \n library \ project . properties \n - target = Google Inc . : Google APIs : 10 \n + target = Google Inc . : Google APIs : 16 \n,"squash ! We need to check if the device is a tablet , because the status bar could be at the bottom . \n Reverting changes in properties files",499
example \ project . properties \n - target = android - 14 \n + target = Google Inc . : Google APIs : 16 \n library \ project . properties \n - target = Google Inc . : Google APIs : 10 \n + target = Google Inc . : Google APIs : 16 \n,"squash ! We need to check if the device is a tablet , because the status bar could be at the top . \n Reverting changes in properties files",499
new file \n core \ java \ android \ os \ incremental \ OWNERS \n + # Bug component : 554432 \n + alexbuy @ google . com \n + schfan @ google . com \n + toddke @ google . com \n + zyy @ google . com \n,Add OWNERS for incremental \n Change - Id : Id0acdfff82c625fe05c6966956d1478ce8355a71,512
core \ java \ android \ util \ OWNERS \n - per - file TypedValue . java = file : / core / java / android / content / res / OWNERS \n + per - file TypedValue . java = file : / core / java / android / content / res / OWNERS \n + \n + per - file PackageUtils . java = file : / core / java / android / content / pm / OWNERS \n new file \n core \ java \ android \ util \ apk \ OWNERS \n + include / core / java / android / content / pm / OWNERS \n,Add to owners \n Change - Id : Ib4f60234f2633f954ab86f7dbf6c21439ee5b24d,512
core \ java \ android \ content \ OWNERS \n + per - file IntentFilter . java = toddke @ google . com \n + per - file IntentFilter . java = patb @ google . com \n + per - file Intent . java = toddke @ google . com \n + per - file Intent . java = patb @ google . com \n,add new owners for IntentFilter and Intent \n Change - Id : I08cf0635715290a3baba049a81b35bcad0eddb03,512
new file \n services \ tests \ shortcutmanagerutils \ OWNERS \n + include / services / core / java / com / android / server / pm / OWNERS \n,Add owners for shortcut utils \n Change - Id : I1eb5cffa074c514345ccb267ab7b06e363538470,512
services \ OWNERS \n + \n + per - file java / com / android / server / * = toddke @ google . com \n,Add toddke to owners for system server \n Change - Id : I16251c6d90d676b3baf8163b53f584c7134697dc,512
new file \n core \ java \ android \ content \ integrity \ OWNERS \n + # Bug component : 722021 \n + \n + toddke @ android . com \n + toddke @ google . com \n + patb @ google . com \n core \ tests \ coretests \ src \ android \ content \ OWNERS \n + per - file AssetTest . java = file : / core / java / android / content / res / OWNERS \n - per - file * Shortcut * = file : / core / java / android / content / pm / SHORTCUT _ OWNERS \n + per - file * Shortcut * = file : / core / java / android / content / pm / SHORTCUT _ OWNERS \n new file \n core \ tests \ coretests \ src \ android \ content \ integrity \ OWNERS \n + include / core / java / android / content / integrity / OWNERS \n core \ tests \ coretests \ src \ android \ content \ pm \ OWNERS \n + include / core / java / android / content / pm / OWNERS \n + \n - per - file SigningDetailsTest . java = mpgroover @ google . com \n + per - file SigningDetailsTest . java = mpgroover @ google . com \n new file \n core \ tests \ coretests \ src \ android \ content \ res \ OWNERS \n + include / core / java / android / content / res / OWNERS \n,Add owners \n Change - Id : If3e8e500c4a5de47ec76cc19413546b736feb5f9,512
"core \ java \ android \ app \ OWNERS \n + # PackageManager \n + per - file ApplicationPackageManager . java = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file InstantAppResolverService . java = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file LoadedApk . java = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file PackageDeleteObserver . java = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file PackageInstallObserver . java = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file EphemeralResolveInfo . aidl = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file IEphemeralResolver . aidl = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file IInstantAppResolver . aidl = file : / services / core / java / com / android / server / pm / OWNERS \n + per - file InstantAppResolveInfo . aidl = file : / services / core / java / com / android / server / pm / OWNERS \n + \n - per - file ResourcesManager = rtmitchell @ google . com , toddke @ google . com \n + per - file ResourcesManager . java = rtmitchell @ google . com , toddke @ google . com \n",add ownership \n Change - Id : I1399a560422d2138c1480d02e099b387a74c6800,512
new file \n apct - tests \ perftests \ core \ src \ android \ os \ OWNERS \n + per - file PackageParsingPerfTest . kt = file : / services / core / java / com / android / server / pm / OWNERS \n,Create owners \n Change - Id : I970b5a32d2da06645d66d0062f8c2fa87924a204,512
new file \n core \ java \ android \ service \ dataloader \ OWNERS \n + include / core / java / android / os / incremental / OWNERS \n,create owners \n Change - Id : I2791a9f9a80b6f68a948c706d6930d24ed59516d,512
new file \n core \ java \ com \ android \ server \ OWNERS \n + per - file SystemConfig . java = toddke @ google . com \n,Add self to owners for SystemConfig . java \n Change - Id : I812841473d390166ccfca6492ff40d3a324b5599,512
core \ proto \ OWNERS \n + per - file package _ item _ info . proto = toddke @ google . com \n,add to owners \n Change - Id : I4d7c3892c7b97bb15e6a9e1a76050b393be4d7e3,512
new file \n services \ core \ java \ android \ content \ pm \ OWNERS \n + include / core / java / android / content / pm / OWNERS \n,add owners \n Change - Id : I8f20ea8e65fba06e013a105e63912ea70d691864,512
"new file \n apct - tests \ perftests \ core \ src \ android \ app \ OWNERS \n + per - file Overlay * = file : / core / java / android / app / RESOURCES _ OWNERS \n + per - file Resources * = file : / core / java / android / app / RESOURCES _ OWNERS \n core \ java \ android \ app \ OWNERS \n - per - file ResourcesManager . java = rtmitchell @ google . com , toddke @ google . com \n + per - file ResourcesManager . java = file : RESOURCES _ OWNERS \n new file \n core \ java \ android \ app \ RESOURCES _ OWNERS \n + rtmitchell @ google . com \n + toddke @ google . com \n",Add resource owners \n Change - Id : I182d6b167ed33fa0d817e70c7811aa6a22840a69,512
"gdx \ src \ com \ badlogic \ gdx \ graphics \ g2d \ BitmapFontCache . java \n - for ( int i = start * 20 + 2 , n = end * 20 ; i < n ; i + = 5 ) \n + for ( int i = start * 20 + 2 , n = Math . min ( end * 20 , idx [ 0 ] ) ; i < n ; i + = 5 ) \n tests \ gdx - tests \ src \ com \ badlogic \ gdx \ tests \ BitmapFontTest . java \n + private BitmapFont smallFont ; \n + smallFont = new BitmapFont ( ) ; / / uses Arial 15 , the default \n - if ( true ) { \n + if ( false ) { \n + cache = smallFont . getCache ( ) ; \n + / / String neeeds to be pretty long to trigger the crash described in # 5834 ; fixed now \n + final String trogdor = "" TROGDOR ! TROGDOR ! Trogdor was a man ! Or maybe he was a . . . Dragon - Man ! "" ; \n + cache . clear ( ) ; \n + cache . addText ( trogdor , 24 , 37 , 500 , Align . center , true ) ; \n + cache . setColors ( Color . FOREST , 0 , trogdor . length ( ) ) ; \n + cache . draw ( spriteBatch ) ; \n + \n","Ensure BitmapFontCache . setColors ( float , int , int ) stays in - bounds \n This only needs a single ` Math . min ( int , int ) ` call to be added per call to ` setColors ( float , int , int ) ` , checking to make sure that the calculated end index is no greater than what other parts of the class use ( ` idx [ page ] ` , where page is always 0 in the broken case ) . I added the reproduction code from libgdx / libgdx # 5834 to BitmapFontTest , which needed an if / else block to be changed to actually run the tests on most of the features .",514
"tests \ gdx - tests \ src \ com \ badlogic \ gdx \ tests \ CollectionsTest . java \n - import java . util . Iterator ; \n - import java . util . Random ; \n - \n - import com . badlogic . gdx . math . MathUtils ; \n + import java . util . Iterator ; \n + \n + \n + / / 49 String keys that all have the same two hashCode ( ) results \n + / / It is extremely easy to generate String keys that have colliding hashCode ( ) s , so we check to make \n + / / sure ObjectSet and OrderedSet can tolerate them in case of low - complexity malicious use . \n + / / If they can tolerate these problem values , then ObjectMap and others should too . \n + private String [ ] problemValues = \n + ( "" 21oo 0oq1 0opP 0ooo 0pPo 21pP 21q1 1Poo 1Pq1 1PpP 0q31 0pR1 0q2P 0q1o 232P 231o 2331 0pQP 22QP "" \n + + "" 22Po 22R1 1QQP 1R1o 1QR1 1R2P 1R31 1QPo 1Qup 1S7p 0r8Q 0r7p 0r92 23X2 2492 248Q 247p 22vQ "" \n + + "" 22up 1S92 1S8Q 23WQ 23Vp 22w2 1QvQ 1Qw2 1RVp 1RWQ 1RX2 0qX2 "" ) . split ( "" "" ) ; \n + testSet ( ObjectSet . class , problemValues ) ; \n + testSet ( OrderedSet . class , problemValues ) ; \n + \n","First , let ' s show the problem with ObjectMap / ObjectSet in a test .",514
"CHANGES \n - API Addition : TextField and TextArea are providing the protected method TextField # checkFocusTraverse ( char ) to handle the focus traversal . \n - API Addition : UIUtils provides the constants UIUtils # isAndroid and UIUtils # isIos now . \n - Fixed : The behaving of TextFields and TextAreas new line and focus traversal works like intended on all platforms now . \n + - API Change : Changed Base64Coder # encodeString ( ) to use UTF - 8 instead of the platform default encoding . See # 6061 \n - API Addition : Allow target display for maximization LWJGL3 backend \n gdx \ src \ com \ badlogic \ gdx \ utils \ Base64Coder . java \n + import java . io . UnsupportedEncodingException ; \n + \n + / * * Encodes a string into Base64 format , optionally using URL - safe encoding instead of the "" regular "" Base64 encoding . \n + * No blanks or line breaks are inserted . \n + * @ param s A String to be encoded . \n + * @ param useUrlsafeEncoding If true , this encodes the result with an alternate URL - safe set of characters . \n + * @ return A String containing the Base64 encoded data . * / \n - return new String ( encode ( s . getBytes ( ) , useUrlsafeEncoding ? urlsafeMap . encodingMap : regularMap . encodingMap ) ) ; \n + try { \n + return new String ( encode ( s . getBytes ( "" UTF - 8 "" ) , useUrlsafeEncoding ? urlsafeMap . encodingMap : regularMap . encodingMap ) ) ; \n + } catch ( UnsupportedEncodingException e ) { \n + / / shouldn ' t ever happen ; only needed because we specify an encoding with a String \n + return "" "" ; \n + } \n - / * * Encodes a byte array into Base 64 format and breaks the output into lines of 76 characters . This method is compatible with \n + / * * Encodes a byte array into Base64 format and breaks the output into lines of 76 characters . This method is compatible with \n - / * * Encodes a byte array into Base 64 format and breaks the output into lines . \n + / * * Encodes a byte array into Base64 format and breaks the output into lines . \n","Specify encoding for Base64Coder . encodeString ( ) , as the rest of GDX does ( # 6061 ) \n * Specify encoding for Base64Coder . encodeString ( ) , as the rest of GDX does \n This commit also adds Javadocs where they were missing for one encodeString ( ) and makes the spelling of "" Base64 "" consistently "" Base64 "" and not sometimes "" Base 64 "" . \n * Add line to CHANGES for # 6061",514
"extensions \ gdx - setup \ src \ com \ badlogic \ gdx \ setup \ DependencyBank . java \n - static String androidPluginImport = "" com . android . tools . build : gradle : 3 . 4 . 1 "" ; \n + static String androidPluginImport = "" com . android . tools . build : gradle : 3 . 4 . 3 "" ; \n - static String aiVersion = "" 1 . 8 . 0 "" ; \n + static String aiVersion = "" 1 . 8 . 2 "" ; \n - * These depedency strings can be later used in a simple gradle plugin to manipulate the users project either after / before \n + * These dependency strings can be later used in a simple gradle plugin to manipulate the users project either after / before \n","Update AGP version to avoid warning , also gdx - ai",514
"extensions \ gdx - setup \ src \ com \ badlogic \ gdx \ setup \ DependencyBank . java \n - static String box2DLightsVersion = "" 1 . 4 "" ; \n - static String ashleyVersion = "" 1 . 7 . 0 "" ; \n + static String box2DLightsVersion = "" 1 . 5 "" ; \n + static String ashleyVersion = "" 1 . 7 . 3 "" ; \n",Also update Ashley and Box2D Lights ( all extensions with versions ),514
"CHANGES \n - API Change : Tree # addToTree and # removeFromTree now have an "" int actorIndex "" parameter . \n - Fixed AndroidInput crashes due to missing array resize ( pressure array ) . \n - API Change : Ray # set methods and Ray # mul ( Matrix4 ) normalize direction vector . Use public field to set and avoid nor ( ) \n + - Changed the internal implementation of all Map and Set classes ( except ArrayMap ) to avoid OutOfMemoryErrors when too many keys collide ; this helps resistance against malicious users who can choose problematic names \n + - API Addition : OrderedMap # alter ( Object , Object ) and OrderedMap # alterIndex ( int , Object ) allow swapping out a key in - place without changing its value ; OrderedSet also has this \n + - More of the LibGDX data structures can now be passed to Json , to read and write things like a LongMap or an IntIntMap \n - API Addition : Allow target display for maximization LWJGL3 backend \n","CHANGES : mention the big security fix , small Json add , minor API nicety",514
"gdx \ src \ com \ badlogic \ gdx \ utils \ IntFloatMap . java \n - public float getAndIncrement ( int key , int defaultValue , int increment ) { \n + public float getAndIncrement ( int key , float defaultValue , float increment ) { \n",Correct IntFloatMap . getAndIncrement ( ) parameter types \n This was a copy - paste error ; it was found by Raymond Buckley trying to use 1 . 9 . 11 - SNAPSHOT with Typing - Label ( which doesn ' t build with the snapshot right now ) .,514
gdx \ src \ com \ badlogic \ gdx \ math \ DelaunayTriangulator . java \n - values [ lower ] = values [ up ] ; \n - values [ up ] = value ; \n + if ( value > values [ up ] ) { \n + values [ lower ] = values [ up ] ; \n + values [ up ] = value ; \n - tempValue = values [ lower + 1 ] ; \n - values [ lower + 1 ] = values [ up + 1 ] ; \n - values [ up + 1 ] = tempValue ; \n + tempValue = values [ lower + 1 ] ; \n + values [ lower + 1 ] = values [ up + 1 ] ; \n + values [ up + 1 ] = tempValue ; \n - tempIndex = originalIndices [ lower / 2 ] ; \n - originalIndices [ lower / 2 ] = originalIndices [ up / 2 ] ; \n - originalIndices [ up / 2 ] = tempIndex ; \n + tempIndex = originalIndices [ lower / 2 ] ; \n + originalIndices [ lower / 2 ] = originalIndices [ up / 2 ] ; \n + originalIndices [ up / 2 ] = tempIndex ; \n + } \n,"Two - line fix for # 4489 ( DelaunayTriangulator bug ) ( # 6177 ) \n * Fix to # 4489 , requesting review re : sorting and / or geometry \n Tested against the issue in the meantime",514
gdx \ src \ com \ badlogic \ gdx \ utils \ IntMap . java \n + valueTable [ i ] = null ; \n + valueTable [ i ] = null ; \n gdx \ src \ com \ badlogic \ gdx \ utils \ LongMap . java \n + valueTable [ i ] = null ; \n + valueTable [ i ] = null ; \n,"Set removed values in IntMap / LongMap to null \n This fixes # 6285 . It makes IntMap and LongMap act how ObjectMap already does . Only the remove ( ) methods on IntMap , LongMap , and their MapIterator inner classes are changed .",514
"extensions \ gdx - tools \ src \ com \ badlogic \ gdx \ tools \ hiero \ Hiero . java \n - import javax . swing . SpinnerModel ; \n + import com . badlogic . gdx . utils . GdxRuntimeException ; \n - updateFont ( ) ; \n + try { \n + updateFont ( ) ; \n + } catch ( GdxRuntimeException ex ) { \n + prefs . remove ( "" system . font "" ) ; \n + fontList . setSelectedValue ( "" Arial "" , true ) ; \n + updateFont ( ) ; \n + sampleTextPane . setText ( "" Selected font does not have the necessary ' x ' character ; falling back to Arial . \ n "" + sampleTextPane . getText ( ) ) ; \n + } \n","If a font lacks ' x ' , fall back to Arial and place a note . ( # 6360 ) \n The note can be easily removed just by pressing the ASCII , NeHe , or Extended buttons , but it lets the user know why Arial was selected instead of some emoji - only font or something .",514
gdx \ src \ com \ badlogic \ gdx \ graphics \ Mesh . java \n - ( ( Buffer ) getVerticesBuffer ( ) ) . position ( srcOffset ) ; \n + ( ( Buffer ) getIndicesBuffer ( ) ) . position ( srcOffset ) ; \n - ( ( Buffer ) getVerticesBuffer ( ) ) . position ( pos ) ; \n + ( ( Buffer ) getIndicesBuffer ( ) ) . position ( pos ) ; \n,"Fix getIndices ( ) crash in Mesh ( # 6390 ) \n Fix getIndices ( ) crash in Mesh , credit to Agueliethun \n This was a copy / paste error from the Buffer casts change recently . The getIndices ( ) code mistakenly changed the vertices buffer where it formerly changed only the indices buffer . This caused crashes in ModelCacheTest when the Cache checkbox was selected and any model was added .",514
gdx \ src \ com \ badlogic \ gdx \ utils \ IntFloatMap . java \n - float value = map . valueTable [ nextIndex ] ; \n + float value = nextIndex = = INDEX _ ZERO ? map . zeroValue : map . valueTable [ nextIndex ] ; \n gdx \ src \ com \ badlogic \ gdx \ utils \ IntIntMap . java \n - int value = map . valueTable [ nextIndex ] ; \n + int value = nextIndex = = INDEX _ ZERO ? map . zeroValue : map . valueTable [ nextIndex ] ; \n,"Fix missing checks for zero key during Values iteration in IntIntMap , IntFloatMap . ( # 6348 ) \n * Fix missing check for INDEX _ ZERO in IntIntMap , IntFloatMap . \n This fixes # 6347 . Thanks @ tomcashman , for making this an easy fix !",514
"extensions \ gdx - tools \ src \ com \ badlogic \ gdx \ tools \ hiero \ Hiero . java \n - else if ( freeTypeRadio . isSelected ( ) ) \n - unicodeFont . setRenderType ( RenderType . FreeType ) ; \n - else \n + else if ( freeTypeRadio . isSelected ( ) ) { \n + try { \n + unicodeFont . setRenderType ( RenderType . FreeType ) ; \n + } catch ( GdxRuntimeException ex ) { \n + unicodeFont . setRenderType ( RenderType . Java ) ; \n + javaRadio . doClick ( ) ; \n + } \n + } else \n - try { \n - updateFont ( ) ; \n - } catch ( GdxRuntimeException ex ) { \n - prefs . remove ( "" system . font "" ) ; \n - fontList . setSelectedValue ( "" Arial "" , true ) ; \n - sampleTextPane . setText ( "" Selected font does not have the necessary ' x ' character ; falling back to Arial . \ n "" + sampleTextPane . getText ( ) ) ; \n - } \n - freeTypeRadio . setSelected ( true ) ; \n + javaRadio . setSelected ( true ) ; \n","Hiero : Default to crash - less Java renderer , return to it if Freetype would cause crash ( # 6403 ) \n * If a font lacks ' x ' , fall back to Arial and place a note . \n The note can be easily removed just by pressing the ASCII , NeHe , or Extended buttons , but it lets the user know why Arial was selected instead of some emoji - only font or something . \n * If a font is missing ' x ' and we use Freetype , switch to Java . \n Only Freetype rendering has an issue with missing ' x ' chars . Java and Native don ' t necessarily show anything if the font has no ASCII chars , but they don ' t crash . \n * We don ' t need the ' x ' check if we default to Java rendering . \n This also enables the effects right away , which I think are a major reason people use Hiero . \n Also , now the Java radio button is selected safely if ' x ' is missing and Freetype is currently selected . The bold and italic checkboxes are also restored as part of that .",514
"gdx \ src \ com \ badlogic \ gdx \ math \ MathUtils . java \n - return ( long ) ( random . nextDouble ( ) * range ) ; \n + / / Uses the lower - bounded overload defined below , which is simpler and doesn ' t lose much optimization . \n + return random ( 0L , range ) ; \n - return start + ( long ) ( random . nextDouble ( ) * ( end - start ) ) ; \n + final long rand = random . nextLong ( ) ; \n + / / In order to get the range to go from start to end , instead of overflowing after end and going \n + / / back around to start , start must be less than end . \n + if ( end < start ) { \n + long t = end ; \n + end = start ; \n + start = t ; \n + } \n + long bound = end - start + 1L ; / / inclusive on end \n + / / Credit to https : / / oroboro . com / large - random - in - range / for the following technique \n + / / It ' s a 128 - bit - product where only the upper 64 of 128 bits are used . \n + final long randLow = rand & 0xFFFFFFFFL ; \n + final long boundLow = bound & 0xFFFFFFFFL ; \n + final long randHigh = ( rand > > > 32 ) ; \n + final long boundHigh = ( bound > > > 32 ) ; \n + return start + ( randHigh * boundLow > > > 32 ) + ( randLow * boundHigh > > > 32 ) + randHigh * boundHigh ; \n gdx \ test \ com \ badlogic \ gdx \ math \ MathUtilsTest . java \n + \n + @ Test \n + public void testRandomLong ( ) { \n + long r ; \n + for ( int i = 0 ; i < 512 ; i + + ) { \n + assertTrue ( ( r = MathUtils . random ( 1L , 5L ) ) > = 1L & & r < = 5L ) ; \n + assertTrue ( ( r = MathUtils . random ( 6L , 1L ) ) > = 1L & & r < = 6L ) ; \n + assertTrue ( ( r = MathUtils . random ( - 1L , - 7L ) ) < = - 1L & & r > = - 7L ) ; \n + assertTrue ( ( r = MathUtils . random ( - 8L , - 1L ) ) < = - 1L & & r > = - 8L ) ; \n + } \n + } \n","Clean up MathUtils . random ( ) for generating longs ( # 6412 ) \n * Complex fix for MathUtils . random ( long ) . \n This one ' s an especially intricate piece of code , and the bug it fixes is sorta non - obvious . Before , if you called ` MathUtils . nextLong ( Long . MAX _ VALUE ) ` many times , you would never get a number with a ` 1 ` bit in any of the bottom 10 bits . This is obviously not random ; the lack of odd numbers might be the most easily noticeable . That happens because the old code used a double ( with 52 bits of mantissa ) to generate a random long ( with 64 bits ) . The ensuing precision loss affects all large - enough ranges . The fix is to use Rafael Baptista ' s technique for getting the upper 64 bits of a 64x64 - to - 128 - bit multiply , treating the inputs as unsigned . It still works for negative bounds , like before , and is inclusive . It also has a speedup if the bound is one less than a power of two ( such as for ` Long . MAX _ VALUE ` ) , since not as much work is needed there . \n * Fix up random ( long , long ) so larger ranges can be produced . \n * Allow UUIDs to use the sign bit . \n Before , they were only positive longs for each portion of the UUID , and before this PR , they were only using 53 bits of each 64 - bit long . \n * Add a test to make sure . \n Co - authored - by : Nathan Sweet < nathan . sweet @ gmail . com >",514
rename from presto - hive \ src \ main \ java \ org \ apache \ parquet \ io \ ColumnIOConverter . java \n rename to presto - parquet \ src \ main \ java \ org \ apache \ parquet \ io \ ColumnIOConverter . java \n,Move ColumnIOConverter to presto - parquet package \n It doesn ' t have any Hive specific dependencies to be in presto - hive module . \n Also it can be used in unittests in presto - parquet package,522
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ parquet \ ParquetPageSourceFactory . java \n - return prestoType . equals ( INTEGER ) | | prestoType . equals ( SMALLINT ) | | prestoType . equals ( DATE ) | | prestoType . equals ( DECIMAL ) | | prestoType . equals ( TINYINT ) ; \n + return prestoType . equals ( INTEGER ) | | prestoType . equals ( BIGINT ) | | prestoType . equals ( SMALLINT ) | | prestoType . equals ( DATE ) | | prestoType . equals ( DECIMAL ) | | prestoType . equals ( TINYINT ) ; \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveFileFormats . java \n + TestColumn longStoredAsIntColumn = new TestColumn ( "" column _ name "" , javaIntObjectInspector , 4 , 4 ) ; \n + / / make sure INT64 ( declared in Hive schema ) stored as INT32 in file is still readable \n + assertThatFileFormat ( PARQUET ) \n + . withWriteColumns ( ImmutableList . of ( longStoredAsIntColumn ) ) \n + . withReadColumns ( ImmutableList . of ( longColumn ) ) \n + . withSession ( parquetPageSourceSession ) \n + . isReadableByPageSource ( new ParquetPageSourceFactory ( TYPE _ MANAGER , HDFS _ ENVIRONMENT , STATS ) ) ; \n + \n",Parquet schema mismatch for type upgrade ( int32 - > int64 ),522
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveClientConfig . java \n + private boolean parquetDereferencePushdownEnabled ; \n + \n + @ Config ( "" hive . enable - parquet - dereference - pushdown "" ) \n + @ ConfigDescription ( "" enable parquet dereference pushdown "" ) \n + public HiveClientConfig setParquetDereferencePushdownEnabled ( boolean parquetDereferencePushdownEnabled ) \n + { \n + this . parquetDereferencePushdownEnabled = parquetDereferencePushdownEnabled ; \n + return this ; \n + } \n + \n + public boolean isParquetDereferencePushdownEnabled ( ) \n + { \n + return this . parquetDereferencePushdownEnabled ; \n + } \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveSessionProperties . java \n + public static final String PARQUET _ DEREFERENCE _ PUSHDOWN _ ENABLED = "" parquet _ dereference _ pushdown _ enabled "" ; \n - BucketFunctionType : : toString ) ) ; \n + BucketFunctionType : : toString ) , \n + booleanProperty ( \n + PARQUET _ DEREFERENCE _ PUSHDOWN _ ENABLED , \n + "" Is dereference pushdown expression pushdown into Parquet reader enabled ? "" , \n + hiveClientConfig . isParquetDereferencePushdownEnabled ( ) , \n + false ) ) ; \n + \n + public static boolean isParquetDereferencePushdownEnabled ( ConnectorSession session ) \n + { \n + return session . getProperty ( PARQUET _ DEREFERENCE _ PUSHDOWN _ ENABLED , Boolean . class ) ; \n + } \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveClientConfig . java \n - . setBucketFunctionTypeForExchange ( HIVE _ COMPATIBLE ) ) ; \n + . setBucketFunctionTypeForExchange ( HIVE _ COMPATIBLE ) \n + . setParquetDereferencePushdownEnabled ( false ) ) ; \n + . put ( "" hive . enable - parquet - dereference - pushdown "" , "" true "" ) \n - . setBucketFunctionTypeForExchange ( PRESTO _ NATIVE ) ; \n + . setBucketFunctionTypeForExchange ( PRESTO _ NATIVE ) \n + . setParquetDereferencePushdownEnabled ( true ) ; \n",Add an option to control Parquet dereferance pushdown,522
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ util \ InternalHiveSplitFactory . java \n - length , \n + fileSize , \n",Pass the correct value for fileSize in Hive internal split factory \n We are passing the split length as ` fileSize ` to ` InternalSplit ` \n which was used by Parquet reader when trying to find the last few bytes \n that contain the Parquet file magic code to verify the file is a Parquet \n file . PR # 12780 accidentally modified this . It looks like Parquet is the \n only reader which is using the filed ` fileSize and this reproes only \n if ` InputFormat . getSplits ( ) ` is used which is not the most common .,522
"presto - common \ src \ main \ java \ com \ facebook \ presto \ common \ SubfieldTokenizer . java \n - return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | c = = ' / ' | | isUnquotedSubscriptCharacter ( c ) ; \n + return c = = ' : ' | | c = = ' $ ' | | c = = ' - ' | | c = = ' / ' | | c = = ' @ ' | | c = = ' | ' | | isUnquotedSubscriptCharacter ( c ) ; \n presto - common \ src \ test \ java \ com \ facebook \ presto \ common \ TestSubfieldTokenizer . java \n + assertPath ( new Subfield ( "" @ basis "" , ImmutableList . of ( ) ) ) ; \n + assertPath ( new Subfield ( "" @ basis | city _ id "" , ImmutableList . of ( ) ) ) ; \n",Add support for column names with ampersand or pipe to SubfieldTokenizer,522
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ parquet \ ParquetPageSourceFactory . java \n + import org . apache . hadoop . security . AccessControlException ; \n + import static com . facebook . presto . spi . StandardErrorCode . PERMISSION _ DENIED ; \n + if ( e instanceof AccessControlException ) { \n + throw new PrestoException ( PERMISSION _ DENIED , e . getMessage ( ) , e ) ; \n + } \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ util \ HiveFileIterator . java \n + import org . apache . hadoop . security . AccessControlException ; \n + import static com . facebook . presto . spi . StandardErrorCode . PERMISSION _ DENIED ; \n + if ( exception instanceof AccessControlException ) { \n + throw new PrestoException ( PERMISSION _ DENIED , exception . getMessage ( ) , exception ) ; \n + } \n",Categorize the AccessControlException as user error \n Currently it shows up as external,522
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ iterative \ rule \ PushDownDereferences . java \n - RowExpression base = dereference . getArguments ( ) . get ( 0 ) ; \n - return ( base instanceof VariableReferenceExpression ) | | ( base instanceof SpecialFormExpression & & ( ( SpecialFormExpression ) base ) . getForm ( ) = = DEREFERENCE ) ; \n + RowExpression expression = dereference ; \n + while ( true ) { \n + if ( expression instanceof VariableReferenceExpression ) { \n + return true ; \n + } \n + if ( ! ( expression instanceof SpecialFormExpression ) | | ( ( SpecialFormExpression ) expression ) . getForm ( ) ! = DEREFERENCE ) { \n + return false ; \n + } \n + expression = ( ( SpecialFormExpression ) expression ) . getArguments ( ) . get ( 0 ) ; \n + } \n,Fix the dereference validity check in PushdownDeferences rule,522
core \ api \ system - current . txt \n + method @ RequiresPermission ( android . Manifest . permission . MANAGE _ IPSEC _ TUNNELS ) public void setUnderlyingNetwork ( @ NonNull android . net . Network ) throws java . io . IOException ; \n core \ java \ android \ net \ IpSecManager . java \n - * @ hide \n,[ API ] Expose IpSecTunnelInterface # setUnderlyingNetwork \n This API is required to perform MOBIKE . This API allows an IPsec \n peer to change the underlying network of its established IPsec \n tunnel without re - establishing the tunnel . \n Bug : 169855650 \n Test : atest IpSecManagerTunnelTest ( new tests added ) \n Change - Id : Ifc8ad902cbfbe4ad07e715f2fef0faa1bf9d68f3,537
"Android . bp \n + "" services / core / java / com / android / server / vcn / util / PersistableBundleUtils . java "" , \n","Include PersistableBundleUtils in framework - ike - shared - srcs \n Bug : 163604823 \n Test : FrameworksIkeTests , CtsIkeTestCases \n Change - Id : Iee38086e122293f59ae14d3350f45a63671e8566",537
"services \ core \ java \ com \ android \ server \ vcn \ util \ PersistableBundleUtils . java \n + import com . android . internal . util . HexDump ; \n + \n + private static final String BYTE _ ARRAY _ KEY = "" BYTE _ ARRAY _ KEY "" ; \n + / / TODO : b / 170513329 Delete # fromByteArray and # toByteArray once BaseBundle # putByteArray and \n + / / BaseBundle # getByteArray are exposed . \n + \n + / * * \n + * Converts a byte array to a PersistableBundle . \n + * \n + * < p > To avoid key collisions , NO additional key / value pairs should be added to the returned \n + * PersistableBundle object . \n + * \n + * @ param array a byte array instance to persist \n + * @ return the PersistableBundle instance \n + * / \n + public static PersistableBundle fromByteArray ( byte [ ] array ) { \n + final PersistableBundle result = new PersistableBundle ( ) ; \n + \n + result . putString ( BYTE _ ARRAY _ KEY , HexDump . toHexString ( array ) ) ; \n + \n + return result ; \n + } \n + \n + / * * \n + * Converts from a PersistableBundle to a byte array . \n + * \n + * @ param bundle the PersistableBundle containing the byte array \n + * @ return the byte array instance \n + * / \n + public static byte [ ] toByteArray ( PersistableBundle bundle ) { \n + Objects . requireNonNull ( bundle , "" PersistableBundle is null "" ) ; \n + \n + String hex = bundle . getString ( BYTE _ ARRAY _ KEY ) ; \n + if ( hex = = null | | hex . length ( ) % 2 ! = 0 ) { \n + throw new IllegalArgumentException ( "" PersistableBundle contains invalid byte array "" ) ; \n + } \n + \n + return HexDump . hexStringToByteArray ( hex ) ; \n + } \n + \n tests \ vcn \ java \ com \ android \ server \ vcn \ util \ PersistableBundleUtilsTest . java \n + import static org . junit . Assert . assertArrayEquals ; \n + \n + @ Test \n + public void testByteArrayConversionLossless ( ) { \n + final byte [ ] byteArray = "" testByteArrayConversionLossless "" . getBytes ( ) ; \n + \n + PersistableBundle bundle = PersistableBundleUtils . fromByteArray ( byteArray ) ; \n + byte [ ] result = PersistableBundleUtils . toByteArray ( bundle ) ; \n + \n + assertArrayEquals ( byteArray , result ) ; \n + } \n",Support converting byte array to / from PersistableBundle \n Test : FrameworksVcnTests : PersistableBundleUtilsTest ( new tests added ) \n Change - Id : I1d700c9b6d10a40ef43abcab449d4b07d897f0ec,537
"services \ core \ java \ com \ android \ server \ vcn \ util \ PersistableBundleUtils . java \n + private static final String INTEGER _ KEY = "" INTEGER _ KEY "" ; \n + / * * Serializer to convert an integer to a PersistableBundle . * / \n + public static final Serializer < Integer > INTEGER _ SERIALIZER = \n + ( i ) - > { \n + final PersistableBundle result = new PersistableBundle ( ) ; \n + result . putInt ( INTEGER _ KEY , i ) ; \n + return result ; \n + } ; \n + \n + / * * Deserializer to convert a PersistableBundle to an integer . * / \n + public static final Deserializer < Integer > INTEGER _ DESERIALIZER = \n + ( bundle ) - > { \n + Objects . requireNonNull ( bundle , "" PersistableBundle is null "" ) ; \n + return bundle . getInt ( INTEGER _ KEY ) ; \n + } ; \n + \n tests \ vcn \ java \ com \ android \ server \ vcn \ util \ PersistableBundleUtilsTest . java \n + \n + @ Test \n + public void testIntegerConversionLossless ( ) throws Exception { \n + final int testInt = 1 ; \n + final PersistableBundle integerBundle = \n + PersistableBundleUtils . INTEGER _ SERIALIZER . toPersistableBundle ( testInt ) ; \n + final int result = \n + PersistableBundleUtils . INTEGER _ DESERIALIZER . fromPersistableBundle ( integerBundle ) ; \n + \n + assertEquals ( testInt , result ) ; \n + } \n",Support converting integer to / from PersistableBundle \n This CL is for facilitating converting Map and List that \n contains integer type objects . \n Bug : 163604823 \n Test : PersistableBundleUtilsTest ( new tests added ) \n Change - Id : I24239caf70035e19c3fb5eb4a85b6a0c6ccadb5a,537
"core \ java \ android \ net \ IpSecAlgorithm . java \n + private static final int SDK _ VERSION _ ZERO = 0 ; \n + \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( CRYPT _ AES _ CBC , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ MD5 , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA1 , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA256 , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA384 , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA512 , Build . VERSION _ CODES . P ) ; \n - ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ CRYPT _ AES _ GCM , Build . VERSION _ CODES . P ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( CRYPT _ AES _ CBC , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ MD5 , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA1 , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA256 , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA384 , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ HMAC _ SHA512 , SDK _ VERSION _ ZERO ) ; \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ CRYPT _ AES _ GCM , SDK _ VERSION _ ZERO ) ; \n","Require devices with first sdk 0 or later to support mandatory algorithms \n It is safe because these mandatory algorithms are already required \n before new algorithms are added \n It is also a quick fix to unblock b / 171279612 , whose root cause is \n the device first sdk is wrong \n Bug : 171279612 \n Test : atest CtsNetTestCases : IpSecManagerTest \n Change - Id : I5b9d85b2bc8f13f54467c97160d138a4628265f7",537
"core \ res \ res \ values \ config . xml \n - * SDK level 30 makes the following algorithms mandatory : "" rfc3686 ( ctr ( aes ) ) "" , \n + * SDK level 31 makes the following algorithms mandatory : "" rfc3686 ( ctr ( aes ) ) "" , \n - - > \n","Fix documentation for config _ optionalIpSecAlgorithms \n New algorithms are mandatory in SDK 31 , not SDK 30 \n Bug : 161716062 \n Test : FrameworksIkeTests , CtsIkeTestCases \n Change - Id : If1a728bbd002a52b91f88569509c9e5113eb6c04",537
"api \ current . txt \n + method @ NonNull public static java . util . Set < java . lang . String > getSupportedAlgorithms ( ) ; \n + field public static final String AUTH _ AES _ XCBC = "" xcbc ( aes ) "" ; \n + field public static final String AUTH _ CRYPT _ CHACHA20 _ POLY1305 = "" rfc7539esp ( chacha20 , poly1305 ) "" ; \n + field public static final String CRYPT _ AES _ CTR = "" rfc3686 ( ctr ( aes ) ) "" ; \n core \ java \ android \ net \ IpSecAlgorithm . java \n - * \n - * @ hide \n - * \n - * @ hide \n - * \n - * @ hide \n - * \n - * @ hide \n non - updatable - api \ current . txt \n + method @ NonNull public static java . util . Set < java . lang . String > getSupportedAlgorithms ( ) ; \n + field public static final String AUTH _ AES _ XCBC = "" xcbc ( aes ) "" ; \n + field public static final String AUTH _ CRYPT _ CHACHA20 _ POLY1305 = "" rfc7539esp ( chacha20 , poly1305 ) "" ; \n + field public static final String CRYPT _ AES _ CTR = "" rfc3686 ( ctr ( aes ) ) "" ; \n",Expose new algorithms as public API \n Bug : 161716062 \n Test : FrameworksNetTests : IpSecAlgorithmTest \n Change - Id : I5041c61ad5a4aa58b259e24de80a2c63d6b19dae,537
"Android . bp \n + "" : ike - srcs "" , \n + "" android . net . ipsec . ike . stubs . module _ lib "" , \n + "" android . net . ipsec . ike . impl "" , \n StubLibraries . bp \n + "" android . net . ipsec . ike . stubs "" , \n + "" android . net . ipsec . ike . stubs . system "" , \n + "" android . net . ipsec . ike . stubs . system "" , \n api \ Android . bp \n + "" : android . net . ipsec . ike { . public . api . txt } "" , \n + "" : android . net . ipsec . ike { . public . stubs . source } "" , \n + "" : android . net . ipsec . ike { . public . removed - api . txt } "" , \n + "" : android . net . ipsec . ike { . system . api . txt } "" , \n + "" : android . net . ipsec . ike { . system . removed - api . txt } "" , \n + "" : android . net . ipsec . ike { . module - lib . api . txt } "" , \n + "" : android . net . ipsec . ike { . module - lib . removed - api . txt } "" , \n services \ core \ Android . bp \n - "" android . net . ipsec . ike . stubs . module _ lib "" , \n","Add IKE stub to main Android SDK \n This CL is required for converting IKE from a shared library to \n a jar in the boot classpath . \n Bug : 177266501 \n Test : build , flash , boot \n Change - Id : I10759d22eaba4861b7d7f283b551156f09f54675 \n Merged - In : I10759d22eaba4861b7d7f283b551156f09f54675",537
"core \ api \ current . txt \n + field public static final String AUTH _ AES _ CMAC = "" cmac ( aes ) "" ; \n core \ java \ android \ net \ IpSecAlgorithm . java \n + / * * \n + * AES - CMAC Authentication / Integrity Algorithm . \n + * \n + * < p > Keys for this algorithm must be 128 bits in length . \n + * \n + * < p > The only valid truncation length is 96 bits . \n + * \n + * < p > This algorithm may be available on the device . Caller MUST check if it is supported before \n + * using it by calling { @ link # getSupportedAlgorithms ( ) } and checking if this algorithm is \n + * included in the returned algorithm set . The returned algorithm set will not change unless the \n + * device is rebooted . { @ link IllegalArgumentException } will be thrown if this algorithm is \n + * requested on an unsupported device . \n + * \n + * < p > @ see { @ link # getSupportedAlgorithms ( ) } \n + * / \n + / / This algorithm may be available on devices released before Android 12 , and is guaranteed \n + / / to be available on devices first shipped with Android 12 or later . \n + public static final String AUTH _ AES _ CMAC = "" cmac ( aes ) "" ; \n + \n + AUTH _ AES _ CMAC , \n + ALGO _ TO _ REQUIRED _ FIRST _ SDK . put ( AUTH _ AES _ CMAC , Build . VERSION _ CODES . R + 1 ) ; \n + case AUTH _ AES _ CMAC : \n + isValidLen = keyLen = = 128 ; \n + isValidTruncLen = truncLen = = 96 ; \n + break ; \n + case AUTH _ AES _ CMAC : \n core \ res \ res \ values \ config . xml \n - "" xcbc ( aes ) "" , "" rfc7539esp ( chacha20 , poly1305 ) "" \n + "" xcbc ( aes ) "" , "" cmac ( aes ) "" , "" rfc7539esp ( chacha20 , poly1305 ) "" \n - - > \n tests \ net \ java \ android \ net \ IpSecAlgorithmTest . java \n + checkAuthKeyAndTruncLenValidation ( IpSecAlgorithm . AUTH _ AES _ CMAC , 128 , 96 ) ; \n","Support new IpSecAlgorithm AUTH _ AES _ CMAC \n Bug : 161716062 \n Test : IpSecAlgorithmTest , verified with CTS \n Change - Id : Ideaf4225bd851fad8c8072505c6ad99d85ba616e",537
"core \ api \ current . txt \n + public abstract class VcnControlPlaneConfig { \n + } \n + \n + public final class VcnControlPlaneIkeConfig extends android . net . vcn . VcnControlPlaneConfig { \n + ctor public VcnControlPlaneIkeConfig ( @ NonNull android . net . ipsec . ike . IkeSessionParams , @ NonNull android . net . ipsec . ike . TunnelModeChildSessionParams ) ; \n + method @ NonNull public android . net . ipsec . ike . TunnelModeChildSessionParams getChildSessionParams ( ) ; \n + method @ NonNull public android . net . ipsec . ike . IkeSessionParams getIkeSessionParams ( ) ; \n + } \n + \n - ctor public VcnGatewayConnectionConfig . Builder ( ) ; \n + ctor public VcnGatewayConnectionConfig . Builder ( @ NonNull android . net . vcn . VcnControlPlaneConfig ) ; \n core \ java \ android \ net \ vcn \ VcnControlPlaneConfig . java \n - * \n - * @ hide \n core \ java \ android \ net \ vcn \ VcnControlPlaneIkeConfig . java \n - * \n - * @ hide \n core \ java \ android \ net \ vcn \ VcnGatewayConnectionConfig . java \n - * @ hide \n - / * * Construct a Builder object . * / \n - / / TODO : Remove this constructor when # Builder ( ctrlPlaneConfig ) is exposed as public API . \n - / / This constructor is created to avoid changing API shape in this CL \n - public Builder ( ) { \n - mCtrlPlaneConfig = null ; \n - } \n - \n","API : Expose VcnControlPlaneConfig \n Each VcnGatewayConnectionConfig must have a VcnControlPlaneConfig \n that contains all connection , authentication and authorization \n parameters required to establish a gateway connection . \n Bug : 163604823 \n Test : make update - api & & make \n Change - Id : If4a58e7b0391b485ee7c4482d422bec5e6ba4148",537
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ scalar \ ArrayDistinctFunction . java \n + import com . facebook . presto . type . TypeUtils ; \n - if ( type . equalTo ( array , 0 , array , 1 ) ) { \n + if ( TypeUtils . positionEqualsPosition ( type , array , 0 , array , 1 ) ) { \n presto - main \ src \ test \ java \ com \ facebook \ presto \ type \ TestArrayOperators . java \n + assertFunction ( "" ARRAY _ DISTINCT ( ARRAY [ 0 , NULL ] ) "" , new ArrayType ( INTEGER ) , asList ( 0 , null ) ) ; \n + assertFunction ( "" ARRAY _ DISTINCT ( ARRAY [ 0 , NULL , 0 , NULL ] ) "" , new ArrayType ( INTEGER ) , asList ( 0 , null ) ) ; \n + assertFunction ( "" ARRAY _ DISTINCT ( ARRAY [ 0 . 0E0 , NULL ] ) "" , new ArrayType ( DOUBLE ) , asList ( 0 . 0 , null ) ) ; \n + assertFunction ( "" ARRAY _ DISTINCT ( ARRAY [ FALSE , NULL ] ) "" , new ArrayType ( BOOLEAN ) , asList ( false , null ) ) ; \n + assertFunction ( "" ARRAY _ DISTINCT ( ARRAY [ FALSE , TRUE , NULL ] ) "" , new ArrayType ( BOOLEAN ) , asList ( false , true , null ) ) ; \n",Fix ARRAY _ DISTINCT wrong results on NULL and 0,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ testing \ TestingTaskContext . java \n - private final DataSize queryMaxTotalMemory = new DataSize ( 512 , MEGABYTE ) ; \n + private DataSize queryMaxTotalMemory = new DataSize ( 512 , MEGABYTE ) ; \n + public Builder setQueryMaxTotalMemory ( DataSize queryMaxTotalMemory ) \n + { \n + this . queryMaxTotalMemory = queryMaxTotalMemory ; \n + return this ; \n + } \n + \n presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ BenchmarkPartitionedOutputOperator . java \n + . setQueryMaxTotalMemory ( MAX _ MEMORY ) \n","Enable setQueryMaxTotalMemory for TestingTaskContext \n Adding setQueryMaxTotalMemory to avoid "" Query exceeded per - node total \n memory limit of 512MB "" error when running new \n BenchmarkPartitionedOutputOperator",542
presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ AbstractArrayBlock . java \n + @ Override \n + public boolean mayHaveNull ( ) \n + { \n + return getValueIsNull ( ) ! = null ; \n + } \n + \n presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ AbstractMapBlock . java \n + @ Override \n + public boolean mayHaveNull ( ) \n + { \n + return getMapIsNull ( ) ! = null ; \n + } \n + \n presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ AbstractRowBlock . java \n + @ Override \n + public boolean mayHaveNull ( ) \n + { \n + return getRowIsNull ( ) ! = null ; \n + } \n + \n,"Make Arrayblock , MapBlock , RowBlock support mayHaveNull",542
presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ BenchmarkPartitionedOutputOperator . java \n + buffer . registerLifespanCompletionCallback ( ignore - > { } ) ; \n,"Fix BenchmarkPartitionedOutputOperator \n Before this commit there was this error running this benchmark : \n Exception in thread "" main "" java . lang . IllegalStateException : \n lifespanCompletionCallback must be set before enqueueing data",542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ListBatchStreamReader . java \n + import static com . facebook . presto . orc . reader . ReaderUtils . convertLengthVectorToOffsetVector ; \n + import static com . facebook . presto . orc . reader . ReaderUtils . unpackLengthNulls ; \n - lengthStream . nextIntVector ( nextBatchSize , offsetVector , 0 , nullVector ) ; \n + lengthStream . nextIntVector ( nextBatchSize - nullValues , offsetVector , 0 , nullVector ) ; \n + unpackLengthNulls ( offsetVector , nullVector , nextBatchSize - nullValues ) ; \n - / / Convert the length values in the offsetVector to offset values in place \n - int currentLength = offsetVector [ 0 ] ; \n - offsetVector [ 0 ] = 0 ; \n - for ( int i = 1 ; i < offsetVector . length ; i + + ) { \n - int nextLength = offsetVector [ i ] ; \n - offsetVector [ i ] = offsetVector [ i - 1 ] + currentLength ; \n - currentLength = nextLength ; \n - } \n + convertLengthVectorToOffsetVector ( offsetVector ) ; \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ MapDirectBatchStreamReader . java \n + import static com . facebook . presto . orc . reader . ReaderUtils . convertLengthVectorToOffsetVector ; \n + import static com . facebook . presto . orc . reader . ReaderUtils . unpackLengthNulls ; \n - lengthStream . nextIntVector ( nextBatchSize , offsetVector , 0 , nullVector ) ; \n + lengthStream . nextIntVector ( nextBatchSize - nullValues , offsetVector , 0 , nullVector ) ; \n + unpackLengthNulls ( offsetVector , nullVector , nextBatchSize - nullValues ) ; \n - / / Convert the length values in the offsetVector to offset values in - place \n - int currentLength = offsetVector [ 0 ] ; \n - offsetVector [ 0 ] = 0 ; \n - for ( int i = 1 ; i < offsetVector . length ; i + + ) { \n - int lastLength = offsetVector [ i ] ; \n - offsetVector [ i ] = offsetVector [ i - 1 ] + currentLength ; \n - currentLength = lastLength ; \n - } \n + convertLengthVectorToOffsetVector ( offsetVector ) ; \n",Improve ORC list and map readers \n Cherry - pick of https : / / github . com / prestosql / presto / pull / 555 \n Co - authored - by : Dain Sundstrom < dain @ iq80 . com >,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ SystemSessionProperties . java \n + public static final String OPTIMIZED _ REPARTITIONING _ ENABLED = "" optimized _ repartitioning "" ; \n - Duration : : toString ) ) ; \n + Duration : : toString ) , \n + booleanProperty ( \n + OPTIMIZED _ REPARTITIONING _ ENABLED , \n + "" Experimental : Use optimized repartitioning "" , \n + featuresConfig . isOptimizedRepartitioningEnabled ( ) , \n + false ) ) ; \n + \n + public static boolean isOptimizedRepartitioningEnabled ( Session session ) \n + { \n + return session . getSystemProperty ( OPTIMIZED _ REPARTITIONING _ ENABLED , Boolean . class ) ; \n + } \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ analyzer \ FeaturesConfig . java \n + private boolean optimizedRepartitioningEnabled ; \n + \n + public boolean isOptimizedRepartitioningEnabled ( ) \n + { \n + return optimizedRepartitioningEnabled ; \n + } \n + \n + @ Config ( "" experimental . optimized - repartitioning "" ) \n + @ ConfigDescription ( "" Experimental : Use optimized repartitioning "" ) \n + public FeaturesConfig setOptimizedRepartitioningEnabled ( boolean optimizedRepartitioningEnabled ) \n + { \n + this . optimizedRepartitioningEnabled = optimizedRepartitioningEnabled ; \n + return this ; \n + } \n presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ analyzer \ TestFeaturesConfig . java \n - . setIndexLoaderTimeout ( new Duration ( 20 , SECONDS ) ) ) ; \n + . setIndexLoaderTimeout ( new Duration ( 20 , SECONDS ) ) \n + . setOptimizedRepartitioningEnabled ( false ) ) ; \n + . put ( "" experimental . optimized - repartitioning "" , "" true "" ) \n - . setIndexLoaderTimeout ( new Duration ( 10 , SECONDS ) ) ; \n + . setIndexLoaderTimeout ( new Duration ( 10 , SECONDS ) ) \n + . setOptimizedRepartitioningEnabled ( true ) ; \n",Add experimental . optimized - repartitioning configuration property,542
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ HiveConnectorFactory . java \n + . quiet ( ) \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ HiveQueryRunner . java \n + import static io . airlift . log . Level . ERROR ; \n + logging . setLevel ( "" com . facebook . presto . security . AccessControlManager "" , WARN ) ; \n + logging . setLevel ( "" com . facebook . presto . server . PluginManager "" , WARN ) ; \n + logging . setLevel ( "" io . airlift . bootstrap . LifeCycleManager "" , WARN ) ; \n + logging . setLevel ( "" org . eclipse . jetty . server . handler . ContextHandler "" , WARN ) ; \n + logging . setLevel ( "" org . eclipse . jetty . server . AbstractConnector "" , WARN ) ; \n + logging . setLevel ( "" org . glassfish . jersey . internal . inject . Providers "" , ERROR ) ; \n","Make HiveQueryRunner logging succinct \n Reduce logging to avoid hitting 4MB limit on the log size in Travis . \n This limit is reached when more tests using HiveQueryRunner are added . \n The Hive config values were removed , and logging level for several \n classes was increased .",542
"presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ BenchmarkBatchStreamReaders . java \n + public static final int MAX _ STRING = 10 ; \n - "" varchar "" , \n + "" varchar _ direct "" , \n + "" varchar _ dictionary "" , \n - type = new TypeRegistry ( ) . getType ( TypeSignature . parseTypeSignature ( typeSignature ) ) ; \n + if ( typeSignature . startsWith ( "" varchar "" ) ) { \n + type = new TypeRegistry ( ) . getType ( TypeSignature . parseTypeSignature ( "" varchar "" ) ) ; \n + } \n + else { \n + type = new TypeRegistry ( ) . getType ( TypeSignature . parseTypeSignature ( typeSignature ) ) ; \n + } \n + \n - case "" varchar "" : \n - return Strings . repeat ( "" 0 "" , 4 ) ; \n + case "" varchar _ dictionary "" : \n + return Strings . repeat ( "" 0 "" , MAX _ STRING ) ; \n + case "" varchar _ direct "" : \n + return randomAsciiString ( random ) ; \n + private static String randomAsciiString ( Random random ) \n + { \n + char [ ] value = new char [ random . nextInt ( MAX _ STRING ) ] ; \n + for ( int i = 0 ; i < value . length ; i + + ) { \n + value [ i ] = ( char ) random . nextInt ( Byte . MAX _ VALUE ) ; \n + } \n + return new String ( value ) ; \n + } \n + \n","Add benchmark for SliceBatchDirectStreamReader \n The existing "" varchar "" typeSignature benchmark only tested \n SliceDictionaryBatchStreamReader . This commit renamed it to \n "" varchar _ dictionary "" and added a new "" varchar _ direct "" typeSignature to \n test SliceBatchDirectStreamReader .",542
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ HiveQueryRunner . java \n + logging . setLevel ( "" com . facebook . presto . event "" , WARN ) ; \n","Reduce HiveQueryRunner logs \n HiveQueryRunner produced a lot of logs and caused Travis to fail with \n "" The job exceeded the maximum log length "" error . This commit increases \n the logging level for com . facebook . presto . event from INFO to WARN to \n reduce the amount of logs produced .",542
presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcBatchPageSource . java \n - private static final int NULL _ ENTRY _ SIZE = 0 ; \n,Remove unused NULL _ ENTRY _ SIZE from OrcBatchPageSource,542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ByteSelectiveStreamReader . java \n + if ( presentStream = = null & & positions [ positionCount - 1 ] = = positionCount - 1 ) { \n + / / contiguous chunk of rows , no nulls \n + dataStream . next ( values , positionCount ) ; \n + outputPositionCount = positionCount ; \n + return positionCount ; \n + } \n + \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ stream \ ByteInputStream . java \n + import static java . lang . Math . min ; \n + \n + \n + public void next ( byte [ ] values , int items ) \n + throws IOException \n + { \n + int outputOffset = 0 ; \n + while ( outputOffset < items ) { \n + if ( offset = = length ) { \n + readNextBlock ( ) ; \n + } \n + if ( length = = 0 ) { \n + throw new OrcCorruptionException ( input . getOrcDataSourceId ( ) , "" Unexpected end of stream "" ) ; \n + } \n + \n + int chunkSize = min ( items - outputOffset , length - offset ) ; \n + System . arraycopy ( buffer , offset , values , outputOffset , chunkSize ) ; \n + \n + outputOffset + = chunkSize ; \n + offset + = chunkSize ; \n + } \n + } \n",Optimize byte reader when reading contiguous rows with no nulls and no filter \n JMH benchmark results show 2x improvement when there is no nulls and no filters . \n Before \n Benchmark ( typeSignature ) ( withNulls ) Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . read tinyint true avgt 20 0 . 045 ± 0 . 001 s / op \n BenchmarkSelectiveStreamReaders . read tinyint false avgt 20 0 . 039 ± 0 . 001 s / op \n After \n Benchmark ( typeSignature ) ( withNulls ) Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . read tinyint true avgt 20 0 . 043 ± 0 . 002 s / op \n BenchmarkSelectiveStreamReaders . read tinyint false avgt 20 0 . 018 ± 0 . 001 s / op,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ HashGenerator . java \n - import static com . google . common . base . Preconditions . checkState ; \n - \n - / / clear the sign bit \n - rawHash & = 0x7fff _ ffff _ ffff _ ffffL ; \n - \n - int partition = ( int ) ( rawHash % partitionCount ) ; \n - \n - checkState ( partition > = 0 & & partition < partitionCount ) ; \n - return partition ; \n + / / This function reduces the 64 bit rawHash to [ 0 , partitionCount ) uniformly . It first reduces the rawHash to 32 bit \n + / / integer x then normalize it to x / 2 ^ 32 * partitionCount to reduce the range of x from [ 0 , 2 ^ 32 ) to [ 0 , partitionCount ) \n + return ( int ) ( ( Integer . toUnsignedLong ( Long . hashCode ( rawHash ) ) * partitionCount ) > > 32 ) ; \n presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ repartition \ BenchmarkPartitionedOutputOperator . java \n + import com . facebook . presto . operator . BucketPartitionFunction ; \n + import java . util . stream . IntStream ; \n + import static com . facebook . presto . sql . planner . SystemPartitioningHandle . SystemPartitionFunction . HASH ; \n - PartitionFunction partitionFunction = new LocalPartitionGenerator ( new PrecomputedHashGenerator ( 0 ) , PARTITION _ COUNT ) ; \n + PartitionFunction partitionFunction = new BucketPartitionFunction ( \n + HASH . createBucketFunction ( ImmutableList . of ( BIGINT ) , true , PARTITION _ COUNT ) , \n + IntStream . range ( 0 , PARTITION _ COUNT ) . toArray ( ) ) ; \n + \n",Improve HashGenerator . getPartition performance \n Change the mod operation to bit shifting in HashGenerator . getPartition . \n BenchmarkPartitionedOutputOperator shows 35 % gain . \n Bigint Before : \n Benchmark ( hasNull ) Mode Cnt Score Error Units \n BenchmarkPartitionedOutputOperator . optimizedAddPage true avgt 30 847 . 520 ± 111 . 003 ms / op \n BenchmarkPartitionedOutputOperator . optimizedAddPage false avgt 30 820 . 443 ± 63 . 596 ms / op \n Bigint After : \n Benchmark ( hasNull ) Mode Cnt Score Error Units \n BenchmarkPartitionedOutputOperator . optimizedAddPage true avgt 30 565 . 254 ± 64 . 455 ms / op \n BenchmarkPartitionedOutputOperator . optimizedAddPage false avgt 30 558 . 286 ± 47 . 540 ms / op,542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ stream \ ByteInputStream . java \n - \n - public void next ( byte [ ] values , int items ) \n - throws IOException \n - { \n - int outputOffset = 0 ; \n - while ( outputOffset < items ) { \n - if ( offset = = length ) { \n - readNextBlock ( ) ; \n - } \n - if ( length = = 0 ) { \n - throw new OrcCorruptionException ( input . getOrcDataSourceId ( ) , "" Unexpected end of stream "" ) ; \n - } \n - \n - int chunkSize = min ( items - outputOffset , length - offset ) ; \n - System . arraycopy ( buffer , offset , values , outputOffset , chunkSize ) ; \n - \n - outputOffset + = chunkSize ; \n - offset + = chunkSize ; \n - } \n - } \n",Fix the build broken by 9633991927 \n Fix the build broken by 9633991927 Improve ORC byte reader .,542
presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ DecodedBlockNode . java \n - int size = INSTANCE _ SIZE ; \n + long size = INSTANCE _ SIZE ; \n,Fix size type when calculating retained size .,542
presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ BlockFlattener . java \n - int [ ] currentRemappedIds = ( int [ ] ) dictionaryBlock . getIds ( ) . getBase ( ) ; \n + int [ ] currentRemappedIds = dictionaryBlock . getRawIds ( ) ; \n - int [ ] ids = ( int [ ] ) dictionaryBlock . getIds ( ) . getBase ( ) ; \n + int [ ] ids = dictionaryBlock . getRawIds ( ) ; \n presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ DictionaryBlock . java \n + int [ ] getRawIds ( ) \n + { \n + return ids ; \n + } \n + \n,Fix slice size overflow in DictionaryBlock . getIds ( ),542
presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ SimpleArrayAllocator . java \n - class SimpleArrayAllocator \n + public class SimpleArrayAllocator \n presto - spi \ src \ test \ java \ com \ facebook \ presto \ spi \ block \ CountingArrayAllocator . java \n - class CountingArrayAllocator \n + public class CountingArrayAllocator \n,Make ArrayAllocator implementations public \n Operators that need to use BlockFlattener need to instantiate an \n ArrayAllocator . However the ArrayAllocators were package private and \n can ' t be accessed by operators not under the root folder of operator . \n This commit makes them public .,542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ repartition \ BenchmarkPartitionedOutputOperator . java \n + import com . facebook . presto . sql . planner . OutputPartitioning ; \n + import java . util . OptionalInt ; \n + OutputPartitioning outputPartitioning = createOutputPartitioning ( partitionFunction ) ; \n - . createOutputOperator ( 0 , new PlanNodeId ( "" plan - node - 0 "" ) , types , Function . identity ( ) , Optional . empty ( ) , serdeFactory ) \n + . createOutputOperator ( 0 , new PlanNodeId ( "" plan - node - 0 "" ) , types , Function . identity ( ) , Optional . of ( outputPartitioning ) , serdeFactory ) \n + OutputPartitioning outputPartitioning = createOutputPartitioning ( partitionFunction ) ; \n + \n - . createOutputOperator ( 0 , new PlanNodeId ( "" plan - node - 0 "" ) , types , Function . identity ( ) , Optional . empty ( ) , serdeFactory ) \n + . createOutputOperator ( 0 , new PlanNodeId ( "" plan - node - 0 "" ) , types , Function . identity ( ) , Optional . of ( outputPartitioning ) , serdeFactory ) \n + private OutputPartitioning createOutputPartitioning ( PartitionFunction partitionFunction ) \n + { \n + return new OutputPartitioning ( \n + partitionFunction , \n + ImmutableList . of ( 0 ) , \n + ImmutableList . of ( Optional . empty ( ) , Optional . empty ( ) ) , \n + false , \n + OptionalInt . empty ( ) ) ; \n + } \n + \n","Fix BenchmarkPartitionedOutputOperator \n OptimizedPartitionedOutputFactory # createOutputOperator ( ) now takes a new \n parameter Optional < OutputPartitioning > outputPartitioning and require it \n to be present . The change came from the "" Refactor LocalExecutionPlanner "" \n commit in # 14099 . This broke BenchmarkPartitionedOutputOperator because \n an empty outputPartitioning was passed in . This commit fixes the problem \n by passing in an non - empty outputPartitioning .",542
"presto - common \ src \ main \ java \ com \ facebook \ presto \ common \ block \ SingleMapBlock . java \n - match = ( Boolean ) mapBlock . keyBlockNativeEquals . invokeExact ( mapBlock . getRawKeyBlock ( ) , offset / 2 + keyPosition , nativeValue ) ; \n + match = mapBlock . getRawKeyBlock ( ) . bytesEqual ( offset / 2 + keyPosition , 0 , nativeValue , 0 , nativeValue . length ( ) ) ; \n presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveIntegrationSmokeTest . java \n + \n + assertUpdate ( "" CREATE TABLE tmp _ map13 AS SELECT MAP ( ARRAY [ ' puppies ' , ' kittens ' ] , ARRAY [ ' corgi ' , ' norwegianWood ' ] ) AS col "" , 1 ) ; \n + assertQuery ( "" SELECT col [ ' puppies ' ] FROM tmp _ map13 "" , "" SELECT ' corgi ' "" ) ; \n + assertQuery ( "" SELECT col [ ' kittens ' ] FROM tmp _ map13 "" , "" SELECT ' norwegianWood ' "" ) ; \n","Do not create Slice while comparing keys in SingleMapBlock \n When seeking a key represented in Slice format , the comparison of the \n key value and the value in the SingleMapBlock at the position of the \n hashCode was done through keyBlockNativeEquals . invokeExact ( ) , which \n creates a new Slice object . When there are many map subscript operations \n in a query , many small Slice objects are created and this causes high \n GC overhead which may lead to reliability problems . This commit uses \n the newly introduced Block . equals ( int , Slice ) to do the comparison and \n it does not create the Slice objects . \n It also improves the map subscript operation on varchars by up to 30 % . \n Before : \n Benchmark ( mapSize ) ( name ) Mode Cnt Score Error Units \n BenchmarkMapSubscript . mapSubscript 1 fix - width avgt 20 43 . 658 ± 2 . 070 ns / op \n BenchmarkMapSubscript . mapSubscript 1 var - width avgt 20 76 . 798 ± 1 . 174 ns / op \n BenchmarkMapSubscript . mapSubscript 1 dictionary avgt 20 71 . 693 ± 1 . 728 ns / op \n BenchmarkMapSubscript . mapSubscript 13 fix - width avgt 20 673 . 659 ± 35 . 320 ns / op \n BenchmarkMapSubscript . mapSubscript 13 var - width avgt 20 1549 . 805 ± 114 . 924 ns / op \n BenchmarkMapSubscript . mapSubscript 13 dictionary avgt 20 1505 . 389 ± 55 . 895 ns / op \n After : \n Benchmark ( mapSize ) ( name ) Mode Cnt Score Error Units \n BenchmarkMapSubscript . mapSubscript 1 fix - width avgt 20 31 . 709 ± 1 . 050 ns / op \n BenchmarkMapSubscript . mapSubscript 1 var - width avgt 20 56 . 716 ± 1 . 767 ns / op \n BenchmarkMapSubscript . mapSubscript 1 dictionary avgt 20 66 . 426 ± 2 . 030 ns / op \n BenchmarkMapSubscript . mapSubscript 13 fix - width avgt 20 569 . 891 ± 21 . 386 ns / op \n BenchmarkMapSubscript . mapSubscript 13 var - width avgt 20 1061 . 052 ± 49 . 004 ns / op \n BenchmarkMapSubscript . mapSubscript 13 dictionary avgt 20 1118 . 587 ± 71 . 122 ns / op",542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ByteSelectiveStreamReader . java \n + import static com . facebook . presto . orc . reader . ReaderUtils . unpackByteNulls ; \n - if ( presentStream = = null & & positions [ positionCount - 1 ] = = positionCount - 1 ) { \n - / / contiguous chunk of rows , no nulls \n - dataStream . next ( values , positionCount ) ; \n + if ( positions [ positionCount - 1 ] = = positionCount - 1 ) { \n + if ( presentStream ! = null ) { \n + int nonNullCount = positionCount - presentStream . getUnsetBits ( positionCount , nulls ) ; \n + dataStream . next ( values , nonNullCount ) ; \n + unpackByteNulls ( values , nulls , positionCount , nonNullCount ) ; \n + } \n + else { \n + / / contiguous chunk of rows , no nulls \n + dataStream . next ( values , positionCount ) ; \n + } \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ ReaderUtils . java \n + public static void unpackByteNulls ( byte [ ] values , boolean [ ] isNull , int positionCount , int nonNullCount ) \n + { \n + int position = nonNullCount - 1 ; \n + for ( int i = positionCount - 1 ; i > = 0 ; i - - ) { \n + if ( ! isNull [ i ] ) { \n + values [ i ] = values [ position - - ] ; \n + } \n + else { \n + values [ i ] = 0 ; \n + } \n + } \n + } \n + \n",Optimize ByteSelectiveStreamReader for no filter with nulls \n Benchmark shows 25 % improvements : \n Before : \n Benchmark Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . read avgt 20 0 . 055 ± 0 . 002 s / op \n After : \n Benchmark Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . read avgt 20 0 . 041 ± 0 . 002 s / op,542
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ DictionaryBlock . java \n - sb . append ( "" positionCount = "" ) . append ( getPositionCount ( ) ) ; \n + sb . append ( "" positionCount = "" ) . append ( getPositionCount ( ) ) . append ( "" , "" ) ; \n + sb . append ( "" dictionary = "" ) . append ( dictionary . toString ( ) ) ; \n presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ RunLengthEncodedBlock . java \n - sb . append ( "" positionCount = "" ) . append ( positionCount ) ; \n + sb . append ( "" { positionCount = "" ) . append ( positionCount ) ; \n",Improve toString ( ) for DictionaryBlock and RunLengthEncodedBlock,542
presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ project \ InputPageProjection . java \n - result = block ; \n + result = block . getLoadedBlock ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ OptimizedPartitionedOutputOperator . java \n - page = page . getLoadedPage ( ) ; \n,Materialize LazyBlock in scan \n Fix the problem downstream operators might receive LazyBlock after scan \n introduced by https : / / github . com / prestodb / presto / pull / 14169,542
"rename from presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ scalar \ BenchmarkArrayIntersect . java \n rename to presto - main \ src \ test \ java \ com \ facebook \ presto \ operator \ scalar \ BenchmarkArraySetFunctions . java \n - public class BenchmarkArrayIntersect \n + public class BenchmarkArraySetFunctions \n - public List < Optional < Page > > arrayIntersect ( BenchmarkData data ) \n + public List < Optional < Page > > arrayFunction ( BenchmarkData data ) \n - private String name = "" array _ intersect "" ; \n + @ Param ( { "" array _ except "" , "" array _ intersect "" , "" array _ union "" } ) \n + private String name = "" array _ union "" ; \n - private int arraySize = 10 ; \n + private int arraySize = 1000 ; \n - new BenchmarkArrayIntersect ( ) . arrayIntersect ( data ) ; \n + new BenchmarkArraySetFunctions ( ) . arrayFunction ( data ) ; \n - new BenchmarkArrayIntersect ( ) . arrayIntersect ( data ) ; \n + new BenchmarkArraySetFunctions ( ) . arrayFunction ( data ) ; \n - . include ( "" . * "" + BenchmarkArrayIntersect . class . getSimpleName ( ) + "" . * "" ) \n + . include ( "" . * "" + BenchmarkArraySetFunctions . class . getSimpleName ( ) + "" . * "" ) \n",Replace BenchmarkArrayIntersectFunctions with BenchmarkArraySetFunctions \n This adds benchmarks for array _ except and array _ union as well .,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ scalar \ ArrayExceptFunction . java \n - import com . facebook . presto . common . block . BlockBuilder ; \n - import com . facebook . presto . operator . aggregation . TypedSet ; \n + import com . facebook . presto . operator . aggregation . OptimizedTypedSet ; \n + import static java . lang . Math . max ; \n + \n - TypedSet typedSet = new TypedSet ( type , leftPositionCount + rightPositionCount , "" array _ except "" ) ; \n - BlockBuilder distinctElementBlockBuilder = type . createBlockBuilder ( null , leftPositionCount ) ; \n - for ( int i = 0 ; i < rightPositionCount ; i + + ) { \n - typedSet . add ( rightArray , i ) ; \n - } \n - for ( int i = 0 ; i < leftPositionCount ; i + + ) { \n - if ( typedSet . add ( leftArray , i ) ) { \n - type . appendTo ( leftArray , i , distinctElementBlockBuilder ) ; \n - } \n - } \n - return distinctElementBlockBuilder . build ( ) ; \n + \n + OptimizedTypedSet typedSet = new OptimizedTypedSet ( type , max ( leftPositionCount , rightPositionCount ) ) ; \n + typedSet . union ( rightArray ) ; \n + typedSet . except ( leftArray ) ; \n + \n + return typedSet . getBlock ( ) ; \n",Optimize array _ except by using OptimizedTypedSet \n JMH benchmark shows 40 % improvement : \n Before \n Benchmark Mode Cnt Score Error Units \n BenchmarkArrayIntersect . arrayIntersect avgt 10 618074 . 452 ± 119912 . 203 ns / op \n After \n Benchmark Mode Cnt Score Error Units \n BenchmarkArrayIntersect . arrayIntersect avgt 10 376854 . 064 ± 21616 . 063 ns / op,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ scalar \ ArrayIntersectFunction . java \n - import com . facebook . presto . common . block . BlockBuilder ; \n - import com . facebook . presto . operator . aggregation . TypedSet ; \n + import com . facebook . presto . operator . aggregation . OptimizedTypedSet ; \n - int leftPositionCount = leftArray . getPositionCount ( ) ; \n - TypedSet rightTypedSet = new TypedSet ( type , rightPositionCount , "" array _ intersect "" ) ; \n - for ( int i = 0 ; i < rightPositionCount ; i + + ) { \n - rightTypedSet . add ( rightArray , i ) ; \n - } \n - \n - BlockBuilder blockBuilder = type . createBlockBuilder ( null , Math . min ( leftPositionCount , rightPositionCount ) ) ; \n - \n - / / The intersected set can have at most rightPositionCount elements \n - TypedSet intersectTypedSet = new TypedSet ( type , blockBuilder , rightPositionCount , "" array _ intersect "" ) ; \n - for ( int i = 0 ; i < leftPositionCount ; i + + ) { \n - if ( rightTypedSet . contains ( leftArray , i ) ) { \n - intersectTypedSet . add ( leftArray , i ) ; \n - } \n - } \n + OptimizedTypedSet typedSet = new OptimizedTypedSet ( type , rightPositionCount ) ; \n + typedSet . union ( rightArray ) ; \n + typedSet . intersect ( leftArray ) ; \n - return blockBuilder . build ( ) ; \n + return typedSet . getBlock ( ) ; \n",Optimize array _ intersect by using OptimizedTypedSet \n JMH benchmark shows 35 % improvement : \n Before \n Benchmark Mode Cnt Score Error Units \n BenchmarkArrayIntersect . arrayIntersect avgt 10 540349 . 423 ± 66298 . 751 ns / op \n After \n Benchmark Mode Cnt Score Error Units \n BenchmarkArrayIntersect . arrayIntersect avgt 10 350934 . 564 ± 34092 . 598 ns / op,542
"presto - spi \ src \ main \ java \ com \ facebook \ presto \ spi \ block \ BlockFlattener . java \n + int currentIdsOffset = dictionaryBlock . getOffsetBase ( ) ; \n + \n - newRemappedIds [ i ] = ids [ currentRemappedIds [ i ] + dictionaryBlock . getOffsetBase ( ) ] ; \n + newRemappedIds [ i ] = ids [ currentRemappedIds [ i + currentIdsOffset ] + dictionaryBlock . getOffsetBase ( ) ] ; \n + currentIdsOffset = 0 ; \n - \n + currentIdsOffset = 0 ; \n presto - spi \ src \ test \ java \ com \ facebook \ presto \ spi \ block \ TestBlockFlattenner . java \n + import static com . facebook . presto . spi . block . DictionaryId . randomDictionaryId ; \n + @ Test \n + public void testNestedDictionaryDictionaryLongArray ( ) \n + { \n + DictionaryBlock block = createTestDictionaryBlock ( createTestDictionaryBlock ( createLongArrayBlock ( 1 , 2 , 3 , 4 , 5 ) ) ) ; \n + assertFlattenNumericTypeBlock ( BIGINT , block , 5 , LongArrayBlock . class ) ; \n + } \n + \n + @ Test \n + public void testNestedDictionaryRleDictionaryLongArray ( ) \n + { \n + DictionaryBlock block = createTestDictionaryBlock ( createTestRleBlock ( createTestDictionaryBlock ( createLongArrayBlock ( 1 ) ) , 5 ) ) ; \n + assertFlattenNumericTypeBlock ( BIGINT , block , 1 , LongArrayBlock . class ) ; \n + } \n + \n - int [ ] dictionaryIndexes = createTestDictionaryIndexes ( block . getPositionCount ( ) ) ; \n - return new DictionaryBlock ( dictionaryIndexes . length , block , dictionaryIndexes ) ; \n + int idsOffset = ThreadLocalRandom . current ( ) . nextInt ( block . getPositionCount ( ) ) + 1 ; \n + int [ ] dictionaryIndexes = createTestDictionaryIndexes ( block . getPositionCount ( ) + idsOffset ) ; \n + return new DictionaryBlock ( idsOffset , block . getPositionCount ( ) , block , dictionaryIndexes , false , randomDictionaryId ( ) ) ; \n",Fix BlockFlattener when DictionaryBlock ' s idsOffset is nonzero,542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ BlockAssertions . java \n + import static com . facebook . presto . spi . block . DictionaryId . randomDictionaryId ; \n + import static java . lang . Math . min ; \n - int [ ] ids = IntStream . range ( 0 , positionCount ) . map ( i - > ThreadLocalRandom . current ( ) . nextInt ( dictionary . getPositionCount ( ) / 10 ) ) . toArray ( ) ; \n - return new DictionaryBlock ( dictionary , ids ) ; \n + return createRandomDictionaryBlock ( dictionary , positionCount , false ) ; \n + } \n + \n + public static DictionaryBlock createRandomDictionaryBlock ( Block dictionary , int positionCount , boolean isView ) \n + { \n + int idsOffset = 0 ; \n + if ( isView ) { \n + idsOffset = min ( ThreadLocalRandom . current ( ) . nextInt ( dictionary . getPositionCount ( ) ) , 1 ) ; \n + } \n + \n + int [ ] ids = IntStream . range ( 0 , positionCount + idsOffset ) . map ( i - > ThreadLocalRandom . current ( ) . nextInt ( dictionary . getPositionCount ( ) / 10 ) ) . toArray ( ) ; \n + return new DictionaryBlock ( idsOffset , positionCount , dictionary , ids , false , randomDictionaryId ( ) ) ; \n - wrappedBlock = createRandomDictionaryBlock ( wrappedBlock , positionCount ) ; \n + wrappedBlock = createRandomDictionaryBlock ( wrappedBlock , positionCount , true ) ; \n",Add support for testing DictionaryBlock with non - zero offset,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ PartitionedOutputOperator . java \n - private final LocalMemoryContext systemMemoryContext ; \n - private final long partitionsInitialRetainedSize ; \n - this . systemMemoryContext = operatorContext . newLocalSystemMemoryContext ( PartitionedOutputOperator . class . getSimpleName ( ) ) ; \n - this . partitionsInitialRetainedSize = this . partitionFunction . getRetainedSizeInBytes ( ) ; \n - this . systemMemoryContext . setBytes ( partitionsInitialRetainedSize ) ; \n - \n - / / We use getSizeInBytes ( ) here instead of getRetainedSizeInBytes ( ) for an approximation of \n - / / the amount of memory used by the pageBuilders , because calculating the retained \n - / / size can be expensive especially for complex types . \n - long partitionsSizeInBytes = partitionFunction . getSizeInBytes ( ) ; \n - \n - / / We also add partitionsInitialRetainedSize as an approximation of the object overhead of the partitions . \n - systemMemoryContext . setBytes ( partitionsSizeInBytes + partitionsInitialRetainedSize ) ; \n + private final LocalMemoryContext systemMemoryContext ; \n + this . systemMemoryContext = operatorContext . newLocalSystemMemoryContext ( PartitionedOutputOperator . class . getSimpleName ( ) ) ; \n + this . systemMemoryContext . setBytes ( getRetainedSizeInBytes ( ) ) ; \n - for ( PageBuilder pageBuilder : pageBuilders ) { \n - sizeInBytes + = pageBuilder . getSizeInBytes ( ) ; \n + if ( pageBuilders ! = null ) { \n + for ( PageBuilder pageBuilder : pageBuilders ) { \n + sizeInBytes + = pageBuilder . getSizeInBytes ( ) ; \n + } \n - for ( PageBuilder pageBuilder : pageBuilders ) { \n - sizeInBytes + = pageBuilder . getRetainedSizeInBytes ( ) ; \n + if ( pageBuilders ! = null ) { \n + for ( PageBuilder pageBuilder : pageBuilders ) { \n + sizeInBytes + = pageBuilder . getRetainedSizeInBytes ( ) ; \n + } \n + \n + / / We track the memory before it ' s flushed to avoid under counting when the page size is large . \n + systemMemoryContext . setBytes ( getRetainedSizeInBytes ( ) ) ; \n + \n",Fix memory tracking for PartitionedOutputOperator \n Previously the PartitionedOutputOperator tracks memory after finishing \n processing the page . This could cause severe under counting when the \n pages are very large and flush every time because flush ( ) resets the \n pageBuilders . This commit reports the memory before flush ( ) which is \n more accurate . It also changes the counting from getSizeInBytes ( ) to \n getRetainedSizeInBytes ( ) because the first was under counting for 20 % .,542
presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ ArrayBlockEncodingBuffer . java \n + valuesBuffers . noMoreBatches ( ) ; \n - \n - \n - valuesBuffers . noMoreBatches ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ MapBlockEncodingBuffer . java \n + valueBuffers . noMoreBatches ( ) ; \n + keyBuffers . noMoreBatches ( ) ; \n - \n - keyBuffers . noMoreBatches ( ) ; \n - valueBuffers . noMoreBatches ( ) ; \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ OptimizedPartitionedOutputOperator . java \n - for ( int i = 0 ; i < channelCount ; i + + ) { \n + for ( int i = channelCount - 1 ; i > = 0 ; i - - ) { \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ RowBlockEncodingBuffer . java \n + for ( int i = fieldBuffers . length - 1 ; i > = 0 ; i - - ) { \n + fieldBuffers [ i ] . noMoreBatches ( ) ; \n + } \n + \n - \n - for ( int i = 0 ; i < fieldBuffers . length ; i + + ) { \n - fieldBuffers [ i ] . noMoreBatches ( ) ; \n - } \n,"Return arrays in reverse order of borrowing \n OptimizedPartitionedOutputOperator uses SimpleArrayAllocator to reuse \n int arrays . SimpleArrayAllocator works in stack mode that most recently \n returned array would be borrowed out first next . To avoid unnecessary \n memory allocations due by mismatch between borrow and return order , \n make sure to return arrays in reverse order of borrowing .",542
presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ DecodedBlockNode . java \n - for ( DecodedBlockNode child : children ) { \n - size + = child . getRetainedSizeInBytes ( ) ; \n - } \n,Fix getRetainedSizeInBytes for DecodedBlockNode \n The DecodedBlockNode # getRetainedSizeInBytes ( ) used to add up the current \n node and all of its childrens ' sizes . But the decodedBlock in current \n node already covers all children ' s decodedBlocks . This commit removes \n the double counting by removing the children ' s retained sizes from the \n sum .,542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ BlockAssertions . java \n + import static java . lang . Math . max ; \n + checkArgument ( dictionary . getPositionCount ( ) > 0 , format ( "" dictionary ' s positionCount % d is less than or equal to 0 "" , dictionary . getPositionCount ( ) ) ) ; \n + \n - int [ ] ids = IntStream . range ( 0 , positionCount + idsOffset ) . map ( i - > ThreadLocalRandom . current ( ) . nextInt ( dictionary . getPositionCount ( ) / 10 ) ) . toArray ( ) ; \n + int [ ] ids = IntStream . range ( 0 , positionCount + idsOffset ) . map ( i - > ThreadLocalRandom . current ( ) . nextInt ( max ( dictionary . getPositionCount ( ) / 10 , 1 ) ) ) . toArray ( ) ; \n","Fix "" bound must be positive "" exception when creating DictionaryBlock",542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ BlockAssertions . java \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n - checkArgument ( positionCount > = 10 , "" positionCount is less than 10 "" ) ; \n - \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n + / / Note : Make sure positionCount is sufficiently large if nullRate is greater than 0 \n + / / Note : Make sure positionCount is sufficiently large if nestedNullRate or primitiveNullRate is greater than 0 \n presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ TestRowBasedSerialization . java \n - assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 20 , 0 . 5f , 0 , false , wrappings ) ) ) ; \n + assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 100 , 0 . 5f , 0 , false , wrappings ) ) ) ; \n - assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 22 , 0 , 0 . 5f , false , wrappings ) ) ) ; \n - assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 28 , 0 . 5f , 0 . 5f , false , wrappings ) ) ) ; \n + assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 100 , 0 , 0 . 5f , false , wrappings ) ) ) ; \n + assertRoundTrip ( types , ImmutableList . of ( createRandomBlockForType ( type , 100 , 0 . 5f , 0 . 5f , false , wrappings ) ) ) ; \n","Remove positionCount check in createRandomLongDecimalsBlock \n TestRowBasedSerialization sometimes fails calling \n createRandomLongDecimalsBlock with less than 10 positions . We should \n allow blocks with less than 10 positions to be created if there are \n such needs . This commit removes the check to enforce the positionCount \n check , and comments were added to suggest the user use a larger \n positinCount when desired nullRate > 0 .",542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ OptimizedPartitionedOutputOperator . java \n + import static com . facebook . presto . array . Arrays . ExpansionFactor . MEDIUM ; \n + import static com . facebook . presto . array . Arrays . ExpansionOption . PRESERVE ; \n + / / We initialize the size of the positions array in each partitionBuffers to be at most the incoming page ' s positionCount , or roughly two times of positionCount \n + / / divided by the number of partitions . This is because the latter could be greater than the positionCount when the number of partitions is 1 or positionCount is 1 . \n + int initialPositionCountForEachBuffer = min ( positionCount , ( positionCount / partitionFunction . getPartitionCount ( ) + 1 ) * 2 ) ; \n - partitionBuffers [ i ] . resetPositions ( positionCount ) ; \n + partitionBuffers [ i ] . resetPositions ( initialPositionCountForEachBuffer ) ; \n - private void resetPositions ( int positionCount ) \n + private void resetPositions ( int estimatedPositionCount ) \n - positions = ensureCapacity ( positions , positionCount ) ; \n + positions = ensureCapacity ( positions , estimatedPositionCount ) ; \n + positions = ensureCapacity ( positions , positionCount + 1 , MEDIUM , PRESERVE ) ; \n","Reduce positions array size in PartitionBuffer \n In OptimizedPartitionedOutputOperator , the PagePartioner has \n partitionCount number of PartitionBuffer , and each PartitionBuffer \n has a positions array to record the positions to be appended to this \n buffer . Previously this positions array was initialized to be the \n incoming page ' s positionCount size . This could waste lots of memory \n since each partition may only get a small portion of rows . This commit \n reduces the initial positions array size from positionCount to \n min ( positionCount , ( positionCount / partitionCount + 1 ) * 2 ) and \n grow it on the fly . \n JMH benchmark shows about 8 - 10 % gain in retained size : \n addPage		optimizedAddPage optimizedAddPage _ reducePositions Gain % \n bigint	 	 	335 , 715 , 874 	 424 , 471 , 312 	 	390 , 497 , 040 		 8 % \n ARRAY ( BIGINT ) 	 	327 , 680 , 906 	 294 , 847 , 046 	 	270 , 506 , 390 		 8 % \n ROW ( BIGINT , BIGINT ) 	315 , 490 , 496 	 261 , 529 , 566 	 	236 , 571 , 362 		 10 %",542
presto - docs \ src \ main \ sphinx \ admin \ properties . rst \n + ` ` driver . max - page - partitioning - buffer - count ` ` \n + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n + \n + * * * Type : * * ` ` integer ` ` \n + * * * Default value : * * ` ` 1000000 ` ` \n + \n + Maximum number of buffers used by repartitioning per driver . This number should be set \n + sufficiently large to avoid the error of requesting too many arrays from the array allocator \n + used in repartitioning . \n + \n,Add documentation for driver . max - page - partitioning - buffer - count,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ project \ PageProcessor . java \n - long pageSize = resultPage . getSizeInBytes ( ) ; \n + / / We use the getApproximateLogicalSizeInBytes ( ) instead of getSizeInBytes ( ) for several reasons : \n + / / \n + / / 1 . For DictionaryBlock , getSizeInBytes ( ) calculates the compacted size . For example a DictionaryBlock with ids [ 1 , 1 ] and dictionary with 3 elements of sizes \n + / / [ 5 , 100 , 10 ] would have sizeInBytes = 100 + 4 * 2 = 108 . However if both position 0 and 1 are being projected , the outcome block should contain the second \n + / / element of the dictionary twice and the actual size of the output block should be 100 * 2 at least . \n + / / \n + / / 2 . getSizeInBytes ( ) is more sensitive to skew and may cause false positives on a larger number of pages . Suppose there are multiple page / block views on a base \n + / / page / blocks . Page / BlockView 1 may happen to project positions with larger elements , while Page / BlockView 2 may project positions with smaller elements . \n + / / Using the sizeInBytes for view 1 may cause view 2 to be sized down which is not desired . On the other hand , getApproximateLogicalSizeInBytes ( ) returns amortized \n + / / sizes and is less jittery . \n + / / \n + / / 3 . getApproximateLogicalSizeInBytes ( ) is over 20x faster than getSizeInBytes ( ) for DictionaryBlock and RleBlocks , and it avoids excessive memory allocations \n + / / that was known to cause reliability issues . \n + long pageSize = resultPage . getApproximateLogicalSizeInBytes ( ) ; \n - pageSize + = blocks [ channel ] . getSizeInBytes ( ) ; \n + pageSize + = blocks [ channel ] . getApproximateRegionLogicalSizeInBytes ( 0 , blocks [ channel ] . getPositionCount ( ) ) ; \n - pageSize + = blocks [ channel ] . getSizeInBytes ( ) ; \n + pageSize + = blocks [ channel ] . getApproximateRegionLogicalSizeInBytes ( 0 , blocks [ channel ] . getPositionCount ( ) ) ; \n",Use getApproximateLogicalSizeInBytes ( ) in PageProcessor \n BenchmarkPageProcessor shows 21x improvment in throughput and 10x reduction in \n memory allocation and GC : \n Before \n Benchmark Mode Cnt Score Error Units \n BenchmarkPageProcessor . identityProjection thrpt 50 125261 . 816 ± 5342 . 200 ops / s \n BenchmarkPageProcessor . identityProjection : ·gc . alloc . rate thrpt 50 2439 . 004 ± 103 . 990 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . alloc . rate . norm thrpt 50 40832 . 029 ± 0 . 033 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Eden _ Space thrpt 50 2461 . 428 ± 364 . 315 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Eden _ Space . norm thrpt 50 41439 . 660 ± 6521 . 978 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Survivor _ Space thrpt 50 0 . 016 ± 0 . 016 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Survivor _ Space . norm thrpt 50 0 . 257 ± 0 . 267 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . count thrpt 50 46 . 000 counts \n BenchmarkPageProcessor . identityProjection : ·gc . time thrpt 50 181 . 000 ms \n After \n Benchmark Mode Cnt Score Error Units \n BenchmarkPageProcessor . identityProjection thrpt 10 2687127 . 250 ± 337956 . 918 ops / s \n BenchmarkPageProcessor . identityProjection : ·gc . alloc . rate thrpt 10 1118 . 285 ± 141 . 900 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . alloc . rate . norm thrpt 10 872 . 001 ± 0 . 005 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Eden _ Space thrpt 10 1050 . 013 ± 1683 . 604 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Eden _ Space . norm thrpt 10 827 . 947 ± 1329 . 288 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Survivor _ Space thrpt 10 0 . 012 ± 0 . 040 MB / sec \n BenchmarkPageProcessor . identityProjection : ·gc . churn . PS _ Survivor _ Space . norm thrpt 10 0 . 011 ± 0 . 034 B / op \n BenchmarkPageProcessor . identityProjection : ·gc . count thrpt 10 5 . 000 counts \n BenchmarkPageProcessor . identityProjection : ·gc . time thrpt 10 21 . 000 ms,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ ArrayBlockEncodingBuffer . java \n + . add ( "" estimatedOffsetBufferMaxCapacity "" , estimatedOffsetBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ ByteArrayBlockEncodingBuffer . java \n + . add ( "" estimatedValueBufferMaxCapacity "" , estimatedValueBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ Int128ArrayBlockEncodingBuffer . java \n + . add ( "" estimatedValueBufferMaxCapacity "" , estimatedValueBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ IntArrayBlockEncodingBuffer . java \n + . add ( "" estimatedValueBufferMaxCapacity "" , estimatedValueBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ LongArrayBlockEncodingBuffer . java \n + . add ( "" estimatedValueBufferMaxCapacity "" , estimatedValueBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ MapBlockEncodingBuffer . java \n + . add ( "" estimatedHashTableBufferMaxCapacity "" , estimatedHashTableBufferMaxCapacity ) \n + . add ( "" estimatedOffsetBufferMaxCapacity "" , estimatedOffsetBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ RowBlockEncodingBuffer . java \n + . add ( "" estimatedOffsetBufferMaxCapacity "" , estimatedOffsetBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ ShortArrayBlockEncodingBuffer . java \n + . add ( "" estimatedValueBufferMaxCapacity "" , estimatedValueBufferMaxCapacity ) \n presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ VariableWidthBlockEncodingBuffer . java \n + . add ( "" estimatedSliceBufferMaxCapacity "" , estimatedSliceBufferMaxCapacity ) \n + . add ( "" estimatedOffsetBufferMaxCapacity "" , estimatedOffsetBufferMaxCapacity ) \n",Print estimated buffer max capacities in BlockEncodingBuffers . toString ( ),542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ repartition \ VariableWidthBlockEncodingBuffer . java \n + import static com . facebook . presto . array . Arrays . ExpansionFactor . MEDIUM ; \n + int totalSliceLength = 0 ; \n + for ( int i = positionsOffset ; i < positionsOffset + batchSize ; i + + ) { \n + int position = positions [ i ] ; \n + totalSliceLength + = variableWidthBlock . getPositionOffset ( position + 1 ) - variableWidthBlock . getPositionOffset ( position ) ; \n + } \n + \n + sliceBuffer = ensureCapacity ( sliceBuffer , sliceBufferIndex + totalSliceLength , estimatedSliceBufferMaxCapacity , MEDIUM , PRESERVE , bufferAllocator ) ; \n + \n - sliceBuffer = ensureCapacity ( sliceBuffer , sliceBufferIndex + length , estimatedSliceBufferMaxCapacity , LARGE , PRESERVE , bufferAllocator ) ; \n - \n","Pre - calculate totalSliceLength before ensureCapacity \n ensureCapacity is quite expensive operation , and we want to minimize the \n callsites of it . This commit pre - calculates the totalSliceLength before \n allocating the sliceBuffer in ensureCapacity , so that only one \n ensureCapacity is called per batch .",542
"presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ TestSelectiveOrcReader . java \n - / / tester . testRoundTripTypes ( \n - / / ImmutableList . of ( VARCHAR , VARCHAR , VARCHAR ) , \n - / / ImmutableList . of ( newArrayList ( "" abc "" , "" def "" , null , "" hij "" , "" klm "" ) , newArrayList ( null , null , null , null , null ) , newArrayList ( "" abc "" , "" def "" , null , null , null ) ) , \n - / / toSubfieldFilters ( ImmutableMap . of ( \n - / / 0 , stringIn ( true , "" abc "" , "" def "" ) , \n - / / 1 , stringIn ( true , "" 10 "" , "" 11 "" ) , \n - / / 2 , stringIn ( true , "" def "" , "" abc "" ) ) ) ) ; \n + tester . testRoundTripTypes ( \n + ImmutableList . of ( VARCHAR , VARCHAR , VARCHAR ) , \n + ImmutableList . of ( newArrayList ( "" abc "" , "" def "" , null , "" hij "" , "" klm "" ) , newArrayList ( null , null , null , null , null ) , newArrayList ( "" abc "" , "" def "" , null , null , null ) ) , \n + toSubfieldFilters ( ImmutableMap . of ( \n + 0 , stringIn ( true , "" abc "" , "" def "" ) , \n + 1 , stringIn ( true , "" 10 "" , "" 11 "" ) , \n + 2 , stringIn ( true , "" def "" , "" abc "" ) ) ) ) ; \n",Restore commented out tests \n Restore the tests commented out in ` 443d10 Fix encryption with \n dictionary encodings `,542
"presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcBatchPageSourceFactory . java \n - orcDataSource , \n + reader . getOrcDataSource ( ) , \n presto - hive \ src \ main \ java \ com \ facebook \ presto \ hive \ orc \ OrcSelectivePageSourceFactory . java \n - orcDataSource , \n + reader . getOrcDataSource ( ) , \n presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ OrcReader . java \n - return createBatchRecordReader ( includedColumns , predicate , 0 , orcDataSource . getSize ( ) , hiveStorageTimeZone , systemMemoryUsage , initialBatchSize , columnsToIntermediateKeys ) ; \n + return createBatchRecordReader ( includedColumns , predicate , 0 , getOrcDataSource ( ) . getSize ( ) , hiveStorageTimeZone , systemMemoryUsage , initialBatchSize , columnsToIntermediateKeys ) ; \n - orcDataSource , \n + getOrcDataSource ( ) , \n - orcDataSource , \n + getOrcDataSource ( ) , \n + \n + public OrcDataSource getOrcDataSource ( ) \n + { \n + return orcDataSource ; \n + } \n","Create OrcPageSource using the OrcDataSource from OrcReader \n OrcReader would wrap the OrcDataSource with CachingOrcDataSource if the \n file is less than the tiny stripe threashold . However the PageSource in \n the scan operators would still use the original OrcDataSource . This \n is confusing since the OrcReader , OrcRecordReder , and StreamReaders all \n keep the CachingOrcDataSource while the PageSource keeps the underlying \n OrcDataSource . This commit creates the PageSource using the wrapped \n CachingOrcDataSource if the original OrcDataSource was wrapped .",542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ reader \ SliceDirectSelectiveStreamReader . java \n - lengthStream . nextIntVector ( nonNullCount , lengthVector , 0 ) ; \n + lengthStream . next ( lengthVector , nonNullCount ) ; \n",Improve reading the lengthVector in SliceDirectSelectiveStreamReader \n This commit uses a more CPU friendly API next ( ) to read all lengths . \n JMH benchmark when reading unbounded varchar for all rows : \n Baseline \n Benchmark ( withNulls ) Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . readAllBlocks PARTIAL avgt 5 0 . 109 ± 0 . 018 s / op \n BenchmarkSelectiveStreamReaders . readAllBlocks NONE avgt 5 0 . 102 ± 0 . 008 s / op \n After \n Benchmark ( withNulls ) Mode Cnt Score Error Units \n BenchmarkSelectiveStreamReaders . readAllBlocks PARTIAL avgt 5 0 . 107 ± 0 . 015 s / op \n BenchmarkSelectiveStreamReaders . readAllBlocks NONE avgt 5 0 . 084 ± 0 . 005 s / op,542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ RelationPlanner . java \n + Expression expression = Coercer . addCoercions ( row , analysis ) ; \n + expression = ExpressionTreeRewriter . rewriteWith ( new ParameterRewriter ( analysis . getParameters ( ) , analysis ) , expression ) ; \n + \n - Expression expression = ExpressionTreeRewriter . rewriteWith ( new ExpressionRewriter < Void > ( ) { \n + expression = ExpressionTreeRewriter . rewriteWith ( new ExpressionRewriter < Void > ( ) { \n - } , row ) ; \n - expression = Coercer . addCoercions ( expression , analysis ) ; \n - expression = ExpressionTreeRewriter . rewriteWith ( new ParameterRewriter ( analysis . getParameters ( ) , analysis ) , expression ) ; \n + } , expression ) ; \n presto - tests \ src \ main \ java \ com \ facebook \ presto \ tests \ AbstractTestQueries . java \n - \n - / / Dereference in VALUES node \n - assertQuery ( "" SELECT v FROM ( VALUES ( ARRAY [ CAST ( ROW ( 2 , ' a ' ) AS ROW ( int _ field BIGINT , str _ field VARCHAR ) ) ] [ 1 ] . str _ field ) ) AS t ( v ) "" , "" SELECT ' a ' "" ) ; \n","Revert "" Fix IllegalArgumentException in RelationPlanner "" \n This reverts commit dd7dad97aaf9e4b03d8ac87bac71feb9ae7a96e4 .",542
presto - docs \ src \ main \ sphinx \ admin \ properties . rst \n - ` ` driver . max - page - partitioning - buffer - count ` ` \n - ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ \n - \n - * * * Type : * * ` ` integer ` ` \n - * * * Default value : * * ` ` 1000000 ` ` \n - \n - Maximum number of buffers used by repartitioning per driver . This number should be set \n - sufficiently large to avoid the error of requesting too many arrays from the array allocator \n - used in repartitioning . \n - \n,Remove unused configuration property from properties . rst \n driver . max - page - partitioning - buffer - count was removed in 0 . 238 but \n the documentation for it was not removed . This commit removes it \n from the properties . rst documentation .,542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ sql \ gen \ BenchmarkPageProcessor . java \n + import com . facebook . presto . spi . relation . ConstantExpression ; \n + import org . openjdk . jmh . annotations . Param ; \n + @ SuppressWarnings ( "" unused "" ) \n + @ Param ( { "" true "" , "" false "" } ) \n + private boolean filterAlwaysFails ; \n + \n - / / where shipdate > = ' 1994 - 01 - 01 ' \n - / / and shipdate < ' 1995 - 01 - 01 ' \n - / / and discount > = 0 . 05 \n - / / and discount < = 0 . 07 \n - / / and quantity < 24 ; \n - private static final RowExpression createFilterExpression ( FunctionManager functionManager ) \n + \n + private final RowExpression createFilterExpression ( FunctionManager functionManager ) \n + if ( ! filterAlwaysFails ) { \n + return new ConstantExpression ( true , BOOLEAN ) ; \n + } \n + \n + / / where shipdate > = ' 1994 - 01 - 01 ' \n + / / and shipdate < ' 1995 - 01 - 01 ' \n + / / and discount > = 0 . 05 \n + / / and discount < = 0 . 07 \n + / / and quantity < 24 ; \n + / / This filters out 100 % of rows . \n - private static final class Tpch1FilterAndProject \n + private final class Tpch1FilterAndProject \n - private static void project ( int position , PageBuilder pageBuilder , Block extendedPriceBlock , Block discountBlock ) \n + private void project ( int position , PageBuilder pageBuilder , Block extendedPriceBlock , Block discountBlock ) \n - private static boolean filter ( int position , Block discountBlock , Block shipDateBlock , Block quantityBlock ) \n + private boolean filter ( int position , Block discountBlock , Block shipDateBlock , Block quantityBlock ) \n + if ( ! filterAlwaysFails ) { \n + return true ; \n + } \n + \n","Allow 100 % filter pass rate in BenchmarkPageProcessor \n Previously BenchmarkPageProcessor filters out 100 % rows , and this makes \n project was not tested at all . This commit adds a new option for the \n filter to pass all rows so that projection can be tested .",542
"presto - main \ src \ main \ java \ com \ facebook \ presto \ operator \ project \ GeneratedPageProjection . java \n - import com . facebook . presto . common . type . Type ; \n - private List < Type > types ; \n + \n + private List < BlockBuilder > blockBuilders ; \n - this . types = projections . stream ( ) . map ( RowExpression : : getType ) . collect ( toImmutableList ( ) ) ; \n + this . blockBuilders = projections . stream ( ) . map ( RowExpression : : getType ) . map ( type - > type . createBlockBuilder ( null , 1 ) ) . collect ( toImmutableList ( ) ) ; \n - List < BlockBuilder > blockBuilders = types . stream ( ) \n - . map ( type - > type . createBlockBuilder ( null , selectedPositions . size ( ) ) ) \n - . collect ( toImmutableList ( ) ) ; \n + blockBuilders = blockBuilders . stream ( ) . map ( blockBuilder - > blockBuilder . newBlockBuilderLike ( null , selectedPositions . size ( ) ) ) . collect ( toImmutableList ( ) ) ; \n","Reserve memory for nested BlockBuilders in projection \n In bf4bf6a610 "" Reserve memory before projecting rows "" we created the \n BlockBuilders new every time . However , nested BlockBuilders for complex \n types would lose the status from previously created BlockBuilders such \n that memory growth increased . For example , for an ARRAY ( BIGINT ) \n BlockBuilder , the nested LongArrayBlockBuilder would just have the same \n expectedEntries as the ArrayBlockBuilder although the entries in the \n LongArrayBlockBuilder could be a lot more . \n This commit uses the newly introduced newBlockBuilderLike ( ) method that \n estimates the expectedEntries for nested BlockBuilders from previously \n created BlockBuilders . The following simple ArrayTransform query shows \n the allocated long [ ] reduced from 118GB to 93GB on TPCH 100GB . \n select transform ( l _ array , x - > x + 1 ) from lineitem _ map _ array ;",542
"presto - orc \ src \ main \ java \ com \ facebook \ presto \ orc \ OrcWriter . java \n - import static java . lang . Integer . max ; \n + import static java . lang . Math . max ; \n - int averageLogicalSizePerRow = estimateAverageLogicalSizePerRow ( page ) ; \n - int maxChunkRowCount = max ( 1 , chunkMaxLogicalBytes / max ( 1 , averageLogicalSizePerRow ) ) ; \n + double averageLogicalSizePerRow = ( double ) page . getApproximateLogicalSizeInBytes ( ) / page . getPositionCount ( ) ; \n + int maxChunkRowCount = max ( 1 , ( int ) ( chunkMaxLogicalBytes / max ( 1 , averageLogicalSizePerRow ) ) ) ; \n - private int estimateAverageLogicalSizePerRow ( Page page ) \n - { \n - checkArgument ( page . getPositionCount ( ) > 0 , "" page is empty "" ) ; \n - / / sample at most 100 rows to estimate average row logical size \n - Page chunk = page . getRegion ( 0 , min ( page . getPositionCount ( ) , 100 ) ) ; \n - return toIntExact ( chunk . getLogicalSizeInBytes ( ) / chunk . getPositionCount ( ) ) ; \n - } \n - \n","Use more efficient getApproximateLogicalSizeInBytes in OrcWriter \n OrcWriter . estimateAverageLogicalSizePerRow has the top memory allocation \n in some KDS pipeline . Since the original code was to estimate the page ' s \n logical size and do not require accurate size to be calculated , this \n commit changes the call of the expensive getLogicalSizeInBytes method to \n a much faster and momory friendly method getApproximateLogicalSizeInBytes \n that estimate the approximate logical size of a page .",542
"presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ BenchmarkSelectiveStreamReaders . java \n - @ OutputTimeUnit ( TimeUnit . SECONDS ) \n + @ OutputTimeUnit ( TimeUnit . MILLISECONDS ) \n + "" 0 | 0 . 5 "" , \n + "" 0 . 1 | 0 . 5 "" , \n + "" 0 . 2 | 0 . 5 "" , \n + "" 0 . 3 | 0 . 5 "" , \n + "" 0 . 4 | 0 . 5 "" , \n + "" 0 . 5 | 0 . 5 "" , \n + "" 0 . 6 | 0 . 5 "" , \n + "" 0 . 7 | 0 . 5 "" , \n + "" 0 . 8 | 0 . 5 "" , \n + "" 0 . 9 | 0 . 5 "" , \n + "" 1 | 0 . 5 "" , \n + "" - 1 | - 1 "" , \n + "" 1 | 1 "" , \n",Add more filter rates to BenchmarkSelectiveStreamReaders \n This commit adds more filter rates to BenchmarkSelectiveStreamReader \n in order to test SliceDirectSelectiveStreamReader . readWithFilter ( ) . \n It also changes the reporting unit from second to millisecond since \n lots of operations only takes 1x ms per op now .,542
"presto - common \ src \ main \ java \ com \ facebook \ presto \ common \ block \ SingleMapBlock . java \n - match = mapBlock . getRawKeyBlock ( ) . bytesEqual ( offset / 2 + keyPosition , 0 , nativeValue , 0 , nativeValue . length ( ) ) ; \n + Block rawKeyBlock = mapBlock . getRawKeyBlock ( ) ; \n + \n + if ( rawKeyBlock . getSliceLength ( offset / 2 + keyPosition ) ! = nativeValue . length ( ) ) { \n + match = false ; \n + } \n + else { \n + match = rawKeyBlock . bytesEqual ( offset / 2 + keyPosition , 0 , nativeValue , 0 , nativeValue . length ( ) ) ; \n + } \n presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ TestMapBlock . java \n + import io . airlift . slice . Slices ; \n + import java . util . stream . IntStream ; \n + @ Test \n + public void testSeekKey ( ) \n + { \n + Block keyBlock = createStringsBlock ( "" k "" ) ; \n + Block valueBlock = createStringsBlock ( "" v "" ) ; \n + Block mapBlock = mapType ( VARCHAR , VARCHAR ) . createBlockFromKeyValue ( 1 , Optional . empty ( ) , IntStream . range ( 0 , 2 ) . toArray ( ) , keyBlock , valueBlock ) ; \n + SingleMapBlock singleMapBlock = ( SingleMapBlock ) mapBlock . getBlock ( 0 ) ; \n + / / Testing not found case . The key to seek should be longer than AbstractVariableWidthType # EXPECTED _ BYTES _ PER _ ENTRY ( 32 ) and has same hash code as the key in keyBlock . \n + / / This is because the default capacity of the slice of the keyBlock for 1 single character key is EXPECTED _ BYTES _ PER _ ENTRY . We want to make the seeked key out of boundary \n + / / to make sure no exception is thrown . \n + assertEquals ( singleMapBlock . seekKeyExact ( Slices . utf8Slice ( new String ( new char [ 10 ] ) . replace ( "" \ 0 "" , "" Doudou "" ) ) ) , - 1 ) ; \n + / / Testing found case . \n + assertEquals ( singleMapBlock . seekKeyExact ( Slices . utf8Slice ( "" k "" ) ) , 1 ) ; \n + } \n + \n","Fix SingleMapBlock . seekKeyExact bug \n When seeking map key of Slice type , we need to compare the bytes value \n in the key block to the key value . When the current position in the \n key block is shorter than the key ' s length , it could return wrong \n results or IndexOutOfBoundsException . This commit fixes this issue .",542
"presto - main \ src \ test \ java \ com \ facebook \ presto \ block \ BlockAssertions . java \n + import java . util . stream . StreamSupport ; \n - BlockBuilder builder = VARCHAR . createBlockBuilder ( null , 100 ) ; \n + BlockBuilder builder = VARCHAR . createBlockBuilder ( null , ( int ) StreamSupport . stream ( values . spliterator ( ) , false ) . count ( ) ) ; \n",Change BlockBuilder ' s expectedEntries to be the number of values,542
presto - orc \ src \ test \ java \ com \ facebook \ presto \ orc \ OrcTester . java \n - return filter = = IS _ NULL ; \n + return filter . testNull ( ) ; \n,"Fix testSubfieldValue in OrcTester \n When filtering the expected rows for ARRAY type , null rows would be \n mistakenly filtered out when the filter is not null but nullAllowed \n is true . This commit fixes this problem by calling filter . testNull ( ) .",542
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ explore \ ExploreIOActivity . java \n + Intent launchIntent = getIntent ( ) ; \n + if ( launchIntent ! = null & & ( ! Intent . ACTION _ MAIN . equals ( launchIntent . getAction ( ) ) \n + | | ! launchIntent . hasCategory ( Intent . CATEGORY _ LAUNCHER ) ) ) { \n + overridePendingTransition ( 0 , 0 ) ; \n + } \n android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ explore \ ExploreIOFragment . java \n - getActivity ( ) . overridePendingTransition ( 0 , 0 ) ; \n",Explore screen transition \n Bug : 27920235 \n Change - Id : Ia61f310f2d4d51543e34d20056ed33bca96f1c0c,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ session \ SessionDetailFragment . java \n + mAddScheduleFab . setVisibility ( View . INVISIBLE ) ; \n android \ src \ main \ res \ layout \ session _ detail _ frag . xml \n - android : visibility = "" invisible "" \n",Fix FAB disappearing on orientation change \n Bug : 28350917 \n Change - Id : I70d9f4673c04918d9ab80eddd0bfbafafcf40acc,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ explore \ SessionsAdapter . java \n + import android . os . Build ; \n + import android . os . Bundle ; \n - final ActivityOptionsCompat options = ActivityOptionsCompat \n - . makeSceneTransitionAnimation ( mHost , v , \n - mHost . getString ( R . string . transition _ session _ background ) ) ; \n - ActivityCompat . startActivity ( mHost , intent , options . toBundle ( ) ) ; \n + final Bundle options ; \n + if ( Build . VERSION . SDK _ INT = = 21 | | Build . VERSION . SDK _ INT = = 22 ) { / / Lollipop \n + options = null ; \n + } else { \n + options = ActivityOptionsCompat \n + . makeSceneTransitionAnimation ( mHost , v , \n + mHost . getString ( R . string . transition _ session _ background ) ) \n + . toBundle ( ) ; \n + } \n + ActivityCompat . startActivity ( mHost , intent , options ) ; \n",Disable activity transition on Lollipop \n Bug : 28343875 \n Change - Id : Ibdf4a29382559bf09456122342f9ba928a96e898,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ session \ SessionDetailFragment . java \n + if ( Build . VERSION . SDK _ INT < 21 ) { \n + / / Lollipop and above use drawable - v21 / ic _ session _ in _ schedule . xml \n + / / For older platforms , we need to set the initial state manually \n + mAddScheduleFab . setImageResource ( isInSchedule ? R . drawable . ic _ fab _ in _ schedule : \n + R . drawable . ic _ add _ to _ schedule ) ; \n + } \n rename from android \ src \ main \ res \ drawable \ ic _ session _ in _ schedule . xml \n rename to android \ src \ main \ res \ drawable - v21 \ ic _ session _ in _ schedule . xml \n android \ src \ main \ res \ values \ add _ to _ schedule . xml \n + < drawable name = "" ic _ session _ in _ schedule "" > @ null < / drawable > \n",Stop using animated - vector on API Level < 21 \n Bug : 28386920 \n Change - Id : Ib9b5a0e5e83030bedaed5a4734839c48b91fb71e,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ SearchActivity . java \n + import android . support . graphics . drawable . VectorDrawableCompat ; \n - Drawable up = DrawableCompat . wrap ( ContextCompat . getDrawable ( this , R . drawable . ic _ up ) ) ; \n + Drawable up = DrawableCompat . wrap ( \n + VectorDrawableCompat . create ( getResources ( ) , R . drawable . ic _ up , getTheme ( ) ) ) ; \n",Fix session search on API Level < 21 \n Bug : 28389292 \n Change - Id : Ib51007d7545923bb8004664c87c275db1c8dd5d9,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ session \ SessionDetailFragment . java \n + mAddScheduleFab . setVisibility ( mShowFab ? View . VISIBLE : View . INVISIBLE ) ; \n android \ src \ main \ res \ layout \ session _ detail _ frag . xml \n + android : visibility = "" invisible "" \n",Fix FAB visibility on API Level < 21 \n Bug : 28390453 \n Change - Id : I2dbe25d58397b1c61a299f0b28021245857f92ab,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ myschedule \ MyScheduleSingleDayFragment . java \n - getListView ( ) . addHeaderView ( getActivity ( ) . getLayoutInflater ( ) \n - . inflate ( \n - R . layout . reserve _ action _ bar _ space _ header _ view , \n - null ) ) ; \n - \n deleted file \n android \ src \ main \ res \ layout \ reserve _ action _ bar _ space _ header _ view . xml \n - < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n - < ! - - \n - Copyright 2014 Google Inc . All rights reserved . \n - \n - Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - you may not use this file except in compliance with the License . \n - You may obtain a copy of the License at \n - \n - http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - \n - Unless required by applicable law or agreed to in writing , software \n - distributed under the License is distributed on an "" AS IS "" BASIS , \n - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - See the License for the specific language governing permissions and \n - limitations under the License . \n - - - > \n - \n - < FrameLayout xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n - android : layout _ width = "" match _ parent "" \n - android : background = "" # ff000000 "" \n - android : layout _ height = "" 200dp "" > \n - \n - < / FrameLayout > \n",Remove the unused header on MySchedule \n Bug : 28389945 \n Change - Id : I42fa34ece274621b5a79e18438f741f71e91968a,545
android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ BaseActivity . java \n - mAppNavigationViewAsDrawer . updateNavigationItems ( ) ; \n + if ( mAppNavigationViewAsDrawer ! = null ) { \n + mAppNavigationViewAsDrawer . updateNavigationItems ( ) ; \n + } \n,Fix NPE in BaseActivity \n Bug : 28391365 \n Change - Id : I042860dc9c432698aa4de528a64bd89e26befa02,545
"android \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ explore \ ExploreSessionsActivity . java \n + import android . graphics . Bitmap ; \n + import com . bumptech . glide . request . RequestListener ; \n + import com . bumptech . glide . request . target . Target ; \n + / / Transition will be postponed until header image is loaded \n + supportPostponeEnterTransition ( ) ; \n - mImageLoader . loadImage ( headerImage , mHeaderImage ) ; \n + mImageLoader . loadImage ( headerImage , mHeaderImage , \n + new RequestListener < String , Bitmap > ( ) { \n + @ Override \n + public boolean onException ( final Exception e , final String model , \n + final Target < Bitmap > target , \n + final boolean isFirstResource ) { \n + supportStartPostponedEnterTransition ( ) ; \n + return false ; \n + } \n + \n + @ Override \n + public boolean onResourceReady ( final Bitmap resource , \n + final String model , final Target < Bitmap > target , \n + final boolean isFromMemoryCache , \n + final boolean isFirstResource ) { \n + target . onResourceReady ( resource , null ) ; \n + supportStartPostponedEnterTransition ( ) ; \n + return true ; \n + } \n + } ) ; \n + supportStartPostponedEnterTransition ( ) ; \n",Postpone transition until header is ready \n Bug : 28261264 \n Change - Id : I0a3346e3b60aa708f08a108f8e5512a62f1b9023,545
mobile \ build . gradle \n + shrinkResources true \n tv \ build . gradle \n + shrinkResources true \n wear \ build . gradle \n + shrinkResources true \n,Shrink resources \n Bug : 76133321 \n Change - Id : I409aa38bdf06fae7b9823a66b08a0957d516c9dd,545
build _ android _ release . sh \n - cp $ DIR / mobile / build / outputs / apk / release / mobile - release - unsigned . apk $ DIST _ DIR / release / \n - cp $ DIR / tv / build / outputs / apk / release / tv - release - unsigned . apk $ DIST _ DIR / release / \n - cp $ DIR / wear / build / outputs / apk / release / wear - release - unsigned . apk $ DIST _ DIR / release / \n + cp $ DIR / mobile / build / outputs / apk / release / mobile - release - unsigned . apk $ DIST _ DIR / release / mobile - release . apk \n + cp $ DIR / tv / build / outputs / apk / release / tv - release - unsigned . apk $ DIST _ DIR / release / tv - release . apk \n + cp $ DIR / wear / build / outputs / apk / release / wear - release - unsigned . apk $ DIST _ DIR / release / wear - release . apk \n,"Rename release APKs when copying to distribution \n Because otherwise signed APKs would have "" unsigned "" in their names . \n Bug : 72100411 \n Change - Id : I4a2a682860ebc86543a2fd6ab0db10498debb8d3",545
"build . gradle \n + / / App version \n + versionName = ' 6 . 0 . 0 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60000 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionCodeWear = versionCodeBase + 1 \n + versionCodeTv = versionCodeBase + 2 \n + versionCodeMobile = versionCodeBase + 3 \n + \n mobile \ build . gradle \n - versionCode 1 \n - versionName "" 1 . 0 "" \n + versionCode rootProject . versionCodeMobile \n + versionName rootProject . versionName \n tv \ build . gradle \n - versionCode 1 \n - versionName "" 1 . 0 "" \n + versionCode rootProject . versionCodeTv \n + versionName rootProject . versionName \n wear \ build . gradle \n - versionCode 1 \n - versionName "" 1 . 0 "" \n + versionCode rootProject . versionCodeWear \n + versionName rootProject . versionName \n",Configure version name and version codes \n Bug : 72100411 \n Change - Id : If577c6e7be8f3b2dbc85fef766d2652754929e7e,545
"tv \ src \ main \ res \ values \ strings . xml \n - < string name = "" search _ hint "" > Search for Google I / O sessions < / string > \n - < string name = "" search _ label "" > Google I / O < / string > \n - < string name = "" search _ settings _ description "" > Search sessions from Google I / O < / string > \n + < string name = "" search _ hint "" translation _ description = "" A placeholder text shown at the search box of I / O sessions . "" > Search for Google I / O sessions < / string > \n + < string name = "" search _ label "" translation _ description = "" The label shown at the search screen . "" > Google I / O < / string > \n + < string name = "" search _ settings _ description "" translation _ description = "" The explanation shown on the search screen of I / O sessions . "" > Search sessions from Google I / O < / string > \n",More translation descriptions \n Change - Id : I301c81ddec6c79af0ab1d34e88a81952ed01a7b8,545
"mobile \ src \ main \ res \ values \ strings . xml \n - < string name = "" dialog _ sign _ in _ content "" translation _ description = "" The content of the dialog . When the user needs to sign in . "" > Sign in to save events , reserve seats and rate sessions ( if an attendee ) . Actions will be synced from your account across app and site < / string > \n + < string name = "" dialog _ sign _ in _ content "" translation _ description = "" The content of the dialog . When the user needs to sign in . "" > Sign in to save events , reserve seats and rate sessions ( if an attendee ) . Actions will be synced from your account across app and site . < / string > \n",Fix a message for sign in \n Change - Id : If444b933a99115269747e5452a70373bf6a43669,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ reservation \ ReserveButton . kt \n + import com . google . samples . apps . iosched . util . srcAsync \n - setImageResource ( R . drawable . asld _ reservation ) \n + srcAsync ( this , R . drawable . asld _ reservation ) \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ ViewBindingAdapters . kt \n + import android . support . annotation . DrawableRes \n + import com . google . samples . apps . iosched . shared . domain . internal . DefaultScheduler \n + \n + / * * \n + * Loads a Drawable asynchronously . \n + * \n + * For most use cases , just use Glide . This method is particularly useful for \n + * AnimatedStateListDrawable . Its inflation is very heavy , and Glide does not support it . \n + * / \n + @ BindingAdapter ( "" srcAsync "" ) \n + fun srcAsync ( imageView : ImageView , @ DrawableRes id : Int ) { \n + val context = imageView . context \n + DefaultScheduler . execute { \n + val drawable = context . getDrawable ( id ) \n + imageView . post { \n + imageView . setImageDrawable ( drawable ) \n + } \n + } \n + } \n mobile \ src \ main \ res \ layout \ item _ session . xml \n + < import type = "" com . google . samples . apps . iosched . R "" / > \n - android : src = "" @ drawable / asld _ star _ event "" \n + app : srcAsync = "" @ { R . drawable . asld _ star _ event } "" \n",Load animated - selector asynchronously \n This makes inflation of session item about 30 % faster . \n Bug : 76448300 \n Change - Id : I1f6b61eafb030b10ab83a8e3fac043cee467f83e,545
"shared \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ shared \ domain \ sessions \ LoadUserSessionsByDayUseCase . kt \n - userSessions . forEach { _ , value - > value . forEach { it . session . type } } \n + userSessions . forEach { it . value . forEach { it . session . type } } \n",Replace Java8 foreach with Kotlin foreach \n Change - Id : I1813fb0fddd740b30c10ba2afd1359f117023d57,545
"playstore \ src \ main \ res \ values \ strings . xml \n - - > \n - < string name = "" playstore _ title "" translation _ description = "" The title of the app on Play Store . Max 30 characters . "" > Google I / O 2018 < / string > \n + < string name = "" playstore _ title "" translation _ description = "" The title of the app on Play Store . Max 50 characters . "" > Google I / O 2018 < / string > \n - < string name = "" playstore _ description "" translation _ description = "" Description on the Play Store . Max 400 characters "" > The official Google I / O 2018 conference app is your co - pilot to navigate the conference , whether you \ ' re attending in - person or remotely . With the app , you can : \ n \ n• Explore the conference schedule , with details on topics and speakers \ n• Save events to Schedule , your personalized schedule \ n• Get reminders before events you \ ' ve saved in Schedule start \ n• Sync your custom schedule between all of your devices and the I / O website \ n• Guide yourself using the vector - based conference map \ n• Opt - in to receive important notifications about the event , schedule , travel , after hours , session recordings and more \ n \ nExclusive for onsite attendees : \ n• Take advantage of facilitated pre - event WiFi configuration \ n• Reserve seats for events ahead of schedule \ n \ nSource code for the app will be available soon after I / O . < / string > \n + < string name = "" playstore _ description "" translation _ description = "" Description on the Play Store . Max 4000 characters "" > The official Google I / O 2018 conference app is your co - pilot to navigate the conference , whether you \ ' re attending in - person or remotely . With the app , you can : \ n \ n• Explore the conference schedule , with details on topics and speakers \ n• Save events to Schedule , your personalized schedule \ n• Get reminders before events you \ ' ve saved in Schedule start \ n• Sync your custom schedule between all of your devices and the I / O website \ n• Guide yourself using the vector - based conference map \ n• Opt - in to receive important notifications about the event , schedule , travel , after hours , session recordings and more \ n \ nExclusive for onsite attendees : \ n• Take advantage of facilitated pre - event WiFi configuration \ n• Reserve seats for events ahead of schedule \ n \ nSource code for the app will be available soon after I / O . < / string > \n",Fix max characters \n Change - Id : I14bdfe2ae990fa2931a5fff5e0d18941bca00216,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ widget \ CustomDimDialog . kt \n - background = ColorDrawable ( ResourcesCompat . getColor ( res , R . color . indigo _ transparent , \n + background = ColorDrawable ( ResourcesCompat . getColor ( res , R . color . scrim , \n",Change the color of dialog dim \n Bug : 77879199 \n Change - Id : I043c6f5c899fb9b3c0f6c54bc3f7870bae441054,545
"playstore \ src \ main \ res \ values \ strings . xml \n - - > \n - < string name = "" playstore _ tagline "" translation _ description = "" Short description on the Play Store . Max 80 characters "" > Your co - pilot to navigate I / O , whether you’re attending in - person or remotely . < / string > \n + < string name = "" playstore _ tagline "" translation _ description = "" Short description on the Play Store . Max 80 characters "" > Your co - pilot to navigate I / O , whether you \ ' re attending in - person or remotely . < / string > \n - < string name = "" playstore _ permission _ location _ information "" translation _ description = "" Explanation on the Play Store about why we need permission for location information "" > Location information : Needed for showing the venue map around the user ' s location . < / string > \n + < string name = "" playstore _ permission _ location _ information "" translation _ description = "" Explanation on the Play Store about why we need permission for location information "" > Location information : Needed for showing the venue map around the user \ ' s location . < / string > \n",Fix playstore strings \n Change - Id : Ie63c70b3916ef05e0c96ca9ec4ca3eeec8eef2dd,545
"mobile \ src \ main \ res \ values \ strings . xml \n - < string name = "" dont _ show "" translation _ description = "" The label for opting out Snackbar messages . "" > Don \ ' t show < / string > \n + < string name = "" dont _ show "" translation _ description = "" The label for opting out of in - app notification messages . "" > Don \ ' t show < / string > \n - < string name = "" a11y _ pinned "" translation _ description = "" Description of a button that used to show only starred and reserved events . "" > Only starred and reserved events < / string > \n + < string name = "" a11y _ pinned "" translation _ description = "" Description of a button that ' s used to show only starred and reserved events . "" > Only starred and reserved events < / string > \n",Backport some translation descriptions \n Change - Id : Ibb92b83457065d2c830557f90634b511e20fe263,545
"build . gradle \n - compileWearSdkVersion = 26 \n + compileWearSdkVersion = 27 \n - targetWearSdkVersion = 26 \n + targetWearSdkVersion = 27 \n - maven { \n - url "" $ mdc _ repo _ location "" \n + / / Material Design Components in Kokoro & local \n + if ( project . hasProperty ( ' mdc _ repo _ location ' ) ) { \n + maven { url "" $ mdc _ repo _ location "" } \n build _ android _ release . sh \n - echo $ ANDROID _ HOME \n + echo "" ANDROID _ HOME = $ ANDROID _ HOME "" \n - GRADLE _ PARAMS = "" - - stacktrace - - offline "" \n + GRADLE _ PARAMS = "" - - stacktrace "" \n + cp $ DIR / wear / build / outputs / apk / debug / wear - debug . apk $ DIST _ DIR / debug / \n + \n + # Staging \n + [ ! - d $ DIST _ DIR / staging ] & & mkdir $ DIST _ DIR / staging \n + cp $ DIR / mobile / build / outputs / apk / staging / mobile - staging . apk $ DIST _ DIR / staging / \n + cp $ DIR / tv / build / outputs / apk / staging / tv - staging . apk $ DIST _ DIR / staging / \n + cp $ DIR / wear / build / outputs / apk / release / wear - release - unsigned . apk $ DIST _ DIR / release / \n wear \ build . gradle \n + repositories { \n + / / - Other dependencies \n + maven { url "" $ { rootProject . projectDir } / . . / iosched - prebuilts / m2repository "" } \n + / / - Support Libraries , etc \n + maven { url "" $ { rootProject . projectDir } / . . / . . / . . / prebuilts / fullsdk / linux / extras / support / m2repository "" } \n + maven { url "" $ { rootProject . projectDir } / . . / . . / . . / prebuilts / fullsdk / linux / extras / android / m2repository "" } \n + } \n + \n",Update build scripts \n Condition out mdc _ repo _ location . Android Build Server does not know \n about it . \n The build script for Wear now declares offline repositories . \n Change - Id : Id09c3d5de432229c5a4ffb0ed4bad28652ec220b,545
"gradle . properties \n - registration _ url = < in local . gradle > \n - \n - conference _ data _ url = https : / / firebasestorage . googleapis . com / v0 / b / io2018 - festivus / o / sessions . json ? alt = media & token = 019af2ec - 9fd1 - 408e - 9b86 - 891e4f66e674 \n - \n - # # Map # # \n - iosched _ google _ maps _ api _ key = < in local . gradle > \n mobile \ build . gradle \n - resValue "" string "" , \n - "" google _ maps _ key "" , \n - ( project . findProperty ( "" iosched _ google _ maps _ api _ key "" ) ? : "" "" ) \n - \n + resValue "" string "" , \n + "" google _ maps _ key "" , \n + "" AIzaSyD5jqwKMm1SeoYsW25vxCXfTlhDBeZ4H5c "" \n + } \n + debug { \n + resValue "" string "" , \n + "" google _ maps _ key "" , \n + "" ABC "" / / TODO : Debug key \n - \n shared \ build . gradle \n - buildConfigField "" String "" , "" REGISTRATION _ ENDPOINT _ URL "" , "" \ "" $ { registration _ url } \ "" "" \n - buildConfigField "" String "" , "" CONFERENCE _ DATA _ URL "" , "" \ "" $ { conference _ data _ url } \ "" "" \n + buildConfigField "" String "" , "" REGISTRATION _ ENDPOINT _ URL "" , "" \ "" https : / / events - d07ac . appspot . com / _ ah / api / registration / v1 / register \ "" "" \n + buildConfigField "" String "" , "" CONFERENCE _ DATA _ URL "" , "" \ "" https : / / firebasestorage . googleapis . com / v0 / b / io2018 - festivus - prod / o / sessions . json ? alt = media & token = 89140adf - e228 - 45a5 - 9ae3 - 8ed01547166a \ "" "" \n + } \n + debug { \n + buildConfigField "" String "" , "" REGISTRATION _ ENDPOINT _ URL "" , "" \ "" https : / / events - dev - 62d2e . appspot . com / _ ah / api / registration / v1 / register \ "" "" \n + buildConfigField "" String "" , "" CONFERENCE _ DATA _ URL "" , "" \ "" https : / / firebasestorage . googleapis . com / v0 / b / io2018 - festivus / o / sessions . json ? alt = media & token = 019af2ec - 9fd1 - 408e - 9b86 - 891e4f66e674 \ "" "" \n - \n",Add keys \n Change - Id : I99e8973c27f0b95fa4e6f9fcff9ccc0a1d5f1312,545
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleUiHintsDialogFragment . kt \n + import android . content . DialogInterface \n - . setOnDismissListener { \n - markScheduleUiHintsShownUseCase ( ) \n - } \n + \n + override fun onDismiss ( dialog : DialogInterface ? ) { \n + markScheduleUiHintsShownUseCase ( ) \n + } \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ signin \ NotificationsPreferenceDialogFragment . kt \n + import android . content . DialogInterface \n - . setOnDismissListener { notificationsPrefShownActionUseCase ( true ) } \n + override fun onDismiss ( dialog : DialogInterface ? ) { \n + notificationsPrefShownActionUseCase ( true ) \n + } \n + \n,Fix dialogs showing up every time \n setOnDismissListener should not be used in DialogFragment . \n Bug : 126659251 \n Change - Id : I8353462908174e796bcbbffd4f2f444ca38876f0,545
"ar \ src \ main \ res \ values \ strings . xml \n - - > \n - < string name = "" feature _ explore _ ar "" translation _ description = "" The feature module name for exploring AR "" > Explore AR < / string > \n shared \ src \ main \ res \ values \ strings . xml \n + < string name = "" feature _ explore _ ar "" translation _ description = "" The feature module name for exploring AR "" > Explore AR < / string > \n",Fix the build \n Change - Id : Ib6f413c66cb8b1a0f7772a9f46f556f88b3f2565,545
"shared \ build . gradle \n - disable ' InvalidPackage ' \n + disable ' InvalidPackage ' , "" MissingTranslation "" \n",Fix kokoro \n Change - Id : I7b53f45463564828653af56bba60d42276f8903b,545
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleUiHintsDialogFragment . kt \n + super . onDismiss ( dialog ) \n mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ signin \ NotificationsPreferenceDialogFragment . kt \n + super . onDismiss ( dialog ) \n,Fix dialogs reappearing at onResume \n Bug : 129243909 \n Change - Id : I964cb9c6e26aca50b88a45f728ad48aac2bbc13c,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ signin \ SignInDialogFragment . kt \n + import android . content . Intent \n + import com . google . samples . apps . iosched . shared . result . EventObserver \n - signInViewModel . performSignInEvent . observe ( this , Observer { request - > \n - if ( request . peekContent ( ) = = RequestSignIn ) { \n - request . getContentIfNotHandled ( ) \n - activity ? . let { \n - signInHandler . makeSignInIntent ( ) . observe ( this , Observer { \n - startActivityForResult ( it , REQUEST _ CODE _ SIGN _ IN ) \n - } ) \n + signInViewModel . performSignInEvent . observe ( this , EventObserver { request - > \n + if ( request = = RequestSignIn ) { \n + activity ? . let { activity - > \n + val signInIntent = signInHandler . makeSignInIntent ( ) \n + val observer = object : Observer < Intent ? > { \n + override fun onChanged ( it : Intent ? ) { \n + activity . startActivityForResult ( it , REQUEST _ CODE _ SIGN _ IN ) \n + signInIntent . removeObserver ( this ) \n + } \n + } \n + signInIntent . observeForever ( observer ) \n",Fix the sign - in dialog not starting sign - in \n Bug : 129373974 \n Change - Id : Ifd18d3da1e9c5d34353d260619798ef1bcdf34c3,545
shared \ build . gradle \n - minifyEnabled false \n,Attempt to fix the ProGuard error \n Change - Id : I8f622972dd155a7a686f2cd704c6e62d32d12dc7,545
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleFragment . kt \n + scheduleViewModel . clearFilters ( ) \n,"Fix "" View your schedule "" on Feed \n Existing filters are cleared . \n Bug : 130524093 \n Change - Id : I86a282294e53215227f2994c3b734d28b9e2b7c8",545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ reservation \ StarReserveFab . kt \n - var reservationStatus = ReservationViewState . RESERVATION _ DISABLED \n + var reservationStatus : ReservationViewState ? = null \n - contentDescription = context . getString ( value . contentDescription ) \n + if ( value ! = null ) { \n + contentDescription = context . getString ( value . contentDescription ) \n + } \n - mergeDrawableStates ( drawableState , reservationStatus . state ) \n + mergeDrawableStates ( drawableState , reservationStatus ? . state ) \n",Fix StarReserveFab when ReservationViewState is DISABLED \n Bug : 130595449 \n Change - Id : I7c2a3da4e997d7f2360fd256550f97cee82eb7b6,545
"shared \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ shared \ data \ session \ json \ SessionDeserializer . kt \n - isLivestream = obj . get ( "" livestream "" ) . asBoolean , \n + isLivestream = obj . get ( "" youtubeVideoType "" ) ? . asString = = "" livestream "" | | \n + obj . get ( "" livestream "" ) ? . asBoolean = = true , \n",Parse youtubeVideoType \n Bug : 130515182 \n Change - Id : I7eaccf73f83b0335850bbbe1915e919a8fd6b4ee,545
"mobile \ src \ main \ res \ values \ strings . xml \n - < string name = "" onboarding _ date _ location "" translation _ description = "" The date and the place of Google I / O 2019 . "" > May 7–9 , 2019 \ nMountain View , CA < / string > \n + < string name = "" onboarding _ date _ location "" translation _ description = "" The date and the place of Google I / O 2019 . [ CHAR _ LIMIT = 80 ] "" > May 7–9 , 2019 \ nMountain View , CA < / string > \n - < string name = "" assistant _ app _ description "" translation _ description = "" Text explaining the I / O 19 app for Google Assistant . "" > Use the I / O 19 Action on Google Assistant . < / string > \n - < string name = "" assistant _ app _ description2 "" translation _ description = "" Text explaining the I / O 19 app for Google Assistant . "" > Just say \ "" Hey Google , talk to Google I / O 19 \ "" ! < / string > \n + < string name = "" assistant _ app _ description "" translation _ description = "" Text explaining the I / O 19 app for Google Assistant . [ CHAR _ LIMIT = 100 ] "" > Use the I / O 19 Action on Google Assistant . < / string > \n + < string name = "" assistant _ app _ description2 "" translation _ description = "" Text explaining the I / O 19 app for Google Assistant . [ CHAR _ LIMIT = 100 ] "" > Just say \ "" Hey Google , talk to Google I / O 19 \ "" ! < / string > \n",Add CHAR _ LIMIT to new strings \n Change - Id : I88effbd2cdebbcc66fb51129d173fb5aed9ecc34,545
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ sessiondetail \ SessionDetailViewModel . kt \n - ! userEvent . isReviewed & & \n - currentSession . type = = SessionType . SESSION & & \n + isSignedIn ( ) & & \n + ! userEvent . isReviewed & & \n + currentSession . type = = SessionType . SESSION & & \n,"Fix "" Rate Session "" visibility \n The button is visible only when all of these are true : \n - The user is signed in \n - The event is a session \n - The sesion is over \n Bug : 130841598 \n Change - Id : I3b8f645bd05601b296fdb8c5b0a0e7601353f9e0",545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleFragment . kt \n + import com . google . samples . apps . iosched . util . requestApplyInsetsWhenAttached \n + binding . coordinatorLayout . postDelayed ( { \n + binding . coordinatorLayout . requestApplyInsetsWhenAttached ( ) \n + } , 500 ) \n",Mitigate the filter inset issue \n This does not fix the issue but makes it less noticeable by adjusting its position afterwards . \n Bug : 130523711 \n Change - Id : I3da541e4d4e2806f1b2103bf085d91144284d719,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ widget \ CountdownView . kt \n - if ( compositions . ready ) { \n + compositions . doOnReady { \n - } \n - handler ? . postDelayed ( this , 1 _ 000L ) / / Run self every second \n + handler ? . postDelayed ( this , 1 _ 000L ) / / Run self every second \n + } \n + private var doOnReadyCallback : ( ( ) - > Unit ) ? = null \n + \n + if ( ready ) { \n + doOnReadyCallback ? . let { \n + it ( ) \n + doOnReadyCallback = null \n + } \n + } \n + fun doOnReady ( body : ( ) - > Unit ) { \n + if ( ready ) { \n + body ( ) \n + } else { \n + doOnReadyCallback = body \n + } \n + } \n + \n",The countdown starts faster \n Bug : 131243685 \n Change - Id : I8690901c525c9a64370852d04658d21e34f3a119,545
"build . gradle \n - versionName = ' 7 . 0 . 11 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 70110 / / XYYZZM ; M = Module ( tv , mobile ) \n + versionName = ' 7 . 0 . 12 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 70120 / / XYYZZM ; M = Module ( tv , mobile ) \n",Bump the version to 7 . 0 . 12 \n Change - Id : I906efa0f38683a09c08fc4b2ad040831c542e167,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleFragment . kt \n + binding . coordinatorLayout . postDelayed ( { \n + binding . coordinatorLayout . requestApplyInsetsWhenAttached ( ) \n + } , 500 ) \n + \n - binding . coordinatorLayout . postDelayed ( { \n - binding . coordinatorLayout . requestApplyInsetsWhenAttached ( ) \n - } , 500 ) \n",Fix the filter sheet hidden by the status bar \n Change - Id : I039474563ace0ce66c6f53325aae41e3c6dcf807,545
"mobile \ src \ main \ res \ layout \ fragment _ onboarding . xml \n + android : importantForAccessibility = "" no "" \n","Fix onboarding a11y \n This ungroups the pages in the ViewPager , and Talkback can announce the texts one by one . \n Bug : 130135509 \n Change - Id : Ic1faf2caf5104f36ee096442fa2460fa17563b7d",545
"mobile \ src \ main \ res \ values \ strings . xml \n - < string name = "" onboarding _ date _ location "" translation _ description = "" The date and the place of Google I / O 2018 . "" > May 8–10 , \ n2018 Mountain View , CA < / string > \n + < string name = "" onboarding _ date _ location "" translation _ description = "" The date and the place of Google I / O 2019 . "" > May 7–9 , \ n2019 Mountain View , CA < / string > \n",Fix the dates on the onboarding screen \n Change - Id : I8636a1d6f39a9293d153ad2b2ffffaf9f7ed8833,545
"mobile \ src \ main \ res \ layout \ item _ session _ info . xml \n + android : importantForAccessibility = "" no "" \n",Fix the session detail screen grouping many items \n Talkback can now announce each of the texts separately . \n Bug : 130135564 \n Change - Id : Id83da5681703e3061781ef1c92671b8a27fb401a,545
shared \ src \ main \ res \ xml \ remote _ config _ defaults . xml \n - < value > false < / value > \n + < value > true < / value > \n,Enable map by default \n Change - Id : Ib8e249ed2262e933048a2985e77c338fd18301d6,545
"mobile \ src \ main \ res \ values - night \ colors . xml \n + < color name = "" header _ grid "" > # 222 < / color > \n mobile \ src \ main \ res \ values \ colors . xml \n + < color name = "" header _ grid "" > # e6e6e6 < / color > \n mobile \ src \ main \ res \ values \ styles . xml \n - < item name = "" android : color "" > ? attr / colorControlLight < / item > \n + < item name = "" android : color "" > @ color / header _ grid < / item > \n",Fix the title background on the session detail \n Bug : 130201050 \n Change - Id : Ic80f0f9f393240baf965ca9d2e19af993b8e6c77,545
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ ViewBindingAdapters . kt \n + if ( url . isBlank ( ) ) { \n + return \n + } \n mobile \ src \ main \ res \ layout \ item _ codelab . xml \n - app : goneUnless = "" @ { isExpanded } "" \n + app : goneUnless = "" @ { isExpanded & amp ; & amp ; codelab . hasUrl ( ) } "" \n model \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ model \ Codelab . kt \n - ) \n + ) { \n + fun hasUrl ( ) = ! codelabUrl . isBlank ( ) \n + } \n",Fix a crash on the codelab screen \n Change - Id : Ia825ee2622f0fb47e74a5507e533a9a745d8ddf1,545
"mobile \ src \ main \ res \ layout \ item _ session _ info . xml \n - app : layout _ constraintTop _ toBottomOf = "" @ id / session _ detail _ recorded "" \n + app : layout _ constraintTop _ toBottomOf = "" @ id / session _ detail _ level "" \n",Fix texts overlapping on the session detail screen \n Bug : 130273573 \n Change - Id : I0526bddc69d51b15e8ac462448162015b91d7f50,545
"mobile \ src \ main \ res \ layout \ item _ question . xml \n + android : minHeight = "" @ dimen / a11y _ min _ touch _ target "" \n",Make the feedback sliders taller \n Bug : 130288022 \n Change - Id : Ice9e5ae7d6a5bb815dfb3265fd4064ab6a0ba10c,545
build _ android _ release . sh \n - cp $ MOBILE _ OUT / bundle / debug / mobile . aab $ DIST _ DIR / mobile - debug . aab \n + cp $ MOBILE _ OUT / bundle / debug / mobile - debug . aab $ DIST _ DIR / mobile - debug . aab \n - cp $ MOBILE _ OUT / bundle / staging / mobile . aab $ DIST _ DIR / mobile - staging . aab \n + cp $ MOBILE _ OUT / bundle / staging / mobile - staging . aab $ DIST _ DIR / mobile - staging . aab \n - cp $ MOBILE _ OUT / bundle / release / mobile . aab $ DIST _ DIR / mobile - release . aab \n + cp $ MOBILE _ OUT / bundle / release / mobile - release . aab $ DIST _ DIR / mobile - release . aab \n,Fix paths of AAB files \n Change - Id : I339c76fb1d19be028645890a32c0a0af1344f90f,545
". travis . yml \n - $ HOME / . m2 \n + \n + addons : \n + apt : \n + packages : \n + - oracle - java8 - installer \n pom . xml \n - < ! - - ALPN library targeted to Java 8 update 25 . - - > \n - < alpn . jdk8 . version > 8 . 1 . 2 . v20141202 < / alpn . jdk8 . version > \n + < ! - - ALPN library targeted to Java 8 update 71 - 74 - - > \n + < alpn . jdk8 . version > 8 . 1 . 7 . v20160121 < / alpn . jdk8 . version > \n + < profile > \n + < id > jdk9 < / id > \n + < activation > \n + < jdk > 9 < / jdk > \n + < / activation > \n + < ! - - Not currently used , but visible in Intellij etc - - > \n + < / profile > \n",build with new alpn - boot and jdk in travis,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ CallTest . java \n + import java . util . LinkedHashSet ; \n + import java . util . Set ; \n - callback . await ( request . url ( ) ) . assertBody ( "" abc "" ) ; \n - callback . await ( request . url ( ) ) . assertBody ( "" def "" ) ; \n + RecordedResponse firstResponse = callback . await ( request . url ( ) ) . assertSuccessful ( ) ; \n + RecordedResponse secondResponse = callback . await ( request . url ( ) ) . assertSuccessful ( ) ; \n + \n + Set < String > bodies = new LinkedHashSet < > ( ) ; \n + bodies . add ( firstResponse . getBody ( ) ) ; \n + bodies . add ( secondResponse . getBody ( ) ) ; \n + \n + assertTrue ( bodies . contains ( "" abc "" ) ) ; \n + assertTrue ( bodies . contains ( "" def "" ) ) ; \n - * OkHttp has a bug where a ` Connection : close ` response header is not honored when establishing \n - * a TLS tunnel . https : / / github . com / square / okhttp / issues / 2426 \n + * OkHttp has a bug where a ` Connection : close ` response header is not honored when establishing a \n + * TLS tunnel . https : / / github . com / square / okhttp / issues / 2426 \n okhttp - tests \ src \ test \ java \ okhttp3 \ RecordedResponse . java \n + \n + public String getBody ( ) { \n + return body ; \n + } \n",fix flaky test CallTest . legalToExecuteTwiceCloning _ Async,547
pom . xml \n + < profile > \n + < id > alpn - when - jdk8 _ 112 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 112 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 9 . v20160720 < / alpn . jdk8 . version > \n + < / properties > \n + < / profile > \n,version bump for JDK 8 ( 112 ),547
"okhttp \ src \ main \ java \ okhttp3 \ EventListener . java \n + / * * \n + * EventListener for analytic events for an OkHttpClient instance . \n + * \n + * < p > All start / connect / acquire events will eventually receive a matching end / release event , \n + * either successful ( non - null parameters ) , or failed ( non - null throwable ) . The first common \n + * parameters of each event pair are used to link the event in case of concurrent or repeated \n + * events e . g . dnsStart ( call , domainName ) - > dnsEnd ( call , domainName , inetAddressList , throwable ) . \n + * \n + * < p > Nesting is as follows \n + * < ul > \n + * < li > call - > ( dns - > connect - > secure connect ) * - > request events < / li > \n + * < li > call - > ( connection acquire / release ) * < / li > \n + * < / ul > \n + * \n + * < p > Request events are ordered : requestHeaders - > requestBody - > responseHeaders - > responseBody \n + * \n + * < p > Since connections may be reused , the dns and connect events may not be present for a call , \n + * or may be repeated in case of failure retries , even concurrently in case of happy eyeballs type \n + * scenarios . A redirect cross domain , or to use https may cause additional connection and request \n + * events . \n + * \n + * < p > All events must fast , without external locking , cannot throw exceptions , \n + * attempt to mutate the event parameters , or be reentrant back into the client . \n + * Any IO - writing to files or network should be done asynchronously . \n + * / \n okhttp \ src \ main \ java \ okhttp3 \ OkHttpClient . java \n + / * * \n + * Configure a single client scoped listener that will receive all analytic events \n + * for this client . \n + * \n + * @ see EventListener for semantics and restrictions on listener implementations . \n + * / \n + / * * \n + * Configure a factory to provide per - call scoped listeners that will receive analytic events \n + * for this client . \n + * \n + * @ see EventListener for semantics and restrictions on listener implementations . \n + * / \n",Event docs ( # 3505 ) \n * Event docs \n * update docs,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ EventListenerTest . java \n - . url ( server . url ( "" / "" ) ) \n - . build ( ) ) ; \n + . url ( server . url ( "" / "" ) ) \n + . build ( ) ) ; \n - "" ConnectStart "" , "" SecureConnectStart "" , "" SecureConnectEnd "" , "" ConnectEnd "" , \n - "" RequestHeadersStart "" , "" RequestHeadersEnd "" , "" ResponseHeadersStart "" , "" ResponseHeadersEnd "" , \n - "" ResponseBodyStart "" , "" FetchEnd "" , "" ResponseBodyEnd "" , "" ConnectionReleased "" ) ; \n + "" ConnectStart "" , "" SecureConnectStart "" , "" SecureConnectEnd "" , "" ConnectEnd "" , \n + "" RequestHeadersStart "" , "" RequestHeadersEnd "" , "" ResponseHeadersStart "" , "" ResponseHeadersEnd "" , \n + "" ResponseBodyStart "" , "" FetchEnd "" , "" ResponseBodyEnd "" , "" ConnectionReleased "" ) ; \n - new MockResponse ( ) . setBodyDelay ( 100 , TimeUnit . MILLISECONDS ) . setChunkedBody ( "" Hello ! "" , 2 ) ) ; \n + new MockResponse ( ) . setBodyDelay ( 100 , TimeUnit . MILLISECONDS ) . setChunkedBody ( "" Hello ! "" , 2 ) ) ; \n okhttp \ src \ main \ java \ okhttp3 \ EventListener . java \n - * < p > All events must fast , without external locking , cannot throw exceptions , \n + * < p > All event methods must execute fast , without external locking , cannot throw exceptions , \n - * < li > The { @ link Call # request ( ) } requires TLS . < / li > \n - * < li > No existing connection from the { @ link ConnectionPool } can be reused . < / li > \n + * < li > The { @ link Call # request ( ) } requires TLS . < / li > \n + * < li > No existing connection from the { @ link ConnectionPool } can be reused . < / li > \n okhttp \ src \ main \ java \ okhttp3 \ WebSocketListener . java \n - / * * Invoked when the remote peer has indicated that no more incoming messages will be transmitted . * / \n + / * * \n + * Invoked when the remote peer has indicated that no more incoming messages will be \n + * transmitted . \n + * / \n",minor cleanup of EventListener formatting ( # 3509 ) \n * minor cleanup of EventListener formatting \n * remove awkward plural \n * fix websocket line length,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ ws \ RealWebSocketTest . java \n + @ Test public void clientCloseWith0Fails ( ) throws IOException { \n + try { \n + client . webSocket . close ( 0 , null ) ; \n + } catch ( IllegalArgumentException expected ) { \n + assertEquals ( expected . getMessage ( ) , "" Code must be in range [ 1000 , 5000 ) : 0 "" ) ; \n + } \n + } \n + \n okhttp \ src \ main \ java \ okhttp3 \ WebSocket . java \n - * href = "" http : / / tools . ietf . org / html / rfc6455 # section - 7 . 4 "" > Section 7 . 4 of RFC 6455 < / a > or { @ code 0 } . \n + * href = "" http : / / tools . ietf . org / html / rfc6455 # section - 7 . 4 "" > Section 7 . 4 of RFC 6455 < / a > . \n + * @ throws IllegalArgumentException if code is invalid . \n",Remove WebSocket API support for optional close code ( # 3540 ) \n Remove public API support for optional close code ( 0 ),547
"okhttp \ src \ main \ java \ okhttp3 \ OkHttpClient . java \n - X509TrustManager trustManager = Platform . get ( ) . trustManager ( sslSocketFactory ) ; \n - if ( trustManager = = null ) { \n - throw new IllegalStateException ( "" Unable to extract the trust manager on "" + Platform . get ( ) \n - + "" , sslSocketFactory is "" + sslSocketFactory . getClass ( ) ) ; \n - } \n - this . certificateChainCleaner = CertificateChainCleaner . get ( trustManager ) ; \n + this . certificateChainCleaner = Platform . get ( ) . buildCertificateChainCleaner ( sslSocketFactory ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ AndroidPlatform . java \n - @ Override public X509TrustManager trustManager ( SSLSocketFactory sslSocketFactory ) { \n + @ Override protected X509TrustManager trustManager ( SSLSocketFactory sslSocketFactory ) { \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ Platform . java \n - public X509TrustManager trustManager ( SSLSocketFactory sslSocketFactory ) { \n + protected X509TrustManager trustManager ( SSLSocketFactory sslSocketFactory ) { \n + public CertificateChainCleaner buildCertificateChainCleaner ( SSLSocketFactory sslSocketFactory ) { \n + X509TrustManager trustManager = trustManager ( sslSocketFactory ) ; \n + \n + if ( trustManager = = null ) { \n + throw new IllegalStateException ( "" Unable to extract the trust manager on "" + Platform . get ( ) \n + + "" , sslSocketFactory is "" + sslSocketFactory . getClass ( ) ) ; \n + } \n + \n + return buildCertificateChainCleaner ( trustManager ) ; \n + } \n + \n",Platform cleanup - move trust manager building internal ( # 3611 ) \n * Platform cleanup move trust manager building internal \n * typo \n * missing commit,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ CallTest . java \n + @ Test public void httpWithExcessiveHeaders ( ) throws IOException { \n + String longLine = "" HTTP / 1 . 1 200 "" + stringFill ( ' O ' , 256 * 1024 ) + "" K "" ; \n + \n + server . setProtocols ( Collections . singletonList ( Protocol . HTTP _ 1 _ 1 ) ) ; \n + \n + server . enqueue ( new MockResponse ( ) \n + . setStatus ( longLine ) \n + . setBody ( "" I ' m not even supposed to be here today . "" ) ) ; \n + \n + executeSynchronously ( "" / "" ) \n + . assertFailureMatches ( "" . * unexpected end of stream on Connection . * "" ) ; \n + } \n + \n + private String stringFill ( char fillChar , int length ) { \n + char [ ] value = new char [ length ] ; \n + Arrays . fill ( value , fillChar ) ; \n + return new String ( value ) ; \n + } \n + \n okhttp - tests \ src \ test \ java \ okhttp3 \ RecordedResponse . java \n - assertNotNull ( failure ) ; \n + assertNotNull ( "" No failure found "" , failure ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ http1 \ Http1Codec . java \n + private static final int HEADER _ LIMIT = Integer . getInteger ( "" okhttp . headerlimit "" , 256 * 1024 ) ; \n + private long headerLimit = HEADER _ LIMIT ; \n - StatusLine statusLine = StatusLine . parse ( source . readUtf8LineStrict ( ) ) ; \n + StatusLine statusLine = StatusLine . parse ( readHeaderLine ( ) ) ; \n + private String readHeaderLine ( ) throws IOException { \n + String line = source . readUtf8LineStrict ( headerLimit ) ; \n + headerLimit - = line . length ( ) ; \n + return line ; \n + } \n + \n - for ( String line ; ( line = source . readUtf8LineStrict ( ) ) . length ( ) ! = 0 ; ) { \n + for ( String line ; ( line = readHeaderLine ( ) ) . length ( ) ! = 0 ; ) { \n",256kB header limit ( # 3602 ) \n * 100k header limit \n * 256k limit,547
"new file \n okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ UtilTest . java \n + / * \n + * Copyright ( C ) 2012 The Android Open Source Project \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * / \n + package okhttp3 . internal ; \n + \n + import org . junit . Test ; \n + \n + import static org . junit . Assert . assertEquals ; \n + import static org . junit . Assert . assertSame ; \n + \n + public class UtilTest { \n + @ Test \n + public void testAssertionError ( ) { \n + NullPointerException nullPointerException = new NullPointerException ( ) ; \n + AssertionError ae = Util . assertionError ( "" npe "" , nullPointerException ) ; \n + assertSame ( nullPointerException , ae . getCause ( ) ) ; \n + assertEquals ( "" npe "" , ae . getMessage ( ) ) ; \n + } \n + } \n okhttp \ src \ main \ java \ okhttp3 \ internal \ Util . java \n - return ( AssertionError ) new AssertionError ( message ) . initCause ( e ) ; \n + AssertionError assertionError = new AssertionError ( message ) ; \n + try { \n + assertionError . initCause ( e ) ; \n + } catch ( IllegalStateException ise ) { \n + / / ignored , shouldn ' t happen \n + } \n + return assertionError ; \n",Assertion error super careful ( # 3696 ) \n * Assertion error super careful \n * Update UtilTest . java,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ ws \ WebSocketHttpTest . java \n + @ Test public void unplannedCloseHandledByCloseWithoutFailure ( ) { \n + webServer . enqueue ( new MockResponse ( ) . withWebSocketUpgrade ( serverListener ) ) ; \n + newWebSocket ( ) ; \n + \n + clientListener . assertOpen ( ) ; \n + WebSocket server = serverListener . assertOpen ( ) ; \n + clientListener . setNextEventDelegate ( new WebSocketListener ( ) { \n + @ Override public void onClosing ( WebSocket webSocket , int code , String reason ) { \n + webSocket . close ( 1000 , null ) ; \n + } \n + } ) ; \n + \n + server . close ( 1001 , "" bye "" ) ; \n + clientListener . assertClosed ( 1001 , "" bye "" ) ; \n + clientListener . assertExhausted ( ) ; \n + serverListener . assertClosing ( 1000 , "" "" ) ; \n + serverListener . assertClosed ( 1000 , "" "" ) ; \n + serverListener . assertExhausted ( ) ; \n + } \n + \n + @ Test public void unplannedCloseHandledWithoutFailure ( ) { \n + webServer . enqueue ( new MockResponse ( ) . withWebSocketUpgrade ( serverListener ) ) ; \n + newWebSocket ( ) ; \n + \n + clientListener . assertOpen ( ) ; \n + WebSocket server = serverListener . assertOpen ( ) ; \n + \n + server . close ( 1001 , "" bye "" ) ; \n + clientListener . assertClosing ( 1001 , "" bye "" ) ; \n + clientListener . assertExhausted ( ) ; \n + serverListener . assertExhausted ( ) ; \n + } \n + \n - @ Test public void clientTimeoutClosesBody ( ) throws IOException { \n + @ Test public void clientTimeoutClosesBody ( ) { \n okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ ws \ WebSocketReaderTest . java \n + @ Test public void closeIncompleteCallsCallback ( ) throws IOException { \n + data . write ( ByteString . decodeHex ( "" 880703e948656c6c6f "" ) ) ; / / Close with code and reason \n + data . close ( ) ; \n + clientReader . processNextFrame ( ) ; \n + callback . assertClosing ( 1001 , "" Hello "" ) ; \n + } \n + \n",Temp Testing : WebSocket close ( # 3725 ) \n * debug socket close \n * more tests,547
"samples \ guide \ src \ main \ java \ okhttp3 \ recipes \ Progress . java \n + boolean firstUpdate = true ; \n + \n - System . out . println ( bytesRead ) ; \n - System . out . println ( contentLength ) ; \n - System . out . println ( done ) ; \n - System . out . format ( "" % d % % done \ n "" , ( 100 * bytesRead ) / contentLength ) ; \n + if ( done ) { \n + System . out . println ( "" completed "" ) ; \n + } else { \n + if ( firstUpdate ) { \n + firstUpdate = false ; \n + if ( contentLength = = - 1 ) { \n + System . out . println ( "" content - length : unknown "" ) ; \n + } else { \n + System . out . format ( "" content - length : % d \ n "" , contentLength ) ; \n + } \n + } \n + \n + System . out . println ( bytesRead ) ; \n + \n + if ( contentLength ! = - 1 ) { \n + System . out . format ( "" % d % % done \ n "" , ( 100 * bytesRead ) / contentLength ) ; \n + } \n + } \n",Improve progress example ( # 3744 ) \n * improve progress example \n * bad import,547
"okhttp \ src \ main \ java \ okhttp3 \ Protocol . java \n - HTTP _ 2 ( "" h2 "" ) ; \n + HTTP _ 2 ( "" h2 "" ) , \n + \n + / * * \n + * QUIC ( Quick UDP Internet Connection ) is a new multiplexed and secure transport atop UDP , \n + * designed from the ground up and optimized for HTTP / 2 semantics . \n + * HTTP / 1 . 1 semantics are layered on HTTP / 2 . \n + * \n + * < p > QUIC is not natively supported by OkHttp , but provided to allow a theoretical \n + * interceptor that provides support . \n + * / \n + QUIC ( "" quic "" ) ; \n + if ( protocol . equals ( QUIC . protocol ) ) return QUIC ; \n + * \n + * @ link https : / / www . iana . org / assignments / tls - extensiontype - values / tls - extensiontype - values . xhtml \n","QUIC constant ( # 3746 ) \n Not actively used , but provided to allow for an externally provided interceptor to implement QUIC support cleanly .",547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ RealConnection . java \n + import javax . net . ssl . SSLSession ; \n - Handshake unverifiedHandshake = Handshake . get ( sslSocket . getSession ( ) ) ; \n + / / block for session establishment \n + SSLSession sslSocketSession = sslSocket . getSession ( ) ; \n + if ( ! isValid ( sslSocketSession ) ) { \n + throw new IOException ( "" a valid ssl session was not established "" ) ; \n + } \n + Handshake unverifiedHandshake = Handshake . get ( sslSocketSession ) ; \n + private boolean isValid ( SSLSession sslSocketSession ) { \n + / / don ' t use SslSocket . getSession since for failed results it returns SSL _ NULL _ WITH _ NULL _ NULL \n + return ! "" NONE "" . equals ( sslSocketSession . getProtocol ( ) ) & & ! "" SSL _ NULL _ WITH _ NULL _ NULL "" . equals ( \n + sslSocketSession . getCipherSuite ( ) ) ; \n + } \n + \n",avoid using invalid sessions ( # 3721 ) \n * avoid using invalid sessions \n * fix tests \n * retain socket and check state \n * fix tests for session validity check \n * fix test \n * simplify \n * extract isValid method \n * reformat,547
okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ Http2Reader . java \n - short id = source . readShort ( ) ; \n + int id = source . readShort ( ) & 0xFFFF ; \n,settings int is unsigned ( # 3751 ),547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ Http2Connection . java \n - pushExecutor . execute ( new NamedRunnable ( "" OkHttp % s Push Request [ % s ] "" , hostname , streamId ) { \n + pushExecutorExecute ( new NamedRunnable ( "" OkHttp % s Push Request [ % s ] "" , hostname , streamId ) { \n - pushExecutor . execute ( new NamedRunnable ( "" OkHttp % s Push Headers [ % s ] "" , hostname , streamId ) { \n + pushExecutorExecute ( new NamedRunnable ( "" OkHttp % s Push Headers [ % s ] "" , hostname , streamId ) { \n - pushExecutor . execute ( new NamedRunnable ( "" OkHttp % s Push Data [ % s ] "" , hostname , streamId ) { \n + pushExecutorExecute ( new NamedRunnable ( "" OkHttp % s Push Data [ % s ] "" , hostname , streamId ) { \n - pushExecutor . execute ( new NamedRunnable ( "" OkHttp % s Push Reset [ % s ] "" , hostname , streamId ) { \n + pushExecutorExecute ( new NamedRunnable ( "" OkHttp % s Push Reset [ % s ] "" , hostname , streamId ) { \n + private synchronized void pushExecutorExecute ( NamedRunnable namedRunnable ) { \n + if ( ! isShutdown ( ) ) { \n + pushExecutor . execute ( namedRunnable ) ; \n + } \n + } \n + \n",Avoid flaky test using pushExecutor after shutdown ( # 3900 ),547
pom . xml \n + < profile > \n + < id > alpn - when - jdk8 _ 161 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 161 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 12 . v20180117 < / alpn . jdk8 . version > \n + < / properties > \n + < / profile > \n + < profile > \n + < id > alpn - when - jdk8 _ 162 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 162 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 12 . v20180117 < / alpn . jdk8 . version > \n + < / properties > \n + < / profile > \n,Add new JDK versions ( # 3803 ) \n Add new JDK versions for alpn - boot 8 . 1 . 12 . v20180117,547
okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ Http2Connection . java \n + import static okhttp3 . internal . http2 . ErrorCode . REFUSED _ STREAM ; \n + if ( nextStreamId > Integer . MAX _ VALUE / 2 ) { \n + shutdown ( REFUSED _ STREAM ) ; \n + } \n - http2Stream . receiveRstStream ( ErrorCode . REFUSED _ STREAM ) ; \n + http2Stream . receiveRstStream ( REFUSED _ STREAM ) ; \n - stream . close ( ErrorCode . REFUSED _ STREAM ) ; \n + stream . close ( REFUSED _ STREAM ) ; \n,Reset stream after a rollover ( # 3752 ) \n * Fail requests that roll over stream id \n * revert bad starting id \n * alternate implementation,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ ErrorCode . java \n - CANCEL ( 8 ) ; \n + CANCEL ( 8 ) , \n + \n + COMPRESSION _ ERROR ( 9 ) , \n + \n + CONNECT _ ERROR ( 0xa ) , \n + \n + ENHANCE _ YOUR _ CALM ( 0xb ) , \n + \n + INADEQUATE _ SECURITY ( 0xc ) , \n + \n + HTTP _ 1 _ 1 _ REQUIRED ( 0xd ) ; \n",Define all HTTP2 error codes ( # 3756 ),547
"okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ http2 \ HttpOverHttp2Test . java \n - assertEquals ( 20 , logs . size ( ) ) ; \n + \n - assertEquals ( 22 , logs . size ( ) ) ; \n + \n",More lenient test involving logging ( # 3859 ) \n * reproduce failing test \n * More lenient tests because logging is JVM wide \n * hide logging,547
"okhttp - testing - support \ src \ main \ java \ okhttp3 \ testing \ InstallUncaughtExceptionHandlerListener . java \n + import java . util . LinkedHashMap ; \n + import java . util . Map ; \n + import org . junit . internal . Throwables ; \n + private final Map < Throwable , String > exceptions = new LinkedHashMap < > ( ) ; \n - @ Override public void testRunStarted ( Description description ) throws Exception { \n + @ Override public void testRunStarted ( Description description ) { \n - System . exit ( - 1 ) ; \n + \n + synchronized ( exceptions ) { \n + exceptions . put ( throwable , lastTestStarted . getDisplayName ( ) ) ; \n + } \n - @ Override public void testStarted ( Description description ) throws Exception { \n + @ Override public void testStarted ( Description description ) { \n + \n + synchronized ( exceptions ) { \n + if ( ! exceptions . isEmpty ( ) ) { \n + throw Throwables . rethrowAsException ( exceptions . keySet ( ) . iterator ( ) . next ( ) ) ; \n + } \n + } \n",Dont System . exit the test runner ( # 3888 ) \n * Dont System . exit \n * Maven aware uncaught exception handling \n * cleanup,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ HttpUrlTest . java \n - assertEquals ( "" : / / host . com / path "" , \n + assertEquals ( "" / / host . com / path "" , \n - assertEquals ( "" : / / host . com : 8080 / path "" , \n + assertEquals ( "" / / host . com : 8080 / path "" , \n okhttp \ src \ main \ java \ okhttp3 \ HttpUrl . java \n + result . append ( "" : / / "" ) ; \n + } else { \n + result . append ( "" / / "" ) ; \n - result . append ( "" : / / "" ) ; \n",Remove colon when scheme missing in builder toString ( # 4361 ),547
". buildscript \ deploy _ snapshot . sh \n - mvn clean source : jar javadoc : jar deploy - - settings = "" . buildscript / settings . xml "" - Dmaven . test . skip = true \n + mvn clean package source : jar javadoc : jar deploy - - settings = "" . buildscript / settings . xml "" - Dmaven . javadoc . failOnError = false - DskipTests \n",Update deploy _ snapshot . sh to temporarily ignore javadoc errors and compile tests but not run ( # 3821 ),547
"okhttp \ src \ main \ java \ okhttp3 \ Protocol . java \n - * @ link https : / / www . iana . org / assignments / tls - extensiontype - values / tls - extensiontype - values . xhtml \n + * @ see < a href = "" https : / / www . iana . org / assignments / tls - extensiontype - values "" > IANA \n + * tls - extensiontype - values < / a > \n","fix javadoc link ( # 3823 ) \n "" mvn javadoc : jar "" failing because of an invalid link . Previous fix was a workaround to skip the failure .",547
pom . xml \n + < profile > \n + < id > alpn - when - jdk8 _ 171 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 171 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 12 . v20180117 < / alpn . jdk8 . version > \n + < / properties > \n + < / profile > \n + < profile > \n + < id > alpn - when - jdk8 _ 172 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 172 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 12 . v20180117 < / alpn . jdk8 . version > \n + < / properties > \n,alpn boot versions - no upstream version yet \n Nothing obviously coming from http : / / www . oracle . com / technetwork / java / javase / 8all - relnotes - 2226344 . html,547
". buildscript \ deploy _ snapshot . sh \n - mvn clean package source : jar javadoc : jar deploy - - settings = "" . buildscript / settings . xml "" - Dmaven . javadoc . failOnError = false - DskipTests \n + mvn clean source : jar javadoc : jar deploy - - settings = "" . buildscript / settings . xml "" - DskipTests \n . travis . yml \n - oracle - java8 - installer # Updates JDK 8 to the latest available . \n + script : mvn test javadoc : jar source : jar - B \n + \n - . buildscript / deploy _ snapshot . sh \n",build javadoc and source jars in normal build to flush out build failures ( # 3824 ),547
"okhttp - tests \ pom . xml \n + < dependency > \n + < groupId > $ { project . groupId } < / groupId > \n + < artifactId > logging - interceptor < / artifactId > \n + < version > $ { project . version } < / version > \n + < scope > test < / scope > \n + < / dependency > \n okhttp - tests \ src \ test \ java \ okhttp3 \ EventListenerTest . java \n + import okhttp3 . logging . HttpLoggingInterceptor ; \n + @ Test public void successfulCallEventSequenceWithListener ( ) throws IOException { \n + server . enqueue ( new MockResponse ( ) . setBody ( "" abc "" ) ) ; \n + \n + client = client . newBuilder ( ) . addNetworkInterceptor ( new HttpLoggingInterceptor ( ) . setLevel ( \n + HttpLoggingInterceptor . Level . BODY ) ) . build ( ) ; \n + \n + Call call = client . newCall ( new Request . Builder ( ) \n + . url ( server . url ( "" / "" ) ) \n + . build ( ) ) ; \n + Response response = call . execute ( ) ; \n + assertEquals ( 200 , response . code ( ) ) ; \n + assertEquals ( "" abc "" , response . body ( ) . string ( ) ) ; \n + response . body ( ) . close ( ) ; \n + \n + List < String > expectedEvents = Arrays . asList ( "" CallStart "" , "" DnsStart "" , "" DnsEnd "" , \n + "" ConnectStart "" , "" ConnectEnd "" , "" ConnectionAcquired "" , "" RequestHeadersStart "" , \n + "" RequestHeadersEnd "" , "" ResponseHeadersStart "" , "" ResponseHeadersEnd "" , "" ResponseBodyStart "" , \n + "" ResponseBodyEnd "" , "" ConnectionReleased "" , "" CallEnd "" ) ; \n + assertEquals ( expectedEvents , listener . recordedEventTypes ( ) ) ; \n + } \n + \n okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ StreamAllocation . java \n + eventListener . callEnd ( call ) ; \n",HTTP Logging interceptor breaks EventListener ( # 4095 ) \n HTTP Logging interceptor breaks EventListener because of changed event ordering . End the call on delayed release .,547
"mockwebserver \ src \ main \ java \ okhttp3 \ mockwebserver \ MockWebServer . java \n - sleepIfDelayed ( response . getBodyDelay ( TimeUnit . MILLISECONDS ) ) ; \n + sleepIfDelayed ( response . getHeadersDelay ( TimeUnit . MILLISECONDS ) ) ; \n okhttp - tests \ src \ test \ java \ okhttp3 \ EventListenerTest . java \n - server . enqueue ( new MockResponse ( ) . setBodyDelay ( 2 , TimeUnit . SECONDS ) ) ; \n + server . enqueue ( new MockResponse ( ) . setHeadersDelay ( 2 , TimeUnit . SECONDS ) ) ; \n",Use header delay instead of body delay before status line ( # 4011 ) \n * Use header delay instead of body delay before status line,547
"mockwebserver \ src \ main \ java \ okhttp3 \ mockwebserver \ MockWebServer . java \n - sleepIfDelayed ( response . getBodyDelay ( TimeUnit . MILLISECONDS ) ) ; \n + sleepIfDelayed ( response . getHeadersDelay ( TimeUnit . MILLISECONDS ) ) ; \n okhttp - tests \ src \ test \ java \ okhttp3 \ EventListenerTest . java \n - server . enqueue ( new MockResponse ( ) . setBodyDelay ( 2 , TimeUnit . SECONDS ) ) ; \n + server . enqueue ( new MockResponse ( ) . setHeadersDelay ( 2 , TimeUnit . SECONDS ) ) ; \n",Use header delay instead of body delay before status line ( # 4011 ) \n * Use header delay instead of body delay before status line,547
"okhttp - tests \ src \ test \ java \ okhttp3 \ ConscryptTest . java \n - . tlsVersions ( TlsVersion . TLS _ 1 _ 3 , TlsVersion . TLS _ 1 _ 2 ) / / and modern TLS \n + . tlsVersions ( TlsVersion . TLS _ 1 _ 2 ) / / and modern TLS \n okhttp \ src \ main \ java \ okhttp3 \ ConnectionSpec . java \n - . tlsVersions ( TlsVersion . TLS _ 1 _ 3 , TlsVersion . TLS _ 1 _ 2 ) \n + . tlsVersions ( TlsVersion . TLS _ 1 _ 2 ) \n - . tlsVersions ( TlsVersion . TLS _ 1 _ 3 , TlsVersion . TLS _ 1 _ 2 , TlsVersion . TLS _ 1 _ 1 , TlsVersion . TLS _ 1 _ 0 ) \n + . tlsVersions ( TlsVersion . TLS _ 1 _ 2 , TlsVersion . TLS _ 1 _ 1 , TlsVersion . TLS _ 1 _ 0 ) \n","Remove TLSv1 . 3 as default ( # 4122 ) \n We specify TLSv1 . 3 , but without any compatible cipher suites . So makes sense to remove for 3 . 11 to avoid weirdness as JVMs supporting TLSv1 . 3 start showing up . n . b . JDK 11 detects this and strips anyway .",547
"okhttp - tests \ src \ test \ java \ okhttp3 \ HeadersTest . java \n + @ Test public void headersAddAll ( ) { \n + Headers sourceHeaders = new Headers . Builder ( ) \n + . add ( "" A "" , "" aa "" ) \n + . add ( "" a "" , "" aa "" ) \n + . add ( "" B "" , "" bb "" ) \n + . build ( ) ; \n + Headers headers = new Headers . Builder ( ) \n + . add ( "" A "" , "" a "" ) \n + . addAll ( sourceHeaders ) \n + . add ( "" C "" , "" c "" ) \n + . build ( ) ; \n + assertEquals ( "" A : a \ nA : aa \ na : aa \ nB : bb \ nC : c \ n "" , headers . toString ( ) ) ; \n + } \n + \n okhttp \ src \ main \ java \ okhttp3 \ Headers . java \n - / * * Add a field with the specified value . * / \n + / * * \n + * Add a header with the specified name and value . Does validation of header names and values . \n + * / \n + / * * \n + * Adds all headers from an existing collection . Does validation of header names and values . \n + * / \n + public Builder addAll ( Headers headers ) { \n + int size = headers . size ( ) ; \n + for ( int i = 0 ; i < size ; i + + ) { \n + addLenient ( headers . name ( i ) , headers . value ( i ) ) ; \n + } \n + \n + return this ; \n + } \n + \n",Add headerBuilder . addAll ( headers ) method ( # 4121 ),547
"okhttp - tests \ src \ test \ java \ okhttp3 \ CallTest . java \n + import java . io . FileNotFoundException ; \n + import java . util . concurrent . atomic . AtomicInteger ; \n + import javax . annotation . Nullable ; \n - import okhttp3 . tls . HeldCertificate ; \n + import okhttp3 . tls . HeldCertificate ; \n - import static okhttp3 . internal . platform . PlatformTest . getPlatform ; \n + @ Test public void postWithFileNotFound ( ) throws Exception { \n + final AtomicInteger called = new AtomicInteger ( 0 ) ; \n + \n + RequestBody body = new RequestBody ( ) { \n + @ Nullable @ Override public MediaType contentType ( ) { \n + return MediaType . get ( "" application / octet - stream "" ) ; \n + } \n + \n + @ Override public void writeTo ( BufferedSink sink ) throws IOException { \n + called . incrementAndGet ( ) ; \n + throw new FileNotFoundException ( ) ; \n + } \n + } ; \n + \n + Request request = new Request . Builder ( ) \n + . url ( server . url ( "" / "" ) ) \n + . post ( body ) \n + . build ( ) ; \n + \n + executeSynchronously ( request ) \n + . assertFailure ( FileNotFoundException . class ) ; \n + \n + assertEquals ( 1L , called . get ( ) ) ; \n + } \n + \n",Test for file not found in post body ( # 4151 ) \n * test for FNFE \n * tighten up test behaviour,547
"okhttp \ src \ main \ java \ okhttp3 \ Handshake . java \n + import java . io . IOException ; \n - public static Handshake get ( SSLSession session ) { \n + public static Handshake get ( SSLSession session ) throws IOException { \n + if ( "" SSL _ NULL _ WITH _ NULL _ NULL "" . equals ( cipherSuiteString ) ) { \n + throw new IOException ( "" cipherSuite = = SSL _ NULL _ WITH _ NULL _ NULL "" ) ; \n + } \n + if ( "" NONE "" . equals ( tlsVersionString ) ) throw new IOException ( "" tlsVersion = = NONE "" ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ RealConnection . java \n - if ( ! isValid ( sslSocketSession ) ) { \n - throw new IOException ( "" a valid ssl session was not established "" ) ; \n - } \n - private boolean isValid ( SSLSession sslSocketSession ) { \n - / / don ' t use SslSocket . getSession since for failed results it returns SSL _ NULL _ WITH _ NULL _ NULL \n - return ! "" NONE "" . equals ( sslSocketSession . getProtocol ( ) ) & & ! "" SSL _ NULL _ WITH _ NULL _ NULL "" . equals ( \n - sslSocketSession . getCipherSuite ( ) ) ; \n - } \n - \n",Move conscrypt NONE checks internal to Handshake ( # 4055 ) \n * double check SSL protocol = = NONE \n * move conscrypt NONE checks internal to Handshake \n * checkstyle,547
"okhttp - dnsoverhttps \ src \ test \ java \ okhttp3 \ dnsoverhttps \ DohProviders . java \n - \n - static DnsOverHttps buildCloudflare ( OkHttpClient bootstrapClient ) { \n + static DnsOverHttps buildCloudflareIp ( OkHttpClient bootstrapClient ) { \n + return new DnsOverHttps . Builder ( ) . client ( bootstrapClient ) \n + . url ( parseUrl ( "" https : / / 1 . 1 . 1 . 1 / dns - query "" ) ) \n + . includeIPv6 ( false ) \n + . build ( ) ; \n + } \n + static DnsOverHttps buildCloudflare ( OkHttpClient bootstrapClient ) { \n - . url ( parseUrl ( "" https : / / cloudflare - dns . com / dns - query ? ct = application / dns - udpwireformat "" ) ) \n - . bootstrapDnsHosts ( getByIp ( "" 104 . 16 . 111 . 25 "" ) , getByIp ( "" 104 . 16 . 112 . 25 "" ) , \n - getByIp ( "" 2400 : cb00 : 2048 : 1 : 0 : 0 : 6810 : 7019 "" ) , getByIp ( "" 2400 : cb00 : 2048 : 1 : 0 : 0 : 6810 : 6f19 "" ) ) \n + . url ( parseUrl ( "" https : / / cloudflare - dns . com / dns - query "" ) ) \n + . bootstrapDnsHosts ( getByIp ( "" 1 . 1 . 1 . 1 "" ) ) \n - \n - . url ( parseUrl ( "" https : / / dns . cloudflare . com / . well - known / dns - query "" ) ) \n + . url ( parseUrl ( "" https : / / cloudflare - dns . com / dns - query ? ct = application / dns - udpwireformat "" ) ) \n + . bootstrapDnsHosts ( getByIp ( "" 104 . 16 . 111 . 25 "" ) , getByIp ( "" 104 . 16 . 112 . 25 "" ) , \n + getByIp ( "" 2400 : cb00 : 2048 : 1 : 0 : 0 : 6810 : 7019 "" ) , getByIp ( "" 2400 : cb00 : 2048 : 1 : 0 : 0 : 6810 : 6f19 "" ) ) \n - . contentType ( UDPWIREFORMAT ) \n + result . add ( buildCloudflareIp ( client ) ) ; \n",Update cloudflare GET example ( # 4097 ) \n * Update cloudflare GET example \n * add IP example,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ AndroidPlatform . java \n + import java . security . NoSuchAlgorithmException ; \n + import javax . net . ssl . SSLContext ; \n + \n + @ Override public SSLContext getSSLContext ( ) { \n + if ( Build . VERSION . SDK _ INT > = 16 & & Build . VERSION . SDK _ INT < 22 ) { \n + try { \n + return SSLContext . getInstance ( "" TLSv1 . 2 "" ) ; \n + } catch ( NoSuchAlgorithmException e ) { \n + / / fallback to TLS \n + } \n + } \n + \n + try { \n + return SSLContext . getInstance ( "" TLS "" ) ; \n + } catch ( NoSuchAlgorithmException e ) { \n + throw new IllegalStateException ( "" No TLS provider "" , e ) ; \n + } \n + } \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ Platform . java \n - public void connectSocket ( Socket socket , InetSocketAddress address , \n - int connectTimeout ) throws IOException { \n + public void connectSocket ( Socket socket , InetSocketAddress address , int connectTimeout ) \n + throws IOException { \n - throw new IllegalStateException ( "" Unable to extract the trust manager on "" + Platform . get ( ) \n - + "" , sslSocketFactory is "" + sslSocketFactory . getClass ( ) ) ; \n + throw new IllegalStateException ( "" Unable to extract the trust manager on "" \n + + Platform . get ( ) \n + + "" , sslSocketFactory is "" \n + + sslSocketFactory . getClass ( ) ) ; \n + String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n + if ( "" 1 . 7 "" . equals ( jvmVersion ) ) { \n + try { \n + / / JDK 1 . 7 ( public version ) only support > TLSv1 with named protocols \n + return SSLContext . getInstance ( "" TLSv1 . 2 "" ) ; \n + } catch ( NoSuchAlgorithmException e ) { \n + / / fallback to TLS \n + } \n + } \n + \n",Android 4 and Java 1 . 7 prefer TLSv1 . 2 provider ( # 4089 ) \n * java 1 . 7 TLV v1 . 2 support \n * simplify TLSv1 . 2 vs TLS selection logic \n * tighten up version checks \n * cleanup,547
". travis . yml \n - oraclejdk8 \n + # - openjdk11 \n okhttp - tests \ src \ test \ java \ okhttp3 \ CallTest . java \n + import javax . net . ssl . SSLException ; \n + import static okhttp3 . internal . platform . PlatformTest . getPlatform ; \n + SSLException . class , / / JDK 11 response to the FAIL _ HANDSHAKE \n + } catch ( SSLException expected ) { \n + / / JDK 11 response to the FAIL _ HANDSHAKE \n + String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n + assertEquals ( "" 11 "" , jvmVersion ) ; \n okhttp - tests \ src \ test \ java \ okhttp3 \ URLConnectionTest . java \n + } catch ( SSLException expected ) { \n + / / JDK 1 . 9 response to the FAIL _ HANDSHAKE \n + / / javax . net . ssl . SSLException : Unexpected handshake message : client _ hello \n okhttp - tests \ src \ test \ java \ okhttp3 \ internal \ tls \ ClientAuthTest . java \n + import javax . net . ssl . SSLException ; \n + import static org . junit . Assert . assertTrue ; \n + } catch ( SSLException expected ) { \n + String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n + assertEquals ( "" 11 "" , jvmVersion ) ; \n + } catch ( SSLException expected ) { \n + / / javax . net . ssl . SSLException : readRecord \n + String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n + assertEquals ( "" 11 "" , jvmVersion ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ ConnectionSpecSelector . java \n + import javax . net . ssl . SSLException ; \n - return ( e instanceof SSLHandshakeException | | e instanceof SSLProtocolException ) ; \n + return ( e instanceof SSLHandshakeException \n + | | e instanceof SSLProtocolException \n + | | e instanceof SSLException ) ; \n",Possible JDK 11 fixes ( # 4138 ) \n tracking upstream fixes in https : / / bugs . java . com / bugdatabase / view _ bug . do ? bug _ id = JDK - 8207223,547
pom . xml \n + < profile > \n + < id > alpn - when - jdk8 _ 181 < / id > \n + < activation > \n + < jdk > 1 . 8 . 0 _ 181 < / jdk > \n + < / activation > \n + < properties > \n + < alpn . jdk8 . version > 8 . 1 . 12 . v20180117 < / alpn . jdk8 . version > \n + < / properties > \n + < / profile > \n,support java 8 u181 ( # 4161 ) \n * support java 8 u181 \n * typo,547
okhttp - dnsoverhttps \ pom . xml \n - < version > 1 . 1 . 0 < / version > \n + < scope > test < / scope > \n okhttp - tests \ pom . xml \n - < version > 1 . 0 . 1 < / version > \n okhttp \ pom . xml \n - < version > 1 . 1 . 3 < / version > \n pom . xml \n + < conscrypt . version > 1 . 1 . 4 < / conscrypt . version > \n + < dependency > \n + < groupId > org . conscrypt < / groupId > \n + < artifactId > conscrypt - openjdk - uber < / artifactId > \n + < version > $ { conscrypt . version } < / version > \n + < / dependency > \n - < version > 1 . 1 . 3 < / version > \n,Avoid hard conscrypt dep ( # 4128 ),547
"okhttp - logging - interceptor \ src \ main \ java \ okhttp3 \ logging \ LoggingEventListener . java \n - logWithTime ( "" secureConnectEnd "" ) ; \n + logWithTime ( "" secureConnectEnd : "" + handshake ) ; \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ LoggingEventListenerTest . java \n - . assertLogMatch ( "" secureConnectEnd "" ) \n + . assertLogMatch ( "" secureConnectEnd : Handshake \ \ { "" \n + + "" tlsVersion = TLS _ 1 _ 2 "" \n + + "" cipherSuite = TLS _ ECDHE _ ECDSA _ WITH _ AES _ 256 _ GCM _ SHA384 "" \n + + "" peerCertificates = \ \ [ CN = localhost \ \ ] "" \n + + "" localCertificates = \ \ [ \ \ ] } "" ) \n okhttp \ src \ main \ java \ okhttp3 \ Handshake . java \n + import java . util . ArrayList ; \n + \n + @ Override public String toString ( ) { \n + return "" Handshake { "" \n + + "" tlsVersion = "" \n + + tlsVersion \n + + "" cipherSuite = "" \n + + cipherSuite \n + + "" peerCertificates = "" \n + + names ( peerCertificates ) \n + + "" localCertificates = "" \n + + names ( localCertificates ) \n + + ' } ' ; \n + } \n + \n + private List < String > names ( List < Certificate > certificates ) { \n + ArrayList < String > strings = new ArrayList < > ( ) ; \n + \n + for ( Certificate cert : certificates ) { \n + if ( cert instanceof X509Certificate ) { \n + strings . add ( String . valueOf ( ( ( X509Certificate ) cert ) . getSubjectDN ( ) ) ) ; \n + } else { \n + strings . add ( cert . getType ( ) ) ; \n + } \n + } \n + \n + return strings ; \n + } \n",Log handshake in LoggingEventListener ( # 4397 ),547
"okhttp - tests \ src \ test \ java \ okhttp3 \ CallTest . java \n + client = client . newBuilder ( ) \n + . dns ( new DoubleInetAddressDns ( ) ) \n + . build ( ) ; \n + \n okhttp \ src \ main \ java \ okhttp3 \ internal \ http \ RetryAndFollowUpInterceptor . java \n + import java . io . FileNotFoundException ; \n - if ( requestSendStarted & & userRequest . body ( ) instanceof UnrepeatableRequestBody ) return false ; \n + if ( requestSendStarted & & requestIsUnrepeatable ( e , userRequest ) ) return false ; \n + private boolean requestIsUnrepeatable ( IOException e , Request userRequest ) { \n + return userRequest . body ( ) instanceof UnrepeatableRequestBody \n + | | e instanceof FileNotFoundException ; \n + } \n + \n",Avoid retrying when client is missing body File,547
". github \ CONTRIBUTING . md \n + Some general advice \n + \n + - Don’t change public API lightly , avoid if possible , and include your reasoning in the PR if essential . It causes pain for developers who use OkHttp and sometimes runtime errors . \n + - Favour a working external library if appropriate . There are many examples of OkHttp libraries that can sit on top or hook in via existing APIs . \n + - Get working code on a personal branch with tests before you submit a PR . \n + - OkHttp is a small and light dependency . Don ' t introduce new dependencies or major new functionality . \n + - OkHttp targets the intersection of RFC correct * and * widely implemented . Incorrect implementations that are very widely implemented e . g . a bug in Apache , Nginx , Google , Firefox should also be handled . \n + \n",Change contributing guide in repo to match wiki ( # 4414 ),547
bom \ pom . xml \n - < parent > \n - < groupId > com . squareup . okhttp3 < / groupId > \n - < artifactId > parent < / artifactId > \n - < version > 3 . 13 . 0 - SNAPSHOT < / version > \n - < / parent > \n - \n + < groupId > com . squareup . okhttp3 < / groupId > \n + < version > 3 . 13 . 0 - SNAPSHOT < / version > \n,"Remove parent of BOM ( # 4413 ) \n Based on discussions in https : / / github . com / square / okhttp / issues / 4407 , remove the parent .",547
"okhttp \ src \ main \ java \ okhttp3 \ Authenticator . java \n + * \n + * The route is best effort , it currently may not always be provided even when logically \n + * available . It may also not be provided when an Authenticator is re - used manually in \n + * an application interceptor , e . g . implementing client specific retries . \n + * \n + * @ param route The route for evaluating how to respond to a challenge e . g . via intranet . \n + * @ param response The response containing the auth challenges to respond to . \n - @ Nullable Request authenticate ( Route route , Response response ) throws IOException ; \n + @ Nullable Request authenticate ( @ Nullable Route route , Response response ) throws IOException ; \n",Nullable route annotation ( # 4257 ) \n * Nullable route annotation \n * Fix comment to mention intranet example,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ ConscryptPlatform . java \n - private Provider getProvider ( ) { \n + @ SuppressWarnings ( "" deprecation "" ) private Provider getProvider ( ) { \n + / / defaults to true , but allow for older versions of conscrypt if still compatible \n + / / new form with boolean is only present in > = 2 . 0 . 0 \n pom . xml \n - < conscrypt . version > 1 . 4 . 2 < / conscrypt . version > \n + < conscrypt . version > 2 . 0 . 0 < / conscrypt . version > \n",Conscrypt 2 . 0 . 0 Upgrade ( # 4614 ) \n Upgrades to 2 . 0 . 0 without using features to allow clients to use older versions for now,547
". circleci \ config . yml \n - build - check - and - test : \n + commit : \n + jobs : \n + - dependencies \n + - checkjdk8 : \n + requires : \n + - dependencies \n + filters : \n + branches : \n + ignore : master \n + - testjdk8 : \n + requires : \n + - dependencies \n + - testjdk11 : \n + requires : \n + - dependencies \n + filters : \n + branches : \n + only : master \n + nightly : \n + triggers : \n + - schedule : \n + cron : "" 0 0 * * * "" \n + filters : \n + branches : \n + only : master \n - compile \n - checkjdk8 : \n",Run cron schedule in circleci ( # 4862 ),547
". circleci \ config . yml \n - v3 - { { checksum "" build . gradle "" } } \n - run : \n - name : dependencies \n + name : Compile \n - v3 - { { checksum "" build . gradle "" } } \n - run : \n - name : test \n + name : Run tests \n - v3 - { { checksum "" build . gradle "" } } \n - run : \n - name : test \n + name : Run tests \n - - dependencies \n + - compile \n - checkjdk8 : \n - - dependencies \n + - compile \n - testjdk8 : \n - - dependencies \n + - compile \n - testjdk11 : \n - - dependencies \n + - compile \n",Fix bad merge commit for circleci config ( # 4863 ),547
"okhttp - testing - support \ src \ main \ java \ okhttp3 \ testing \ PlatformRule . kt \n - fun conscrypt ( ) = PlatformRule ( \n - CONSCRYPT _ PROPERTY ) \n + fun conscrypt ( ) = PlatformRule ( CONSCRYPT _ PROPERTY ) \n - fun jdk8alpn ( ) = PlatformRule ( \n - JDK8 _ ALPN _ PROPERTY ) \n + fun jdk8alpn ( ) = PlatformRule ( JDK8 _ ALPN _ PROPERTY ) \n okhttp \ src \ test \ java \ okhttp3 \ CallTest . java \n - import static org . hamcrest . CoreMatchers . anything ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ ClientAuthTest . java \n + import okhttp3 . testing . PlatformVersion ; \n - String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n - assertThat ( jvmVersion ) . matches ( "" 1 [ 123 ] "" ) ; \n + assertThat ( PlatformVersion . INSTANCE . getMajorVersion ( ) ) . isGreaterThanOrEqualTo ( 11 ) ; \n - assertThat ( getPlatformSystemProperty ( ) ) . isEqualTo ( "" jdk9 "" ) ; \n + assertThat ( getPlatformSystemProperty ( ) ) . isIn ( PlatformRule . JDK9 _ PROPERTY , \n + PlatformRule . CONSCRYPT _ PROPERTY ) ; \n - String jvmVersion = System . getProperty ( "" java . specification . version "" ) ; \n - assertThat ( jvmVersion ) . matches ( "" 1 [ 123 ] "" ) ; \n + assertThat ( PlatformVersion . INSTANCE . getMajorVersion ( ) ) . isGreaterThanOrEqualTo ( 11 ) ; \n - assertThat ( getPlatformSystemProperty ( ) ) . isEqualTo ( "" jdk9 "" ) ; \n + assertThat ( getPlatformSystemProperty ( ) ) . isIn ( PlatformRule . JDK9 _ PROPERTY , \n + PlatformRule . CONSCRYPT _ PROPERTY ) ; \n",Fix for conscrypt tests ( # 5263 ),547
"build . gradle \n - ' bouncycastle ' : ' 1 . 60 ' , \n + ' bouncycastle ' : ' 1 . 62 ' , \n",Bouncy castle upgrade ( # 5264 ) \n * Bouncy castle upgrade \n * Testing on more platforms \n * Revert CI change,547
"mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ CustomDispatcherTest . java \n - import org . junit . After ; \n + import org . junit . Rule ; \n + import org . junit . rules . Timeout ; \n - private MockWebServer mockWebServer = new MockWebServer ( ) ; \n + @ Rule public MockWebServer mockWebServer = new MockWebServer ( ) ; \n - @ After public void tearDown ( ) throws Exception { \n - mockWebServer . shutdown ( ) ; \n - } \n + @ Rule public Timeout globalTimeout = Timeout . seconds ( 30 ) ; \n - mockWebServer . start ( ) ; \n - mockWebServer . start ( ) ; \n mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ MockWebServerTest . java \n - import org . junit . After ; \n + import org . junit . rules . Timeout ; \n + @ Rule public Timeout globalTimeout = Timeout . seconds ( 30 ) ; \n + \n - @ After public void tearDown ( ) throws IOException { \n - server . shutdown ( ) ; \n - } \n - \n - } catch ( ConnectException e ) { \n + } catch ( ConnectException e ) { \n - + "" [ h2 _ prior _ knowledge , http / 1 . 1 ] "" ) ) ; \n + + "" [ h2 _ prior _ knowledge , http / 1 . 1 ] "" ) ) ; \n - + "" [ h2 _ prior _ knowledge , h2 _ prior _ knowledge ] "" ) ) ; \n + + "" [ h2 _ prior _ knowledge , h2 _ prior _ knowledge ] "" ) ) ; \n mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ RecordedRequestTest . java \n + import org . junit . Rule ; \n + import org . junit . rules . Timeout ; \n + @ Rule public Timeout globalTimeout = Timeout . seconds ( 30 ) ; \n + \n",Use Timeout rule for MockWebServer tests ( # 4774 ),547
okhttp \ src \ main \ java \ okhttp3 \ Headers . java \n - this . namesAndValues = builder . namesAndValues . toArray ( new String [ builder . namesAndValues . size ( ) ] ) ; \n + this . namesAndValues = builder . namesAndValues . toArray ( new String [ 0 ] ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ Util . java \n - return result . toArray ( new String [ result . size ( ) ] ) ; \n + return result . toArray ( new String [ 0 ] ) ; \n okhttp \ src \ main \ java \ okhttp3 \ internal \ cache \ DiskLruCache . java \n - for ( Entry entry : lruEntries . values ( ) . toArray ( new Entry [ lruEntries . size ( ) ] ) ) { \n + for ( Entry entry : lruEntries . values ( ) . toArray ( new Entry [ 0 ] ) ) { \n - for ( Entry entry : lruEntries . values ( ) . toArray ( new Entry [ lruEntries . size ( ) ] ) ) { \n + for ( Entry entry : lruEntries . values ( ) . toArray ( new Entry [ 0 ] ) ) { \n okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ Http2Connection . java \n - streamsToClose = streams . values ( ) . toArray ( new Http2Stream [ streams . size ( ) ] ) ; \n + streamsToClose = streams . values ( ) . toArray ( new Http2Stream [ 0 ] ) ; \n - streamsToNotify = streams . values ( ) . toArray ( new Http2Stream [ streams . size ( ) ] ) ; \n + streamsToNotify = streams . values ( ) . toArray ( new Http2Stream [ 0 ] ) ; \n - streamsCopy = streams . values ( ) . toArray ( new Http2Stream [ streams . size ( ) ] ) ; \n + streamsCopy = streams . values ( ) . toArray ( new Http2Stream [ 0 ] ) ; \n,Use intrinsic version to toArray ( # 4777 ) \n performs as well or better post JDK 1 . 6,547
. circleci \ config . yml \n - - image : circleci / openjdk : 8 - jdk \n + - image : circleci / openjdk : 8u171 - jdk \n,Another JDK 8 build ( # 4783 ),547
". circleci \ config . yml \n - v1 - dependencies - { { checksum "" build . gradle "" } } \n - v1 - dependencies - \n - - run : . / gradlew downloadDependencies \n + - run : \n + name : dependencies \n + command : . / gradlew downloadDependencies \n + environment : \n + GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . parallel = false - Xmx1G \n - save _ cache : \n - ~ / . gradle / caches \n - - run : . / gradlew check \n + - run : \n + name : check \n + command : . / gradlew check \n + environment : \n + GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . parallel = false - Xmx1G \n - run : \n - store _ test _ results : \n - store _ artifacts : \n - path : ~ / test - results / junit \n + path : ~ / test - results / junit \n",Adjust circleci memory and remove daemon ( # 4804 ) \n remove daemon and reduce memory,547
". circleci \ config . yml \n - v1 - dependencies - { { checksum "" build . gradle "" } } \n - v1 - dependencies - \n - - run : \n + - run : \n - store _ artifacts : \n + \n + testjdk11 : \n + docker : \n + - image : circleci / openjdk : 11 . 0 . 2 - jdk \n + \n + working _ directory : ~ / testrepo11 \n + \n + environment : \n + JVM _ OPTS : - Xmx1g \n + TERM : dumb \n + \n + steps : \n + - checkout \n + \n + - restore _ cache : \n + keys : \n + - v1 - dependencies - { { checksum "" build . gradle "" } } \n + - v1 - dependencies - \n + \n + - run : \n + name : test \n + command : . / gradlew test \n + environment : \n + GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . parallel = false - Xmx1G \n + \n + - run : \n + name : Save test results \n + command : | \n + mkdir - p ~ / testrepo11 / test - results / junit / \n + find . - type f - regex "" . * / build / test - results / . * xml "" - exec cp { } ~ / testrepo11 / test - results / junit / \ ; \n + when : always \n + \n + - store _ test _ results : \n + name : Store test results \n + path : ~ / testrepo11 / test - results \n + \n + - run : \n + name : Save gradle reports \n + command : | \n + mkdir - p ~ / testrepo11 / reports / \n + tar cf - * / build / reports | ( cd ~ / testrepo11 / reports / ; tar xf - ) \n + when : always \n + \n + - store _ artifacts : \n + name : Store gradle reports \n + path : ~ / testrepo11 / reports \n + \n + version : 2 \n - dependencies \n - testjdk8 : \n - dependencies \n + - testjdk11 : \n + requires : \n + - dependencies \n",Check different JDKs in CircleCI ( # 4835 ) \n Use JDK8 and JDK11 to run tests,547
". circleci \ config . yml \n - compile \n - testconscrypt : \n - - compile \n + - compile \n build . gradle \n - ' conscrypt ' : ' 2 . 0 . 0 ' , \n + ' conscrypt ' : ' 2 . 1 . 0 ' , \n",Conscrypt 2 . 1 . 0 upgrade ( # 4868 ),547
"android - test \ build . gradle \n - androidTestImplementation project ( ' : okhttp - testing - support ' ) \n + androidTestImplementation ( project ( ' : okhttp - testing - support ' ) ) { \n + exclude group : ' org . openjsse ' , module : ' openjsse ' \n + } \n",Android Test Fixes for OpenJSSE ( # 5407 ) \n * Android Test Fixes for OpenJSSE \n * Specific fixes,547
gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 3 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 4 - all . zip \n,Gradle 5 . 4 upgrade ( # 4959 ),547
. travis . yml \n - oraclejdk8 \n - - openjdk8 \n - - openjdk11 \n - . / gradlew check \n,Travis CI builds in JDK 8 only \n No need to build all here given progress towards CircleCI .,547
". circleci \ config . yml \n - image : circleci / openjdk : 8u171 - jdk \n - JVM _ OPTS : - Xmx768m \n + JVM _ OPTS : - Xmx1g \n + - run : \n + name : Run tests \n + command : . / gradlew - - parallel - - build - cache test \n + environment : \n + GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . workers . max = 3 - Xmx1G \n + \n - save _ cache : \n - ~ / . gradle / caches \n - ~ / . gradle / wrapper \n - # Under normal usage , saves compiled results from master once a day \n + # Under normal usage , saves compiled results from master at least once a day \n - restore _ cache : \n + # master - compile is published on each build ( cron or master commit ) so is fresher \n - v4 - { { . Branch } } - { { . Environment . CIRCLE _ JOB } } \n - v4 - master - compile \n",Use cached test results from master build ( # 4876 ),547
"build . gradle \n - ' kotlin ' : ' 1 . 3 . 30 ' , \n + ' kotlin ' : ' 1 . 3 . 31 ' , \n",Kotlin 1 . 3 . 31 upgrade ( # 5064 ),547
"okhttp - logging - interceptor \ src \ main \ java \ okhttp3 \ logging \ HttpLoggingInterceptor . kt \n - source . request ( java . lang . Long . MAX _ VALUE ) / / Buffer the entire body . \n + source . request ( Long . MAX _ VALUE ) / / Buffer the entire body . \n okhttp \ src \ main \ java \ okhttp3 \ internal \ UtilKt . kt \n + \n + fun Long . toHexString ( ) = java . lang . Long . toHexString ( this ) \n + \n + fun Int . toHexString ( ) = Integer . toHexString ( this ) \n okhttp \ src \ main \ java \ okhttp3 \ internal \ ws \ WebSocketReader . kt \n + import okhttp3 . internal . toHexString \n - import java . lang . Integer . toHexString \n - "" Frame length 0x $ { java . lang . Long . toHexString ( frameLength ) } > 0x7FFFFFFFFFFFFFFF "" ) \n + "" Frame length 0x $ { frameLength . toHexString ( ) } > 0x7FFFFFFFFFFFFFFF "" ) \n - throw ProtocolException ( "" Unknown control opcode : "" + toHexString ( opcode ) ) \n + throw ProtocolException ( "" Unknown control opcode : "" + opcode . toHexString ( ) ) \n - throw ProtocolException ( "" Unknown opcode : $ { toHexString ( opcode ) } "" ) \n + throw ProtocolException ( "" Unknown opcode : $ { opcode . toHexString ( ) } "" ) \n - throw ProtocolException ( "" Expected continuation opcode . Got : $ { toHexString ( opcode ) } "" ) \n + throw ProtocolException ( "" Expected continuation opcode . Got : $ { opcode . toHexString ( ) } "" ) \n",Avoiding direct java . lang usage ( # 5065 ) \n * i \n * i \n * i,547
". travis . yml \n - secure : "" WMkcWrsvzJNf48w7DJwipUNbhAoggCkC + NM31esq9 / GDceGtVWj4hssQETynG4 + ckxr0wGqUxsTRTz0uGhX6Fi58haG8yKp + g / HVClqI5EYjI44ptPcwlqlbYjuGbk65k1OGGZLctA6fQA3uT0zee05 / yBjJx / jOqrN + PD1tW38 = "" \n - except : \n - - gh - pages \n + only : \n + - master \n",Build in Travis CI only on master ( # 5062 ),547
"new file \n SECURITY . md \n + # Security Policy \n + \n + # # Supported Versions \n + \n + | Version | Supported | \n + | - - - - - - - | - - - - - - - - - - - - - - - - - - | \n + | 4 . x | : white _ check _ mark : | \n + | 3 . 14 . x | : white _ check _ mark : | \n + | 3 . 12 . x | : white _ check _ mark : | \n + \n + # # Reporting a Vulnerability \n + \n + Square recognizes the important contributions the security research community \n + can make . We therefore encourage reporting security issues with the code \n + contained in this repository . \n + \n + If you believe you have discovered a security vulnerability , please follow the \n + guidelines at https : / / hackerone . com / square - open - source \n",Add githubs new security policy ( # 5117 ),547
"SECURITY . md \n - | Version | Supported | \n - | - - - - - - - | - - - - - - - - - - - - - - - - - - | \n - | 4 . x | : white _ check _ mark : | \n - | 3 . 14 . x | : white _ check _ mark : | \n - | 3 . 12 . x | : white _ check _ mark : | \n + | Version | Supported | Notes | \n + | - - - - - - - | - - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - | \n + | 4 . x | : x : | Not released . | \n + | 3 . 14 . x | : white _ check _ mark : | | \n + | 3 . 12 . x | : white _ check _ mark : | Android 2 . 3 + ( API level 9 + ) and Java 7 + . Platforms may not support TLSv1 . 2 . Until December 31 , 2020 | \n + | 2 . 7 . x | : x : | Not supported . | \n",Update SECURITY . md ( # 5131 ) \n * Update SECURITY . md \n * Update SECURITY . md \n * Update SECURITY . md,547
. circleci \ config . yml \n - - image : circleci / openjdk : 11 . 0 . 2 - jdk \n + - image : circleci / openjdk : 11 . 0 . 3 - jdk - stretch \n - - image : circleci / openjdk : 11 . 0 . 2 - jdk \n + - image : circleci / openjdk : 11 . 0 . 3 - jdk - stretch \n,Upgrade CircleCI to 11 . 0 . 3,547
"build . gradle \n - ' kotlin ' : ' 1 . 3 . 40 ' , \n + ' kotlin ' : ' 1 . 3 . 41 ' , \n",Kotlin upgrade to 1 . 3 . 41 \n Automatically prompted by IDE,547
gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 4 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 5 - all . zip \n gradlew \n - # http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + # https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n gradlew . bat \n - @ rem http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + @ rem https : / / www . apache . org / licenses / LICENSE - 2 . 0 \n,Gradle Wrapper 5 . 5 ( # 5271 ) \n * Gradle Wrapper 5 . 5 \n * Binary,547
"build . gradle \n - ' kotlin ' : ' 1 . 3 . 31 ' , \n + ' kotlin ' : ' 1 . 3 . 40 ' , \n",Kotlin 1 . 3 . 40 upgrade ( # 5210 ),547
"okhttp \ src \ test \ java \ okhttp3 \ ConnectionCoalescingTest . java \n - platform . assumeNotConscrypt ( ) ; \n - / * * Run against public external sites , doesn ' t run by default . * / \n - @ Ignore \n - @ Test public void coalescesConnectionsToRealSites ( ) throws IOException { \n - client = new OkHttpClient ( ) ; \n - \n - assert200Http2Response ( execute ( "" https : / / graph . facebook . com / robots . txt "" ) , "" graph . facebook . com "" ) ; \n - assert200Http2Response ( execute ( "" https : / / www . facebook . com / robots . txt "" ) , "" m . facebook . com "" ) ; \n - assert200Http2Response ( execute ( "" https : / / fb . com / robots . txt "" ) , "" m . facebook . com "" ) ; \n - assert200Http2Response ( execute ( "" https : / / messenger . com / robots . txt "" ) , "" messenger . com "" ) ; \n - assert200Http2Response ( execute ( "" https : / / m . facebook . com / robots . txt "" ) , "" m . facebook . com "" ) ; \n - \n - assertThat ( client . connectionPool ( ) . connectionCount ( ) ) . isEqualTo ( 3 ) ; \n - } \n - \n okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ ClientAuthTest . java \n - platform . assumeNotConscrypt ( ) ; \n - \n",Enable additional passing tests for conscrypt ( # 5227 ) \n * Testing conscrypt \n * Revert circleci,547
"mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ internal \ http2 \ Http2Server . java \n - closeQuietly ( socket ) ; \n + if ( socket ! = null ) { \n + closeQuietly ( socket ) ; \n + } \n - closeQuietly ( socket ) ; \n + if ( socket ! = null ) { \n + closeQuietly ( socket ) ; \n + } \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ HandshakeCertificatesTest . java \n - closeQuietly ( rawSocket ) ; \n - closeQuietly ( sslSocket ) ; \n + if ( rawSocket ! = null ) { \n + closeQuietly ( rawSocket ) ; \n + } \n + if ( sslSocket ! = null ) { \n + closeQuietly ( sslSocket ) ; \n + } \n - closeQuietly ( sslSocket ) ; \n + if ( sslSocket ! = null ) { \n + closeQuietly ( sslSocket ) ; \n + } \n okhttp \ src \ main \ java \ okhttp3 \ internal \ Util . kt \n - / * * Closes this , ignoring any checked exceptions . Does nothing if this is null . * / \n + / * * Closes this , ignoring any checked exceptions . * / \n - / * * Closes this , ignoring any checked exceptions . Does nothing if this is null . * / \n + / * * Closes this , ignoring any checked exceptions . * / \n - / * * Closes this , ignoring any checked exceptions . Does nothing if this is null . * / \n + / * * Closes this , ignoring any checked exceptions . * / \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ MockHttp2Peer . java \n - closeQuietly ( socket ) ; \n - closeQuietly ( serverSocket ) ; \n + if ( socket ! = null ) { \n + closeQuietly ( socket ) ; \n + } \n + if ( serverSocket ! = null ) { \n + closeQuietly ( serverSocket ) ; \n + } \n",Allow nullable on Util . close ( # 5224 ) \n Enforce null check in java with any mutable nullable closable,547
okhttp - testing - support \ src \ main \ java \ okhttp3 \ OkHttpClientTestRule . kt \n - val connectionPool = prototype ! ! . connectionPool \n - connectionPool . evictAll ( ) \n - assertThat ( connectionPool . idleConnectionCount ( ) ) . isEqualTo ( 0 ) \n + prototype ? . let { \n + val connectionPool = it . connectionPool \n + connectionPool . evictAll ( ) \n + assertThat ( connectionPool . connectionCount ( ) ) . isEqualTo ( 0 ) \n + } \n - prototypes . push ( prototype ) \n - prototype = null \n + prototype ? . let { \n + prototypes . push ( it ) \n + prototype = null \n + } \n + / * * \n + * Called if a test is known to be leaky . \n + * / \n + fun abandonClient ( ) { \n + prototype ? . let { \n + prototype = null \n + it . dispatcher . executorService . shutdownNow ( ) \n + it . connectionPool . evictAll ( ) \n + } \n + } \n + \n okhttp \ src \ test \ java \ okhttp3 \ internal \ ws \ WebSocketHttpTest . java \n + clientTestRule . abandonClient ( ) ; \n,"OkHttpClientTestRule check connectionCount instead of idle ( # 5226 ) \n * OkHttpClientTestRule check connectionCount instead of idle \n Clients should be clean after use , not just from idle connections . \n * Abandon unclean clients \n * Simplify logic",547
"okhttp - brotli \ src \ main \ java \ okhttp3 \ brotli \ BrotliInterceptor . kt \n - * responses . n . b . this replaces the transparent gzip compression InBridgeInterceptor . \n + * responses . n . b . this replaces the transparent gzip compression in BridgeInterceptor . \n okhttp - brotli \ src \ test \ java \ okhttp3 \ brotli \ BrotliInterceptorTest . kt \n + @ Test \n + fun testUncompressGzip ( ) { \n + val s = \n + "" 1f8b0800968f215d02ff558ec10e82301044ef7c45b3e75269d0c478e340e4a426e007086c4a636c9bb65e "" + \n + "" 24fcbb5b484c3cec61deccecee9c3106eaa39dc3114e2cfa377296d8848f117d20369324500d03ba98 "" + \n + "" d766b0a3368a0ce83d4f55581b14696c88894f31ba5e1b61bdfa79f7803eaf149a35619f29b3db0b29 "" + \n + "" 8abcbd54b7b6b97640c965bbfec238d9f4109ceb6edb01d66ba54d6247296441531e445970f627215b "" + \n + "" b22f1017320dd5000000 "" \n + \n + val response = response ( "" https : / / httpbin . org / gzip "" , s . decodeHex ( ) ) { \n + header ( "" Content - Encoding "" , "" gzip "" ) \n + } \n + \n + val uncompressed = BrotliInterceptor . uncompress ( response ) \n + \n + val responseString = uncompressed . body ? . string ( ) \n + assertThat ( responseString ) . contains ( "" \ "" gzipped \ "" : true , "" ) \n + assertThat ( responseString ) . contains ( "" \ "" Accept - Encoding \ "" : \ "" br , gzip \ "" "" ) \n + } \n + \n - } \n + } \n okhttp - brotli \ src \ test \ java \ okhttp3 \ brotli \ BrotliTestMain . kt \n - val req = Request . Builder ( ) \n - . url ( "" https : / / httpbin . org / brotli "" ) \n - . build ( ) \n + sendRequest ( "" https : / / httpbin . org / brotli "" , client ) \n + sendRequest ( "" https : / / httpbin . org / gzip "" , client ) \n + } \n + \n + private fun sendRequest ( url : String , client : OkHttpClient ) { \n + val req = Request . Builder ( ) . url ( url ) . build ( ) \n",Check gzip response in brotli interceptor ( # 5274 ) \n * Check gzip response in brotli interceptor \n * Update BrotliInterceptorTest . kt,547
"README . md \n - OkHttp has one library dependency on [ Okio ] [ okio ] , a small library for high - performance I / O . \n + OkHttp depends on [ Okio ] [ okio ] for high - performance I / O and the [ Kotlin standard library ] [ kotlin ] . Both are small libraries with strong backwards - compatibility . \n + [ kotlin ] : https : / / kotlinlang . org / \n",Document kotlin library dependency ( # 5273 ),547
"okhttp - testing - support \ src \ main \ java \ okhttp3 \ testing \ Flaky . kt \n - annotation class Flaky ( val issues : Array < String > = [ ] ) \n + annotation class Flaky \n okhttp \ src \ test \ java \ okhttp3 \ URLConnectionTest . java \n - @ Flaky ( issues = "" https : / / github . com / square / okhttp / issues / 5222 "" ) \n + @ Flaky \n + / / Flaky https : / / github . com / square / okhttp / issues / 5222 \n + \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ HttpOverHttp2Test . java \n - @ Flaky ( issues = { "" https : / / github . com / square / okhttp / issues / 4632 "" , \n - "" https : / / github . com / square / okhttp / issues / 4633 "" } ) \n + @ Flaky \n + / / Flaky https : / / github . com / square / okhttp / issues / 4632 \n + / / Flaky https : / / github . com / square / okhttp / issues / 4633 \n + \n - @ Flaky ( issues = "" https : / / github . com / square / okhttp / issues / 5221 "" ) \n + @ Flaky \n - @ Flaky ( issues = "" https : / / github . com / square / okhttp / issues / 4836 "" ) \n + @ Flaky \n + / / Flaky https : / / github . com / square / okhttp / issues / 4836 \n okhttp \ src \ test \ java \ okhttp3 \ internal \ ws \ WebSocketHttpTest . java \n - @ Flaky ( issues = { "" https : / / github . com / square / okhttp / issues / 4515 "" , \n - "" https : / / github . com / square / okhttp / issues / 4953 "" } ) \n + @ Flaky \n + / / Flaky https : / / github . com / square / okhttp / issues / 4515 \n + / / Flaky https : / / github . com / square / okhttp / issues / 4953 \n + \n",Move flaky issues to comments ( # 5289 ),547
. travis . yml \n + dist : trusty \n + \n - oraclejdk8 \n,TravisCI downgrade back to trusty ( # 5301 ),547
. travis . yml \n - oraclejdk8 \n + # avoid . / gradlew assemble default which builds docs \n + install : \n + - . / gradlew jar - - parallel \n + \n - - . / gradlew check - - parallel \n + - . / gradlew test - - parallel \n - . buildscript / deploy _ snapshot . sh \n,Avoid gradle assemble in Travis ( # 5312 ),547
. circleci \ config . yml \n - - testcorretto : \n - filters : \n - branches : \n - only : master \n + # - testcorretto \n - schedule : \n - testconscrypt : \n - compile \n - - testcorretto : \n - requires : \n - - compile \n,Avoid running Corretto platform until fixed ( # 5637 ),547
. circleci \ config . yml \n - testopenjsse : \n - ignore : \n - - gh - pages \n + only : master \n - testjdk11 : \n,Avoid running openjsse on each PR ( # 5381 ),547
. circleci \ config . yml \n - - image : circleci / openjdk : 8u171 - jdk \n + - image : circleci / openjdk : 8u222 - jdk - stretch \n - - image : circleci / openjdk : 8u171 - jdk \n + - image : circleci / openjdk : 8u222 - jdk - stretch \n - - image : circleci / openjdk : 8u171 - jdk \n + - image : circleci / openjdk : 8u222 - jdk - stretch \n - - image : circleci / openjdk : 8u171 - jdk \n + - image : circleci / openjdk : 8u222 - jdk - stretch \n - - image : circleci / openjdk : 8u171 - jdk \n + - image : circleci / openjdk : 8u222 - jdk - stretch \n - - image : circleci / openjdk : 11 . 0 . 3 - jdk - stretch \n + - image : circleci / openjdk : 11 . 0 . 4 - jdk - stretch \n - - image : circleci / dynamodb : 12 . 0 . 1 - jdk \n + - image : circleci / dynamodb : 12 . 0 . 2 - jdk \n - - image : circleci / openjdk : 11 . 0 . 3 - jdk - stretch \n + - image : circleci / openjdk : 11 . 0 . 4 - jdk - stretch \n,Bump CI JDK versions ( # 5386 ),547
"okhttp \ src \ main \ java \ okhttp3 \ OkHttpClient . kt \n - @ get : JvmName ( "" proxySelector "" ) val proxySelector : ProxySelector = builder . proxySelector \n + @ get : JvmName ( "" proxySelector "" ) val proxySelector : ProxySelector = \n + when { \n + / / Avoid possible SecurityException from ProxySelector . getDefault \n + builder . proxy ! = null - > NullProxySelector ( ) \n + else - > builder . proxySelector ? : ProxySelector . getDefault ( ) ? : NullProxySelector ( ) \n + } \n - internal var proxySelector : ProxySelector = ProxySelector . getDefault ( ) ? : NullProxySelector ( ) \n + internal var proxySelector : ProxySelector ? = null \n okhttp \ src \ test \ java \ okhttp3 \ OkHttpClientTest . java \n + import java . net . Proxy ; \n + import okhttp3 . internal . proxy . NullProxySelector ; \n + \n + @ Test public void testProxyDefaults ( ) { \n + OkHttpClient client = new OkHttpClient . Builder ( ) . build ( ) ; \n + assertThat ( client . proxy ( ) ) . isNull ( ) ; \n + assertThat ( client . proxySelector ( ) ) . isNotInstanceOf ( NullProxySelector . class ) ; \n + \n + client = new OkHttpClient . Builder ( ) . proxy ( Proxy . NO _ PROXY ) . build ( ) ; \n + assertThat ( client . proxy ( ) ) . isSameAs ( Proxy . NO _ PROXY ) ; \n + assertThat ( client . proxySelector ( ) ) . isInstanceOf ( NullProxySelector . class ) ; \n + \n + client = new OkHttpClient . Builder ( ) . proxySelector ( new FakeProxySelector ( ) ) . build ( ) ; \n + assertThat ( client . proxy ( ) ) . isNull ( ) ; \n + assertThat ( client . proxySelector ( ) ) . isInstanceOf ( FakeProxySelector . class ) ; \n + } \n",Avoid SecurityException on ProxySelector . getDefault when proxy set ( # 5332 ) \n * Handle SecurityException on ProxySelector . getDefault \n * Review comments \n * remove newline,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ android \ AndroidSocketAdapter . kt \n + } catch ( e : NullPointerException ) { \n + when { \n + / / https : / / github . com / square / okhttp / issues / 5587 \n + e . message = = "" ssl = = null "" - > null \n + else - > throw e \n + } \n",Workaround AOSP conscrypt NPE ( # 5590 ),547
". circleci \ config . yml \n - testjdk8 : \n - only : master \n + ignore : \n + - gh - pages \n - testjdk8alpn : \n okhttp \ src \ test \ java \ okhttp3 \ CallTest . java \n + import okhttp3 . internal . platform . Platform ; \n - assertThat ( call . execute ( ) . body ( ) . string ( ) ) . isEqualTo ( "" Response 1 "" ) ; \n + try ( Response response = call . execute ( ) ) { \n + assertThat ( response . code ( ) ) . isEqualTo ( 200 ) ; \n + assertThat ( response . body ( ) . string ( ) ) . isNotBlank ( ) ; \n + } \n + \n + long connectCount = listener . eventSequence . stream ( ) . filter ( ( event ) - > event instanceof RecordingEventListener . ConnectStart ) . count ( ) ; \n + long expected = platform . isJdk8 ( ) ? 2 : 1 ; \n + assertThat ( connectCount ) . isEqualTo ( expected ) ; \n",Run Jdk8 on CI and fix test expectations ( # 5582 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ HttpOverHttp2Test . java \n - private PlatformRule platform = new PlatformRule ( ) ; \n + private final PlatformRule platform = new PlatformRule ( ) ; \n + private final OkHttpClientTestRule clientTestRule = new OkHttpClientTestRule ( ) ; \n - RuleChain . outerRule ( platform ) . around ( new Timeout ( 5 , SECONDS ) ) ; \n + RuleChain . outerRule ( platform ) . around ( clientTestRule ) . around ( new Timeout ( 5 , SECONDS ) ) ; \n - @ Rule public final OkHttpClientTestRule clientTestRule = new OkHttpClientTestRule ( ) ; \n",Testing fix / workaround for missingPongsFailsConnection with JDK12 ( # 5584 ),547
"mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ MockWebServerTest . java \n - BufferedReader reader = new BufferedReader ( new InputStreamReader ( connection . getInputStream ( ) ) ) ; \n + BufferedReader reader = \n + new BufferedReader ( new InputStreamReader ( connection . getInputStream ( ) , UTF _ 8 ) ) ; \n okhttp - hpacktests \ src \ test \ java \ okhttp3 \ internal \ http2 \ hpackjson \ HpackJsonUtil . java \n - return storyNames . toArray ( new String [ storyNames . size ( ) ] ) ; \n + return storyNames . toArray ( new String [ 0 ] ) ; \n - return Collections . singletonList ( MISSING ) ; \n + result . add ( MISSING ) ; \n okhttp - sse \ src \ test \ java \ okhttp3 \ internal \ sse \ EventSourceHttpTest . java \n + "" data : hey \ n "" \n + "" \ n "" ) . setHeader ( "" content - type "" , "" text / plain "" ) ) ; \n - EventSource source = newEventSource ( ) ; \n + newEventSource ( ) ; \n + "" data : hey \ n "" \n + "" \ n "" ) . setHeader ( "" content - type "" , "" text / event - stream "" ) . setResponseCode ( 401 ) ) ; \n - EventSource source = newEventSource ( ) ; \n + newEventSource ( ) ; \n",ErrorProne cleanup of two modules ( # 5640 ) \n * Fix \n * Fix 2,547
"android - test \ build . gradle \n + testInstrumentationRunnerArguments ( [ ' notClass ' : ' org . conscrypt . KitKatPlatformOpenSSLSocketImplAdapter ' ] ) \n + implementation "" org . jetbrains . kotlin : kotlin - reflect : $ { versions . kotlin } "" \n - exclude group : ' org . openjsse ' , module : ' openjsse ' \n + exclude group : ' org . openjsse ' , module : ' openjsse ' \n + exclude group : ' org . conscrypt ' , module : ' conscrypt - openjdk - uber ' \n + androidTestImplementation "" org . conscrypt : conscrypt - android : 2 . 2 . 1 "" \n android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n + import org . conscrypt . Conscrypt \n + import java . security . Security \n + @ Test \n + fun testConscryptRequest ( ) { \n + assumeNetwork ( ) \n + \n + try { \n + Security . insertProviderAt ( Conscrypt . newProviderBuilder ( ) . build ( ) , 1 ) \n + \n + val request = Request . Builder ( ) . url ( "" https : / / facebook . com / robots . txt "" ) . build ( ) \n + \n + var socketClass : String ? = null \n + \n + client = OkHttpClient . Builder ( ) . eventListener ( object : EventListener ( ) { \n + override fun connectionAcquired ( call : Call , connection : Connection ) { \n + socketClass = connection . socket ( ) . javaClass . name \n + } \n + } ) . build ( ) \n + \n + val response = client . newCall ( request ) . execute ( ) \n + \n + response . use { \n + assertEquals ( Protocol . HTTP _ 2 , response . protocol ) \n + assertEquals ( TlsVersion . TLS _ 1 _ 3 , response . handshake ? . tlsVersion ) \n + assertEquals ( 200 , response . code ) \n + assertEquals ( "" org . conscrypt . Java8FileDescriptorSocket "" , socketClass ) \n + } \n + } finally { \n + Security . removeProvider ( "" Conscrypt "" ) \n + } \n + } \n + \n",Add Conscrypt specific test for Android ( # 5473 ) \n * Add Conscrypt specific test for Android \n * Fix,547
. circleci \ config . yml \n - GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dorg . gradle . workers . max = 3 - Xmx1G \n + GRADLE _ OPTS : - Dorg . gradle . daemon = false - Dokhttp . platform = jdk9 - Dorg . gradle . workers . max = 3 - Xmx1G \n - save _ cache : \n,Second fix for CircleCI ( # 5478 ),547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ AndroidPlatform . kt \n + \n + / / account for android - all , forces UnsatisfiedLinkError in Intellij \n + check ( Build . VERSION . SDK _ INT > 0 ) \n + \n + / / Running in a JVM \n + false \n + } catch ( _ : UnsatisfiedLinkError ) { \n + / / Running in a JVM / Intellij with android - all on the classpath \n - val isSupported : Boolean = try { \n - / / Trigger an early exception over a fatal error , prefer a RuntimeException over Error . \n - Class . forName ( "" com . android . org . conscrypt . OpenSSLSocketImpl "" ) \n - \n - / / Fail Fast \n - check ( \n - Build . VERSION . SDK _ INT > = 21 ) { "" Expected Android API level 21 + but was $ { Build . VERSION . SDK _ INT } "" } \n + val isSupported : Boolean = when { \n + ! isAndroid - > false \n + else - > { \n + / / Fail Fast \n + check ( \n + Build . VERSION . SDK _ INT > = 21 ) { "" Expected Android API level 21 + but was $ { Build . VERSION . SDK _ INT } "" } \n - true \n - } catch ( _ : ClassNotFoundException ) { \n - false \n + true \n + } \n","Revise isAndroid test ( # 5491 ) \n More specific tests for isAndroid , that also accounts for Intellij with android - all on the classpath .",547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ RealConnectionPool . kt \n + import okhttp3 . internal . lockAndWaitNanos \n - import okhttp3 . internal . lockAndWaitNanos \n - } catch ( _ : InterruptedException ) { \n + } catch ( ie : InterruptedException ) { \n + / / Will cause the thread to exit unless other connections are created ! \n + evictAll ( ) \n okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ ConnectionPoolTest . java \n + @ Test public void interruptStopsThread ( ) throws Exception { \n + RealConnectionPool pool = new RealConnectionPool ( 2 , 100L , TimeUnit . NANOSECONDS ) ; \n + RealConnection c1 = newConnection ( pool , routeA1 , Long . MAX _ VALUE ) ; \n + \n + assertThat ( pool . getCleanupRunning ( ) ) . isTrue ( ) ; \n + \n + Thread . sleep ( 100 ) ; \n + \n + Thread [ ] threads = new Thread [ Thread . activeCount ( ) * 2 ] ; \n + Thread . enumerate ( threads ) ; \n + for ( Thread t : threads ) { \n + if ( t ! = null & & t . getName ( ) . equals ( "" OkHttp ConnectionPool "" ) ) { \n + t . interrupt ( ) ; \n + } \n + } \n + \n + Thread . sleep ( 100 ) ; \n + \n + assertThat ( pool . getCleanupRunning ( ) ) . isFalse ( ) ; \n + } \n + \n",Allow interrupt of singleton cleanup thread ( # 5334 ) \n * Allow interrupt of singleton cleanup thread \n * inline \n * Cleanup connections on interrupt \n * Additional test debugging \n * Delay before interrupting \n * Remove println,547
"okhttp \ src \ test \ java \ okhttp3 \ WholeOperationTimeoutTest . java \n + import okhttp3 . testing . Flaky ; \n + @ Flaky \n + / / Flaky https : / / github . com / square / okhttp / issues / 5304 \n + \n - call . timeout ( ) . timeout ( 1000 , TimeUnit . MILLISECONDS ) ; \n + call . timeout ( ) . timeout ( 2000 , TimeUnit . MILLISECONDS ) ; \n",Increase timeout for flaky test ( # 5305 ),547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - val request = Request . Builder ( ) . url ( "" http : / / api . twitter . com / robots . txt "" ) . build ( ) \n + val request = Request . Builder ( ) . url ( "" http : / / squareup . com / robots . txt "" ) . build ( ) \n",Update test host to squareup ( # 5343 ),547
". circleci \ config . yml \n - runtests : \n + testjdk13 : \n + docker : \n + - image : circleci / openjdk : 13 . 0 . 1 - jdk - buster \n + \n + environment : \n + JVM _ OPTS : - Xmx1g \n + TERM : dumb \n + \n + steps : \n + - checkout \n + \n + - runtests : \n + platform : jdk9 \n + \n - image : circleci / openjdk : 11 . 0 . 5 - jdk - stretch \n + - testjdk13 : \n + filters : \n + branches : \n + ignore : \n + - gh - pages \n - testconscrypt : \n - testjdk12 : \n - compile \n + - testjdk13 : \n + requires : \n + - compile \n - testconscrypt : \n - compile \n build . gradle \n - classpath ' com . diffplug . spotless : spotless - plugin - gradle : 3 . 21 . 1 ' \n + classpath ' com . diffplug . spotless : spotless - plugin - gradle : 3 . 25 . 0 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 5 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 0 - all . zip \n okhttp - testing - support \ src \ main \ java \ okhttp3 \ testing \ PlatformRule . kt \n + fun expectFailureOnJdkVersion ( majorVersion : Int ) { \n + expectFailure ( onMajor ( majorVersion ) ) \n + } \n + \n + fun onMajor ( version : Int ) : Matcher < PlatformVersion > { \n + return object : TypeSafeMatcher < PlatformVersion > ( ) { \n + override fun describeTo ( description : Description ) { \n + description . appendText ( "" JDK with version $ version "" ) \n + } \n + \n + override fun matchesSafely ( item : PlatformVersion ) : Boolean { \n + return item . majorVersion = = version \n + } \n + } \n + } \n + \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ HttpOverHttp2Test . java \n - platform . expectFailureFromJdkVersion ( 12 ) ; \n + platform . expectFailureOnJdkVersion ( 12 ) ; \n",JDK 13 and Gradle 6 ( # 5561 ) \n * JDK 13 and Gradle 6 RC 1 \n * Wrong JDK \n * Passes test on JDK 13 \n * Fix \n * Spotless upgrade \n * Update gradle - wrapper . properties \n * Gradle 6,547
". buildscript \ deploy _ snapshot . sh \n - JDK = "" oraclejdk8 "" \n + JDK = "" openjdk11 "" \n . travis . yml \n - - oraclejdk8 \n - \n - # avoid . / gradlew assemble default which builds docs \n - install : \n - - . / gradlew jar - - parallel \n + - openjdk11 \n - - . / gradlew test - - parallel \n + - . / gradlew jar - - parallel \n - . buildscript / deploy _ snapshot . sh \n",Bump Travis to JDK 11 ( # 5601 ) \n * Bump Travis to JDK 11 \n * Testing \n * Publish snapshots \n * empty \n * empty \n * JDK 9 \n * OpenJDK 11 \n * Travis testing \n * Skip master tests in Travis CI \n * For landing,547
"build . gradle \n - ' kotlin ' : ' 1 . 3 . 20 ' , \n + ' kotlin ' : ' 1 . 3 . 30 ' , \n",Kotlin 1 . 3 . 30 Upgrade ( # 4931 ),547
okhttp - logging - interceptor \ src \ main \ java \ okhttp3 \ logging \ LoggingEventListener . kt \n + constructor ( block : ( string : String ) - > Unit ) : this ( HttpLoggingInterceptor . Logger ( block ) ) \n + \n okhttp \ src \ test \ java \ okhttp3 \ KotlinSourceCompatibilityTest . kt \n + builder = builder . eventListenerFactory ( LoggingEventListener . Factory { s - > TODO ( ) } ) \n,Fix kotlin source compatibility with logger ( # 4927 ) \n * Document broken kotlin source \n * Fix existing code,547
"okhttp - logging - interceptor \ src \ main \ java \ okhttp3 \ logging \ LoggingEventListener . kt \n - constructor ( block : ( string : String ) - > Unit ) : this ( HttpLoggingInterceptor . Logger ( block ) ) \n + constructor ( block : ( string : String ) - > Unit ) : this ( HttpLoggingInterceptor . Logger ( block ) ) \n okhttp \ src \ main \ java - templates \ okhttp3 \ internal \ Version . kt \n - const val userAgent = "" okhttp / $ { projectVersion } "" \n + const val userAgent = "" okhttp / $ projectVersion "" \n okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ RealConnectionPool . kt \n - 60L , TimeUnit . SECONDS , / / keepAliveTime . \n + 60L , TimeUnit . SECONDS , / / keepAliveTime . \n",Fix merge conflicts after spotless applied ( # 4933 ),547
build . gradle \n - case 191 . . 212 : \n + case 191 . . 222 : \n,New OpenJDK 8 version ( # 5354 ),547
"build . gradle \n - testImplementation "" org . mortbay . jetty . alpn : alpn - boot : $ alpnBootVersion "" \n + testCompile "" org . mortbay . jetty . alpn : alpn - boot : $ alpnBootVersion "" \n",Revert build change that broke jdk8alpn ( # 5358 ) \n * Revert build change that broke jdk8alpn \n * revert ci change,547
. circleci \ config . yml \n - runtests : \n - testjdk12 : \n - docker : \n - # best source of JDK 12 for now \n - - image : circleci / dynamodb : 12 . 0 . 2 - jdk \n - \n - environment : \n - JVM _ OPTS : - Xmx1g \n - TERM : dumb \n - \n - steps : \n - - checkout \n - \n - - runtests : \n - platform : jdk9 \n - \n - image : circleci / openjdk : 13 . 0 . 1 - jdk - buster \n - - testopenjsse : \n - filters : \n - branches : \n - only : master \n - testjdk11 : \n - gh - pages \n - - testjdk12 : \n - filters : \n - branches : \n - only : master \n - testjdk13 : \n - gh - pages \n - - testconscrypt : \n - filters : \n - branches : \n - only : master \n + # - testopenjsse \n + # - testconscrypt \n - testjdk11 : \n - compile \n - - testjdk12 : \n - requires : \n - - compile \n - testjdk13 : \n - compile \n,Remove JDK 12 ( non - LTS ) from CI ( # 5642 ) \n Reduce per commit builds to minimal key platforms,547
"build . gradle \n + \n + systemProperty ' okhttp . platform ' , platform \n",Declare platform property to affect gradle build caching ( # 5661 ) \n * Declare platform property to affect gradle build cache key \n * Fix,547
okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ ConscryptPlatform . kt \n + } catch ( e : NoClassDefFoundError ) { \n + false \n,Handle NoClassDefFoundError for Conscrypt ( # 5763 ),547
"samples \ compare \ src \ test \ kotlin \ okhttp3 \ compare \ ApacheHttpClientTest . kt \n + * \n + * Baseline test if we ned to validate OkHttp behaviour against other popular clients . \n - class ApacheHttpClientTest ( \n - private val server : MockWebServer \n - ) { \n + class ApacheHttpClientTest { \n - @ Test fun get ( ) { \n + @ Test fun get ( server : MockWebServer ) { \n samples \ compare \ src \ test \ kotlin \ okhttp3 \ compare \ JavaHttpClientTest . kt \n + import mockwebserver3 . MockResponse \n + import mockwebserver3 . MockWebServer \n - import mockwebserver3 . MockResponse \n - import mockwebserver3 . MockWebServer \n + import okhttp3 . testing . PlatformRule \n - import org . junit . jupiter . api . Disabled \n + import org . junit . jupiter . api . extension . RegisterExtension \n + * \n + * Baseline test if we ned to validate OkHttp behaviour against other popular clients . \n - @ Disabled ( "" Requires Java 11 , but OkHttp runs on Java 8 + "" ) \n - class JavaHttpClientTest ( \n - private val server : MockWebServer \n - ) { \n - private val httpClient = HttpClient . newBuilder ( ) \n + class JavaHttpClientTest { \n + @ JvmField @ RegisterExtension val platform = PlatformRule ( ) \n + \n + @ Test fun get ( server : MockWebServer ) { \n + / / Not available \n + platform . expectFailureOnJdkVersion ( 8 ) \n + \n + val httpClient = HttpClient . newBuilder ( ) \n - @ Test fun get ( ) { \n samples \ compare \ src \ test \ kotlin \ okhttp3 \ compare \ JettyHttpClientTest . kt \n + * \n + * Baseline test if we ned to validate OkHttp behaviour against other popular clients . \n - class JettyHttpClientTest ( \n - val server : MockWebServer \n - ) { \n - \n + class JettyHttpClientTest { \n - @ Test fun get ( ) { \n + @ Test fun get ( server : MockWebServer ) { \n samples \ compare \ src \ test \ kotlin \ okhttp3 \ compare \ OkHttpClientTest . kt \n - class OkHttpClientTest ( \n - private val server : MockWebServer \n - ) { \n - @ RegisterExtension @ JvmField val platform = PlatformRule ( ) \n + class OkHttpClientTest { \n + @ JvmField @ RegisterExtension val platform = PlatformRule ( ) \n - private val client = OkHttpClient ( ) \n - \n - @ Test fun get ( ) { \n + @ Test fun get ( server : MockWebServer ) { \n + val client = OkHttpClient ( ) \n + \n",Migrate samples / compare to junit 5 ( # 6369 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ authenticator \ JavaNetAuthenticatorTest . kt \n - import org . junit . After \n - import org . junit . Assert . assertEquals \n - import org . junit . Before \n - import org . junit . Test \n + import org . junit . jupiter . api . AfterEach \n + import org . junit . jupiter . api . Assertions . assertEquals \n + import org . junit . jupiter . api . BeforeEach \n + import org . junit . jupiter . api . Test \n - @ Before \n + @ BeforeEach \n - @ After \n + @ AfterEach \n,Move authenticator tests to Junit 5 ( # 6374 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ ConnectionPoolTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ ConnectionSpecSelectorTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ RouteExceptionTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ RouteSelectorTest . java \n - import static org . junit . Assert . fail ; \n + import static org . junit . jupiter . api . Assertions . fail ; \n - fail ( ) ; \n + fail ( "" "" ) ; \n",Move connection tests to Junit 5 ( # 6376 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ FrameLogTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ HpackTest . java \n - import org . junit . Before ; \n - import org . junit . Test ; \n + import org . junit . jupiter . api . BeforeEach ; \n + import org . junit . jupiter . api . Test ; \n - import static org . junit . Assert . fail ; \n + import static org . junit . jupiter . api . Assertions . fail ; \n - @ Before public void reset ( ) { \n + @ BeforeEach public void reset ( ) { \n - fail ( ) ; \n + fail ( "" "" ) ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ Http2Test . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n - import static org . junit . Assert . fail ; \n + import static org . junit . jupiter . api . Assertions . fail ; \n - fail ( ) ; \n + fail ( "" "" ) ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ HuffmanTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n - import static org . junit . Assert . assertEquals ; \n + import static org . junit . jupiter . api . Assertions . assertEquals ; \n",Move most http2 tests to Junit 5 ( # 6378 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ publicsuffix \ PublicSuffixDatabaseTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n,Move most public suffix tests to Junit 5 ( # 6379 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ CertificatePinnerChainValidationTest . java \n - import static org . junit . Assert . fail ; \n + import static org . junit . jupiter . api . Assertions . fail ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ HostnameVerifierTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n,Move most tls tests to Junit 5 ( # 6380 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ UtilTest . kt \n - import org . junit . Assert . fail \n - import org . junit . Test \n + import org . junit . jupiter . api . Assertions . fail \n + import org . junit . jupiter . api . Test \n,Move util tests to Junit 5 ( # 6382 ),547
"okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ CertificatesJavaTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ CertificatesTest . kt \n - import org . junit . Assert \n - import org . junit . Test \n + import org . junit . jupiter . api . Assertions . assertEquals \n + import org . junit . jupiter . api . Test \n - Assert . assertEquals ( certificateString , certificate . certificatePem ( ) ) \n + assertEquals ( certificateString , certificate . certificatePem ( ) ) \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ internal \ der \ DerCertificatesTest . kt \n - import org . junit . Test \n + import org . junit . jupiter . api . Test \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ internal \ der \ DerTest . kt \n - import org . junit . Assert . fail \n - import org . junit . Ignore \n - import org . junit . Test \n + import org . junit . jupiter . api . Disabled \n + import org . junit . jupiter . api . Test \n + import org . junit . jupiter . api . fail \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - @ Ignore ( "" fractional seconds are not implemented "" ) \n + @ Disabled ( "" fractional seconds are not implemented "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n - fail ( ) \n + fail ( "" "" ) \n",Move tls tests to Junit 5 ( # 6372 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ concurrent \ TaskLoggerTest . kt \n - import org . junit . Test \n + import org . junit . jupiter . api . Test \n okhttp \ src \ test \ java \ okhttp3 \ internal \ concurrent \ TaskRunnerRealBackendTest . kt \n - import org . junit . After \n - import org . junit . Test \n + import org . junit . jupiter . api . AfterEach \n + import org . junit . jupiter . api . Test \n - @ After fun tearDown ( ) { \n + @ AfterEach fun tearDown ( ) { \n,Move concurrent tests to Junit 5 ( # 6375 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ http \ HttpDateTest . kt \n - import org . junit . After \n - import org . junit . Before \n - import org . junit . Test \n + import org . junit . jupiter . api . AfterEach \n + import org . junit . jupiter . api . BeforeEach \n + import org . junit . jupiter . api . Test \n - @ Before \n - @ Throws ( Exception : : class ) \n + @ BeforeEach \n - @ After \n + @ AfterEach \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http \ StatusLineTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n - import static org . junit . Assert . fail ; \n + import static org . junit . jupiter . api . Assertions . fail ; \n - fail ( ) ; \n + fail ( "" "" ) ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http \ ThreadInterruptTest . java \n - fail ( ) ; \n + fail ( "" "" ) ; \n",Move http tests to Junit 5 ( # 6377 ),547
okhttp \ src \ test \ java \ okhttp3 \ osgi \ OsgiTest . java \n - import org . junit . Before ; \n - import org . junit . Test ; \n + import org . junit . jupiter . api . BeforeEach ; \n + import org . junit . jupiter . api . Test ; \n - @ Before \n + @ BeforeEach \n,Move osgi tests to Junit 5 ( # 6373 ),547
"native - image - tests \ build . gradle \n - id "" com . palantir . graal "" version "" 0 . 7 . 1 "" \n + id "" com . palantir . graal "" version "" 0 . 7 . 2 "" \n",Update native image plugin ( # 6368 ),547
"okhttp - tls \ src \ main \ java \ okhttp3 \ tls \ HeldCertificate . kt \n + import java . security . cert . CertificateParsingException \n - val certificates = CertificateFactory . getInstance ( "" X . 509 "" ) \n + val certificateFactory = CertificateFactory . getInstance ( "" X . 509 "" ) \n + val certificates = certificateFactory \n - return certificates . iterator ( ) . next ( ) as X509Certificate \n + \n + try { \n + return certificates . single ( ) as X509Certificate \n + } catch ( nsee : NoSuchElementException ) { \n + throw CertificateParsingException ( nsee ) \n + } catch ( iae : IllegalArgumentException ) { \n + throw CertificateParsingException ( iae ) \n + } \n",Handle Conscrypt decode behaviour ( # 5733 ) \n * Handle Conscrypt decode behaviour \n * Cleanup,547
okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ HandshakeCertificatesTest . java \n + . addTrustedCertificate ( root . certificate ( ) ) / / BouncyCastle requires at least one \n,Fix for BouncyCastle keyManager test ( # 5747 ),547
BUG - BOUNTY . md \n - guidelines at https : / / hackerone . com / square - open - source \n + guidelines at https : / / bugcrowd . com / squareopensource \n docs \ security . md \n - guidelines at https : / / hackerone . com / square - open - source \n + guidelines at https : / / bugcrowd . com / squareopensource \n,Updated bug bounty ( # 5753 ) \n * Updated bug bounty \n * Fix the bugcrowd URL \n * Fix the bugcrowd URL \n * Restore the https : / / in the bugcrowd URL \n Co - authored - by : Jesse Wilson < jesse @ swank . ca >,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ connection \ Transmitter . kt \n - check ( exchange = = null ) \n + check ( exchange = = null ) { \n + "" cannot make a new request because the previous response is still open : "" + \n + "" please call response . close ( ) "" \n + } \n",Explain prior responses issue for App Interceptors ( # 5752 ),547
"mockwebserver \ src \ main \ java \ okhttp3 \ mockwebserver \ MockWebServer . kt \n - connection . start ( ) \n + connection . start ( taskRunner = taskRunner ) \n okhttp \ src \ main \ java \ okhttp3 \ internal \ http2 \ Http2Connection . kt \n + * @ param taskRunner the TaskRunner to use , daemon by default . \n - fun start ( sendConnectionPreface : Boolean = true ) { \n + fun start ( sendConnectionPreface : Boolean = true , taskRunner : TaskRunner = TaskRunner . INSTANCE ) { \n - Thread ( readerRunnable , connectionName ) . start ( ) / / Not a daemon thread . \n + / / Thread doesn ' t use client Dispatcher , since it is scoped potentially across clients via \n + / / ConnectionPool . \n + taskRunner . newQueue ( ) . execute ( name = connectionName , block = readerRunnable ) \n - ) : Runnable , Http2Reader . Handler { \n - override fun run ( ) { \n + ) : Http2Reader . Handler , ( ) - > Unit { \n + override fun invoke ( ) { \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ Http2ConnectionTest . java \n + import okhttp3 . internal . concurrent . TaskFaker ; \n + import okhttp3 . internal . concurrent . TaskQueue ; \n - connection . start ( false ) ; \n + connection . start ( / * sendConnectionPreface = * / false ) ; \n - connection . start ( false ) ; \n + connection . start ( / * sendConnectionPreface = * / false ) ; \n + @ Test public void connectionUsesTaskRunner ( ) throws Exception { \n + peer . acceptFrame ( ) ; / / SYN _ STREAM . \n + peer . play ( ) ; \n + \n + TaskFaker taskFaker = new TaskFaker ( ) ; \n + TaskRunner taskRunner = taskFaker . getTaskRunner ( ) ; \n + \n + Socket socket = peer . openSocket ( ) ; \n + Http2Connection connection = new Http2Connection . Builder ( true , taskRunner ) \n + . socket ( socket ) \n + . pushObserver ( IGNORE ) \n + . build ( ) ; \n + connection . start ( / * sendConnectionPreface = * / false , taskRunner ) ; \n + \n + List < TaskQueue > queues = taskRunner . activeQueues ( ) ; \n + assertThat ( queues ) . hasSize ( 1 ) ; \n + } \n + \n - connection . start ( false ) ; \n + connection . start ( / * sendConnectionPreface = * / false ) ; \n",Switch Http2Connection to daemon for clients ( # 5834 ) \n Allow for container usage where libraries / plugins may use OkHttp internally and it ' s not clear who cleans up . This brings HTTP / 2 inline with the daemon only behaviour of HTTP / 1 . 1 .,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ Util . kt \n + \n + fun Exception . withSuppressed ( suppressed : List < Exception > ) : Throwable = apply { \n + if ( suppressed . size > 1 ) { \n + println ( suppressed ) \n + } \n + \n + for ( e in suppressed ) addSuppressed ( e ) \n + } \n okhttp \ src \ main \ java \ okhttp3 \ internal \ http \ RetryAndFollowUpInterceptor . kt \n + import okhttp3 . internal . withSuppressed \n + var recoveredFailures = listOf < IOException > ( ) \n - throw e . firstConnectException \n + throw e . firstConnectException . withSuppressed ( recoveredFailures ) \n + } else { \n + recoveredFailures + = e . firstConnectException \n - throw e \n + throw e . withSuppressed ( recoveredFailures ) \n + } else { \n + recoveredFailures + = e \n okhttp \ src \ test \ java \ okhttp3 \ CallKotlinTest . kt \n + import java . net . Proxy \n + import java . time . Duration \n + import okhttp3 . internal . http . RecordingProxySelector \n + \n + @ Test fun exceptionsAreReturnedAsSuppressed ( ) { \n + val proxySelector = RecordingProxySelector ( ) \n + proxySelector . proxies . add ( Proxy ( Proxy . Type . HTTP , TestUtil . UNREACHABLE _ ADDRESS ) ) \n + proxySelector . proxies . add ( Proxy . NO _ PROXY ) \n + \n + server . enqueue ( MockResponse ( ) . setSocketPolicy ( SocketPolicy . DISCONNECT _ AT _ START ) ) \n + \n + client = client . newBuilder ( ) \n + . proxySelector ( proxySelector ) \n + . readTimeout ( Duration . ofMillis ( 100 ) ) \n + . connectTimeout ( Duration . ofMillis ( 100 ) ) \n + . build ( ) \n + \n + val request = Request . Builder ( ) . url ( server . url ( "" / "" ) ) . build ( ) \n + try { \n + client . newCall ( request ) . execute ( ) \n + fail ( ) \n + } catch ( expected : IOException ) { \n + assertThat ( expected . suppressed ) . hasSize ( 1 ) \n + val suppressed = expected . suppressed [ 0 ] \n + assertThat ( suppressed ) . isInstanceOf ( IOException : : class . java ) \n + assertThat ( suppressed ) . isNotSameAs ( expected ) \n + } \n + } \n",Add SuppressedExceptions for multiple Routes ( # 5836 ) \n Allow understanding the failures of each route from the final exception thrown .,547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n + import okhttp3 . internal . concurrent . TaskRunner \n + import okhttp3 . internal . http2 . Http2 \n + import java . util . concurrent . atomic . AtomicInteger \n + import java . util . logging . Handler \n + import java . util . logging . Level \n + import java . util . logging . LogRecord \n + fun testLoggingLevels ( ) { \n + enableTls ( ) \n + \n + val testHandler = object : Handler ( ) { \n + val calls = mutableMapOf < String , AtomicInteger > ( ) \n + \n + override fun publish ( record : LogRecord ) { \n + calls . getOrPut ( record . loggerName ) { AtomicInteger ( 0 ) } \n + . incrementAndGet ( ) \n + } \n + \n + override fun flush ( ) { \n + } \n + \n + override fun close ( ) { \n + } \n + } . apply { \n + level = Level . FINEST \n + } \n + \n + Logger . getLogger ( "" "" ) \n + . addHandler ( testHandler ) \n + Logger . getLogger ( "" okhttp3 "" ) \n + . addHandler ( testHandler ) \n + Logger . getLogger ( Http2 : : class . java . name ) \n + . addHandler ( testHandler ) \n + Logger . getLogger ( TaskRunner : : class . java . name ) \n + . addHandler ( testHandler ) \n + Logger . getLogger ( OkHttpClient : : class . java . name ) \n + . addHandler ( testHandler ) \n + \n + server . enqueue ( MockResponse ( ) . setBody ( "" abc "" ) ) \n + \n + val request = Request . Builder ( ) \n + . url ( server . url ( "" / "" ) ) \n + . build ( ) \n + \n + val response = client . newCall ( request ) \n + . execute ( ) \n + \n + response . use { \n + assertEquals ( 200 , response . code ) \n + assertEquals ( Protocol . HTTP _ 2 , response . protocol ) \n + } \n + \n + / / Only logs to the test logger above \n + / / Will fail if "" adb shell setprop log . tag . okhttp . Http2 DEBUG "" is called \n + assertEquals ( setOf ( OkHttpTest : : class . java . name ) , testHandler . calls . keys ) \n + } \n + \n",Confirm android logging disabled ( # 6008 ),547
"build . gradle \n - ' animalSniffer ' : ' 1 . 18 ' , \n + ' animalSniffer ' : ' 1 . 19 ' , \n - id "" ru . vyarus . animalsniffer "" version "" 1 . 5 . 0 "" \n + id "" ru . vyarus . animalsniffer "" version "" 1 . 5 . 1 "" \n - / / https : / / github . com / mojohaus / animal - sniffer / issues / 70 \n - excludeJars "" android - all - * "" \n",Animal Sniffer upgrade ( # 6300 ) \n * Animal Sniffer upgrade \n * Animal Sniffer upgrade,547
"android - test \ build . gradle \n - testInstrumentationRunnerArguments ( [ ' notClass ' : ' org . conscrypt . KitKatPlatformOpenSSLSocketImplAdapter ' ] ) \n + testInstrumentationRunnerArguments ( [ ' notClass ' : ' org . conscrypt . KitKatPlatformOpenSSLSocketImplAdapter , org . bouncycastle . pqc . crypto . qtesla . QTeslaKeyEncodingTests ' ] ) \n android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - assertEquals ( TlsVersion . TLS _ 1 _ 2 , response . handshake ? . tlsVersion ) \n + val tlsVersion = response . handshake ? . tlsVersion \n + assertTrue ( tlsVersion = = TlsVersion . TLS _ 1 _ 2 | | tlsVersion = = TlsVersion . TLS _ 1 _ 3 ) \n - assertEquals ( listOf ( "" CallStart "" , "" ProxySelectStart "" , "" ProxySelectEnd "" , \n + assertEquals ( listOf ( "" CallStart "" , \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ Android10Platform . kt \n + import android . annotation . TargetApi \n + @ TargetApi ( Build . VERSION _ CODES . N ) \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ AndroidPlatform . kt \n + Build . VERSION . SDK _ INT > = 30 - > false / / graylisted methods are banned \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ android \ Android10SocketAdapter . kt \n + import android . annotation . SuppressLint \n + @ SuppressLint ( "" NewApi "" ) \n + @ SuppressLint ( "" NewApi "" ) \n",Fixes for Android Test ( including R ) ( # 5817 ),547
"okhttp \ src \ main \ kotlin \ okhttp3 \ CacheControl . kt \n - if ( isEmpty ( ) ) return "" "" \n + if ( length = = 0 ) return "" "" / / isEmpty ( ) is problematic with Kotlin 1 . 4 and JDK 15 \n",Avoid isEmpty ( ) ( # 6388 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ HostnameVerifierTest . java \n + assertThat ( verifier . verify ( "" : : ffff : 192 . 168 . 1 . 1 "" , session ) ) . isTrue ( ) ; \n + assertThat ( verifier . verify ( "" 0 : 0 : 0 : 0 : 0 : FFFF : C0A8 : 0101 "" , session ) ) . isTrue ( ) ; \n",More extreme canonical forms in Hostname Verifier ( # 5892 ),547
". circleci \ config . yml \n - runtests : \n - \n - image : circleci / openjdk : 13 . 0 . 2 - jdk - buster \n - runtests : \n + testjdk14 : \n + docker : \n + - image : circleci / openjdk : 14 - ea - 34 - jdk - buster \n + \n + environment : \n + JVM _ OPTS : - Xmx1g \n + TERM : dumb \n + \n + steps : \n + - checkout \n + \n + - runtests : \n + platform : jdk9 \n + \n - image : circleci / openjdk : 11 . 0 . 6 - jdk - stretch \n - gh - pages \n + - testjdk14 : \n + filters : \n + branches : \n + ignore : \n + - gh - pages \n gradle \ wrapper \ gradle - wrapper . jar \n Binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 3 - all . zip \n gradlew . bat \n + @ rem Resolve any "" . "" and "" . . "" in APP _ HOME to make it shorter . \n + for % % i in ( "" % APP _ HOME % "" ) do set APP _ HOME = % % ~ fi \n + \n okhttp \ src \ test \ java \ okhttp3 \ internal \ connection \ RouteSelectorTest . java \n + import okhttp3 . testing . PlatformRule ; \n + import okhttp3 . testing . PlatformVersion ; \n + @ Rule public final PlatformRule platform = new PlatformRule ( ) ; \n - assertThat ( route . toString ( ) ) . isEqualTo ( "" Route { host : 1234 } "" ) ; \n + assertThat ( route . toString ( ) ) . isEqualTo ( \n + PlatformVersion . INSTANCE . getMajorVersion ( ) > = 14 \n + ? "" Route { host / < unresolved > : 1234 } "" \n + : "" Route { host : 1234 } "" ) ; \n",JDK 14 and Gradle 6 . 3 ( # 5838 ),547
docs \ security . md \n - | 4 . x | ✅ | | \n + | 4 . x | ✅ | Android 5 . 0 + ( API level 21 + ) and on Java 8 + . | \n,Document 4 . x requirements ( # 5897 ),547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n + client . close ( ) \n + client . close ( ) \n + fun OkHttpClient . close ( ) { \n + dispatcher . executorService . shutdown ( ) \n + connectionPool . evictAll ( ) \n + } \n + \n okhttp - testing - support \ src \ main \ java \ okhttp3 \ OkHttpClientTestRule . kt \n - import org . assertj . core . api . Assertions . assertThat \n + import org . junit . Assert . assertEquals \n + import org . junit . Assert . fail \n - assertThat ( connectionPool . connectionCount ( ) ) . isEqualTo ( 0 ) \n + assertEquals ( 0 , connectionPool . connectionCount ( ) ) \n - assertThat ( queue . idleLatch ( ) . await ( 1 _ 000L , TimeUnit . MILLISECONDS ) ) \n - . withFailMessage ( "" Queue still active after 1000 ms "" ) \n - . isTrue ( ) \n + if ( ! queue . idleLatch ( ) . await ( 1 _ 000L , TimeUnit . MILLISECONDS ) ) { \n + TaskRunner . INSTANCE . cancelAll ( ) \n + fail ( "" Queue still active after 1000 ms "" ) \n + } \n okhttp \ src \ main \ java \ okhttp3 \ internal \ concurrent \ TaskRunner . kt \n - private fun cancelAll ( ) { \n + fun cancelAll ( ) { \n - readyQueues [ i ] . cancelAllAndDecide ( ) \n + busyQueues [ i ] . cancelAllAndDecide ( ) \n",Force cancel all events on client ( # 5901 ),547
android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - client . newCall ( request ) . execute ( ) \n + client . newCall ( request ) . execute ( ) . close ( ) \n,Close Android test properly in case it passes ( # 5905 ) \n * Close test properly in case it passes \n * Fix,547
"okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ BouncyCastlePlatform . kt \n - Class . forName ( "" org . bouncycastle . jsse . provider . BouncyCastleJsseProvider "" ) \n + Class . forName ( "" org . bouncycastle . jsse . provider . BouncyCastleJsseProvider "" , false , javaClass . classLoader ) \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ ConscryptPlatform . kt \n - Class . forName ( "" org . conscrypt . Conscrypt \ $ Version "" ) \n + Class . forName ( "" org . conscrypt . Conscrypt \ $ Version "" , false , javaClass . classLoader ) \n okhttp \ src \ main \ java \ okhttp3 \ internal \ platform \ OpenJSSEPlatform . kt \n - Class . forName ( "" org . openjsse . net . ssl . OpenJSSE "" ) \n + Class . forName ( "" org . openjsse . net . ssl . OpenJSSE "" , false , javaClass . classLoader ) \n",Defer class initialization to avoid spamming on Conscrypt errors ( not for landing ) ( # 5909 ),547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - if ( Build . VERSION . SDK _ INT > = 24 ) { \n - assertEquals ( "" org . conscrypt . Java8FileDescriptorSocket "" , socketClass ) \n - } else { \n - assertEquals ( "" org . conscrypt . ConscryptFileDescriptorSocket "" , socketClass ) \n + when { \n + Build . VERSION . SDK _ INT > = 24 - > { \n + assertEquals ( "" org . conscrypt . Java8FileDescriptorSocket "" , socketClass ) \n + } \n + Build . VERSION . SDK _ INT < 22 - > { \n + assertEquals ( "" org . conscrypt . KitKatPlatformOpenSSLSocketImplAdapter "" , socketClass ) \n + } \n + else - > { \n + assertEquals ( "" org . conscrypt . ConscryptFileDescriptorSocket "" , socketClass ) \n + } \n",Handle Android 5 . 0 socket type in tests,547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n + import com . google . android . gms . common . GooglePlayServicesNotAvailableException \n - import org . junit . After \n - import org . junit . Before \n - ProviderInstaller . installIfNeeded ( InstrumentationRegistry . getTargetContext ( ) ) \n + try { \n + ProviderInstaller . installIfNeeded ( InstrumentationRegistry . getTargetContext ( ) ) \n + } catch ( gpsnae : GooglePlayServicesNotAvailableException ) { \n + throw AssumptionViolatedException ( "" Google Play Services not available "" ) \n + } \n",Google Play assumption failures handled ( # 5692 ) \n * Google Play assumption failures handled \n * import fixes,547
"okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ publicsuffix \ PublicSuffixDatabase . kt \n - val domainLabels = unicodeDomain . split ( ' . ' ) \n + val domainLabels = splitDomain ( unicodeDomain ) \n + \n - return domain . split ( ' . ' ) . asSequence ( ) . drop ( firstLabelOffset ) . joinToString ( "" . "" ) \n + return splitDomain ( domain ) . asSequence ( ) . drop ( firstLabelOffset ) . joinToString ( "" . "" ) \n + } \n + \n + private fun splitDomain ( domain : String ) : List < String > { \n + val domainLabels = domain . split ( ' . ' ) \n + \n + if ( domainLabels . last ( ) = = "" "" ) { \n + / / allow for domain name trailing dot \n + return domainLabels . dropLast ( 1 ) \n + } \n + \n + return domainLabels \n okhttp \ src \ test \ java \ okhttp3 \ HttpUrlTest . java \n + \n + / / https : / / github . com / square / okhttp / issues / 6109 \n + assertThat ( parse ( "" http : / / a . / "" ) . topPrivateDomain ( ) ) . isNull ( ) ; \n + assertThat ( parse ( "" http : / / . / "" ) . topPrivateDomain ( ) ) . isNull ( ) ; \n + \n + assertThat ( parse ( "" http : / / squareup . com . / "" ) . topPrivateDomain ( ) ) . isEqualTo ( "" squareup . com "" ) ; \n + } \n + \n + @ Test \n + public void unparseableTopPrivateDomain ( ) { \n + assertInvalid ( "" http : / / a . . / "" , "" Invalid URL host : \ "" a . . \ "" "" ) ; \n + assertInvalid ( "" http : / / . . a / "" , "" Invalid URL host : \ "" . . a \ "" "" ) ; \n + assertInvalid ( "" http : / / a . . b / "" , "" Invalid URL host : \ "" a . . b \ "" "" ) ; \n + assertInvalid ( "" http : / / . a / "" , "" Invalid URL host : \ "" . a \ "" "" ) ; \n + assertInvalid ( "" http : / / . . / "" , "" Invalid URL host : \ "" . . \ "" "" ) ; \n",Allow for domain name trailing dot in PublicSuffixDatabase ( # 6111 ),547
okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ Util . kt \n - if ( suppressed . size > 1 ) { \n - println ( suppressed ) \n - } \n - \n,Remove println from code ( # 6305 ),547
mockwebserver \ src \ test \ java \ okhttp3 \ mockwebserver \ MockWebServerTest . java \n - import java . nio . charset . StandardCharsets ; \n + @ Test \n + public void shutdownTwice ( ) throws IOException { \n + MockWebServer server2 = new MockWebServer ( ) ; \n + \n + server2 . start ( ) ; \n + server2 . shutdown ( ) ; \n + try { \n + server2 . start ( ) ; \n + fail ( ) ; \n + } catch ( IllegalArgumentException iae ) { \n + / / expected \n + } \n + server2 . shutdown ( ) ; \n + } \n + \n,Confirm MockWebServer shutdown is idempotent ( # 5946 ),547
"okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ platform \ AndroidPlatform . kt \n + import android . security . NetworkSecurityPolicy \n - override fun isCleartextTrafficPermitted ( hostname : String ) : Boolean { \n - return try { \n - val networkPolicyClass = Class . forName ( "" android . security . NetworkSecurityPolicy "" ) \n - val getInstanceMethod = networkPolicyClass . getMethod ( "" getInstance "" ) \n - val networkSecurityPolicy = getInstanceMethod . invoke ( null ) \n - api24IsCleartextTrafficPermitted ( hostname , networkPolicyClass , networkSecurityPolicy ) \n - } catch ( _ : ClassNotFoundException ) { \n - super . isCleartextTrafficPermitted ( hostname ) \n - } catch ( _ : NoSuchMethodException ) { \n - super . isCleartextTrafficPermitted ( hostname ) \n - } catch ( e : IllegalAccessException ) { \n - throw AssertionError ( "" unable to determine cleartext support "" , e ) \n - } catch ( e : IllegalArgumentException ) { \n - throw AssertionError ( "" unable to determine cleartext support "" , e ) \n - } catch ( e : InvocationTargetException ) { \n - throw AssertionError ( "" unable to determine cleartext support "" , e ) \n - } \n - } \n - \n - @ Throws ( InvocationTargetException : : class , IllegalAccessException : : class ) \n - private fun api24IsCleartextTrafficPermitted ( \n - hostname : String , \n - networkPolicyClass : Class < * > , \n - networkSecurityPolicy : Any \n - ) : Boolean = try { \n - val isCleartextTrafficPermittedMethod = networkPolicyClass \n - . getMethod ( "" isCleartextTrafficPermitted "" , String : : class . java ) \n - isCleartextTrafficPermittedMethod . invoke ( networkSecurityPolicy , hostname ) as Boolean \n - } catch ( _ : NoSuchMethodException ) { \n - api23IsCleartextTrafficPermitted ( hostname , networkPolicyClass , networkSecurityPolicy ) \n - } \n - \n - @ Throws ( InvocationTargetException : : class , IllegalAccessException : : class ) \n - private fun api23IsCleartextTrafficPermitted ( \n - hostname : String , \n - networkPolicyClass : Class < * > , \n - networkSecurityPolicy : Any \n - ) : Boolean = try { \n - val isCleartextTrafficPermittedMethod = networkPolicyClass \n - . getMethod ( "" isCleartextTrafficPermitted "" ) \n - isCleartextTrafficPermittedMethod . invoke ( networkSecurityPolicy ) as Boolean \n - } catch ( _ : NoSuchMethodException ) { \n - super . isCleartextTrafficPermitted ( hostname ) \n + override fun isCleartextTrafficPermitted ( hostname : String ) : Boolean = when { \n + Build . VERSION . SDK _ INT > = 24 - > NetworkSecurityPolicy . getInstance ( ) . isCleartextTrafficPermitted ( hostname ) \n + Build . VERSION . SDK _ INT > = 23 - > NetworkSecurityPolicy . getInstance ( ) . isCleartextTrafficPermitted \n + else - > true \n",Use Android API for NetworkSecurityPolicy ( # 5959 ) \n * Use Android API \n * Cleanup,547
"mockwebserver \ src \ main \ java \ okhttp3 \ mockwebserver \ MockWebServer . kt \n - logger . info ( "" $ this starting to accept connections "" ) \n + logger . fine ( "" $ this starting to accept connections "" ) \n - logger . info ( "" $ { this @ MockWebServer } done accepting connections : $ { e . message } "" ) \n + logger . fine ( "" $ { this @ MockWebServer } done accepting connections : $ { e . message } "" ) \n - logger . info ( "" $ this connection from $ { raw . inetAddress } failed : $ e "" ) \n + logger . fine ( "" $ this connection from $ { raw . inetAddress } failed : $ e "" ) \n - if ( logger . isLoggable ( Level . INFO ) ) { \n - logger . info ( \n + if ( logger . isLoggable ( Level . FINE ) ) { \n + logger . fine ( \n - if ( logger . isLoggable ( Level . INFO ) ) { \n - logger . info ( \n + if ( logger . isLoggable ( Level . FINE ) ) { \n + logger . fine ( \n",Reduce logging in MockWebServer ( # 5696 ),547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - throw AssumptionViolatedException ( "" Google Play Services not available "" ) \n + assumeNoException ( "" Google Play Services not available "" , gpsnae ) \n",Fix missing import in Android Test ( # 5697 ),547
"okhttp - testing - support \ src \ main \ kotlin \ okhttp3 \ ClientRuleEventListener . kt \n - private var startNs : Long = 0 \n + private var startNs : Long ? = null \n - val timeMs = TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - startNs ) \n + val startNs = startNs \n + val timeMs = if ( startNs = = null ) { \n + / / Event occurred before start , for an example an early cancel . \n + 0L \n + } else { \n + TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - startNs ) \n + } \n + \n okhttp - testing - support \ src \ main \ kotlin \ okhttp3 \ OkHttpClientTestRule . kt \n + lateinit var testName : String \n + \n + if ( connectionPool . connectionCount ( ) > 0 ) { \n + / / Minimise test flakiness due to possible race conditions with connections closing . \n + / / Some number of tests will report here , but not fail due to this delay . \n + println ( "" Delaying to avoid flakes "" ) \n + Thread . sleep ( 500L ) \n + println ( "" After delay : "" + connectionPool . connectionCount ( ) ) \n + } \n + \n + testName = description . methodName \n + \n - println ( "" Events ( $ { clientEventsList . size } ) "" ) \n + println ( "" $ testName Events ( $ { clientEventsList . size } ) "" ) \n okhttp \ src \ test \ java \ okhttp3 \ EventListenerTest . java \n - import static org . junit . Assert . assertNotNull ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ ws \ WebSocketHttpTest . java \n - @ After public void tearDown ( ) { \n + @ After public void tearDown ( ) throws InterruptedException { \n",Attempt to minimise WebSocket test flakiness ( # 6045 ),547
android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - . addInsecureHost ( server . hostName ) \n + . apply { \n + if ( Build . VERSION . SDK _ INT > = 24 ) { \n + addInsecureHost ( server . hostName ) \n + } \n + } \n - localhostInsecureRequest ( ) ; \n + if ( Build . VERSION . SDK _ INT > = 24 ) { \n + localhostInsecureRequest ( ) ; \n + } \n - . addPlatformTrustedCertificates ( ) \n - . addInsecureHost ( server . hostName ) \n + . addPlatformTrustedCertificates ( ) . apply { \n + if ( Build . VERSION . SDK _ INT > = 24 ) { \n + addInsecureHost ( server . hostName ) \n + } \n + } \n - localhostInsecureRequest ( ) ; \n + if ( Build . VERSION . SDK _ INT > = 24 ) { \n + localhostInsecureRequest ( ) ; \n + } \n,Make the Android tests pass on < = 23,547
"okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ platform \ android \ AndroidLog . kt \n - private fun loggerTag ( loggerName : String ) = knownLoggers [ loggerName ] ? : loggerName \n + private fun loggerTag ( loggerName : String ) : String { \n + / / We need to handle long logger names before they hit Log . \n + / / java . lang . IllegalArgumentException : Log tag "" okhttp3 . mockwebserver . MockWebServer "" exceeds limit of 23 characters \n + return knownLoggers [ loggerName ] ? : loggerName . take ( 23 ) \n + } \n",Handle tests that try to log via MockWebServer ( # 6072 ) \n * Handle tests that try to log via MockWebServer \n * Comments,547
"okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ http2 \ Http2 . kt \n - val formattedType = if ( type < FRAME _ NAMES . size ) FRAME _ NAMES [ type ] else format ( "" 0x % 02x "" , type ) \n + val formattedType = formattedType ( type ) \n + internal fun formattedType ( type : Int ) = \n + if ( type < FRAME _ NAMES . size ) FRAME _ NAMES [ type ] else format ( "" 0x % 02x "" , type ) \n + \n okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ http2 \ Http2Reader . kt \n + import okhttp3 . internal . http2 . Http2 . formattedType \n - if ( requireSettings & & type ! = TYPE _ SETTINGS ) { \n - throw IOException ( "" Expected a SETTINGS frame but was $ type "" ) \n - } \n + if ( requireSettings & & type ! = TYPE _ SETTINGS ) { \n + throw IOException ( "" Expected a SETTINGS frame but was $ { formattedType ( type ) } "" ) \n + } \n + \n okhttp \ src \ test \ java \ okhttp3 \ internal \ http2 \ Http2ConnectionTest . java \n - assertThat ( expected . getMessage ( ) ) . isEqualTo ( "" Expected a SETTINGS frame but was 1 "" ) ; \n + assertThat ( expected . getMessage ( ) ) . isEqualTo ( "" Expected a SETTINGS frame but was HEADERS "" ) ; \n",Make unexpected frame message clearer ( # 6090 ) \n Logs the failing frame during HTTP / 2 setup and provides a clearer exception message .,547
"okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ platform \ android \ AndroidLog . kt \n - this [ OkHttpClient : : class . java . ` package ` . name ] = "" OkHttp "" \n - this [ OkHttpClient : : class . java . name ] = "" okhttp . OkHttpClient "" \n - this [ Http2 : : class . java . name ] = "" okhttp . Http2 "" \n - this [ TaskRunner : : class . java . name ] = "" okhttp . TaskRunner "" \n - } . toMap ( ) \n + val packageName = OkHttpClient : : class . java . ` package ` ? . name \n + \n + if ( packageName ! = null ) { \n + this [ packageName ] = "" OkHttp "" \n + } \n + \n + this [ OkHttpClient : : class . java . name ] = "" okhttp . OkHttpClient "" \n + this [ Http2 : : class . java . name ] = "" okhttp . Http2 "" \n + this [ TaskRunner : : class . java . name ] = "" okhttp . TaskRunner "" \n + } . toMap ( ) \n",Fix null package name in AndroidLog after proguard ( # 6094 ),547
"docs \ debug _ logging . md \n - On Android , use [ OkHttpDebugLogcat . kt ] instead . It connects OkHttp logs to Logcat in Android Studio . \n + # # # Activating on Android \n + \n + ` ` ` \n + $ adb shell setprop log . tag . okhttp . Http2 DEBUG \n + $ adb shell setprop log . tag . okhttp . TaskRunner DEBUG \n + $ adb logcat ' * : E ' ' okhttp . Http2 : D ' ' okhttp . TaskRunner : D ' \n + ` ` ` \n - [ OkHttpDebugLogging . kt ] : https : / / github . com / square / okhttp / blob / master / okhttp - testing - support / src / main / java / okhttp3 / OkHttpDebugLogging . kt \n - [ OkHttpDebugLogcat . kt ] : https : / / github . com / square / okhttp / blob / master / android - test / src / androidTest / java / okhttp / android / test / OkHttpDebugLogcat . kt \n + [ OkHttpDebugLogging . kt ] : https : / / github . com / square / okhttp / blob / master / okhttp - testing - support / src / main / kotlin / okhttp3 / OkHttpDebugLogging . kt \n",Simplify Android debug logging docs ( # 6097 ),547
"okhttp - tls \ src \ main \ kotlin \ okhttp3 \ tls \ Certificates . kt \n - import java . security . cert . CertificateParsingException \n - throw CertificateParsingException ( nsee ) \n + throw IllegalArgumentException ( "" failed to decode certificate "" , nsee ) \n - throw CertificateParsingException ( iae ) \n + throw IllegalArgumentException ( "" failed to decode certificate "" , iae ) \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ HeldCertificateTest . java \n - @ Test public void decodeRsa512 ( ) throws Exception { \n + @ Test public void decodeRsa512 ( ) { \n + "" - - - - - END PRIVATE KEY - - - - - \ n "" ) ; \n - assertThat ( expected ) . hasMessage ( "" failed to decode certificate "" ) ; \n + if ( ! platform . isConscrypt ( ) ) { \n + assertThat ( expected ) . hasMessage ( "" failed to decode certificate "" ) ; \n + } \n + "" - - - - - END PRIVATE KEY - - - - - \ n "" ) ; \n - assertThat ( expected ) . hasMessage ( "" failed to decode private key "" ) ; \n + if ( ! platform . isConscrypt ( ) ) { \n + assertThat ( expected ) . hasMessage ( "" failed to decode private key "" ) ; \n + } \n",Fix for conscrypt error parsing certificates ( # 6098 ) \n Fails with a runtime exception on bad input .,547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n - / / avoid cleaning bug for now \n - . eventListener ( EventListener . NONE ) \n - / / avoid cleaning bug for now \n - . eventListener ( EventListener . NONE ) \n okhttp \ src \ main \ java \ okhttp3 \ Handshake . kt \n + val peerCertificatesString = try { \n + peerCertificates . map { it . name } . toString ( ) \n + } catch ( _ : SSLPeerUnverifiedException ) { \n + "" Failed : SSLPeerUnverifiedException "" \n + } \n - "" peerCertificates = $ { peerCertificates . map { it . name } } "" + \n + "" peerCertificates = $ peerCertificatesString "" + \n","Allow toString ( ) for debugging , even when cert cleaner will fail",547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ ClientAuthTest . java \n + import java . io . IOException ; \n + import java . util . List ; \n + import okhttp3 . CallEvent ; \n + import okhttp3 . RecordingEventListener ; \n + import static org . junit . Assert . assertEquals ; \n + @ Test public void invalidClientAuthEvents ( ) throws Throwable { \n + server . enqueue ( new MockResponse ( ) . setBody ( "" abc "" ) ) ; \n + \n + clientCert = new HeldCertificate . Builder ( ) \n + . signedBy ( clientIntermediateCa ) \n + . serialNumber ( 4L ) \n + . commonName ( "" Jethro Willis "" ) \n + . addSubjectAlternativeName ( "" jethrowillis . com "" ) \n + . validityInterval ( 1 , 2 ) \n + . build ( ) ; \n + \n + OkHttpClient client = buildClient ( clientCert , clientIntermediateCa . certificate ( ) ) ; \n + \n + RecordingEventListener listener = new RecordingEventListener ( ) ; \n + \n + client = client . newBuilder ( ) \n + . eventListener ( listener ) \n + . build ( ) ; \n + \n + SSLSocketFactory socketFactory = buildServerSslSocketFactory ( ) ; \n + \n + server . useHttps ( socketFactory , false ) ; \n + server . requireClientAuth ( ) ; \n + \n + Call call = client . newCall ( new Request . Builder ( ) . url ( server . url ( "" / "" ) ) . build ( ) ) ; \n + \n + try { \n + call . execute ( ) ; \n + fail ( ) ; \n + } catch ( IOException expected ) { \n + } \n + \n + / / Observed Events are variable \n + / / JDK 14 \n + / / CallStart , ProxySelectStart , ProxySelectEnd , DnsStart , DnsEnd , ConnectStart , SecureConnectStart , \n + / / SecureConnectEnd , ConnectEnd , ConnectionAcquired , RequestHeadersStart , RequestHeadersEnd , \n + / / ResponseFailed , ConnectionReleased , CallFailed \n + / / JDK 8 \n + / / CallStart , ProxySelectStart , ProxySelectEnd , DnsStart , DnsEnd , ConnectStart , SecureConnectStart , \n + / / ConnectFailed , CallFailed \n + / / Gradle - JDK 11 \n + / / CallStart , ProxySelectStart , ProxySelectEnd , DnsStart , DnsEnd , ConnectStart , SecureConnectStart , \n + / / SecureConnectEnd , ConnectFailed , CallFailed \n + \n + List < String > recordedEventTypes = listener . recordedEventTypes ( ) ; \n + assertThat ( recordedEventTypes ) . startsWith ( \n + "" CallStart "" , "" ProxySelectStart "" , "" ProxySelectEnd "" , "" DnsStart "" , "" DnsEnd "" , "" ConnectStart "" , "" SecureConnectStart "" ) ; \n + assertThat ( recordedEventTypes ) . endsWith ( "" CallFailed "" ) ; \n + } \n + \n",Test client auth failure events ( # 6117 ),547
"build . gradle \n - ' moshi ' : ' 1 . 10 . 0 ' , \n - ' okio ' : ' 2 . 8 . 0 ' , \n + ' moshi ' : ' 1 . 11 . 0 ' , \n + ' okio ' : ' 2 . 9 . 0 ' , \n",Okio and Moshi dependency upgrades ( # 6307 ),547
"native - image - tests \ src \ main \ kotlin \ okhttp3 \ SampleTest . kt \n + import okhttp3 . internal . publicsuffix . PublicSuffixDatabase \n + \n + @ Test \n + fun testPublicSuffixes ( ) { \n + PublicSuffixDatabase : : class . java . getResourceAsStream ( PublicSuffixDatabase . PUBLIC _ SUFFIX _ RESOURCE ) . use { \n + assertThat ( it . available ( ) ) . isGreaterThan ( 30000 ) \n + } \n + } \n okhttp \ src \ main \ resources \ META - INF \ native - image \ okhttp \ okhttp \ resource - config . json \n - { "" pattern "" : "" publicsuffixes . gz "" } \n + { "" pattern "" : "" okhttp3 / internal / publicsuffix / publicsuffixes . gz "" } \n",Fix publicsuffixes in native image ( # 6395 ),547
". circleci \ config . yml \n - - image : circleci / openjdk : 11 . 0 . 7 - jdk - buster \n + # Held back to ensure a JDK 8 is in the image , which is true for stretch but not buster \n + - image : circleci / openjdk : 11 . 0 . 6 - jdk - stretch \n",Fix openjsse CI ( # 6127 ) \n Revert to docket image with Java 8 available .,547
"okhttp - logging - interceptor \ src \ main \ kotlin \ okhttp3 \ logging \ LoggingEventListener . kt \n + override fun satisfactionFailure ( call : Call , response : Response ) { \n + logWithTime ( "" satisfactionFailure : $ response "" ) \n + } \n + \n + override fun cacheHit ( call : Call , response : Response ) { \n + logWithTime ( "" cacheHit : $ response "" ) \n + } \n + \n + override fun cacheMiss ( call : Call ) { \n + logWithTime ( "" cacheMiss "" ) \n + } \n + \n + override fun cacheConditionalHit ( call : Call , cachedResponse : Response ) { \n + logWithTime ( "" cacheConditionalHit : $ cachedResponse "" ) \n + } \n + \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ LoggingEventListenerTest . java \n + import okhttp3 . Call ; \n + import okhttp3 . EventListener ; \n + import okhttp3 . Protocol ; \n + @ Test \n + public void testCacheEvents ( ) { \n + Request request = new Request . Builder ( ) . url ( url ) . build ( ) ; \n + Call call = client . newCall ( request ) ; \n + Response response = new Response . Builder ( ) . request ( request ) . code ( 200 ) . message ( "" "" ) . protocol ( HTTP _ 2 ) . build ( ) ; \n + \n + EventListener listener = loggingEventListenerFactory . create ( call ) ; \n + \n + listener . cacheConditionalHit ( call , response ) ; \n + listener . cacheHit ( call , response ) ; \n + listener . cacheMiss ( call ) ; \n + listener . satisfactionFailure ( call , response ) ; \n + \n + logRecorder \n + . assertLogMatch ( "" cacheConditionalHit : Response \ \ { protocol = h2 , code = 200 , message = , url = "" + url + "" } "" ) \n + . assertLogMatch ( "" cacheHit : Response \ \ { protocol = h2 , code = 200 , message = , url = "" + url + "" } "" ) \n + . assertLogMatch ( "" cacheMiss "" ) \n + . assertLogMatch ( "" satisfactionFailure : Response \ \ { protocol = h2 , code = 200 , message = , url = "" + url + "" } "" ) \n + . assertNoMoreLogs ( ) ; \n + } \n + \n",Add Cache events to LoggingEventListener ( # 6020 ),547
gradle \ wrapper \ gradle - wrapper . jar \n Binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 3 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 4 - all . zip \n gradlew \n + \n + \n gradlew . bat \n + \n,Gradle 6 . 4 Upgrade ( # 6023 ),547
"native - image - tests \ build . gradle \n - if ( ! properties . containsKey ( ' android . injected . invoked . from . ide ' ) ) { \n + def isIDE = properties . containsKey ( ' android . injected . invoked . from . ide ' ) | | \n + ( System . getenv ( "" XPC _ SERVICE _ NAME "" ) ? : "" "" ) . contains ( "" intellij "" ) \n + if ( ! isIDE ) { \n",Avoid duplicate source roots in Intellij ( # 6397 ) \n * Avoid duplicate source roots in Intellij \n * Avoid duplicate source roots in Intellij,547
"okhttp - tls \ src \ main \ kotlin \ okhttp3 \ tls \ internal \ der \ certificates . kt \n - val subjectAlternativeNames : Extension \n + val subjectAlternativeNames : Extension ? \n - return tbsCertificate . extensions . first { \n + return tbsCertificate . extensions . firstOrNull { \n okhttp - tls \ src \ test \ java \ okhttp3 \ tls \ internal \ der \ DerCertificatesTest . kt \n + @ Test \n + fun ` missing subject alternative names ` ( ) { \n + val certificate = HeldCertificate . Builder ( ) \n + . certificateAuthority ( 3 ) \n + . commonName ( "" Jurassic Park "" ) \n + . organizationalUnit ( "" Gene Research "" ) \n + . validityInterval ( - 1000L , 2000L ) \n + . serialNumber ( 17L ) \n + . build ( ) \n + \n + val certificateByteString = certificate . certificate . encoded . toByteString ( ) \n + \n + val okHttpCertificate = CertificateAdapters . certificate \n + . fromDer ( certificateByteString ) \n + \n + assertThat ( okHttpCertificate . commonName ) . isEqualTo ( "" Jurassic Park "" ) \n + assertThat ( okHttpCertificate . subjectAlternativeNames ) . isNull ( ) \n + } \n + \n",Allow missing SAN in certificates ( # 6186 ),547
okhttp - logging - interceptor \ src \ main \ kotlin \ okhttp3 \ logging \ HttpLoggingInterceptor . kt \n - val DEFAULT : Logger = object : Logger { \n + val DEFAULT : Logger = DefaultLogger ( ) \n + private class DefaultLogger : Logger { \n - level = DeprecationLevel . ERROR ) \n + level = DeprecationLevel . ERROR \n + ) \n okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ io \ FileSystem . kt \n - val SYSTEM : FileSystem = object : FileSystem { \n + val SYSTEM : FileSystem = SystemFileSystem ( ) \n + private class SystemFileSystem : FileSystem { \n,Avoid DefaultImpls bug ( # 6198 ) \n * Avoid DefaultImpls bug \n * private classes,547
. circleci \ config . yml \n - testjdk12windows : \n - ignore : \n - - gh - pages \n + only : master \n - testjdk13 : \n,Don ' t run Windows builds in CircleCI on PRs,547
"android - test \ build . gradle \n - androidTestImplementation "" org . conscrypt : conscrypt - android : 2 . 2 . 1 "" \n + androidTestImplementation "" org . conscrypt : conscrypt - android : 2 . 4 . 0 "" \n build . gradle \n - ' kotlin ' : ' 1 . 3 . 70 ' , \n + ' kotlin ' : ' 1 . 3 . 71 ' , \n - classpath "" org . jetbrains . dokka : dokka - gradle - plugin : 0 . 10 . 0 "" \n - classpath ' com . diffplug . spotless : spotless - plugin - gradle : 3 . 27 . 0 ' \n + classpath "" org . jetbrains . dokka : dokka - gradle - plugin : 0 . 10 . 1 "" \n + classpath ' com . diffplug . spotless : spotless - plugin - gradle : 3 . 27 . 1 ' \n + / / noinspection GradleDynamicVersion \n",Kotlin 1 . 3 . 71 and misc dep upgrades ( # 5925 ),547
okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ HostnameVerifierTest . java \n + import java . util . Collection ; \n + import java . util . List ; \n - return peerCertificate . getSubjectAlternativeNames ( ) . stream ( ) . map ( c - > ( String ) c . get ( 1 ) ) ; \n + Collection < List < ? > > subjectAlternativeNames = peerCertificate . getSubjectAlternativeNames ( ) ; \n + \n + if ( subjectAlternativeNames = = null ) { \n + return Stream . empty ( ) ; \n + } else { \n + return subjectAlternativeNames . stream ( ) . map ( c - > ( String ) c . get ( 1 ) ) ; \n + } \n,Avoid NPE in conscrypt ( # 6399 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ HostnameVerifierTest . java \n + import okhttp3 . testing . PlatformRule ; \n + import org . junit . jupiter . api . extension . RegisterExtension ; \n + @ RegisterExtension public PlatformRule platform = new PlatformRule ( ) ; \n + "" - - - - - END CERTIFICATE - - - - - \ n "" ) ; \n - assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" bar . com "" , "" ������ . co . jp "" ) ; \n + if ( platform . isConscrypt ( ) ) { \n + assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" bar . com "" ) ; \n + } else { \n + assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" bar . com "" , "" ������ . co . jp "" ) ; \n + } \n + "" - - - - - END CERTIFICATE - - - - - \ n "" ) ; \n - assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" * . bar . com "" , "" * . ������ . co . jp "" ) ; \n + if ( platform . isConscrypt ( ) ) { \n + assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" * . bar . com "" ) ; \n + } else { \n + assertThat ( certificateSANs ( peerCertificate ) ) . containsExactly ( "" * . bar . com "" , "" * . ������ . co . jp "" ) ; \n + } \n",Test fix for cert names ( # 6398 ),547
"native - image - tests \ build . gradle \n - ( System . getenv ( "" XPC _ SERVICE _ NAME "" ) ? : "" "" ) . contains ( "" intellij "" ) \n + ( System . getenv ( "" XPC _ SERVICE _ NAME "" ) ? : "" "" ) . contains ( "" intellij "" ) | | \n + System . getenv ( "" IDEA _ INITIAL _ DIRECTORY "" ) ! = null \n",Fix windows IDE detection ( # 6402 ),547
"native - image - tests \ build . gradle \n + option "" - H : + AddAllCharsets "" \n new file \n okhttp \ src \ main \ resources \ META - INF \ native - image \ okhttp \ okhttp \ reflect - config . json \n + [ \n + { \n + "" name "" : "" kotlin . internal . jdk8 . JDK8PlatformImplementations "" , \n + "" allDeclaredConstructors "" : true \n + } , \n + { \n + "" name "" : "" kotlin . KotlinVersion "" , \n + "" allPublicMethods "" : true , \n + "" allDeclaredFields "" : true , \n + "" allDeclaredMethods "" : true , \n + "" allDeclaredConstructors "" : true \n + } , \n + { \n + "" name "" : "" kotlin . KotlinVersion [ ] "" \n + } , \n + { \n + "" name "" : "" kotlin . KotlinVersion $ Companion "" \n + } , \n + { \n + "" name "" : "" kotlin . KotlinVersion $ Companion [ ] "" \n + } \n + ] \n",Workaround native image charset and kotlin issue ( # 6404 ),547
"android - test \ build . gradle \n - androidTestImplementation "" org . conscrypt : conscrypt - android : 2 . 4 . 0 "" \n + androidTestImplementation "" org . conscrypt : conscrypt - android : 2 . 5 . 0 "" \n build . gradle \n - ' conscrypt ' : ' 2 . 4 . 0 ' , \n + ' conscrypt ' : ' 2 . 5 . 0 ' , \n okhttp \ src \ main \ kotlin \ okhttp3 \ internal \ platform \ ConscryptPlatform . kt \n + import java . security . cert . X509Certificate \n + import javax . net . ssl . SSLSession \n + import org . conscrypt . ConscryptHostnameVerifier \n - / / n . b . We should consider defaulting to OpenJDK 11 trust manager \n - / / https : / / groups . google . com / forum / # ! topic / conscrypt / 3vYzbesjOb4 \n - private val provider : Provider = Conscrypt . newProviderBuilder ( ) . provideTrustManager ( true ) . build ( ) \n + private val provider : Provider = Conscrypt . newProvider ( ) \n - Conscrypt . setHostnameVerifier ( x509TrustManager ) { _ , _ - > true } \n + / / Disabled because OkHttp will run anyway \n + Conscrypt . setHostnameVerifier ( x509TrustManager , DisabledHostnameVerifier ) \n + internal object DisabledHostnameVerifier : ConscryptHostnameVerifier { \n + fun verify ( \n + hostname : String ? , \n + session : SSLSession ? \n + ) : Boolean { \n + return true \n + } \n + \n + override fun verify ( \n + certs : Array < out X509Certificate > ? , \n + hostname : String ? , \n + session : SSLSession ? \n + ) : Boolean { \n + return true \n + } \n + } \n + \n - } . socketFactory . also { \n - Conscrypt . setUseEngineSocket ( it , true ) \n - } \n + } . socketFactory \n + / / Bump this version if we ever have a binary incompatibility \n",Conscrypt 2 . 5 . 0 upgrade ( # 6228 ) \n Conscrypt 2 . 5 . 0 upgrade with a workaround for changed Conscrypt API,547
okhttp \ src \ main \ kotlin \ okhttp3 \ Authenticator . kt \n + * # # Authentication Retries \n + * \n + * If your authentication may be flaky and requires retries you should apply some policy \n + * to limit the retries by the class of errors and number of attempts . To get the number of \n + * attempts to the current point use this function . \n + * \n + * ` ` ` \n + * private int responseCount ( Response response ) { \n + * int result = 1 ; \n + * while ( ( response = response . priorResponse ( ) ) ! = null ) { \n + * result + + ; \n + * } \n + * return result ; \n + * } \n + * ` ` ` \n + * \n,Document auth retries function ( # 6031 ) \n * Document auth retries function \n * Update Authenticator . kt,547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ http \ CancelTest . kt \n - val expectedEvents = mutableListOf < String > ( ) . apply { \n - addAll ( listOf ( "" CallStart "" , "" ConnectStart "" , "" ConnectEnd "" , "" ConnectionAcquired "" ) ) \n - if ( cancelMode = = CANCEL ) { \n - add ( "" Canceled "" ) \n - } \n - addAll ( listOf ( "" ResponseFailed "" , "" ConnectionReleased "" ) ) \n - } \n - \n - assertThat ( events ) . isEqualTo ( expectedEvents ) \n + \n + assertThat ( events ) . startsWith ( "" CallStart "" , "" ConnectStart "" , "" ConnectEnd "" , "" ConnectionAcquired "" ) \n + if ( cancelMode = = CANCEL ) { \n + / / Flaky https : / / github . com / square / okhttp / issues / 6033 \n + / / assertThat ( events ) . contains ( "" Canceled "" ) \n + } else { \n + assertThat ( events ) . doesNotContain ( "" Canceled "" ) \n + } \n + assertThat ( events ) . contains ( "" ResponseFailed "" ) \n + assertThat ( events ) . endsWith ( "" ConnectionReleased "" ) \n",Fix flaky CancelTest ( # 6035 ) \n * Fix flaky CancelTest \n * Test for flaky cancel event,547
build . gradle \n + tasks . withType ( JavaCompile ) { \n + options . encoding = ' UTF - 8 ' \n + } \n + \n,"Fix build on windows ( # 6257 ) \n Issue relates to default encoding picked up for daemons affecting compile , previous approach was launch property which doesn ' t affect Gradle daemons .",547
okhttp - logging - interceptor \ src \ main \ kotlin \ okhttp3 \ logging \ HttpLoggingInterceptor . kt \n + import okhttp3 . logging . internal . isProbablyUtf8 \n rename from okhttp - logging - interceptor \ src \ main \ kotlin \ okhttp3 \ logging \ utf8 . kt \n rename to okhttp - logging - interceptor \ src \ main \ kotlin \ okhttp3 \ logging \ internal \ utf8 . kt \n - package okhttp3 . logging \n + package okhttp3 . logging . internal \n - internal fun Buffer . isProbablyUtf8 ( ) : Boolean { \n + fun Buffer . isProbablyUtf8 ( ) : Boolean { \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ IsProbablyUtf8Test . kt \n + import okhttp3 . logging . internal . isProbablyUtf8 \n,Move isProbablyUtf8 from kotlin internal to package named internal . ( # 6350 ),547
"okhttp \ src \ test \ java \ okhttp3 \ HttpUrlTest . java \n + @ Test \n + public void quirks ( ) throws Exception { \n + assertThat ( parse ( "" http : / / facebook . com "" ) . host ( ) ) . isEqualTo ( "" facebook . com "" ) ; \n + assertThat ( parse ( "" http : / / facebooK . com "" ) . host ( ) ) . isEqualTo ( "" facebook . com "" ) ; \n + assertThat ( parse ( "" http : / / Facebook . com "" ) . host ( ) ) . isEqualTo ( "" facebook . com "" ) ; \n + assertThat ( parse ( "" http : / / FacebooK . com "" ) . host ( ) ) . isEqualTo ( "" facebook . com "" ) ; \n + } \n + \n",Test quirks of HttpUrl ( # 6352 ),547
okhttp - logging - interceptor \ build . gradle \n - testImplementation project ( ' : mockwebserver - deprecated ' ) \n + testImplementation project ( ' : mockwebserver ' ) \n + testImplementation project ( ' : mockwebserver - junit5 ' ) \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ HttpLoggingInterceptorTest . java \n - import okhttp3 . mockwebserver . MockResponse ; \n - import okhttp3 . mockwebserver . MockWebServer ; \n + import mockwebserver3 . MockResponse ; \n + import mockwebserver3 . MockWebServer ; \n - import org . junit . Before ; \n - import org . junit . Rule ; \n - import org . junit . Test ; \n + import org . junit . jupiter . api . BeforeEach ; \n + import org . junit . jupiter . api . Test ; \n + import org . junit . jupiter . api . extension . RegisterExtension ; \n - @ Rule public final PlatformRule platform = new PlatformRule ( ) ; \n - @ Rule public final MockWebServer server = new MockWebServer ( ) ; \n + @ RegisterExtension public final PlatformRule platform = new PlatformRule ( ) ; \n + private MockWebServer server ; \n - @ Before public void setUp ( ) { \n + @ BeforeEach public void setUp ( MockWebServer server ) { \n + this . server = server ; \n + \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ IsProbablyUtf8Test . kt \n - import org . junit . Test \n + import org . junit . jupiter . api . Test \n okhttp - logging - interceptor \ src \ test \ java \ okhttp3 \ logging \ LoggingEventListenerTest . java \n - import okhttp3 . Protocol ; \n - import okhttp3 . mockwebserver . MockResponse ; \n - import okhttp3 . mockwebserver . MockWebServer ; \n - import okhttp3 . mockwebserver . SocketPolicy ; \n + import mockwebserver3 . MockResponse ; \n + import mockwebserver3 . MockWebServer ; \n + import mockwebserver3 . SocketPolicy ; \n - import org . junit . Before ; \n - import org . junit . Rule ; \n - import org . junit . Test ; \n + import org . junit . jupiter . api . BeforeEach ; \n + import org . junit . jupiter . api . Test ; \n + import org . junit . jupiter . api . extension . RegisterExtension ; \n - @ Rule public final PlatformRule platform = new PlatformRule ( ) ; \n - @ Rule public final MockWebServer server = new MockWebServer ( ) ; \n + @ RegisterExtension public final PlatformRule platform = new PlatformRule ( ) ; \n + private MockWebServer server ; \n - @ Before \n - public void setUp ( ) { \n + @ BeforeEach \n + public void setUp ( MockWebServer server ) { \n + this . server = server ; \n,Migrate Logging tests to Junit5 ( # 6355 ),547
okhttp - sse \ build . gradle \n - testImplementation project ( ' : mockwebserver - deprecated ' ) \n + testImplementation project ( ' : mockwebserver ' ) \n + testImplementation project ( ' : mockwebserver - junit5 ' ) \n okhttp - sse \ src \ test \ java \ okhttp3 \ sse \ internal \ EventSourceHttpTest . java \n - import okhttp3 . mockwebserver . MockResponse ; \n - import okhttp3 . mockwebserver . MockWebServer ; \n + import mockwebserver3 . MockResponse ; \n + import mockwebserver3 . MockWebServer ; \n - import org . junit . After ; \n - import org . junit . Rule ; \n - import org . junit . Test ; \n + import org . junit . jupiter . api . AfterEach ; \n + import org . junit . jupiter . api . BeforeEach ; \n + import org . junit . jupiter . api . Test ; \n + import org . junit . jupiter . api . extension . RegisterExtension ; \n - @ Rule public final PlatformRule platform = new PlatformRule ( ) ; \n + @ RegisterExtension public final PlatformRule platform = new PlatformRule ( ) ; \n - @ Rule public final MockWebServer server = new MockWebServer ( ) ; \n - @ Rule public final OkHttpClientTestRule clientTestRule = new OkHttpClientTestRule ( ) ; \n + private MockWebServer server ; \n + @ RegisterExtension public final OkHttpClientTestRule clientTestRule = new OkHttpClientTestRule ( ) ; \n - @ After public void after ( ) { \n + @ BeforeEach public void before ( MockWebServer server ) { \n + this . server = server ; \n + } \n + \n + @ AfterEach public void after ( ) { \n,Migrate Logging tests to Junit5 ( # 6356 ),547
"native - image - tests \ build . gradle \n + sourceSets { \n + main . java . srcDirs + = project . file ( "" . . / okhttp - logging - interceptor / src / test / java "" ) \n + main . java . srcDirs + = project . file ( "" . . / okhttp - sse / src / test / java "" ) \n + } \n + \n native - image - tests \ src \ main \ kotlin \ okhttp3 \ RunTests . kt \n - / / okhttp3 . sse . internal . EventSourceHttpTest : : class . java , \n - / / okhttp3 . logging . IsProbablyUtf8Test : : class . java , \n - / / okhttp3 . logging . LoggingEventListenerTest : : class . java , \n - / / okhttp3 . logging . HttpLoggingInterceptorTest : : class . java , \n - / / okhttp3 . sse . internal . ServerSentEventIteratorTest : : class . java , \n + okhttp3 . logging . IsProbablyUtf8Test : : class . java , \n + okhttp3 . logging . LoggingEventListenerTest : : class . java , \n + okhttp3 . logging . HttpLoggingInterceptorTest : : class . java , \n + okhttp3 . sse . internal . EventSourceHttpTest : : class . java , \n + okhttp3 . sse . internal . ServerSentEventIteratorTest : : class . java , \n",Run some junit5 tests ( # 6359 ),547
"okhttp \ src \ test \ java \ okhttp3 \ internal \ http \ CancelTest . java \n + import java . util . Collection ; \n + import okhttp3 . internal . connection . RealCall ; \n + import org . junit . After ; \n + import org . junit . runner . RunWith ; \n + import org . junit . runners . Parameterized ; \n + import static java . util . Arrays . asList ; \n + import static org . junit . Assert . assertEquals ; \n + @ RunWith ( Parameterized . class ) \n + private Thread threadToCancel ; \n + \n + enum CancelMode { \n + CANCEL , \n + INTERRUPT \n + } \n + \n + private final CancelMode mode ; \n + \n + @ Parameterized . Parameters ( name = "" { 0 } "" ) \n + public static Collection < CancelMode > cancelModes ( ) { \n + return asList ( CancelMode . values ( ) ) ; \n + } \n + \n + public CancelTest ( CancelMode mode ) { \n + this . mode = mode ; \n + } \n - @ Before public void setUp ( ) throws Exception { \n + @ Before public void setUp ( ) { \n + \n + threadToCancel = Thread . currentThread ( ) ; \n + assertEquals ( mode = = CancelMode . INTERRUPT , Thread . interrupted ( ) ) ; \n + assertEquals ( mode = = CancelMode . INTERRUPT , Thread . interrupted ( ) ) ; \n - call . cancel ( ) ; \n + if ( mode = = CancelMode . CANCEL ) { \n + call . cancel ( ) ; \n + } else { \n + threadToCancel . interrupt ( ) ; \n + } \n",Confirm basic cancel behaviour in test ( # 5937 ),547
"okhttp \ src \ main \ kotlin \ okhttp3 \ OkHttpClient . kt \n - import java . security . SecureRandom \n - / / no support for bouncycastle SecureRandom on Android \n - / / see JcaTlsCryptoProvider . create \n - val random = SecureRandom ( ) \n - sslContext . init ( null , arrayOf < TrustManager > ( trustManager ) , random ) \n + sslContext . init ( null , arrayOf < TrustManager > ( trustManager ) , null ) \n",Revert to null SecureRandom ( # 5939 ) \n Short lived change to enable BouncyCastle on Android .,547
"build . gradle \n - ' kotlin ' : ' 1 . 4 . 0 ' , \n + ' kotlin ' : ' 1 . 4 . 10 ' , \n - classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 0 "" \n + classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 10 "" \n",Kotlin 1 . 4 . 10 Upgrade ( # 6264 ),547
"build . gradle \n - ' conscrypt ' : ' 2 . 5 . 0 ' , \n + ' conscrypt ' : ' 2 . 5 . 1 ' , \n",Conscrypt 2 . 5 . 1 Upgrade ( # 6263 ),547
"native - image - tests \ build . gradle \n - option "" - - enable - https "" \n - option "" - - initialize - at - build - time = kotlin . text . Charsets "" \n - option "" - H : EnableURLProtocols = http , https "" \n - option "" - H : + AddAllCharsets "" \n native - image - tests \ src \ main \ kotlin \ okhttp3 \ TestRegistration . kt \n + import org . graalvm . nativeimage . hosted . RuntimeClassInitialization \n + / / Presumably needed for parsing the testlist . txt file . \n + RuntimeClassInitialization . initializeAtBuildTime ( access . findClassByName ( "" kotlin . text . Charsets "" ) ) \n + \n new file \n okhttp \ src \ main \ resources \ META - INF \ native - image \ okhttp \ okhttp \ native - image . properties \n + Args = - H : + AddAllCharsets - H : EnableURLProtocols = http , https - - enable - https \n",Fix for native image and config ( # 6416 ),547
"okcurl \ build . gradle \n - id "" com . palantir . graal "" version "" 0 . 7 . 1 "" \n + id "" com . palantir . graal "" version "" 0 . 7 . 2 "" \n - implementation ' info . picocli : picocli - codegen : 4 . 5 . 1 ' \n - annotationProcessor ' info . picocli : picocli - codegen : 4 . 5 . 1 ' \n + implementation ' info . picocli : picocli - codegen : 4 . 5 . 2 ' \n + annotationProcessor ' info . picocli : picocli - codegen : 4 . 5 . 2 ' \n - testImplementation deps . junit \n + testImplementation deps . junit5Api \n - option "" - - enable - https "" \n deleted file \n okcurl \ src \ test \ java \ okhttp3 \ curl \ GenerateReflectionConfig . kt \n - / * \n - * Copyright ( C ) 2020 Square , Inc . \n - * \n - * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n - * you may not use this file except in compliance with the License . \n - * You may obtain a copy of the License at \n - * \n - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n - * \n - * Unless required by applicable law or agreed to in writing , software \n - * distributed under the License is distributed on an "" AS IS "" BASIS , \n - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n - * See the License for the specific language governing permissions and \n - * limitations under the License . \n - * / \n - package okhttp3 . curl \n - \n - import picocli . CommandLine . Model . CommandSpec . forAnnotatedObject \n - import picocli . codegen . aot . graalvm . ReflectionConfigGenerator \n - import java . io . File \n - \n - / * * \n - * Manual process to update reflect - config . json \n - * / \n - fun main ( ) { \n - val configFile = File ( "" okcurl / src / main / resources / META - INF / native - image / okhttp3 / okcurl / reflect - config . json "" ) \n - configFile . writeText ( ReflectionConfigGenerator . generateReflectionConfig ( forAnnotatedObject ( Main ( ) ) ) ) \n - } \n okcurl \ src \ test \ java \ okhttp3 \ curl \ MainTest . java \n - import org . junit . Test ; \n + import org . junit . jupiter . api . Test ; \n",Okcurl upgrade and cleanup ( # 6417 ) \n * Cleanup okcurl build \n * Cleanup okcurl build,547
"android - test \ build . gradle \n - testInstrumentationRunnerArguments ( [ ' runnerBuilder ' : ' de . mannodermaus . junit5 . AndroidJUnit5Builder ' ] ) \n + testInstrumentationRunnerArguments ( [ \n + ' runnerBuilder ' : ' de . mannodermaus . junit5 . AndroidJUnit5Builder ' , \n + ' notPackage ' : ' org . bouncycastle ' \n + ] ) \n",Avoid bouncy castle tests in Android ( # 6418 ),547
"native - image - tests \ build . gradle \n - implementation ( "" org . graalvm . nativeimage : svm : 20 . 2 . 0 "" ) { \n + implementation ( "" org . graalvm . nativeimage : svm : 20 . 3 . 0 "" ) { \n - graalVersion "" 20 . 2 . 0 "" \n + graalVersion "" 20 . 3 . 0 "" \n - option "" - H : + TraceClassInitialization "" \n okcurl \ build . gradle \n - graalVersion "" 20 . 2 . 0 "" \n + graalVersion "" 20 . 3 . 0 "" \n",Graal 20 . 3 . 0 ( # 6427 ),547
"build . gradle \n - ' kotlin ' : ' 1 . 4 . 10 ' , \n + ' kotlin ' : ' 1 . 4 . 20 ' , \n - classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 10 "" \n + classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 20 "" \n",Kotlin 1 . 4 . 20 ( # 6341 ) \n * Early testing with kotlin 1 . 4 . 20 \n * Update build . gradle \n * Kotlin 1 . 4 . 20 RC \n * Kotlin 1 . 4 . 20 RC \n * Update build . gradle,547
build . gradle \n - sourceCompatibility = JavaVersion . VERSION _ 1 _ 8 \n - targetCompatibility = JavaVersion . VERSION _ 1 _ 8 \n - \n,Fix for JDK8 ALPN ( # 6444 ) \n * Fix for JDK8 ALPN \n * Fix for JDK8 ALPN,547
"native - image - tests \ src \ main \ kotlin \ okhttp3 \ DotListener . kt \n - TestExecutionResult . Status . ABORTED - > printStatus ( "" E "" ) \n + TestExecutionResult . Status . ABORTED - > printStatus ( "" - "" ) \n okhttp - testing - support \ src \ main \ kotlin \ okhttp3 \ TestUtil . kt \n - @ JvmStatic \n - private val isGraalVmImage = System . getProperty ( "" org . graalvm . nativeimage . imagecode "" ) ! = null \n + @ JvmStatic val isGraalVmImage = System . getProperty ( "" org . graalvm . nativeimage . imagecode "" ) ! = null \n okhttp - testing - support \ src \ main \ kotlin \ okhttp3 \ testing \ PlatformRule . kt \n + import okhttp3 . TestUtil \n - expectFailure ( fromMajor ( majorVersion ) ) \n + if ( ! TestUtil . isGraalVmImage ) { \n + expectFailure ( fromMajor ( majorVersion ) ) \n + } \n - expectFailure ( onMajor ( majorVersion ) ) \n + if ( ! TestUtil . isGraalVmImage ) { \n + expectFailure ( onMajor ( majorVersion ) ) \n + } \n + fun isGraalVMImage ( ) = TestUtil . isGraalVmImage \n + \n + fun assumeGraalVMImage ( ) { \n + assumeTrue ( isGraalVMImage ( ) ) \n + } \n + \n + fun assumeNotGraalVMImage ( ) { \n + assumeFalse ( isGraalVMImage ( ) ) \n + } \n + \n + assumeNotGraalVMImage ( ) \n",Fix single failing graal test ( # 6445 ),547
"okhttp - testing - support \ src \ main \ java \ okhttp3 \ testing \ PlatformRule . kt \n - System . err . println ( "" Running with $ { Platform . get ( ) . javaClass . simpleName } "" ) \n - \n + \n + if ( requiredPlatformName ! = null ) { \n + System . err . println ( "" Running with $ { Platform . get ( ) . javaClass . simpleName } "" ) \n + } \n - if ( getPlatformSystemProperty ( ) = = CONSCRYPT _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" Conscrypt "" ) { \n + val platformSystemProperty = getPlatformSystemProperty ( ) \n + \n + if ( platformSystemProperty = = CONSCRYPT _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" Conscrypt "" ) { \n - } else if ( getPlatformSystemProperty ( ) = = JDK8 _ ALPN _ PROPERTY ) { \n + } else if ( platformSystemProperty = = JDK8 _ ALPN _ PROPERTY ) { \n - } else if ( getPlatformSystemProperty ( ) = = JDK8 _ PROPERTY ) { \n + } else if ( platformSystemProperty = = JDK8 _ PROPERTY ) { \n - } else if ( getPlatformSystemProperty ( ) = = OPENJSSE _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" OpenJSSE "" ) { \n + } else if ( platformSystemProperty = = OPENJSSE _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" OpenJSSE "" ) { \n - } else if ( getPlatformSystemProperty ( ) = = BOUNCYCASTLE _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" BC "" ) { \n + } else if ( platformSystemProperty = = BOUNCYCASTLE _ PROPERTY & & Security . getProviders ( ) [ 0 ] . name ! = "" BC "" ) { \n - } else if ( getPlatformSystemProperty ( ) = = CORRETTO _ PROPERTY ) { \n + } else if ( platformSystemProperty = = CORRETTO _ PROPERTY ) { \n + \n + System . err . println ( "" Running Tests with $ { Platform . get ( ) . javaClass . simpleName } "" ) \n - var property : String ? = System . getProperty ( \n - PROPERTY _ NAME ) \n + var property : String ? = System . getProperty ( PROPERTY _ NAME ) \n",Reduce platform logging for each test ( # 5723 ),547
"android - test \ src \ androidTest \ java \ okhttp \ android \ test \ OkHttpTest . kt \n + import java . security . KeyStore \n + import java . security . SecureRandom \n + import javax . net . ssl . TrustManager \n + import javax . net . ssl . TrustManagerFactory \n - val request = Request . Builder ( ) . url ( "" https : / / facebook . com / robots . txt "" ) . build ( ) \n - \n - / / Need fresh client to reset sslSocketFactoryOrNull \n - client = OkHttpClient . Builder ( ) . eventListenerFactory ( clientTestRule . wrap ( object : EventListener ( ) { \n - override fun connectionAcquired ( call : Call , connection : Connection ) { \n - socketClass = connection . socket ( ) . javaClass . name \n - } \n - } ) ) . build ( ) \n + val trustManager = TrustManagerFactory . getInstance ( TrustManagerFactory . getDefaultAlgorithm ( ) ) . apply { \n + init ( null as KeyStore ? ) \n + } . trustManagers . first ( ) as X509TrustManager \n + \n + val sslContext = Platform . get ( ) . newSSLContext ( ) . apply { \n + / / TODO remove most of this code after https : / / github . com / bcgit / bc - java / issues / 686 \n + init ( null , arrayOf ( trustManager ) , SecureRandom ( ) ) \n + } \n + \n + client = client . newBuilder ( ) \n + . sslSocketFactory ( sslContext . socketFactory , trustManager ) \n + . eventListenerFactory ( clientTestRule . wrap ( object : EventListener ( ) { \n + override fun connectionAcquired ( call : Call , connection : Connection ) { \n + socketClass = connection . socket ( ) . javaClass . name \n + } \n + } ) ) \n + . build ( ) \n + \n + val request = Request . Builder ( ) . url ( "" https : / / facebook . com / robots . txt "" ) . build ( ) \n - client . close ( ) \n",Workaround bouncycastle random issue ( # 5942 ) \n * Workaround bouncycastle random issue \n * Cleanup,547
"okhttp \ src \ main \ kotlin \ okhttp3 \ OkHttpClient . kt \n - * Configure this client to follow redirects from HTTPS to HTTP and from HTTP to HTTPS . \n + * Configure this client to allow protocol redirects from HTTPS to HTTP and from HTTP to HTTPS . \n + * Redirects are still first restricted by [ followRedirects ] . Defaults to true . \n - * If unset , protocol redirects will be followed . This is different than the built - in \n - * ` HttpURLConnection ` ' s default . \n + * @ param followProtocolRedirects whether to follow redirects between HTTPS and HTTP . \n",Update followSslRedirects documentation ( # 5945 ) \n * Update followSslRedirects documentation \n * Update OkHttpClient . kt,547
README . md \n - / / define any required OkHttp artifacts without verion \n + / / define any required OkHttp artifacts without version \n,fix README . md typo ( # 6469 ),547
"build . gradle \n - dependencies { \n - testCompile "" org . mortbay . jetty . alpn : alpn - boot : $ alpnBootVersion "" \n - } \n - def alpnBootJar = configurations . testCompile . find { it . name . startsWith ( "" alpn - boot - "" ) } \n + def alpnBootJar = configurations . detachedConfiguration ( \n + dependencies . create ( "" org . mortbay . jetty . alpn : alpn - boot : $ alpnBootVersion "" ) ) . singleFile \n",Fix jdk8 with alpn - boot ( # 6458 ),547
"okhttp - tls \ src \ main \ kotlin \ okhttp3 \ tls \ HandshakeCertificates . kt \n + import java . security . KeyStoreException \n + \n + val heldCertificate = heldCertificate \n + if ( heldCertificate ! = null & & heldCertificate . keyPair . private . format = = null ) { \n + throw KeyStoreException ( "" unable to support unencodable private key "" ) \n + } \n + \n",Fail on unencodable keys ( # 6468 ),547
build . gradle \n - repositories { \n - mavenCentral ( ) \n - maven { \n - url ' https : / / dl . bintray . com / kotlin / dokka ' \n - } \n - google ( ) \n - } \n - \n + vendor = JvmVendorSpec . ADOPTOPENJDK \n + vendor = JvmVendorSpec . ADOPTOPENJDK \n gradle \ wrapper \ gradle - wrapper . properties \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 7 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 6 . 8 . 1 - all . zip \n settings . gradle \n + \n + dependencyResolutionManagement { \n + repositories { \n + mavenCentral ( ) \n + maven { \n + url ' https : / / dl . bintray . com / kotlin / dokka ' \n + } \n + google ( ) \n + } \n + } \n,"Gradle upgrade , more specific toolchain ( # 6529 )",547
okhttp \ src \ test \ java \ okhttp3 \ CallHandshakeTest . kt \n + / / We are avoiding making guarantees on ordering of secondary Platforms . \n + platform . assumeNotConscrypt ( ) \n + \n + / / We are avoiding making guarantees on ordering of secondary Platforms . \n + platform . assumeNotConscrypt ( ) \n + \n + / / We are avoiding making guarantees on ordering of secondary Platforms . \n + platform . assumeNotConscrypt ( ) \n + \n + / / We are avoiding making guarantees on ordering of secondary Platforms . \n + platform . assumeNotConscrypt ( ) \n okhttp \ src \ test \ java \ okhttp3 \ RecordedResponse . java \n - assertThat ( response . code ( ) ) . isEqualTo ( expectedCode ) ; \n + assertThat ( response = = null ? null : response . code ( ) ) . isEqualTo ( expectedCode ) ; \n okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ HostnameVerifierTest . java \n + / / OpenJDK related test . \n + platform . assumeNotConscrypt ( ) ; \n + \n,Handle specific test failures on master ( # 6530 ) \n * Handle specific test failures on master \n * Revert change,547
"build . gradle \n - ' kotlin ' : ' 1 . 4 . 21 ' , \n + ' kotlin ' : ' 1 . 4 . 30 ' , \n - classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 21 "" \n + classpath "" org . jetbrains . kotlin : kotlin - gradle - plugin : 1 . 4 . 30 "" \n",Kotlin 1 . 4 . 30 ( # 6545 ) \n Kotlin 1 . 4 . 30 upgrade . Should ideally be released along side okio using same version .,547
okhttp \ src \ test \ java \ okhttp3 \ CallTest . java \n - long connectCount = listener . getEventSequence ( ) . stream ( ) \n - . filter ( ( event ) - > event instanceof ConnectStart ) \n - . count ( ) ; \n - long expected = platform . isJdk8 ( ) ? 2 : 1 ; \n - assertThat ( connectCount ) . isEqualTo ( expected ) ; \n + if ( ! platform . isJdk8 ( ) ) { \n + long connectCount = listener . getEventSequence ( ) . stream ( ) \n + . filter ( ( event ) - > event instanceof ConnectStart ) \n + . count ( ) ; \n + assertThat ( connectCount ) . isEqualTo ( 1 ) ; \n + } \n okhttp \ src \ test \ java \ okhttp3 \ internal \ tls \ ClientAuthTest . java \n - assertThat ( PlatformVersion . INSTANCE . getMajorVersion ( ) ) . isGreaterThanOrEqualTo ( 11 ) ; \n - assertThat ( PlatformVersion . INSTANCE . getMajorVersion ( ) ) . isGreaterThanOrEqualTo ( 11 ) ; \n,Fix build for jdk8 ( # 6549 ) \n JDK 8 improvements have changed results on JDK8 which is now essentially feature complete compared to JDK11 .,547
new file \n CONTRIBUTING . MD \n + This is great you have something to contribute ! \n + \n + Before going any further please read the [ wiki ] ( https : / / github . com / iluwatar / java - design - patterns / wiki ) \n + with convemtions and rules we used for this project . \n,add - contributing \n so github will show link whenever PR are made,550
CONTRIBUTING . MD \n - with convemtions and rules we used for this project . \n + with cenventions and rules we used for this project . \n,Update CONTRIBUTING . MD \n fix the typo,550
CONTRIBUTING . MD \n - with cenventions and rules we used for this project . \n + with conventions and rules we used for this project . \n,Update CONTRIBUTING . MD \n real fix : ),550
"PULL _ REQUEST _ TEMPLATE . md \n - # # # What this PR do ? \n - - Describes the main changes that come with the pull request in present tense \n - - For instance - "" Add correction to facade pattern "" \n - # # # Context \n - - \n + Pull request title \n + - Clearly and concisely describes what it does \n + - Refer to the issue that it solves , if available \n - > DELETE ME | for detailed contributing instructions see https : / / github . com / iluwatar / java - design - patterns / wiki / 01 . - How - to - contribute \n + \n + Pull request description \n + \n + - Describes the main changes that come with the pull request \n + - Any relevant additional information is provided \n + \n + \n + \n + > For detailed contributing instructions see https : / / github . com / iluwatar / java - design - patterns / wiki / 01 . - How - to - contribute \n",Update PULL _ REQUEST _ TEMPLATE . md,550
"new file \n PULL _ REQUEST _ TEMPLATE . md \n + # # # What this PR do ? \n + - Describes the main changes that come with the pull request in present tense \n + - For instance - "" Add correction to facade pattern "" \n + \n + # # # Context \n + - \n + \n + \n + > DELETE ME | for detailed contributing instructions see https : / / github . com / iluwatar / java - design - patterns / wiki / 01 . - How - to - contribute \n",Create PULL _ REQUEST _ TEMPLATE . md,550
README . md \n + [ ! [ CII Best Practices ] ( https : / / bestpractices . coreinfrastructure . org / projects / 1503 / badge ) ] ( https : / / bestpractices . coreinfrastructure . org / projects / 1503 ) \n,Update README . md \n add CII Best Practices badge,550
"dubbo - demo \ dubbo - demo - provider \ src \ main \ resources \ META - INF \ spring \ dubbo - demo - provider . xml \n - < dubbo : registry group = "" dubboregistrygroup1 "" address = "" zookeeper : / / 127 . 0 . 0 . 1 : 2181 "" / > \n + < dubbo : registry address = "" zookeeper : / / 127 . 0 . 0 . 1 : 2181 "" / > \n",remove the group of registry from demo - provider,579
"dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ AbstractInterfaceConfig . java \n - logger . info ( "" There ' s no valid metadata config found , if you are using the simplified mode of registry url , please make sure you have a metadata address configured properly . "" ) ; \n + logger . warn ( "" There ' s no valid metadata config found , if you are using the simplified mode of registry url , please make sure you have a metadata address configured properly . "" ) ; \n","if no metadata config address , config the log level to warn",579
"dubbo - config \ dubbo - config - spring \ src \ main \ java \ org \ apache \ dubbo \ config \ spring \ context \ annotation \ DubboConfigConfiguration . java \n + import org . apache . dubbo . config . MetadataReportConfig ; \n - @ EnableDubboConfigBinding ( prefix = "" dubbo . configcenter "" , type = ConfigCenterBean . class ) \n + @ EnableDubboConfigBinding ( prefix = "" dubbo . configcenter "" , type = ConfigCenterBean . class ) , \n + @ EnableDubboConfigBinding ( prefix = "" dubbo . metadatareport "" , type = MetadataReportConfig . class ) \n",fix : dubbo . properties cannot work on MetadataReportConfig,579
"dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ common \ Constants . java \n + / / package version in the manifest \n + public static final String SPECIFICATION _ VERSION _ KEY = "" specVersion "" ; \n - GROUP _ KEY , LOADBALANCE _ KEY , MOCK _ KEY , PATH _ KEY , TIMEOUT _ KEY , TOKEN _ KEY , VERSION _ KEY , WARMUP _ KEY , WEIGHT _ KEY , TIMESTAMP _ KEY , DUBBO _ VERSION _ KEY } ; \n + GROUP _ KEY , LOADBALANCE _ KEY , MOCK _ KEY , PATH _ KEY , TIMEOUT _ KEY , TOKEN _ KEY , VERSION _ KEY , WARMUP _ KEY , WEIGHT _ KEY , TIMESTAMP _ KEY , DUBBO _ VERSION _ KEY , SPECIFICATION _ VERSION _ KEY } ; \n - public static final String [ ] DEFAULT _ REGISTER _ CONSUMER _ KEYS = { APPLICATION _ KEY , VERSION _ KEY , GROUP _ KEY , DUBBO _ VERSION _ KEY } ; \n + public static final String [ ] DEFAULT _ REGISTER _ CONSUMER _ KEYS = { APPLICATION _ KEY , VERSION _ KEY , GROUP _ KEY , DUBBO _ VERSION _ KEY , SPECIFICATION _ VERSION _ KEY } ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ ReferenceConfig . java \n + map . put ( Constants . SPECIFICATION _ VERSION _ KEY , Version . getVersion ( ) ) ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ ServiceConfig . java \n + map . put ( Constants . SPECIFICATION _ VERSION _ KEY , Version . getVersion ( ) ) ; \n",add dubbo specification version into registry for ops,579
README . md \n - < version > 2 . 6 . 4 < / version > \n + < version > 2 . 6 . 5 < / version > \n,modify dubbo version to 2 . 6 . 5,579
"dubbo - remoting \ dubbo - remoting - zookeeper \ src \ main \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ support \ AbstractZookeeperTransporter . java \n - logger . info ( "" Get result from map for the first time when invoking zookeeperTransporter . connnect . "" ) ; \n + logger . info ( "" find valid zookeeper client from the cache for address : "" + url ) ; \n - logger . info ( "" Get result from map for the second time when invoking zookeeperTransporter . connnect . "" ) ; \n + logger . info ( "" find valid zookeeper client from the cache for address : "" + url ) ; \n - zookeeperClient = createZookeeperClient ( createServerURL ( url ) ) ; \n - logger . info ( "" Get result by creating new connection when invoking zookeeperTransporter . connnect . "" ) ; \n + zookeeperClient = createZookeeperClient ( toClientURL ( url ) ) ; \n + logger . info ( "" No valid zookeeper client found from cache , therefore create a new client for url . "" + url ) ; \n - URL createServerURL ( URL url ) { \n + URL toClientURL ( URL url ) { \n dubbo - remoting \ dubbo - remoting - zookeeper \ src \ test \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ support \ AbstractZookeeperTransporterTest . java \n - import org . apache . curator . test . TestingServer ; \n + \n + import org . apache . curator . test . TestingServer ; \n - URL newUrl = abstractZookeeperTransporter . createServerURL ( url ) ; \n + URL newUrl = abstractZookeeperTransporter . toClientURL ( url ) ; \n - public void testCreateServerURLWhenHasUser ( ) { \n + public void testToCreateURLWhenHasUser ( ) { \n - URL newUrl = abstractZookeeperTransporter . createServerURL ( url ) ; \n + URL newUrl = abstractZookeeperTransporter . toClientURL ( url ) ; \n",just for modify comments and imports ( # 3227 ),579
dubbo - all \ pom . xml \n + < dependency > \n + < groupId > com . google . code . gson < / groupId > \n + < artifactId > gson < / artifactId > \n + < / dependency > \n - < include > com . google . code . gson : gson < / include > \n,"Merge pull request # 3246 from cvictory : 2 . 7 . 0 - release remove gson from dubbo . jar in shading mode , and change to dependency way . \n * just for modify comments and imports \n * remove gson from dubbo . jar in shading mode , add dependency",579
"dubbo - all \ pom . xml \n + < filters > \n + < filter > \n + < artifact > org . apache . dubbo : dubbo < / artifact > \n + < excludes > \n + < ! - - These two line is optional , it can remove some warn log - - > \n + < exclude > com / * * < / exclude > \n + < exclude > org / * * < / exclude > \n + < ! - - This one is required - - > \n + < exclude > META - INF / dubbo / * * < / exclude > \n + < / excludes > \n + < / filter > \n + < / filters > \n dubbo - container \ dubbo - container - api \ pom . xml \n - < forceCreation > true < / forceCreation > \n - < / project > \n + < / project > \n pom . xml \n - < forceCreation > true < / forceCreation > \n",fix # 2842 . remove duplicate SPI definitions for 2 . 7 . x ( # 3340 ) \n remove duplicate SPI definitions for 2 . 7 . x,579
dubbo - dependencies - bom \ pom . xml \n - < dependency > \n - < groupId > org . apache . tomcat . embed < / groupId > \n - < artifactId > tomcat - embed - logging - juli < / artifactId > \n - < version > $ { tomcat _ embed _ version } < / version > \n - < / dependency > \n,remove tomcat - embed - logging - juli ( # 4430 ) \n fixes # 4400,579
"dubbo - metadata - report \ dubbo - metadata - report - api \ src \ main \ java \ org \ apache \ dubbo \ metadata \ support \ AbstractMetadataReport . java \n - / / Local disk cache , where the special key value . registries records the list of registry centers , and the others are the list of notified service providers \n + / / Local disk cache , where the special key value . registries records the list of metadata centers , and the others are the list of notified service providers \n - final ScheduledExecutorService retryExecutor = Executors . newScheduledThreadPool ( 0 , new NamedThreadFactory ( "" DubboRegistryFailedRetryTimer "" , true ) ) ; \n + final ScheduledExecutorService retryExecutor = Executors . newScheduledThreadPool ( 0 , new NamedThreadFactory ( "" DubboMetadataReportRetryTimer "" , true ) ) ; \n - / / Check and connect to the registry \n + / / Check and connect to the metadata \n",Modify MetadataReportRetry ThreadName ( # 3550 ) \n * fix : rename the thread name from DubboRegistryFailedRetryTimer to DubboMetadataReportRetryTimer in MetadataReportRetry,579
"dubbo - metadata - report \ dubbo - metadata - report - api \ src \ main \ java \ org \ apache \ dubbo \ metadata \ identifier \ MetadataIdentifier . java \n - return serviceInterface + SEPARATOR + ( version = = null ? "" "" : version + SEPARATOR ) + ( group = = null ? "" "" : group + SEPARATOR ) + side + SEPARATOR + application ; \n + return serviceInterface + SEPARATOR + ( version = = null ? "" "" : version ) + SEPARATOR + ( group = = null ? "" "" : group ) + SEPARATOR + side + SEPARATOR + application ; \n dubbo - metadata - report \ dubbo - metadata - report - api \ src \ test \ java \ org \ apache \ dubbo \ metadata \ identifier \ MetadataIdentifierTest . java \n - + ( group = = null ? "" "" : ( group + PATH _ SEPARATOR ) ) + PROVIDER _ SIDE \n + + ( group = = null ? "" "" : ( group + PATH _ SEPARATOR ) ) + PROVIDER _ SIDE \n + PATH _ SEPARATOR + application ) ; \n - ( version = = null ? "" "" : version + MetadataIdentifier . SEPARATOR ) \n - + ( group = = null ? "" "" : group + MetadataIdentifier . SEPARATOR ) \n + ( version = = null ? "" "" : version ) + MetadataIdentifier . SEPARATOR \n + + ( group = = null ? "" "" : group ) + MetadataIdentifier . SEPARATOR \n + PROVIDER _ SIDE + MetadataIdentifier . SEPARATOR + application ) ; \n",make metadata key contain : when version and group is empty ( # 4465 ),579
"dubbo - remoting \ dubbo - remoting - zookeeper \ src \ main \ java \ org \ apache \ dubbo \ remoting \ zookeeper \ curator \ CuratorZookeeperClient . java \n + import org . apache . dubbo . common . logger . Logger ; \n + import org . apache . dubbo . common . logger . LoggerFactory ; \n + protected static final Logger logger = LoggerFactory . getLogger ( CuratorZookeeperClient . class ) ; \n + \n + if ( logger . isInfoEnabled ( ) ) { \n + logger . info ( "" listen the zookeeper changed . The changed data : "" + event . getData ( ) ) ; \n + } \n - content = new String ( event . getData ( ) . getData ( ) , CHARSET ) ; \n + content = event . getData ( ) . getData ( ) = = null ? "" "" : new String ( event . getData ( ) . getData ( ) , CHARSET ) ; \n - content = new String ( event . getData ( ) . getData ( ) , CHARSET ) ; \n + content = event . getData ( ) . getData ( ) = = null ? "" "" : new String ( event . getData ( ) . getData ( ) , CHARSET ) ; \n",check curator event with empty data value ( # 4126 ) \n fixes # 3866,579
"dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ AsyncRpcResult . java \n + public void subscribeTo ( CompletableFuture < ? > future ) { \n + future . whenComplete ( ( obj , t ) - > { \n + if ( t ! = null ) { \n + this . completeExceptionally ( t ) ; \n + } else { \n + this . complete ( ( Result ) obj ) ; \n + } \n + } ) ; \n + } \n + \n",bugfix follow # 4127 ( # 4155 ),579
"dubbo - registry \ dubbo - registry - nacos \ src \ main \ java \ org \ apache \ dubbo \ registry \ nacos \ NacosRegistry . java \n + import org . apache . dubbo . common . URLBuilder ; \n - import java . util . Collections ; \n - import static org . apache . dubbo . registry . Constants . ADMIN _ PROTOCOL ; \n + import static org . apache . dubbo . common . constants . RegistryConstants . EMPTY _ PROTOCOL ; \n + import static org . apache . dubbo . registry . Constants . ADMIN _ PROTOCOL ; \n - urls . addAll ( buildURLs ( url , instances ) ) ; \n + urls . addAll ( buildURLs ( url , serviceName , instances ) ) ; \n - notifySubscriber ( url , listener , instances ) ; \n + notifySubscriber ( url , serviceName , listener , instances ) ; \n - private List < URL > buildURLs ( URL consumerURL , Collection < Instance > instances ) { \n + private List < URL > buildURLs ( URL consumerURL , String serviceName , Collection < Instance > instances ) { \n - return Collections . emptyList ( ) ; \n + return emptyURL ( consumerURL , serviceName ) ; \n - notifySubscriber ( url , listener , e . getInstances ( ) ) ; \n + notifySubscriber ( url , serviceName , listener , e . getInstances ( ) ) ; \n + * @ param serviceName \n - private void notifySubscriber ( URL url , NotifyListener listener , Collection < Instance > instances ) { \n + private void notifySubscriber ( URL url , String serviceName , NotifyListener listener , Collection < Instance > instances ) { \n - List < URL > urls = buildURLs ( url , healthyInstances ) ; \n + List < URL > urls = buildURLs ( url , serviceName , healthyInstances ) ; \n + private List < URL > emptyURL ( URL consumerURL , String serviceName ) { \n + int i = serviceName . indexOf ( SERVICE _ NAME _ SEPARATOR ) ; \n + String category = i < 0 ? serviceName : serviceName . substring ( 0 , i ) ; \n + URL empty = URLBuilder . from ( consumerURL ) \n + . setProtocol ( EMPTY _ PROTOCOL ) \n + . addParameter ( CATEGORY _ KEY , category ) \n + . build ( ) ; \n + List < URL > result = new ArrayList < URL > ( ) ; \n + result . add ( empty ) ; \n + return result ; \n + } \n + \n",Use empty protocol for nacos registry when address list is empty . ( # 4349 ) \n fixes # 4294 .,579
dubbo - bom \ pom . xml \n + < dependency > \n + < groupId > org . apache . dubbo < / groupId > \n + < artifactId > dubbo - metadata - definition - protobuf < / artifactId > \n + < version > $ { project . version } < / version > \n + < / dependency > \n,add bom dependency for new module ' metadata - definition - protobuf ' ( # 4417 ) \n commit following # 4408,579
dubbo - config \ dubbo - config - spring \ src \ main \ java \ org \ apache \ dubbo \ config \ spring \ ServiceBean . java \n - if ( StringUtils . isEmpty ( registryIds ) ) { \n + if ( StringUtils . isEmpty ( registryIds ) & & ( config . isDefault ( ) = = null | | config . isDefault ( ) . booleanValue ( ) ) ) { \n,"multiple registries , services only register to default registry . ( # 4420 ) \n fixes # 4412",579
"dubbo - cluster \ src \ main \ java \ org \ apache \ dubbo \ rpc \ cluster \ router \ tag \ TagRouter . java \n + import static org . apache . dubbo . common . constants . CommonConstants . ANYHOST _ VALUE ; \n + \n + if ( ( ANYHOST _ VALUE + "" : "" + port ) . equals ( address ) ) { \n + return true ; \n + } \n",tag router supports anyhost ( # 4431 ) \n Fixes # 4393,579
"dubbo - metadata \ dubbo - metadata - api \ src \ main \ java \ org \ apache \ dubbo \ metadata \ store \ InMemoryWritableMetadataService . java \n - logger . error ( "" publishProvider interfaceName is empty . providerUrl : "" + providerUrl . toFullString ( ) ) ; \n + logger . info ( "" publishProvider interfaceName is empty . providerUrl : "" + providerUrl . toFullString ( ) ) ; \n","when the url is generic , the log level should be info ( # 6363 )",579
gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ Button . java \n + setSkin ( skin ) ; \n gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ ImageButton . java \n + setSkin ( skin ) ; \n + setSkin ( skin ) ; \n,Buttons keep skin reference ( # 4391 ),580
"gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ ProgressBar . java \n - Math . round ( knobAfter . getMinWidth ( ) ) , Math . round ( height - position + knobHeightHalf ) ) ; \n + Math . round ( knobAfter . getMinWidth ( ) ) , Math . round ( height - position - knobHeightHalf ) ) ; \n - knobAfter . getMinWidth ( ) , height - position + knobHeightHalf ) ; \n + knobAfter . getMinWidth ( ) , height - position - knobHeightHalf ) ; \n - Math . round ( width - position + knobWidthHalf ) , Math . round ( knobAfter . getMinHeight ( ) ) ) ; \n + Math . round ( width - position - knobWidthHalf ) , Math . round ( knobAfter . getMinHeight ( ) ) ) ; \n - width - position + knobWidthHalf , knobAfter . getMinHeight ( ) ) ; \n + width - position - knobWidthHalf , knobAfter . getMinHeight ( ) ) ; \n",Fix # 4446 ( ProgressBar knobAfter ) ( # 4447 ) \n Fixes # 4446,580
"gdx \ src \ com \ badlogic \ gdx \ graphics \ g2d \ PolygonSpriteBatch . java \n - throw new IllegalArgumentException ( "" Can ' t have more than 32767 vertices per batch : "" + maxTriangles ) ; \n + throw new IllegalArgumentException ( "" Can ' t have more than 32767 vertices per batch : "" + maxVertices ) ; \n",Fix PolygonSpriteBatch error message ( # 4451 ),580
"CHANGES \n - NinepatchDrawable is now a TransformDrawable . \n - API Change : Group add * methods no longer remove and re - add the actor if it is already in the group , instead they do nothing . \n - API Change : g2d . Animation is now generic so it can support Drawables , PolygonRegions , NinePatches , etc . To fix existing code , specify the TextureRegion type in animation declarations ( and instantiations in Java 6 ) , i . e . Animation < TextureRegion > myAnimation = new Animation < TextureRegion > ( . . . ) ; \n - - TiledDrawable throws unsupported operation kif trying to draw rotated / scaled . # 4005 \n + - TiledDrawable throws unsupported operation if trying to draw rotated / scaled . # 4005 \n + - API Change : DragAndDrop now puts default position of drag actor at pointer location . The original default offset from the pointer was ( 14 , - 20 ) . \n - Added ShaderProgramLoader for AssetManager . \n","Update changes for the DragAndDrop change ( # 4457 ) \n # 4286 changed default behavior , so it needs to be mentioned .",580
"gdx \ src \ com \ badlogic \ gdx \ assets \ loaders \ ShaderProgramLoader . java \n + / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n + * Copyright 2011 See AUTHORS file . \n + * \n + * Licensed under the Apache License , Version 2 . 0 ( the "" License "" ) ; \n + * you may not use this file except in compliance with the License . \n + * You may obtain a copy of the License at \n + * \n + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 \n + * \n + * Unless required by applicable law or agreed to in writing , software \n + * distributed under the License is distributed on an "" AS IS "" BASIS , \n + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . \n + * See the License for the specific language governing permissions and \n + * limitations under the License . \n + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / \n",Add license header ( # 4462 ) \n Oops !,580
"gdx \ src \ com \ badlogic \ gdx \ graphics \ g3d \ utils \ RenderContext . java \n - / * * Sets up the render context , must be matched with a call to { @ link # end ( ) } . Assumes that the OpenGL states are in their \n - * defaults . * / \n + / * * Sets up the render context , must be matched with a call to { @ link # end ( ) } . * / \n","Fix RenderContext Javadoc ( # 4458 ) \n * Fix RenderContext Javadoc \n The begin ( ) method states that it assumes default OpenGL state , but actually it enforces it , regardless of what the state was before calling begin ( ) . \n * Clarify docs \n * Shorten / clarify doc",580
"gdx \ src \ com \ badlogic \ gdx \ graphics \ glutils \ IndexBufferObjectSubData . java \n - * In IndexBufferObject wraps OpenGL ' s index buffer functionality to be used in conjunction with VBOs . This class can be \n - * seamlessly used with OpenGL ES 1 . x and 2 . 0 . \n - * < / p > \n - * \n - * < p > \n - * Uses indirect Buffers on Android 1 . 5 / 1 . 6 to fix GC invocation due to leaking PlatformAddress instances . \n + * IndexBufferObject wraps OpenGL ' s index buffer functionality to be used in conjunction with VBOs . \n - if ( bufferHandle = = 0 ) throw new GdxRuntimeException ( "" buuh "" ) ; \n + if ( bufferHandle = = 0 ) throw new GdxRuntimeException ( "" IndexBufferObject cannot be used after it has been disposed . "" ) ; \n",More useful error message and clean docs ( # 4372 ) \n See http : / / badlogicgames . com / forum / viewtopic . php ? f = 11 & t = 23869,580
gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ ImageButton . java \n - private void updateImage ( ) { \n + / * * Updates the Image with the appropriate Drawable from the style before it is drawn . * / \n + protected void updateImage ( ) { \n gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ ImageTextButton . java \n - private void updateImage ( ) { \n + / * * Updates the Image with the appropriate Drawable from the style before it is drawn . * / \n + protected void updateImage ( ) { \n,Make updateImage ( ) protected ( # 4694 ),580
gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ utils \ TextureRegionDrawable . java \n - setMinWidth ( region . getRegionWidth ( ) ) ; \n - setMinHeight ( region . getRegionHeight ( ) ) ; \n + if ( region ! = null ) { \n + setMinWidth ( region . getRegionWidth ( ) ) ; \n + setMinHeight ( region . getRegionHeight ( ) ) ; \n + } \n,Can set null region on TextureRegionDrawable ( # 4702 ),580
gdx \ src \ com \ badlogic \ gdx \ math \ WindowedMean . java \n - return last _ value = = values . length - 1 ? values [ 0 ] : values [ last _ value ] ; \n + return added _ values < values . length ? values [ 0 ] : values [ last _ value ] ; \n,Fix getOldest ( ) ( # 4735 ),580
backends \ gdx - backends - gwt \ src \ com \ badlogic \ gdx \ backends \ gwt \ emu \ com \ badlogic \ gdx \ graphics \ Pixmap . java \n + import com . badlogic . gdx . graphics . Pixmap . Filter ; \n - Blending blending ; \n + Blending blending = Blending . SourceOver ; \n + Filter filter = Filter . BiLinear ; \n + this . filter = filter ; \n + } \n + \n + / * * @ return the currently set { @ link Filter } * / \n + public Filter getFilter ( ) { \n + return filter ; \n gdx \ src \ com \ badlogic \ gdx \ graphics \ Pixmap . java \n + private Filter filter = Filter . BiLinear ; \n + this . filter = filter ; \n + \n + / * * @ return the currently set { @ link Filter } * / \n + public Filter getFilter ( ) { \n + return filter ; \n + } \n,Add getFilter and fix GWT getBlending ( # 4721 ),580
"gdx \ src \ com \ badlogic \ gdx \ math \ WindowedMean . java \n - return last _ value = = values . length - 1 ? values [ 0 ] : values [ last _ value + 1 ] ; \n + return last _ value = = values . length - 1 ? values [ 0 ] : values [ last _ value ] ; \n + \n + / * * @ return A new < code > float [ ] < / code > containing all values currently in the window of the stream , in order from oldest to \n + * latest . The length of the array is smaller than the window size if not enough data has been added . * / \n + public float [ ] getWindowValues ( ) { \n + float [ ] windowValues = new float [ added _ values ] ; \n + if ( hasEnoughData ( ) ) { \n + for ( int i = 0 ; i < windowValues . length ; i + + ) { \n + windowValues [ i ] = values [ ( i + last _ value ) % values . length ] ; \n + } \n + } else { \n + System . arraycopy ( values , 0 , windowValues , 0 , added _ values ) ; \n + } \n + return windowValues ; \n + } \n",Fix getOldest ( ) and add getWindowValues ( ) ( # 4728 ),580
"gdx \ src \ com \ badlogic \ gdx \ assets \ AssetManager . java \n + import com . badlogic . gdx . assets . loaders . CubemapLoader ; \n + import com . badlogic . gdx . graphics . Cubemap ; \n + setLoader ( Cubemap . class , new CubemapLoader ( resolver ) ) ; \n",Add CubemapLoader as one of the defaults ( # 4847 ),580
"CHANGES \n - API Change : ParticleEmitter getSprite , setSprite , getImagePath , setImagePath are now getSprites , setSprites , getImagePaths , setImagePaths . \n - Added support for 2d particles independant scale X and Y . \n - API Change : ParticleEmitter getScale , matchSize are now getScaleX / getScaleY , matchSizeX / matchSizeY . Added scaleSize ( float scaleX , float scaleY ) \n + - API Change : Added iconDropped ( ) callback to AndroidWallpaperListener . \n - Fix performance regression in LWJGL3 backend , use java . nio instead of BufferUtils . Those are intrinsics and quite a bit faster than BufferUtils on HotSpot . \n CONTRIBUTORS \n + cypherdare https : / / github . com / cypherdare \n",Add API change for AndroidWallpaperListener ( # 4884 ),580
gdx \ src \ com \ badlogic \ gdx \ assets \ loaders \ SkinLoader . java \n - Skin skin = new Skin ( atlas ) ; \n + Skin skin = generateSkin ( atlas ) ; \n + \n + / * * Override to allow subclasses of Skin to be loaded . \n + * @ param atlas The TextureAtlas that the skin will use . \n + * @ return A new Skin ( or subclass of Skin ) instance based on the provided TextureAtlas . * / \n + protected Skin generateSkin ( TextureAtlas atlas ) { \n + return new Skin ( atlas ) ; \n + } \n - } \n + } \n,Can use Skin subclasses with SkinLoader ( # 4291 ),580
"gdx \ src \ com \ badlogic \ gdx \ graphics \ g2d \ ParticleEffect . java \n - import java . util . HashMap ; \n + import com . badlogic . gdx . utils . ObjectMap ; \n - HashMap < String , Sprite > loadedSprites = new HashMap < String , Sprite > ( emitters . size ) ; \n + ObjectMap < String , Sprite > loadedSprites = new ObjectMap < String , Sprite > ( emitters . size ) ; \n",Replace HashMap with ObjectMap ( # 5133 ),580
"gdx \ src \ com \ badlogic \ gdx \ scenes \ scene2d \ ui \ SplitPane . java \n + boolean cursorOverHandle ; \n + \n + public boolean mouseMoved ( InputEvent event , float x , float y ) { \n + cursorOverHandle = handleBounds . contains ( x , y ) ; \n + return false ; \n + } \n + \n + public boolean isCursorOverHandle ( ) { \n + return cursorOverHandle ; \n + } \n",Add SplitPane . isCursorOverHandle ( ) ( # 5112 ),580
backends \ gdx - backend - lwjgl3 \ src \ com \ badlogic \ gdx \ backends \ lwjgl3 \ Lwjgl3Window . java \n + / * * \n + * Brings the window to front and sets input focus . The window should already be visible and not iconified . \n + * / \n + public void focusWindow ( ) { \n + GLFW . glfwFocusWindow ( windowHandle ) ; \n + } \n + \n,Add focusWindow ( ) to Lwjgl3Window ( # 5100 ),580
pom . xml \n - < version > 5 . 0 . 0 < / version > \n + < version > 5 . 1 . 0 < / version > \n,Bump dependency - check - maven from 5 . 0 . 0 to 5 . 1 . 0 \n Bumps [ dependency - check - maven ] ( https : / / github . com / jeremylong / DependencyCheck ) from 5 . 0 . 0 to 5 . 1 . 0 . \n - [ Release notes ] ( https : / / github . com / jeremylong / DependencyCheck / releases ) \n - [ Changelog ] ( https : / / github . com / jeremylong / DependencyCheck / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jeremylong / DependencyCheck / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < junit5 . version > 5 . 4 . 2 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 0 < / junit5 . version > \n,Bump junit5 . version from 5 . 4 . 2 to 5 . 5 . 0 \n Bumps ` junit5 . version ` from 5 . 4 . 2 to 5 . 5 . 0 . \n Updates ` junit - bom ` from 5 . 4 . 2 to 5 . 5 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 4 . 2 . . . r5 . 5 . 0 ) \n Updates ` junit - vintage - engine ` from 5 . 4 . 2 to 5 . 5 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 4 . 2 . . . r5 . 5 . 0 ) \n Updates ` junit - jupiter - engine ` from 5 . 4 . 2 to 5 . 5 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 4 . 2 . . . r5 . 5 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < version > 2 . 4 . 0 < / version > \n + < version > 2 . 5 . 0 < / version > \n,Bump sphinx - maven - plugin from 2 . 4 . 0 to 2 . 5 . 0 ( # 2820 ) \n Bumps [ sphinx - maven - plugin ] ( https : / / github . com / trustin / sphinx - maven - plugin ) from 2 . 4 . 0 to 2 . 5 . 0 . \n - [ Release notes ] ( https : / / github . com / trustin / sphinx - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / trustin / sphinx - maven - plugin / compare / sphinx - maven - plugin - 2 . 4 . 0 . . . sphinx - maven - plugin - 2 . 5 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
. github \ settings . xml \n - < mirrors > \n + < ! - - mirrors > \n - < / mirrors > \n + < / mirrors - - > \n dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 9 . 10 < / jackson . version > \n + < jackson . version > 2 . 10 . 0 < / jackson . version > \n,Bump jackson - bom from 2 . 9 . 10 to 2 . 10 . 0 ( # 2944 ) \n * Bump jackson - bom from 2 . 9 . 10 to 2 . 10 . 0 \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 9 . 10 to 2 . 10 . 0 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 9 . 10 . . . jackson - bom - 2 . 10 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Disable Maven Central mirror on GitHub Actions,584
dropwizard - bom \ pom . xml \n - < version > 2 . 9 . 0 < / version > \n + < version > 2 . 10 . 0 < / version > \n,Bump checker - qual from 2 . 9 . 0 to 2 . 10 . 0 ( # 2865 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 9 . 0 to 2 . 10 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 9 . 0 . . . checker - framework - 2 . 10 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 2 . 10 . 1 < / checker - qual . version > \n + < checker - qual . version > 2 . 11 . 0 < / checker - qual . version > \n,Bump checker - qual from 2 . 10 . 1 to 2 . 11 . 0 ( # 2902 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 10 . 1 to 2 . 11 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 10 . 1 . . . checker - framework - 2 . 11 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < mockito . version > 3 . 0 . 0 < / mockito . version > \n + < mockito . version > 3 . 1 . 0 < / mockito . version > \n,Bump mockito . version from 3 . 0 . 0 to 3 . 1 . 0 ( # 2957 ) \n Bumps ` mockito . version ` from 3 . 0 . 0 to 3 . 1 . 0 . \n Updates ` mockito - core ` from 3 . 0 . 0 to 3 . 1 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 0 . 0 . . . v3 . 1 . 0 ) \n Updates ` mockito - junit - jupiter ` from 3 . 0 . 0 to 3 . 1 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 0 . 0 . . . v3 . 1 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 2 . 11 . 0 < / checker - qual . version > \n + < checker - qual . version > 2 . 11 . 1 < / checker - qual . version > \n,Bump checker - qual from 2 . 11 . 0 to 2 . 11 . 1 ( # 2955 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 11 . 0 to 2 . 11 . 1 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 11 . 0 . . . checker - framework - 2 . 11 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < mockito . version > 3 . 1 . 0 < / mockito . version > \n + < mockito . version > 3 . 2 . 0 < / mockito . version > \n,Bump mockito . version from 3 . 1 . 0 to 3 . 2 . 0 ( # 3044 ) \n Bumps ` mockito . version ` from 3 . 1 . 0 to 3 . 2 . 0 . \n Updates ` mockito - core ` from 3 . 1 . 0 to 3 . 2 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 1 . 0 . . . v3 . 2 . 0 ) \n Updates ` mockito - junit - jupiter ` from 3 . 1 . 0 to 3 . 2 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 1 . 0 . . . v3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jmhGradleVersion = "" 0 . 5 . 0 - rc - 2 "" \n + ext . jmhGradleVersion = "" 0 . 5 . 0 "" \n",Bump jmh - gradle - plugin from 0 . 5 . 0 - rc - 2 to 0 . 5 . 0 ( # 6733 ) \n Bumps jmh - gradle - plugin from 0 . 5 . 0 - rc - 2 to 0 . 5 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . guavaVersion = "" 28 . 0 - jre "" \n + ext . guavaVersion = "" 28 . 1 - jre "" \n",Bump guava from 28 . 0 - jre to 28 . 1 - jre ( # 6734 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 0 - jre to 28 . 1 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . bndVersion = "" 4 . 2 . 0 "" \n + ext . bndVersion = "" 4 . 3 . 1 "" \n",Bump biz . aQute . bnd . gradle from 4 . 2 . 0 to 4 . 3 . 1 ( # 6738 ) \n Bumps biz . aQute . bnd . gradle from 4 . 2 . 0 to 4 . 3 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 0 . 0 "" \n + ext . mockitoVersion = "" 3 . 2 . 0 "" \n",Bump mockito - core from 3 . 0 . 0 to 3 . 2 . 0 ( # 6737 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 0 . 0 to 3 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 0 . 0 . . . v3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 5 . 2 "" \n + ext . jfrogExtractorVersion = "" 4 . 11 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 5 . 2 to 4 . 11 . 0 ( # 6736 ) \n Bumps build - info - extractor - gradle from 4 . 5 . 2 to 4 . 11 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . bintrayVersion = "" 1 . 7 . 3 "" \n + ext . bintrayVersion = "" 1 . 8 . 4 "" \n",Bump gradle - bintray - plugin from 1 . 7 . 3 to 1 . 8 . 4 ( # 6735 ) \n Bumps gradle - bintray - plugin from 1 . 7 . 3 to 1 . 8 . 4 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < commons - text . version > 1 . 7 < / commons - text . version > \n + < commons - text . version > 1 . 8 < / commons - text . version > \n,Bump commons - text from 1 . 7 to 1 . 8 ( # 2905 ) \n Bumps commons - text from 1 . 7 to 1 . 8 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 0 . 0 < / checker - qual . version > \n + < checker - qual . version > 3 . 0 . 1 < / checker - qual . version > \n,Bump checker - qual from 3 . 0 . 0 to 3 . 0 . 1 ( # 3048 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 0 . 0 to 3 . 0 . 1 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 0 . 0 . . . checker - framework - 3 . 0 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 2 . 1 \n + Sphinx = = 2 . 2 . 2 \n,Bump sphinx from 2 . 2 . 1 to 2 . 2 . 2 in / docs ( # 3049 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 2 . 1 to 2 . 2 . 2 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 2 . 1 . . . v2 . 2 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < error _ prone _ annotations . version > 2 . 3 . 3 < / error _ prone _ annotations . version > \n + < error _ prone _ annotations . version > 2 . 3 . 4 < / error _ prone _ annotations . version > \n,Bump error _ prone _ annotations from 2 . 3 . 3 to 2 . 3 . 4 ( # 3046 ) \n Bumps [ error _ prone _ annotations ] ( https : / / github . com / google / error - prone ) from 2 . 3 . 3 to 2 . 3 . 4 . \n - [ Release notes ] ( https : / / github . com / google / error - prone / releases ) \n - [ Commits ] ( https : / / github . com / google / error - prone / compare / v2 . 3 . 3 . . . v2 . 3 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < error _ prone . version > 2 . 3 . 3 < / error _ prone . version > \n + < error _ prone . version > 2 . 3 . 4 < / error _ prone . version > \n,Bump error _ prone _ core from 2 . 3 . 3 to 2 . 3 . 4 ( # 3047 ) \n Bumps [ error _ prone _ core ] ( https : / / github . com / google / error - prone ) from 2 . 3 . 3 to 2 . 3 . 4 . \n - [ Release notes ] ( https : / / github . com / google / error - prone / releases ) \n - [ Commits ] ( https : / / github . com / google / error - prone / compare / v2 . 3 . 3 . . . v2 . 3 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 2 . 8 . 2 < / version > \n + < version > 2 . 9 . 0 < / version > \n,Bump checker - qual from 2 . 8 . 2 to 2 . 9 . 0 \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 8 . 2 to 2 . 9 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 8 . 2 . . . checker - framework - 2 . 9 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 6 < / version > \n + < version > 1 . 7 < / version > \n,Bump commons - text from 1 . 6 to 1 . 7 \n Bumps commons - text from 1 . 6 to 1 . 7 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 9 . 1 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 10 . 0 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 9 . 1 to 3 . 10 . 0 \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 9 . 1 to 3 . 10 . 0 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 2 . 10 . 2 < / version > \n + < version > 2 . 10 . 3 < / version > \n,Bump joda - time from 2 . 10 . 2 to 2 . 10 . 3 \n Bumps [ joda - time ] ( https : / / github . com / JodaOrg / joda - time ) from 2 . 10 . 2 to 2 . 10 . 3 . \n - [ Release notes ] ( https : / / github . com / JodaOrg / joda - time / releases ) \n - [ Changelog ] ( https : / / github . com / JodaOrg / joda - time / blob / master / RELEASE - NOTES . txt ) \n - [ Commits ] ( https : / / github . com / JodaOrg / joda - time / compare / v2 . 10 . 2 . . . v2 . 10 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 9 . 16 < / version > \n + < version > 1 . 10 . 0 < / version > \n,Bump byte - buddy from 1 . 9 . 16 to 1 . 10 . 0 \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 9 . 16 to 1 . 10 . 0 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 9 . 16 . . . byte - buddy - 1 . 10 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < assertj . version > 3 . 13 . 1 < / assertj . version > \n + < assertj . version > 3 . 13 . 2 < / assertj . version > \n,Bump assertj - core from 3 . 13 . 1 to 3 . 13 . 2 ( # 2867 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 13 . 1 to 3 . 13 . 2 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 13 . 1 . . . assertj - core - 3 . 13 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 1 . 0 < / version > \n + < version > 3 . 2 . 0 < / version > \n pom . xml \n - < maven - source - plugin . version > 3 . 1 . 0 < / maven - source - plugin . version > \n + < maven - source - plugin . version > 3 . 2 . 0 < / maven - source - plugin . version > \n,Bump maven - source - plugin from 3 . 1 . 0 to 3 . 2 . 0 ( # 3011 ) \n Bumps [ maven - source - plugin ] ( https : / / github . com / apache / maven - source - plugin ) from 3 . 1 . 0 to 3 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / apache / maven - source - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - source - plugin / compare / maven - source - plugin - 3 . 1 . 0 . . . maven - source - plugin - 3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 1 . 2 < / version > \n + < version > 3 . 2 . 0 < / version > \n pom . xml \n - < maven - jar - plugin . version > 3 . 1 . 2 < / maven - jar - plugin . version > \n + < maven - jar - plugin . version > 3 . 2 . 0 < / maven - jar - plugin . version > \n,Bump maven - jar - plugin from 3 . 1 . 2 to 3 . 2 . 0 ( # 3010 ) \n Bumps [ maven - jar - plugin ] ( https : / / github . com / apache / maven - jar - plugin ) from 3 . 1 . 2 to 3 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / apache / maven - jar - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - jar - plugin / compare / maven - jar - plugin - 3 . 1 . 2 . . . maven - jar - plugin - 3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 2 . 11 . 1 < / checker - qual . version > \n + < checker - qual . version > 3 . 0 . 0 < / checker - qual . version > \n,Bump checker - qual from 2 . 11 . 1 to 3 . 0 . 0 ( # 3012 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 11 . 1 to 3 . 0 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 11 . 1 . . . checker - framework - 3 . 0 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - benchmarks \ pom . xml \n - < jmh . version > 1 . 21 < / jmh . version > \n + < jmh . version > 1 . 22 < / jmh . version > \n,Bump jmh . version from 1 . 21 to 1 . 22 ( # 3008 ) \n Bumps ` jmh . version ` from 1 . 21 to 1 . 22 . \n Updates ` jmh - core ` from 1 . 21 to 1 . 22 \n Updates ` jmh - generator - annprocess ` from 1 . 21 to 1 . 22 \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < slf4j . version > 1 . 7 . 28 < / slf4j . version > \n + < slf4j . version > 1 . 7 . 29 < / slf4j . version > \n,Bump slf4j . version from 1 . 7 . 28 to 1 . 7 . 29 ( # 3009 ) \n Bumps ` slf4j . version ` from 1 . 7 . 28 to 1 . 7 . 29 . \n Updates ` slf4j - api ` from 1 . 7 . 28 to 1 . 7 . 29 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / commits ) \n Updates ` jul - to - slf4j ` from 1 . 7 . 28 to 1 . 7 . 29 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / commits ) \n Updates ` log4j - over - slf4j ` from 1 . 7 . 28 to 1 . 7 . 29 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / commits ) \n Updates ` jcl - over - slf4j ` from 1 . 7 . 28 to 1 . 7 . 29 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 2 . 7 . 0 < / version > \n + < version > 2 . 8 . 0 < / version > \n,Bump caffeine from 2 . 7 . 0 to 2 . 8 . 0 ( # 2868 ) \n Bumps [ caffeine ] ( https : / / github . com / ben - manes / caffeine ) from 2 . 7 . 0 to 2 . 8 . 0 . \n - [ Release notes ] ( https : / / github . com / ben - manes / caffeine / releases ) \n - [ Commits ] ( https : / / github . com / ben - manes / caffeine / compare / v2 . 7 . 0 . . . v2 . 8 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < javassist . version > 3 . 25 . 0 - GA < / javassist . version > \n + < javassist . version > 3 . 26 . 0 - GA < / javassist . version > \n,Bump javassist from 3 . 25 . 0 - GA to 3 . 26 . 0 - GA ( # 2961 ) \n Bumps [ javassist ] ( https : / / github . com / jboss - javassist / javassist ) from 3 . 25 . 0 - GA to 3 . 26 . 0 - GA . \n - [ Release notes ] ( https : / / github . com / jboss - javassist / javassist / releases ) \n - [ Commits ] ( https : / / github . com / jboss - javassist / javassist / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 20 . v20190813 < / jetty . version > \n + < jetty . version > 9 . 4 . 21 . v20190926 < / jetty . version > \n dropwizard - jetty \ src \ test \ java \ io \ dropwizard \ jetty \ setup \ ServletEnvironmentTest . java \n - final Filter filter = mock ( Filter . class ) ; \n + final Filter filter = new WelcomeFilter ( ) ; \n - assertThat ( holder . getValue ( ) . getFilter ( ) ) \n - . isEqualTo ( filter ) ; \n + assertThat ( holder . getValue ( ) ) . hasFieldOrPropertyWithValue ( "" _ instance "" , filter ) ; \n",Bump jetty . version from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 ( # 2956 ) \n * Bump jetty . version from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 \n Bumps ` jetty . version ` from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 . \n Updates ` jetty - bom ` from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 20 . v20190813 . . . jetty - 9 . 4 . 21 . v20190926 ) \n Updates ` jetty - servlet ` from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 20 . v20190813 . . . jetty - 9 . 4 . 21 . v20190926 ) \n Updates ` jetty - http ` from 9 . 4 . 20 . v20190813 to 9 . 4 . 21 . v20190926 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 20 . v20190813 . . . jetty - 9 . 4 . 21 . v20190926 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Fix ServletEnvironmentTest \n The ` filter ` field of ` FilterHolder ` is only initialized after ` FilterHolder # initialize ( ) ` has been called .,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 9 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 10 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 9 . Final to 5 . 4 . 10 . Final ( # 3052 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 9 . Final to 5 . 4 . 10 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 9 . . . 5 . 4 . 10 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < jersey . version > 2 . 28 < / jersey . version > \n + < jersey . version > 2 . 29 < / jersey . version > \n,Bump jersey . version from 2 . 28 to 2 . 29 ( # 2813 ) \n Bumps ` jersey . version ` from 2 . 28 to 2 . 29 . \n Updates ` jersey - bom ` from 2 . 28 to 2 . 29 \n Updates ` jersey - hk2 ` from 2 . 28 to 2 . 29 \n Updates ` jersey - test - framework - core ` from 2 . 28 to 2 . 29 \n Updates ` jersey - test - framework - provider - grizzly2 ` from 2 . 28 to 2 . 29 \n Updates ` jersey - test - framework - provider - inmemory ` from 2 . 28 to 2 . 29 \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Closes # 2817,584
dropwizard - bom \ pom . xml \n - < slf4j . version > 1 . 7 . 26 < / slf4j . version > \n + < slf4j . version > 1 . 7 . 27 < / slf4j . version > \n,Bump slf4j . version from 1 . 7 . 26 to 1 . 7 . 27 ( # 2873 ) \n Bumps ` slf4j . version ` from 1 . 7 . 26 to 1 . 7 . 27 . \n Updates ` slf4j - api ` from 1 . 7 . 26 to 1 . 7 . 27 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 26 . . . v _ 1 . 7 . 27 ) \n Updates ` jul - to - slf4j ` from 1 . 7 . 26 to 1 . 7 . 27 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 26 . . . v _ 1 . 7 . 27 ) \n Updates ` log4j - over - slf4j ` from 1 . 7 . 26 to 1 . 7 . 27 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 26 . . . v _ 1 . 7 . 27 ) \n Updates ` jcl - over - slf4j ` from 1 . 7 . 26 to 1 . 7 . 27 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 26 . . . v _ 1 . 7 . 27 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < jdbi3 . version > 3 . 9 . 0 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 9 . 1 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 9 . 0 to 3 . 9 . 1 ( # 2872 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 9 . 0 to 3 . 9 . 1 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 9 . 0 . . . v3 . 9 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < objenesis . version > 3 . 0 . 1 < / objenesis . version > \n + < objenesis . version > 3 . 1 < / objenesis . version > \n,Bump objenesis from 3 . 0 . 1 to 3 . 1 ( # 2968 ) \n Bumps [ objenesis ] ( https : / / github . com / easymock / objenesis ) from 3 . 0 . 1 to 3 . 1 . \n - [ Release notes ] ( https : / / github . com / easymock / objenesis / releases ) \n - [ Commits ] ( https : / / github . com / easymock / objenesis / compare / 3 . 0 . 1 . . . 3 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 0 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 1 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 0 to 3 . 8 . 1 ( # 3016 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 0 to 3 . 8 . 1 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 1 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / liquibase - parent - 3 . 8 . 0 . . . v3 . 8 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 1 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 2 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 1 to 4 . 1 . 2 ( # 3055 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 1 to 4 . 1 . 2 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 1 . . . v4 . 1 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 4 . 2 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 0 < / junit5 . version > \n,Bump junit - jupiter from 5 . 4 . 2 to 5 . 5 . 0 ( # 2842 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 4 . 2 to 5 . 5 . 0 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 4 . 2 . . . r5 . 5 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 3 . 6 . 3 < / version > \n + < version > 3 . 7 . 0 < / version > \n,Bump liquibase - core from 3 . 6 . 3 to 3 . 7 . 0 ( # 2845 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 6 . 3 to 3 . 7 . 0 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / liquibase - parent - 3 . 7 . 0 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / liquibase - parent - 3 . 6 . 3 . . . liquibase - parent - 3 . 7 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 5 . 0 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 1 < / junit5 . version > \n,Bump junit - jupiter from 5 . 5 . 0 to 5 . 5 . 1 ( # 2850 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 5 . 0 to 5 . 5 . 1 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 0 . . . r5 . 5 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 9 . 14 < / version > \n + < version > 1 . 9 . 15 < / version > \n,Bump byte - buddy from 1 . 9 . 14 to 1 . 9 . 15 ( # 2849 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 9 . 14 to 1 . 9 . 15 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 9 . 14 . . . byte - buddy - 1 . 9 . 15 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < junit5 . version > 5 . 5 . 0 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 1 < / junit5 . version > \n,Bump junit5 . version from 5 . 5 . 0 to 5 . 5 . 1 ( # 2848 ) \n Bumps ` junit5 . version ` from 5 . 5 . 0 to 5 . 5 . 1 . \n Updates ` junit - bom ` from 5 . 5 . 0 to 5 . 5 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 0 . . . r5 . 5 . 1 ) \n Updates ` junit - vintage - engine ` from 5 . 5 . 0 to 5 . 5 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 0 . . . r5 . 5 . 1 ) \n Updates ` junit - jupiter - engine ` from 5 . 5 . 0 to 5 . 5 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 0 . . . r5 . 5 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < jdbi3 . version > 3 . 8 . 2 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 9 . 0 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 8 . 2 to 3 . 9 . 0 ( # 2855 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 8 . 2 to 3 . 9 . 0 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 8 . 2 . . . v3 . 9 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < version > 2 . 5 . 0 < / version > \n + < version > 2 . 6 . 0 < / version > \n,Bump sphinx - maven - plugin from 2 . 5 . 0 to 2 . 6 . 0 \n Bumps [ sphinx - maven - plugin ] ( https : / / github . com / trustin / sphinx - maven - plugin ) from 2 . 5 . 0 to 2 . 6 . 0 . \n - [ Release notes ] ( https : / / github . com / trustin / sphinx - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / trustin / sphinx - maven - plugin / compare / sphinx - maven - plugin - 2 . 5 . 0 . . . sphinx - maven - plugin - 2 . 6 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < assertj . version > 3 . 12 . 2 < / assertj . version > \n + < assertj . version > 3 . 13 . 0 < / assertj . version > \n,Bump assertj - core from 3 . 12 . 2 to 3 . 13 . 0 ( # 2861 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 12 . 2 to 3 . 13 . 0 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 12 . 2 . . . assertj - core - 3 . 13 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 9 . 15 < / version > \n + < version > 1 . 9 . 16 < / version > \n,Bump byte - buddy from 1 . 9 . 15 to 1 . 9 . 16 ( # 2860 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 9 . 15 to 1 . 9 . 16 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 9 . 15 . . . byte - buddy - 1 . 9 . 16 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 7 . 1 < / version > \n + < version > 3 . 8 . 2 < / version > \n pom . xml \n - < version > 3 . 7 . 1 < / version > \n + < version > 3 . 8 . 2 < / version > \n,Bump maven - site - plugin from 3 . 7 . 1 to 3 . 8 . 2 ( # 2858 ) \n Bumps [ maven - site - plugin ] ( https : / / github . com / apache / maven - site - plugin ) from 3 . 7 . 1 to 3 . 8 . 2 . \n - [ Release notes ] ( https : / / github . com / apache / maven - site - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - site - plugin / compare / maven - site - plugin - 3 . 7 . 1 . . . maven - site - plugin - 3 . 8 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < assertj . version > 3 . 13 . 0 < / assertj . version > \n + < assertj . version > 3 . 13 . 1 < / assertj . version > \n,Bump assertj - core from 3 . 13 . 0 to 3 . 13 . 1 ( # 2862 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 13 . 0 to 3 . 13 . 1 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 13 . 0 . . . assertj - core - 3 . 13 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 5 . 4 . 3 . Final < / version > \n + < version > 5 . 4 . 4 . Final < / version > \n,Bump hibernate - core from 5 . 4 . 3 . Final to 5 . 4 . 4 . Final ( # 2863 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 3 . Final to 5 . 4 . 4 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 3 . . . 5 . 4 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < version > 3 . 0 . 1 < / version > \n + < version > 3 . 1 . 1 < / version > \n,Bump maven - javadoc - plugin from 3 . 0 . 1 to 3 . 1 . 1 \n Bumps [ maven - javadoc - plugin ] ( https : / / github . com / apache / maven - javadoc - plugin ) from 3 . 0 . 1 to 3 . 1 . 1 . \n - [ Release notes ] ( https : / / github . com / apache / maven - javadoc - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - javadoc - plugin / compare / maven - javadoc - plugin - 3 . 0 . 1 . . . maven - javadoc - plugin - 3 . 1 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < pgpverify - maven - plugin . version > 1 . 4 . 0 < / pgpverify - maven - plugin . version > \n + < pgpverify - maven - plugin . version > 1 . 5 . 0 < / pgpverify - maven - plugin . version > \n,Bump pgpverify - maven - plugin from 1 . 4 . 0 to 1 . 5 . 0 ( # 3054 ) \n Bumps [ pgpverify - maven - plugin ] ( https : / / github . com / s4u / pgpverify - maven - plugin ) from 1 . 4 . 0 to 1 . 5 . 0 . \n - [ Release notes ] ( https : / / github . com / s4u / pgpverify - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / s4u / pgpverify - maven - plugin / compare / pgpverify - maven - plugin - 1 . 4 . 0 . . . pgpverify - maven - plugin - 1 . 5 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 2 . 3 . 28 < / version > \n + < version > 2 . 3 . 29 < / version > \n,Bump freemarker from 2 . 3 . 28 to 2 . 3 . 29 ( # 2887 ) \n Bumps freemarker from 2 . 3 . 28 to 2 . 3 . 29 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 1 . 2 \n + Sphinx = = 2 . 2 . 0 \n,Bump sphinx from 2 . 1 . 2 to 2 . 2 . 0 in / docs ( # 2886 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 1 . 2 to 2 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 1 . 2 . . . v2 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 9 . 0 . 22 < / version > \n + < version > 9 . 0 . 24 < / version > \n,Bump tomcat - jdbc from 9 . 0 . 22 to 9 . 0 . 24 ( # 2885 ) \n Bumps tomcat - jdbc from 9 . 0 . 22 to 9 . 0 . 24 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 3 . 7 . 0 < / version > \n + < version > 3 . 8 . 0 < / version > \n,Bump liquibase - core from 3 . 7 . 0 to 3 . 8 . 0 ( # 2890 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 7 . 0 to 3 . 8 . 0 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / liquibase - parent - 3 . 8 . 0 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / liquibase - parent - 3 . 7 . 0 . . . liquibase - parent - 3 . 8 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - archetypes \ pom . xml \n - < version > 3 . 1 . 1 < / version > \n + < version > 3 . 1 . 2 < / version > \n,Bump archetype - packaging from 3 . 1 . 1 to 3 . 1 . 2 ( # 2896 ) \n Bumps [ archetype - packaging ] ( https : / / github . com / apache / maven - archetype ) from 3 . 1 . 1 to 3 . 1 . 2 . \n - [ Release notes ] ( https : / / github . com / apache / maven - archetype / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - archetype / compare / maven - archetype - 3 . 1 . 1 . . . maven - archetype - 3 . 1 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - archetypes \ pom . xml \n - < version > 3 . 1 . 1 < / version > \n + < version > 3 . 1 . 2 < / version > \n,Bump maven - archetype - plugin from 3 . 1 . 1 to 3 . 1 . 2 ( # 2895 ) \n Bumps [ maven - archetype - plugin ] ( https : / / github . com / apache / maven - archetype ) from 3 . 1 . 1 to 3 . 1 . 2 . \n - [ Release notes ] ( https : / / github . com / apache / maven - archetype / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - archetype / compare / maven - archetype - 3 . 1 . 1 . . . maven - archetype - 3 . 1 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 2 . 10 . 0 < / version > \n + < version > 2 . 10 . 1 < / version > \n,Bump checker - qual from 2 . 10 . 0 to 2 . 10 . 1 ( # 2894 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 2 . 10 . 0 to 2 . 10 . 1 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 2 . 10 . 0 . . . checker - framework - 2 . 10 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < guava . version > 28 . 0 - jre < / guava . version > \n + < guava . version > 28 . 1 - jre < / guava . version > \n,Bump guava from 28 . 0 - jre to 28 . 1 - jre ( # 2900 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 0 - jre to 28 . 1 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < mockito . version > 2 . 28 . 2 < / mockito . version > \n + < mockito . version > 3 . 0 . 0 < / mockito . version > \n,Bump mockito . version from 2 . 28 . 2 to 3 . 0 . 0 \n Bumps ` mockito . version ` from 2 . 28 . 2 to 3 . 0 . 0 . \n Updates ` mockito - core ` from 2 . 28 . 2 to 3 . 0 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v2 . 28 . 2 . . . v3 . 0 . 0 ) \n Updates ` mockito - junit - jupiter ` from 2 . 28 . 2 to 3 . 0 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v2 . 28 . 2 . . . v3 . 0 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 9 . 13 < / version > \n + < version > 1 . 9 . 14 < / version > \n,Bump byte - buddy from 1 . 9 . 13 to 1 . 9 . 14 \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 9 . 13 to 1 . 9 . 14 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 9 . 13 . . . byte - buddy - 1 . 9 . 14 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 5 . 1 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 2 < / junit5 . version > \n,Bump junit - jupiter from 5 . 5 . 1 to 5 . 5 . 2 ( # 2911 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 5 . 1 to 5 . 5 . 2 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 1 . . . r5 . 5 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jakarta . el . version > 3 . 0 . 2 < / jakarta . el . version > \n + < jakarta . el . version > 3 . 0 . 3 < / jakarta . el . version > \n,Bump jakarta . el from 3 . 0 . 2 to 3 . 0 . 3 ( # 2912 ) \n Bumps [ jakarta . el ] ( https : / / github . com / eclipse - ee4j / el - ri ) from 3 . 0 . 2 to 3 . 0 . 3 . \n - [ Release notes ] ( https : / / github . com / eclipse - ee4j / el - ri / releases ) \n - [ Commits ] ( https : / / github . com / eclipse - ee4j / el - ri / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < junit5 . version > 5 . 5 . 1 < / junit5 . version > \n + < junit5 . version > 5 . 5 . 2 < / junit5 . version > \n,Bump junit5 . version from 5 . 5 . 1 to 5 . 5 . 2 ( # 2910 ) \n Bumps ` junit5 . version ` from 5 . 5 . 1 to 5 . 5 . 2 . \n Updates ` junit - bom ` from 5 . 5 . 1 to 5 . 5 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 1 . . . r5 . 5 . 2 ) \n Updates ` junit - vintage - engine ` from 5 . 5 . 1 to 5 . 5 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 1 . . . r5 . 5 . 2 ) \n Updates ` junit - jupiter - engine ` from 5 . 5 . 1 to 5 . 5 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 1 . . . r5 . 5 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < maven - invoker - plugin . version > 3 . 2 . 0 < / maven - invoker - plugin . version > \n + < maven - invoker - plugin . version > 3 . 2 . 1 < / maven - invoker - plugin . version > \n,Bump maven - invoker - plugin from 3 . 2 . 0 to 3 . 2 . 1 ( # 2920 ) \n Bumps [ maven - invoker - plugin ] ( https : / / github . com / apache / maven - invoker - plugin ) from 3 . 2 . 0 to 3 . 2 . 1 . \n - [ Release notes ] ( https : / / github . com / apache / maven - invoker - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - invoker - plugin / compare / maven - invoker - plugin - 3 . 2 . 0 . . . maven - invoker - plugin - 3 . 2 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < bcprov - jdk15on . version > 1 . 62 < / bcprov - jdk15on . version > \n + < bcprov - jdk15on . version > 1 . 63 < / bcprov - jdk15on . version > \n,Bump bcprov - jdk15on from 1 . 62 to 1 . 63 \n Bumps [ bcprov - jdk15on ] ( https : / / github . com / bcgit / bc - java ) from 1 . 62 to 1 . 63 . \n - [ Release notes ] ( https : / / github . com / bcgit / bc - java / releases ) \n - [ Changelog ] ( https : / / github . com / bcgit / bc - java / blob / master / docs / releasenotes . html ) \n - [ Commits ] ( https : / / github . com / bcgit / bc - java / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n + < jakarta . annotation - api . version > 1 . 3 . 5 < / jakarta . annotation - api . version > \n - < jersey . version > 2 . 29 < / jersey . version > \n + < jersey . version > 2 . 29 . 1 < / jersey . version > \n + < dependency > \n + < groupId > jakarta . annotation < / groupId > \n + < artifactId > jakarta . annotation - api < / artifactId > \n + < version > $ { jakarta . annotation - api . version } < / version > \n + < / dependency > \n,Bump jersey - bom from 2 . 29 to 2 . 29 . 1 ( # 2916 ) \n * Bump jersey - bom from 2 . 29 to 2 . 29 . 1 \n Bumps jersey - bom from 2 . 29 to 2 . 29 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Add jakarta . annotation : jakarta . annotation - api to dependencyManagement,584
dropwizard - dependencies \ pom . xml \n - < logback - throttling - appender . version > 1 . 0 . 1 < / logback - throttling - appender . version > \n + < logback - throttling - appender . version > 1 . 1 . 0 < / logback - throttling - appender . version > \n,Bump logback - throttling - appender from 1 . 0 . 1 to 1 . 1 . 0 \n Bumps [ logback - throttling - appender ] ( https : / / github . com / dropwizard / logback - throttling - appender ) from 1 . 0 . 1 to 1 . 1 . 0 . \n - [ Release notes ] ( https : / / github . com / dropwizard / logback - throttling - appender / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / logback - throttling - appender / compare / logback - throttling - appender - 1 . 0 . 1 . . . logback - throttling - appender - 1 . 1 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 10 . 0 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 10 . 1 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 10 . 0 to 3 . 10 . 1 \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 10 . 0 to 3 . 10 . 1 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 10 . 0 . . . v3 . 10 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 24 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 26 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 24 to 9 . 0 . 26 \n Bumps tomcat - jdbc from 9 . 0 . 24 to 9 . 0 . 26 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < joda - time . version > 2 . 10 . 3 < / joda - time . version > \n + < joda - time . version > 2 . 10 . 4 < / joda - time . version > \n,Bump joda - time from 2 . 10 . 3 to 2 . 10 . 4 ( # 2937 ) \n Bumps [ joda - time ] ( https : / / github . com / JodaOrg / joda - time ) from 2 . 10 . 3 to 2 . 10 . 4 . \n - [ Release notes ] ( https : / / github . com / JodaOrg / joda - time / releases ) \n - [ Changelog ] ( https : / / github . com / JodaOrg / joda - time / blob / master / RELEASE - NOTES . txt ) \n - [ Commits ] ( https : / / github . com / JodaOrg / joda - time / compare / v2 . 10 . 3 . . . v2 . 10 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 4 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 6 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 4 . Final to 5 . 4 . 6 . Final ( # 2952 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 4 . Final to 5 . 4 . 6 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 4 . . . 5 . 4 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 9 . 0 . 21 < / version > \n + < version > 9 . 0 . 22 < / version > \n,Bump tomcat - jdbc from 9 . 0 . 21 to 9 . 0 . 22 \n Bumps tomcat - jdbc from 9 . 0 . 21 to 9 . 0 . 22 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < httpclient . version > 4 . 5 . 9 < / httpclient . version > \n + < httpclient . version > 4 . 5 . 10 < / httpclient . version > \n,Bump httpclient from 4 . 5 . 9 to 4 . 5 . 10 ( # 2914 ) \n Bumps httpclient from 4 . 5 . 9 to 4 . 5 . 10 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 2 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 3 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 2 to 1 . 10 . 3 ( # 3018 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 2 to 1 . 10 . 3 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 2 . . . byte - buddy - 1 . 10 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 10 . 0 < / jackson . version > \n + < jackson . version > 2 . 10 . 1 < / jackson . version > \n,Bump jackson - bom from 2 . 10 . 0 to 2 . 10 . 1 ( # 3019 ) \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 10 . 0 to 2 . 10 . 1 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 10 . 0 . . . jackson - bom - 2 . 10 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 26 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 27 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 26 to 9 . 0 . 27 ( # 2979 ) \n Bumps tomcat - jdbc from 9 . 0 . 26 to 9 . 0 . 27 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jacoco - maven - plugin . version > 0 . 8 . 4 < / jacoco - maven - plugin . version > \n + < jacoco - maven - plugin . version > 0 . 8 . 5 < / jacoco - maven - plugin . version > \n dropwizard - example \ pom . xml \n - < version > 0 . 8 . 4 < / version > \n + < version > 0 . 8 . 5 < / version > \n,Bump jacoco - maven - plugin from 0 . 8 . 4 to 0 . 8 . 5 ( # 2980 ) \n Bumps [ jacoco - maven - plugin ] ( https : / / github . com / jacoco / jacoco ) from 0 . 8 . 4 to 0 . 8 . 5 . \n - [ Release notes ] ( https : / / github . com / jacoco / jacoco / releases ) \n - [ Commits ] ( https : / / github . com / jacoco / jacoco / compare / v0 . 8 . 4 . . . v0 . 8 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 1 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 2 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 1 to 1 . 10 . 2 \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 1 to 1 . 10 . 2 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 1 . . . byte - buddy - 1 . 10 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < classmate . version > 1 . 5 . 0 < / classmate . version > \n + < classmate . version > 1 . 5 . 1 < / classmate . version > \n,Bump classmate from 1 . 5 . 0 to 1 . 5 . 1 ( # 2985 ) \n Bumps [ classmate ] ( https : / / github . com / FasterXML / java - classmate ) from 1 . 5 . 0 to 1 . 5 . 1 . \n - [ Release notes ] ( https : / / github . com / FasterXML / java - classmate / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / java - classmate / compare / classmate - 1 . 5 . 0 . . . classmate - 1 . 5 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 0 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 1 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 0 to 4 . 1 . 1 ( # 2986 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 0 to 4 . 1 . 1 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 0 . . . v4 . 1 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < h2 . version > 1 . 4 . 199 < / h2 . version > \n + < h2 . version > 1 . 4 . 200 < / h2 . version > \n dropwizard - migrations \ src \ test \ resources \ test - db . mv . db \n Binary files a / dropwizard - migrations / src / test / resources / test - db . mv . db and b / dropwizard - migrations / src / test / resources / test - db . mv . db differ \n,Bump h2 from 1 . 4 . 199 to 1 . 4 . 200 ( # 2983 ) \n * Bump h2 from 1 . 4 . 199 to 1 . 4 . 200 \n Bumps [ h2 ] ( https : / / github . com / h2database / h2database ) from 1 . 4 . 199 to 1 . 4 . 200 . \n - [ Release notes ] ( https : / / github . com / h2database / h2database / releases ) \n - [ Commits ] ( https : / / github . com / h2database / h2database / compare / version - 1 . 4 . 199 . . . version - 1 . 4 . 200 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Recreate H2 test database for dropwizard - migrations,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 6 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 7 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 6 . Final to 5 . 4 . 7 . Final ( # 2993 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 6 . Final to 5 . 4 . 7 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 6 . . . 5 . 4 . 7 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 21 . v20190926 < / jetty . version > \n + < jetty . version > 9 . 4 . 22 . v20191022 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 21 . v20190926 to 9 . 4 . 22 . v20191022 ( # 2997 ) \n Bumps ` jetty . version ` from 9 . 4 . 21 . v20190926 to 9 . 4 . 22 . v20191022 . \n Updates ` jetty - bom ` from 9 . 4 . 21 . v20190926 to 9 . 4 . 22 . v20191022 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 21 . v20190926 . . . jetty - 9 . 4 . 22 . v20191022 ) \n Updates ` jetty - servlet ` from 9 . 4 . 21 . v20190926 to 9 . 4 . 22 . v20191022 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 21 . v20190926 . . . jetty - 9 . 4 . 22 . v20191022 ) \n Updates ` jetty - http ` from 9 . 4 . 21 . v20190926 to 9 . 4 . 22 . v20191022 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 21 . v20190926 . . . jetty - 9 . 4 . 22 . v20191022 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 2 . 0 \n + Sphinx = = 2 . 2 . 1 \n,Bump sphinx from 2 . 2 . 0 to 2 . 2 . 1 in / docs ( # 3002 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 2 . 0 to 2 . 2 . 1 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 2 . 0 . . . v2 . 2 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < assertj . version > 3 . 13 . 2 < / assertj . version > \n + < assertj . version > 3 . 14 . 0 < / assertj . version > \n,Bump assertj - core from 3 . 13 . 2 to 3 . 14 . 0 ( # 3004 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 13 . 2 to 3 . 14 . 0 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 13 . 2 . . . assertj - core - 3 . 14 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 7 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 8 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 7 . Final to 5 . 4 . 8 . Final ( # 3007 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 7 . Final to 5 . 4 . 8 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 7 . . . 5 . 4 . 8 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < joda - time . version > 2 . 10 . 4 < / joda - time . version > \n + < joda - time . version > 2 . 10 . 5 < / joda - time . version > \n,Bump joda - time from 2 . 10 . 4 to 2 . 10 . 5 ( # 2998 ) \n Bumps [ joda - time ] ( https : / / github . com / JodaOrg / joda - time ) from 2 . 10 . 4 to 2 . 10 . 5 . \n - [ Release notes ] ( https : / / github . com / JodaOrg / joda - time / releases ) \n - [ Changelog ] ( https : / / github . com / JodaOrg / joda - time / blob / master / RELEASE - NOTES . txt ) \n - [ Commits ] ( https : / / github . com / JodaOrg / joda - time / compare / v2 . 10 . 4 . . . v2 . 10 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - core \ src \ test \ java \ io \ dropwizard \ validation \ InjectValidatorFeatureTest . java \n + import org . hibernate . validator . internal . constraintvalidators . bv . number . bound . MinValidatorForInteger ; \n - verify ( mockedFactory ) . getInstance ( eq ( MinValidatorForNumber . class ) ) ; \n + verify ( mockedFactory ) . getInstance ( eq ( MinValidatorForInteger . class ) ) ; \n dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 0 . 17 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 0 . Final < / hibernate - validator . version > \n,Bump hibernate - validator from 6 . 0 . 17 . Final to 6 . 1 . 0 . Final ( # 3003 ) \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 0 . 17 . Final to 6 . 1 . 0 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 0 . 17 . Final . . . 6 . 1 . 0 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 8 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 9 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 8 . Final to 5 . 4 . 9 . Final ( # 3026 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 8 . Final to 5 . 4 . 9 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 8 . . . 5 . 4 . 9 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 10 . 1 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 11 . 0 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 10 . 1 to 3 . 11 . 0 ( # 3027 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 10 . 1 to 3 . 11 . 0 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 22 . v20191022 < / jetty . version > \n + < jetty . version > 9 . 4 . 23 . v20191118 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 22 . v20191022 to 9 . 4 . 23 . v20191118 ( # 3031 ) \n Bumps ` jetty . version ` from 9 . 4 . 22 . v20191022 to 9 . 4 . 23 . v20191118 . \n Updates ` jetty - bom ` from 9 . 4 . 22 . v20191022 to 9 . 4 . 23 . v20191118 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 22 . v20191022 . . . jetty - 9 . 4 . 23 . v20191118 ) \n Updates ` jetty - servlet ` from 9 . 4 . 22 . v20191022 to 9 . 4 . 23 . v20191118 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 22 . v20191022 . . . jetty - 9 . 4 . 23 . v20191118 ) \n Updates ` jetty - http ` from 9 . 4 . 22 . v20191022 to 9 . 4 . 23 . v20191118 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 22 . v20191022 . . . jetty - 9 . 4 . 23 . v20191118 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 11 . 0 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 11 . 1 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 11 . 0 to 3 . 11 . 1 ( # 3030 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 11 . 0 to 3 . 11 . 1 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 23 . v20191118 < / jetty . version > \n + < jetty . version > 9 . 4 . 24 . v20191120 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 23 . v20191118 to 9 . 4 . 24 . v20191120 ( # 3033 ) \n Bumps ` jetty . version ` from 9 . 4 . 23 . v20191118 to 9 . 4 . 24 . v20191120 . \n Updates ` jetty - bom ` from 9 . 4 . 23 . v20191118 to 9 . 4 . 24 . v20191120 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 23 . v20191118 . . . jetty - 9 . 4 . 24 . v20191120 ) \n Updates ` jetty - servlet ` from 9 . 4 . 23 . v20191118 to 9 . 4 . 24 . v20191120 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 23 . v20191118 . . . jetty - 9 . 4 . 24 . v20191120 ) \n Updates ` jetty - http ` from 9 . 4 . 23 . v20191118 to 9 . 4 . 24 . v20191120 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 23 . v20191118 . . . jetty - 9 . 4 . 24 . v20191120 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 27 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 29 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 27 to 9 . 0 . 29 ( # 3034 ) \n Bumps tomcat - jdbc from 9 . 0 . 27 to 9 . 0 . 29 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 1 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 2 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 1 to 3 . 8 . 2 ( # 3038 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 1 to 3 . 8 . 2 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 2 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 1 . . . v3 . 8 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 3 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 4 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 3 to 1 . 10 . 4 ( # 3041 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 3 to 1 . 10 . 4 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 3 . . . byte - buddy - 1 . 10 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < slf4j . version > 1 . 7 . 27 < / slf4j . version > \n + < slf4j . version > 1 . 7 . 28 < / slf4j . version > \n,Bump slf4j . version from 1 . 7 . 27 to 1 . 7 . 28 ( # 2877 ) \n Bumps ` slf4j . version ` from 1 . 7 . 27 to 1 . 7 . 28 . \n Updates ` slf4j - api ` from 1 . 7 . 27 to 1 . 7 . 28 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 27 . . . v _ 1 . 7 . 28 ) \n Updates ` jul - to - slf4j ` from 1 . 7 . 27 to 1 . 7 . 28 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 27 . . . v _ 1 . 7 . 28 ) \n Updates ` log4j - over - slf4j ` from 1 . 7 . 27 to 1 . 7 . 28 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 27 . . . v _ 1 . 7 . 28 ) \n Updates ` jcl - over - slf4j ` from 1 . 7 . 27 to 1 . 7 . 28 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 27 . . . v _ 1 . 7 . 28 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - bom \ pom . xml \n - < version > 1 . 10 . 0 < / version > \n + < version > 1 . 10 . 1 < / version > \n,Bump byte - buddy from 1 . 10 . 0 to 1 . 10 . 1 ( # 2876 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 0 to 1 . 10 . 1 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 0 . . . byte - buddy - 1 . 10 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < bcprov - jdk15on . version > 1 . 63 < / bcprov - jdk15on . version > \n + < bcprov - jdk15on . version > 1 . 64 < / bcprov - jdk15on . version > \n,Bump bcprov - jdk15on from 1 . 63 to 1 . 64 ( # 2972 ) \n Bumps [ bcprov - jdk15on ] ( https : / / github . com / bcgit / bc - java ) from 1 . 63 to 1 . 64 . \n - [ Release notes ] ( https : / / github . com / bcgit / bc - java / releases ) \n - [ Changelog ] ( https : / / github . com / bcgit / bc - java / blob / master / docs / releasenotes . html ) \n - [ Commits ] ( https : / / github . com / bcgit / bc - java / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 4 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 5 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 4 to 1 . 10 . 5 \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 4 to 1 . 10 . 5 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 4 . . . byte - buddy - 1 . 10 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 29 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 30 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 29 to 9 . 0 . 30 \n Bumps tomcat - jdbc from 9 . 0 . 29 to 9 . 0 . 30 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 2 . 2 \n + Sphinx = = 2 . 3 . 0 \n,Bump sphinx from 2 . 2 . 2 to 2 . 3 . 0 in / docs ( # 3063 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 2 . 2 to 2 . 3 . 0 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 2 . 2 . . . v2 . 3 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 11 . 1 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 12 . 0 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 11 . 1 to 3 . 12 . 0 ( # 3064 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 11 . 1 to 3 . 12 . 0 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 11 . 1 . . . v3 . 12 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 2 . 0 "" \n + ext . mockitoVersion = "" 3 . 2 . 4 "" \n",Bump mockito - core from 3 . 2 . 0 to 3 . 2 . 4 ( # 6764 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 2 . 0 to 3 . 2 . 4 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 0 . . . v3 . 2 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < mockito . version > 3 . 2 . 0 < / mockito . version > \n + < mockito . version > 3 . 2 . 4 < / mockito . version > \n,Bump mockito . version from 3 . 2 . 0 to 3 . 2 . 4 ( # 3067 ) \n Bumps ` mockito . version ` from 3 . 2 . 0 to 3 . 2 . 4 . \n Updates ` mockito - core ` from 3 . 2 . 0 to 3 . 2 . 4 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 0 . . . v3 . 2 . 4 ) \n Updates ` mockito - junit - jupiter ` from 3 . 2 . 0 to 3 . 2 . 4 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 0 . . . v3 . 2 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < slf4j . version > 1 . 7 . 29 < / slf4j . version > \n + < slf4j . version > 1 . 7 . 30 < / slf4j . version > \n,Bump slf4j . version from 1 . 7 . 29 to 1 . 7 . 30 ( # 3066 ) \n Bumps ` slf4j . version ` from 1 . 7 . 29 to 1 . 7 . 30 . \n Updates ` slf4j - api ` from 1 . 7 . 29 to 1 . 7 . 30 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 29 . . . v _ 1 . 7 . 30 ) \n Updates ` jul - to - slf4j ` from 1 . 7 . 29 to 1 . 7 . 30 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 29 . . . v _ 1 . 7 . 30 ) \n Updates ` log4j - over - slf4j ` from 1 . 7 . 29 to 1 . 7 . 30 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 29 . . . v _ 1 . 7 . 30 ) \n Updates ` jcl - over - slf4j ` from 1 . 7 . 29 to 1 . 7 . 30 \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 29 . . . v _ 1 . 7 . 30 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 2 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 3 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 2 to 3 . 8 . 3 ( # 3070 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 2 to 3 . 8 . 3 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 3 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 2 . . . v3 . 8 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 5 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 6 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 5 to 1 . 10 . 6 ( # 3071 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 5 to 1 . 10 . 6 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 5 . . . byte - buddy - 1 . 10 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < pgpverify - maven - plugin . version > 1 . 5 . 0 < / pgpverify - maven - plugin . version > \n + < pgpverify - maven - plugin . version > 1 . 5 . 1 < / pgpverify - maven - plugin . version > \n,Bump pgpverify - maven - plugin from 1 . 5 . 0 to 1 . 5 . 1 \n Bumps [ pgpverify - maven - plugin ] ( https : / / github . com / s4u / pgpverify - maven - plugin ) from 1 . 5 . 0 to 1 . 5 . 1 . \n - [ Release notes ] ( https : / / github . com / s4u / pgpverify - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / s4u / pgpverify - maven - plugin / compare / pgpverify - maven - plugin - 1 . 5 . 0 . . . pgpverify - maven - plugin - 1 . 5 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 2 . 0 < / version > \n + < version > 3 . 2 . 1 < / version > \n pom . xml \n - < maven - source - plugin . version > 3 . 2 . 0 < / maven - source - plugin . version > \n + < maven - source - plugin . version > 3 . 2 . 1 < / maven - source - plugin . version > \n,Bump maven - source - plugin from 3 . 2 . 0 to 3 . 2 . 1 \n Bumps [ maven - source - plugin ] ( https : / / github . com / apache / maven - source - plugin ) from 3 . 2 . 0 to 3 . 2 . 1 . \n - [ Release notes ] ( https : / / github . com / apache / maven - source - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - source - plugin / compare / maven - source - plugin - 3 . 2 . 0 . . . maven - source - plugin - 3 . 2 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 3 . 0 \n + Sphinx = = 2 . 3 . 1 \n,Bump sphinx from 2 . 3 . 0 to 2 . 3 . 1 in / docs \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 3 . 0 to 2 . 3 . 1 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 3 . 0 . . . v2 . 3 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 3 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 4 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 3 to 3 . 8 . 4 \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 3 to 3 . 8 . 4 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 4 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 3 . . . v3 . 8 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 11 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 12 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 11 . 0 to 4 . 12 . 0 ( # 6792 ) \n Bumps build - info - extractor - gradle from 4 . 11 . 0 to 4 . 12 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 24 . v20191120 < / jetty . version > \n + < jetty . version > 9 . 4 . 25 . v20191220 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 24 . v20191120 to 9 . 4 . 25 . v20191220 ( # 3080 ) \n Bumps ` jetty . version ` from 9 . 4 . 24 . v20191120 to 9 . 4 . 25 . v20191220 . \n Updates ` jetty - bom ` from 9 . 4 . 24 . v20191120 to 9 . 4 . 25 . v20191220 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 24 . v20191120 . . . jetty - 9 . 4 . 25 . v20191220 ) \n Updates ` jetty - servlet ` from 9 . 4 . 24 . v20191120 to 9 . 4 . 25 . v20191220 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 24 . v20191120 . . . jetty - 9 . 4 . 25 . v20191220 ) \n Updates ` jetty - http ` from 9 . 4 . 24 . v20191120 to 9 . 4 . 25 . v20191220 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 24 . v20191120 . . . jetty - 9 . 4 . 25 . v20191220 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < guava . version > 28 . 1 - jre < / guava . version > \n + < guava . version > 28 . 2 - jre < / guava . version > \n,Bump guava from 28 . 1 - jre to 28 . 2 - jre \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 1 - jre to 28 . 2 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . guavaVersion = "" 28 . 1 - jre "" \n + ext . guavaVersion = "" 28 . 2 - jre "" \n",Bump guava from 28 . 1 - jre to 28 . 2 - jre ( # 6802 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 1 - jre to 28 . 2 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < mongo - java - driver . version > 3 . 12 . 0 < / mongo - java - driver . version > \n + < mongo - java - driver . version > 3 . 12 . 1 < / mongo - java - driver . version > \n,Bump mongo - java - driver from 3 . 12 . 0 to 3 . 12 . 1 ( # 1169 ) \n Bumps [ mongo - java - driver ] ( https : / / github . com / mongodb / mongo - java - driver ) from 3 . 12 . 0 to 3 . 12 . 1 . \n - [ Release notes ] ( https : / / github . com / mongodb / mongo - java - driver / releases ) \n - [ Commits ] ( https : / / github . com / mongodb / mongo - java - driver / compare / r3 . 12 . 0 . . . r3 . 12 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < version > 3 . 25 . 0 - GA < / version > \n + < version > 3 . 26 . 0 - GA < / version > \n,Bump javassist from 3 . 25 . 0 - GA to 3 . 26 . 0 - GA ( # 1170 ) \n Bumps [ javassist ] ( https : / / github . com / jboss - javassist / javassist ) from 3 . 25 . 0 - GA to 3 . 26 . 0 - GA . \n - [ Release notes ] ( https : / / github . com / jboss - javassist / javassist / releases ) \n - [ Commits ] ( https : / / github . com / jboss - javassist / javassist / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
caching \ pom . xml \n - < version > 3 . 12 . 0 < / version > \n + < version > 3 . 12 . 1 < / version > \n,Bump mongodb - driver from 3 . 12 . 0 to 3 . 12 . 1 ( # 1173 ) \n Bumps [ mongodb - driver ] ( https : / / github . com / mongodb / mongo - java - driver ) from 3 . 12 . 0 to 3 . 12 . 1 . \n - [ Release notes ] ( https : / / github . com / mongodb / mongo - java - driver / releases ) \n - [ Commits ] ( https : / / github . com / mongodb / mongo - java - driver / compare / r3 . 12 . 0 . . . r3 . 12 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 14 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 15 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 14 . Final to 5 . 4 . 15 . Final ( # 3268 ),584
dropwizard - example \ pom . xml \n - < version > 1 . 14 . 2 < / version > \n + < version > 1 . 14 . 3 < / version > \n,Bump testcontainers - bom from 1 . 14 . 2 to 1 . 14 . 3 ( # 3314 ) \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 18 . 1 "" \n + ext . jfrogExtractorVersion = "" 4 . 18 . 2 "" \n",Bump build - info - extractor - gradle from 4 . 18 . 1 to 4 . 18 . 2 ( # 7123 ) \n Bumps build - info - extractor - gradle from 4 . 18 . 1 to 4 . 18 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jersey . version > 2 . 29 . 1 < / jersey . version > \n + < jersey . version > 2 . 30 < / jersey . version > \n,Bump jersey - bom from 2 . 29 . 1 to 2 . 30 \n Bumps jersey - bom from 2 . 29 . 1 to 2 . 30 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 12 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 13 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 12 . 0 to 4 . 13 . 0 ( # 6808 ) \n Bumps build - info - extractor - gradle from 4 . 12 . 0 to 4 . 13 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 1 . 0 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 1 . Final < / hibernate - validator . version > \n,Bump hibernate - validator from 6 . 1 . 0 . Final to 6 . 1 . 1 . Final ( # 3101 ) \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 1 . 0 . Final to 6 . 1 . 1 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 1 . 0 . Final . . . 6 . 1 . 1 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < caffeine . version > 2 . 8 . 0 < / caffeine . version > \n + < caffeine . version > 2 . 8 . 1 < / caffeine . version > \n,Bump caffeine from 2 . 8 . 0 to 2 . 8 . 1 \n Bumps [ caffeine ] ( https : / / github . com / ben - manes / caffeine ) from 2 . 8 . 0 to 2 . 8 . 1 . \n - [ Release notes ] ( https : / / github . com / ben - manes / caffeine / releases ) \n - [ Commits ] ( https : / / github . com / ben - manes / caffeine / compare / v2 . 8 . 0 . . . v2 . 8 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
event - sourcing \ pom . xml \n - < version > 2 . 8 . 1 < / version > \n + < version > 2 . 8 . 6 < / version > \n,Bump gson from 2 . 8 . 1 to 2 . 8 . 6 ( # 1147 ) \n Bumps [ gson ] ( https : / / github . com / google / gson ) from 2 . 8 . 1 to 2 . 8 . 6 . \n - [ Release notes ] ( https : / / github . com / google / gson / releases ) \n - [ Changelog ] ( https : / / github . com / google / gson / blob / master / CHANGELOG . md ) \n - [ Commits ] ( https : / / github . com / google / gson / compare / gson - parent - 2 . 8 . 1 . . . gson - parent - 2 . 8 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < httpclient . version > 4 . 5 . 10 < / httpclient . version > \n + < httpclient . version > 4 . 5 . 11 < / httpclient . version > \n,Bump httpclient from 4 . 5 . 10 to 4 . 5 . 11 ( # 3104 ) \n Bumps httpclient from 4 . 5 . 10 to 4 . 5 . 11 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 25 . v20191220 < / jetty . version > \n + < jetty . version > 9 . 4 . 26 . v20200117 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 25 . v20191220 to 9 . 4 . 26 . v20200117 ( # 3105 ) \n Bumps ` jetty . version ` from 9 . 4 . 25 . v20191220 to 9 . 4 . 26 . v20200117 . \n Updates ` jetty - bom ` from 9 . 4 . 25 . v20191220 to 9 . 4 . 26 . v20200117 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 25 . v20191220 . . . jetty - 9 . 4 . 26 . v20200117 ) \n Updates ` jetty - servlet ` from 9 . 4 . 25 . v20191220 to 9 . 4 . 26 . v20200117 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 25 . v20191220 . . . jetty - 9 . 4 . 26 . v20200117 ) \n Updates ` jetty - http ` from 9 . 4 . 25 . v20191220 to 9 . 4 . 26 . v20200117 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 25 . v20191220 . . . jetty - 9 . 4 . 26 . v20200117 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < slf4j . version > 1 . 7 . 28 < / slf4j . version > \n + < slf4j . version > 1 . 7 . 30 < / slf4j . version > \n,Bump slf4j - api from 1 . 7 . 28 to 1 . 7 . 30 ( # 1153 ) \n Bumps [ slf4j - api ] ( https : / / github . com / qos - ch / slf4j ) from 1 . 7 . 28 to 1 . 7 . 30 . \n - [ Release notes ] ( https : / / github . com / qos - ch / slf4j / releases ) \n - [ Commits ] ( https : / / github . com / qos - ch / slf4j / compare / v _ 1 . 7 . 28 . . . v _ 1 . 7 . 30 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 5 . 2 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 0 < / junit5 . version > \n,Bump junit - jupiter from 5 . 5 . 2 to 5 . 6 . 0 ( # 3108 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 5 . 2 to 5 . 6 . 0 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 2 . . . r5 . 6 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < junit5 . version > 5 . 5 . 2 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 0 < / junit5 . version > \n,Bump junit5 . version from 5 . 5 . 2 to 5 . 6 . 0 ( # 3109 ) \n Bumps ` junit5 . version ` from 5 . 5 . 2 to 5 . 6 . 0 . \n Updates ` junit - bom ` from 5 . 5 . 2 to 5 . 6 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 2 . . . r5 . 6 . 0 ) \n Updates ` junit - vintage - engine ` from 5 . 5 . 2 to 5 . 6 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 2 . . . r5 . 6 . 0 ) \n Updates ` junit - jupiter - engine ` from 5 . 5 . 2 to 5 . 6 . 0 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 5 . 2 . . . r5 . 6 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 6 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 7 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 6 to 1 . 10 . 7 ( # 3110 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 6 to 1 . 10 . 7 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 6 . . . byte - buddy - 1 . 10 . 7 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . bndVersion = "" 4 . 3 . 1 "" \n + ext . bndVersion = "" 5 . 0 . 0 "" \n",Bump biz . aQute . bnd . gradle from 4 . 3 . 1 to 5 . 0 . 0 ( # 6861 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 4 . 3 . 1 to 5 . 0 . 0 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - lesscpy = = 0 . 13 . 0 \n + lesscpy = = 0 . 14 . 0 \n,Bump lesscpy from 0 . 13 . 0 to 0 . 14 . 0 in / docs ( # 3113 ) \n Bumps [ lesscpy ] ( https : / / github . com / lesscpy / lesscpy ) from 0 . 13 . 0 to 0 . 14 . 0 . \n - [ Release notes ] ( https : / / github . com / lesscpy / lesscpy / releases ) \n - [ Commits ] ( https : / / github . com / lesscpy / lesscpy / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - benchmarks \ pom . xml \n - < jmh . version > 1 . 22 < / jmh . version > \n + < jmh . version > 1 . 23 < / jmh . version > \n,Bump jmh . version from 1 . 22 to 1 . 23 ( # 3112 ) \n Bumps ` jmh . version ` from 1 . 22 to 1 . 23 . \n Updates ` jmh - core ` from 1 . 22 to 1 . 23 \n Updates ` jmh - generator - annprocess ` from 1 . 22 to 1 . 23 \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < assertj . version > 3 . 14 . 0 < / assertj . version > \n + < assertj . version > 3 . 15 . 0 < / assertj . version > \n,Bump assertj - core from 3 . 14 . 0 to 3 . 15 . 0 \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 14 . 0 to 3 . 15 . 0 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 14 . 0 . . . assertj - core - 3 . 15 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 10 . 2 < / jackson . version > \n + < jackson . version > 2 . 10 . 2 . 20200130 < / jackson . version > \n,Bump jackson - bom from 2 . 10 . 2 to 2 . 10 . 2 . 20200130 ( # 3122 ) \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 10 . 2 to 2 . 10 . 2 . 20200130 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 10 . 2 . . . jackson - bom - 2 . 10 . 2 . 20200130 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 26 . v20200117 < / jetty . version > \n + < jetty . version > 9 . 4 . 27 . v20200227 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 26 . v20200117 to 9 . 4 . 27 . v20200227 ( # 3176 ) \n Bumps ` jetty . version ` from 9 . 4 . 26 . v20200117 to 9 . 4 . 27 . v20200227 . \n Updates ` jetty - bom ` from 9 . 4 . 26 . v20200117 to 9 . 4 . 27 . v20200227 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 26 . v20200117 . . . jetty - 9 . 4 . 27 . v20200227 ) \n Updates ` jetty - servlet ` from 9 . 4 . 26 . v20200117 to 9 . 4 . 27 . v20200227 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 26 . v20200117 . . . jetty - 9 . 4 . 27 . v20200227 ) \n Updates ` jetty - http ` from 9 . 4 . 26 . v20200117 to 9 . 4 . 27 . v20200227 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 26 . v20200117 . . . jetty - 9 . 4 . 27 . v20200227 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jaxb - api . version > 2 . 3 . 2 < / jaxb - api . version > \n + < jaxb - api . version > 2 . 3 . 3 < / jaxb - api . version > \n,Bump jakarta . xml . bind - api from 2 . 3 . 2 to 2 . 3 . 3 ( # 3175 ) \n Bumps jakarta . xml . bind - api from 2 . 3 . 2 to 2 . 3 . 3 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 13 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 14 . 1 "" \n",Bump build - info - extractor - gradle from 4 . 13 . 0 to 4 . 14 . 1 ( # 6924 ) \n Bumps build - info - extractor - gradle from 4 . 13 . 0 to 4 . 14 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 2 . 0 < / checker - qual . version > \n + < checker - qual . version > 3 . 3 . 0 < / checker - qual . version > \n,Bump checker - qual from 3 . 2 . 0 to 3 . 3 . 0 ( # 3224 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 2 . 0 to 3 . 3 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 2 . 0 . . . checker - framework - 3 . 3 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 16 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 17 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 16 . Final to 5 . 4 . 17 . Final ( # 3316 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 16 . Final to 5 . 4 . 17 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / 5 . 4 . 17 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 16 . . . 5 . 4 . 17 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 0 . 1 "" \n + ext . bndVersion = "" 5 . 1 . 0 "" \n",Bump biz . aQute . bnd . gradle from 5 . 0 . 1 to 5 . 1 . 0 ( # 7003 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 0 . 1 to 5 . 1 . 0 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 4 . 0 < / checker - qual . version > \n + < checker - qual . version > 3 . 4 . 1 < / checker - qual . version > \n,Bump checker - qual from 3 . 4 . 0 to 3 . 4 . 1 ( # 3318 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 4 . 0 to 3 . 4 . 1 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 4 . 0 . . . checker - framework - 3 . 4 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"deleted file \n . dependabot \ config . yml \n - version : 1 \n - update _ configs : \n - - package _ manager : "" java : maven "" \n - directory : "" / "" \n - update _ schedule : "" daily "" \n - - package _ manager : "" python "" \n - directory : "" / docs "" \n - update _ schedule : "" live "" \n - - package _ manager : "" ruby : bundler "" \n - directory : "" / docs "" \n - update _ schedule : "" live "" \n - - package _ manager : "" java : maven "" \n - directory : "" / "" \n - update _ schedule : "" daily "" \n - target _ branch : "" release / 2 . 0 . x "" \n - allowed _ updates : \n - - match : \n - update _ type : "" security "" \n new file \n . github \ dependabot . yml \n + version : 2 \n + updates : \n + - package - ecosystem : maven \n + directory : "" / "" \n + schedule : \n + interval : daily \n + open - pull - requests - limit : 10 \n + - package - ecosystem : pip \n + directory : "" / docs "" \n + schedule : \n + interval : daily \n + open - pull - requests - limit : 10 \n + - package - ecosystem : bundler \n + directory : "" / docs "" \n + schedule : \n + interval : daily \n + open - pull - requests - limit : 10 \n",Update Dependabot config file ( # 3319 ) \n * Update Dependabot config file \n * Unignore org . hibernate : hibernate - validator \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com > \n Co - authored - by : Jochen Schalanda < jochen @ schalanda . name >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 7 "" \n + ext . mockitoVersion = "" 3 . 5 . 9 "" \n",Bump mockito - core from 3 . 5 . 7 to 3 . 5 . 9 ( # 7069 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 7 to 3 . 5 . 9 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 7 . . . v3 . 5 . 9 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 2 . 1 < / version > \n + < version > 3 . 2 . 2 < / version > \n,Bump maven - shade - plugin from 3 . 2 . 1 to 3 . 2 . 2 \n Bumps [ maven - shade - plugin ] ( https : / / github . com / apache / maven - shade - plugin ) from 3 . 2 . 1 to 3 . 2 . 2 . \n - [ Release notes ] ( https : / / github . com / apache / maven - shade - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - shade - plugin / compare / maven - shade - plugin - 3 . 2 . 1 . . . maven - shade - plugin - 3 . 2 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 12 . 0 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 12 . 2 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 12 . 0 to 3 . 12 . 2 \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 12 . 0 to 3 . 12 . 2 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 12 . 0 . . . v3 . 12 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 11 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 12 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 11 . Final to 5 . 4 . 12 . Final ( # 3147 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 11 . Final to 5 . 4 . 12 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 11 . . . 5 . 4 . 12 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < plexus - compiler - javac - errorprone . version > 2 . 8 . 5 < / plexus - compiler - javac - errorprone . version > \n + < plexus - compiler - javac - errorprone . version > 2 . 8 . 6 < / plexus - compiler - javac - errorprone . version > \n,Bump plexus - compiler - javac - errorprone from 2 . 8 . 5 to 2 . 8 . 6 ( # 3150 ) \n Bumps plexus - compiler - javac - errorprone from 2 . 8 . 5 to 2 . 8 . 6 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 4 . 0 \n + Sphinx = = 2 . 4 . 1 \n,Bump sphinx from 2 . 4 . 0 to 2 . 4 . 1 in / docs ( # 3141 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 4 . 0 to 2 . 4 . 1 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 2 . 0 / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 4 . 0 . . . v2 . 4 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 7 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 8 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 7 to 1 . 10 . 8 ( # 3151 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 7 to 1 . 10 . 8 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 7 . . . byte - buddy - 1 . 10 . 8 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 4 . 1 \n + Sphinx = = 2 . 4 . 2 \n,Bump sphinx from 2 . 4 . 1 to 2 . 4 . 2 in / docs ( # 3155 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 4 . 1 to 2 . 4 . 2 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 4 . 1 . . . v2 . 4 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < activation - api . version > 1 . 2 . 1 < / activation - api . version > \n + < activation - api . version > 1 . 2 . 2 < / activation - api . version > \n,Bump jakarta . activation - api from 1 . 2 . 1 to 1 . 2 . 2 ( # 3161 ) \n Bumps jakarta . activation - api from 1 . 2 . 1 to 1 . 2 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jersey . version > 2 . 30 < / jersey . version > \n + < jersey . version > 2 . 30 . 1 < / jersey . version > \n,Bump jersey - bom from 2 . 30 to 2 . 30 . 1 \n Bumps jersey - bom from 2 . 30 to 2 . 30 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 4 . 2 \n + Sphinx = = 2 . 4 . 3 \n,Bump sphinx from 2 . 4 . 2 to 2 . 4 . 3 in / docs \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 4 . 2 to 2 . 4 . 3 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 4 . 2 . . . v2 . 4 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - auth \ src \ test \ java \ io \ dropwizard \ auth \ CachingAuthenticatorTest . java \n - @ Mock \n + @ Mock ( lenient = true ) \n dropwizard - dependencies \ pom . xml \n - < mockito . version > 3 . 2 . 4 < / mockito . version > \n + < mockito . version > 3 . 3 . 0 < / mockito . version > \n,Bump mockito . version from 3 . 2 . 4 to 3 . 3 . 0 ( # 3164 ) \n * Bump mockito . version from 3 . 2 . 4 to 3 . 3 . 0 \n Bumps ` mockito . version ` from 3 . 2 . 4 to 3 . 3 . 0 . \n Updates ` mockito - core ` from 3 . 2 . 4 to 3 . 3 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 4 . . . v3 . 3 . 0 ) \n Updates ` mockito - junit - jupiter ` from 3 . 2 . 4 to 3 . 3 . 0 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 4 . . . v3 . 3 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Silence Mockito unused stubs warnings \n Co - authored - by : Jochen Schalanda < jochen @ schalanda . name >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 2 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 3 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 2 to 4 . 1 . 3 ( # 3169 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 2 to 4 . 1 . 3 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 2 . . . v4 . 1 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 6 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 7 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 6 to 3 . 8 . 7 ( # 3170 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 6 to 3 . 8 . 7 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 7 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 6 . . . v3 . 8 . 7 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 3 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 4 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 3 to 4 . 1 . 4 ( # 3173 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 3 to 4 . 1 . 4 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 3 . . . v4 . 1 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty - setuid - java . version > 1 . 0 . 3 < / jetty - setuid - java . version > \n + < jetty - setuid - java . version > 1 . 0 . 4 < / jetty - setuid - java . version > \n,Bump jetty - setuid - java from 1 . 0 . 3 to 1 . 0 . 4 ( # 3172 ) \n Bumps jetty - setuid - java from 1 . 0 . 3 to 1 . 0 . 4 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"docs \ Gemfile . lock \n - addressable ( 2 . 5 . 2 ) \n - public _ suffix ( > = 2 . 0 . 2 , < 4 . 0 ) \n - faraday ( 0 . 15 . 4 ) \n + addressable ( 2 . 7 . 0 ) \n + public _ suffix ( > = 2 . 0 . 2 , < 5 . 0 ) \n + faraday ( 1 . 0 . 0 ) \n - multipart - post ( 2 . 0 . 0 ) \n - octokit ( 4 . 14 . 0 ) \n + multipart - post ( 2 . 1 . 1 ) \n + octokit ( 4 . 15 . 0 ) \n + faraday ( > = 0 . 9 ) \n - public _ suffix ( 3 . 0 . 3 ) \n - sawyer ( 0 . 8 . 1 ) \n - addressable ( > = 2 . 3 . 5 , < 2 . 6 ) \n - faraday ( ~ > 0 . 8 , < 1 . 0 ) \n + public _ suffix ( 4 . 0 . 2 ) \n + sawyer ( 0 . 8 . 2 ) \n + addressable ( > = 2 . 3 . 5 ) \n + faraday ( > 0 . 8 , < 2 . 0 ) \n",Bump octokit from 4 . 14 . 0 to 4 . 15 . 0 in / docs \n Bumps [ octokit ] ( https : / / github . com / octokit / octokit . rb ) from 4 . 14 . 0 to 4 . 15 . 0 . \n - [ Release notes ] ( https : / / github . com / octokit / octokit . rb / releases ) \n - [ Changelog ] ( https : / / github . com / octokit / octokit . rb / blob / 4 - stable / RELEASE . md ) \n - [ Commits ] ( https : / / github . com / octokit / octokit . rb / compare / v4 . 14 . 0 . . . v4 . 15 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 1 . 1 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 2 . Final < / hibernate - validator . version > \n,Bump hibernate - validator from 6 . 1 . 1 . Final to 6 . 1 . 2 . Final ( # 3126 ) \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 1 . 1 . Final to 6 . 1 . 2 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 1 . 1 . Final . . . 6 . 1 . 2 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 10 . 2 . 20200130 < / jackson . version > \n + < jackson . version > 2 . 10 . 3 < / jackson . version > \n,Bump jackson - bom from 2 . 10 . 2 . 20200130 to 2 . 10 . 3 ( # 3179 ) \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 10 . 2 . 20200130 to 2 . 10 . 3 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 10 . 2 . 20200130 . . . jackson - bom - 2 . 10 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 1 . 1 < / checker - qual . version > \n + < checker - qual . version > 3 . 2 . 0 < / checker - qual . version > \n,Bump checker - qual from 3 . 1 . 1 to 3 . 2 . 0 ( # 3178 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 1 . 1 to 3 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 1 . 1 . . . checker - framework - 3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 6 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 7 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 6 to 4 . 1 . 7 ( # 3271 ),584
"build . gradle \n - ext . testNgVersion = "" 7 . 0 . 0 "" \n + ext . testNgVersion = "" 7 . 3 . 0 "" \n",Bump testng from 7 . 0 . 0 to 7 . 3 . 0 ( # 7047 ) \n Bumps [ testng ] ( https : / / github . com / cbeust / testng ) from 7 . 0 . 0 to 7 . 3 . 0 . \n - [ Release notes ] ( https : / / github . com / cbeust / testng / releases ) \n - [ Changelog ] ( https : / / github . com / cbeust / testng / blob / master / CHANGES . txt ) \n - [ Commits ] ( https : / / github . com / cbeust / testng / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 2 . 4 "" \n + ext . mockitoVersion = "" 3 . 3 . 3 "" \n",Bump mockito - core from 3 . 2 . 4 to 3 . 3 . 3 ( # 6935 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 2 . 4 to 3 . 3 . 3 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 2 . 4 . . . v3 . 3 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
pom . xml \n - < maven - javadoc - plugin . version > 3 . 1 . 1 < / maven - javadoc - plugin . version > \n + < maven - javadoc - plugin . version > 3 . 2 . 0 < / maven - javadoc - plugin . version > \n,Bump maven - javadoc - plugin from 3 . 1 . 1 to 3 . 2 . 0 ( # 3194 ) \n Bumps [ maven - javadoc - plugin ] ( https : / / github . com / apache / maven - javadoc - plugin ) from 3 . 1 . 1 to 3 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / apache / maven - javadoc - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - javadoc - plugin / compare / maven - javadoc - plugin - 3 . 1 . 1 . . . maven - javadoc - plugin - 3 . 2 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < mockito . version > 3 . 3 . 0 < / mockito . version > \n + < mockito . version > 3 . 3 . 3 < / mockito . version > \n,Bump mockito . version from 3 . 3 . 0 to 3 . 3 . 3 ( # 3193 ) \n Bumps ` mockito . version ` from 3 . 3 . 0 to 3 . 3 . 3 . \n Updates ` mockito - core ` from 3 . 3 . 0 to 3 . 3 . 3 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 3 . 0 . . . v3 . 3 . 3 ) \n Updates ` mockito - junit - jupiter ` from 3 . 3 . 0 to 3 . 3 . 3 \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 3 . 0 . . . v3 . 3 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 31 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 33 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 31 to 9 . 0 . 33 ( # 3196 ) \n Bumps tomcat - jdbc from 9 . 0 . 31 to 9 . 0 . 33 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 14 . 1 "" \n + ext . jfrogExtractorVersion = "" 4 . 15 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 14 . 1 to 4 . 15 . 0 ( # 6937 ) \n Bumps build - info - extractor - gradle from 4 . 14 . 1 to 4 . 15 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < javassist . version > 3 . 26 . 0 - GA < / javassist . version > \n + < javassist . version > 3 . 27 . 0 - GA < / javassist . version > \n,Bump javassist from 3 . 26 . 0 - GA to 3 . 27 . 0 - GA ( # 3199 ) \n Bumps [ javassist ] ( https : / / github . com / jboss - javassist / javassist ) from 3 . 26 . 0 - GA to 3 . 27 . 0 - GA . \n - [ Release notes ] ( https : / / github . com / jboss - javassist / javassist / releases ) \n - [ Commits ] ( https : / / github . com / jboss - javassist / javassist / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 7 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 8 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 7 to 3 . 8 . 8 ( # 3200 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 7 to 3 . 8 . 8 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 8 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 7 . . . v3 . 8 . 8 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 15 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 15 . 1 "" \n",Bump build - info - extractor - gradle from 4 . 15 . 0 to 4 . 15 . 1 ( # 6940 ) \n Bumps build - info - extractor - gradle from 4 . 15 . 0 to 4 . 15 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 6 . 0 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 1 < / junit5 . version > \n,Bump junit - jupiter from 5 . 6 . 0 to 5 . 6 . 1 ( # 3203 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 6 . 0 to 5 . 6 . 1 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 0 . . . r5 . 6 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < junit5 . version > 5 . 6 . 0 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 1 < / junit5 . version > \n,Bump junit5 . version from 5 . 6 . 0 to 5 . 6 . 1 ( # 3204 ) \n Bumps ` junit5 . version ` from 5 . 6 . 0 to 5 . 6 . 1 . \n Updates ` junit - bom ` from 5 . 6 . 0 to 5 . 6 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 0 . . . r5 . 6 . 1 ) \n Updates ` junit - vintage - engine ` from 5 . 6 . 0 to 5 . 6 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 0 . . . r5 . 6 . 1 ) \n Updates ` junit - jupiter - engine ` from 5 . 6 . 0 to 5 . 6 . 1 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 0 . . . r5 . 6 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 0 . 0 "" \n + ext . bndVersion = "" 5 . 0 . 1 "" \n",Bump biz . aQute . bnd . gradle from 5 . 0 . 0 to 5 . 0 . 1 ( # 6941 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 0 . 0 to 5 . 0 . 1 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
acyclic - visitor \ pom . xml \n - < version > 1 . 9 . 5 < / version > \n + < version > 1 . 10 . 19 < / version > \n,Bump mockito - all from 1 . 9 . 5 to 1 . 10 . 19 ( # 1202 ) \n Bumps [ mockito - all ] ( https : / / github . com / mockito / mockito ) from 1 . 9 . 5 to 1 . 10 . 19 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v1 . 9 . 5 . . . v1 . 10 . 19 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
acyclic - visitor \ pom . xml \n - < version > 1 . 0 . 0 < / version > \n + < version > 1 . 2 . 0 < / version > \n,Bump slf4j - test from 1 . 0 . 0 to 1 . 2 . 0 ( # 1204 ) \n Bumps slf4j - test from 1 . 0 . 0 to 1 . 2 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ Gemfile . lock \n - octokit ( 4 . 17 . 0 ) \n + octokit ( 4 . 18 . 0 ) \n,Bump octokit from 4 . 17 . 0 to 4 . 18 . 0 in / docs ( # 3207 ) \n Bumps [ octokit ] ( https : / / github . com / octokit / octokit . rb ) from 4 . 17 . 0 to 4 . 18 . 0 . \n - [ Release notes ] ( https : / / github . com / octokit / octokit . rb / releases ) \n - [ Changelog ] ( https : / / github . com / octokit / octokit . rb / blob / 4 - stable / RELEASE . md ) \n - [ Commits ] ( https : / / github . com / octokit / octokit . rb / compare / v4 . 17 . 0 . . . v4 . 18 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 12 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 13 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 12 . Final to 5 . 4 . 13 . Final ( # 3217 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 12 . Final to 5 . 4 . 13 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 12 . . . 5 . 4 . 13 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < conscrypt - openjdk - uber . version > 2 . 1 . 0 < / conscrypt - openjdk - uber . version > \n + < conscrypt - openjdk - uber . version > 2 . 4 . 0 < / conscrypt - openjdk - uber . version > \n dropwizard - parent \ pom . xml \n + < pgpverify . keyserver > hkps : / / hkps . pool . sks - keyservers . net ; hkps : / / keyserver . ubuntu . com < / pgpverify . keyserver > \n + \n,Bump conscrypt - openjdk - uber from 2 . 1 . 0 to 2 . 4 . 0 ( # 3211 ) \n * Bump conscrypt - openjdk - uber from 2 . 1 . 0 to 2 . 4 . 0 \n Bumps [ conscrypt - openjdk - uber ] ( https : / / github . com / google / conscrypt ) from 2 . 1 . 0 to 2 . 4 . 0 . \n - [ Release notes ] ( https : / / github . com / google / conscrypt / releases ) \n - [ Commits ] ( https : / / github . com / google / conscrypt / compare / 2 . 1 . 0 . . . 2 . 4 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Use default and Ubuntu PGP keyservers \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com > \n Co - authored - by : Jochen Schalanda < jochen @ schalanda . name >,584
dropwizard - dependencies \ pom . xml \n - < commons - lang3 . version > 3 . 9 < / commons - lang3 . version > \n + < commons - lang3 . version > 3 . 10 < / commons - lang3 . version > \n,Bump commons - lang3 from 3 . 9 to 3 . 10 ( # 3218 ) \n Bumps commons - lang3 from 3 . 9 to 3 . 10 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 8 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 9 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 8 to 1 . 10 . 9 \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 8 to 1 . 10 . 9 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 8 . . . byte - buddy - 1 . 10 . 9 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ pom . xml \n - < version > 2 . 6 . 0 < / version > \n + < version > 2 . 7 . 0 < / version > \n,Bump sphinx - maven - plugin from 2 . 6 . 0 to 2 . 7 . 0 ( # 3219 ) \n Bumps [ sphinx - maven - plugin ] ( https : / / github . com / trustin / sphinx - maven - plugin ) from 2 . 6 . 0 to 2 . 7 . 0 . \n - [ Release notes ] ( https : / / github . com / trustin / sphinx - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / trustin / sphinx - maven - plugin / compare / sphinx - maven - plugin - 2 . 6 . 0 . . . sphinx - maven - plugin - 2 . 7 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 1 . 0 < / checker - qual . version > \n + < checker - qual . version > 3 . 1 . 1 < / checker - qual . version > \n,Bump checker - qual from 3 . 1 . 0 to 3 . 1 . 1 ( # 3127 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 1 . 0 to 3 . 1 . 1 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 1 . 0 . . . checker - framework - 3 . 1 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 2 . 2 < / version > \n + < version > 3 . 2 . 3 < / version > \n,Bump maven - shade - plugin from 3 . 2 . 2 to 3 . 2 . 3 ( # 3252 ) \n Bumps [ maven - shade - plugin ] ( https : / / github . com / apache / maven - shade - plugin ) from 3 . 2 . 2 to 3 . 2 . 3 . \n - [ Release notes ] ( https : / / github . com / apache / maven - shade - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - shade - plugin / compare / maven - shade - plugin - 3 . 2 . 2 . . . maven - shade - plugin - 3 . 2 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < guava . version > 28 . 2 - jre < / guava . version > \n + < guava . version > 29 . 0 - jre < / guava . version > \n,Bump guava from 28 . 2 - jre to 29 . 0 - jre ( # 3251 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 2 - jre to 29 . 0 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . guavaVersion = "" 28 . 2 - jre "" \n + ext . guavaVersion = "" 29 . 0 - jre "" \n",Bump guava from 28 . 2 - jre to 29 . 0 - jre ( # 6959 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 28 . 2 - jre to 29 . 0 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 1 . 3 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 4 . Final < / hibernate - validator . version > \n,Bump hibernate - validator from 6 . 1 . 3 . Final to 6 . 1 . 4 . Final \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 1 . 3 . Final to 6 . 1 . 4 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / 6 . 1 . 4 . Final / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 1 . 3 . Final . . . 6 . 1 . 4 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ requirements . txt \n - Sphinx = = 3 . 0 . 1 \n + Sphinx = = 3 . 0 . 2 \n,Bump sphinx from 3 . 0 . 1 to 3 . 0 . 2 in / docs ( # 3254 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 3 . 0 . 1 to 3 . 0 . 2 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v3 . 0 . 1 . . . v3 . 0 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 15 . 1 "" \n + ext . jfrogExtractorVersion = "" 4 . 15 . 2 "" \n",Bump build - info - extractor - gradle from 4 . 15 . 1 to 4 . 15 . 2 ( # 6967 ) \n Bumps build - info - extractor - gradle from 4 . 15 . 1 to 4 . 15 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ requirements . txt \n - Sphinx = = 3 . 0 . 2 \n + Sphinx = = 3 . 0 . 3 \n,Bump sphinx from 3 . 0 . 2 to 3 . 0 . 3 in / docs \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 3 . 0 . 2 to 3 . 0 . 3 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v3 . 0 . 2 . . . v3 . 0 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < joda - time . version > 2 . 10 . 5 < / joda - time . version > \n + < joda - time . version > 2 . 10 . 6 < / joda - time . version > \n,Bump joda - time from 2 . 10 . 5 to 2 . 10 . 6 ( # 3264 ) \n Bumps [ joda - time ] ( https : / / github . com / JodaOrg / joda - time ) from 2 . 10 . 5 to 2 . 10 . 6 . \n - [ Release notes ] ( https : / / github . com / JodaOrg / joda - time / releases ) \n - [ Changelog ] ( https : / / github . com / JodaOrg / joda - time / blob / master / RELEASE - NOTES . txt ) \n - [ Commits ] ( https : / / github . com / JodaOrg / joda - time / compare / v2 . 10 . 5 . . . v2 . 10 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 11 . 0 . rc1 < / jackson . version > \n + < jackson . version > 2 . 11 . 0 < / jackson . version > \n,Bump jackson - bom from 2 . 11 . 0 . rc1 to 2 . 11 . 0 ( # 3263 ) \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 11 . 0 . rc1 to 2 . 11 . 0 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 11 . 0 . rc1 . . . jackson - bom - 2 . 11 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jdbi3 . version > 3 . 12 . 2 < / jdbi3 . version > \n + < jdbi3 . version > 3 . 13 . 0 < / jdbi3 . version > \n,Bump jdbi3 - bom from 3 . 12 . 2 to 3 . 13 . 0 ( # 3260 ) \n Bumps [ jdbi3 - bom ] ( https : / / github . com / jdbi / jdbi ) from 3 . 12 . 2 to 3 . 13 . 0 . \n - [ Release notes ] ( https : / / github . com / jdbi / jdbi / releases ) \n - [ Changelog ] ( https : / / github . com / jdbi / jdbi / blob / master / RELEASE _ NOTES . md ) \n - [ Commits ] ( https : / / github . com / jdbi / jdbi / compare / v3 . 12 . 2 . . . v3 . 13 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < caffeine . version > 2 . 8 . 1 < / caffeine . version > \n + < caffeine . version > 2 . 8 . 2 < / caffeine . version > \n,Bump caffeine from 2 . 8 . 1 to 2 . 8 . 2 ( # 3265 ) \n Bumps [ caffeine ] ( https : / / github . com / ben - manes / caffeine ) from 2 . 8 . 1 to 2 . 8 . 2 . \n - [ Release notes ] ( https : / / github . com / ben - manes / caffeine / releases ) \n - [ Commits ] ( https : / / github . com / ben - manes / caffeine / compare / v2 . 8 . 1 . . . v2 . 8 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < byte - buddy . version > 1 . 10 . 9 < / byte - buddy . version > \n + < byte - buddy . version > 1 . 10 . 10 < / byte - buddy . version > \n,Bump byte - buddy from 1 . 10 . 9 to 1 . 10 . 10 ( # 3267 ) \n Bumps [ byte - buddy ] ( https : / / github . com / raphw / byte - buddy ) from 1 . 10 . 9 to 1 . 10 . 10 . \n - [ Release notes ] ( https : / / github . com / raphw / byte - buddy / releases ) \n - [ Changelog ] ( https : / / github . com / raphw / byte - buddy / blob / master / release - notes . md ) \n - [ Commits ] ( https : / / github . com / raphw / byte - buddy / compare / byte - buddy - 1 . 10 . 9 . . . byte - buddy - 1 . 10 . 10 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ Gemfile . lock \n - octokit ( 4 . 15 . 0 ) \n + octokit ( 4 . 16 . 0 ) \n - public _ suffix ( 4 . 0 . 2 ) \n + public _ suffix ( 4 . 0 . 3 ) \n,Bump octokit from 4 . 15 . 0 to 4 . 16 . 0 in / docs \n Bumps [ octokit ] ( https : / / github . com / octokit / octokit . rb ) from 4 . 15 . 0 to 4 . 16 . 0 . \n - [ Release notes ] ( https : / / github . com / octokit / octokit . rb / releases ) \n - [ Changelog ] ( https : / / github . com / octokit / octokit . rb / blob / 4 - stable / RELEASE . md ) \n - [ Commits ] ( https : / / github . com / octokit / octokit . rb / compare / v4 . 15 . 0 . . . v4 . 16 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . jmhGradleVersion = "" 0 . 5 . 1 "" \n + ext . jmhGradleVersion = "" 0 . 5 . 2 "" \n",Bump jmh - gradle - plugin from 0 . 5 . 1 to 0 . 5 . 2 ( # 7082 ) \n Bumps jmh - gradle - plugin from 0 . 5 . 1 to 0 . 5 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . animalSnifferVersion = "" 1 . 5 . 1 "" \n + ext . animalSnifferVersion = "" 1 . 5 . 2 "" \n",Bump gradle - animalsniffer - plugin from 1 . 5 . 1 to 1 . 5 . 2 ( # 7106 ) \n Bumps gradle - animalsniffer - plugin from 1 . 5 . 1 to 1 . 5 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 7 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 8 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 7 to 4 . 1 . 8 ( # 3294 ),584
dropwizard - example \ pom . xml \n - < version > 1 . 14 . 1 < / version > \n + < version > 1 . 14 . 2 < / version > \n,Bump testcontainers - bom from 1 . 14 . 1 to 1 . 14 . 2 ( # 3295 ) \n Bumps [ testcontainers - bom ] ( https : / / github . com / testcontainers / testcontainers - java ) from 1 . 14 . 1 to 1 . 14 . 2 . \n - [ Release notes ] ( https : / / github . com / testcontainers / testcontainers - java / releases ) \n - [ Changelog ] ( https : / / github . com / testcontainers / testcontainers - java / blob / master / CHANGELOG . md ) \n - [ Commits ] ( https : / / github . com / testcontainers / testcontainers - java / compare / 1 . 14 . 1 . . . 1 . 14 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < caffeine . version > 2 . 8 . 2 < / caffeine . version > \n + < caffeine . version > 2 . 8 . 3 < / caffeine . version > \n,Bump caffeine from 2 . 8 . 2 to 2 . 8 . 3 ( # 3296 ),584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 15 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 16 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 15 . Final to 5 . 4 . 16 . Final ( # 3297 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 15 . Final to 5 . 4 . 16 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / 5 . 4 . 16 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 15 . . . 5 . 4 . 16 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < pgpverify - maven - plugin . version > 1 . 7 . 0 < / pgpverify - maven - plugin . version > \n + < pgpverify - maven - plugin . version > 1 . 8 . 0 < / pgpverify - maven - plugin . version > \n,Bump pgpverify - maven - plugin from 1 . 7 . 0 to 1 . 8 . 0 ( # 3302 ) \n Bumps [ pgpverify - maven - plugin ] ( https : / / github . com / s4u / pgpverify - maven - plugin ) from 1 . 7 . 0 to 1 . 8 . 0 . \n - [ Release notes ] ( https : / / github . com / s4u / pgpverify - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / s4u / pgpverify - maven - plugin / compare / v1 . 7 . 0 . . . v1 . 8 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < caffeine . version > 2 . 8 . 3 < / caffeine . version > \n + < caffeine . version > 2 . 8 . 4 < / caffeine . version > \n,Bump caffeine from 2 . 8 . 3 to 2 . 8 . 4 ( # 3303 ),584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 28 . v20200408 < / jetty . version > \n + < jetty . version > 9 . 4 . 29 . v20200521 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 28 . v20200408 to 9 . 4 . 29 . v20200521 ( # 3304 ) \n Bumps ` jetty . version ` from 9 . 4 . 28 . v20200408 to 9 . 4 . 29 . v20200521 . \n Updates ` jetty - bom ` from 9 . 4 . 28 . v20200408 to 9 . 4 . 29 . v20200521 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 28 . v20200408 . . . jetty - 9 . 4 . 29 . v20200521 ) \n Updates ` jetty - servlet ` from 9 . 4 . 28 . v20200408 to 9 . 4 . 29 . v20200521 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 28 . v20200408 . . . jetty - 9 . 4 . 29 . v20200521 ) \n Updates ` jetty - http ` from 9 . 4 . 28 . v20200408 to 9 . 4 . 29 . v20200521 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 28 . v20200408 . . . jetty - 9 . 4 . 29 . v20200521 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jersey . version > 2 . 30 . 1 < / jersey . version > \n + < jersey . version > 2 . 31 < / jersey . version > \n,Bump jersey - bom from 2 . 30 . 1 to 2 . 31 ( # 3307 ),584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 8 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 9 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 8 to 4 . 1 . 9 ( # 3308 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 8 to 4 . 1 . 9 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 8 . . . v4 . 1 . 9 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ requirements . txt \n - Sphinx = = 3 . 0 . 3 \n + Sphinx = = 3 . 0 . 4 \n,Bump sphinx from 3 . 0 . 3 to 3 . 0 . 4 in / docs ( # 3310 ) \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < bcprov - jdk15on . version > 1 . 65 < / bcprov - jdk15on . version > \n + < bcprov - jdk15on . version > 1 . 65 . 01 < / bcprov - jdk15on . version > \n,Bump bcprov - jdk15on from 1 . 65 to 1 . 65 . 01 ( # 3312 ) \n Bumps [ bcprov - jdk15on ] ( https : / / github . com / bcgit / bc - java ) from 1 . 65 to 1 . 65 . 01 . \n - [ Release notes ] ( https : / / github . com / bcgit / bc - java / releases ) \n - [ Changelog ] ( https : / / github . com / bcgit / bc - java / blob / master / docs / releasenotes . html ) \n - [ Commits ] ( https : / / github . com / bcgit / bc - java / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jackson . version > 2 . 10 . 1 < / jackson . version > \n + < jackson . version > 2 . 10 . 2 < / jackson . version > \n,Bump jackson - bom from 2 . 10 . 1 to 2 . 10 . 2 ( # 3092 ) \n Bumps [ jackson - bom ] ( https : / / github . com / FasterXML / jackson - bom ) from 2 . 10 . 1 to 2 . 10 . 2 . \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - bom / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - bom / compare / jackson - bom - 2 . 10 . 1 . . . jackson - bom - 2 . 10 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 0 . 1 < / checker - qual . version > \n + < checker - qual . version > 3 . 1 . 0 < / checker - qual . version > \n,Bump checker - qual from 3 . 0 . 1 to 3 . 1 . 0 ( # 3093 ) \n Bumps [ checker - qual ] ( https : / / github . com / typetools / checker - framework ) from 3 . 0 . 1 to 3 . 1 . 0 . \n - [ Release notes ] ( https : / / github . com / typetools / checker - framework / releases ) \n - [ Changelog ] ( https : / / github . com / typetools / checker - framework / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / typetools / checker - framework / compare / checker - framework - 3 . 0 . 1 . . . checker - framework - 3 . 1 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < junit . version > 4 . 12 < / junit . version > \n + < junit . version > 4 . 13 < / junit . version > \n,Bump junit from 4 . 12 to 4 . 13 ( # 3088 ) \n Bumps [ junit ] ( https : / / github . com / junit - team / junit4 ) from 4 . 12 to 4 . 13 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit4 / releases ) \n - [ Changelog ] ( https : / / github . com / junit - team / junit4 / blob / master / doc / ReleaseNotes4 . 12 . md ) \n - [ Commits ] ( https : / / github . com / junit - team / junit4 / compare / r4 . 12 . . . r4 . 13 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < freemarker . version > 2 . 3 . 29 < / freemarker . version > \n + < freemarker . version > 2 . 3 . 30 < / freemarker . version > \n,Bump freemarker from 2 . 3 . 29 to 2 . 3 . 30 ( # 3182 ) \n Bumps freemarker from 2 . 3 . 29 to 2 . 3 . 30 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ pom . xml \n - < version > 2 . 7 . 0 < / version > \n + < version > 2 . 9 . 0 < / version > \n,Bump sphinx - maven - plugin from 2 . 7 . 0 to 2 . 9 . 0 ( # 3231 ) \n Bumps [ sphinx - maven - plugin ] ( https : / / github . com / trustin / sphinx - maven - plugin ) from 2 . 7 . 0 to 2 . 9 . 0 . \n - [ Release notes ] ( https : / / github . com / trustin / sphinx - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / trustin / sphinx - maven - plugin / compare / sphinx - maven - plugin - 2 . 7 . 0 . . . sphinx - maven - plugin - 2 . 9 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 4 . 4 \n + Sphinx = = 3 . 0 . 0 \n,Bump sphinx from 2 . 4 . 4 to 3 . 0 . 0 in / docs ( # 3230 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 4 . 4 to 3 . 0 . 0 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 4 . 4 . . . v3 . 0 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < bcprov - jdk15on . version > 1 . 64 < / bcprov - jdk15on . version > \n + < bcprov - jdk15on . version > 1 . 65 < / bcprov - jdk15on . version > \n,Bump bcprov - jdk15on from 1 . 64 to 1 . 65 ( # 3232 ) \n Bumps [ bcprov - jdk15on ] ( https : / / github . com / bcgit / bc - java ) from 1 . 64 to 1 . 65 . \n - [ Release notes ] ( https : / / github . com / bcgit / bc - java / releases ) \n - [ Changelog ] ( https : / / github . com / bcgit / bc - java / blob / master / docs / releasenotes . html ) \n - [ Commits ] ( https : / / github . com / bcgit / bc - java / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < assertj . version > 3 . 15 . 0 < / assertj . version > \n + < assertj . version > 3 . 16 . 0 < / assertj . version > \n,Bump assertj - core from 3 . 15 . 0 to 3 . 16 . 0 ( # 3281 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 15 . 0 to 3 . 16 . 0 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 15 . 0 . . . assertj - core - 3 . 16 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 1 . 0 "" \n + ext . bndVersion = "" 5 . 1 . 1 "" \n",Bump biz . aQute . bnd . gradle from 5 . 1 . 0 to 5 . 1 . 1 ( # 7009 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 1 . 0 to 5 . 1 . 1 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 15 . 2 "" \n + ext . jfrogExtractorVersion = "" 4 . 16 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 15 . 2 to 4 . 16 . 0 ( # 7013 ) \n Bumps build - info - extractor - gradle from 4 . 15 . 2 to 4 . 16 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . junitVersion = "" 4 . 12 "" \n + ext . junitVersion = "" 4 . 13 "" \n",Bump junit from 4 . 12 to 4 . 13 ( # 6810 ) \n Bumps [ junit ] ( https : / / github . com / junit - team / junit4 ) from 4 . 12 to 4 . 13 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit4 / releases ) \n - [ Changelog ] ( https : / / github . com / junit - team / junit4 / blob / master / doc / ReleaseNotes4 . 12 . md ) \n - [ Commits ] ( https : / / github . com / junit - team / junit4 / compare / r4 . 12 . . . r4 . 13 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 13 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 14 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 13 . Final to 5 . 4 . 14 . Final ( # 3234 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 13 . Final to 5 . 4 . 14 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 13 . . . 5 . 4 . 14 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 3 . 3 "" \n + ext . mockitoVersion = "" 3 . 4 . 0 "" \n",Bump mockito - core from 3 . 3 . 3 to 3 . 4 . 0 ( # 7027 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 3 . 3 to 3 . 4 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 3 . 3 . . . v3 . 4 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 4 . 0 "" \n + ext . mockitoVersion = "" 3 . 4 . 2 "" \n",Bump mockito - core from 3 . 4 . 0 to 3 . 4 . 2 ( # 7031 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 4 . 0 to 3 . 4 . 2 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 4 . 0 . . . v3 . 4 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 4 . 2 "" \n + ext . mockitoVersion = "" 3 . 4 . 4 "" \n",Bump mockito - core from 3 . 4 . 2 to 3 . 4 . 4 ( # 7035 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 4 . 2 to 3 . 4 . 4 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 4 . 2 . . . v3 . 4 . 4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 1 . 1 "" \n + ext . bndVersion = "" 5 . 1 . 2 "" \n",Bump biz . aQute . bnd . gradle from 5 . 1 . 1 to 5 . 1 . 2 ( # 7038 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 1 . 1 to 5 . 1 . 2 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 4 . 4 "" \n + ext . mockitoVersion = "" 3 . 4 . 6 "" \n",Bump mockito - core from 3 . 4 . 4 to 3 . 4 . 6 ( # 7043 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 4 . 4 to 3 . 4 . 6 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 4 . 4 . . . v3 . 4 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
pom . xml \n - < version > 3 . 0 . 0 - M3 < / version > \n + < version > 3 . 0 . 0 - M4 < / version > \n,Bump maven - surefire - plugin from 3 . 0 . 0 - M3 to 3 . 0 . 0 - M4 ( # 1126 ) \n Bumps [ maven - surefire - plugin ] ( https : / / github . com / apache / maven - surefire ) from 3 . 0 . 0 - M3 to 3 . 0 . 0 - M4 . \n - [ Release notes ] ( https : / / github . com / apache / maven - surefire / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - surefire / compare / surefire - 3 . 0 . 0 - M3 . . . surefire - 3 . 0 . 0 - M4 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < mongo - java - driver . version > 3 . 3 . 0 < / mongo - java - driver . version > \n + < mongo - java - driver . version > 3 . 12 . 0 < / mongo - java - driver . version > \n,Bump mongo - java - driver from 3 . 3 . 0 to 3 . 12 . 0 ( # 1127 ) \n Bumps [ mongo - java - driver ] ( https : / / github . com / mongodb / mongo - java - driver ) from 3 . 3 . 0 to 3 . 12 . 0 . \n - [ Release notes ] ( https : / / github . com / mongodb / mongo - java - driver / releases ) \n - [ Commits ] ( https : / / github . com / mongodb / mongo - java - driver / compare / r3 . 3 . 0 . . . r3 . 12 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
naked - objects \ pom . xml \n - < version > 2 . 4 < / version > \n + < version > 3 . 2 . 3 < / version > \n,Bump maven - war - plugin from 2 . 4 to 3 . 2 . 3 ( # 1129 ) \n Bumps [ maven - war - plugin ] ( https : / / github . com / apache / maven - war - plugin ) from 2 . 4 to 3 . 2 . 3 . \n - [ Release notes ] ( https : / / github . com / apache / maven - war - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - war - plugin / compare / maven - war - plugin - 2 . 4 . . . maven - war - plugin - 3 . 2 . 3 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 8 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 9 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 8 to 3 . 8 . 9 ( # 3237 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 8 to 3 . 8 . 9 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 9 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 8 . . . v3 . 8 . 9 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 1 . 4 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 5 . Final < / hibernate - validator . version > \n dropwizard - validation \ src \ test \ java \ io \ dropwizard \ validation \ SelfValidationTest . java \n - "" A2 "" , \n + "" $ \ \ A { 1 + 1 } "" , \n",Bump hibernate - validator from 6 . 1 . 4 . Final to 6 . 1 . 5 . Final ( # 3282 ) \n * Bump hibernate - validator from 6 . 1 . 4 . Final to 6 . 1 . 5 . Final \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 1 . 4 . Final to 6 . 1 . 5 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / 6 . 1 . 5 . Final / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 1 . 4 . Final . . . 6 . 1 . 5 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n * Fix SelfValidationTest # violationMessagesAreInterpolatedIfEscapingDisabled \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com > \n Co - authored - by : Jochen Schalanda < jochen @ schalanda . name >,584
"build . gradle \n - ext . animalSnifferVersion = "" 1 . 5 . 0 "" \n + ext . animalSnifferVersion = "" 1 . 5 . 1 "" \n",Bump gradle - animalsniffer - plugin from 1 . 5 . 0 to 1 . 5 . 1 ( # 7007 ) \n Bumps gradle - animalsniffer - plugin from 1 . 5 . 0 to 1 . 5 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 16 . 1 "" \n + ext . jfrogExtractorVersion = "" 4 . 17 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 16 . 1 to 4 . 17 . 0 ( # 7053 ) \n Bumps build - info - extractor - gradle from 4 . 16 . 1 to 4 . 17 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 4 . 6 "" \n + ext . mockitoVersion = "" 3 . 5 . 0 "" \n",Bump mockito - core from 3 . 4 . 6 to 3 . 5 . 0 ( # 7057 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 4 . 6 to 3 . 5 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 4 . 6 . . . v3 . 5 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 17 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 17 . 1 "" \n",Bump build - info - extractor - gradle from 4 . 17 . 0 to 4 . 17 . 1 ( # 7059 ) \n Bumps build - info - extractor - gradle from 4 . 17 . 0 to 4 . 17 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 0 "" \n + ext . mockitoVersion = "" 3 . 5 . 2 "" \n",Bump mockito - core from 3 . 5 . 0 to 3 . 5 . 2 ( # 7060 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 0 to 3 . 5 . 2 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 0 . . . v3 . 5 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 2 "" \n + ext . mockitoVersion = "" 3 . 5 . 5 "" \n",Bump mockito - core from 3 . 5 . 2 to 3 . 5 . 5 ( # 7062 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 2 to 3 . 5 . 5 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 2 . . . v3 . 5 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 5 "" \n + ext . mockitoVersion = "" 3 . 5 . 6 "" \n",Bump mockito - core from 3 . 5 . 5 to 3 . 5 . 6 ( # 7063 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 5 to 3 . 5 . 6 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 5 . . . v3 . 5 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 6 "" \n + ext . mockitoVersion = "" 3 . 5 . 7 "" \n",Bump mockito - core from 3 . 5 . 6 to 3 . 5 . 7 ( # 7064 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 6 to 3 . 5 . 7 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 6 . . . v3 . 5 . 7 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jmhGradleVersion = "" 0 . 5 . 0 "" \n + ext . jmhGradleVersion = "" 0 . 5 . 1 "" \n",Bump jmh - gradle - plugin from 0 . 5 . 0 to 0 . 5 . 1 ( # 7066 ) \n Bumps jmh - gradle - plugin from 0 . 5 . 0 to 0 . 5 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 17 . 1 "" \n + ext . jfrogExtractorVersion = "" 4 . 17 . 2 "" \n",Bump build - info - extractor - gradle from 4 . 17 . 1 to 4 . 17 . 2 ( # 7067 ) \n Bumps build - info - extractor - gradle from 4 . 17 . 1 to 4 . 17 . 2 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ requirements . txt \n - Sphinx = = 2 . 3 . 1 \n + Sphinx = = 2 . 4 . 0 \n,Bump sphinx from 2 . 3 . 1 to 2 . 4 . 0 in / docs ( # 3132 ) \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 2 . 3 . 1 to 2 . 4 . 0 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / master / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v2 . 3 . 1 . . . v2 . 4 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < pgpverify - maven - plugin . version > 1 . 5 . 1 < / pgpverify - maven - plugin . version > \n + < pgpverify - maven - plugin . version > 1 . 7 . 0 < / pgpverify - maven - plugin . version > \n,Bump pgpverify - maven - plugin from 1 . 5 . 1 to 1 . 7 . 0 ( # 3184 ) \n Bumps [ pgpverify - maven - plugin ] ( https : / / github . com / s4u / pgpverify - maven - plugin ) from 1 . 5 . 1 to 1 . 7 . 0 . \n - [ Release notes ] ( https : / / github . com / s4u / pgpverify - maven - plugin / releases ) \n - [ Commits ] ( https : / / github . com / s4u / pgpverify - maven - plugin / compare / pgpverify - maven - plugin - 1 . 5 . 1 . . . v1 . 7 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 4 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 5 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 4 to 4 . 1 . 5 ( # 3188 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 4 to 4 . 1 . 5 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 4 . . . v4 . 1 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < httpclient . version > 4 . 5 . 11 < / httpclient . version > \n + < httpclient . version > 4 . 5 . 12 < / httpclient . version > \n,Bump httpclient from 4 . 5 . 11 to 4 . 5 . 12 ( # 3183 ) \n Bumps httpclient from 4 . 5 . 11 to 4 . 5 . 12 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 33 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 34 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 33 to 9 . 0 . 34 ( # 3238 ) \n Bumps tomcat - jdbc from 9 . 0 . 33 to 9 . 0 . 34 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < checker - qual . version > 3 . 3 . 0 < / checker - qual . version > \n + < checker - qual . version > 3 . 4 . 0 < / checker - qual . version > \n,Bump checker - qual from 3 . 3 . 0 to 3 . 4 . 0 ( # 3275 ),584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 16 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 16 . 1 "" \n",Bump build - info - extractor - gradle from 4 . 16 . 0 to 4 . 16 . 1 ( # 7024 ) \n Bumps build - info - extractor - gradle from 4 . 16 . 0 to 4 . 16 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 10 "" \n + ext . mockitoVersion = "" 3 . 5 . 11 "" \n",Bump mockito - core from 3 . 5 . 10 to 3 . 5 . 11 ( # 7077 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 10 to 3 . 5 . 11 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 10 . . . v3 . 5 . 11 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 11 "" \n + ext . mockitoVersion = "" 3 . 5 . 13 "" \n",Bump mockito - core from 3 . 5 . 11 to 3 . 5 . 13 ( # 7086 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 11 to 3 . 5 . 13 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 11 . . . v3 . 5 . 13 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 4 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 5 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 4 to 3 . 8 . 5 ( # 3095 ) \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 4 to 3 . 8 . 5 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / v3 . 8 . 5 / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 4 . . . v3 . 8 . 5 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < liquibase - core . version > 3 . 8 . 5 < / liquibase - core . version > \n + < liquibase - core . version > 3 . 8 . 6 < / liquibase - core . version > \n,Bump liquibase - core from 3 . 8 . 5 to 3 . 8 . 6 \n Bumps [ liquibase - core ] ( https : / / github . com / liquibase / liquibase ) from 3 . 8 . 5 to 3 . 8 . 6 . \n - [ Release notes ] ( https : / / github . com / liquibase / liquibase / releases ) \n - [ Changelog ] ( https : / / github . com / liquibase / liquibase / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / liquibase / liquibase / compare / v3 . 8 . 5 . . . v3 . 8 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - core . version > 5 . 4 . 10 . Final < / hibernate - core . version > \n + < hibernate - core . version > 5 . 4 . 11 . Final < / hibernate - core . version > \n,Bump hibernate - core from 5 . 4 . 10 . Final to 5 . 4 . 11 . Final ( # 3137 ) \n Bumps [ hibernate - core ] ( https : / / github . com / hibernate / hibernate - orm ) from 5 . 4 . 10 . Final to 5 . 4 . 11 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - orm / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - orm / blob / master / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - orm / compare / 5 . 4 . 10 . . . 5 . 4 . 11 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < metrics4 . version > 4 . 1 . 5 < / metrics4 . version > \n + < metrics4 . version > 4 . 1 . 6 < / metrics4 . version > \n,Bump metrics - bom from 4 . 1 . 5 to 4 . 1 . 6 ( # 3241 ) \n Bumps [ metrics - bom ] ( https : / / github . com / dropwizard / metrics ) from 4 . 1 . 5 to 4 . 1 . 6 . \n - [ Release notes ] ( https : / / github . com / dropwizard / metrics / releases ) \n - [ Commits ] ( https : / / github . com / dropwizard / metrics / compare / v4 . 1 . 5 . . . v4 . 1 . 6 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
docs \ requirements . txt \n - Sphinx = = 3 . 0 . 0 \n + Sphinx = = 3 . 0 . 1 \n,Bump sphinx from 3 . 0 . 0 to 3 . 0 . 1 in / docs \n Bumps [ sphinx ] ( https : / / github . com / sphinx - doc / sphinx ) from 3 . 0 . 0 to 3 . 0 . 1 . \n - [ Release notes ] ( https : / / github . com / sphinx - doc / sphinx / releases ) \n - [ Changelog ] ( https : / / github . com / sphinx - doc / sphinx / blob / 3 . x / CHANGES ) \n - [ Commits ] ( https : / / github . com / sphinx - doc / sphinx / compare / v3 . 0 . 0 . . . v3 . 0 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 1 . 2 "" \n + ext . bndVersion = "" 5 . 2 . 0 "" \n",Bump biz . aQute . bnd . gradle from 5 . 1 . 2 to 5 . 2 . 0 ( # 7097 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 1 . 2 to 5 . 2 . 0 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . guavaVersion = "" 29 . 0 - jre "" \n + ext . guavaVersion = "" 30 . 0 - jre "" \n",Bump guava from 29 . 0 - jre to 30 . 0 - jre ( # 7098 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 29 . 0 - jre to 30 . 0 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 13 "" \n + ext . mockitoVersion = "" 3 . 5 . 15 "" \n",Bump mockito - core from 3 . 5 . 13 to 3 . 5 . 15 ( # 7099 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 13 to 3 . 5 . 15 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 13 . . . v3 . 5 . 15 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 15 "" \n + ext . mockitoVersion = "" 3 . 6 . 0 "" \n",Bump mockito - core from 3 . 5 . 15 to 3 . 6 . 0 ( # 7103 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 15 to 3 . 6 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 15 . . . v3 . 6 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 17 . 2 "" \n + ext . jfrogExtractorVersion = "" 4 . 18 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 17 . 2 to 4 . 18 . 0 ( # 7102 ) \n Bumps build - info - extractor - gradle from 4 . 17 . 2 to 4 . 18 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
value - object \ pom . xml \n - < version > 19 . 0 < / version > \n + < version > 23 . 0 < / version > \n,Bump guava - testlib from 19 . 0 to 23 . 0 ( # 1130 ) \n Bumps [ guava - testlib ] ( https : / / github . com / google / guava ) from 19 . 0 to 23 . 0 . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / compare / v19 . 0 . . . v23 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
pom . xml \n - < jackson . version > 2 . 8 . 5 < / jackson . version > \n + < jackson . version > 2 . 10 . 2 < / jackson . version > \n,[ Security ] Bump jackson . version from 2 . 8 . 5 to 2 . 10 . 2 ( # 1133 ) \n Bumps ` jackson . version ` from 2 . 8 . 5 to 2 . 10 . 2 . \n Updates ` jackson - core ` from 2 . 8 . 5 to 2 . 10 . 2 \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson - core / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson - core / compare / jackson - core - 2 . 8 . 5 . . . jackson - core - 2 . 10 . 2 ) \n Updates ` jackson - databind ` from 2 . 8 . 5 to 2 . 10 . 2 \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson / commits ) \n Updates ` jackson - annotations ` from 2 . 8 . 5 to 2 . 10 . 2 \n - [ Release notes ] ( https : / / github . com / FasterXML / jackson / releases ) \n - [ Commits ] ( https : / / github . com / FasterXML / jackson / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
caching \ pom . xml \n - < version > 3 . 0 . 4 < / version > \n + < version > 3 . 12 . 0 < / version > \n,Bump mongodb - driver from 3 . 0 . 4 to 3 . 12 . 0 ( # 1135 ) \n Bumps [ mongodb - driver ] ( https : / / github . com / mongodb / mongo - java - driver ) from 3 . 0 . 4 to 3 . 12 . 0 . \n - [ Release notes ] ( https : / / github . com / mongodb / mongo - java - driver / releases ) \n - [ Commits ] ( https : / / github . com / mongodb / mongo - java - driver / compare / r3 . 0 . 4 . . . r3 . 12 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
docs \ Gemfile . lock \n - octokit ( 4 . 16 . 0 ) \n + octokit ( 4 . 17 . 0 ) \n,Bump octokit from 4 . 16 . 0 to 4 . 17 . 0 in / docs ( # 3189 ) \n Bumps [ octokit ] ( https : / / github . com / octokit / octokit . rb ) from 4 . 16 . 0 to 4 . 17 . 0 . \n - [ Release notes ] ( https : / / github . com / octokit / octokit . rb / releases ) \n - [ Changelog ] ( https : / / github . com / octokit / octokit . rb / blob / 4 - stable / RELEASE . md ) \n - [ Commits ] ( https : / / github . com / octokit / octokit . rb / compare / v4 . 16 . 0 . . . v4 . 17 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - example \ pom . xml \n - < version > 3 . 8 . 2 < / version > \n + < version > 3 . 9 . 0 < / version > \n pom . xml \n - < maven - site - plugin . version > 3 . 8 . 2 < / maven - site - plugin . version > \n + < maven - site - plugin . version > 3 . 9 . 0 < / maven - site - plugin . version > \n,Bump maven - site - plugin from 3 . 8 . 2 to 3 . 9 . 0 ( # 3190 ) \n Bumps [ maven - site - plugin ] ( https : / / github . com / apache / maven - site - plugin ) from 3 . 8 . 2 to 3 . 9 . 0 . \n - [ Release notes ] ( https : / / github . com / apache / maven - site - plugin / releases ) \n - [ Commits ] ( https : / / github . com / apache / maven - site - plugin / compare / maven - site - plugin - 3 . 8 . 2 . . . maven - site - plugin - 3 . 9 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bintrayVersion = "" 1 . 8 . 4 "" \n + ext . bintrayVersion = "" 1 . 8 . 5 "" \n",Bump gradle - bintray - plugin from 1 . 8 . 4 to 1 . 8 . 5 ( # 6951 ) \n Bumps gradle - bintray - plugin from 1 . 8 . 4 to 1 . 8 . 5 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < assertj . version > 3 . 16 . 0 < / assertj . version > \n + < assertj . version > 3 . 16 . 1 < / assertj . version > \n,Bump assertj - core from 3 . 16 . 0 to 3 . 16 . 1 ( # 3288 ) \n Bumps [ assertj - core ] ( https : / / github . com / joel - costigliola / assertj - core ) from 3 . 16 . 0 to 3 . 16 . 1 . \n - [ Release notes ] ( https : / / github . com / joel - costigliola / assertj - core / releases ) \n - [ Commits ] ( https : / / github . com / joel - costigliola / assertj - core / compare / assertj - core - 3 . 16 . 0 . . . assertj - core - 3 . 16 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 6 . 0 "" \n + ext . mockitoVersion = "" 3 . 6 . 28 "" \n",Bump mockito - core from 3 . 6 . 0 to 3 . 6 . 28 ( # 7116 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 6 . 0 to 3 . 6 . 28 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 6 . 0 . . . v3 . 6 . 28 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 18 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 18 . 1 "" \n",Bump build - info - extractor - gradle from 4 . 18 . 0 to 4 . 18 . 1 ( # 7118 ) \n Bumps build - info - extractor - gradle from 4 . 18 . 0 to 4 . 18 . 1 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 30 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 31 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 30 to 9 . 0 . 31 ( # 3143 ) \n Bumps tomcat - jdbc from 9 . 0 . 30 to 9 . 0 . 31 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com >,584
dropwizard - dependencies \ pom . xml \n - < hibernate - validator . version > 6 . 1 . 2 . Final < / hibernate - validator . version > \n + < hibernate - validator . version > 6 . 1 . 3 . Final < / hibernate - validator . version > \n,Bump hibernate - validator from 6 . 1 . 2 . Final to 6 . 1 . 3 . Final ( # 3249 ) \n Bumps [ hibernate - validator ] ( https : / / github . com / hibernate / hibernate - validator ) from 6 . 1 . 2 . Final to 6 . 1 . 3 . Final . \n - [ Release notes ] ( https : / / github . com / hibernate / hibernate - validator / releases ) \n - [ Changelog ] ( https : / / github . com / hibernate / hibernate - validator / blob / 6 . 1 . 3 . Final / changelog . txt ) \n - [ Commits ] ( https : / / github . com / hibernate / hibernate - validator / compare / 6 . 1 . 2 . Final . . . 6 . 1 . 3 . Final ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - example \ pom . xml \n - < junit5 . version > 5 . 6 . 1 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 2 < / junit5 . version > \n,Bump junit - jupiter from 5 . 6 . 1 to 5 . 6 . 2 ( # 3247 ) \n Bumps [ junit - jupiter ] ( https : / / github . com / junit - team / junit5 ) from 5 . 6 . 1 to 5 . 6 . 2 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 1 . . . r5 . 6 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < jetty . version > 9 . 4 . 27 . v20200227 < / jetty . version > \n + < jetty . version > 9 . 4 . 28 . v20200408 < / jetty . version > \n,Bump jetty . version from 9 . 4 . 27 . v20200227 to 9 . 4 . 28 . v20200408 ( # 3250 ) \n Bumps ` jetty . version ` from 9 . 4 . 27 . v20200227 to 9 . 4 . 28 . v20200408 . \n Updates ` jetty - bom ` from 9 . 4 . 27 . v20200227 to 9 . 4 . 28 . v20200408 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 27 . v20200227 . . . jetty - 9 . 4 . 28 . v20200408 ) \n Updates ` jetty - servlet ` from 9 . 4 . 27 . v20200227 to 9 . 4 . 28 . v20200408 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 27 . v20200227 . . . jetty - 9 . 4 . 28 . v20200408 ) \n Updates ` jetty - http ` from 9 . 4 . 27 . v20200227 to 9 . 4 . 28 . v20200408 \n - [ Release notes ] ( https : / / github . com / eclipse / jetty . project / releases ) \n - [ Commits ] ( https : / / github . com / eclipse / jetty . project / compare / jetty - 9 . 4 . 27 . v20200227 . . . jetty - 9 . 4 . 28 . v20200408 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < junit5 . version > 5 . 6 . 1 < / junit5 . version > \n + < junit5 . version > 5 . 6 . 2 < / junit5 . version > \n,Bump junit5 . version from 5 . 6 . 1 to 5 . 6 . 2 ( # 3248 ) \n Bumps ` junit5 . version ` from 5 . 6 . 1 to 5 . 6 . 2 . \n Updates ` junit - bom ` from 5 . 6 . 1 to 5 . 6 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 1 . . . r5 . 6 . 2 ) \n Updates ` junit - vintage - engine ` from 5 . 6 . 1 to 5 . 6 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 1 . . . r5 . 6 . 2 ) \n Updates ` junit - jupiter - engine ` from 5 . 6 . 1 to 5 . 6 . 2 \n - [ Release notes ] ( https : / / github . com / junit - team / junit5 / releases ) \n - [ Commits ] ( https : / / github . com / junit - team / junit5 / compare / r5 . 6 . 1 . . . r5 . 6 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
dropwizard - dependencies \ pom . xml \n - < tomcat - jdbc . version > 9 . 0 . 34 < / tomcat - jdbc . version > \n + < tomcat - jdbc . version > 9 . 0 . 35 < / tomcat - jdbc . version > \n,Bump tomcat - jdbc from 9 . 0 . 34 to 9 . 0 . 35 ( # 3290 ) \n Bumps tomcat - jdbc from 9 . 0 . 34 to 9 . 0 . 35 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 5 . 9 "" \n + ext . mockitoVersion = "" 3 . 5 . 10 "" \n",Bump mockito - core from 3 . 5 . 9 to 3 . 5 . 10 ( # 7070 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 5 . 9 to 3 . 5 . 10 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 5 . 9 . . . v3 . 5 . 10 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . junitVersion = "" 4 . 13 "" \n + ext . junitVersion = "" 4 . 13 . 1 "" \n",Bump junit from 4 . 13 to 4 . 13 . 1 ( # 7094 ) \n Bumps [ junit ] ( https : / / github . com / junit - team / junit4 ) from 4 . 13 to 4 . 13 . 1 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit4 / releases ) \n - [ Changelog ] ( https : / / github . com / junit - team / junit4 / blob / main / doc / ReleaseNotes4 . 13 . 1 . md ) \n - [ Commits ] ( https : / / github . com / junit - team / junit4 / compare / r4 . 13 . . . r4 . 13 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . guavaVersion = "" 30 . 0 - jre "" \n + ext . guavaVersion = "" 30 . 1 - jre "" \n",Bump guava from 30 . 0 - jre to 30 . 1 - jre ( # 7134 ) \n Bumps [ guava ] ( https : / / github . com / google / guava ) from 30 . 0 - jre to 30 . 1 - jre . \n - [ Release notes ] ( https : / / github . com / google / guava / releases ) \n - [ Commits ] ( https : / / github . com / google / guava / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 18 . 2 "" \n + ext . jfrogExtractorVersion = "" 4 . 18 . 3 "" \n",Bump build - info - extractor - gradle from 4 . 18 . 2 to 4 . 18 . 3 ( # 7140 ) \n Bumps build - info - extractor - gradle from 4 . 18 . 2 to 4 . 18 . 3 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 7 . 0 "" \n + ext . mockitoVersion = "" 3 . 7 . 7 "" \n",Bump mockito - core from 3 . 7 . 0 to 3 . 7 . 7 ( # 7152 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 7 . 0 to 3 . 7 . 7 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 7 . 0 . . . v3 . 7 . 7 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 18 . 3 "" \n + ext . jfrogExtractorVersion = "" 4 . 19 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 18 . 3 to 4 . 19 . 0 ( # 7159 ) \n Bumps build - info - extractor - gradle from 4 . 18 . 3 to 4 . 19 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 19 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 20 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 19 . 0 to 4 . 20 . 0 ( # 7171 ) \n Bumps build - info - extractor - gradle from 4 . 19 . 0 to 4 . 20 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . vanniktechPublishPlugin = "" 0 . 13 . 0 "" \n + ext . vanniktechPublishPlugin = "" 0 . 14 . 1 "" \n",Bump gradle - maven - publish - plugin from 0 . 13 . 0 to 0 . 14 . 1 ( # 7186 ) \n Bumps [ gradle - maven - publish - plugin ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin ) from 0 . 13 . 0 to 0 . 14 . 1 . \n - [ Release notes ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / releases ) \n - [ Changelog ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / blob / master / CHANGELOG . md ) \n - [ Commits ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / compare / 0 . 13 . 0 . . . 0 . 14 . 1 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . vanniktechPublishPlugin = "" 0 . 14 . 1 "" \n + ext . vanniktechPublishPlugin = "" 0 . 14 . 2 "" \n",Bump gradle - maven - publish - plugin from 0 . 14 . 1 to 0 . 14 . 2 ( # 7189 ) \n Bumps [ gradle - maven - publish - plugin ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin ) from 0 . 14 . 1 to 0 . 14 . 2 . \n - [ Release notes ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / releases ) \n - [ Changelog ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / blob / master / CHANGELOG . md ) \n - [ Commits ] ( https : / / github . com / vanniktech / gradle - maven - publish - plugin / compare / 0 . 14 . 1 . . . 0 . 14 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . junitVersion = "" 4 . 13 . 1 "" \n + ext . junitVersion = "" 4 . 13 . 2 "" \n",Bump junit from 4 . 13 . 1 to 4 . 13 . 2 ( # 7188 ) \n Bumps [ junit ] ( https : / / github . com / junit - team / junit4 ) from 4 . 13 . 1 to 4 . 13 . 2 . \n - [ Release notes ] ( https : / / github . com / junit - team / junit4 / releases ) \n - [ Changelog ] ( https : / / github . com / junit - team / junit4 / blob / main / doc / ReleaseNotes4 . 13 . 1 . md ) \n - [ Commits ] ( https : / / github . com / junit - team / junit4 / compare / r4 . 13 . 1 . . . r4 . 13 . 2 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jmhGradleVersion = "" 0 . 5 . 2 "" \n + ext . jmhGradleVersion = "" 0 . 5 . 3 "" \n",Bump jmh - gradle - plugin from 0 . 5 . 2 to 0 . 5 . 3 ( # 7182 ) \n Bumps jmh - gradle - plugin from 0 . 5 . 2 to 0 . 5 . 3 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . animalSnifferVersion = "" 1 . 5 . 2 "" \n + ext . animalSnifferVersion = "" 1 . 5 . 3 "" \n",Bump gradle - animalsniffer - plugin from 1 . 5 . 2 to 1 . 5 . 3 ( # 7192 ) \n Bumps gradle - animalsniffer - plugin from 1 . 5 . 2 to 1 . 5 . 3 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . bndVersion = "" 5 . 2 . 0 "" \n + ext . bndVersion = "" 5 . 3 . 0 "" \n",Bump biz . aQute . bnd . gradle from 5 . 2 . 0 to 5 . 3 . 0 ( # 7194 ) \n Bumps [ biz . aQute . bnd . gradle ] ( https : / / github . com / bndtools / bnd ) from 5 . 2 . 0 to 5 . 3 . 0 . \n - [ Release notes ] ( https : / / github . com / bndtools / bnd / releases ) \n - [ Changelog ] ( https : / / github . com / bndtools / bnd / blob / master / docs / ADDING _ RELEASE _ DOCS . md ) \n - [ Commits ] ( https : / / github . com / bndtools / bnd / commits ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 7 . 7 "" \n + ext . mockitoVersion = "" 3 . 8 . 0 "" \n",Bump mockito - core from 3 . 7 . 7 to 3 . 8 . 0 ( # 7193 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 7 . 7 to 3 . 8 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 7 . 7 . . . v3 . 8 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . jfrogExtractorVersion = "" 4 . 20 . 0 "" \n + ext . jfrogExtractorVersion = "" 4 . 21 . 0 "" \n",Bump build - info - extractor - gradle from 4 . 20 . 0 to 4 . 21 . 0 ( # 7198 ) \n Bumps build - info - extractor - gradle from 4 . 20 . 0 to 4 . 21 . 0 . \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
"build . gradle \n - ext . mockitoVersion = "" 3 . 6 . 28 "" \n + ext . mockitoVersion = "" 3 . 7 . 0 "" \n",Bump mockito - core from 3 . 6 . 28 to 3 . 7 . 0 ( # 7141 ) \n Bumps [ mockito - core ] ( https : / / github . com / mockito / mockito ) from 3 . 6 . 28 to 3 . 7 . 0 . \n - [ Release notes ] ( https : / / github . com / mockito / mockito / releases ) \n - [ Commits ] ( https : / / github . com / mockito / mockito / compare / v3 . 6 . 28 . . . v3 . 7 . 0 ) \n Signed - off - by : dependabot - preview [ bot ] < support @ dependabot . com > \n Co - authored - by : dependabot - preview [ bot ] < 27856297 + dependabot - preview [ bot ] @ users . noreply . github . com >,584
src \ clj \ clojure \ core . clj \n + ( [ ] identity ) \n,Added zero - arity body to comp function returning identity fn \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"test \ clojure \ test _ clojure \ other _ functions . clj \n + \n + ( deftest test - comp \n + ( let [ c0 ( comp ) ] \n + ( are [ x ] ( = ( identity x ) ( c0 x ) ) \n + nil \n + 42 \n + [ 1 2 3 ] \n + # { } \n + : foo ) \n + ( are [ x y ] ( = ( identity x ) ( c0 y ) ) \n + ( + 1 2 3 ) 6 \n + ( keyword "" foo "" ) : foo ) ) ) \n + \n",Added tests for zero - arity comp implementation . \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
src \ clj \ clojure \ core _ proxy . clj \n - ( . proxy ( _ _ initClojureFnMappings mappings ) ) ) \n + ( . proxy ( _ _ initClojureFnMappings mappings ) ) \n + proxy ) \n - ( . proxy ( _ _ updateClojureFnMappings mappings ) ) ) \n + ( . proxy ( _ _ updateClojureFnMappings mappings ) ) \n + proxy ) \n,added proxy as return value for init - proxy and update - proxy \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"src \ clj \ clojure \ core _ proxy . clj \n - sets the proxy ' s fn map . "" \n + sets the proxy ' s fn map . Returns the proxy . "" \n - behavior of an existing instance without changing its identity . "" \n + behavior of an existing instance without changing its identity . \n + Returns the proxy . "" \n test \ clojure \ test _ clojure \ java _ interop . clj \n + ( deftest test - proxy - chain \n + ( testing "" That the proxy functions can chain "" \n + ( are [ x y ] ( = x y ) \n + ( - > ( get - proxy - class Object ) \n + construct - proxy \n + ( init - proxy { } ) \n + ( update - proxy { "" toString "" ( fn [ this ] "" chain chain chain "" ) } ) \n + str ) \n + "" chain chain chain "" \n + \n + ( - > ( proxy [ Object ] [ ] ( toString [ ] "" superfuzz bigmuff "" ) ) \n + ( update - proxy { "" toString "" ( fn [ this ] "" chain chain chain "" ) } ) \n + str ) \n + "" chain chain chain "" ) ) ) \n + \n",Added tests and updated docs for init - proxy and update - proxy . Also updated the docstrings . \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"test \ clojure \ test _ clojure \ java _ interop . clj \n - ( update - proxy { "" toString "" ( fn [ this ] "" chain chain chain "" ) } ) \n + ( update - proxy { "" toString "" ( fn [ _ ] "" chain chain chain "" ) } ) \n - ( update - proxy { "" toString "" ( fn [ this ] "" chain chain chain "" ) } ) \n + ( update - proxy { "" toString "" ( fn [ _ ] "" chain chain chain "" ) } ) \n",removed this ref \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
src \ clj \ clojure \ string . clj \n - ( : require ' [ clojure . string : as str ] ) ) \n + ( : require [ clojure . string : as str ] ) ) \n,CLJ - 674 : Modified clojure . string docstring to remove the quote in the require directive \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"test \ clojure \ test _ clojure \ compilation . clj \n + ( deftest test - CLJ - 671 - regression \n + ( testing "" that the presence of hints does not cause the compiler to infinitely loop "" \n + ( letfn [ ( gcd [ x y ] \n + ( loop [ x ( long x ) y ( long y ) ] \n + ( if ( = = y 0 ) \n + x \n + ( recur y ^ Long ( rem x y ) ) ) ) ) ] \n + ( is ( = 4 ( gcd 8 100 ) ) ) ) ) ) \n",Wrote regression for CLJ - 671 . \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"src \ clj \ clojure \ core _ print . clj \n - ( print "" ipcpd "" ) \n - ( defmethod print - dup clojure . lang . PersistentHashMap [ o w ] ( print "" phmpd "" ) ( print - method o w ) ) \n + ( defmethod print - dup clojure . lang . PersistentHashMap [ o w ] ( print - method o w ) ) \n",Fixes dumb little debug messages . CLJ - 794 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"src \ clj \ clojure \ core _ print . clj \n - ; ; Types \n - \n - ( defn - print - deftype [ o ^ Writer w ] \n - ( . write w "" # "" ) \n - ( . write w ( . getName ( class o ) ) ) \n - ( let [ basii ( for [ fld ( map str ( clojure . lang . Reflector / invokeStaticMethod ( class o ) "" getBasis "" ( to - array [ ] ) ) ) ] \n - ( clojure . lang . Reflector / getInstanceField o fld ) ) ] \n - ( print - sequential "" [ "" pr - on "" , "" "" ] "" basii w ) ) ) \n - \n - ( defmethod print - method clojure . lang . IType [ o ^ Writer w ] \n - ( print - deftype o w ) ) \n - \n - ( defmethod print - dup clojure . lang . IType [ o ^ Writer w ] \n - ( print - deftype o w ) ) \n - \n - \n test \ clojure \ test _ clojure \ protocols . clj \n - ( binding [ * print - dup * true * verbose - defrecords * true ] ( pr - str r ) ) ) ) \n - ( is ( = "" # clojure . test _ clojure . protocols . TypeToTestLiterals [ 42 ] "" \n - ( binding [ * print - dup * true ] ( pr - str ( TypeToTestLiterals . 42 ) ) ) ) ) ) ) ) \n + ( binding [ * print - dup * true * verbose - defrecords * true ] ( pr - str r ) ) ) ) ) ) ) \n",CLJ - 812 : Removed print - dup and print - method for deftypes \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
test \ clojure \ test _ clojure \ java _ interop . clj \n + ; ( . target - prop ) \n + ( are [ x y ] ( = x y ) \n + ( let [ p ( java . awt . Point . 1 2 ) ] \n + 1 ( . - x p ) \n + 2 ( . - y p ) \n + 1 ( . p - x ) \n + 2 ( . p - y ) \n + 1 ( . ( java . awt . Point . 1 2 ) - x ) \n + 2 ( . ( java . awt . Point . 1 2 ) - y ) ) ) \n + \n,CLJ - 872 : Added tests for prop lookup syntax \n Signed - off - by : Stuart Sierra < mail @ stuartsierra . com >,602
test \ clojure \ test _ clojure \ other _ functions . clj \n - ( let [ p1 ( partial + 20 ) \n + ( let [ p0 ( partial inc ) \n + p1 ( partial + 20 ) \n + ( is ( = 41 ( p0 40 ) ) ) \n,Wrote a test to exercise the patch on CLJ - 1012 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"test \ clojure \ test _ clojure \ protocols . clj \n - ( eval ' ( old - method ( reify Elusive ( new - method [ x ] : new - method ) ) ) ) ) ) ) \n - ( testing "" you can define a marker protocol "" \n - ( is ( = ' ( ) ( method - names clojure . test _ clojure . protocols . examples . MarkerProtocol ) ) ) ) ) \n + ( eval ' ( old - method ( reify Elusive ( new - method [ x ] : new - method ) ) ) ) ) ) ) ) \n + \n + ( deftype HasMarkers [ ] \n + ExampleProtocol \n + ( foo [ this ] "" foo "" ) \n + MarkerProtocol \n + MarkerProtocol2 ) \n + \n + ( deftype WillGetMarker [ ] \n + ExampleProtocol \n + ( foo [ this ] "" foo "" ) ) \n + \n + ( extend - type WillGetMarker MarkerProtocol ) \n + \n + ( deftest marker - tests \n + ( testing "" That a marker protocol has no methods "" \n + ( is ( = ' ( ) ( method - names clojure . test _ clojure . protocols . examples . MarkerProtocol ) ) ) ) \n + ( testing "" That types with markers are reportedly satifying them . "" \n + ( let [ hm ( HasMarkers . ) \n + wgm ( WillGetMarker . ) ] \n + ( is ( satisfies ? MarkerProtocol hm ) ) \n + ( is ( satisfies ? MarkerProtocol2 hm ) ) \n + ( is ( satisfies ? MarkerProtocol wgm ) ) ) ) ) \n test \ clojure \ test _ clojure \ protocols \ examples . clj \n + ( defprotocol MarkerProtocol2 ) \n + \n",Added further tests for marker protocols as defined in CLJ - 966 \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"src \ clj \ clojure \ core . clj \n - The isa ? hierarchy value used for dispatch , e . g . \n - ( isa ? my - hierarchy : : square : : shape ) \n + The value used for hierarchical dispatch ( e . g . : : square is - a : : shape ) \n - inheritance . The hierarchy relationship can be established via derive , \n - and the root ancestor may be obtained from make - hierarchy in order to \n - avoid directly using the global hierarchy map . Multimethods expect the \n - value of the hierarchy option to be supplied as a reference type e . g . \n - a var . You can supply this option via the Var - quote dispatch macro ( # ' ) . \n - If no hierarchy is supplied , defaults to the global hierarchy . \n - \n - Hierarchy example : \n - \n - ( def my - hierarchy ( - > ( make - hierarchy ) \n - ( derive : : rect : : shape ) \n - ( derive : : square : : rect ) \n - ( derive : : circle : : shape ) ) ) \n - \n - ( defmulti foo identity : hierarchy # ' my - hierarchy ) "" \n + inheritance . By default Clojure ' s multimethods dispatch off of a \n + global hierarchy map . However , a hierarchy relationship can be \n + created with the derive function used to augment the root ancestor \n + created with make - hierarchy . \n + \n + Multimethods expect the value of the hierarchy option to be supplied as \n + a reference type e . g . a var ( i . e . via the Var - quote dispatch macro # ' \n + or the var special form ) . "" \n",CLJ - 835 : Refined language around defmulti hierarchies and removed examples per RH ' s request \n Signed - off - by : Stuart Halloway < stu @ thinkrelevance . com >,602
"android \ guava - testlib \ test \ com \ google \ common \ testing \ EqualsTesterTest . java \n + @ SuppressWarnings ( "" MissingTestCall "" ) \n guava - testlib \ test \ com \ google \ common \ testing \ EqualsTesterTest . java \n + @ SuppressWarnings ( "" MissingTestCall "" ) \n","Suppress violation of MissingEqualsCall for EqualsTesterTest , given it quite legitimately fails to call # testEquals . \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 210138846",605
"guava \ src \ com \ google \ common \ base \ Objects . java \n - public static int hashCode ( Object @ Nullable . . . objects ) { \n + public static int hashCode ( @ Nullable Object @ Nullable . . . objects ) { \n guava \ src \ com \ google \ common \ base \ Preconditions . java \n - Object @ Nullable . . . errorMessageArgs ) { \n + @ Nullable Object @ Nullable . . . errorMessageArgs ) { \n - T reference , @ Nullable String errorMessageTemplate , Object @ Nullable . . . errorMessageArgs ) { \n + T reference , \n + @ Nullable String errorMessageTemplate , \n + @ Nullable Object @ Nullable . . . errorMessageArgs ) { \n",Add more @ Nullables to variadic parameter lists . \n RELNOTES = Add more @ Nullables to variadic parameter lists . \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 254718073,605
"android \ guava - tests \ test \ com \ google \ common \ collect \ SynchronizedDequeTest . java \n - create ( ) . contains ( "" foo "" ) ; \n - create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n + boolean unused = create ( ) . contains ( "" foo "" ) ; \n + boolean unused2 = create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n android \ guava - tests \ test \ com \ google \ common \ collect \ SynchronizedQueueTest . java \n - create ( ) . contains ( "" foo "" ) ; \n - create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n + boolean unused = create ( ) . contains ( "" foo "" ) ; \n + boolean unused2 = create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n guava - tests \ test \ com \ google \ common \ collect \ SynchronizedDequeTest . java \n - create ( ) . contains ( "" foo "" ) ; \n - create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n + boolean unused = create ( ) . contains ( "" foo "" ) ; \n + boolean unused2 = create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n guava - tests \ test \ com \ google \ common \ collect \ SynchronizedQueueTest . java \n - create ( ) . contains ( "" foo "" ) ; \n - create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n + boolean unused = create ( ) . contains ( "" foo "" ) ; \n + boolean unused2 = create ( ) . containsAll ( ImmutableList . of ( "" foo "" ) ) ; \n",Assign the result of contains ( ) and containsAll ( ) to a variable . \n This satisfies the CheckReturnValue checker . \n [ ] \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 287279350,605
"android \ guava - testlib \ src \ com \ google \ common \ collect \ testing \ MapInterfaceTest . java \n - map . containsKey ( null ) ; \n + boolean unused = map . containsKey ( null ) ; \n - map . containsKey ( null ) ; \n + boolean unused2 = map . containsKey ( null ) ; \n - map . containsValue ( null ) ; \n + boolean unused = map . containsValue ( null ) ; \n - map . containsKey ( null ) ; \n + boolean unused2 = map . containsKey ( null ) ; \n android \ guava - tests \ test \ com \ google \ common \ collect \ SynchronizedMapTest . java \n - create ( ) . containsKey ( null ) ; \n + boolean unused = create ( ) . containsKey ( null ) ; \n - create ( ) . containsValue ( null ) ; \n + boolean unused = create ( ) . containsValue ( null ) ; \n guava - testlib \ src \ com \ google \ common \ collect \ testing \ MapInterfaceTest . java \n - map . containsKey ( null ) ; \n + boolean unused = map . containsKey ( null ) ; \n - map . containsKey ( null ) ; \n + boolean unused2 = map . containsKey ( null ) ; \n - map . containsValue ( null ) ; \n + boolean unused = map . containsValue ( null ) ; \n - map . containsKey ( null ) ; \n + boolean unused2 = map . containsKey ( null ) ; \n guava - tests \ test \ com \ google \ common \ collect \ ImmutableSetTest . java \n - ImmutableList . of ( QueryOp . create ( "" contains "" , Set : : contains , Math : : log ) ) ) ; \n + ImmutableList . of ( \n + QueryOp . create ( \n + "" contains "" , \n + ( s , o ) - > { \n + boolean unused = s . contains ( o ) ; \n + } , \n + Math : : log ) ) ) ; \n guava - tests \ test \ com \ google \ common \ collect \ SynchronizedMapTest . java \n - create ( ) . containsKey ( null ) ; \n + boolean unused = create ( ) . containsKey ( null ) ; \n - create ( ) . containsValue ( null ) ; \n + boolean unused = create ( ) . containsValue ( null ) ; \n",Suppress ignored return values from Collection # contains * . \n I think this is all of them ! \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 288028198,605
android \ guava - tests \ test \ com \ google \ common \ util \ concurrent \ SequentialExecutorTest . java \n - assertThat ( Thread . currentThread ( ) . interrupted ( ) ) . isTrue ( ) ; \n + assertThat ( Thread . interrupted ( ) ) . isTrue ( ) ; \n - assertThat ( Thread . currentThread ( ) . interrupted ( ) ) . isTrue ( ) ; \n + assertThat ( Thread . interrupted ( ) ) . isTrue ( ) ; \n guava - tests \ test \ com \ google \ common \ util \ concurrent \ SequentialExecutorTest . java \n - assertThat ( Thread . currentThread ( ) . interrupted ( ) ) . isTrue ( ) ; \n + assertThat ( Thread . interrupted ( ) ) . isTrue ( ) ; \n - assertThat ( Thread . currentThread ( ) . interrupted ( ) ) . isTrue ( ) ; \n + assertThat ( Thread . interrupted ( ) ) . isTrue ( ) ; \n,"Replace Thread . currentThread ( ) . interrupted ( ) with Thread . interrupted ( ) or Thread . currentThread ( ) . interrupt ( ) , whichever seems appropriate . \n Thread . interrupted : static method on Thread which returns whether the thread has been interrupted ( and resets the interrupt bit ) \n Thread . currentThread ( ) . interrupt ( ) : interrupts the current thread \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 301162686",605
"android \ guava \ src \ com \ google \ common \ cache \ LocalCache . java \n + @ SuppressWarnings ( "" GuardedBy "" ) \n guava \ src \ com \ google \ common \ cache \ LocalCache . java \n + @ SuppressWarnings ( "" GuardedBy "" ) \n","Suppress GuardedBy violation in LocalCache . \n This looks like it ' s just for testing , which I think makes it / probably OK / , but feel free to suggest otherwise . \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 288479243",605
android \ guava \ src \ com \ google \ common \ collect \ ImmutableSet . java \n - @ CanIgnoreReturnValue \n + @ CanIgnoreReturnValue \n guava \ src \ com \ google \ common \ collect \ ImmutableSet . java \n - @ Override \n + @ Override \n,Fix annotation positions in Guava . \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 319981882,605
"android \ guava - tests \ test \ com \ google \ common \ util \ concurrent \ JdkFutureAdaptersTest . java \n + @ SuppressWarnings ( "" IsInstanceIncompatibleType "" ) / / intentional . \n guava - tests \ test \ com \ google \ common \ util \ concurrent \ JdkFutureAdaptersTest . java \n + @ SuppressWarnings ( "" IsInstanceIncompatibleType "" ) / / intentional . \n",Deal with Class # isInstance checks which are guaranteed to be false . \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 332298366,605
"android \ guava \ src \ com \ google \ common \ cache \ LocalCache . java \n - / / Only becomes available in Java 8 when it ' s on the interface . \n - / / @ Override \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod will not exist if we build with - - release 7 . \n android \ guava \ src \ com \ google \ common \ collect \ ContiguousSet . java \n - / / TODO ( kevinb ) : we can probably make these real @ Overrides now \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n guava \ src \ com \ google \ common \ collect \ ContiguousSet . java \n - / / TODO ( kevinb ) : we can probably make these real @ Overrides now \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n - / * @ Override * / \n + @ SuppressWarnings ( "" MissingOverride "" ) / / Supermethod does not exist under GWT . \n",PUBLIC : Add missing Override annotations . \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 344396802,605
"DaoExample \ src \ main \ java \ de \ greenrobot \ daoexample \ Customer . java \n - @ Column ( name = "" _ id "" ) \n DaoExample \ src \ main \ java \ de \ greenrobot \ daoexample \ Note . java \n - @ Column ( name = "" _ id "" ) \n DaoExample \ src \ main \ java \ de \ greenrobot \ daoexample \ Order . java \n - @ Column ( name = "" _ id "" ) \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Property . java \n + } else if ( primaryKey & & propertyType = = PropertyType . Long & & columnName . equals ( "" _ id "" ) ) { \n + nonDefaultColumnName = false ; \n",migration : support _ id as default column name,609
"DaoGenerator \ src - template \ entity . ftl \n - < # assign orderSpec = toMany . orderSpec > \n - < # if orderSpec ? ? > \n + < # assign orderSpec = ( toMany . orderSpec ) ! "" 0 "" > \n + < # if orderSpec ! = "" 0 "" > \n",fix NPE in entity . ftl for toMany . orderSpec,609
DaoGenerator \ src - template \ entity . ftl \n + @ Generated \n,mark Entity ' s default constructor with @ Generated,609
DaoGenerator \ src - template \ entity . ftl \n + < / # if > \n + < # if property . javaDocField ? ? > \n + $ { property . javaDocField } \n + < / # if > \n + < # if property . codeBeforeField ? ? > \n + $ { property . codeBeforeField } \n - < / # if > \n - < # if property . javaDocField ? ? > \n - $ { property . javaDocField } \n - < / # if > \n - < # if property . codeBeforeField ? ? > \n - $ { property . codeBeforeField } \n - < # if property . notNull & & ! primitiveTypes ? seq _ contains ( property . javaTypeInEntity ) > \n - @ NotNull \n - < / # if > \n + < / # if > \n + < # if property . notNull & & ! primitiveTypes ? seq _ contains ( property . javaTypeInEntity ) > \n + @ NotNull \n,entity . ftl : put java doc and custom code above greendao annotations,609
DaoGenerator \ src - template \ entity . ftl \n - \n + \n - \n + \n,entity . ftl : better formatting for toMany and toOne,609
"DaoExample \ src \ main \ java \ de \ greenrobot \ daoexample \ NoteDao . java \n - "" ( \ "" TEXT \ "" , \ "" DATE \ "" ) ; "" ) ; \n + "" ( \ "" TEXT \ "" , \ "" DATE \ "" DESC ) ; "" ) ; \n DaoGenerator \ src - template \ dao . ftl \n - - > \n + < # - - @ ftlvariable name = "" entity "" type = "" de . greenrobot . daogenerator . Entity "" - - > \n + < # - - @ ftlvariable name = "" schema "" type = "" de . greenrobot . daogenerator . Schema "" - - > \n + \n - as property > \ "" $ { property . columnName } \ "" < # if property _ has _ next > , < / # if > < / # list > ) ; "" ) ; \n + as property > \ "" $ { property . columnName } \ "" < # if ( index . propertiesOrder [ property _ index ] ) ? ? > $ { index . propertiesOrder [ property _ index ] } < / # if > < # sep > , < / # list > ) ; "" ) ; \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ PropertyOrderList . java \n - List < String > getPropertiesOrder ( ) { \n + public List < String > getPropertiesOrder ( ) { \n",support asc / desc for indexes on greendao level,609
"DaoGenerator \ src - template \ entity . ftl \n - @ ToOne ( mappedBy = "" $ { toOne . fkProperties [ 0 ] . propertyName } "" , unique = $ { toOne . fkProperties [ 0 ] . unique ? then ( "" true "" , "" false "" ) } ) \n + @ ToOne ( mappedBy = "" $ { toOne . fkProperties [ 0 ] . propertyName } "" < # if toOne . fkProperties [ 0 ] . unique > , unique = true < / # if > ) \n","migration : don ' t generate "" unique = false "" for @ ToOne",609
"DaoCore \ src \ main \ java \ org \ greenrobot \ greendao \ annotations \ Id . java \n + \n + / * * \n + * Whether the primary key should be in descending order \n + * / \n + boolean orderDesc ( ) default false ; \n DaoGenerator \ src - template \ entity . ftl \n - @ Id < # if property . autoincrement > ( autoincrement = true ) < / # if > \n + < # if property . autoincrement & & property . pkDesc > \n + @ Id ( autoincrement = true , orderDesc = true ) \n + < # elseif property . autoincrement > \n + @ Id ( autoincrement = true ) \n + < # elseif property . pkDesc > \n + @ Id ( orderDesc = true ) \n + < # else > \n + @ Id \n + < / # if > \n DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Property . java \n + public boolean isPkAsc ( ) { \n + return pkAsc ; \n + } \n + \n + public boolean isPkDesc ( ) { \n + return pkDesc ; \n + } \n + \n",v3 : support asc / desc on primary key,609
DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Entity . java \n - if ( ! pack . equals ( javaPackage ) ) { \n + if ( pack ! = null & & ! pack . equals ( javaPackage ) ) { \n - if ( ! pack . equals ( javaPackageDao ) ) { \n + if ( pack ! = null & & ! pack . equals ( javaPackageDao ) ) { \n - if ( ! pack . equals ( javaPackageDao ) ) { \n + if ( pack ! = null & & ! pack . equals ( javaPackageDao ) ) { \n,DaoGenerator : fix using converter class name without package name,609
DaoGenerator \ build . gradle \n - version = ' 2 . 2 . 0 ' \n + version = ' 3 . 0 . 0 - 1 - SNAPSHOT ' \n,DaoGenerator : change version to 3 . 0 . 0 - 1 - SNAPSHOT,609
"DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 3 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 4 - SNAPSHOT ' \n DaoCore \ src \ main \ java \ org \ greenrobot \ greendao \ annotation \ Id . java \n - \n - / * * \n - * Whether the primary key should be in descending order \n - * / \n - boolean orderDesc ( ) default false ; \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 3 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 4 - SNAPSHOT ' \n DaoGenerator \ src - template \ entity . ftl \n - < # if property . autoincrement & & property . pkDesc > \n - @ Id ( autoincrement = true , orderDesc = true ) \n - < # elseif property . autoincrement > \n - @ Id ( autoincrement = true ) \n - < # elseif property . pkDesc > \n - @ Id ( orderDesc = true ) \n - < # else > \n - @ Id \n - < / # if > \n + @ Id < # if property . autoincrement > ( autoincrement = true ) < / # if > \n",Partly revert : v3 : support asc / desc on primary key,609
DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 4 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 6 - SNAPSHOT ' \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 4 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 6 - SNAPSHOT ' \n,version 3 . 0 . 0 - 6 - SNAPSHOT,609
DaoGenerator \ src - template \ dao - session . ftl \n - * @ see de . greenrobot . dao . AbstractDaoSession \n + * @ see org . greenrobot . greendao . AbstractDaoSession \n DaoGenerator \ src - template \ entity . ftl \n - - > \n - * Convenient call for { @ link de . greenrobot . dao . AbstractDao # delete ( Object ) } . \n + * Convenient call for { @ link org . greenrobot . greendao . AbstractDao # delete ( Object ) } . \n - * Convenient call for { @ link de . greenrobot . dao . AbstractDao # update ( Object ) } . \n + * Convenient call for { @ link org . greenrobot . greendao . AbstractDao # update ( Object ) } . \n - * Convenient call for { @ link de . greenrobot . dao . AbstractDao # refresh ( Object ) } . \n + * Convenient call for { @ link org . greenrobot . greendao . AbstractDao # refresh ( Object ) } . \n,de - > org fixes for some ftl,609
DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 6 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 7 - SNAPSHOT ' \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 6 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 7 - SNAPSHOT ' \n,version 3 . 0 . 0 - 7 - SNAPSHOT,609
DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 7 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 8 - SNAPSHOT ' \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 7 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 8 - SNAPSHOT ' \n,version 3 . 0 . 0 - 8 - SNAPSHOT,609
DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 9 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 10 - SNAPSHOT ' \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 9 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 10 - SNAPSHOT ' \n,3 . 0 . 0 - 10 - SNAPSHOT,609
"DaoGenerator \ src \ de \ greenrobot \ daogenerator \ Entity . java \n - if ( ! targetEntity . getJavaPackage ( ) . equals ( javaPackageDao ) ) { \n - additionalImportsDao . add ( targetEntity . getJavaPackage ( ) + "" . "" + targetEntity . getClassName ( ) ) ; \n - } \n + checkAdditionalImportsDaoTargetEntity ( targetEntity ) ; \n + for ( ToManyBase incomingToMany : incomingToManyRelations ) { \n + if ( incomingToMany instanceof ToManyWithJoinEntity ) { \n + final ToManyWithJoinEntity toManyWithJoinEntity = ( ToManyWithJoinEntity ) incomingToMany ; \n + final Entity joinEntity = toManyWithJoinEntity . getJoinEntity ( ) ; \n + checkAdditionalImportsDaoTargetEntity ( joinEntity ) ; \n + } \n + } \n + \n + private void checkAdditionalImportsDaoTargetEntity ( Entity targetEntity ) { \n + if ( ! targetEntity . getJavaPackage ( ) . equals ( javaPackageDao ) ) { \n + additionalImportsDao . add ( targetEntity . getJavaPackage ( ) + "" . "" + targetEntity . getClassName ( ) ) ; \n + } \n + } \n + \n",fix join entity is not imported into dao,609
DaoCore \ build . gradle \n - version = ' 3 . 0 . 0 - 10 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 11 - SNAPSHOT ' \n DaoGenerator \ build . gradle \n - version = ' 3 . 0 . 0 - 10 - SNAPSHOT ' \n + version = ' 3 . 0 . 0 - 11 - SNAPSHOT ' \n,3 . 0 . 0 - 11 - SNAPSHOT,609
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Notification . scala \n - private [ scala ] def asJava : rx . Notification [ _ < : T ] \n + private [ scala ] val asJava : rx . Notification [ _ < : T ] \n - def unapply [ U ] ( n : Notification [ U ] ) : Option [ U ] = n match { \n - case n2 : OnNext [ U ] = > Some ( n . getValue ) \n + def unapply [ U ] ( notification : Notification [ U ] ) : Option [ U ] = notification match { \n + case onNext : OnNext [ U ] = > Some ( onNext . value ) \n - def unapply [ U ] ( n : Notification [ U ] ) : Option [ Throwable ] = n match { \n - case n2 : OnError [ U ] = > Some ( n2 . error ) \n + def unapply [ U ] ( notification : Notification [ U ] ) : Option [ Throwable ] = notification match { \n + case onError : OnError [ U ] = > Some ( onError . error ) \n - def unapply [ U ] ( n : Notification [ U ] ) : Option [ Unit ] = n match { \n - case n2 : OnCompleted [ U ] = > Some ( ) \n + def unapply [ U ] ( notification : Notification [ U ] ) : Option [ Unit ] = notification match { \n + case onCompleted : OnCompleted [ U ] = > Some ( ) \n language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observer . scala \n - def apply [ T ] ( onError : Throwable = > Unit ) : Observer [ T ] = apply ( v = > { } , onError , ( ) = > { } ) \n - def apply [ T ] ( onCompleted : ( ) = > Unit ) : Observer [ T ] = apply ( v = > { } , e = > { } , onCompleted ) \n - def apply [ T ] ( onError : Throwable = > Unit , onCompleted : ( ) = > Unit ) : Observer [ T ] = apply ( v = > { } , onError , onCompleted ) \n",Cosmetic changes to Notification . \n Cleaned up overloads for Observer .,611
language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n - val oScala1 : Observable [ java . util . List [ T ] ] = new Observable [ java . util . List [ T ] ] { def asJavaObservable = jObs } \n + val oScala1 : Observable [ java . util . List [ T ] ] = new Observable [ java . util . List [ T ] ] { val asJavaObservable = jObs } \n - val oScala1 : Observable [ rx . Observable [ _ < : T ] ] = new Observable [ rx . Observable [ _ < : T ] ] { def asJavaObservable = jObs } \n - oScala1 . map ( ( oJava : rx . Observable [ _ < : T ] ) = > new Observable [ T ] { def asJavaObservable = oJava } ) \n + val oScala1 : Observable [ rx . Observable [ _ < : T ] ] = new Observable [ rx . Observable [ _ < : T ] ] { val asJavaObservable = jObs } \n + oScala1 . map ( ( oJava : rx . Observable [ _ < : T ] ) = > new Observable [ T ] { val asJavaObservable = oJava } ) \n - new Observable [ T ] { \n - def asJavaObservable = observable \n + new Observable [ T ] { \n + val asJavaObservable = observable \n,private [ scala ] val asJavaXXX for all .,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observer . scala \n - def apply [ T ] ( ) : Observer [ T ] = apply ( v = > { } , e = > { } , ( ) = > { } ) \n - def apply [ T ] ( onNext : T = > Unit ) : Observer [ T ] = apply ( onNext , e = > { } , ( ) = > { } ) \n - def apply [ T ] ( onNext : T = > Unit , onError : Throwable = > Unit ) : Observer [ T ] = apply ( onNext , onError , ( ) = > { } ) \n - def apply [ T ] ( onNext : T = > Unit , onCompleted : ( ) = > Unit ) : Observer [ T ] = apply ( onNext , e = > { } , onCompleted ) \n + def apply [ T ] ( ) : Observer [ T ] = apply [ T ] ( ( v : T ) = > ( ) , ( e : Throwable ) = > ( ) , ( ) = > ( ) ) \n + def apply [ T ] ( onNext : T = > Unit ) : Observer [ T ] = apply [ T ] ( onNext , ( e : Throwable ) = > ( ) , ( ) = > ( ) ) \n + def apply [ T ] ( onNext : T = > Unit , onError : Throwable = > Unit ) : Observer [ T ] = apply [ T ] ( onNext , onError , ( ) = > ( ) ) \n + def apply [ T ] ( onNext : T = > Unit , onCompleted : ( ) = > Unit ) : Observer [ T ] = apply [ T ] ( onNext , ( e : Throwable ) = > ( ) , onCompleted ) \n language - adaptors \ rxjava - scala \ src \ test \ scala \ rx \ lang \ scala \ SubjectTests . scala \n + val zzz = Observer [ Integer ] ( ) \n + \n","Tried to improve type inference , alas .",611
"language - adaptors \ rxjava - scala \ ReleaseNotes . md \n - private [ scala ] def asJavaObservable : rx . Observable [ _ < : T ] \n + private [ scala ] val asJavaObservable : rx . Observable [ _ < : T ] \n - private [ scala ] def asJavaScheduler : rx . Scheduler ; \n + private [ scala ] val asJavaScheduler : rx . Scheduler ; \n - private [ scala ] def asJavaNotification : rx . Notification [ _ < : T ] \n + private [ scala ] val asJavaNotification : rx . Notification [ _ < : T ] \n - To construct a ` Notification ` , you import ` rx . lang . scala . Notification . _ ` and use ` OnNext ( "" hello "" ) ` , or ` OnError ( new Exception ( "" Oops ! "" ) ) ` , or ` OnCompleted ( ) ` . \n + To construct a ` Notification ` , you import ` rx . lang . scala . Notification . _ ` and use ` OnNext ( "" hello "" ) ` , \n + or ` OnError ( new Exception ( "" Oops ! "" ) ) ` , or ` OnCompleted ( ) ` . \n + \n",Changed def to val in release notes to match source code . Which I could put in hyperlink ; - ),611
"language - adaptors \ rxjava - scala \ ReleaseNotes . md \n - To create an instance of say ` Observer [ String ] ` in user code , you can create a new instance of the ` Observer ` trait \n + To create an instance of say ` Observer [ SensorEvent ] ` in user code , you can create a new instance of the ` Observer ` trait \n - val printObserver = new Observer [ String ] { \n - override def onNext ( value : String ) : Unit = { . . . } \n + val printObserver = new Observer [ SensorEvent ] { \n + override def onNext ( value : SensorEvent ) : Unit = { . . . value . toString . . . } \n - - - - - - - \n - The ` Subject ` trait now also hides the underlying Java ` asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : R ] ` . \n + The ` Subject ` trait now also hides the underlying Java ` asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : T ] ` \n + and takes only a single * invariant * type parameter ` T ` . all existing implementations of ` Subject ` are parametrized \n + by a single type , and this reflects that reality . \n - trait Subject [ - T , + R ] extends Observable [ R ] with Observer [ T ] { \n - private [ scala ] val asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : R ] \n + trait Subject [ T ] extends Observable [ T ] with Observer [ T ] { \n + private [ scala ] val asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : T ] \n - \n - * I will remove PublishSubject making it * Subject * There is no companion object for ` Subject ` but instead * \n - making ` asJavaSubject ` private . \n + making ` asJavaSubject ` private , and collapsing its type parameters . Neither of these should cause trouble . \n - - - - - - - - - - \n",Updated release notes for Subject [ T ],611
language - adaptors \ rxjava - scala \ ReleaseNotes . md \n - The major changes in ` Observable ` are wrt to the factory methods * Can ' t write this when I don ' t have Samuel ' s changes * . \n + The major changes in ` Observable ` are wrt to the factory methods * TODO : add constructor changes * . \n - - - - - - - \n,"README \n * Needed to comment out interop test because , build cannot find my javac . \n * Note scheduler test don ' t terminate with JDK 7 on my machine .",611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Notification . scala \n - def accept [ R ] ( onNext : T = > R , onError : Throwable = > R , onCompleted : ( ) = > R ) : R = { \n + def apply [ R ] ( onNext : T = > R , onError : Throwable = > R , onCompleted : ( ) = > R ) : R = { \n language - adaptors \ rxjava - scala \ src \ test \ scala \ rx \ lang \ scala \ NotificationTests . scala \n - Assert . assertEquals ( 42 , onNext . accept ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n + Assert . assertEquals ( 42 , onNext ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n - Assert . assertEquals ( 4711 , onError . accept ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n + Assert . assertEquals ( 4711 , onError ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n - Assert . assertEquals ( 13 , onCompleted . accept ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n + Assert . assertEquals ( 13 , onCompleted ( x = > 42 , e = > 4711 , ( ) = > 13 ) ) \n",renamed ` accept ` to ` apply ` for Notification .,611
language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n + / * * \n + * $ subscribeObserverMain \n + * \n + * @ param observer $ subscribeObserverParamObserver \n + * @ return $ subscribeAllReturn \n + * / \n + def apply ( observer : Observer [ T ] ) : Subscription = subscribe ( observer ) \n + \n - * ` ` \n + * \n,added apply ( Observer ) to Observable [ T ] trait,611
language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ subjects \ PublishSubject . scala \n + import rx . subjects \n - private [ scala ] class PublishSubject [ T ] private [ scala ] ( val asJavaSubject : rx . subjects . PublishSubject [ T ] ) \n - extends Subject [ T ] { } \n + private [ scala ] object PublishSubject { \n + private [ scala ] def apply [ T ] ( ) : PublishSubject [ T ] = return new PublishSubject [ T ] ( new subjects . PublishSubject [ T ] ( ) ) \n + } \n + \n + private [ scala ] class PublishSubject [ T ] private [ scala ] ( val asJavaSubject : rx . subjects . PublishSubject [ T ] ) extends Subject [ T ] { } \n,Added back private PublishSubject [ T ] object .,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Scheduler . scala \n - private def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription ) : Subscription = { \n + private [ scala ] def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription ) : Subscription = { \n - private def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , delayTime : Duration ) : Subscription = { \n + private [ scala ] def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , delayTime : Duration ) : Subscription = { \n - private def schedulePeriodically [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , initialDelay : Duration , period : Duration ) : Subscription = { \n + private [ scala ] def schedulePeriodically [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , initialDelay : Duration , period : Duration ) : Subscription = { \n - private def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , dueTime : Date ) : Subscription = { \n + private [ scala ] def schedule [ T ] ( state : T , action : ( Scheduler , T ) = > Subscription , dueTime : Date ) : Subscription = { \n",Made rx . Scheduler bindings private [ scala ] such that you can access them them if needed .,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ package . scala \n - import java . util . concurrent . TimeUnit \n - import java . util . Date \n - import rx . lang . scala . concurrency . Scheduler \n - \n - / * * \n - * This package contains all classes that RxScala users need . \n - * \n - * It mirrors the structure of package ` rx ` , but implementation classes that RxScala users \n - * will not need are left out . \n - * / \n - \n - / * * \n - * Allows to construct observables in a similar way as futures . \n - * \n - * Example : \n - * \n - * { { { \n - * implicit val scheduler = Schedulers . threadPoolForIO \n - * val o : Observable [ List [ Friend ] ] = observable { \n - * session . getFriends \n - * } \n - * o . subscribe ( \n - * friendList = > println ( friendList ) , \n - * err = > println ( err . getMessage ) \n - * ) \n - * } } } \n - * / \n - def observable [ T ] ( body : = > T ) ( implicit scheduler : Scheduler ) : Observable [ T ] = { \n - Observable ( 1 ) . observeOn ( scheduler ) . map ( _ = > body ) \n - } \n","Removed dead function , left package object for scala docs .",611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n - * the [ [ Scheduler ] ] on which Observers subscribe to the Observable \n + * the [ [ rx . lang . scala . Scheduler ] ] on which Observers subscribe to the Observable \n - Observable [ ( T , U ) ] ( rx . Observable . zip [ T , U , ( T , U ) ] ( this . asJavaObservable , that . asJavaObservable , ( t : T , u : U ) = > ( t , u ) ) ) \n + zip ( that , ( t : T , u : U ) = > ( t , u ) ) \n + } \n + \n + / * * \n + * Returns an Observable formed from this Observable and another Observable by combining \n + * corresponding elements using the selector function . \n + * The number of ` onNext ` invocations of the resulting ` Observable [ ( T , U ) ] ` \n + * is the minumum of the number of ` onNext ` invocations of ` this ` and ` that ` . \n + * / \n + def zip [ U , R ] ( that : Observable [ U ] , selector : ( T , U ) = > R ) : Observable [ R ] = { \n + Observable [ R ] ( rx . Observable . zip [ T , U , R ] ( this . asJavaObservable , that . asJavaObservable , selector ) ) \n language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Subject . scala \n - val asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : R ] \n + val asJavaSubject : rx . subjects . Subject [ _ > : T , _ < : R ] \n - def asJavaObserver : rx . Observer [ _ > : T ] = asJavaSubject \n + def asJavaObserver : rx . Observer [ _ > : T ] = asJavaSubject \n language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Subscription . scala \n - def apply ( subscription : rx . Subscription ) : Subscription = { \n + private [ scala ] def apply ( subscription : rx . Subscription ) : Subscription = { \n - case x : rx . Subscription = > Subscription { x . unsubscribe ( ) } \n + case x : rx . Subscription = > Subscription { x . unsubscribe ( ) } / / add isUnsubscribed \n + \n",Made Subscription . app ( rx . Subscription ) private . \n Added overload for zip,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Scheduler . scala \n - def schedule ( delayTime : Duration ) ( action : Scheduler = > Subscription ) : Subscription = { \n + def schedule ( delayTime : Duration , action : Scheduler = > Subscription ) : Subscription = { \n - def schedule ( initialDelay : Duration , period : Duration ) ( action : Scheduler = > Subscription ) : Subscription = { \n + def schedule ( initialDelay : Duration , period : Duration , action : Scheduler = > Subscription ) : Subscription = { \n - def schedule ( dueTime : Date ) ( action : Scheduler = > Subscription ) : Subscription = { \n + def schedule ( dueTime : Date , action : Scheduler = > Subscription ) : Subscription = { \n - def schedule ( delayTime : Duration ) ( action : = > Unit ) : Subscription = { \n + def schedule ( delayTime : Duration , action : = > Unit ) : Subscription = { \n - def schedule ( initialDelay : Duration , period : Duration ) ( action : = > Unit ) : Subscription = { \n + def schedule ( initialDelay : Duration , period : Duration , action : = > Unit ) : Subscription = { \n",Fixed ambigous definitions ; kuddos to https : / / class . coursera . org / reactive - 001 / forum / thread ? thread _ id = 1466 .,611
language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n + def create [ T ] ( func : Observer [ T ] = > Subscription ) : Observable [ T ] = { \n + Observable [ T ] ( rx . Observable . create ( new OnSubscribeFunc [ T ] { \n + def onSubscribe ( t1 : rx . Observer [ _ > : T ] ) : rx . Subscription = { \n + func ( Observer ( t1 ) ) \n + } \n + } ) ) \n + } \n + \n,"Added Observable . create . \n ( a ) it will stop the pointless discussions around it . \n ( b ) it is removes the interference with from ( T * ) \n ( c ) we should remove the latter , since that is not the common case .",611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ subscriptions \ SerialSubscription . scala \n - class SerialSubscription private [ scala ] ( serial : rx . subscriptions . SerialSubscription ) extends Subscription { \n + class SerialSubscription private [ scala ] ( override val asJavaSubscription : rx . subscriptions . SerialSubscription ) extends Subscription { \n - / * \n - * As long as rx . subscriptions . SerialSubscription has no isUnsubscribed , \n - * we need to intercept and do it ourselves . \n - * / \n - override val asJavaSubscription : rx . subscriptions . SerialSubscription = new rx . subscriptions . SerialSubscription ( ) { \n - override def unsubscribe ( ) : Unit = { \n - if ( unsubscribed . compareAndSet ( false , true ) ) { serial . unsubscribe ( ) } \n - } \n - override def setSubscription ( subscription : rx . Subscription ) : Unit = serial . setSubscription ( subscription ) \n - override def getSubscription ( ) : rx . Subscription = serial . getSubscription ( ) \n - } \n + override def unsubscribe ( ) : Unit = asJavaSubscription . unsubscribe ( ) \n + override def isUnsubscribed : Boolean = asJavaSubscription . isUnsubscribed \n - def subscription _ = ( value : Subscription ) : this . type = { asJavaSubscription . setSubscription ( value . asJavaSubscription ) ; this } \n + def subscription _ = ( value : Subscription ) : this . type = { \n + asJavaSubscription . setSubscription ( value . asJavaSubscription ) \n + this \n + } \n",Removed local SerialSubscription isUnsubscribed implementation since underlying subscription now implements it .,611
"rxjava - core \ src \ main \ java \ rx \ Observable . java \n - * Note : the items will be immediately emitted each time an { @ link Observer } \n - * subscribes . Since this occurs before the { @ link Subscription } is \n - * returned , it is not possible to unsubscribe from the sequence before it \n - * completes . \n - * \n - * Note : the entire range is immediately emitted each time an \n - * { @ link Observer } subscribes . Since this occurs before the \n - * { @ link Subscription } is returned , it is not possible to unsubscribe from \n - * the sequence before it completes . \n - * \n rxjava - core \ src \ test \ java \ rx \ ObservableWindowTests . java \n - / * \n - Observable . from ( 1 , 2 , 3 , 4 , 5 , 6 ) \n - . window ( 3 ) . map ( new Func1 < Observable < Integer > , List < Integer > > ( ) { \n - \n - @ Override \n - public List < Integer > call ( Observable < Integer > o ) { \n - return o . toList ( ) . toBlockingObservable ( ) . single ( ) ; \n - } \n - \n - } ) . toBlockingObservable ( ) . forEach ( new Action1 < List < Integer > > ( ) { \n - \n - @ Override \n - public void call ( List < Integer > t ) { \n - lists . add ( t ) ; \n - } \n - } ) ; \n - * / \n",Observable . from with scheduler \n Fixed blocking test in ObservableWindowTest,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n - val fScala : ( T , Integer ) = > ( T , Int ) = ( elem : T , index : Integer ) = > ( elem , index ) \n - val fJava : Func2 [ _ > : T , Integer , _ < : ( T , Int ) ] = fScala \n - toScalaObservable [ ( T , Int ) ] ( asJavaObservable . mapWithIndex [ ( T , Int ) ] ( fJava ) ) \n + var n = 0 ; \n + this . map ( x = > { val result = ( x , n ) ; n + = 1 ; result } ) \n settings . gradle \n - / / ' language - adaptors : rxjava - scala ' , \ \n + ' language - adaptors : rxjava - scala ' , \ \n",Fixed ZipWithIndex using mutable state ( not pretty ),611
language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ schedulers \ ComputationScheduler . scala \n - def apply ( ) : IOScheduler = { \n - new IOScheduler ( rx . schedulers . Schedulers . computation ( ) ) \n + def apply ( ) : ComputationScheduler = { \n + new ComputationScheduler ( rx . schedulers . Schedulers . computation ( ) ) \n - / * * \n - * Created by netflix on 2 / 5 / 14 . \n - * / \n,Fixed cut & paster error in io scheduler,611
"language - adaptors \ rxjava - scala \ src \ main \ scala \ rx \ lang \ scala \ Observable . scala \n - def publish [ U > : T , R ] ( selector : Observable [ U ] = > Observable [ R ] ) : Observable [ R ] = { \n - val thisJava = this . asJavaObservable . asInstanceOf [ rx . Observable [ U ] ] \n - val fJava : Func1 [ rx . Observable [ U ] , rx . Observable [ R ] ] = \n - ( jo : rx . Observable [ U ] ) = > selector ( toScalaObservable [ U ] ( jo ) ) . asJavaObservable . asInstanceOf [ rx . Observable [ R ] ] \n + def publish [ R ] ( selector : Observable [ T ] = > Observable [ R ] ) : Observable [ R ] = { \n + val thisJava = this . asJavaObservable . asInstanceOf [ rx . Observable [ T ] ] \n + val fJava : Func1 [ rx . Observable [ T ] , rx . Observable [ R ] ] = \n + ( jo : rx . Observable [ T ] ) = > selector ( toScalaObservable [ T ] ( jo ) ) . asJavaObservable . asInstanceOf [ rx . Observable [ R ] ] \n","Publish signature \n Less variance , more type inference",611
"junit \ tests \ TextRunnerTest . java \n + assertEquals ( success , p . exitValue ( ) = = 0 ) ; \n",Enhanced TextRunnerTest to catch missing return values .,633
junit \ runner \ BaseTestRunner . java \n - { \n + static { \n junit \ runner \ excluded . properties \n - excluded . 5 = java . * \n + excluded . 5 = java . * \n + excluded . 6 = com . w3c . * \n + excluded . 7 = org . xml . * \n,Changed to static initialization for fPreferences in BaseTestRunner and excluded common problem causing packages .,633
"new file \n junit \ tests \ framework \ DoublePrecisionAssertTest . java \n + package junit . tests . framework ; \n + \n + import junit . framework . AssertionFailedError ; \n + import junit . framework . TestCase ; \n + \n + public class DoublePrecisionAssertTest extends TestCase { \n + \n + / * * \n + * Test for the special Double . NaN value . \n + * / \n + public void testAssertEqualsNaNFails ( ) { \n + try { \n + assertEquals ( 1 . 234 , Double . NaN , 0 . 0 ) ; \n + fail ( ) ; \n + } catch ( AssertionFailedError e ) { \n + } \n + } \n + \n + public void testAssertNaNEqualsFails ( ) { \n + try { \n + assertEquals ( Double . NaN , 1 . 234 , 0 . 0 ) ; \n + fail ( ) ; \n + } catch ( AssertionFailedError e ) { \n + } \n + } \n + \n + public void testAssertNaNEqualsNaNFails ( ) { \n + try { \n + assertEquals ( Double . NaN , Double . NaN , 0 . 0 ) ; \n + fail ( ) ; \n + } catch ( AssertionFailedError e ) { \n + } \n + } \n + \n + public void testAssertPosInfinityNotEqualsNegInfinity ( ) { \n + try { \n + assertEquals ( Double . POSITIVE _ INFINITY , Double . NEGATIVE _ INFINITY , 0 . 0 ) ; \n + fail ( ) ; \n + } catch ( AssertionFailedError e ) { \n + } \n + } \n + \n + public void testAssertPosInfinityNotEquals ( ) { \n + try { \n + assertEquals ( Double . POSITIVE _ INFINITY , 1 . 23 , 0 . 0 ) ; \n + fail ( ) ; \n + } catch ( AssertionFailedError e ) { \n + } \n + } \n + \n + public void testAssertPosInfinityEqualsInfinity ( ) { \n + assertEquals ( Double . POSITIVE _ INFINITY , Double . POSITIVE _ INFINITY , 0 . 0 ) ; \n + } \n + \n + public void testAssertNegInfinityEqualsInfinity ( ) { \n + assertEquals ( Double . NEGATIVE _ INFINITY , Double . NEGATIVE _ INFINITY , 0 . 0 ) ; \n + } \n + \n + } \n",Oops . Assertion tests can ' t use the standard format for exception tests because the exception to be thrown is AssertionFailedError and the exception that signals failure is also AssertionFailedError .,633
"deleted file \n . vcm _ meta \n - < ? xml version = "" 1 . 0 "" encoding = "" UTF - 8 "" ? > \n - < project - description > \n - < comment > < / comment > \n - < nature id = "" org . eclipse . jdt . core . javanature "" / > \n - < builder name = "" org . eclipse . jdt . core . javabuilder "" > \n - < / builder > \n - < / project - description > \n",Deleted unnecessary . vcm _ meta file .,633
junit \ tests \ runner \ TextFeedbackTest . java \n - ResultPrinter printer = new ResultPrinter ( new PrintStream ( output ) ) { \n + ResultPrinter printer = new TestResultPrinter ( new PrintStream ( output ) ) { \n,Fixed timing problem in TextFeedbackTest . testError ( ),633
"junit \ framework \ Assert . java \n - throw new ComparisonFailure ( message , expected = = null ? "" null "" : expected . toString ( ) , actual = = null ? "" null "" : actual . toString ( ) ) ; \n + throw new ComparisonFailure ( message , expected . toString ( ) , actual . toString ( ) ) ; \n","The problem is better solved by only using ComparisonFailure \n when comparing Strings . Once we have more experience of \n actual usage of ComparisonFailure , we can consider expanding \n it to comparisons of objects .",633
"junit \ awtui \ TestRunner . java \n - / * * \n - * runs a suite . \n - * @ deprecated use runSuite ( ) instead \n - * / \n - public void run ( ) { \n - runSuite ( ) ; \n - } \n junit \ framework \ Assert . java \n - / * * \n - * Asserts that a condition is true . If it isn ' t it throws \n - * an AssertionFailedError with the given message . \n - * @ deprecated use assertTrue \n - * / \n - static public void assert ( String message , boolean condition ) { \n - if ( ! condition ) \n - fail ( message ) ; \n - } \n - / * * \n - * Asserts that a condition is true . If it isn ' t it throws \n - * an AssertionFailedError . \n - * @ deprecated use assertTrue \n - * \n - * / \n - static public void assert ( boolean condition ) { \n - assert ( null , condition ) ; \n - } \n junit \ framework \ TestResult . java \n - / * * \n - * Gets the number of run tests . \n - * @ deprecated use < code > runCount < / code > instead \n - * / \n - public synchronized int runTests ( ) { \n - return runCount ( ) ; \n - } \n - / * * \n - * Gets the number of detected errors . \n - * @ deprecated use < code > errorCount < / code > instead \n - * / \n - public synchronized int testErrors ( ) { \n - return errorCount ( ) ; \n - } \n - / * * \n - * Gets the number of detected failures . \n - * @ deprecated use < code > failureCount < / code > instead \n - * / \n - public synchronized int testFailures ( ) { \n - return failureCount ( ) ; \n - } \n - return testFailures ( ) = = 0 & & testErrors ( ) = = 0 ; \n + return failureCount ( ) = = 0 & & errorCount ( ) = = 0 ; \n junit \ swingui \ TestRunner . java \n - / * * \n - * runs a suite . \n - * @ deprecated use runSuite ( ) instead \n - * / \n - public void run ( ) { \n - runSuite ( ) ; \n - } \n - \n junit \ textui \ TestRunner . java \n - / * * \n - * @ deprecated Use getWriter ( ) \n - * / \n - protected PrintStream writer ( ) { \n - return getWriter ( ) ; \n - } \n","Deleted deprecated methods and classes , this time really",633
"junit \ framework \ Assert . java \n + fail ( format ( message , expected , actual ) ) ; \n + } \n + \n + static String format ( String message , Object expected , Object actual ) { \n - fail ( formatted + "" expected : < "" + expected + "" > but was : < "" + actual + "" > "" ) ; \n + return formatted + "" expected : < "" + expected + "" > but was : < "" + actual + "" > "" ; \n junit \ framework \ ComparisonFailure . java \n - return format ( fActual , fExpected ) ; \n + return Assert . format ( super . getMessage ( ) , fExpected , fActual ) ; \n - return format ( actual , expected ) ; \n - } \n - \n - private String format ( String actual , String expected ) { \n - String message = super . getMessage ( ) ; \n - String formatted = "" "" ; \n - if ( message ! = null ) \n - formatted = message + "" : "" ; \n - return formatted + "" expected : < "" + expected + "" > but was : < "" + actual + "" > "" ; \n + return Assert . format ( super . getMessage ( ) , expected , actual ) ; \n",Factored out commonality between ComparisonFailure and Assert . There still looks to be more to do in Assert itself .,633
"junit \ tests \ runner \ AllTests . java \n + suite . addTestSuite ( TextFeedbackTest . class ) ; \n new file \n junit \ tests \ runner \ TextFeedbackTest . java \n + \n + package junit . tests . runner ; \n + \n + import java . io . ByteArrayOutputStream ; \n + import java . io . OutputStream ; \n + import java . io . PrintStream ; \n + import java . text . Collator ; \n + import java . text . RuleBasedCollator ; \n + \n + import junit . framework . TestCase ; \n + import junit . framework . TestSuite ; \n + import junit . textui . TestRunner ; \n + \n + public class TextFeedbackTest extends TestCase { \n + public static void main ( String [ ] args ) { \n + TestRunner . run ( TextFeedbackTest . class ) ; \n + } \n + \n + public void testNormalOperation ( ) { \n + OutputStream output = new ByteArrayOutputStream ( ) ; \n + PrintStream writer = new PrintStream ( output ) ; \n + String expected = expected ( new String [ ] { "" "" , "" Time : 0 "" , "" "" , "" OK ( 0 tests ) "" , "" "" } ) ; \n + TestRunner runner = new TestRunner ( writer ) ; \n + runner . doRun ( new TestSuite ( ) ) ; \n + Collator c = Collator . getInstance ( ) ; \n + assertEquals ( expected . toString ( ) , output . toString ( ) ) ; \n + } \n + \n + private String expected ( String [ ] lines ) { \n + OutputStream expected = new ByteArrayOutputStream ( ) ; \n + PrintStream expectedWriter = new PrintStream ( expected ) ; \n + expectedWriter . println ( ) ; \n + expectedWriter . println ( "" Time : 0 "" ) ; \n + expectedWriter . println ( ) ; \n + expectedWriter . println ( "" OK ( 0 tests ) "" ) ; \n + expectedWriter . println ( ) ; \n + return expected . toString ( ) ; \n + } \n + \n + } \n junit \ textui \ TestRunner . java \n + public TestResult doRun ( Test test ) { \n + return doRun ( test , false ) ; \n + } \n + \n - static public TestResult run ( Test suite ) { \n - TestRunner aTestRunner = new TestRunner ( ) ; \n - return aTestRunner . doRun ( suite , false ) ; \n + static public TestResult run ( Test test ) { \n + TestRunner runner = new TestRunner ( ) ; \n + return runner . doRun ( test ) ; \n",Began writing tests for the textui . TestRunner in preparation for refactoring,633
"new file \n junit \ textui \ ResultPrinter . java \n + \n + package junit . textui ; \n + \n + import java . io . PrintStream ; \n + \n + public class ResultPrinter { \n + PrintStream fWriter ; \n + int fColumn = 0 ; \n + \n + public ResultPrinter ( PrintStream writer ) { \n + fWriter = writer ; \n + } \n + \n + public void testStarted ( String testName ) { \n + getWriter ( ) . print ( "" . "" ) ; \n + if ( fColumn + + > = 40 ) { \n + getWriter ( ) . println ( ) ; \n + fColumn = 0 ; \n + } \n + } \n + \n + protected PrintStream getWriter ( ) { \n + return fWriter ; \n + } \n + } \n","Why didn ' t this get added automatically , oh Eclipse gods ?",633
"junit \ framework \ TestCase . java \n + Throwable running = null ; \n + } catch ( Throwable e ) { \n + running = e ; \n - tearDown ( ) ; \n + try { \n + tearDown ( ) ; \n + } catch ( Exception e ) { \n + throw ( running ! = null ) ? running : e ; \n + } \n junit \ tests \ framework \ TestCaseTest . java \n + public void testErrorTearingDownDoesntMaskErrorRunning ( ) { \n + final Exception running = new Exception ( ) ; \n + TestCase t = new TestCase ( ) { \n + protected void runTest ( ) throws Throwable { \n + throw running ; \n + } \n + protected void tearDown ( ) throws Exception { \n + throw new Exception ( ) ; \n + } \n + } ; \n + try { \n + t . runBare ( ) ; \n + } catch ( Throwable thrown ) { \n + assertEquals ( thrown , running ) ; \n + } \n + } \n + \n",Make sure an exception thrown during tearDown ( ) doesn ' t mask an \n exception thrown during running the test . I don ' t much like the TestCase . runBare ( ) \n code but I can ' t see how to simplify it . It was so much simpler before . Sniff . . .,633
"junit \ tests \ runner \ TestCaseClassLoaderTest . java \n - assertNotNull ( "" Cannot find test . jar "" , url ) ; \n + if ( url = = null ) \n + return ; / / This test only makes sense when run from Ant , so silently ignore \n","If test . jar doesn ' t exist , ignore the test , don ' t fail . This test only makes sense when run from Ant .",633
"junit \ framework \ Assert . java \n - static private void failSame ( String message ) { \n + static public void failSame ( String message ) { \n - static private void failNotSame ( String message , Object expected , Object actual ) { \n + static public void failNotSame ( String message , Object expected , Object actual ) { \n - static private void failNotEquals ( String message , Object expected , Object actual ) { \n + static public void failNotEquals ( String message , Object expected , Object actual ) { \n",[ 658044 ] failNotEquals ( ) should be protected \n We made all the varieties of fail * ( ) public .,633
"junit \ framework \ Assert . java \n - / / handle infinity specially since subtracting to infinite values gives NaN and the \n - / / the following test fails \n - if ( Double . isInfinite ( expected ) ) { \n - if ( ! ( expected = = actual ) ) \n - failNotEquals ( message , new Double ( expected ) , new Double ( actual ) ) ; \n - } else if ( ! ( Math . abs ( expected - actual ) < = delta ) ) / / Because comparison with NaN always returns false \n + if ( Double . compare ( expected , actual ) = = 0 ) \n + return ; \n + if ( ! ( Math . abs ( expected - actual ) < = delta ) ) \n junit \ tests \ framework \ DoublePrecisionAssertTest . java \n - public void testAssertNaNEqualsNaNFails ( ) { \n - try { \n - assertEquals ( Double . NaN , Double . NaN , 0 . 0 ) ; \n - } catch ( AssertionFailedError e ) { \n - return ; \n - } \n - fail ( ) ; \n + public void testAssertNaNEqualsNaN ( ) { \n + assertEquals ( Double . NaN , Double . NaN , 0 . 0 ) ; \n",[ 609819 ] NaN ' s in assertEquals,633
"junit \ runner \ BaseTestRunner . java \n - getPreferences ( ) . store ( fos , "" "" ) ; \n + / / calling of the deprecated save method to enable compiling under 1 . 1 . 7 \n + getPreferences ( ) . save ( fos , "" "" ) ; \n - getPreferences ( ) . setProperty ( key , value ) ; \n + getPreferences ( ) . put ( key , value ) ; \n junit \ swingui \ DefaultFailureDetailView . java \n - fLines . add ( st . nextToken ( ) ) ; \n + fLines . addElement ( st . nextToken ( ) ) ; \n",[ 774304 ] Fix for JUnit 3 . 8 . 1 does not compile with JDK 1 . 1,633
". project \n + < buildCommand > \n + < name > com . agitar . eclipse . project . agitatorbuilder < / name > \n + < arguments > \n + < / arguments > \n + < / buildCommand > \n + < nature > com . agitar . eclipse . project . agitatornature < / nature > \n - < / projectDescription > \n - \n + < / projectDescription > \n junit \ framework \ TestCase . java \n - Throwable running = null ; \n + Throwable exception = null ; \n - } catch ( Throwable e ) { \n - running = e ; \n + } catch ( Throwable running ) { \n + exception = running ; \n - } catch ( Exception e ) { \n - throw ( running ! = null ) ? running : e ; \n + } catch ( Throwable tearingDown ) { \n + if ( exception = = null ) exception = tearingDown ; \n + if ( exception ! = null ) throw exception ; \n - assertNotNull ( fName ) ; \n + assertNotNull ( fName ) ; / / Some VMs crash when calling getMethod ( null , null ) ; \n junit \ tests \ framework \ TestCaseTest . java \n - throw new Error ( ) ; \n + throw new Error ( "" running "" ) ; \n - / / This test documents the current behavior . With 1 . 4 , we should \n + / / With 1 . 4 , we should \n - throw new Error ( "" tearDown "" ) ; \n + throw new Error ( "" tearingDown "" ) ; \n - assertEquals ( "" tearDown "" , failure . thrownException ( ) . getMessage ( ) ) ; \n + assertEquals ( "" running "" , failure . thrownException ( ) . getMessage ( ) ) ; \n - final Exception running = new Exception ( ) ; \n + final Exception running = new Exception ( "" Running "" ) ; \n - throw new Exception ( ) ; \n + throw new Error ( "" Tearing down "" ) ; \n - assertEquals ( thrown , running ) ; \n + assertSame ( running , thrown ) ; \n","My previous fix didn ' t work correctly . \n This version should report exceptions thrown while running tests . \n If an exception is thrown during tearDown ( ) also , the exception \n thrown while running the test will be reported .",633
"org \ junit \ runner \ JUnitCore . java \n - * JUnit 3 . 8 . 2 tests , and mixtures . To run tests from the command line , run < code > java org . junit . runner . JUnitCore TestClass1 TestClass2 . . . < / code > . \n + * JUnit 3 . 8 . x tests , and mixtures . To run tests from the command line , run < code > java org . junit . runner . JUnitCore TestClass1 TestClass2 . . . < / code > . \n",Corrected javadoc to refer to early versions as 3 . 8 . x,633
"org \ junit \ Assert . java \n - throw new AssertionError ( message ) ; \n + throw new AssertionError ( message = = null ? "" "" : message ) ; \n org \ junit \ tests \ AssertionTest . java \n - \n + } \n + \n + @ Test public void multiDimensionalArraysAreNotEqualNoMessage ( ) { \n + try { \n + assertEquals ( new Object [ ] [ ] { { true , true } , { false , false } } , new Object [ ] [ ] { { true , true } , { true , false } } ) ; \n + fail ( ) ; \n + } catch ( AssertionError exception ) { \n + assertEquals ( "" arrays first differed at element [ 1 ] [ 0 ] ; expected : < false > but was : < true > "" , exception . getMessage ( ) ) ; \n + } \n + \n + @ Test public void nullMessage ( ) { \n + try { \n + fail ( null ) ; \n + } catch ( AssertionError exception ) { \n + assertEquals ( "" "" , exception . getMessage ( ) ) ; \n + } \n + } \n",Fixed problem with null message to fail ( ),633
"org \ junit \ Assert . java \n - if ( expected instanceof String & & actual instanceof String ) \n - throw new ComparisonFailure ( message , ( String ) expected , ( String ) actual ) ; \n + if ( expected instanceof String & & actual instanceof String ) { \n + String cleanMessage = message = = null ? "" "" : message ; \n + throw new ComparisonFailure ( cleanMessage , ( String ) expected , ( String ) actual ) ; \n + } \n - if ( message ! = null ) \n + if ( message ! = null & & ! message . equals ( "" "" ) ) \n org \ junit \ runner \ JUnitCore . java \n + import org . junit . runner . notification . Failure ; \n + List < Failure > missingClasses = new ArrayList < Failure > ( ) ; \n + Description description = Description . createSuiteDescription ( each ) ; \n + Failure failure = new Failure ( description , e ) ; \n + missingClasses . add ( failure ) ; \n - return run ( classes . toArray ( new Class [ 0 ] ) ) ; \n + Result result = run ( classes . toArray ( new Class [ 0 ] ) ) ; \n + for ( Failure each : missingClasses ) \n + result . getFailures ( ) . add ( each ) ; \n + return result ; \n org \ junit \ tests \ AssertionTest . java \n - \n - \n + \n - assertEquals ( "" expected same : < hello > was not : < good - bye > "" , exception \n - . getMessage ( ) ) ; \n + assertEquals ( "" expected same : < hello > was not : < good - bye > "" , exception . getMessage ( ) ) ; \n + \n + @ Test public void nullMessageDisappearsWithStringAssertEquals ( ) { \n + try { \n + assertEquals ( null , "" a "" , "" b "" ) ; \n + } catch ( ComparisonFailure e ) { \n + assertEquals ( "" expected : < [ a ] > but was : < [ b ] > "" , e . getMessage ( ) ) ; \n + } \n + } \n + \n + @ Test public void nullMessageDisappearsWithAssertEquals ( ) { \n + try { \n + assertEquals ( null , 1 , 2 ) ; \n + } catch ( AssertionError e ) { \n + assertEquals ( "" expected : < 1 > but was : < 2 > "" , e . getMessage ( ) ) ; \n + } \n + } \n org \ junit \ tests \ JUnitCoreTest . java \n + @ Test public void missingClassCausesExitCodeOf1 ( ) throws Exception { \n + runClass ( "" Foo "" , 1 ) ; \n + } \n + \n","Fixed problems with assertEquals ( null , String , String ) and return code when classes aren ' t found .",633
". classpath \n - < classpathentry kind = "" con "" path = "" org . eclipse . jdt . launching . JRE _ CONTAINER / org . eclipse . jdt . internal . debug . ui . launcher . StandardVMType / jdk1 . 5 . 0 _ 07 "" / > \n + < classpathentry kind = "" con "" path = "" org . eclipse . jdt . launching . JRE _ CONTAINER "" / > \n org \ junit \ Assert . java \n - if ( expected instanceof String & & actual instanceof String ) { \n + if ( expected . getClass ( ) . isArray ( ) & & actual . getClass ( ) . isArray ( ) ) { \n + Object [ ] expectedArray = ( Object [ ] ) expected ; \n + Object [ ] actualArray = ( Object [ ] ) actual ; \n + assertEquals ( message , expectedArray , actualArray ) ; \n + } else if ( expected instanceof String & & actual instanceof String ) { \n org \ junit \ tests \ AssertionTest . java \n + \n + @ Test public void arraysDeclaredAsObjectAreComparedAsArrays ( ) { \n + Object a1 = new Object [ ] { "" abc "" } ; \n + Object a2 = new Object [ ] { "" abc "" } ; \n + assertEquals ( a1 , a2 ) ; \n + } \n",Comparing arrays declared as Object now uses array comparison . There was also a strange change to the . classpath file that I reverted . \n - - Kent,633
"src \ org \ junit \ Assert . java \n - return formatted + "" expected : < "" + expected + "" > but was : < "" + actual + "" > "" ; \n + String expectedString = expected . toString ( ) ; \n + String actualString = actual . toString ( ) ; \n + if ( expectedString . equals ( actualString ) ) \n + return formatted + "" expected : "" + expected . getClass ( ) . getName ( ) + "" < "" + expectedString + "" > but was : "" + actual . getClass ( ) . getName ( ) + "" < "" + actualString + "" > "" ; \n + else \n + return formatted + "" expected : < "" + expectedString + "" > but was : < "" + actualString + "" > "" ; \n src \ org \ junit \ runners \ AllTests . java \n + @ SuppressWarnings ( "" unchecked "" ) \n + public AllTests ( Class < ? > klass ) throws Throwable { \n + super ( suite ( klass ) ) ; \n + } \n + \n - \n - @ SuppressWarnings ( "" unchecked "" ) \n - public AllTests ( Class < ? > klass ) throws Throwable { \n - super ( suite ( klass ) ) ; \n - } \n src \ org \ junit \ tests \ AssertionTest . java \n + \n + @ Test public void errorMessageDistinguishesDifferentValuesWithSameToString ( ) { \n + try { \n + assertEquals ( "" 4 "" , new Integer ( 4 ) ) ; \n + } catch ( AssertionError e ) { \n + assertEquals ( "" expected : java . lang . String < 4 > but was : java . lang . Integer < 4 > "" , e . getMessage ( ) ) ; \n + } \n + } \n",Added class names to error message when two values fail the equality test but produce the same toString ( ) .,633
"src \ org \ junit \ Test . java \n - @ Target ( ElementType . METHOD ) \n + @ Target ( { ElementType . METHOD } ) \n src \ org \ junit \ tests \ AllTests . java \n + import org . junit . tests . running . methods . InheritedTestTest ; \n - CategoryTest . class \n + CategoryTest . class , \n + InheritedTestTest . class \n new file \n src \ org \ junit \ tests \ running \ methods \ InheritedTestTest . java \n + package org . junit . tests . running . methods ; \n + \n + import static org . junit . Assert . assertTrue ; \n + import org . junit . Test ; \n + import org . junit . runner . JUnitCore ; \n + import org . junit . runner . Result ; \n + \n + public class InheritedTestTest { \n + public abstract static class Super { \n + @ Test public void nothing ( ) { } \n + } \n + public static class Sub extends Super { } \n + \n + @ Test public void subclassWithOnlyInheritedTestsRuns ( ) { \n + Result result = JUnitCore . runClasses ( Sub . class ) ; \n + assertTrue ( result . wasSuccessful ( ) ) ; \n + } \n + } \n",Added explicit test for subclasses that only inherit test methods .,633
"src \ org \ junit \ experimental \ theories \ Theories . java \n - return notifying ( method , new Link ( ) { \n - @ Override \n - public void run ( Roadie context ) throws Throwable { \n - possiblyExpectingExceptions ( method , invoke ( method ) ) . run ( context ) ; \n - } \n - } ) ; \n + Link next = invoke ( method ) ; \n + next = ignoreViolatedAssumptions ( next ) ; \n + next = possiblyExpectingExceptions ( method , next ) ; \n + return notifying ( method , next ) ; \n src \ org \ junit \ internal \ runners \ JUnit4ClassRunner . java \n - import org . junit . internal . runners . links . ExpectingNoException ; \n + import org . junit . internal . runners . links . IgnoreViolatedAssumptions ; \n + link = ignoreViolatedAssumptions ( link ) ; \n + \n + protected Link ignoreViolatedAssumptions ( Link next ) { \n + return new IgnoreViolatedAssumptions ( next ) ; \n + } \n - : new ExpectingNoException ( next ) ; \n + : next ; \n - if ( method . isIgnored ( ) ) \n - return new IgnoreTest ( ) ; \n - return new Notifying ( link ) ; \n + return method . isIgnored ( ) \n + ? new IgnoreTest ( ) \n + : new Notifying ( link ) ; \n src \ org \ junit \ internal \ runners \ links \ ExpectingException . java \n - import org . junit . Assume . AssumptionViolatedException ; \n + fExpected . getName ( ) ) ) ; \n - } catch ( AssumptionViolatedException e ) { \n - / / Do nothing \n rename from src \ org \ junit \ internal \ runners \ links \ ExpectingNoException . java \n rename to src \ org \ junit \ internal \ runners \ links \ IgnoreViolatedAssumptions . java \n - public class ExpectingNoException extends Link { \n + public class IgnoreViolatedAssumptions extends Link { \n - public ExpectingNoException ( Link next ) { \n + public IgnoreViolatedAssumptions ( Link next ) { \n",Simplified Theories . Factored out ignoring violated assumptions into its own Link .,633
"acknowledgements . txt \n - Walter Gildersleeve : Found assertEquals ( null , "" null "" ) defect ( 1857283 ) \n + Walter Gildersleeve : Found assertEquals ( null , "" null "" ) defect ( 1857283 ) \n + \n + 2008 July 1 \n + Johannes Link : Submitted test for running subclasses of Suite \n src \ test \ java \ org \ junit \ tests \ AllTests . java \n + import org . junit . tests . running . classes . UseSuiteAsASuperclassTest ; \n - JUnit4ClassRunnerTest . class \n + JUnit4ClassRunnerTest . class , \n + UseSuiteAsASuperclassTest . class \n new file \n src \ test \ java \ org \ junit \ tests \ running \ classes \ UseSuiteAsASuperclassTest . java \n + package org . junit . tests . running . classes ; \n + \n + import static org . junit . Assert . * ; \n + import org . junit . Test ; \n + import org . junit . internal . runners . InitializationError ; \n + import org . junit . runner . JUnitCore ; \n + import org . junit . runner . Result ; \n + import org . junit . runner . RunWith ; \n + import org . junit . runners . Suite ; \n + \n + public class UseSuiteAsASuperclassTest { \n + \n + public static class TestA { \n + @ Test \n + public void pass ( ) { \n + } \n + } \n + \n + public static class TestB { \n + @ Test \n + public void dontPass ( ) { \n + fail ( ) ; \n + } \n + } \n + \n + public static class MySuite extends Suite { \n + public MySuite ( Class < ? > klass ) throws InitializationError { \n + super ( klass , new Class [ ] { TestA . class , TestB . class } ) ; \n + } \n + } \n + \n + @ RunWith ( MySuite . class ) \n + public static class AllWithMySuite { \n + } \n + \n + @ Test \n + public void ensureTestsAreRun ( ) { \n + JUnitCore core = new JUnitCore ( ) ; \n + Result result = core . run ( AllWithMySuite . class ) ; \n + assertEquals ( 2 , result . getRunCount ( ) ) ; \n + assertEquals ( 1 , result . getFailureCount ( ) ) ; \n + } \n + } \n",Added Johannes Link ' s test for running subclasses of Suite,633
"src \ main \ java \ org \ junit \ internal \ runners \ JUnit4ClassRunner . java \n - import org . junit . internal . runners . model . TestMethodElement ; \n + import org . junit . internal . runners . model . TestMethod ; \n - return new RunAfters ( link , new TestMethodElement ( getTestClass ( ) ) , target ) ; \n + return new RunAfters ( link , new TestMethod ( getTestClass ( ) ) , target ) ; \n - return new RunBefores ( link , new TestMethodElement ( getTestClass ( ) ) , target ) ; \n + return new RunBefores ( link , new TestMethod ( getTestClass ( ) ) , target ) ; \n src \ main \ java \ org \ junit \ internal \ runners \ links \ RunAfters . java \n - private final List < Throwable > fErrors = new ArrayList < Throwable > ( ) ; \n - \n + List < Throwable > fErrors = new ArrayList < Throwable > ( ) ; \n src \ main \ java \ org \ junit \ internal \ runners \ model \ TestElement . java \n - public abstract List < FrameworkMethod > getAfters ( ) ; \n - \n - \n - / / TODO I inlined runBefores ( ) for symmetry with runAfters . Either this or both methods should be here . \n + \n + public abstract List < FrameworkMethod > getAfters ( ) ; \n rename from src \ main \ java \ org \ junit \ internal \ runners \ model \ TestMethodElement . java \n rename to src \ main \ java \ org \ junit \ internal \ runners \ model \ TestMethod . java \n - public class TestMethodElement extends TestElement { \n + public class TestMethod extends TestElement { \n - public TestMethodElement ( TestClass testClass ) { \n + public TestMethod ( TestClass testClass ) { \n src \ test \ java \ org \ junit \ tests \ extension \ TestMethodInterfaceTest . java \n - import org . junit . internal . runners . model . TestMethodElement ; \n + import org . junit . internal . runners . model . TestMethod ; \n - TestMethodElement testMethod = new TestMethodElement ( new TestClass ( \n + TestMethod testMethod = new TestMethod ( new TestClass ( \n",Found a final home for runBefores ( ) and runAfters ( ),633
"acknowledgements . txt \n - dakcalouro : Found bug with comparing ints and longs ( 1555161 ) \n - Ben Maurer : Found bug with timeouts taking twice as long as specified ( 1536198 ) \n + dakcalouro : Found defect with comparing ints and longs ( 1555161 ) \n + Ben Maurer : Found defect with timeouts taking twice as long as specified ( 1536198 ) \n - Kazimierz Pogoda : Found bug with null array elements ( 1438163 ) \n + Kazimierz Pogoda : Found defect with null array elements ( 1438163 ) \n - wangqq : Found bug with @ After not running after a timeout ( 1745048 ) \n + wangqq : Found defect with @ After not running after a timeout ( 1745048 ) \n - Andrew Dick : Found bug with assertEquals comparing non - Integer Numbers ( 1715326 ) \n - Michael Schechter : Found bug with Filters and suite ( ) methods ( 1739095 ) \n + Andrew Dick : Found defect with assertEquals comparing non - Integer Numbers ( 1715326 ) \n + Michael Schechter : Found defect with Filters and suite ( ) methods ( 1739095 ) \n + \n + 2008 February 5 \n + Walter Gildersleeve : Found assertEquals ( null , "" null "" ) defect ( 1857283 ) \n src \ main \ java \ org \ junit \ Assert . java \n - return formatted + "" expected : "" + expected . getClass ( ) . getName ( ) + "" < "" + expectedString + "" > but was : "" + actual . getClass ( ) . getName ( ) + "" < "" + actualString + "" > "" ; \n + return formatted + "" expected : "" + formatClassAndValue ( expected , expectedString ) + "" but was : "" + formatClassAndValue ( actual , actualString ) ; \n + \n + private static String formatClassAndValue ( Object value , String valueString ) { \n + String className = value = = null ? "" null "" : value . getClass ( ) . getName ( ) ; \n + return className + "" < "" + valueString + "" > "" ; \n + } \n src \ test \ java \ org \ junit \ tests \ assertion \ AssertionTest . java \n + \n + @ Test public void nullAndStringNullPrintCorrectError ( ) { \n + try { \n + assertEquals ( null , "" null "" ) ; \n + } catch ( AssertionError e ) { \n + assertEquals ( "" expected : null < null > but was : java . lang . String < null > "" , e . getMessage ( ) ) ; \n + } \n + } \n + \n + @ Test ( expected = AssertionError . class ) public void stringNullAndNullWorksToo ( ) { \n + assertEquals ( "" null "" , null ) ; \n + } \n + \n","Fixed 1857283 , assertEquals ( null , "" null )",633
"src \ main \ java \ org \ junit \ runners \ Suite . java \n + import org . junit . internal . builders . AllDefaultPossibilitiesBuilder ; \n + / * \n + * Call this when the default builder is good enough . Left in for compatibility with JUnit 4 . 4 . \n + * @ param klass the root of the suite \n + * @ param suiteClasses the classes in the suite \n + * @ throws InitializationError \n + * / \n + / / TODO this needs a unit test \n + protected Suite ( Class < ? > klass , Class < ? > [ ] suiteClasses ) throws InitializationError { \n + this ( new AllDefaultPossibilitiesBuilder ( true ) , klass , suiteClasses ) ; \n + } \n + \n","Added protected Suite ( Class < ? > klass , Class < ? > [ ] suiteClasses ) to support ClasspathSuite . This still needs a test .",633
"src \ main \ java \ junit \ runner \ Version . java \n - return "" 4 . 5 - SNAPSHOT - 20080715 - 1721 "" ; \n + return "" 4 . 5 - SNAPSHOT - 20080722 - 1051 "" ; \n",* * * empty log message * * *,633
"src \ main \ java \ org \ junit \ AfterClass . java \n - * & # 064 ; BeforeClass public void login ( ) { \n + * & # 064 ; BeforeClass public static void login ( ) { \n - * & # 064 ; AfterClass public void logout ( ) { \n + * & # 064 ; AfterClass public static void logout ( ) { \n src \ test \ java \ org \ junit \ tests \ validation \ ValidationTest . java \n + import org . junit . runner . JUnitCore ; \n + import org . junit . runner . Result ; \n - \n + \n + \n + public static class Malformed { \n + @ BeforeClass public void before ( ) { } \n + @ Test public void hereBecauseEveryTestClassNeedsATest ( ) { } \n + } \n + \n + @ Test \n + public void something ( ) { \n + Result result = JUnitCore . runClasses ( Malformed . class ) ; \n + assertEquals ( "" Method before ( ) should be static "" , result . getFailures ( ) . get ( 0 ) . getMessage ( ) ) ; \n + } \n",Fixed AfterClass javadoc and added a ValidationTest that appears to already be working in spite of complaints to the contrary .,633
src \ main \ java \ org \ junit \ runners \ ParentRunner . java \n + \n + / / TODO : add a flag for whether or not to run children in parallel \n + / / ( as a step towards a delegation - based solution that is more general ) \n,* * * empty log message * * *,633
"src \ main \ java \ junit \ runner \ Version . java \n - return "" 4 . 5 - SNAPSHOT - 20080602 - 1631 "" ; \n + return "" 4 . 5 - SNAPSHOT - 20080603 - 1001 "" ; \n src \ test \ java \ org \ junit \ tests \ running \ classes \ TestClassTest . java \n - @ Test ( timeout = 10 ) public void snappyRetrievalOfAnnotatedMethods ( ) { \n + @ Test ( timeout = 100 ) public void snappyRetrievalOfAnnotatedMethods ( ) { \n + / / TODO it would be better to make this relative \n",* * * empty log message * * *,633
"src \ main \ java \ org \ junit \ internal \ runners \ ParentRunner . java \n - private Sorter fSorter = null ; \n + private Sorter fSorter = Sorter . NULL ; \n - filtered . add ( sortChild ( filterChild ( each ) ) ) ; \n + filterChild ( each ) ; \n + sortChild ( each ) ; \n + filtered . add ( each ) ; \n - if ( fSorter ! = null ) \n - Collections . sort ( filtered , comparator ( ) ) ; \n + Collections . sort ( filtered , comparator ( ) ) ; \n - private T sortChild ( T child ) { \n - if ( fSorter ! = null ) \n - fSorter . apply ( child ) ; \n - return child ; \n + private void sortChild ( T child ) { \n + fSorter . apply ( child ) ; \n - private T filterChild ( T child ) throws NoTestsRemainException { \n + private void filterChild ( T child ) throws NoTestsRemainException { \n - return child ; \n src \ main \ java \ org \ junit \ runner \ manipulation \ Sorter . java \n + public static Sorter NULL = new Sorter ( new Comparator < Description > ( ) { \n + public int compare ( Description o1 , Description o2 ) { \n + return 0 ; \n + } } ) ; \n src \ test \ java \ org \ junit \ tests \ manipulation \ FilterableTest . java \n + System . out . println ( description . getDisplayName ( ) ) ; \n - private int x ; \n - \n - this . x = x ; \n - \n",Cleaned up ParentRunner in search of the elusive filter bug,633
src \ main \ java \ org \ junit \ experimental \ theories \ Theories . java \n - new BlockJUnit4ClassRunner ( getTestClass ( ) ) { \n + new BlockJUnit4ClassRunner ( getTestClass ( ) . getJavaClass ( ) ) { \n src \ main \ java \ org \ junit \ internal \ runners \ ParentRunner . java \n - } \n + } \n src \ main \ java \ org \ junit \ runners \ BlockJUnit4ClassRunner . java \n - this ( new TestClass ( klass ) ) ; \n - } \n - \n - public BlockJUnit4ClassRunner ( TestClass testClass ) throws InitializationError { \n - super ( testClass ) ; \n + super ( new TestClass ( klass ) ) ; \n - \n + \n,Refinement of BlockJUnit4ClassRunner to make it easier to override .,633
"src \ main \ java \ org \ junit \ runner \ JUnitCore . java \n + import org . junit . tests . experimental . max . CouldNotReadCoreException ; \n + import org . junit . tests . experimental . max . MaxCore ; \n - return run ( request . getRunner ( ) ) ; \n - / / MaxCore max = null ; \n - / / try { \n - / / max = MaxCore . forFolder ( "" defaultMaxCore "" ) ; \n - / / } catch ( CouldNotReadCoreException e ) { \n - / / e . printStackTrace ( ) ; \n - / / } \n - / / max . run ( request ) ; \n - / / return null ; \n + / / return run ( request . getRunner ( ) ) ; \n + MaxCore max = null ; \n + try { \n + max = MaxCore . forFolder ( "" defaultMaxCore "" ) ; \n + } catch ( CouldNotReadCoreException e ) { \n + e . printStackTrace ( ) ; \n + } \n + return max . run ( request , this ) ; \n src \ test \ java \ org \ junit \ tests \ experimental \ max \ MaxCore . java \n + import org . junit . internal . requests . SortingRequest ; \n + import org . junit . runner . Result ; \n - JUnitCore core = new JUnitCore ( ) ; \n + run ( request , new JUnitCore ( ) ) ; \n + } \n + \n + public Result run ( Request request , JUnitCore core ) { \n - public void testStarted ( Description description ) throws Exception { \n + public void testStarted ( Description description ) throws Exception { \n - core . run ( request ) ; \n - try { \n - save ( ) ; \n - } catch ( FileNotFoundException e ) { \n - / / TODO \n - e . printStackTrace ( ) ; \n - } catch ( IOException e ) { \n - / / TODO \n - e . printStackTrace ( ) ; \n + try { \n + return core . run ( sortRequest ( request ) . getRunner ( ) ) ; \n + } finally { \n + try { \n + save ( ) ; \n + } catch ( FileNotFoundException e ) { \n + / / TODO \n + e . printStackTrace ( ) ; \n + } catch ( IOException e ) { \n + / / TODO \n + e . printStackTrace ( ) ; \n + } \n + } \n + } \n + \n + private Request sortRequest ( Request request ) { \n + if ( request instanceof SortingRequest ) { / / We ' ll pay big karma points for this \n + return request ; \n + return request . sortWith ( new TestComparator ( ) ) ; \n","AllTests passes , but Eclipse doesn ' t cal JUnitCore , so first attempt at dogfooding failed .",633
"src \ main \ java \ org \ junit \ runner \ JUnitCore . java \n - private RunNotifier fNotifier ; \n + RunNotifier fNotifier ; \n src \ main \ java \ org \ junit \ runner \ Request . java \n + import org . junit . runner . notification . RunNotifier ; \n + import org . junit . tests . experimental . max . CouldNotReadCoreException ; \n + import org . junit . tests . experimental . max . MaxCore ; \n + private static boolean firstTime = true ; \n - return new ClassRequest ( clazz ) ; \n + if ( firstTime ) { \n + firstTime = false ; \n + final ClassRequest delegate = new ClassRequest ( clazz ) ; \n + return new Request ( ) { \n + @ Override \n + public Runner getRunner ( ) { \n + return new Runner ( ) { \n + \n + @ Override \n + public void run ( RunNotifier notifier ) { \n + JUnitCore core = new JUnitCore ( ) ; \n + core . fNotifier = notifier ; \n + try { \n + MaxCore . forFolder ( "" defaultMaxCore "" ) . run ( delegate , core ) ; \n + } catch ( CouldNotReadCoreException e ) { \n + e . printStackTrace ( ) ; \n + } \n + } \n + \n + @ Override \n + public Description getDescription ( ) { \n + return delegate . getRunner ( ) . getDescription ( ) ; \n + } \n + } ; \n + } \n + } ; \n + } \n + else \n + return new ClassRequest ( clazz ) ; \n src \ test \ java \ org \ junit \ tests \ manipulation \ FilterableTest . java \n + throw new Error ( ) ; \n",Eclipse isn ' t quite calling Max just yet . Keep sinning until it does .,633
"src \ main \ java \ org \ junit \ internal \ runners \ JUnit38ClassRunner . java \n + private static class FilteredTestSuite extends TestSuite implements Describable { \n + private final TestSuite fSuite ; \n + private final Filter fFilter ; \n + \n + public FilteredTestSuite ( TestSuite suite , Filter filter ) { \n + fSuite = suite ; \n + fFilter = filter ; \n + } \n + \n + public Description getDescription ( ) { \n + String name = fSuite . getName ( ) = = null ? "" "" : fSuite . getName ( ) ; \n + Description description = Description . createSuiteDescription ( name ) ; \n + int n = fSuite . testCount ( ) ; \n + for ( int i = 0 ; i < n ; i + + ) { \n + Description childDescription = makeDescription ( fSuite . testAt ( i ) ) ; \n + if ( fFilter . shouldRun ( childDescription ) ) { \n + description . addChild ( childDescription ) ; \n + } \n + } \n + return description ; \n + } \n + \n + @ Override \n + public void runTest ( Test test , TestResult result ) { \n + if ( fFilter . shouldRun ( makeDescription ( test ) ) ) \n + super . runTest ( test , result ) ; \n + } \n + } \n + \n - private Description makeDescription ( Test test ) { \n + private static Description makeDescription ( Test test ) { \n + } else if ( fTest instanceof TestSuite ) { \n + TestSuite suite = ( TestSuite ) fTest ; \n + TestSuite filtered = new FilteredTestSuite ( suite , filter ) ; \n + fTest = filtered ; \n",* * * empty log message * * *,633
". cvsignore \n + * . ser \n src \ main \ java \ org \ junit \ runner \ Description . java \n + / / This seems like reasonable API once we "" Composite - ize "" Description \n - Matcher matcher = Pattern . compile ( "" ( . * ) \ \ ( ( . * ) \ \ ) "" ) . matcher ( toString ( ) ) ; \n - if ( matcher . matches ( ) ) \n - try { \n - return Class . forName ( matcher . group ( 2 ) ) ; \n - } catch ( ClassNotFoundException e ) { \n + String name = getClassName ( ) ; \n + if ( name = = null ) \n + return null ; \n + try { \n + return Class . forName ( name ) ; \n + } catch ( ClassNotFoundException e ) { \n - e . printStackTrace ( ) ; \n - } \n - return null ; \n + e . printStackTrace ( ) ; \n + return null ; \n + } \n - public String parseMethod ( ) { \n + public String getClassName ( ) { \n + Matcher matcher = Pattern . compile ( "" ( . * ) \ \ ( ( . * ) \ \ ) "" ) . matcher ( toString ( ) ) ; \n + return matcher . matches ( ) \n + ? matcher . group ( 2 ) \n + : null ; \n + } \n + \n + private String parseMethod ( ) { \n + \n + public String getMethodName ( ) { \n + return parseMethod ( ) ; \n + } \n src \ main \ java \ org \ junit \ runners \ model \ FrameworkMethod . java \n - package org . junit . runners . model ; \n + package org . junit . runners . model ; \n src \ test \ java \ org \ junit \ tests \ experimental \ max \ MaxStarterTest . java \n - assertNull ( Description . TEST _ MECHANISM . parseMethod ( ) ) ; \n + assertNull ( Description . TEST _ MECHANISM . getMethodName ( ) ) ; \n","Description seems to be heading towards Composite . Added "" getTestName """,633
ptr - demo \ build . gradle \n + task ( copyLibs ) < < { \n + } \n + \n deleted file \n ptr - demo \ libs \ clog - 1 . 0 . 2 - sources . jar \n Binary files a / ptr - demo / libs / clog - 1 . 0 . 2 - sources . jar and / dev / null differ \n deleted file \n ptr - demo \ libs \ clog - 1 . 0 . 2 . jar \n Binary files a / ptr - demo / libs / clog - 1 . 0 . 2 . jar and / dev / null differ \n deleted file \n ptr - demo \ libs \ cube - sdk - 1 . 0 . 40 . apklib \n Binary files a / ptr - demo / libs / cube - sdk - 1 . 0 . 40 . apklib and / dev / null differ \n deleted file \n ptr - demo \ libs \ support - v4 - r7 - sources . jar \n Binary files a / ptr - demo / libs / support - v4 - r7 - sources . jar and / dev / null differ \n deleted file \n ptr - demo \ libs \ support - v4 - r7 . jar \n Binary files a / ptr - demo / libs / support - v4 - r7 . jar and / dev / null differ \n deleted file \n ptr - demo \ libs \ ultra - ptr - 1 . 0 . 2 . apklib \n Binary files a / ptr - demo / libs / ultra - ptr - 1 . 0 . 2 . apklib and / dev / null differ \n ptr - demo \ pom . xml \n - < version > 1 . 0 . 2 < / version > \n + < version > 1 . 0 . 3 < / version > \n - \n - \n ptr - lib \ pom . xml \n - < version > 1 . 0 . 2 < / version > \n + < version > 1 . 0 . 3 < / version > \n - < description > GridView with Header and Footer < / description > \n + < description > Ultra Pull to Refresh in Android < / description > \n update - version . py \n - version _ name = ' 1 . 0 . 4 ' \n + version _ name = ' 1 . 0 . 3 ' \n,update version to 1 . 0 . 3,643
"ptr - demo \ src \ in \ srain \ cube \ views \ ptr \ demo \ ui \ MaterialStyleFragment . java \n - / / final PtrClassicDefaultHeader header = new PtrClassicDefaultHeader ( getContext ( ) ) ; \n - \n - frame . setWillNotDraw ( false ) ; \n + frame . setLoadingMinTime ( 1000 ) ; \n - frame . autoRefresh ( false ) ; \n + frame . autoRefresh ( ) ; \n ptr - demo \ src \ in \ srain \ cube \ views \ ptr \ demo \ ui \ classic \ AutoRefresh . java \n - ptrFrame . autoRefresh ( true ) ; \n + ptrFrame . autoRefresh ( false ) ; \n ptr - demo \ src \ in \ srain \ cube \ views \ ptr \ demo \ ui \ classic \ WithGridView . java \n - } , 1000 ) ; \n + } , 00 ) ; \n ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ PtrClassicDefaultHeader . java \n + / * * \n + * Specify the last update time by this key string \n + * \n + * @ param key \n + * / \n + / * * \n + * Using an object to specify the last update time . \n + * \n + * @ param object \n + * / \n ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ PtrClassicFrameLayout . java \n + / * * \n + * Specify the last update time by this key string \n + * \n + * @ param key \n + * / \n + / * * \n + * Using an object to specify the last update time . \n + * \n + * @ param object \n + * / \n ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ PtrFrameLayout . java \n - private int mLoadingMinTime = 0 ; \n + private int mLoadingMinTime = 500 ; \n - CLog . d ( LOG _ TAG , "" action down "" ) ; \n + / * * \n + * loading will last at least for so long \n + * \n + * @ param time \n + * / \n + public void setLoadingMinTime ( int time ) { \n + mLoadingStartTime = time ; \n + } \n + \n ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ header \ MaterialHeader . java \n + mDrawable . setAlpha ( 255 ) ; \n","add hook , fix # 19 ; add minimum loading time , fix # 18",643
README - cn . md \n - < version > 1 . 0 . 3 < / version > \n + < version > 1 . 0 . 5 < / version > \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - compile ' in . srain . cube : ultra - ptr : 1 . 0 . 4 @ aar ' \n + compile ' in . srain . cube : ultra - ptr : 1 . 0 . 5 @ aar ' \n README . md \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - compile ' in . srain . cube : ultra - ptr : 1 . 0 . 4 @ aar ' \n + compile ' in . srain . cube : ultra - ptr : 1 . 0 . 5 @ aar ' \n ptr - demo \ pom . xml \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n ptr - lib \ gradle . properties \n - VERSION _ NAME = 1 . 0 . 4 \n + VERSION _ NAME = 1 . 0 . 5 \n ptr - lib \ pom . xml \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n update - version . py \n - version _ name = ' 1 . 0 . 4 ' \n + version _ name = ' 1 . 0 . 5 ' \n,"update version , release 1 . 0 . 5",643
README - cn . md \n - < version > 1 . 0 . 3 < / version > \n + < version > 1 . 0 . 5 < / version > \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - compile ' in . srain . cube : ultra - ptr : 1 . 0 . 4 @ aar ' \n + compile ' in . srain . cube : ultra - ptr : 1 . 0 . 5 @ aar ' \n README . md \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n - compile ' in . srain . cube : ultra - ptr : 1 . 0 . 4 @ aar ' \n + compile ' in . srain . cube : ultra - ptr : 1 . 0 . 5 @ aar ' \n ptr - demo \ pom . xml \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n ptr - demo \ src \ in \ srain \ cube \ views \ ptr \ demo \ ui \ MaterialStyleFragment . java \n - frame . autoRefresh ( ) ; \n + frame . autoRefresh ( true ) ; \n ptr - demo \ src \ in \ srain \ cube \ views \ ptr \ demo \ ui \ classic \ AutoRefresh . java \n - ptrFrame . autoRefresh ( false ) ; \n + ptrFrame . autoRefresh ( true ) ; \n ptr - lib \ gradle . properties \n - VERSION _ NAME = 1 . 0 . 4 \n + VERSION _ NAME = 1 . 0 . 5 \n ptr - lib \ pom . xml \n - < version > 1 . 0 . 4 < / version > \n + < version > 1 . 0 . 5 < / version > \n update - version . py \n - version _ name = ' 1 . 0 . 4 ' \n + version _ name = ' 1 . 0 . 5 ' \n,"update version , release 1 . 0 . 5",643
"new file \n ptr - demo \ res \ drawable \ text _ view _ bg . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < selector xmlns : android = "" http : / / schemas . android . com / apk / res / android "" > \n + < item android : drawable = "" @ color / cube _ mints _ app _ base _ background "" android : state _ pressed = "" true "" / > \n + < item android : drawable = "" @ color / cube _ mints _ 4d90fe "" / > \n + < / selector > \n ptr - demo \ res \ layout \ fragment _ classic _ header _ with _ textview . xml \n - android : background = "" @ color / cube _ mints _ 4d90fe "" \n + android : clickable = "" true "" \n + android : background = "" @ drawable / text _ view _ bg "" \n ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ PtrFrameLayout . java \n + sendCancelEvent ( ) ; \n","fix # 33 , send cancle event to children when release",643
README - cn . md \n + # # # # 下拉刷新 + 加载更多？ \n + \n + 本类库是单纯的下拉刷新。如果你需要用到 ` 加载更多 ` ，看这个项目 : https : / / github . com / liaohuqiu / android - cube - app \n + \n template \ README - cn . md \n + # # # # 下拉刷新 + 加载更多？ \n + \n + 本类库是单纯的下拉刷新。如果你需要用到 ` 加载更多 ` ，看这个项目 : https : / / github . com / liaohuqiu / android - cube - app \n + \n,"update for add android - cube - app in Chinese README , thank you @ 红博 - android",643
new file \n ptr - demo - debug . apk \n Binary files / dev / null and b / ptr - demo - debug . apk differ \n,add ptr - demo - debug . apk,643
library \ build . gradle \n - minSdkVersion = 9 \n + minSdkVersion = 8 \n - } \n + } \n,"down minSDK to 8 , fix # 57",643
"ptr - lib \ src \ in \ srain \ cube \ views \ ptr \ PtrFrameLayout . java \n - private MotionEvent mDownEvent ; \n - mDownEvent = e ; \n - MotionEvent last = mDownEvent ; \n - last = mLastMoveEvent ; \n + / / The ScrollChecker will update position and lead to send cancel event when mLastMoveEvent is null . \n + / / fix # 104 , # 80 , # 92 \n + if ( mLastMoveEvent = = null ) { \n + return ; \n + } \n + MotionEvent last = mLastMoveEvent ; \n","The ScrollChecker will update position and lead to send cancel event when mLastMoveEvent is null . fix # 104 , # 80 , # 92",643
"README - cn . md \n - # # # # # # [ 关注我的GitHub吧，江湖救急，需要你的支持和帮助 ] ( http : / / www . liaohuqiu . net / cn / posts / follow - me - on - github / ) \n + # # # # # # 欢迎关注我 \n - Github : https : / / github . com / liaohuqiu \n + GitHub : https : / / github . com / liaohuqiu \n + 知乎 : http : / / www . zhihu . com / people / liao - hu - qiu \n + \n - - - \n README . md \n - # # # # # # [ Please follow me on GitHub , I need your support ] ( http : / / www . liaohuqiu . net / posts / follow - me - on - github / ) \n + # # # # # # Welcome to follow me on GitHub or Twitter \n - Github : https : / / github . com / liaohuqiu \n + GitHub : https : / / github . com / liaohuqiu \n - twitter : https : / / twitter . com / liaohuqiu \n + Twitter : https : / / twitter . com / liaohuqiu \n - - - \n template \ README - cn . md \n - # # # # # # [ 关注我的GitHub吧，江湖救急，需要你的支持和帮助 ] ( http : / / www . liaohuqiu . net / cn / posts / follow - me - on - github / ) \n + # # # # # # 欢迎关注我 \n - Github : https : / / github . com / liaohuqiu \n + GitHub : https : / / github . com / liaohuqiu \n + 知乎 : http : / / www . zhihu . com / people / liao - hu - qiu \n + \n - - - \n template \ README . md \n - # # # # # # [ Please follow me on GitHub , I need your support ] ( http : / / www . liaohuqiu . net / posts / follow - me - on - github / ) \n + # # # # # # Welcome to follow me on GitHub or Twitter \n - Github : https : / / github . com / liaohuqiu \n + GitHub : https : / / github . com / liaohuqiu \n - twitter : https : / / twitter . com / liaohuqiu \n + Twitter : https : / / twitter . com / liaohuqiu \n - - - \n",remove cube - sdk - adv qq tribe number from readme,643
"guava \ src \ com \ google \ common \ collect \ RegularImmutableList . java \n - import com . google . common . base . Preconditions ; \n - private final transient int offset ; \n - private final transient int size ; \n - RegularImmutableList ( Object [ ] array , int offset , int size ) { \n - this . offset = offset ; \n - this . size = size ; \n - this . array = array ; \n - } \n - \n - this ( array , 0 , array . length ) ; \n + this . array = array ; \n - return size ; \n + return array . length ; \n - return size ! = array . length ; \n + return false ; \n - System . arraycopy ( array , offset , dst , dstOff , size ) ; \n - return dstOff + size ; \n + System . arraycopy ( array , 0 , dst , dstOff , array . length ) ; \n + return dstOff + array . length ; \n - Preconditions . checkElementIndex ( index , size ) ; \n - return ( E ) array [ index + offset ] ; \n - } \n - \n - @ Override \n - ImmutableList < E > subListUnchecked ( int fromIndex , int toIndex ) { \n - return new RegularImmutableList < E > ( array , offset + fromIndex , toIndex - fromIndex ) ; \n + return ( E ) array [ index ] ; \n - return ( UnmodifiableListIterator < E > ) Iterators . forArray ( array , offset , size , index ) ; \n + return ( UnmodifiableListIterator < E > ) Iterators . forArray ( array , 0 , array . length , index ) ; \n","Remove the offset and size fields from RegularImmutableList . \n These seemed to be designed to create a faster sublist ( ) , but our base \n implementation of sublist seems likely to be quite similar in performance . \n Plus by eliminating these fields we : \n * eliminate a preconditions check and extra field reads on each call to get ( int ) \n * save 8 bytes for the fields ( and maybe more for alignment on some platforms ) \n This design seems to be from the very first version of RegularImmutableList and there don ' t appear to be benchmarks covering ImmutableList . get ( ) , so this change is somewhat speculative . I ' m curious what your thoughts are . \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 133794845",647
guava \ src \ com \ google \ common \ collect \ ImmutableList . java \n - case 1 : \n - return of ( get ( fromIndex ) ) ; \n,Remove the singleton list optimization from ImmutableList . sublist \n since SingletonImmutableList no longer exists there is no benefit and this will \n cause singleton sublists to consume more memory than non singleton sublists \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 151861509,647
android \ guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - if ( wasInterrupted ( ) ) { \n + if ( wasInterrupted ) { \n guava \ src \ com \ google \ common \ util \ concurrent \ AggregateFuture . java \n - if ( wasInterrupted ( ) ) { \n + if ( wasInterrupted ) { \n,Super - minor cleanup to AggregateFuture \n access the wasInterrupted local instead of calling the method again \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 162687910,647
"android \ guava \ src \ com \ google \ common \ primitives \ ImmutableDoubleArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n android \ guava \ src \ com \ google \ common \ primitives \ ImmutableIntArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n android \ guava \ src \ com \ google \ common \ primitives \ ImmutableLongArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n guava \ src \ com \ google \ common \ primitives \ ImmutableDoubleArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n guava \ src \ com \ google \ common \ primitives \ ImmutableIntArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n guava \ src \ com \ google \ common \ primitives \ ImmutableLongArray . java \n + import com . google . errorprone . annotations . Immutable ; \n + @ Immutable \n + / / The array is never mutated after storing in this field and the construction strategies ensure \n + / / it doesn ' t escape this class \n + @ SuppressWarnings ( "" Immutable "" ) \n",Mark Immutable ( Int | Long | Double ) Array with the errorprone @ Immutable annotation \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 158732518,647
"android \ guava \ src \ com \ google \ common \ util \ concurrent \ AbstractFuture . java \n - / / structure for them . \n + / / structure for them . Also , some implementations rely on this running prior to listeners \n + / / so that the cleanup work is visible to listeners . \n guava \ src \ com \ google \ common \ util \ concurrent \ AbstractFuture . java \n + import java . util . Locale ; \n - import java . util . Locale ; \n - / / structure for them . \n + / / structure for them . Also , some implementations rely on this running prior to listeners \n + / / so that the cleanup work is visible to listeners . \n",Add a note about the relative ordering of afterDone and listener execution \n RELNOTES = n / a \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 207146806,647
"android \ guava - tests \ test \ com \ google \ common \ net \ HttpHeadersTest . java \n + "" SOURCE _ MAP "" , \n + "" SourceMap "" , \n android \ guava \ src \ com \ google \ common \ net \ HttpHeaders . java \n + \n + / * * \n + * The HTTP < a href = "" http : / / goo . gl / Dxx19N "" > { @ code SourceMap } < / a > header field name . \n + * \n + * @ since NEXT \n + * / \n + @ Beta public static final String SOURCE _ MAP = "" SourceMap "" ; \n + \n guava - tests \ test \ com \ google \ common \ net \ HttpHeadersTest . java \n + "" SOURCE _ MAP "" , \n + "" SourceMap "" , \n guava \ src \ com \ google \ common \ net \ HttpHeaders . java \n + \n + / * * \n + * The HTTP < a href = "" http : / / goo . gl / Dxx19N "" > { @ code SourceMap } < / a > header field name . \n + * \n + * @ since NEXT \n + * / \n + @ Beta public static final String SOURCE _ MAP = "" SourceMap "" ; \n + \n","Create constants for the SourceMap header \n None of the tests like this header name , so each required some workarounds . \n RELNOTES = Add the SourceMap header to HttpHeaders \n - - - - - - - - - - - - - \n Created by MOE : https : / / github . com / google / moe \n MOE _ MIGRATED _ REVID = 234254287",647
UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - import android . content . res . Configuration ; \n + import android . util . DisplayMetrics ; \n - import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n - * 3 ) Get device screen dimensions . \n + * 3 ) Get < b > maxImageWidthForMemoryCache < / b > and < b > maxImageHeightForMemoryCache < / b > from configuration . If both of them are not set then go to step # 3 . < br / > \n + * 4 ) Get device screen dimensions . \n + DisplayMetrics displayMetrics = imageView . getContext ( ) . getResources ( ) . getDisplayMetrics ( ) ; \n + \n + if ( width < = 0 ) width = displayMetrics . widthPixels ; \n - \n - / / Consider device screen orientation \n - int screenOrientation = imageView . getContext ( ) . getResources ( ) . getConfiguration ( ) . orientation ; \n - if ( ( screenOrientation = = Configuration . ORIENTATION _ PORTRAIT & & width > height ) \n - | | ( screenOrientation = = Configuration . ORIENTATION _ LANDSCAPE & & width < height ) ) { \n - int tmp = width ; \n - width = height ; \n - height = tmp ; \n - } \n + if ( height < = 0 ) height = displayMetrics . heightPixels ; \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n - import android . util . DisplayMetrics ; \n - DisplayMetrics displayMetrics = context . getResources ( ) . getDisplayMetrics ( ) ; \n - if ( maxImageWidthForMemoryCache = = 0 ) { \n - maxImageWidthForMemoryCache = displayMetrics . widthPixels ; \n - } \n - if ( maxImageHeightForMemoryCache = = 0 ) { \n - maxImageHeightForMemoryCache = displayMetrics . heightPixels ; \n - } \n,Issue # 93 - Problem with landscape images \n Fixed calculation of size the original image is needed scale to,656
UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ ImageDecoder . java \n - subsampledBitmap . recycle ( ) ; \n + if ( scaledBitmap ! = subsampledBitmap ) { \n + subsampledBitmap . recycle ( ) ; \n + } \n,Issue # 101 - Prevent recycling of using Bitmap,656
"UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n + * < li > bitmap decoding configuration < / li > \n + private final Bitmap . Config bitmapConfig ; \n + bitmapConfig = builder . bitmapConfig ; \n + Bitmap . Config getBitmapConfig ( ) { \n + return bitmapConfig ; \n + } \n + \n + private Bitmap . Config bitmapConfig = Bitmap . Config . ARGB _ 8888 ; \n + / * * Sets { @ link Bitmap . Config bitmap config } for image decoding . Default value - { @ link Bitmap . Config # ARGB _ 8888 } * / \n + public Builder bitmapConfig ( Bitmap . Config bitmapConfig ) { \n + this . bitmapConfig = bitmapConfig ; \n + return this ; \n + } \n + \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ ImageDecoder . java \n + * @ see DisplayImageOptions \n + private final DisplayImageOptions displayOptions ; \n - ImageDecoder ( URI imageUri , ImageDownloader imageDownloader ) { \n + ImageDecoder ( URI imageUri , ImageDownloader imageDownloader , DisplayImageOptions options ) { \n + this . displayOptions = options ; \n - Options options = new Options ( ) ; \n - options . inSampleSize = computeImageScale ( targetSize , scaleType , viewScaleType ) ; \n - return options ; \n + Options decodeOptions = new Options ( ) ; \n + decodeOptions . inSampleSize = computeImageScale ( targetSize , scaleType , viewScaleType ) ; \n + decodeOptions . inPreferredConfig = displayOptions . getBitmapConfig ( ) ; \n + return decodeOptions ; \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - ImageDecoder decoder = new ImageDecoder ( imageUri , configuration . downloader ) ; \n + ImageDecoder decoder = new ImageDecoder ( imageUri , configuration . downloader , imageLoadingInfo . options ) ; \n - ImageDecoder decoder = new ImageDecoder ( imageUri , configuration . downloader ) ; \n + ImageDecoder decoder = new ImageDecoder ( imageUri , configuration . downloader , imageLoadingInfo . options ) ; \n - ImageDecoder decoder = new ImageDecoder ( new URI ( imageLoadingInfo . uri ) , configuration . downloader ) ; \n + ImageDecoder decoder = new ImageDecoder ( new URI ( imageLoadingInfo . uri ) , configuration . downloader , imageLoadingInfo . options ) ; \n",Issue # 101 - Added possibility to set Bitmap config ( colorspace ) in \n DisplayImageOptions,656
"UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ download \ ImageDownloader . java \n + protected static final int BUFFER _ SIZE = 8 * 1024 ; / / 8 Kb \n + \n - return new BufferedInputStream ( imageUri . toURL ( ) . openStream ( ) ) ; \n + return new BufferedInputStream ( imageUri . toURL ( ) . openStream ( ) , BUFFER _ SIZE ) ; \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ download \ URLConnectionImageDownloader . java \n - return new FlushedInputStream ( new BufferedInputStream ( conn . getInputStream ( ) ) ) ; \n + return new FlushedInputStream ( new BufferedInputStream ( conn . getInputStream ( ) , BUFFER _ SIZE ) ) ; \n",Pass 8Kb to BufferedInputStream constructor to avoid redundant logging,656
"UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayBitmapTask . java \n + ImageLoader . getInstance ( ) . cancelDisplayTask ( imageView ) ; \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n + import java . util . HashMap ; \n - private Map < ImageView , String > cacheKeysForImageViews = Collections . synchronizedMap ( new WeakHashMap < ImageView , String > ( ) ) ; \n + private Map < Integer , String > cacheKeysForImageViews = Collections . synchronizedMap ( new HashMap < Integer , String > ( ) ) ; \n - cacheKeysForImageViews . remove ( imageView ) ; \n + cacheKeysForImageViews . remove ( imageView . hashCode ( ) ) ; \n - cacheKeysForImageViews . put ( imageView , memoryCacheKey ) ; \n + cacheKeysForImageViews . put ( imageView . hashCode ( ) , memoryCacheKey ) ; \n - return cacheKeysForImageViews . get ( imageView ) ; \n + return cacheKeysForImageViews . get ( imageView . hashCode ( ) ) ; \n - cacheKeysForImageViews . remove ( imageView ) ; \n + cacheKeysForImageViews . remove ( imageView . hashCode ( ) ) ; \n UniversalImageLoader \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - boolean checkTaskIsNotActual ( ) { \n + private boolean checkTaskIsNotActual ( ) { \n",Issue # 108 - cacheKeysForImageViews consumes a lot of memory \n Map key : ImageView - > ImageView . hashcode ( ) . Remove map entry after \n successful displaying .,656
UniversalImageLoaderExample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n + import android . graphics . drawable . BitmapDrawable ; \n - ( ( ViewPager ) container ) . removeView ( ( View ) object ) ; \n + View rootView = ( View ) object ; \n + ImageView imageView = ( ImageView ) rootView . findViewById ( R . id . image ) ; \n + BitmapDrawable drawable = ( BitmapDrawable ) imageView . getDrawable ( ) ; \n + if ( drawable ! = null ) { \n + Bitmap bitmap = drawable . getBitmap ( ) ; \n + if ( bitmap ! = null ) { \n + bitmap . recycle ( ) ; \n + } \n + } \n + \n + ( ( ViewPager ) container ) . removeView ( rootView ) ; \n,Example : recycle Bitmaps for destroyed items in ViewPager,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n,Maven support : Added - SNAPSHOT additions to POMs,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
library \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 0,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 7 . 0 "" \n This reverts commit f0766a41348e388b3d75ca29f0192b2fa7d7f29a .",656
library \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 0,656
pom . xml \n - < android - maven . version > 3 . 2 . 0 < / android - maven . version > \n - < version > 2 . 3 . 2 < / version > \n + < version > 2 . 0 . 2 < / version > \n - < version > 2 . 3 . 2 < / version > \n + < version > 2 . 0 - beta - 9 < / version > \n - < version > $ { android - maven . version } < / version > \n + < version > 3 . 5 . 0 < / version > \n - < version > 2 . 2 . 1 < / version > \n + < version > 2 . 1 < / version > \n,Maven support : Use plugin versions compatible with Maven 3 . x,656
pom . xml \n - < version > 2 . 0 . 2 < / version > \n + < version > 3 . 0 < / version > \n - < version > 2 . 0 - beta - 9 < / version > \n + < version > 2 . 4 < / version > \n - < version > 2 . 8 < / version > \n + < version > 2 . 9 < / version > \n - < version > 2 . 1 < / version > \n + < version > 2 . 2 . 1 < / version > \n,Maven support : Use the newest plugin versions,656
library \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 0,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 7 . 0 "" \n This reverts commit 7ac63fe34dcfbb449a9991be483b1124d846d651 .",656
library \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 0,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 0 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 7 . 0 "" \n This reverts commit 5a3c346ca8a3f2089a8f80affad75f34a592979a .",656
library \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 - SNAPSHOT < / version > \n + < version > 1 . 7 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 0,656
library \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 7 . 0 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
new file \n downloads \ universal - image - loader - 1 . 7 . 0 - javadoc . jar \n Binary files / dev / null and b / downloads / universal - image - loader - 1 . 7 . 0 - javadoc . jar differ \n downloads \ universal - image - loader - 1 . 7 . 0 - sources . jar \n Binary files a / downloads / universal - image - loader - 1 . 7 . 0 - sources . jar and b / downloads / universal - image - loader - 1 . 7 . 0 - sources . jar differ \n new file \n downloads \ universal - image - loader - 1 . 7 . 0 - with - sources . jar \n Binary files / dev / null and b / downloads / universal - image - loader - 1 . 7 . 0 - with - sources . jar differ \n downloads \ universal - image - loader - 1 . 7 . 0 . jar \n Binary files a / downloads / universal - image - loader - 1 . 7 . 0 . jar and b / downloads / universal - image - loader - 1 . 7 . 0 . jar differ \n,Added JARs and APK to downloads folder .,656
"library \ src \ com \ nostra13 \ universalimageloader \ utils \ StorageUtils . java \n - try { \n - new File ( dataDir , "" . nomedia "" ) . createNewFile ( ) ; \n - } catch ( IOException e ) { \n - L . e ( e , "" Can ' t create \ "" . nomedia \ "" file in application external cache directory "" ) ; \n - } \n + try { \n + new File ( appCacheDir , "" . nomedia "" ) . createNewFile ( ) ; \n + } catch ( IOException e ) { \n + L . i ( "" Can ' t create \ "" . nomedia \ "" file in application external cache directory "" ) ; \n + } \n","Issue # 143 - "" Can ' t create "" . nomedia "" file "" logs \n Create "" . nomedia "" in cache dir , not in data . L . e - > L . i",656
sample \ pom . xml \n - < version > 1 . 6 _ r2 < / version > \n + < version > 2 . 3 . 1 < / version > \n,Maven : Increase sample project Android version dependency,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n + import java . util . concurrent . Executors ; \n + private ExecutorService taskDistributor ; \n - public void displayImage ( String uri , ImageView imageView , DisplayImageOptions options , ImageLoadingListener listener ) { \n + public void displayImage ( final String uri , ImageView imageView , DisplayImageOptions options , ImageLoadingListener listener ) { \n - LoadAndDisplayImageTask displayImageTask = new LoadAndDisplayImageTask ( configuration , imageLoadingInfo , new Handler ( ) ) ; \n - boolean isImageCachedOnDisc = configuration . discCache . get ( uri ) . exists ( ) ; \n - if ( isImageCachedOnDisc ) { \n - cachedImageLoadingExecutor . submit ( displayImageTask ) ; \n - } else { \n - imageLoadingExecutor . submit ( displayImageTask ) ; \n - } \n + final LoadAndDisplayImageTask displayImageTask = new LoadAndDisplayImageTask ( configuration , imageLoadingInfo , new Handler ( ) ) ; \n + \n + taskDistributor . submit ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + boolean isImageCachedOnDisc = configuration . discCache . get ( uri ) . exists ( ) ; \n + if ( isImageCachedOnDisc ) { \n + cachedImageLoadingExecutor . submit ( displayImageTask ) ; \n + } else { \n + imageLoadingExecutor . submit ( displayImageTask ) ; \n + } \n + } \n + } ) ; \n - imageLoadingExecutor = createExecutor ( ) ; \n + imageLoadingExecutor = createTaskExecutor ( ) ; \n - cachedImageLoadingExecutor = createExecutor ( ) ; \n + cachedImageLoadingExecutor = createTaskExecutor ( ) ; \n + } \n + if ( taskDistributor = = null | | taskDistributor . isShutdown ( ) ) { \n + taskDistributor = Executors . newCachedThreadPool ( ) ; \n - private ExecutorService createExecutor ( ) { \n + private ExecutorService createTaskExecutor ( ) { \n + if ( taskDistributor ! = null ) { \n + taskDistributor . shutdownNow ( ) ; \n + } \n",Issue 129 - Filesystem access from main thread \n Issue 154 - ANR while accessing to disk cache \n Not make I / O operations on main thread .,656
library \ pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n - < tag > v1 . 7 . 0 < / tag > \n + < tag > v1 . 7 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 1,656
library \ pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n - < tag > v1 . 7 . 1 < / tag > \n + < tag > v1 . 7 . 0 < / tag > \n sample \ pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 7 . 1 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 7 . 1 "" \n This reverts commit b5ea690ce34a04c12673ef9de0935d89488db045 .",656
library \ pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n - < tag > v1 . 7 . 0 < / tag > \n + < tag > v1 . 7 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 7 . 1 - SNAPSHOT < / version > \n + < version > 1 . 7 . 1 < / version > \n,[ maven - release - plugin ] prepare release v1 . 7 . 1,656
library \ pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 8 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 8 . 0 - SNAPSHOT < / version > \n - < tag > v1 . 7 . 1 < / tag > \n + < tag > v1 . 7 . 0 < / tag > \n sample \ pom . xml \n - < version > 1 . 7 . 1 < / version > \n + < version > 1 . 8 . 0 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - import android . content . Context ; \n - * @ param context Application context ( used for creation of fake { @ link ImageView } ) \n - public void loadImage ( Context context , String uri , ImageLoadingListener listener ) { \n - loadImage ( context , uri , null , null , listener ) ; \n + public void loadImage ( String uri , ImageLoadingListener listener ) { \n + loadImage ( uri , null , null , listener ) ; \n - * @ param context Application context ( used for creation of fake { @ link ImageView } ) \n - public void loadImage ( Context context , String uri , ImageSize minImageSize , ImageLoadingListener listener ) { \n - loadImage ( context , uri , minImageSize , null , listener ) ; \n + public void loadImage ( String uri , ImageSize minImageSize , ImageLoadingListener listener ) { \n + loadImage ( uri , minImageSize , null , listener ) ; \n - * @ param context Application context ( used for creation of fake { @ link ImageView } ) \n - public void loadImage ( Context context , String uri , DisplayImageOptions options , ImageLoadingListener listener ) { \n - loadImage ( context , uri , null , options , listener ) ; \n + public void loadImage ( String uri , DisplayImageOptions options , ImageLoadingListener listener ) { \n + loadImage ( uri , null , options , listener ) ; \n - * @ param context Application context ( used for creation of fake { @ link ImageView } ) \n - public void loadImage ( Context context , String uri , ImageSize minImageSize , DisplayImageOptions options , ImageLoadingListener listener ) { \n + public void loadImage ( String uri , ImageSize minImageSize , DisplayImageOptions options , ImageLoadingListener listener ) { \n - ImageView fakeImage = new ImageView ( context ) ; \n + ImageView fakeImage = new ImageView ( configuration . context ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n + final Context context ; \n + \n + context = builder . context ; \n",Changed API : Removed context reference from ImageLoader . loadImage ( . . . ) \n parameters . Keep app context in configuration .,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ widget \ UILWidgetProvider . java \n - ImageLoader . getInstance ( ) . loadImage ( context , IMAGES [ 0 ] , minImageSize , optionsWithFakeDisplayer , new SimpleImageLoadingListener ( ) { \n + ImageLoader . getInstance ( ) . loadImage ( IMAGES [ 0 ] , minImageSize , optionsWithFakeDisplayer , new SimpleImageLoadingListener ( ) { \n - ImageLoader . getInstance ( ) . loadImage ( context , IMAGES [ 1 ] , minImageSize , optionsWithFakeDisplayer , new SimpleImageLoadingListener ( ) { \n + ImageLoader . getInstance ( ) . loadImage ( IMAGES [ 1 ] , minImageSize , optionsWithFakeDisplayer , new SimpleImageLoadingListener ( ) { \n",Sample : Used new API of ImageLoader . loadImage ( . . . ),656
library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n + imageOnFail = options . imageOnFail ; \n + extraForDownloader = options . extraForDownloader ; \n + preProcessor = options . preProcessor ; \n + postProcessor = options . postProcessor ; \n,Issue # 173 - cloneFrom does not clone pre / postprocessor,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n + private static final String STATE _ POSITION = "" STATE _ POSITION "" ; \n + \n + ViewPager pager ; \n + \n + if ( savedInstanceState ! = null ) { \n + pagerPosition = savedInstanceState . getInt ( STATE _ POSITION ) ; \n + } \n + \n - ViewPager pager = ( ViewPager ) findViewById ( R . id . pager ) ; \n + pager = ( ViewPager ) findViewById ( R . id . pager ) ; \n + @ Override \n + public void onSaveInstanceState ( Bundle outState ) { \n + outState . putInt ( STATE _ POSITION , pager . getCurrentItem ( ) ) ; \n + } \n + \n",Sample : Save position for pager on screen rotation,656
library \ src \ com \ nostra13 \ universalimageloader \ cache \ memory \ BaseMemoryCache . java \n + import java . util . HashSet ; \n - return softMap . keySet ( ) ; \n + return new HashSet < K > ( softMap . keySet ( ) ) ; \n,Issue # 174 - Concurrent Modification Synchronization issue,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ ImageDownloader . java \n - if ( SCHEME _ HTTP . equals ( scheme ) | | SCHEME _ HTTPS . equals ( scheme ) | | SCHEME _ FTP . equals ( scheme ) ) { \n + if ( SCHEME _ HTTP . equals ( scheme ) | | SCHEME _ HTTPS . equals ( scheme ) ) { \n,Not process images from FTP by default .,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ UILApplication . java \n - import android . app . ActivityManager ; \n + import android . graphics . Bitmap ; \n + import com . nostra13 . universalimageloader . cache . memory . MemoryCacheAware ; \n + import com . nostra13 . universalimageloader . cache . memory . impl . LRULimitedMemoryCache ; \n + import com . nostra13 . universalimageloader . cache . memory . impl . LruMemoryCache ; \n - int memoryCacheSize ; \n - if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . ECLAIR ) { \n - int memClass = ( ( ActivityManager ) context . getSystemService ( Context . ACTIVITY _ SERVICE ) ) . getMemoryClass ( ) ; \n - memoryCacheSize = ( memClass / 8 ) * 1024 * 1024 ; / / 1 / 8 of app memory limit \n + int memoryCacheSize = ( int ) ( Runtime . getRuntime ( ) . maxMemory ( ) / 8 ) ; \n + \n + MemoryCacheAware < String , Bitmap > memoryCache ; \n + if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . GINGERBREAD ) { \n + memoryCache = new LruMemoryCache ( memoryCacheSize ) ; \n - memoryCacheSize = 2 * 1024 * 1024 ; \n + memoryCache = new LRULimitedMemoryCache ( memoryCacheSize ) ; \n - . threadPriority ( Thread . NORM _ PRIORITY - 2 ) \n - . memoryCacheSize ( memoryCacheSize ) \n - . denyCacheImageMultipleSizesInMemory ( ) \n - . discCacheFileNameGenerator ( new Md5FileNameGenerator ( ) ) \n - . tasksProcessingOrder ( QueueProcessingType . LIFO ) \n - . enableLogging ( ) / / Not necessary in common \n - . build ( ) ; \n + . threadPriority ( Thread . NORM _ PRIORITY - 2 ) \n + . memoryCache ( memoryCache ) \n + . denyCacheImageMultipleSizesInMemory ( ) \n + . discCacheFileNameGenerator ( new Md5FileNameGenerator ( ) ) \n + . tasksProcessingOrder ( QueueProcessingType . LIFO ) \n + . enableLogging ( ) / / Not necessary in common \n + . build ( ) ; \n",Sample : Set memory cache depending on Android version,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGridActivity . java \n - listView . setAdapter ( new ImageAdapter ( ) ) ; \n + ( ( GridView ) listView ) . setAdapter ( new ImageAdapter ( ) ) ; \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n - listView . setAdapter ( new ItemAdapter ( ) ) ; \n + ( ( ListView ) listView ) . setAdapter ( new ItemAdapter ( ) ) ; \n,Sample : Issue # 206 - java . lang . NoSuchMethodError : \n android . widget . AbsListView . setAdapter,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ Constants . java \n + "" http : / / img001 . us . expono . com / 100001 / 100001 - 1bc30 - 2d736f _ m . jpg "" , / / EXIF \n",Sample : Added test URL for EXIF image,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n - . imageScaleType ( ImageScaleType . IN _ SAMPLE _ INT ) \n + . imageScaleType ( ImageScaleType . EXACTLY ) \n,Sample : Use ImageScaleType . EXACTLY for pager,656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ LimitedDiscCache . java \n - int size = 0 ; \n - File [ ] cachedFiles = cacheDir . listFiles ( ) ; \n - for ( File cachedFile : cachedFiles ) { \n - size + = getSize ( cachedFile ) ; \n - lastUsageDates . put ( cachedFile , cachedFile . lastModified ( ) ) ; \n - } \n - cacheSize . set ( size ) ; \n + new Thread ( new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + int size = 0 ; \n + File [ ] cachedFiles = cacheDir . listFiles ( ) ; \n + for ( File cachedFile : cachedFiles ) { \n + size + = getSize ( cachedFile ) ; \n + lastUsageDates . put ( cachedFile , cachedFile . lastModified ( ) ) ; \n + } \n + cacheSize . set ( size ) ; \n + } \n + } ) . start ( ) ; \n","Init LimitedDiscCache asynchronously , prevent long I / O operation on UI \n thread",656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n + import com . nostra13 . universalimageloader . cache . memory . impl . FuzzyKeyMemoryCache ; \n + import com . nostra13 . universalimageloader . core . assist . MemoryCacheUtil ; \n + } else if ( denyCacheImageMultipleSizesInMemory ) { \n + memoryCache = new FuzzyKeyMemoryCache < String , Bitmap > ( memoryCache , MemoryCacheUtil . createFuzzyKeyComparator ( ) ) ; \n",Fixed bug : . denyCacheImageMultipleSizesInMemory doesn ' t work if own \n memory cache is set,656
library \ pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 3 < / version > \n pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 3 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 3 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 3 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 3,656
library \ pom . xml \n - < version > 1 . 8 . 3 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 3 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 3 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 3 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ pom . xml \n - < project \n - xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n - xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n - xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n pom . xml \n - < project \n - xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n - xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n - xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n - < / scm > \n + < tag > v1 . 8 . 4 < / tag > \n + < / scm > \n sample \ pom . xml \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n",[ maven - release - plugin ] prepare release v1 . 8 . 4,656
"library \ pom . xml \n - < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project \n + xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n + xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n + xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n pom . xml \n - < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project \n + xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n + xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n + xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 4 < / tag > \n - < / scm > \n + < / scm > \n sample \ pom . xml \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 4 - SNAPSHOT < / version > \n","Revert "" [ maven - release - plugin ] prepare release v1 . 8 . 4 "" \n This reverts commit a08f62b8d8e4a4e3daed4c376a4363bb6c19e0a2 .",656
"library \ pom . xml \n - < project \n - xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n - xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n - xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n pom . xml \n - < project \n - xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" \n - xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" \n - xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n + < project xmlns = "" http : / / maven . apache . org / POM / 4 . 0 . 0 "" xmlns : xsi = "" http : / / www . w3 . org / 2001 / XMLSchema - instance "" xsi : schemaLocation = "" http : / / maven . apache . org / POM / 4 . 0 . 0 http : / / maven . apache . org / xsd / maven - 4 . 0 . 0 . xsd "" > \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n - < / scm > \n + < tag > v1 . 8 . 4 < / tag > \n + < / scm > \n sample \ pom . xml \n - < version > 1 . 8 . 4 - SNAPSHOT < / version > \n + < version > 1 . 8 . 4 < / version > \n",[ maven - release - plugin ] prepare release v1 . 8 . 4,656
library \ pom . xml \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 5 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 5 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 4 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 4 < / version > \n + < version > 1 . 8 . 5 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ assist \ ImageSize . java \n + private static final int TO _ STRING _ MAX _ LENGHT = 9 ; / / "" 9999x9999 "" . length ( ) \n - return new StringBuilder ( width ) . append ( SEPARATOR ) . append ( height ) . toString ( ) ; \n + return new StringBuilder ( TO _ STRING _ MAX _ LENGHT ) . append ( width ) . append ( SEPARATOR ) . append ( height ) . toString ( ) ; \n",Fixed ImageSize . toString ( ) ( wrong logs ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + log ( LOG _ TASK _ CANCELLED ) ; \n - \n - if ( imageViewWasReused ) log ( LOG _ TASK _ CANCELLED ) ; \n - bitmap = decodeImage ( imageUriForDecoding ) ; \n - if ( bitmap = = null ) { \n - fireImageLoadingFailedEvent ( FailType . DECODING _ ERROR , null ) ; \n + if ( ! checkTaskIsNotActual ( ) ) { \n + bitmap = decodeImage ( imageUriForDecoding ) ; \n + if ( bitmap = = null ) { \n + fireImageLoadingFailedEvent ( FailType . DECODING _ ERROR , null ) ; \n + } \n",Issue # 247 - Prevent image decoding if image is reused,656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ BaseDiscCache . java \n + private static final String ERROR _ ARG _ NULL = "" \ "" % s \ "" argument must be not null "" ; \n + \n + if ( cacheDir = = null ) { \n + throw new IllegalArgumentException ( "" cacheDir "" + ERROR _ ARG _ NULL ) ; \n + } \n + if ( fileNameGenerator = = null ) { \n + throw new IllegalArgumentException ( "" fileNameGenerator "" + ERROR _ ARG _ NULL ) ; \n + } \n + \n",Issue # 226 - Throw IllegalArgumentException in BaseDiscCache,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ProcessAndDisplayImageTask . java \n - if ( processedBitmap ! = bitmap ) { \n - bitmap . recycle ( ) ; \n - } \n,Issue # 259 - PostProcessor gives recycled bitmap \n Prevent recycling of cached in memory images .,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ decode \ BaseImageDecoder . java \n - final int rotation ; \n - final boolean flipHorizontal ; \n + protected final int rotation ; \n + protected final boolean flipHorizontal ; \n - ExifInfo ( ) { \n + protected ExifInfo ( ) { \n - ExifInfo ( int rotation , boolean flipHorizontal ) { \n + protected ExifInfo ( int rotation , boolean flipHorizontal ) { \n - final ImageSize imageSize ; \n - final ExifInfo exif ; \n + protected final ImageSize imageSize ; \n + protected final ExifInfo exif ; \n - ImageFileInfo ( ImageSize imageSize , ExifInfo exif ) { \n + protected ImageFileInfo ( ImageSize imageSize , ExifInfo exif ) { \n",Expanded visibility of inner class members in BaseImageDecoder,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ display \ RoundedBitmapDisplayer . java \n - if ( roundBitmap ! = bitmap ) { \n - bitmap . recycle ( ) ; \n - } \n,"Revert "" Recycle old bitmap in RoundedBitmapDisplayer "" \n This reverts commit bcde84ac96e239ca1299a86676b30c4b625a8ff3 .",656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderEngine . java \n - if ( taskExecutor = = null ) { \n + if ( ! configuration . customExecutor & & ( ( ExecutorService ) taskExecutor ) . isShutdown ( ) ) { \n - if ( taskExecutorForCachedImages = = null ) { \n + if ( ! configuration . customExecutorForCachedImages & & ( ( ExecutorService ) taskExecutorForCachedImages ) . isShutdown ( ) ) { \n - taskExecutor = null ; \n + ( ( ExecutorService ) taskExecutor ) . shutdownNow ( ) ; \n - taskExecutorForCachedImages = null ; \n + ( ( ExecutorService ) taskExecutorForCachedImages ) . shutdownNow ( ) ; \n,"Issue # 301 - NPE in ImageLoaderEngine \n Not null executors , shutdown built - in executors on engine stop",656
library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - private static final int BUFFER _ SIZE = 8 * 1024 ; / / 8 Kb \n + private static final int BUFFER _ SIZE = 32 * 1024 ; / / 32 Kb \n library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - protected static final int BUFFER _ SIZE = 8 * 1024 ; / / 8 Kb \n + protected static final int BUFFER _ SIZE = 32 * 1024 ; / / 32 Kb \n library \ src \ com \ nostra13 \ universalimageloader \ utils \ IoUtils . java \n - private static final int BUFFER _ SIZE = 8 * 1024 ; / / 8 KB \n + private static final int BUFFER _ SIZE = 32 * 1024 ; / / 32 KB \n,Issue # 249 : Buffer size 8K - > 32K,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n - * < li > auxiliary object which will be passed to { @ link ImageDownloader # getStream ( java . net . URI , Object ) ImageDownloader } < / li > \n + * < li > auxiliary object which will be passed to { @ link ImageDownloader # getStream ( String , Object ) ImageDownloader } < / li > \n - / * * { @ link android . widget . ImageView ImageView } will be reset ( set < b > null < / b > ) before image loading start * / \n + / * * \n + * { @ link android . widget . ImageView ImageView } will be reset ( set < b > null < / b > ) before image loading start \n + * \n + * @ deprecated Use { @ link # resetViewBeforeLoading ( boolean ) resetViewBeforeLoading ( true ) } instead \n + * / \n - / * * Loaded image will be cached in memory * / \n + / * * Sets whether { @ link android . widget . ImageView ImageView } will be reset ( set < b > null < / b > ) before image loading start * / \n + public Builder resetViewBeforeLoading ( boolean resetViewBeforeLoading ) { \n + this . resetViewBeforeLoading = resetViewBeforeLoading ; \n + return this ; \n + } \n + \n + / * * \n + * Loaded image will be cached in memory \n + * \n + * @ deprecated Use { @ link # cacheInMemory ( boolean ) cacheInMemory ( true ) } instead \n + * / \n - / * * Loaded image will be cached on disc * / \n + / * * Sets whether loaded image will be cached in memory * / \n + public Builder cacheInMemory ( boolean cacheInMemory ) { \n + this . cacheInMemory = cacheInMemory ; \n + return this ; \n + } \n + \n + / * * \n + * Loaded image will be cached on disc \n + * \n + * @ deprecated Use { @ link # cacheOnDisc ( boolean ) cacheOnDisc ( true ) } instead \n + * / \n + / * * Sets whether loaded image will be cached on disc * / \n + public Builder cacheOnDisc ( boolean cacheOnDisc ) { \n + this . cacheOnDisc = cacheOnDisc ; \n + return this ; \n + } \n + \n - / * * Sets auxiliary object which will be passed to { @ link ImageDownloader # getStream ( java . net . URI , Object ) } * / \n + / * * Sets auxiliary object which will be passed to { @ link ImageDownloader # getStream ( String , Object ) } * / \n","Issue # 252 - Introduced DisplayImageOptions . cacheInMemory ( boolean ) , . cacheOnDisc ( boolean ) , resetViewBeforeLoading ( boolean ) \n Deprecated appropriate methods without boolean param",656
library \ src \ com \ nostra13 \ universalimageloader \ utils \ L . java \n - import com . nostra13 . universalimageloader . core . ImageLoader ; \n - \n + import com . nostra13 . universalimageloader . core . ImageLoader ; \n - * \n + * \n + private static volatile boolean DISABLED = false ; \n + public static void enableLogging ( ) { \n + DISABLED = false ; \n + } \n + \n + public static void disableLogging ( ) { \n + DISABLED = true ; \n + } \n + \n + if ( DISABLED ) return ; \n,Issue # 270 - Printing log messages should be configurable \n Added L . disableLogging ( ) and . enableLogging ( ) to completely on / off UIL ' s logs,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ display \ RoundedBitmapDisplayer . java \n - width = Math . min ( vw , bw ) ; \n - height = Math . min ( vh , bh ) ; \n + width = srcWidth ; / / Math . min ( vw , bw ) ; \n + height = srcHeight ; / / Math . min ( vh , bh ) ; \n",Issue # 315 - RoundedBitmapDisplayer not display round corner correctly ( CenterCrop ),656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - imageView . setImageBitmap ( null ) ; \n + imageView . setImageDrawable ( null ) ; \n - imageView . setImageBitmap ( null ) ; \n + imageView . setImageDrawable ( null ) ; \n,ImageView . setImageBitmap ( ) - > setImageDrawable ( ) to reset view \n Fixed Issue # 260,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ Constants . java \n + "" http : / / cdn . urbanislandz . com / wp - content / uploads / 2011 / 10 / MMSposter - large . jpg "" , / / very large image \n",Sample : Added link of very large image,656
pom . xml \n - < version > 3 . 5 . 3 < / version > \n + < version > 3 . 6 . 0 < / version > \n,Maven : Use new version 3 . 6 . 0 of android - maven - plugin,656
library \ pom . xml \n - < version > 1 . 8 . 5 - SNAPSHOT < / version > \n + < version > 1 . 8 . 5 < / version > \n pom . xml \n - < version > 1 . 8 . 5 - SNAPSHOT < / version > \n + < version > 1 . 8 . 5 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 5 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 5 - SNAPSHOT < / version > \n + < version > 1 . 8 . 5 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 5,656
library \ pom . xml \n - < version > 1 . 8 . 5 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 5 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 5 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 5 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ utils \ StorageUtils . java \n - if ( Environment . getExternalStorageState ( ) . equals ( MEDIA _ MOUNTED ) & & hasExternalStoragePermission ( context ) ) { \n + if ( MEDIA _ MOUNTED . equals ( Environment . getExternalStorageState ( ) ) & & hasExternalStoragePermission ( context ) ) { \n - L . w ( "" Can ' t define system cache directory ! "" ) ; \n - appCacheDir = context . getCacheDir ( ) ; / / retry \n + L . w ( "" Can ' t define system cache directory ! The app should be re - installed . "" ) ; \n - if ( Environment . getExternalStorageState ( ) . equals ( MEDIA _ MOUNTED ) & & hasExternalStoragePermission ( context ) ) { \n + if ( MEDIA _ MOUNTED . equals ( Environment . getExternalStorageState ( ) ) & & hasExternalStoragePermission ( context ) ) { \n",Issue # 326 - Fixed unexpected NPE for Environment . getExternalStorageState ( ),656
library \ pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 6 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 6,656
library \ pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 6 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 8 . 6 """,656
library \ pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n sample \ pom . xml \n - < version > 1 . 8 . 6 - SNAPSHOT < / version > \n + < version > 1 . 8 . 6 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 6,656
library \ pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 7 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 7 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 8 . 6 < / version > \n + < version > 1 . 8 . 7 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ decode \ BaseImageDecoder . java \n - protected final int rotation ; \n - protected final boolean flipHorizontal ; \n + public final int rotation ; \n + public final boolean flipHorizontal ; \n - protected final ImageSize imageSize ; \n - protected final ExifInfo exif ; \n + public final ImageSize imageSize ; \n + public final ExifInfo exif ; \n,Fixed visibility of ImageFileInfo and ExifInfo class members .,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - HttpURLConnection conn = createConnection ( imageUri ) ; \n + HttpURLConnection conn = createConnection ( imageUri , extra ) ; \n - conn = createConnection ( conn . getHeaderField ( "" Location "" ) ) ; \n + conn = createConnection ( conn . getHeaderField ( "" Location "" ) , extra ) ; \n - * @ param url URL to connect to \n - * @ return { @ linkplain HttpURLConnection Connection } for incoming URL . Connection isn ' t established so it still \n - * configurable . \n + * @ param url URL to connect to \n + * @ param extra Auxiliary object which was passed to { @ link DisplayImageOptions . Builder # extraForDownloader ( Object ) \n + * DisplayImageOptions . extraForDownloader ( Object ) } ; can be null \n + * @ return { @ linkplain HttpURLConnection Connection } for incoming URL . Connection isn ' t established so it still configurable . \n - protected HttpURLConnection createConnection ( String url ) throws IOException { \n + protected HttpURLConnection createConnection ( String url , Object extra ) throws IOException { \n",Pass extra into protected createConnection ( . . . ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - \n - OutputStream os = new BufferedOutputStream ( new FileOutputStream ( targetFile ) , BUFFER _ SIZE ) ; \n - boolean compressedSuccessfully = false ; \n - try { \n - compressedSuccessfully = bmp . compress ( configuration . imageCompressFormatForDiscCache , configuration . imageQualityForDiscCache , os ) ; \n - } finally { \n - IoUtils . closeSilently ( os ) ; \n - } \n - if ( compressedSuccessfully ) { \n - bmp . recycle ( ) ; \n - return ; \n + if ( bmp ! = null ) { \n + OutputStream os = new BufferedOutputStream ( new FileOutputStream ( targetFile ) , BUFFER _ SIZE ) ; \n + boolean compressedSuccessfully = false ; \n + try { \n + compressedSuccessfully = bmp . compress ( configuration . imageCompressFormatForDiscCache , configuration . imageQualityForDiscCache , os ) ; \n + } finally { \n + IoUtils . closeSilently ( os ) ; \n + } \n + if ( compressedSuccessfully ) { \n + bmp . recycle ( ) ; \n + return ; \n + } \n",Try to cache image on disc first if it can ' t be decoded directly from \n network,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ UILApplication . java \n + import android . app . ActivityManager ; \n + int memoryCacheSize ; \n + if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . ECLAIR ) { \n + int memClass = ( ( ActivityManager ) context . getSystemService ( Context . ACTIVITY _ SERVICE ) ) . getMemoryClass ( ) ; \n + memoryCacheSize = ( memClass / 8 ) * 1024 * 1024 ; / / 1 / 8 of app memory limit \n + } else { \n + memoryCacheSize = 2 * 1024 * 1024 ; \n + } \n + \n - . memoryCacheSize ( 2 * 1024 * 1024 ) / / 2 Mb \n + . memoryCacheSize ( memoryCacheSize ) \n,Sample : Set memory cache size as 1 / 8 available app memory,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n + import java . util . Collections ; \n + import java . util . LinkedList ; \n + import java . util . List ; \n + \n + import android . graphics . Bitmap ; \n + import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . display . FadeInBitmapDisplayer ; \n + @ Override \n + public void onBackPressed ( ) { \n + AnimateFirstDisplayListener . displayedImages . clear ( ) ; \n + super . onBackPressed ( ) ; \n + } \n + \n - imageLoader . displayImage ( imageUrls [ position ] , holder . image , options ) ; \n + final String imageUri = imageUrls [ position ] ; \n + final ImageView imageView = holder . image ; \n + imageLoader . displayImage ( imageUri , imageView , options , new AnimateFirstDisplayListener ( imageUri , imageView ) ) ; \n + \n + private static class AnimateFirstDisplayListener extends SimpleImageLoadingListener { \n + \n + static final List < String > displayedImages = Collections . synchronizedList ( new LinkedList < String > ( ) ) ; \n + \n + private final String imageUri ; \n + private final ImageView imageView ; \n + \n + AnimateFirstDisplayListener ( String imageUri , ImageView imageView ) { \n + this . imageUri = imageUri ; \n + this . imageView = imageView ; \n + } \n + \n + @ Override \n + public void onLoadingComplete ( Bitmap loadedImage ) { \n + if ( loadedImage ! = null ) { \n + boolean firstDisplay = ! displayedImages . contains ( imageUri ) ; \n + if ( firstDisplay ) { \n + FadeInBitmapDisplayer . animate ( imageView , 500 ) ; \n + } else { \n + imageView . setImageBitmap ( loadedImage ) ; \n + } \n + displayedImages . add ( imageUri ) ; \n + } \n + } \n + } \n",Sample : Fade in images only on first display,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n - * will contain bitmap processed by incoming preProcessor . \n + * will contain bitmap processed by incoming preProcessor . < br / > \n + * Image will be pre - processed even if caching in memory is disabled . \n library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + if ( options . shouldPreProcess ( ) ) { \n + log ( LOG _ PREPROCESS _ IMAGE , memoryCacheKey ) ; \n + bmp = options . getPreProcessor ( ) . process ( bmp ) ; \n + } \n - if ( options . shouldPreProcess ( ) ) { \n - log ( LOG _ PREPROCESS _ IMAGE , memoryCacheKey ) ; \n - bmp = options . getPreProcessor ( ) . process ( bmp ) ; \n - } \n - \n",Pre - process images even if they won ' t be cached in memory,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n + private final int imageOnFail ; \n + imageOnFail = builder . imageOnFail ; \n + boolean shouldShowImageOnFail ( ) { \n + return imageOnFail ! = 0 ; \n + } \n + \n - Integer getStubImage ( ) { \n + int getStubImage ( ) { \n - Integer getImageForEmptyUri ( ) { \n + int getImageForEmptyUri ( ) { \n + int getImageOnFail ( ) { \n + return imageOnFail ; \n + } \n + \n + private int imageOnFail = 0 ; \n - * Image will be displayed in { @ link android . widget . ImageView ImageView } if empty URI ( null or empty string ) \n - * will be passed to < b > ImageLoader . displayImage ( . . . ) < / b > method . \n + * Incoming image will be displayed in { @ link android . widget . ImageView ImageView } if empty URI ( null or empty \n + * string ) will be passed to < b > ImageLoader . displayImage ( . . . ) < / b > method . \n + / * * \n + * Incoming image will be displayed in { @ link android . widget . ImageView ImageView } if some error occurs during \n + * requested image loading / decoding . \n + * \n + * @ param imageRes Image resource \n + * / \n + public Builder showImageOnFail ( int imageRes ) { \n + imageOnFail = imageRes ; \n + return this ; \n + } \n + \n library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + if ( options . shouldShowImageOnFail ( ) ) { \n + imageView . setImageResource ( options . getImageOnFail ( ) ) ; \n + } \n,Introduced DisplayImageOptions . showImageOnFail ( . . . ),656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGalleryActivity . java \n - . showImageForEmptyUri ( R . drawable . ic _ empty ) \n + . showImageForEmptyUri ( R . drawable . ic _ empty ) \n + . showImageOnFail ( R . drawable . ic _ error ) \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGridActivity . java \n + . showImageOnFail ( R . drawable . ic _ error ) \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n + . showImageOnFail ( R . drawable . ic _ error ) \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n + . showImageOnFail ( R . drawable . ic _ error ) \n - imageView . setImageResource ( R . drawable . ic _ error ) ; \n,Sample : Used DIO . showImageOnFail ( . . . ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n + import java . net . URL ; \n + private static final int MAX _ REDIRECT _ COUNT = 5 ; \n + \n + "" You should implement this support yourself ( BaseImageDownloader . getStreamFromOtherSource ( . . . ) ) "" ; \n - HttpURLConnection conn = ( HttpURLConnection ) imageUri . toURL ( ) . openConnection ( ) ; \n + HttpURLConnection conn = connectTo ( imageUri . toString ( ) ) ; \n + \n + int redirectCount = 0 ; \n + while ( conn . getResponseCode ( ) / 100 = = 3 & & redirectCount < MAX _ REDIRECT _ COUNT ) { \n + conn = connectTo ( conn . getHeaderField ( "" Location "" ) ) ; \n + redirectCount + + ; \n + } \n + \n + return new FlushedInputStream ( conn . getInputStream ( ) , BUFFER _ SIZE ) ; \n + } \n + \n + private HttpURLConnection connectTo ( String url ) throws IOException { \n + HttpURLConnection conn = ( HttpURLConnection ) new URL ( url ) . openConnection ( ) ; \n - return new FlushedInputStream ( conn . getInputStream ( ) , BUFFER _ SIZE ) ; \n + conn . connect ( ) ; \n + return conn ; \n",Handle redirects ( HTTP < - > HTTPS ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoadingInfo . java \n - import android . net . Uri ; \n - this . uri = Uri . encode ( uri , "" @ # & = * + - _ . , : ! ? ( ) / ~ ' % "" ) ; \n + this . uri = uri ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + import android . net . Uri ; \n + private static final String ALLOWED _ URI _ CHARS = "" @ # & = * + - _ . , : ! ? ( ) / ~ ' % "" ; \n + \n + final String encodedUri ; \n + encodedUri = Uri . encode ( uri , ALLOWED _ URI _ CHARS ) ; \n - imageUriForDecoding = new URI ( uri ) ; \n + imageUriForDecoding = new URI ( encodedUri ) ; \n - ImageDecoder decoder = new ImageDecoder ( new URI ( uri ) , getDownloader ( ) , options ) ; \n + ImageDecoder decoder = new ImageDecoder ( new URI ( encodedUri ) , getDownloader ( ) , options ) ; \n - InputStream is = getDownloader ( ) . getStream ( new URI ( uri ) , options . getExtraForDownloader ( ) ) ; \n + InputStream is = getDownloader ( ) . getStream ( new URI ( encodedUri ) , options . getExtraForDownloader ( ) ) ; \n","Fixed usage of encoded URI . Use original incoming URI for callbacks , \n disc cache ' s file name generator . ( Affects URIs with special / local \n UTF - 8 symbols )",656
library \ pom . xml \n - < version > 1 . 8 . 1 - SNAPSHOT < / version > \n + < version > 1 . 8 . 1 < / version > \n pom . xml \n - < version > 1 . 8 . 1 - SNAPSHOT < / version > \n + < version > 1 . 8 . 1 < / version > \n - < / scm > \n + < tag > v1 . 8 . 1 < / tag > \n + < / scm > \n sample \ pom . xml \n - < version > 1 . 8 . 1 - SNAPSHOT < / version > \n + < version > 1 . 8 . 1 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 1,656
library \ pom . xml \n - < version > 1 . 8 . 1 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 1 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 1 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 1 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGalleryActivity . java \n - . showStubImage ( R . drawable . ic _ stub ) \n + . showImageOnLoading ( R . drawable . ic _ stub ) \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGridActivity . java \n - . showStubImage ( R . drawable . ic _ stub ) \n + . showImageOnLoading ( R . drawable . ic _ stub ) \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n - . showStubImage ( R . drawable . ic _ stub ) \n + . showImageOnLoading ( R . drawable . ic _ stub ) \n,Sample : Not use deprecated DIO . showStubImage ( int ),656
library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + File cacheDir = targetFile . getParentFile ( ) ; \n + if ( ! cacheDir . exists ( ) ) { \n + cacheDir . mkdirs ( ) ; \n + } \n + \n,"Issue # 168 - Images aren ' t loaded after "" Clear Cache "" in app info",656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n - import android . graphics . drawable . BitmapDrawable ; \n - View rootView = ( View ) object ; \n - ImageView imageView = ( ImageView ) rootView . findViewById ( R . id . image ) ; \n - BitmapDrawable drawable = ( BitmapDrawable ) imageView . getDrawable ( ) ; \n - if ( drawable ! = null ) { \n - Bitmap bitmap = drawable . getBitmap ( ) ; \n - if ( bitmap ! = null ) { \n - bitmap . recycle ( ) ; \n - } \n - } \n - \n - ( ( ViewPager ) container ) . removeView ( rootView ) ; \n + ( ( ViewPager ) container ) . removeView ( ( View ) object ) ; \n + case NETWORK _ DENIED : \n + message = "" Downloads are denied "" ; \n + break ; \n + case UNSUPPORTED _ URI _ SCHEME : \n + message = "" Unsupported URI scheme "" ; \n + break ; \n",Sample : Consider new FailReasons . Not recycle bitmap in pager to prevent \n crashes .,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - int height = params . height ! = LayoutParams . WRAP _ CONTENT ? 0 : imageView . getHeight ( ) ; / / Get actual image height \n + int height = params . height = = LayoutParams . WRAP _ CONTENT ? 0 : imageView . getHeight ( ) ; / / Get actual image height \n,Issue # 200 - Possible bug in getImageSizeScaleTo ( ) - Fixed,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n - / * * Create { @ linkplain HashCodeFileNameGenerator default implementation } of FileNameGenerator * / \n + / * * Creates { @ linkplain HashCodeFileNameGenerator default implementation } of FileNameGenerator * / \n - / * * Create default implementation of { @ link DisckCacheAware } depends on incoming parameters * / \n + / * * Creates default implementation of { @ link DisckCacheAware } depends on incoming parameters * / \n - / * * Create default implementation of { @ link MemoryCacheAware } depends on incoming parameters * / \n + / * * Creates reserve disc cache which will be used if primary disc cache becomes unavailable * / \n + public static DiscCacheAware createReserveDiscCache ( Context context ) { \n + File cacheDir = context . getCacheDir ( ) ; \n + File individualDir = new File ( cacheDir , "" uil - images "" ) ; \n + if ( individualDir . exists ( ) | | individualDir . mkdir ( ) ) { \n + cacheDir = individualDir ; \n + } \n + return new TotalSizeLimitedDiscCache ( cacheDir , 2 * 1024 * 1024 ) ; / / limit - 2 Mb \n + } \n + \n + / * * Creates default implementation of { @ link MemoryCacheAware } depends on incoming parameters * / \n - / * * Create default implementation of { @ link ImageDownloader } - { @ link BaseImageDownloader } * / \n + / * * Creates default implementation of { @ link ImageDownloader } - { @ link BaseImageDownloader } * / \n - / * * Create default implementation of { @ link BitmapDisplayer } * / \n + / * * Creates default implementation of { @ link BitmapDisplayer } * / \n library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n + final DiscCacheAware reserveDiscCache ; \n + \n + reserveDiscCache = DefaultConfigurationFactory . createReserveDiscCache ( context ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + File cacheDir = imageFile . getParentFile ( ) ; \n + if ( cacheDir = = null | | ( ! cacheDir . exists ( ) & & ! cacheDir . mkdirs ( ) ) ) { \n + imageFile = configuration . reserveDiscCache . get ( uri ) ; \n + } \n - File cacheDir = targetFile . getParentFile ( ) ; \n - if ( cacheDir = = null | | ! cacheDir . exists ( ) ) { \n - cacheDir . mkdirs ( ) ; \n - } \n - \n",Issue # 170 - NPE after unmount SD card \n Cache images on device ' s file system if SD card becomes unmounted,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - void denyNetworkDownloads ( boolean denyNetworkDownloads ) { \n + public void denyNetworkDownloads ( boolean denyNetworkDownloads ) { \n - void handleSlowNetwork ( boolean handleSlowNetwork ) { \n + public void handleSlowNetwork ( boolean handleSlowNetwork ) { \n,Fixed visibility of methods ImageLoader . denyNetworkDownloads ( . . . ) and \n ImageLoader . handleSlowNetworks ( . . . ),656
"library \ AndroidManifest . xml \n - android : versionCode = "" 27 "" \n - android : versionName = "" 1 . 7 . 1 "" / > \n + android : versionCode = "" 28 "" \n + android : versionName = "" 1 . 8 . 0 "" / > \n sample \ AndroidManifest . xml \n - android : versionCode = "" 27 "" \n - android : versionName = "" 1 . 7 . 1 "" > \n + android : versionCode = "" 28 "" \n + android : versionName = "" 1 . 8 . 0 "" > \n - < receiver android : name = "" . widget . UILWidgetProvider "" > \n + < receiver android : name = "" . widget . UILWidgetProvider "" > \n",Prepared Manifests for release 1 . 8 . 0,656
library \ pom . xml \n - < version > 1 . 8 . 0 - SNAPSHOT < / version > \n + < version > 1 . 8 . 0 < / version > \n pom . xml \n - < version > 1 . 8 . 0 - SNAPSHOT < / version > \n + < version > 1 . 8 . 0 < / version > \n - < tag > v1 . 7 . 0 < / tag > \n + < tag > v1 . 8 . 0 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 0 - SNAPSHOT < / version > \n + < version > 1 . 8 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 0,656
library \ pom . xml \n - < version > 1 . 8 . 0 < / version > \n + < version > 1 . 8 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 0 < / version > \n + < version > 1 . 8 . 1 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 0 < / tag > \n + < tag > v1 . 7 . 0 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 0 < / version > \n + < version > 1 . 8 . 1 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n + import java . util . concurrent . ThreadFactory ; \n + import java . util . concurrent . atomic . AtomicInteger ; \n + \n + public static ThreadFactory createThreadFactory ( int threadPriority ) { \n + return new DefaultThreadFactory ( threadPriority ) ; \n + } \n + \n + private static class DefaultThreadFactory implements ThreadFactory { \n + \n + private static final AtomicInteger poolNumber = new AtomicInteger ( 1 ) ; \n + \n + private final ThreadGroup group ; \n + private final AtomicInteger threadNumber = new AtomicInteger ( 1 ) ; \n + private final String namePrefix ; \n + private final int threadPriority ; \n + \n + DefaultThreadFactory ( int threadPriority ) { \n + this . threadPriority = threadPriority ; \n + SecurityManager s = System . getSecurityManager ( ) ; \n + group = ( s ! = null ) ? s . getThreadGroup ( ) : Thread . currentThread ( ) . getThreadGroup ( ) ; \n + namePrefix = "" pool - "" + poolNumber . getAndIncrement ( ) + "" - thread - "" ; \n + } \n + \n + public Thread newThread ( Runnable r ) { \n + Thread t = new Thread ( group , r , namePrefix + threadNumber . getAndIncrement ( ) , 0 ) ; \n + if ( t . isDaemon ( ) ) t . setDaemon ( false ) ; \n + t . setPriority ( threadPriority ) ; \n + return t ; \n + } \n + } \n library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n - import java . util . concurrent . ThreadFactory ; \n - \n - import com . nostra13 . universalimageloader . core . download . NetworkDeniedImageDownloader ; \n + import com . nostra13 . universalimageloader . core . download . NetworkDeniedImageDownloader ; \n - final ThreadFactory displayImageThreadFactory ; \n + final int threadPriority ; \n - displayImageThreadFactory = new ThreadFactory ( ) { \n - @ Override \n - public Thread newThread ( Runnable r ) { \n - Thread t = new Thread ( r ) ; \n - t . setPriority ( builder . threadPriority ) ; \n - return t ; \n - } \n - } ; \n + threadPriority = builder . threadPriority ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderEngine . java \n - configuration . displayImageThreadFactory ) ; \n + DefaultConfigurationFactory . createThreadFactory ( configuration . threadPriority ) ) ; \n",Changed ThreadFactory for executors ( name threads ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n + import java . io . FileInputStream ; \n - return new BufferedInputStream ( imageUri . toURL ( ) . openStream ( ) , BUFFER _ SIZE ) ; \n + return new BufferedInputStream ( new FileInputStream ( imageUri . getRawPath ( ) ) , BUFFER _ SIZE ) ; \n",Issue # 179 - De / Encoding for File URI image load problem \n Handled local files with encoded symbols in file name,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ Constants . java \n - "" file : / / / sdcard / UniversalImageLoader . png "" , / / Image from SD card \n + "" file : / / / sdcard / UniversalImageLoader - http % 3A % 2F % 2Fd . png "" , / / Image from SD card with encoded symbols \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ HomeActivity . java \n - File testImageOnSdCard = new File ( "" / mnt / sdcard / UniversalImageLoader . png "" ) ; \n + File testImageOnSdCard = new File ( "" / mnt / sdcard / UniversalImageLoader - http % 3A % 2F % 2Fd . png "" ) ; \n",Sample : Use encoded symbols in local file name,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - private static final int MAX _ REDIRECT _ COUNT = 5 ; \n + protected static final int MAX _ REDIRECT _ COUNT = 5 ; \n + "" You should implement this support yourself ( BaseImageDownloader . getStreamFromOtherSource ( . . . ) ) "" ; \n - * URI . \n + * URL . \n - HttpURLConnection conn = connectTo ( imageUri ) ; \n + HttpURLConnection conn = createConnection ( imageUri ) ; \n - conn = connectTo ( conn . getHeaderField ( "" Location "" ) ) ; \n + conn = createConnection ( conn . getHeaderField ( "" Location "" ) ) ; \n - private HttpURLConnection connectTo ( String url ) throws IOException { \n + / * * \n + * Create { @ linkplain HttpURLConnection HTTP connection } for incoming URL \n + * \n + * @ param url URL to connect to \n + * @ return { @ linkplain HttpURLConnection Connection } for incoming URL . Connection isn ' t established so it still \n + * configurable . \n + * @ throws IOException if some I / O error occurs during network request or if no InputStream could be created for \n + * URL . \n + * / \n + protected HttpURLConnection createConnection ( String url ) throws IOException { \n - conn . connect ( ) ; \n",Allow override BaseImageDownloader . createConnection ( String ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n - namePrefix = "" pool - "" + poolNumber . getAndIncrement ( ) + "" - thread - "" ; \n + namePrefix = "" uil - pool - "" + poolNumber . getAndIncrement ( ) + "" - thread - "" ; \n + @ Override \n",Issue # 440 - Thread pool threads should use proper names,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ display \ RoundedBitmapDisplayer . java \n - import android . view . View ; \n + import com . nostra13 . universalimageloader . core . imageaware . ImageViewAware ; \n - * Displays bitmap with rounded corners . < br / > \n + * Displays bitmap with rounded corners . This implementation works only with ImageViews wrapped in ImageViewAware . < br / > \n - View imageView = imageAware . getWrappedView ( ) ; \n - if ( ! ( imageView instanceof ImageView ) ) { \n + if ( ! ( imageAware instanceof ImageViewAware ) ) { \n - Bitmap roundedBitmap = roundCorners ( bitmap , ( ImageView ) imageView , roundPixels ) ; \n + Bitmap roundedBitmap = roundCorners ( bitmap , ( ImageViewAware ) imageAware , roundPixels ) ; \n - * Process incoming { @ linkplain Bitmap } to make rounded corners according to target { @ link ImageView } . < br / > \n + * Process incoming { @ linkplain Bitmap } to make rounded corners according to target \n + * { @ link com . nostra13 . universalimageloader . core . imageaware . ImageViewAware } . < br / > \n - * @ param imageView Target { @ link ImageView } to display bitmap in \n + * @ param imageAware Target { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware ImageAware } to \n + * display bitmap in \n - public static Bitmap roundCorners ( Bitmap bitmap , ImageView imageView , int roundPixels ) { \n + public static Bitmap roundCorners ( Bitmap bitmap , ImageViewAware imageAware , int roundPixels ) { \n + ImageView imageView = imageAware . getWrappedView ( ) ; \n - L . w ( "" View is collected probably . Can ' t round bitmap corners without view parameters . "" ) ; \n + L . w ( "" View is collected probably . Can ' t round bitmap corners without view properties . "" ) ; \n - int vw = imageView . getWidth ( ) ; \n - int vh = imageView . getHeight ( ) ; \n + int vw = imageAware . getWidth ( ) ; \n + int vh = imageAware . getHeight ( ) ; \n","Issue # 393 - Fixed RoundedBitmapDisplayer for the case when view isn ' t drawn yet and size is unknown . Use ImageViewAware instead of ImageView . \n Changed API : RoundedBitmapDisplayer . roundCorners ( Bitmap , ImageView , int ) - > . roundCorners ( Bitmap , ImageViewAware , int )",656
"library \ AndroidManifest . xml \n - android : versionName = "" 1 . 8 . 7 "" > \n + android : versionName = "" 1 . 9 . 0 "" > \n library \ pom . xml \n - < version > 1 . 8 . 7 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 7 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 - SNAPSHOT < / version > \n sample \ AndroidManifest . xml \n - android : versionName = "" 1 . 8 . 7 "" > \n + android : versionName = "" 1 . 9 . 0 "" > \n sample \ pom . xml \n - < version > 1 . 8 . 7 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 - SNAPSHOT < / version > \n",Maven : Changed next version 1 . 8 . 7 - > 1 . 9 . 0,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n + import android . os . Looper ; \n - return isSyncLoading ? null : ( handler = = null ? new Handler ( ) : handler ) ; \n + if ( isSyncLoading ) { \n + return null ; \n + } else { \n + if ( handler = = null ) { \n + if ( Looper . myLooper ( ) ! = Looper . getMainLooper ( ) ) { \n + throw new IllegalStateException ( "" ImageLoader . displayImage ( . . . ) must be invoked from the main thread or from Looper thread "" ) ; \n + } \n + return new Handler ( ) ; \n + } else { \n + return handler ; \n + } \n + } \n",Check if ImageLoader . displayImage ( . . . ) isa called on main thread,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - * { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware } \n + * { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware ImageAware } \n + / * * \n + * Returns URI of image which is loading at this moment into passed \n + * { @ link android . widget . ImageView ImageView } \n + * / \n + public String getLoadingUriForView ( ImageView imageView ) { \n + return engine . getLoadingUriForView ( new ImageViewAware ( imageView ) ) ; \n + } \n + \n - * { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware } . \n + * { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware ImageAware } . \n - * @ param imageAware { @ link ImageView } for which display task will be cancelled \n + * @ param imageAware { @ link com . nostra13 . universalimageloader . core . imageaware . ImageAware ImageAware } for \n + * which display task will be cancelled \n + / * * \n + * Cancel the task of loading and displaying image for passed \n + * { @ link android . widget . ImageView ImageView } . \n + * \n + * @ param imageView { @ link android . widget . ImageView ImageView } for which display task will be cancelled \n + * / \n + public void cancelDisplayTask ( ImageView imageView ) { \n + engine . cancelDisplayTaskFor ( new ImageViewAware ( imageView ) ) ; \n + } \n + \n,Returned ImageLoader . getLoadingUriForView ( ImageView ) and . cancelDisplayTask ( ImageView ),656
library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + if ( targetFile . exists ( ) ) { \n + targetFile . delete ( ) ; \n + } \n,Issue # 379 - Delete corrupted cache files ( if loading failed ),656
"library \ src \ com \ nostra13 \ universalimageloader \ utils \ StorageUtils . java \n - * @ return Cache { @ link File directory } \n + * @ return Cache { @ link File directory } . < br / > \n + * < b > NOTE : < / b > Can be null in some unpredictable cases ( if SD card is unmounted and \n + * { @ link android . content . Context # getCacheDir ( ) Context . getCacheDir ( ) } returns null ) . \n - L . w ( "" Can ' t define system cache directory ! The app should be restarted . "" ) ; \n + String cacheDirPath = "" / data / data / "" + context . getPackageName ( ) + "" / cache / "" ; \n + L . w ( "" Can ' t define system cache directory ! ' % s ' will be used . "" , cacheDirPath ) ; \n + appCacheDir = new File ( cacheDirPath ) ; \n",Issue # 392 - Hardcode cache dir path if Context . getCacheDir ( ) return null,656
pom . xml \n - < version > 3 . 6 . 0 < / version > \n + < version > 3 . 8 . 0 < / version > \n,Maven : use android - maven - plugin 3 . 8 . 0,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n + import com . nostra13 . universalimageloader . utils . StorageUtils ; \n + import java . io . File ; \n - reserveDiscCache = DefaultConfigurationFactory . createReserveDiscCache ( builder . context . getCacheDir ( ) ) ; \n + File reserveCacheDir = StorageUtils . getCacheDirectory ( builder . context , false ) ; \n + reserveDiscCache = DefaultConfigurationFactory . createReserveDiscCache ( reserveCacheDir ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ utils \ StorageUtils . java \n + return getCacheDirectory ( context , true ) ; \n + } \n + \n + / * * \n + * Returns application cache directory . Cache directory will be created on SD card \n + * < i > ( "" / Android / data / [ app _ package _ name ] / cache "" ) < / i > ( if card is mounted and app has appropriate permission ) or \n + * on device ' s file system depending incoming parameters . \n + * \n + * @ param context Application context \n + * @ param preferExternal Whether prefer external location for cache \n + * @ return Cache { @ link File directory } . < br / > \n + * < b > NOTE : < / b > Can be null in some unpredictable cases ( if SD card is unmounted and \n + * { @ link android . content . Context # getCacheDir ( ) Context . getCacheDir ( ) } returns null ) . \n + * / \n + public static File getCacheDirectory ( Context context , boolean preferExternal ) { \n - if ( MEDIA _ MOUNTED . equals ( Environment . getExternalStorageState ( ) ) & & hasExternalStoragePermission ( context ) ) { \n + if ( preferExternal & & MEDIA _ MOUNTED \n + . equals ( Environment . getExternalStorageState ( ) ) & & hasExternalStoragePermission ( context ) ) { \n",Prevent NPE of Context . getCacheDir ( ) for reserve disc cache,656
library \ pom . xml \n - < version > 1 . 9 . 0 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 < / version > \n pom . xml \n - < version > 1 . 9 . 0 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 9 . 0 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 0 - SNAPSHOT < / version > \n + < version > 1 . 9 . 0 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 0,656
library \ pom . xml \n - < version > 1 . 9 . 0 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 0 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n - < tag > v1 . 9 . 0 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 0 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n - } else { \n - imageView . setImageBitmap ( loadedImage ) ; \n,Sample : Fixed bug of disappeared rounded angles after first display,656
"rename from sample \ assets \ LivingThings . jpg \n rename to sample \ assets \ Living Things @ # & = + - _ . , ! ( ) ~ ' % 20 . jpg \n rename from sample \ assets \ UniversalImageLoader . png \n rename to sample \ assets \ Universal Image Loader @ # & = + - _ . , ! ( ) ~ ' % 20 . png \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ Constants . java \n - "" file : / / / sdcard / UniversalImageLoader - http % 3A % 2F % 2Fd . png "" , / / Image from SD card with encoded symbols \n - "" assets : / / LivingThings . jpg "" , / / Image from assets \n + "" file : / / / sdcard / Universal Image Loader @ # & = + - _ . , ! ( ) ~ ' % 20 . png "" , / / Image from SD card with encoded symbols \n + "" assets : / / Living Things @ # & = + - _ . , ! ( ) ~ ' % 20 . jpg "" , / / Image from assets \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ HomeActivity . java \n + \n + private static final String TEST _ FILE _ NAME = "" Universal Image Loader @ # & = + - _ . , ! ( ) ~ ' % 20 . png "" ; \n + \n - File testImageOnSdCard = new File ( "" / mnt / sdcard / UniversalImageLoader - http % 3A % 2F % 2Fd . png "" ) ; \n + File testImageOnSdCard = new File ( "" / mnt / sdcard "" , TEST _ FILE _ NAME ) ; \n - \n + \n - InputStream is = getAssets ( ) . open ( "" UniversalImageLoader . png "" ) ; \n + InputStream is = getAssets ( ) . open ( TEST _ FILE _ NAME ) ; \n","Sample : Use spaces , special chars and encoded chars in file names",656
library \ pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 2 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 2,656
library \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 2 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
library \ pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 2 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 3 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n,"Revert "" [ maven - release - plugin ] prepare for next development iteration "" \n This reverts commit 29f47dd81f3077c0b7142c1df8cba9ae246cfcd1 .",656
library \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 2 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 2 - SNAPSHOT < / version > \n,"Revert "" [ maven - release - plugin ] prepare release v1 . 8 . 2 "" \n This reverts commit 5009e0b3565220aed813f167c84df114acf010bc .",656
library \ pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 8 . 2 < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 2 - SNAPSHOT < / version > \n + < version > 1 . 8 . 2 < / version > \n,[ maven - release - plugin ] prepare release v1 . 8 . 2,656
library \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n - < tag > v1 . 8 . 2 < / tag > \n + < tag > HEAD < / tag > \n sample \ pom . xml \n - < version > 1 . 8 . 2 < / version > \n + < version > 1 . 8 . 3 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - ImageNonViewAware imageAware = new ImageNonViewAware ( targetImageSize , ViewScaleType . CROP ) ; \n + ImageNonViewAware imageAware = new ImageNonViewAware ( uri , targetImageSize , ViewScaleType . CROP ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ imageaware \ ImageNonViewAware . java \n + import android . text . TextUtils ; \n + protected final String imageUri ; \n + this ( null , imageSize , scaleType ) ; \n + } \n + \n + public ImageNonViewAware ( String imageUri , ImageSize imageSize , ViewScaleType scaleType ) { \n + this . imageUri = imageUri ; \n - return super . hashCode ( ) ; \n + return TextUtils . isEmpty ( imageUri ) ? super . hashCode ( ) : imageUri . hashCode ( ) ; \n","Issue # 475 - Cancel non - actual "" loadImage ( . . . ) "" tasks for same URIs .",656
"new file \n sample \ build . gradle \n + buildscript { \n + repositories { \n + mavenCentral ( ) \n + } \n + \n + dependencies { \n + classpath ' com . android . tools . build : gradle : 0 . 6 . + ' \n + } \n + } \n + \n + \n + apply plugin : ' android ' \n + \n + repositories { \n + mavenCentral ( ) \n + } \n + \n + dependencies { \n + compile fileTree ( dir : ' libs ' , include : ' * . jar ' ) \n + } \n + \n + android { \n + compileSdkVersion 16 \n + buildToolsVersion "" 18 . 1 "" \n + \n + sourceSets { \n + main { \n + manifest . srcFile ' AndroidManifest . xml ' \n + java . srcDirs = [ ' src ' ] \n + res . srcDirs = [ ' res ' ] \n + } \n + } \n + } \n new file \n sample \ libs \ universal - image - loader - 1 . 9 . 1 - SNAPSHOT - with - sources . jar \n Binary files / dev / null and b / sample / libs / universal - image - loader - 1 . 9 . 1 - SNAPSHOT - with - sources . jar differ \n new file \n sample \ res \ values - v11 \ styles . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + \n + < style name = "" ProgressBarStyle "" parent = "" @ android : style / Widget . Holo . ProgressBar . Horizontal "" / > \n + \n + < / resources > \n new file \n sample \ res \ values \ styles . xml \n + < ? xml version = "" 1 . 0 "" encoding = "" utf - 8 "" ? > \n + < resources > \n + \n + < style name = "" ProgressBarStyle "" parent = "" @ android : style / Widget . ProgressBar . Horizontal "" / > \n + \n + < / resources > \n",Merge master - > new _ disc _ cache _ api,656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ impl \ UnlimitedDiscCache . java \n - \n - @ Override \n - public void put ( String key , File file ) { \n - / / Do nothing \n - } \n library \ src \ com \ nostra13 \ universalimageloader \ core \ assist \ DiscCacheUtil . java \n - return image . exists ( ) ? image : null ; \n + return image ! = null & & image . exists ( ) ? image : null ; \n - return image . delete ( ) ; \n + return image ! = null & & image . exists ( ) & & image . delete ( ) ; \n",Merge branch ' master ' into new _ disk _ cache _ api,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ decode \ BaseImageDecoder . java \n - * @ param loggingEnabled Whether debug logs will be written to LogCat . \n - * Usually should match { @ link com . nostra13 . universalimageloader . core . ImageLoaderConfiguration . Builder # writeDebugLogs ( ) ImageLoaderConfiguration . writeDebugLogs ( ) } \n + * @ param loggingEnabled Whether debug logs will be written to LogCat . Usually should match { @ link \n + * com . nostra13 . universalimageloader . core . ImageLoaderConfiguration . Builder # writeDebugLogs ( ) \n + * ImageLoaderConfiguration . writeDebugLogs ( ) } \n + Bitmap decodedBitmap ; \n + ImageFileInfo imageInfo ; \n + \n - ImageFileInfo imageInfo = defineImageSizeAndRotation ( imageStream , decodingInfo ) ; \n - Options decodingOptions = prepareDecodingOptions ( imageInfo . imageSize , decodingInfo ) ; \n - imageStream = resetStream ( imageStream , decodingInfo ) ; \n - Bitmap decodedBitmap = decodeStream ( imageStream , decodingOptions ) ; \n + try { \n + imageInfo = defineImageSizeAndRotation ( imageStream , decodingInfo ) ; \n + imageStream = resetStream ( imageStream , decodingInfo ) ; \n + Options decodingOptions = prepareDecodingOptions ( imageInfo . imageSize , decodingInfo ) ; \n + decodedBitmap = BitmapFactory . decodeStream ( imageStream , null , decodingOptions ) ; \n + } finally { \n + IoUtils . closeSilently ( imageStream ) ; \n + } \n + \n - decodedBitmap = considerExactScaleAndOrientaiton ( decodedBitmap , decodingInfo , imageInfo . exif . rotation , imageInfo . exif . flipHorizontal ) ; \n + decodedBitmap = considerExactScaleAndOrientaiton ( decodedBitmap , decodingInfo , imageInfo . exif . rotation , \n + imageInfo . exif . flipHorizontal ) ; \n + IoUtils . closeSilently ( imageStream ) ; \n - protected Bitmap decodeStream ( InputStream imageStream , Options decodingOptions ) throws IOException { \n - try { \n - return BitmapFactory . decodeStream ( imageStream , null , decodingOptions ) ; \n - } finally { \n - IoUtils . closeSilently ( imageStream ) ; \n - } \n - } \n - \n - int rotation , boolean flipHorizontal ) { \n + int rotation , boolean flipHorizontal ) { \n",Issue # 482 - Close streams for sure,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n - import android . os . Build ; \n - import com . nostra13 . universalimageloader . cache . memory . impl . LRULimitedMemoryCache ; \n - import java . util . concurrent . * ; \n + import java . util . concurrent . BlockingQueue ; \n + import java . util . concurrent . Executor ; \n + import java . util . concurrent . LinkedBlockingQueue ; \n + import java . util . concurrent . ThreadFactory ; \n + import java . util . concurrent . ThreadPoolExecutor ; \n + import java . util . concurrent . TimeUnit ; \n - * Creates default implementation of { @ link MemoryCacheAware } depends on incoming parameters : < br / > \n - * { @ link LruMemoryCache } ( for API > = 9 ) or { @ link LRULimitedMemoryCache } ( for API < 9 ) . < br / > \n + * Creates default implementation of { @ link MemoryCacheAware } - { @ link LruMemoryCache } < br / > \n - MemoryCacheAware < String , Bitmap > memoryCache ; \n - if ( Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . GINGERBREAD ) { \n - memoryCache = new LruMemoryCache ( memoryCacheSize ) ; \n - } else { \n - memoryCache = new LRULimitedMemoryCache ( memoryCacheSize ) ; \n - } \n - return memoryCache ; \n + return new LruMemoryCache ( memoryCacheSize ) ; \n",Issue # 81 - Stop using memory cache with weak references by default for Android < 2 . 3 . Always use LryMemoryCache on strong references .,656
library \ pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n - < tag > HEAD < / tag > \n + < tag > v1 . 9 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 1,656
library \ pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 1 - SNAPSHOT < / version > \n,Revert [ maven - release - plugin ] prepare release v1 . 9 . 1,656
library \ pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n sample \ pom . xml \n - < version > 1 . 9 . 1 - SNAPSHOT < / version > \n + < version > 1 . 9 . 1 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 1,656
library \ pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 2 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 2 - SNAPSHOT < / version > \n sample \ pom . xml \n - < version > 1 . 9 . 1 < / version > \n + < version > 1 . 9 . 2 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - \n - import java . io . * ; \n + import com . nostra13 . universalimageloader . utils . IoUtils ; \n + \n + import java . io . BufferedInputStream ; \n + import java . io . ByteArrayInputStream ; \n + import java . io . ByteArrayOutputStream ; \n + import java . io . File ; \n + import java . io . FileInputStream ; \n + import java . io . FileNotFoundException ; \n + import java . io . IOException ; \n + import java . io . InputStream ; \n - return new ContentLengthInputStream ( new BufferedInputStream ( conn . getInputStream ( ) , BUFFER _ SIZE ) , \n - conn . getContentLength ( ) ) ; \n + InputStream imageStream ; \n + try { \n + imageStream = conn . getInputStream ( ) ; \n + } catch ( IOException e ) { \n + / / Read all data to allow reuse connection ( http : / / bit . ly / 1ad35PY ) \n + IoUtils . readAndCloseStream ( conn . getErrorStream ( ) ) ; \n + throw e ; \n + } \n + return new ContentLengthInputStream ( new BufferedInputStream ( imageStream , BUFFER _ SIZE ) , conn . getContentLength ( ) ) ; \n - new File ( filePath ) . length ( ) ) ; \n + new File ( filePath ) . length ( ) ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ utils \ IoUtils . java \n + / * * \n + * Reads all data from stream and close it silently \n + * \n + * @ param is Input stream \n + * / \n + public static void readAndCloseStream ( InputStream is ) { \n + final byte [ ] bytes = new byte [ DEFAULT _ BUFFER _ SIZE ] ; \n + try { \n + while ( is . read ( bytes , 0 , DEFAULT _ BUFFER _ SIZE ) ! = - 1 ) { \n + } \n + } catch ( IOException e ) { \n + / / Do nothing \n + } finally { \n + closeSilently ( is ) ; \n + } \n + } \n + \n",Issue # 418 - TCP Resets when error codes are returned with data Read all data to free connection for reusing,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - \n - import java . io . * ; \n + import com . nostra13 . universalimageloader . utils . IoUtils ; \n + \n + import java . io . BufferedInputStream ; \n + import java . io . ByteArrayInputStream ; \n + import java . io . ByteArrayOutputStream ; \n + import java . io . File ; \n + import java . io . FileInputStream ; \n + import java . io . FileNotFoundException ; \n + import java . io . IOException ; \n + import java . io . InputStream ; \n - return new ContentLengthInputStream ( new BufferedInputStream ( conn . getInputStream ( ) , BUFFER _ SIZE ) , \n - conn . getContentLength ( ) ) ; \n + InputStream imageStream ; \n + try { \n + imageStream = conn . getInputStream ( ) ; \n + } catch ( IOException e ) { \n + / / Read all data to allow reuse connection ( http : / / bit . ly / 1ad35PY ) \n + IoUtils . readAndCloseStream ( conn . getErrorStream ( ) ) ; / / read all data to close \n + throw e ; \n + } \n + return new ContentLengthInputStream ( new BufferedInputStream ( imageStream , BUFFER _ SIZE ) , conn . getContentLength ( ) ) ; \n - new File ( filePath ) . length ( ) ) ; \n + new File ( filePath ) . length ( ) ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ utils \ IoUtils . java \n + / * * \n + * Reads all data from stream and close it silently \n + * \n + * @ param is Input stream \n + * / \n + public static void readAndCloseStream ( InputStream is ) { \n + final byte [ ] bytes = new byte [ DEFAULT _ BUFFER _ SIZE ] ; \n + try { \n + while ( is . read ( bytes , 0 , DEFAULT _ BUFFER _ SIZE ) ! = - 1 ) { \n + } \n + } catch ( IOException e ) { \n + / / Do nothing \n + } finally { \n + closeSilently ( is ) ; \n + } \n + } \n + \n",Issue # 418 - TCP Resets when error codes are returned with data \n Read all data to free connection for reusing,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ AbsListViewBaseActivity . java \n - import com . nostra13 . universalimageloader . core . assist . PauseOnScrollListener ; \n + import com . nostra13 . universalimageloader . core . listener . PauseOnScrollListener ; \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGridActivity . java \n - import com . nostra13 . universalimageloader . core . assist . ImageLoadingProgressListener ; \n - import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . listener . ImageLoadingProgressListener ; \n + import com . nostra13 . universalimageloader . core . listener . SimpleImageLoadingListener ; \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n - import com . nostra13 . universalimageloader . core . assist . ImageLoadingListener ; \n - import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . listener . ImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . listener . SimpleImageLoadingListener ; \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImagePagerActivity . java \n - import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . listener . SimpleImageLoadingListener ; \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ widget \ UILWidgetProvider . java \n - import com . nostra13 . universalimageloader . core . assist . SimpleImageLoadingListener ; \n + import com . nostra13 . universalimageloader . core . listener . SimpleImageLoadingListener ; \n,Sample : Fixed imports for new package structure,656
rename from sample \ libs \ universal - image - loader - 1 . 9 . 2 - SNAPSHOT - with - sources . jar \n rename to sample \ libs \ universal - image - loader - 1 . 9 . 2 - with - sources . jar \n Binary files a / sample / libs / universal - image - loader - 1 . 9 . 2 - SNAPSHOT - with - sources . jar and b / sample / libs / universal - image - loader - 1 . 9 . 2 - with - sources . jar differ \n,Sample : Use 1 . 9 . 2 jar,656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ assist \ ImageScaleType . java \n + / * * \n + * Image will be scaled down only if image size is greater than \n + * { @ linkplain javax . microedition . khronos . opengles . GL10 # GL _ MAX _ TEXTURE _ SIZE maximum acceptable texture size } . \n + * Usually it ' s 2048x2048 . < br / > \n + * If Bitmap is expected to display than it must not exceed this size ( otherwise you ' ll get the exception \n + * "" OpenGLRenderer : Bitmap too large to be uploaded into a texture "" . < br / > \n + * Image will be subsampled in an integer number of times ( 1 , 2 , 3 , . . . ) to maximum texture size of device . \n + * / \n + NONE _ SAFE , \n - \n library \ src \ com \ nostra13 \ universalimageloader \ core \ decode \ BaseImageDecoder . java \n + scale = 1 ; \n + } else if ( scaleType = = ImageScaleType . NONE _ SAFE ) { \n",Changed ImageScaleType . NONE to not scale down images anyway . \n Introduced ImageScaleType . NONE _ SAFE to consider max texture size .,656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ impl \ LruDiscCache . java \n - private static final String ERROR _ ARG _ NULL = "" \ "" % s \ "" argument must be not null "" ; \n + private static final String ERROR _ ARG _ NULL = "" argument must be not null "" ; \n - this . cache = DiskLruCache . open ( cacheDir , 1 , 1 , cacheMaxSize ) ; \n + cache = DiskLruCache . open ( cacheDir , 1 , 1 , cacheMaxSize ) ; \n - boolean copied = IoUtils . copyStream ( imageStream , os , listener , bufferSize ) ; \n + boolean copied ; \n + try { \n + copied = IoUtils . copyStream ( imageStream , os , listener , bufferSize ) ; \n + } finally { \n + IoUtils . closeSilently ( os ) ; \n + } \n + cache = DiskLruCache . open ( cache . getDirectory ( ) , 1 , 1 , cache . getMaxSize ( ) ) ; \n","Fixed LruDiscCache : close steam , recreate cache after delete ( ) .",656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n + private final boolean syncLoading ; \n + syncLoading = options . isSyncLoading ( ) ; \n - runTask ( displayBitmapTask , options . isSyncLoading ( ) , handler , engine ) ; \n + runTask ( displayBitmapTask , syncLoading , handler , engine ) ; \n - return progressListener = = null | | fireProgressEvent ( current , total ) ; \n + return fireProgressEvent ( current , total ) ; \n - if ( options . isSyncLoading ( ) | | isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return false ; \n - Runnable r = new Runnable ( ) { \n - @ Override \n - public void run ( ) { \n - progressListener . onProgressUpdate ( uri , imageAware . getWrappedView ( ) , current , total ) ; \n - } \n - } ; \n - runTask ( r , false , handler , engine ) ; \n + if ( syncLoading | | isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return false ; \n + if ( progressListener ! = null ) { \n + Runnable r = new Runnable ( ) { \n + @ Override \n + public void run ( ) { \n + progressListener . onProgressUpdate ( uri , imageAware . getWrappedView ( ) , current , total ) ; \n + } \n + } ; \n + runTask ( r , false , handler , engine ) ; \n + } \n - if ( options . isSyncLoading ( ) | | isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return ; \n + if ( syncLoading | | isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return ; \n - if ( options . isSyncLoading ( ) | | isTaskInterrupted ( ) ) return ; \n + if ( syncLoading | | isTaskInterrupted ( ) ) return ; \n",Always interrupt not actual downloads ( even without progressListener ),656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DisplayBitmapTask . java \n - listener . onLoadingComplete ( imageUri , imageAware . getWrappedView ( ) , bitmap ) ; \n + listener . onLoadingComplete ( imageUri , imageAware . getWrappedView ( ) , bitmap ) ; \n","Mark task "" processed "" before firing success callback ( previous logic : fire success callback before mark task "" processed "" )",656
library \ pom . xml \n - < version > 1 . 9 . 2 - SNAPSHOT < / version > \n + < version > 1 . 9 . 2 < / version > \n pom . xml \n - < version > 1 . 9 . 2 - SNAPSHOT < / version > \n + < version > 1 . 9 . 2 < / version > \n - < tag > v1 . 9 . 1 < / tag > \n + < tag > v1 . 9 . 2 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 2 - SNAPSHOT < / version > \n + < version > 1 . 9 . 2 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 2,656
library \ pom . xml \n - < version > 1 . 9 . 2 < / version > \n + < version > 1 . 9 . 3 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 2 < / version > \n + < version > 1 . 9 . 3 - SNAPSHOT < / version > \n - < tag > v1 . 9 . 2 < / tag > \n + < tag > v1 . 9 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 2 < / version > \n + < version > 1 . 9 . 3 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageGridActivity . java \n + static class ViewHolder { \n + ImageView imageView ; \n + ProgressBar progressBar ; \n + } \n + \n - \n - class ViewHolder { \n - ImageView imageView ; \n - ProgressBar progressBar ; \n - } \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ ImageListActivity . java \n + private static class ViewHolder { \n + TextView text ; \n + ImageView image ; \n + } \n + \n - private class ViewHolder { \n - public TextView text ; \n - public ImageView image ; \n - } \n - \n,Sample : static ViewHolders ( thanks to @ jaydeepw ),656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ impl \ ext \ LruDiscCache . java \n + if ( cache = = null ) { \n + throw new RuntimeException ( "" Can ' t initialize disk cache "" , e ) ; \n + } \n library \ src \ com \ nostra13 \ universalimageloader \ core \ display \ BitmapDisplayer . java \n - * ImageAware } \n",Throw exception if LruDiskCache can ' t be initialized,656
library \ src \ com \ nostra13 \ universalimageloader \ utils \ IoUtils . java \n + public static final int DEFAULT _ IMAGE _ TOTAL _ SIZE = 500 * 1024 ; / / 500 Kb \n + / * * { @ value } * / \n - final int total = is . available ( ) ; \n + int total = is . available ( ) ; \n + if ( total < = 0 ) { \n + total = DEFAULT _ IMAGE _ TOTAL _ SIZE ; \n + } \n,"Image copying : check if total = = 0 , use default total size",656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - return fireProgressEvent ( current , total ) ; \n + return syncLoading | | fireProgressEvent ( current , total ) ; \n - if ( syncLoading | | isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return false ; \n + if ( isTaskInterrupted ( ) | | isTaskNotActual ( ) ) return false ; \n",Issue # 636 - Fixed loadImageSync ( . . . ) ( caching on disk didn ' t work ),656
library \ pom . xml \n - < version > 1 . 9 . 3 - SNAPSHOT < / version > \n + < version > 1 . 9 . 3 < / version > \n pom . xml \n - < version > 1 . 9 . 3 - SNAPSHOT < / version > \n + < version > 1 . 9 . 3 < / version > \n - < tag > v1 . 9 . 1 < / tag > \n + < tag > v1 . 9 . 3 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 3 - SNAPSHOT < / version > \n + < version > 1 . 9 . 3 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 3,656
library \ pom . xml \n - < version > 1 . 9 . 3 < / version > \n + < version > 1 . 9 . 4 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 3 < / version > \n + < version > 1 . 9 . 4 - SNAPSHOT < / version > \n - < tag > v1 . 9 . 3 < / tag > \n + < tag > v1 . 9 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 3 < / version > \n + < version > 1 . 9 . 4 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n - SecurityManager s = System . getSecurityManager ( ) ; \n - group = ( s ! = null ) ? s . getThreadGroup ( ) : Thread . currentThread ( ) . getThreadGroup ( ) ; \n + group = Thread . currentThread ( ) . getThreadGroup ( ) ; \n,System . getSecurityManager ( ) is always null \n Issue # 683 : Fixed,656
library \ src \ com \ nostra13 \ universalimageloader \ utils \ IoUtils . java \n + os . flush ( ) ; \n,Issue # 602 : Prevent IOException suppressing at the end of file copying,656
"library \ src \ com \ nostra13 \ universalimageloader \ utils \ StorageUtils . java \n - if ( preferExternal & & MEDIA _ MOUNTED \n - . equals ( Environment . getExternalStorageState ( ) ) & & hasExternalStoragePermission ( context ) ) { \n + String externalStorageState ; \n + try { \n + externalStorageState = Environment . getExternalStorageState ( ) ; \n + } catch ( NullPointerException e ) { / / ( sh ) it happens ( Issue # 660 ) \n + externalStorageState = "" "" ; \n + } \n + if ( preferExternal & & MEDIA _ MOUNTED . equals ( externalStorageState ) & & hasExternalStoragePermission ( context ) ) { \n",Issue # 660 - Catch Android NPE in Environment . getExternalStorageState ( ),656
"library \ src \ com \ nostra13 \ universalimageloader \ utils \ ImageSizeUtils . java \n + scale = considerMaxTextureSize ( srcWidth , srcHeight , scale , powerOf2Scale ) ; \n + private static int considerMaxTextureSize ( int srcWidth , int srcHeight , int scale , boolean powerOf2 ) { \n + final int maxWidth = maxBitmapSize . getWidth ( ) ; \n + final int maxHeight = maxBitmapSize . getHeight ( ) ; \n + while ( ( srcWidth / scale ) > maxWidth | | ( srcHeight / scale ) > maxHeight ) { \n + if ( powerOf2 ) { \n + scale * = 2 ; \n + } else { \n + scale + + ; \n + } \n + } \n + return scale ; \n + } \n + \n","Issue # 508 - Fixed "" Bitmap too large . . . "" for all ImageScaleTypes",656
"library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ DiscCacheAware . java \n + * Incoming image stream shouldn ' t be closed in this method . \n - * @ param imageStream Input stream of image \n + * @ param imageStream Input stream of image ( shouldn ' t be closed in this method ) \n library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ impl \ BaseDiscCache . java \n - IoUtils . closeSilently ( imageStream ) ; \n library \ src \ com \ nostra13 \ universalimageloader \ core \ LoadAndDisplayImageTask . java \n - return configuration . diskCache . save ( uri , is , this ) ; \n + try { \n + return configuration . diskCache . save ( uri , is , this ) ; \n + } finally { \n + IoUtils . closeSilently ( is ) ; \n + } \n","Close image stream outside of DiskCache , save ( . . . )",656
"library \ src \ com \ nostra13 \ universalimageloader \ core \ DefaultConfigurationFactory . java \n + import android . annotation . TargetApi ; \n + import android . app . ActivityManager ; \n + import android . content . pm . ApplicationInfo ; \n + import android . os . Build ; \n - public static MemoryCache createMemoryCache ( int memoryCacheSize ) { \n + public static MemoryCache createMemoryCache ( Context context , int memoryCacheSize ) { \n - memoryCacheSize = ( int ) ( Runtime . getRuntime ( ) . maxMemory ( ) / 8 ) ; \n + ActivityManager am = ( ActivityManager ) context . getSystemService ( Context . ACTIVITY _ SERVICE ) ; \n + int memoryClass = am . getMemoryClass ( ) ; \n + if ( hasHoneycomb ( ) & & isLargeHeap ( context ) ) { \n + memoryClass = getLargeMemoryClass ( am ) ; \n + } \n + memoryCacheSize = 1024 * 1024 * memoryClass / 8 ; \n + private static boolean hasHoneycomb ( ) { \n + return Build . VERSION . SDK _ INT > = Build . VERSION _ CODES . HONEYCOMB ; \n + } \n + \n + @ TargetApi ( Build . VERSION _ CODES . HONEYCOMB ) \n + private static boolean isLargeHeap ( Context context ) { \n + return ( context . getApplicationInfo ( ) . flags & ApplicationInfo . FLAG _ LARGE _ HEAP ) ! = 0 ; \n + } \n + \n + @ TargetApi ( Build . VERSION _ CODES . HONEYCOMB ) \n + private static int getLargeMemoryClass ( ActivityManager am ) { \n + return am . getLargeMemoryClass ( ) ; \n + } \n + \n library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderConfiguration . java \n - * < li > memoryCache = { @ link DefaultConfigurationFactory # createMemoryCache ( int ) } < / li > \n + * < li > memoryCache = { @ link DefaultConfigurationFactory # createMemoryCache ( android . content . Context , int ) } < / li > \n - public static final int DEFAULT _ THREAD _ PRIORITY = Thread . NORM _ PRIORITY - 1 ; \n + public static final int DEFAULT _ THREAD _ PRIORITY = Thread . NORM _ PRIORITY - 2 ; \n - memoryCache = DefaultConfigurationFactory . createMemoryCache ( memoryCacheSize ) ; \n + memoryCache = DefaultConfigurationFactory . createMemoryCache ( context , memoryCacheSize ) ; \n",Consider largeHeap param while define memory cache size,656
library \ src \ com \ nostra13 \ universalimageloader \ cache \ disc \ impl \ ext \ LruDiscCache . java \n + DiskLruCache . Snapshot snapshot = null ; \n - DiskLruCache . Snapshot snapshot = cache . get ( getKey ( imageUri ) ) ; \n + snapshot = cache . get ( getKey ( imageUri ) ) ; \n + } finally { \n + if ( snapshot ! = null ) { \n + snapshot . close ( ) ; \n + } \n,Issue # 606 : Close DiskLruCache . Snapshot after usage,656
"sample \ src \ com \ nostra13 \ example \ universalimageloader \ Constants . java \n - "" https : / / si0 . twimg . com / profile _ images / 1135218951 / gmail _ profile _ icon3 _ normal . png "" , \n - "" http : / / www . krify . net / wp - content / uploads / 2011 / 09 / Macromedia _ Flash _ dock _ icon . png "" , \n sample \ src \ com \ nostra13 \ example \ universalimageloader \ UILApplication . java \n + . diskCacheSize ( 50 * 1024 * 1024 ) / / 50 Mb \n","Sample : Removed broken URLs , limit disk cache",656
library \ src \ com \ nostra13 \ universalimageloader \ core \ imageaware \ ImageViewAware . java \n + import android . graphics . drawable . AnimationDrawable ; \n + if ( drawable instanceof AnimationDrawable ) { \n + ( ( AnimationDrawable ) drawable ) . start ( ) ; \n + } \n,"Issue # 662 - Auto start AnimateDrawables in . showImageOnLoading ( ) , . showImageOnFail ( ) , . showImageForEmptyUri ( )",656
pom . xml \n - < version > 3 . 8 . 1 < / version > \n + < version > 3 . 9 . 0 - rc . 2 < / version > \n,Maven : Update maven - android - plugin version,656
. travis . yml \n - - build - tools - 20 . 0 . 0 \n + - build - tools - 21 . 1 . 1 \n - android - 16 \n,Travis : Build tools 21 . 1 . 1,656
. travis . yml \n - - build - tools - 21 . 1 . 1 \n + - build - tools - 21 . 1 . 2 \n - android - 16 \n,Travis : build tools 21 . 1 . 2,656
library \ src \ main \ java \ com \ nostra13 \ universalimageloader \ core \ decode \ BaseImageDecoder . java \n - try { \n - imageStream . reset ( ) ; \n - } catch ( IOException e ) { \n - IoUtils . closeSilently ( imageStream ) ; \n - imageStream = getImageStream ( decodingInfo ) ; \n + if ( imageStream . markSupported ( ) ) { \n + try { \n + imageStream . reset ( ) ; \n + return imageStream ; \n + } catch ( IOException ignored ) { \n + } \n - return imageStream ; \n + IoUtils . closeSilently ( imageStream ) ; \n + return getImageStream ( decodingInfo ) ; \n - } \n + } \n,Issue # 1026 - Check markSupported ( ),656
library \ src \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - private final ImageLoadingListener emptyListener = new SimpleImageLoadingListener ( ) ; \n + private ImageLoadingListener defaultListener = new SimpleImageLoadingListener ( ) ; \n - listener = emptyListener ; \n + listener = defaultListener ; \n + / * * Sets a default loading listener for all display and loading tasks . * / \n + public void setDefaultLoadingListener ( ImageLoadingListener listener ) { \n + defaultListener = listener = = null ? new SimpleImageLoadingListener ( ) : listener ; \n + } \n + \n,New API : ImageLoader . setDefaultLoadingListener ( . . . ),656
library \ pom . xml \n - < version > 1 . 9 . 4 - SNAPSHOT < / version > \n + < version > 1 . 9 . 4 < / version > \n pom . xml \n - < version > 1 . 9 . 4 - SNAPSHOT < / version > \n + < version > 1 . 9 . 4 < / version > \n - < tag > v1 . 9 . 1 < / tag > \n + < tag > v1 . 9 . 4 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 4 - SNAPSHOT < / version > \n + < version > 1 . 9 . 4 < / version > \n,[ maven - release - plugin ] prepare release v1 . 9 . 4,656
library \ pom . xml \n - < version > 1 . 9 . 4 < / version > \n + < version > 1 . 9 . 5 - SNAPSHOT < / version > \n pom . xml \n - < version > 1 . 9 . 4 < / version > \n + < version > 1 . 9 . 5 - SNAPSHOT < / version > \n - < tag > v1 . 9 . 4 < / tag > \n + < tag > v1 . 9 . 1 < / tag > \n sample \ pom . xml \n - < version > 1 . 9 . 4 < / version > \n + < version > 1 . 9 . 5 - SNAPSHOT < / version > \n,[ maven - release - plugin ] prepare for next development iteration,656
library \ src \ main \ java \ com \ nostra13 \ universalimageloader \ core \ DisplayImageOptions . java \n - * < code > new { @ link DisplayImageOptions } . { @ link Builder # Builder ( ) Builder ( ) } . { @ link Builder # cacheInMemory ( ) cacheInMemory ( ) } . \n + * < code > new { @ link DisplayImageOptions } . Builder ( ) . { @ link Builder # cacheInMemory ( ) cacheInMemory ( ) } . \n - public Builder ( ) { \n - decodingOptions . inPurgeable = true ; \n - decodingOptions . inInputShareable = true ; \n - } \n - \n,Issue # 1020 - Fixed : inPurgeable and inInputShareable causes file descriptor leak on KitKat,656
build . gradle \n - classpath ' com . android . tools . build : gradle : 3 . 3 . 2 ' \n + classpath ' com . android . tools . build : gradle : 3 . 4 . 0 ' \n gradle \ wrapper \ gradle - wrapper . properties \n - # Mon Apr 08 16 : 35 : 19 MSK 2019 \n + # Tue Apr 23 15 : 38 : 19 MSK 2019 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 10 . 1 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 5 . 1 . 1 - all . zip \n library \ build . gradle \n - sourceCompatibility JavaVersion . VERSION _ 1 _ 6 \n - targetCompatibility JavaVersion . VERSION _ 1 _ 6 \n + sourceCompatibility JavaVersion . VERSION _ 1 _ 8 \n + targetCompatibility JavaVersion . VERSION _ 1 _ 8 \n deleted file \n sample \ src \ main \ res \ drawable - ldpi \ ic _ empty . png \n Binary files a / sample / src / main / res / drawable - ldpi / ic _ empty . png and / dev / null differ \n deleted file \n sample \ src \ main \ res \ drawable - ldpi \ ic _ error . png \n Binary files a / sample / src / main / res / drawable - ldpi / ic _ error . png and / dev / null differ \n deleted file \n sample \ src \ main \ res \ drawable - ldpi \ ic _ launcher . png \n Binary files a / sample / src / main / res / drawable - ldpi / ic _ launcher . png and / dev / null differ \n deleted file \n sample \ src \ main \ res \ drawable - ldpi \ ic _ stub . png \n Binary files a / sample / src / main / res / drawable - ldpi / ic _ stub . png and / dev / null differ \n,Update Gradle : 4 . 10 - > 5 . 1 . Update Gradle plugin : 3 . 3 . 2 - > 3 . 4 . 0 . \n Remove ldpi resources .,656
"build . gradle \n + google ( ) \n - classpath ' com . android . tools . build : gradle : 1 . 5 . 0 ' \n + classpath ' com . android . tools . build : gradle : 3 . 3 . 2 ' \n + google ( ) \n gradle \ wrapper \ gradle - wrapper . properties \n - # Sat Jun 06 16 : 36 : 13 FET 2015 \n + # Mon Apr 08 16 : 35 : 19 MSK 2019 \n - distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 2 . 5 - all . zip \n + distributionUrl = https \ : / / services . gradle . org / distributions / gradle - 4 . 10 . 1 - all . zip \n library \ build . gradle \n - compileSdkVersion 23 \n - buildToolsVersion "" 23 . 0 . 2 "" \n + compileSdkVersion 28 \n + buildToolsVersion "" 28 . 0 . 3 "" \n - minSdkVersion 5 \n - targetSdkVersion 22 \n + minSdkVersion 14 \n + targetSdkVersion 28 \n - testCompile ' junit : junit : 4 . 12 ' \n - testCompile ' org . robolectric : robolectric : 3 . 0 - rc3 ' \n - testCompile ' com . squareup . assertj : assertj - android : 1 . 0 . 0 ' \n + testImplementation ' junit : junit : 4 . 12 ' \n + testImplementation ' org . robolectric : robolectric : 3 . 0 - rc3 ' \n + testImplementation ' com . squareup . assertj : assertj - android : 1 . 0 . 0 ' \n sample \ build . gradle \n - compileSdkVersion 23 \n - buildToolsVersion "" 23 . 0 . 2 "" \n + compileSdkVersion 28 \n + buildToolsVersion "" 28 . 0 . 3 "" \n - minSdkVersion 5 \n - targetSdkVersion 22 \n + minSdkVersion 14 \n + targetSdkVersion 28 \n - compile project ( ' : library ' ) \n - compile ' com . android . support : support - v4 : 23 . 1 . 1 ' \n - compile ' com . squareup . okhttp : okhttp : 2 . 4 . 0 ' \n + implementation project ( ' : library ' ) \n + implementation ' com . android . support : appcompat - v7 : 28 . 0 . 0 ' \n + implementation ' com . squareup . okhttp : okhttp : 2 . 4 . 0 ' \n","Update Gradle , build tools , support lib . Up minSDK to 14 . \n Make project compilable .",656
library \ src \ main \ java \ com \ nostra13 \ universalimageloader \ core \ download \ BaseImageDownloader . java \n - String extension = MimeTypeMap . getFileExtensionFromUrl ( uri ) ; \n + String extension = MimeTypeMap . getFileExtensionFromUrl ( Uri . encode ( uri ) ) ; \n,[ # 1262 ] Improve detection of video file extension .,656
"library \ src \ main \ java \ com \ nostra13 \ universalimageloader \ core \ ImageLoader . java \n - engine . pause ( ) ; \n + if ( isInited ( ) ) { \n + engine . pause ( ) ; \n + } else { \n + L . w ( "" Trying to pause not - initialized ImageLoader "" ) ; \n + } \n - engine . resume ( ) ; \n + if ( isInited ( ) ) { \n + engine . resume ( ) ; \n + } else { \n + L . w ( "" Trying to resume not - initialized ImageLoader "" ) ; \n + } \n - engine . stop ( ) ; \n + if ( isInited ( ) ) { \n + engine . stop ( ) ; \n + } else { \n + L . w ( "" Trying to stop not - initialized ImageLoader "" ) ; \n + } \n - if ( configuration ! = null ) L . d ( LOG _ DESTROY ) ; \n - stop ( ) ; \n - configuration . diskCache . close ( ) ; \n - engine = null ; \n - configuration = null ; \n + if ( isInited ( ) ) { \n + L . d ( LOG _ DESTROY ) ; \n + stop ( ) ; \n + configuration . diskCache . close ( ) ; \n + engine = null ; \n + configuration = null ; \n + } else { \n + L . w ( "" Trying to destroy not - initialized ImageLoader "" ) ; \n + } \n",[ # 1229 ] Prevent crash on managing ImageLoader .,656
library \ src \ main \ java \ com \ nostra13 \ universalimageloader \ core \ ImageLoaderEngine . java \n + import static com . nostra13 . universalimageloader . core . download . ImageDownloader . * ; \n + \n - boolean isImageCachedOnDisk = image ! = null & & image . exists ( ) ; \n + boolean isImageCachedOnDisk = image ! = null & & image . exists ( ) \n + | | isLocalUri ( task . getLoadingUri ( ) ) ; \n + private boolean isLocalUri ( String uri ) { \n + Scheme scheme = Scheme . ofUri ( uri ) ; \n + return scheme = = Scheme . ASSETS | | scheme = = Scheme . FILE | | scheme = = Scheme . DRAWABLE ; \n + } \n + \n,"[ # 1084 ] Used "" cached images "" executor for local files ( assets , drawables ) .",656
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ LocalExecutionPlanner . java \n - import com . facebook . presto . sql . planner . Partitioning . ArgumentBinding ; \n - . map ( ArgumentBinding : : getColumn ) \n - . map ( outputLayout : : indexOf ) \n + . map ( argument - > { \n + if ( argument . isConstant ( ) ) { \n + return - 1 ; \n + } \n + return outputLayout . indexOf ( argument . getColumn ( ) ) ; \n + } ) \n,"Be explicit in constant handling when collecting partitionChannels \n This change would produce the same result as before except it is explicit about \n handling constant bindings differently from handling variable bindings . Since \n PartitionedOutputOperator expects partitionChannels and partitionConstants to \n have the same length as the number of arguments , and arguments are used by \n position , we need to designate a special value ( position holder ) for constants \n in partitionChannels .",667
presto - main \ src \ main \ java \ com \ facebook \ presto \ type \ LikeFunctions . java \n - @ ScalarFunction \n + @ ScalarFunction ( hidden = true ) \n,Change like _ pattern to be a hidden function,667
"presto - hive \ src \ test \ java \ com \ facebook \ presto \ hive \ TestHiveIntegrationSmokeTest . java \n + @ Test \n + public void testGroupByWithUnion ( ) \n + { \n + assertQuery ( "" SELECT \ n "" + \n + "" linenumber , \ n "" + \n + "" ' xxx ' \ n "" + \n + "" FROM \ n "" + \n + "" ( \ n "" + \n + "" ( SELECT orderkey , linenumber FROM lineitem ) \ n "" + \n + "" UNION \ n "" + \n + "" ( SELECT orderkey , linenumber FROM lineitem ) \ n "" + \n + "" ) WHERE orderkey = 1 \ n "" + \n + "" GROUP BY \ n "" + \n + "" linenumber "" ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ PropertyDerivations . java \n - import static com . facebook . presto . sql . planner . optimizations . AddExchanges . computeIdentityTranslations ; \n - Map < VariableReferenceExpression , VariableReferenceExpression > identities = computeIdentityTranslations ( node . getAssignments ( ) , types ) ; \n + Map < VariableReferenceExpression , VariableReferenceExpression > identities = computeIdentityTranslations ( node . getAssignments ( ) . getMap ( ) , types ) ; \n + private static Map < VariableReferenceExpression , VariableReferenceExpression > computeIdentityTranslations ( Map < VariableReferenceExpression , Expression > assignments , TypeProvider types ) \n + { \n + Map < VariableReferenceExpression , VariableReferenceExpression > inputToOutput = new HashMap < > ( ) ; \n + for ( Map . Entry < VariableReferenceExpression , Expression > assignment : assignments . entrySet ( ) ) { \n + if ( assignment . getValue ( ) instanceof SymbolReference ) { \n + inputToOutput . put ( toVariableReference ( Symbol . from ( assignment . getValue ( ) ) , types ) , assignment . getKey ( ) ) ; \n + } \n + } \n + return inputToOutput ; \n + } \n + \n",Create correct identity translation for PropertyDeriviations \n Method PropertyDerivations # computeIdentityTranslations is accidentally removed in refactor \n c94abe10762d1595013bbfeebf114c492e6cd182,667
presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ optimizations \ AddExchanges . java \n - PreferredProperties translatedPreferred = preferredProperties . translate ( variable - > node . getReplicateVariables ( ) . contains ( new Symbol ( variable . getName ( ) ) ) ? Optional . of ( variable ) : Optional . empty ( ) ) ; \n + PreferredProperties translatedPreferred = preferredProperties . translate ( variable - > node . getReplicateVariables ( ) . contains ( variable ) ? Optional . of ( variable ) : Optional . empty ( ) ) ; \n,Fix type mismatch in AddExchanges . Rewriter . visitUnnest,667
"presto - base - jdbc \ src \ main \ java \ com \ facebook \ presto \ plugin \ jdbc \ JdbcPageSink . java \n + import io . airlift . log . Logger ; \n + private static final Logger log = Logger . get ( JdbcPageSink . class ) ; \n + \n - throw new PrestoException ( JDBC _ ERROR , e ) ; \n + / / Exceptions happened during abort do not cause any real damage so ignore them \n + log . debug ( e , "" SQLException when abort "" ) ; \n",Do not throw when exception happens in JdbcPageSink : : abort,667
"presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ EnforceSingleRowNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ FilterNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n - @ JsonProperty ( "" predicate "" ) \n + @ JsonProperty \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ LimitNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ SampleNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ SortNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n presto - main \ src \ main \ java \ com \ facebook \ presto \ sql \ planner \ plan \ TopNNode . java \n + import com . facebook . presto . spi . relation . VariableReferenceExpression ; \n + @ Override \n + public List < VariableReferenceExpression > getOutputVariables ( ) \n + { \n + return source . getOutputVariables ( ) ; \n + } \n + \n","Add getOutputVariables to pass through PlanNodes \n The following PlanNodes output the same symbols ( variables ) as their source : \n EnforceSignelRowNode , FilterNode , LimitNode , SampleNode , SortNode and TopNNode .",667
"presto - docs \ src \ main \ sphinx \ release \ release - 0 . 218 . rst \n + . . warning : : \n + \n + This release has the potential to produce incorrect results for three way joins where one of the joins is a ` ` FULL OUTER JOIN ` ` and one subquery \n + of the ` ` FULL OUTER JOIN ` ` has a ` ` GROUP BY ` ` on the join key and some expression that could be evaluated to a constant . For details , please \n + refer to : issue : ` 12577 ` . \n + \n - - - - - - - - - - - - - - - \n",Add a warning to Release 0 . 218 about FULL OUTER JOIN regression,667
"build . gradle \n - versionName = ' 6 . 0 . 9 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60090 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 10 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60100 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 0 . 10 \n Change - Id : Ib1845a8ac404d33762cd8ff2e9994af1951978c0,673
"build . gradle \n - versionName = ' 6 . 0 . 10 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60100 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 1 . 0 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 61000 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 1 . 0 \n Change - Id : I9c01af7759f55b83eaa171bed9ed52b6491e712d,673
"gradle . properties \n - registration _ url = https : / / us - central1 - events - dev - 62d2e . cloudfunctions . net / registered / \n + registration _ url = < in local . gradle > \n shared \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ shared \ data \ signin \ AuthenticatedUserRegistration . kt \n - . header ( "" Authorization "" , token ) \n + . header ( "" Authorization "" , "" Bearer "" + token ) \n",Updated registration endpoint \n Change - Id : I90cf8bf3979ef4cd9900f68be51d5abf4c93f328,673
"build . gradle \n - versionName = ' 6 . 0 . 1 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60010 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 2 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60020 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Bump APK version to 6 . 0 . 2 \n Change - Id : I03ef3e5f69c840656476b893c3d2a1032322ca8d,673
"mobile \ src \ main \ res \ layout \ dialog _ schedule _ hints . xml \n + android : importantForAccessibility = "" no "" \n - android : contentDescription = "" @ string / schedule _ hint _ star _ event _ content _ description "" \n + android : importantForAccessibility = "" no "" \n - android : contentDescription = "" @ string / schedule _ hint _ reserve _ session _ seat _ content _ description "" \n + android : importantForAccessibility = "" no "" \n",Fixed a11y problems in customizing dialog \n Change - Id : I22acbfb970eff3e6dd4a17bde5998277ba10055e,673
"mobile \ src \ main \ res \ menu \ navigation . xml \n - - > \n - < menu xmlns : android = "" http : / / schemas . android . com / apk / res / android "" > \n + < menu xmlns : android = "" http : / / schemas . android . com / apk / res / android "" \n + xmlns : app = "" http : / / schemas . android . com / apk / res - auto "" > \n - android : title = "" @ string / title _ info "" / > \n + android : title = "" @ string / title _ info "" \n + app : contentDescription = "" @ string / title _ info "" / > \n - android : title = "" @ string / title _ schedule "" / > \n + android : title = "" @ string / title _ schedule "" \n + app : contentDescription = "" @ string / title _ schedule "" / > \n - android : title = "" @ string / title _ map "" / > \n + android : title = "" @ string / title _ map "" \n + app : contentDescription = "" @ string / title _ map "" / > \n",Added a11y labels to bottom nav items . \n Bug : 8225457 \n Change - Id : I72f08bde4cf6cbc460148f4b38cd6ca69e9ea075,673
"build . gradle \n - versionName = ' 6 . 0 . 2 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60020 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 3 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60030 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 0 . 3 \n Change - Id : I0089d7830320020286b00732f8045dea2f1e2bb0,673
"mobile \ src \ main \ res \ layout \ fragment _ session _ detail . xml \n + android : contentDescription = "" @ string / navigate _ up "" \n mobile \ src \ main \ res \ values \ strings . xml \n + < string name = "" navigate _ up "" translation - description = "" Arrow at the top left of the screen for navigation "" > Navigate up < / string > \n + \n",Added a11y label for up arrow . \n Bug : 78222803 \n Change - Id : I16b93513da2c0cab43b3016825343157edd5d87f,673
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ day \ ScheduleItemBindingAdapter . kt \n - val timeString = TimeUtils . timeString ( localStartTime , localEndTime ) \n - textView . context . getString ( R . string . session _ duration _ location , timeString , room . name ) \n + fullDateTime ( localStartTime , localEndTime , textView , room ) \n - \n + / / For accessibility , always use the full date time ; without this , sticky headers will confuse \n + / / a Talkback user . \n + textView . contentDescription = fullDateTime ( localStartTime , localEndTime , textView , room ) \n + } \n + \n + private fun fullDateTime ( \n + localStartTime : ZonedDateTime , \n + localEndTime : ZonedDateTime , \n + textView : TextView , \n + room : Room \n + ) : String { \n + val timeString = TimeUtils . timeString ( localStartTime , localEndTime ) \n + return textView . context . getString ( R . string . session _ duration _ location , timeString , room . name ) \n",Announcing full session date and time for a11y . \n Bug : 78220814 \n Change - Id : I842dc6159487997cfe5de7017fb9cbcda0a298e0,673
"build . gradle \n - versionName = ' 6 . 0 . 3 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60030 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 4 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60040 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Bumped version to 6 . 0 . 4 \n Change - Id : I91d23356a17d537179de80788a7d461753506b20,673
"build . gradle \n - versionName = ' 6 . 0 . 4 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60040 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 5 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60050 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 0 . 5 \n Change - Id : I4f0db91426c7b2a7d278f533b40e509a41ffb8c9,673
"build . gradle \n - versionName = ' 6 . 0 . 5 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60050 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 6 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60060 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated verion to 6 . 0 . 6 \n Change - Id : I7c662331be2a0b0b6f526bdd0401b8312d335287,673
"build . gradle \n - versionName = ' 6 . 0 . 6 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60060 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 7 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60070 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Update version to 6 . 0 . 7 \n Change - Id : I403a8d648289d35925dcf5b52e4f03f68c8b2290,673
"build . gradle \n - versionName = ' 6 . 0 . 7 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60070 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 8 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60080 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 0 . 8 \n Change - Id : I6230342a132dddce154c36a326e411264df166ed,673
"build . gradle \n - versionName = ' 6 . 0 . 8 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 60080 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 0 . 9 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 60090 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 0 . 9 \n Change - Id : I7bd06108ddebcdf6b58f5469bd20e8efddaee109,673
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ MainApplication . kt \n - import com . squareup . leakcanary . LeakCanary \n - if ( LeakCanary . isInAnalyzerProcess ( this ) ) { \n - / / This process is dedicated to LeakCanary for heap analysis . \n - / / You should not init your app in this process . \n - return \n - } \n - \n - LeakCanary . install ( this ) \n,Removed LeakCanary \n Change - Id : Ieafc0fc269b03329f48e8ce90b5b7e566fad6ca6,673
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ day \ ScheduleItemBindingAdapter . kt \n - durationString ( textView . context , Duration . between ( startTime , endTime ) ) , room \n + durationString ( textView . context , Duration . between ( startTime , endTime ) ) , room . name \n",Fixed room name on schedule \n Change - Id : I54d62eca9515039a81799b7fd4194bec263e8a2a,673
"build . gradle \n - versionName = ' 6 . 1 . 0 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 61000 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 1 . 1 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 61010 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 1 . 1 \n Change - Id : Icda2c534432c15d009355d6bf5b2d868d7d470d5,673
"build . gradle \n - versionName = ' 6 . 1 . 1 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n - versionCodeBase = 61010 / / XYZZM ; M = Module ( wear , tv , mobile ) \n + versionName = ' 6 . 1 . 2 ' / / X . Y . Z ; X = Major , Y = minor , Z = Patch level \n + versionCodeBase = 61020 / / XYZZM ; M = Module ( wear , tv , mobile ) \n",Updated version to 6 . 1 . 2 \n Change - Id : I8719f5ac1b573252776f8fbec9d36ec30bacdc47,673
"mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleViewModel . kt \n - private val _ profileContentDesc = MediatorLiveData < Int > ( ) . apply { value = R . string . a11y _ sign _ in } \n + private val _ profileContentDesc = MediatorLiveData < Int > ( ) . apply { value = R . string . sign _ in } \n - R . string . a11y _ sign _ out \n + R . string . sign _ out \n - R . string . a11y _ sign _ in \n + R . string . sign _ in \n mobile \ src \ main \ res \ values \ strings . xml \n - < string name = "" a11y _ sign _ in "" translatable = "" false "" > TODO : a11y content description for sign in action < / string > \n - < string name = "" a11y _ sign _ out "" translatable = "" false "" > TODO : a11y content description for sign out action < / string > \n - \n mobile \ src \ test \ java \ com \ google \ samples \ apps \ iosched \ ui \ schedule \ ScheduleViewModelTest . kt \n - assertEquals ( R . string . a11y _ sign _ out , \n + assertEquals ( R . string . sign _ out , \n - assertEquals ( R . string . a11y _ sign _ in , LiveDataTestUtil . getValue ( viewModel . profileContentDesc ) ) \n + assertEquals ( R . string . sign _ in , LiveDataTestUtil . getValue ( viewModel . profileContentDesc ) ) \n - assertEquals ( R . string . a11y _ sign _ in , LiveDataTestUtil . getValue ( viewModel . profileContentDesc ) ) \n + assertEquals ( R . string . sign _ in , LiveDataTestUtil . getValue ( viewModel . profileContentDesc ) ) \n",Removed TODO a11y text from sign in button \n Change - Id : I1827d8b5be1602d5e8e6265aa2ff166e71f71b13,673
"mobile \ src \ main \ res \ layout - land \ include _ schedule _ appbar . xml \n + android : contentDescription = "" @ string / a11y _ pinned "" \n mobile \ src \ main \ res \ layout \ include _ schedule _ appbar . xml \n + android : contentDescription = "" @ string / a11y _ pinned "" \n mobile \ src \ main \ res \ values \ strings . xml \n + \n + < string name = "" a11y _ pinned "" translation _ description = "" Description of a button that used to show only starred and reserved events . "" > Only starred and reserved events < / string > \n",Added a11y label to user events toggle . \n Bug : 77645012 \n Change - Id : I17a8f3206c276db036bdfdaac128743f007be63a,673
mobile \ src \ main \ java \ com \ google \ samples \ apps \ iosched \ util \ signin \ SignInHandler . kt \n - . requestProfile ( ) \n,Not asking for profile scope for sign in \n Change - Id : Idd77a013c2748981c574e70668423b69df4c23c6,673
"dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ ProtocolConfig . java \n + / / thread pool core thread size \n + private Integer corethreads ; \n + \n + public Integer getCorethreads ( ) { \n + return corethreads ; \n + } \n + \n + public void setCorethreads ( Integer corethreads ) { \n + this . corethreads = corethreads ; \n + } \n + \n dubbo - config \ dubbo - config - api \ src \ test \ java \ org \ apache \ dubbo \ config \ ProtocolConfigTest . java \n + @ Test \n + public void testCorethreads ( ) throws Exception { \n + ProtocolConfig protocol = new ProtocolConfig ( ) ; \n + protocol . setCorethreads ( 10 ) ; \n + assertThat ( protocol . getCorethreads ( ) , is ( 10 ) ) ; \n + } \n + \n dubbo - config \ dubbo - config - spring \ src \ main \ resources \ META - INF \ dubbo . xsd \n + < xsd : attribute name = "" corethreads "" type = "" xsd : string "" use = "" optional "" > \n + < xsd : annotation > \n + < xsd : documentation > < ! [ CDATA [ The thread pool core threads size . ] ] > < / xsd : documentation > \n + < / xsd : annotation > \n + < / xsd : attribute > \n",[ Issue - 303 ] Add the tag corethreads to < dubbo : protocol > in dubbo . xsd ( # 1989 ),688
"dubbo - compatible \ src \ main \ java \ com \ alibaba \ dubbo \ config \ annotation \ Reference . java \n - int retries ( ) default 0 ; \n + int retries ( ) default 2 ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ annotation \ Reference . java \n - int retries ( ) default 0 ; \n + int retries ( ) default 2 ; \n dubbo - config \ dubbo - config - spring \ src \ test \ java \ org \ apache \ dubbo \ config \ spring \ beans \ factory \ annotation \ AnnotationPropertyValuesAdapterTest . java \n - Assert . assertEquals ( Integer . valueOf ( 2 ) , referenceBean . getRetries ( ) ) ; \n + Assert . assertEquals ( Integer . valueOf ( 1 ) , referenceBean . getRetries ( ) ) ; \n - ondisconnect = "" ondisconnect "" , owner = "" owner "" , layer = "" layer "" , retries = 2 , \n + ondisconnect = "" ondisconnect "" , owner = "" owner "" , layer = "" layer "" , retries = 1 , \n",[ Dubbo - # 2162 ] Correct the reference retries default value 0 to 2 ( # 2183 ) \n * Correct the reference retries default value 0 to 2 \n * fix the unit test error,688
"dubbo - registry \ dubbo - registry - api \ src \ test \ java \ org \ apache \ dubbo \ registry \ support \ AbstractRegistryFactoryTest . java \n + import java . util . Collection ; \n + @ Test \n + public void testDestroyAllRegistries ( ) { \n + Registry registry1 = registryFactory . getRegistry ( URL . valueOf ( "" dubbo : / / "" + NetUtils . getLocalHost ( ) + "" : 8888 ? group = xxx "" ) ) ; \n + Registry registry2 = registryFactory . getRegistry ( URL . valueOf ( "" dubbo : / / "" + NetUtils . getLocalHost ( ) + "" : 9999 ? group = yyy "" ) ) ; \n + Collection < Registry > registries = AbstractRegistryFactory . getRegistries ( ) ; \n + Assert . assertTrue ( registries . contains ( registry1 ) ) ; \n + Assert . assertTrue ( registries . contains ( registry2 ) ) ; \n + AbstractRegistryFactory . destroyAll ( ) ; \n + Assert . assertFalse ( registries . contains ( registry1 ) ) ; \n + Assert . assertFalse ( registries . contains ( registry2 ) ) ; \n + } \n",AbstractRegistryFactory Unit Test : destroyAll method ( # 2581 ),688
"dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ ServiceConfig . java \n + logger . warn ( "" Use random available port ( "" + port + "" ) for protocol "" + protocol ) ; \n - logger . warn ( "" Use random available port ( "" + portToBind + "" ) for protocol "" + name ) ; \n",Remove the log to putRandomPort when one protocol use random port ( # 2931 ) \n * optimize findConfigedPorts method of ServiceConfig to log only one time when userandom port \n * move the log to method putRandomPort,688
"dubbo - cluster \ src \ main \ java \ org \ apache \ dubbo \ rpc \ cluster \ loadbalance \ RandomLoadBalance . java \n - int totalWeight = 0 ; / / The sum of weights \n - for ( int i = 0 ; i < length ; i + + ) { \n + int firstWeight = getWeight ( invokers . get ( 0 ) , invocation ) ; \n + int totalWeight = firstWeight ; / / The sum of weights \n + for ( int i = 1 ; i < length ; i + + ) { \n - if ( sameWeight & & i > 0 \n - & & weight ! = getWeight ( invokers . get ( i - 1 ) , invocation ) ) { \n + if ( sameWeight & & weight ! = firstWeight ) { \n",Optimize the doSelect method of RandomLoadBalance to reduce the times of invoke of the getWeight method of the AbstractLoadBalance ( # 2597 ),688
"dubbo - registry \ dubbo - registry - api \ src \ test \ java \ org \ apache \ dubbo \ registry \ support \ FailbackRegistryTest . java \n + import org . junit . Assert ; \n + @ Test \n + public void testRecover ( ) throws Exception { \n + CountDownLatch countDownLatch = new CountDownLatch ( 4 ) ; \n + final AtomicReference < Boolean > notified = new AtomicReference < Boolean > ( false ) ; \n + NotifyListener listener = new NotifyListener ( ) { \n + @ Override \n + public void notify ( List < URL > urls ) { \n + notified . set ( Boolean . TRUE ) ; \n + } \n + } ; \n + \n + MockRegistry mockRegistry = new MockRegistry ( registryUrl , countDownLatch ) ; \n + mockRegistry . register ( serviceUrl ) ; \n + mockRegistry . subscribe ( serviceUrl , listener ) ; \n + Assert . assertEquals ( 1 , mockRegistry . getRegistered ( ) . size ( ) ) ; \n + Assert . assertEquals ( 1 , mockRegistry . getSubscribed ( ) . size ( ) ) ; \n + mockRegistry . recover ( ) ; \n + countDownLatch . await ( ) ; \n + Assert . assertEquals ( 0 , mockRegistry . getFailedRegistered ( ) . size ( ) ) ; \n + Assert . assertEquals ( null , mockRegistry . getFailedSubscribed ( ) . get ( registryUrl ) ) ; \n + Assert . assertEquals ( countDownLatch . getCount ( ) , 0 ) ; \n + } \n","【Unit Test】FailbackRegistry Test : recover method ( # 2591 ) \n * FailbackRegistry Test : recover method \n * fix the type error , and use CountDownLatch await method to fix the unstable problom \n * trigger the travis ci test retry \n * trigger the code static check again",688
dubbo - rpc \ dubbo - rpc - dubbo \ src \ main \ java \ org \ apache \ dubbo \ rpc \ protocol \ dubbo \ telnet \ InvokeTelnetHandler . java \n + Class < ? > boxedType = ReflectUtils . getBoxedClass ( type ) ; \n + if ( boxedType ! = arg . getClass ( ) ) { \n + return false ; \n + } \n,[ dubbo - 2766 ] fix the bug of isMatch method of InvokeTelnetHandler ( # 2787 ),688
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ cpp \ CcBinary . java \n - / / For CcBinary targets , we only want to ensure that we process headers in dependencies and \n - / / thus only add header tokens to HIDDEN _ TOP _ LEVEL . If we add all HIDDEN _ TOP _ LEVEL artifacts \n - / / from dependent CcLibrary targets , we ' d be building . pic . o files in nopic builds . \n - . addOutputGroup ( OutputGroupInfo . HIDDEN _ TOP _ LEVEL , headerTokens ) \n + . addOutputGroup ( OutputGroupInfo . VALIDATION , headerTokens ) \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ cpp \ CcLibraryConfiguredTargetTest . java \n - assertThat ( hiddenTopLevel ) . contains ( "" y . h . processed "" ) ; \n + assertThat ( hiddenTopLevel ) . doesNotContain ( "" y . h . processed "" ) ; \n + String validation = ActionsTestUtil . baseNamesOf ( getOutputGroup ( x , OutputGroupInfo . VALIDATION ) ) ; \n + assertThat ( validation ) . contains ( "" y . h . processed "" ) ; \n src \ test \ java \ com \ google \ devtools \ build \ lib \ starlark \ StarlarkIntegrationTest . java \n - OutputGroupInfo . TEMP _ FILES ) ; \n + OutputGroupInfo . TEMP _ FILES , \n + OutputGroupInfo . VALIDATION ) ; \n","Automated rollback of commit 10ba63455b228c3d17951e9a0c18ff18e18fbebd . \n * * * Reason for rollback * * * \n Performance "" regression "" has been analyzed and approved \n RELNOTES : This change can cause memory and performance regressions for some builds with C + + dependencies , due to extra actions being executed . \n * * * Original change description * * * \n Automated rollback of commit 5cf0635fb1d3b6b2bb88edad4b1faf6817366563 . \n * * * Reason for rollback * * * \n Causes performance regression , see b / 163274249 \n * * * Original change description * * * \n Make parse _ header a validation action \n Move header tokens of cc _ binary to validation , so that building \n targets that depend on the cc _ binary will trigger header validation . \n This way , parse _ headers will trigger properly for android . \n RELNOTES : None \n PiperOrigin - RevId : 327426390",693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcCommon . java \n - Iterables . concat ( artifacts . getSrcs ( ) , artifacts . getNonArcSrcs ( ) ) ; \n - / / TODO ( bazel - team ) : Add private headers to the provider when we have module maps to enforce \n - / / them . \n + Iterables . concat ( \n + artifacts . getSrcs ( ) , artifacts . getNonArcSrcs ( ) , artifacts . getPrivateHdrs ( ) ) ; \n src \ main \ java \ com \ google \ devtools \ build \ lib \ starlarkbuildapi \ apple \ ObjcProviderApi . java \n - "" Header files from this target directly ( no transitive headers ) . "" \n - + "" These may be either public or private headers . "" ) \n + "" Public header files from this target directly ( no transitive headers ) . "" \n + + "" These are mostly headers from the ' hdrs ' attribute . "" ) \n - doc = "" All direct source files from this target ( no transitive files ) . "" ) \n + doc = \n + "" All direct source files from this target ( no transitive files ) , "" \n + + "" including any headers in the ' srcs ' attribute . "" ) \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcLibraryTest . java \n - . containsExactly ( "" bar . m "" ) ; \n + . containsExactly ( "" bar . m "" , "" bar _ impl . h "" ) ; \n",Add private headers to direct sources \n This is the desired behavior ; it was probably an oversight that they \n weren ' t there before . \n PiperOrigin - RevId : 331651766,693
"src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ cpp \ CcLibraryConfiguredTargetTest . java \n - assertThat ( getGeneratingAction ( getBinArtifact ( "" _ objs / x / . pic . o "" , x ) ) ) . isNull ( ) ; \n + assertThat ( getGeneratingAction ( getBinArtifact ( "" _ objs / x / x . o "" , x ) ) ) . isNull ( ) ; \n",Fix artifact path in test \n PiperOrigin - RevId : 334326427,693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcCommandLineOptions . java \n - defaultValue = "" false "" , \n + defaultValue = "" true "" , \n",Flip - - incompatible _ objc _ compile _ info _ migration to true \n RELNOTES : The flag ` - - incompatible _ objc _ compile _ info _ migration ` is enabled by default . See # 10854 . \n PiperOrigin - RevId : 338330651,693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ packages \ semantics \ BuildLanguageOptions . java \n - defaultValue = "" false "" , \n + defaultValue = "" true "" , \n - "" - incompatible _ objc _ provider _ remove _ compile _ info "" ; \n + "" + incompatible _ objc _ provider _ remove _ compile _ info "" ; \n",Flip - - incompatible _ objc _ provider _ remove _ compile _ info to true \n RELNOTES : The flag ` - - incompatible _ objc _ provider _ remove _ compile _ info ` is enabled by default . See # 11359 . \n PiperOrigin - RevId : 338339157,693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ AppleBinary . java \n - extraLinkArgs . add ( "" - Xlinker "" , "" - rpath "" , "" - Xlinker "" , "" @ loader _ path / Frameworks "" ) ; \n + extraLinkArgs . add ( "" - Wl , - rpath , @ loader _ path / Frameworks "" ) ; \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcRuleTestCase . java \n - . contains ( "" - Xlinker - rpath - Xlinker @ loader _ path / Frameworks "" ) ; \n + . contains ( "" - Wl , - rpath , @ loader _ path / Frameworks "" ) ; \n","Replace - Xlinker flag with - Wl flag \n They are equivalent , but the latter allows us to combine linker \n arguments and plays more nicely with param files . \n PiperOrigin - RevId : 339543243",693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ J2ObjcLibrary . java \n - . addCcCompilationContexts ( \n + . addDirectCcCompilationContexts ( \n src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcCommon . java \n + private Iterable < CcCompilationContext > directCCompilationContexts = ImmutableList . of ( ) ; \n + Builder addDirectCcCompilationContexts ( Iterable < CcInfo > ccInfos ) { \n + / / TODO ( waltl ) : Support direct CcCompilationContexts in CcCompilationHelper . \n + Preconditions . checkState ( \n + this . purpose . equals ( Purpose . LINK _ ONLY ) , \n + "" direct CcCompilationContext is only supported for LINK _ ONLY purpose "" ) ; \n + this . directCCompilationContexts = \n + Iterables . concat ( this . directCCompilationContexts , getCcCompilationContexts ( ccInfos ) ) ; \n + return this ; \n + } \n + \n + . addDirectCcCompilationContexts ( directCCompilationContexts ) \n src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcCompilationContext . java \n + private final ImmutableList < CcCompilationContext > directCcCompilationContexts ; \n + Iterable < CcCompilationContext > directCcCompilationContexts , \n + this . directCcCompilationContexts = ImmutableList . copyOf ( directCcCompilationContexts ) ; \n + public ImmutableList < CcCompilationContext > getDirectCcCompilationContexts ( ) { \n + return directCcCompilationContexts ; \n + } \n + \n - . mergeDependentCcCompilationContexts ( getCcCompilationContexts ( ) ) ; \n + . mergeDependentCcCompilationContexts ( \n + getDirectCcCompilationContexts ( ) , getCcCompilationContexts ( ) ) ; \n + private final List < CcCompilationContext > directCcCompilationContexts = new ArrayList < > ( ) ; \n + public Builder addDirectCcCompilationContexts ( \n + Iterable < CcCompilationContext > ccCompilationContexts ) { \n + Iterables . addAll ( this . directCcCompilationContexts , ccCompilationContexts ) ; \n + return this ; \n + } \n + \n + directCcCompilationContexts , \n",Propagate direct CcCompilationContext for j2objc _ library \n This is in preparation for enabling layering check . The behavior we \n want it for j2objc _ library to export the transpiled headers of its \n direct dependencies . \n PiperOrigin - RevId : 360205750,693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ CompilationSupport . java \n + ImmutableSet . Builder < String > disableFeatures = ImmutableSet . < String > builder ( ) ; \n + / / TODO ( b / 159096411 ) : Remove once supports _ header _ parsing is removed from the cc _ toolchain rule . \n + if ( disableParseHeaders | | ! ccToolchain . supportsHeaderParsing ( ) ) { \n + disableFeatures . add ( CppRuleClasses . PARSE _ HEADERS ) ; \n + } \n + if ( disableLayeringCheck ) { \n + disableFeatures . add ( CppRuleClasses . LAYERING _ CHECK ) ; \n + } \n + \n + ImmutableSet < String > disableFeaturesSet = disableFeatures . build ( ) ; \n - if ( ! ccToolchain . supportsHeaderParsing ( ) ) { \n - / / TODO ( b / 159096411 ) : Remove once supports _ header _ parsing has been removed from the \n - / / cc _ toolchain rule . \n + if ( ! disableFeaturesSet . isEmpty ( ) ) { \n - . filter ( feature - > ! feature . equals ( CppRuleClasses . PARSE _ HEADERS ) ) \n + . filter ( feature - > ! disableFeaturesSet . contains ( feature ) ) \n + private final boolean disableLayeringCheck ; \n + private final boolean disableParseHeaders ; \n - boolean usePch ) \n + boolean usePch , \n + boolean disableLayeringCheck , \n + boolean disableParseHeaders ) \n + this . disableLayeringCheck = disableLayeringCheck ; \n + this . disableParseHeaders = disableParseHeaders ; \n + private boolean disableLayeringCheck = false ; \n + private boolean disableParseHeaders = false ; \n + / * * Sets that this { @ link CompilationSupport } will disable layering check . * / \n + public Builder disableLayeringCheck ( ) { \n + this . disableLayeringCheck = true ; \n + return this ; \n + } \n + \n + / * * Sets that this { @ link CompilationSupport } will disable parse headers . * / \n + public Builder disableParseHeaders ( ) { \n + this . disableParseHeaders = true ; \n + return this ; \n + } \n + \n - usePch ) ; \n + usePch , \n + disableLayeringCheck , \n + disableParseHeaders ) ; \n src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ J2ObjcAspect . java \n + . disableLayeringCheck ( ) \n + . disableParseHeaders ( ) \n","Disable layering check and parse headers for J2Objc transpiled code \n In general , there is less value in doing these checks for generated \n code - - e . g . we don ' t do it for proto headers . \n Parse headers is currently off for J2Objc anyways , but it would \n otherwise be enabled when we migrate header tokens to \n CcCompilationContext . \n Layering check is not currently available , but when it is , we would \n like it to continue disabling it for transpiled code . \n PiperOrigin - RevId : 360227588",693
src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ cpp \ CcCompilationHelper . java \n + boolean isObjcFile = CppFileTypes . OBJC _ SOURCE . matches ( path ) ; \n + boolean isObjcppFile = CppFileTypes . OBJCPP _ SOURCE . matches ( path ) ; \n - if ( ! isCFile & & ! isCppFile ) { \n + if ( ! isCFile & & ! isCppFile & & ! isObjcFile & & ! isObjcppFile ) { \n,Support - - save _ temps for objc _ library \n PiperOrigin - RevId : 359550727,693
"src \ main \ java \ com \ google \ devtools \ build \ lib \ rules \ cpp \ CcLinkingHelper . java \n + String mnemonic = \n + ( linkType . equals ( LinkTargetType . OBJCPP _ EXECUTABLE ) \n + | | linkType . equals ( LinkTargetType . OBJC _ EXECUTABLE ) ) \n + ? "" ObjcLink "" \n + : null ; \n - . setMnemonic ( \n - featureConfiguration . isEnabled ( CppRuleClasses . LANG _ OBJC ) ? "" ObjcLink "" : null ) \n + . setMnemonic ( mnemonic ) \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcLibraryTest . java \n + import com . google . devtools . build . lib . rules . cpp . CppLinkAction ; \n + @ Test \n + public void testLinkActionMnemonic ( ) throws Exception { \n + scratchConfiguredTarget ( "" foo "" , "" x "" , "" objc _ library ( name = ' x ' , srcs = [ ' a . m ' ] ) "" ) ; \n + \n + CppLinkAction archiveAction = ( CppLinkAction ) archiveAction ( "" / / foo : x "" ) ; \n + assertThat ( archiveAction . getMnemonic ( ) ) . isEqualTo ( "" CppLink "" ) ; \n + CppLinkAction fullyArchiveAction = \n + ( CppLinkAction ) getGeneratingActionForLabel ( "" / / foo : x _ fully _ linked . a "" ) ; \n + assertThat ( fullyArchiveAction . getMnemonic ( ) ) . isEqualTo ( "" CppLink "" ) ; \n + } \n + \n","Restore objc archive mnemonic to "" CppLink "" \n PiperOrigin - RevId : 359778845",693
"src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ BazelJ2ObjcLibraryTest . java \n - useConfiguration ( "" - - experimental _ objc _ enable _ module _ maps "" ) ; \n src \ test \ java \ com \ google \ devtools \ build \ lib \ rules \ objc \ ObjcRuleTestCase . java \n - useConfiguration ( "" - - experimental _ objc _ enable _ module _ maps "" ) ; \n","Delete unnecessary - - experimental _ objc _ enable _ module _ maps in tests \n There was a time when use of module maps required this flag , but \n that ' s no longer true . \n PiperOrigin - RevId : 356263747",693
"README . md \n - compile "" com . daimajia . swipelayout : library : 1 . 1 . 0 @ aar "" \n + compile "" com . daimajia . swipelayout : library : 1 . 1 . 1 @ aar "" \n - < version > 1 . 1 . 0 < / version > \n + < version > 1 . 1 . 1 < / version > \n",v1 . 1 . 1 \n Better selector effect .,702
"README . md \n - [ Download Demo ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 0 . 0 / AndroidSwipeLayout - Demo - 1 . 0 . 1 - snapshot . apk ) \n + [ Download Demo ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 1 . 3 / AndroidSwipeLayout - v1 . 1 . 3 . apk ) \n - Before I made this , I actually found some libraries ( eg . [ SwipeListView ] ( https : / / github . com / 47deg / android - swipelistview ) ) that helps developers to integrate swiping with your UI component . But they have too much limitation , only in ListView , or some other limitations . \n + Before I made this , I actually found some libraries ( eg . [ SwipeListView ] ( https : / / github . com / 47deg / android - swipelistview ) ) that helps developers to integrate swiping with your UI component . But it only works in ` ListView ` . What a pity . \n - compile "" com . daimajia . swipelayout : library : 1 . 1 . 1 @ aar "" \n + compile "" com . daimajia . swipelayout : library : 1 . 1 . 3 @ aar "" \n - < version > 1 . 1 . 1 < / version > \n + < version > 1 . 1 . 3 < / version > \n",v1 . 1 . 3 \n better SwipeAdapter,702
"README . md \n - [ Download Demo ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 1 . 4 / AndroidSwipeLayout - 1 . 1 . 4 . apk ) \n + [ Download Demo ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 1 . 6 / AndroidSwipeLayout - v1 . 1 . 6 . apk ) \n - compile "" com . daimajia . swipelayout : library : 1 . 1 . 5 @ aar "" \n + compile "" com . daimajia . swipelayout : library : 1 . 1 . 6 @ aar "" \n - < version > 1 . 1 . 5 < / version > \n + < version > 1 . 1 . 6 < / version > \n - [ AndroidSwipeLayout - v1 . 1 . 5 . jar ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 1 . 5 / AndroidSwipeLayout - v1 . 1 . 5 . jar ) \n + [ AndroidSwipeLayout - v1 . 1 . 6 . jar ] ( https : / / github . com / daimajia / AndroidSwipeLayout / releases / download / v1 . 1 . 6 / AndroidSwipeLayout - v1 . 1 . 6 . jar ) \n",v1 . 1 . 6 \n Support double click .,702
"README . md \n - compile "" com . daimajia . swipelayout : library : 1 . 0 . 7 @ aar "" \n + compile "" com . daimajia . swipelayout : library : 1 . 0 . 8 @ aar "" \n - < version > 1 . 0 . 7 < / version > \n + < version > 1 . 0 . 8 < / version > \n",v1 . 0 . 8 \n Selector Support # 23,702
README . md \n - ` ` ` sh \n - adb devices \n - List of devices attached \n - 004c03eb5615429f device \n - ` ` ` \n + ` ` ` sh \n + adb devices \n + List of devices attached \n + 004c03eb5615429f device \n + ` ` ` \n + \n,fix README format issue . ( # 4212 ) \n * fix README format issue . \n * Align lines .,702
"README . md \n - [ ! [ Gitter ] ( https : / / badges . gitter . im / Join % 20Chat . svg ) ] ( https : / / gitter . im / daimajia / AndroidViewAnimations ? utm _ source = badge & utm _ medium = badge & utm _ campaign = pr - badge & utm _ content = badge ) \n - \n - \n - [ ! [ Insight . io ] ( https : / / insight . io / repoBadge / github . com / daimajia / AndroidViewAnimations ) ] ( https : / / insight . io / github . com / daimajia / AndroidViewAnimations ) \n - \n - [ AFViewShaker ] ( https : / / github . com / ArtFeel / AFViewShaker ) \n - [ Animate . css ] ( https : / / github . com / daneden / animate . css ) \n + # Why YoYo ? \n + \n + YoYo is a [ toy ] ( https : / / en . wikipedia . org / wiki / Yo - yo ) , with a lot of [ Techniques ] ( . / library / src / main / java / com / daimajia / androidanimations / library / Techniques . java ) . \n + \n - A student in mainland China . \n + ( 2013 ) \n + A student in mainland China . \n + \n + ( 2019 ) \n + Five years later , now I become an investment associate in China . \n + \n + Welcome to send your business plan to [ me ] ( mailto : daimajia @ gmail . com ) . Maybe I would have a better understanding on your startup project than others . Trust me . \n","update readme , update my status right now .",702
"dubbo - cluster \ src \ main \ java \ com \ alibaba \ dubbo \ rpc \ cluster \ support \ FailbackClusterInvoker . java \n - import com . alibaba . dubbo . common . utils . NamedThreadFactory ; \n + import com . alibaba . dubbo . common . threadlocal . NamedInternalThreadFactory ; \n + import com . alibaba . dubbo . rpc . RpcContext ; \n - private final ScheduledExecutorService scheduledExecutorService = Executors . newScheduledThreadPool ( 2 , new NamedThreadFactory ( "" failback - cluster - timer "" , true ) ) ; \n + / * * \n + * Use { @ link NamedInternalThreadFactory } to produce { @ link com . alibaba . dubbo . common . threadlocal . InternalThread } \n + * which with the use of { @ link com . alibaba . dubbo . common . threadlocal . InternalThreadLocal } in { @ link RpcContext } . \n + * / \n + private final ScheduledExecutorService scheduledExecutorService = Executors . newScheduledThreadPool ( 2 , \n + new NamedInternalThreadFactory ( "" failback - cluster - timer "" , true ) ) ; \n + \n dubbo - cluster \ src \ main \ java \ com \ alibaba \ dubbo \ rpc \ cluster \ support \ ForkingClusterInvoker . java \n - import com . alibaba . dubbo . common . utils . NamedThreadFactory ; \n + import com . alibaba . dubbo . common . threadlocal . NamedInternalThreadFactory ; \n - private final ExecutorService executor = Executors . newCachedThreadPool ( new NamedThreadFactory ( "" forking - cluster - timer "" , true ) ) ; \n + / * * \n + * Use { @ link NamedInternalThreadFactory } to produce { @ link com . alibaba . dubbo . common . threadlocal . InternalThread } \n + * which with the use of { @ link com . alibaba . dubbo . common . threadlocal . InternalThreadLocal } in { @ link RpcContext } . \n + * / \n + private final ExecutorService executor = Executors . newCachedThreadPool ( \n + new NamedInternalThreadFactory ( "" forking - cluster - timer "" , true ) ) ; \n",Use InternalThreadLocal in consumer side ( # 1825 ) \n * SerializerFactory 获取Serializer时，锁住整个hashmap，导致整个过程被block \n * 单元测试。保证一个class只有一个serializer和deserializer。单线程和多线程测试 \n * 增加线程数 50 模拟多个线程来获取serializer和deserializer \n * 当cores线程数全都使用的情况下，默认线程池会把任务放入到队列中。队列满则再创建线程（总数不会超过Max线程数） \n 增强线程池：在请求量阶段性出现高峰时使用 \n 特性：cores线程全部使用的情况下，优先创建线程（总数不会超过max），当max个线程全都在忙的情况下，才将任务放入队列。请求量下降时，线程池会自动维持cores个线程，多余的线程退出。 \n * 当cores线程数全都使用的情况下，默认线程池会把任务放入到队列中。队列满则再创建线程（总数不会超过Max线程数） \n 增强线程池：在请求量阶段性出现高峰时使用 \n 特性：cores线程全部使用的情况下，优先创建线程（总数不会超过max），当max个线程全都在忙的情况下，才将任务放入队列。请求量下降时，线程池会自动维持cores个线程，多余的线程退出。 \n * 补全单元测试，测试扩展是否生效 \n * 错误命名 \n * 增加 @ Override注解 \n long 初始化赋值时，小写l改为大写L防止误读 \n * 修复单元测试 \n * remove enhanced \n * remove enhanced \n * Change ThreadFactory for consumer side which is to use InternalThreadLocal in RpcContext .,703
transport \ src \ main \ java \ io \ netty \ channel \ nio \ NioEventLoop . java \n - final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet ( ) ; \n - \n + final SelectedSelectionKeySet selectedKeySet = new SelectedSelectionKeySet ( ) ; \n,SelectedSelectionKeySet should only be created if the set can be instrumented \n Motivation : \n If we can not replace the internal used Set of the Selector there is no need to create an SelectedSelectionKeySet instance . \n Modification : \n Only create SelectedSelectionKeySet if we will replace the internal set . \n Result : \n Less object creation in some cases and cleaner code .,703
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n + import java . util . Collections ; \n + import java . util . concurrent . ConcurrentHashMap ; \n - private final ConcurrentMap < DefaultResourceLeak < ? > , LeakEntry > allLeaks = PlatformDependent . newConcurrentHashMap ( ) ; \n + private final Set < DefaultResourceLeak < ? > > allLeaks = \n + Collections . newSetFromMap ( new ConcurrentHashMap < DefaultResourceLeak < ? > , Boolean > ( ) ) ; \n - private final ConcurrentMap < DefaultResourceLeak < ? > , LeakEntry > allLeaks ; \n + private final Set < DefaultResourceLeak < ? > > allLeaks ; \n - ConcurrentMap < DefaultResourceLeak < ? > , LeakEntry > allLeaks ) { \n + Set < DefaultResourceLeak < ? > > allLeaks ) { \n - allLeaks . put ( this , LeakEntry . INSTANCE ) ; \n + allLeaks . add ( this ) ; \n - return allLeaks . remove ( this , LeakEntry . INSTANCE ) ; \n + return allLeaks . remove ( this ) ; \n - / / Use the ConcurrentMap remove method , which avoids allocating an iterator . \n - if ( allLeaks . remove ( this , LeakEntry . INSTANCE ) ) { \n + if ( allLeaks . remove ( this ) ) { \n - \n - private static final class LeakEntry { \n - static final LeakEntry INSTANCE = new LeakEntry ( ) ; \n - private static final int HASH = System . identityHashCode ( INSTANCE ) ; \n - \n - private LeakEntry ( ) { \n - } \n - \n - @ Override \n - public int hashCode ( ) { \n - return HASH ; \n - } \n - \n - @ Override \n - public boolean equals ( Object obj ) { \n - return obj = = this ; \n - } \n - } \n","Replace ConcurrentHashMap at allLeaks with a thread - safe set ( # 8467 ) \n Motivation : \n allLeaks is to store the DefaultResourceLeak . When we actually use it , the key is DefaultResourceLeak , and the value is actually a meaningless value . \n We only care about the keys of allLeaks and don ' t care about the values . So Set is more in line with this scenario . \n Using Set as a container is more consistent with the definition of a container than Map . \n Modification : \n Replace allLeaks with set . Create a thread - safe set using ' Collections . newSetFromMap ( new ConcurrentHashMap < DefaultResourceLeak < ? > , Boolean > ( ) ) . '",703
"dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ common \ extension \ ExtensionLoader . java \n - try { \n - this . getExtensionClass ( name ) ; \n - return true ; \n - } catch ( Throwable t ) { \n - return false ; \n - } \n + Class < ? > c = this . getExtensionClass ( name ) ; \n + return c ! = null ; \n - Class < ? > clazz = getExtensionClasses ( ) . get ( name ) ; \n - if ( clazz = = null ) { \n - throw new IllegalStateException ( "" No such extension \ "" "" + name + "" \ "" for "" + type . getName ( ) + "" ! "" ) ; \n - } \n - return clazz ; \n + return getExtensionClasses ( ) . get ( name ) ; \n",Optimize getExtensionClass method . ( # 2788 ) \n Just return the class instead of throwing exception .,703
"dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ AsyncContext . java \n + / * * \n + * AsyncContext works like { @ see javax . servlet . AsyncContext } in the Servlet 3 . 0 . \n + * An AsyncContext is stated by a call to { @ link RpcContext # startAsync ( ) } . \n + * < p > \n + * The demo is { @ see com . alibaba . dubbo . examples . async . AsyncConsumer } \n + * and { @ see com . alibaba . dubbo . examples . async . AsyncProvider } \n + * / \n + / * * \n + * write value and complete the async context . \n + * \n + * @ param value invoke result \n + * / \n + / * * \n + * @ return true if the aysnc context is started \n + * / \n + / * * \n + * change the context state to stop \n + * / \n + / * * \n + * change the context state to stop \n + * / \n dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ AsyncContextImpl . java \n + } else { \n + future . complete ( new RpcResult ( value ) ) ; \n - future . complete ( new RpcResult ( value ) ) ; \n - if ( started . compareAndSet ( true , false ) ) { \n - / / future . cancel ( true ) ; \n - return true ; \n - } \n - return false ; \n + return started . compareAndSet ( true , false ) ; \n",* fix a bug when the provider write a throwable into aysnc context ( # 1946 ) \n * sth doc \n * simple code,703
"dubbo - remoting \ dubbo - remoting - api \ src \ main \ java \ org \ apache \ dubbo \ remoting \ exchange \ support \ header \ HeaderExchangeHandler . java \n - void handleRequest ( ExchangeChannel channel , Request req ) throws RemotingException { \n + void handleRequest ( final ExchangeChannel channel , Request req ) throws RemotingException { \n - ExchangeChannel exchangeChannel = HeaderExchangeChannel . getOrAddChannel ( channel ) ; \n + final ExchangeChannel exchangeChannel = HeaderExchangeChannel . getOrAddChannel ( channel ) ; \n",Make channel final because of using in inner class . ( # 2086 ),703
"dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ AsyncContext . java \n + / * * \n + * get the internal future which is binding to this async context \n + * \n + * @ return the internal future \n + * / \n + / * * \n + * Signal RpcContext switch . \n + * Use this method to switch RpcContext from a Dubbo thread to a new thread created by the user . \n + * \n + * Note that you should use it in a new thread like this : \n + * < code > \n + * public class AsyncServiceImpl implements AsyncService { \n + * public String sayHello ( String name ) { \n + * final AsyncContext asyncContext = RpcContext . startAsync ( ) ; \n + * new Thread ( ( ) - > { \n + * \n + * / / right place to use this method \n + * asyncContext . signalContextSwitch ( ) ; \n + * \n + * try { \n + * Thread . sleep ( 500 ) ; \n + * } catch ( InterruptedException e ) { \n + * e . printStackTrace ( ) ; \n + * } \n + * asyncContext . write ( "" Hello "" + name + "" , response from provider . "" ) ; \n + * } ) . start ( ) ; \n + * return null ; \n + * } \n + * } \n + * < / code > \n + * / \n dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ AsyncRpcResult . java \n - public AsyncRpcResult ( CompletableFuture < Object > future , CompletableFuture < Result > rFuture , boolean registerCallback ) { \n + public AsyncRpcResult ( CompletableFuture < Object > future , final CompletableFuture < Result > rFuture , boolean registerCallback ) { \n - throw new IllegalArgumentException ( "" "" ) ; \n + throw new IllegalArgumentException ( ) ; \n - * \n + * tmp context to use when the thread switch to Dubbo thread . \n",* Improve AsyncContext docs ( # 2101 ) \n * Make the future final which is in the constructor of AsyncRpcResult because of using in a inner class .,703
dubbo - remoting \ dubbo - remoting - api \ src \ main \ java \ org \ apache \ dubbo \ remoting \ transport \ AbstractClient . java \n - disconnect ( ) ; \n - connect ( ) ; \n + if ( ! isConnected ( ) ) { \n + connectLock . lock ( ) ; \n + try { \n + if ( ! isConnected ( ) ) { \n + disconnect ( ) ; \n + connect ( ) ; \n + } \n + } finally { \n + connectLock . unlock ( ) ; \n + } \n + } \n,"Fix a bug when client reconnect ( # 2135 ) \n * Add reconnection lock to control only one thread can can reconnect method . \n This will avoid problem in this case : \n Thread A reconnecting , and success , then send msg . \n Thread B reconnecting but invoke disconnect . Then the Thread A will send msg fail because of Thread B ' s disconnecting call . \n * fix sth",703
"dubbo - plugin \ dubbo - qos \ src \ main \ java \ org \ apache \ dubbo \ qos \ server \ DubboLogo . java \n - public static String dubbo = \n - "" ████████▄ ███ █▄ ▀█████████▄ ▀█████████▄ ▄██████▄ \ n "" + \n - "" ███ ▀███ ███ ███ ███ ███ ███ ███ ███ ███ \ n "" + \n - "" ███ ███ ███ ███ ███ ███ ███ ███ ███ ███ \ n "" + \n - "" ███ ███ ███ ███ ▄███▄▄▄██▀ ▄███▄▄▄██▀ ███ ███ \ n "" + \n - "" ███ ███ ███ ███ ▀▀███▀▀▀██▄ ▀▀███▀▀▀██▄ ███ ███ \ n "" + \n - "" ███ ███ ███ ███ ███ ██▄ ███ ██▄ ███ ███ \ n "" + \n - "" ███ ▄███ ███ ███ ███ ███ ███ ███ ███ ███ \ n "" + \n - "" ████████▀ ████████▀ ▄█████████▀ ▄█████████▀ ▀██████▀ \ n "" + \n - "" \ n "" + \n - "" \ n "" ; \n + public static final String dubbo = \n + "" _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ n "" + \n + "" / _ \ \ / / / / / _ ) / _ ) / _ _ \ \ \ n "" + \n + "" / / / / / / _ / / / _ | / _ | / / _ / / \ n "" + \n + "" / _ _ _ _ / \ \ _ _ _ _ / / _ _ _ _ / / _ _ _ _ / \ \ _ _ _ _ / \ n "" ; \n",New ascii logo . ( # 2395 ),703
"dubbo - common \ src \ main \ java \ com \ alibaba \ dubbo \ common \ logger \ support \ FailsafeLogger . java \n - return "" [ DUBBO ] "" + msg + "" , dubbo version : "" + Version . getVersion ( ) + "" , current host : "" + NetUtils . getLogHost ( ) ; \n + return "" [ DUBBO ] "" + msg + "" , dubbo version : "" + Version . getVersion ( ) + "" , current host : "" + NetUtils . getLocalHost ( ) ; \n dubbo - common \ src \ main \ java \ com \ alibaba \ dubbo \ common \ utils \ NetUtils . java \n - public static String getLogHost ( ) { \n - InetAddress address = getLocalAddress ( ) ; \n - return address = = null ? LOCALHOST : address . getHostAddress ( ) ; \n - } \n - \n",remove the method with the same function but the different name in NetUtils ( # 1572 ),703
dubbo - serialization \ dubbo - serialization - api \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The serialization interface module of dubbo project < / description > \n dubbo - serialization \ dubbo - serialization - fastjson \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The fastjson serialization module of dubbo project < / description > \n dubbo - serialization \ dubbo - serialization - fst \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The fst serialization module of dubbo project < / description > \n dubbo - serialization \ dubbo - serialization - hessian2 \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The hessian2 serialization module of dubbo project < / description > \n dubbo - serialization \ dubbo - serialization - jdk \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The jdk serialization module of dubbo project < / description > \n dubbo - serialization \ dubbo - serialization - kryo \ pom . xml \n - < description > The common module of dubbo project < / description > \n + < description > The kryo serialization module of dubbo project < / description > \n,Fix incorrect descriptions for dubbo - serialization module . ( # 2620 ) \n Fix incorrect descriptions for dubbo - serialization module .,703
"dubbo - cluster \ src \ main \ java \ org \ apache \ dubbo \ rpc \ cluster \ support \ ClusterUtils . java \n + import java . util . HashSet ; \n + import java . util . Set ; \n - * \n + \n + / / remove method async entry . \n + Set < String > methodAsyncKey = new HashSet < > ( ) ; \n + for ( String key : map . keySet ( ) ) { \n + if ( key ! = null & & key . endsWith ( "" . "" + Constants . ASYNC _ KEY ) ) { \n + methodAsyncKey . add ( key ) ; \n + } \n + } \n + for ( String needRemove : methodAsyncKey ) { \n + map . remove ( needRemove ) ; \n + } \n","Merge pull request # 2434 , Remove method . async of provider url . \n Fixes # 2321 .",703
transport \ src \ main \ java \ io \ netty \ channel \ RecvByteBufAllocator . java \n - * Determine if the current read loop should should continue . \n + * Determine if the current read loop should continue . \n,Remove extra ' should ' word in docs of continueReading ( ) method,703
dubbo - rpc \ dubbo - rpc - dubbo \ src \ main \ java \ org \ apache \ dubbo \ rpc \ protocol \ dubbo \ FutureAdapter . java \n - return this . isDone ( ) ; \n + return super . isDone ( ) ; \n,"Merge pull request # 2070 , fix a bug which make isDone method infinite - loop .",703
"dubbo - common \ src \ main \ java \ org \ apache \ dubbo \ common \ Constants . java \n + / * * \n + * Most retry times \n + * / \n + public static final String REGISTRY _ RETRY _ TIMES _ KEY = "" retry . times "" ; \n + \n + / * * \n + * Default value for the times of retry : 3 \n + * / \n + public static final int DEFAULT _ REGISTRY _ RETRY _ TIMES = 3 ; \n + \n dubbo - registry \ dubbo - registry - api \ src \ main \ java \ org \ apache \ dubbo \ registry \ retry \ AbstractRetryTask . java \n - protected final long retryPeriod ; \n + final long retryPeriod ; \n + \n + / * * \n + * define the most retry times \n + * / \n + private final int retryTimes ; \n - protected final String taskName ; \n + private final String taskName ; \n + \n + / * * \n + * times of retry . \n + * retry task is execute in single thread so that the times is not need volatile . \n + * / \n + private int times = 1 ; \n + this . retryTimes = url . getParameter ( Constants . REGISTRY _ RETRY _ TIMES _ KEY , Constants . DEFAULT _ REGISTRY _ RETRY _ TIMES ) ; \n - \n + times + + ; \n + if ( times > retryTimes ) { \n + / / reach the most times of retry . \n + logger . warn ( "" Final failed to execute task "" + taskName + "" , url : "" + url + "" , retry "" + retryTimes + "" times . "" ) ; \n + return ; \n + } \n",Limit the times of registry retry . ( # 2946 ) \n The default value is 3 .,703
"dubbo - cluster \ src \ main \ java \ org \ apache \ dubbo \ rpc \ cluster \ support \ AbstractClusterInvoker . java \n - * @ throws RpcException \n + * @ throws RpcException exception \n - List < Invoker < T > > invokers , List < Invoker < T > > selected ) throws RpcException { \n + List < Invoker < T > > invokers , List < Invoker < T > > selected ) throws RpcException { \n - . getMethodParameter ( methodName , Constants . CLUSTER _ STICKY _ KEY , Constants . DEFAULT _ CLUSTER _ STICKY ) ; \n + . getMethodParameter ( methodName , Constants . CLUSTER _ STICKY _ KEY , Constants . DEFAULT _ CLUSTER _ STICKY ) ; \n - List < Invoker < T > > invokers , List < Invoker < T > > selected ) throws RpcException { \n + List < Invoker < T > > invokers , List < Invoker < T > > selected ) throws RpcException { \n - * @ param loadbalance \n - * @ param invocation \n - * @ param invokers \n - * @ param selected \n - * @ return \n - * @ throws RpcException \n + * @ param loadbalance load balance policy \n + * @ param invocation invocation \n + * @ param invokers invoker candidates \n + * @ param selected exclude selected invokers or not \n + * @ param availablecheck check invoker available if true \n + * @ return the reselect result to do invoke \n + * @ throws RpcException exception \n - List < Invoker < T > > invokers , List < Invoker < T > > selected , boolean availablecheck ) throws RpcException { \n + List < Invoker < T > > invokers , List < Invoker < T > > selected , boolean availablecheck ) throws RpcException { \n - invokers . size ( ) > 1 ? ( invokers . size ( ) - 1 ) : invokers . size ( ) ) ; \n + invokers . size ( ) > 1 ? ( invokers . size ( ) - 1 ) : invokers . size ( ) ) ; \n - \n + "" use dubbo version "" + Version . getVersion ( ) \n dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ filter \ ContextFilter . java \n - attachments = new HashMap < String , String > ( attachments ) ; \n + attachments = new HashMap < > ( attachments ) ; \n + attachments . remove ( Constants . INTERFACE _ KEY ) ; \n dubbo - rpc \ dubbo - rpc - api \ src \ main \ java \ org \ apache \ dubbo \ rpc \ protocol \ AbstractInvoker . java \n - \n","Merge pull request # 3017 , fixes # 2981 , refresh invocation ' s attachments in each invoke . \n Fixes # 2981 .",703
"dubbo - rpc \ dubbo - rpc - rest \ src \ main \ java \ org \ apache \ dubbo \ rpc \ protocol \ rest \ RpcContextFilter . java \n - \n + import java . nio . charset . StandardCharsets ; \n - String value = entry . getKey ( ) ; \n + String value = entry . getValue ( ) ; \n - size + = value . getBytes ( "" UTF - 8 "" ) . length ; \n + size + = value . getBytes ( StandardCharsets . UTF _ 8 ) . length ; \n",Fix context filter ' s bug ( # 3526 ),703
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n - private final ConcurrentMap < String , Boolean > reportedLeaks = PlatformDependent . newConcurrentHashMap ( ) ; \n + private final Set < String > reportedLeaks = \n + Collections . newSetFromMap ( new ConcurrentHashMap < String , Boolean > ( ) ) ; \n - @ SuppressWarnings ( "" unchecked "" ) \n - @ SuppressWarnings ( "" unchecked "" ) \n - if ( reportedLeaks . putIfAbsent ( records , Boolean . TRUE ) = = null ) { \n + if ( reportedLeaks . add ( records ) ) { \n","Replace map with set . ( # 9833 ) \n Motivation : \n Replace Map with Set . ` reportedLeaks ` has better semantics as a Set , and if it is a Map , it seems that the value of this Map has no meaning to us . \n Modifications : \n Use Set . \n Result : \n Cleaner code",703
"dubbo - remoting \ dubbo - remoting - api \ src \ main \ java \ org \ apache \ dubbo \ remoting \ exchange \ support \ DefaultFuture . java \n + private static final Map < Long , Timeout > PENDING _ TASKS = new ConcurrentHashMap < > ( ) ; \n + \n - TIME _ OUT _ TIMER . newTimeout ( task , future . getTimeout ( ) , TimeUnit . MILLISECONDS ) ; \n + Timeout t = TIME _ OUT _ TIMER . newTimeout ( task , future . getTimeout ( ) , TimeUnit . MILLISECONDS ) ; \n + PENDING _ TASKS . put ( future . getId ( ) , t ) ; \n + Timeout t = PENDING _ TASKS . remove ( future . getId ( ) ) ; \n + if ( t ! = null ) { \n + / / decrease Time \n + t . cancel ( ) ; \n + } \n + ( new SimpleDateFormat ( "" yyyy - MM - dd HH : mm : ss . SSS "" ) . format ( new Date ( ) ) ) \n - if ( future = = null | | future . isDone ( ) ) { \n + / / remove from pending task \n + PENDING _ TASKS . remove ( future . getId ( ) ) ; \n + \n + if ( future . isDone ( ) ) { \n - \n - ResponseCallback callbackCopy = c ; \n - if ( callbackCopy = = null ) { \n + if ( c = = null ) { \n - callbackCopy . done ( res . getResult ( ) ) ; \n + c . done ( res . getResult ( ) ) ; \n - callbackCopy . caught ( te ) ; \n + c . caught ( te ) ; \n - callbackCopy . caught ( re ) ; \n + c . caught ( re ) ; \n",Shorten the life cycle of TimeoutTask to avoid frequent gc . ( # 4040 ),703
"codec \ src \ main \ java \ io \ netty \ handler \ codec \ LengthFieldBasedFrameDecoder . java \n - * < p > \n - * If you are sure that the frame and its content are not accessed after \n - * the current { @ link # decode ( ChannelHandlerContext , ByteBuf ) } \n - * call returns , you can even avoid memory copy by returning the sliced \n - * sub - region ( i . e . < tt > return buffer . slice ( index , length ) < / tt > ) . \n - * It ' s often useful when you convert the extracted frame into an object . \n - * Refer to the source code of { @ link ObjectDecoder } to see how this method \n - * is overridden to avoid memory copy . \n","Clean up expired docs . ( # 9756 ) \n Motivation : \n Since the ` extractFrame ` has used ` retainedSlice ` to avoid memory copy , we should clean this doc that was expired . \n Result : \n Better doc .",703
"dubbo - cluster \ src \ main \ java \ org \ apache \ dubbo \ rpc \ cluster \ router \ tag \ TagRouter . java \n - if ( tagRouterRule = = null | | ! tagRouterRule . isValid ( ) | | ! tagRouterRule . isEnabled ( ) ) { \n + / / since the rule can be changed by config center , we should copy one to use . \n + final TagRouterRule tagRouterRuleCopy = tagRouterRule ; \n + if ( tagRouterRuleCopy = = null | | ! tagRouterRuleCopy . isValid ( ) | | ! tagRouterRuleCopy . isEnabled ( ) ) { \n - List < String > addresses = tagRouterRule . getTagnameToAddresses ( ) . get ( tag ) ; \n + List < String > addresses = tagRouterRuleCopy . getTagnameToAddresses ( ) . get ( tag ) ; \n - if ( CollectionUtils . isNotEmpty ( result ) | | tagRouterRule . isForce ( ) ) { \n + if ( CollectionUtils . isNotEmpty ( result ) | | tagRouterRuleCopy . isForce ( ) ) { \n - tagRouterRule . getAddresses ( ) ) ) ; \n + tagRouterRuleCopy . getAddresses ( ) ) ) ; \n - List < String > addresses = tagRouterRule . getAddresses ( ) ; \n + List < String > addresses = tagRouterRuleCopy . getAddresses ( ) ; \n - return StringUtils . isEmpty ( localTag ) | | ! tagRouterRule . getTagNames ( ) . contains ( localTag ) ; \n + return StringUtils . isEmpty ( localTag ) | | ! tagRouterRuleCopy . getTagNames ( ) . contains ( localTag ) ; \n - * \n + * < p > \n - * \n + * < p > \n",Dump TagRouterRule ( # 3536 ) \n Dump TagRouterRule since the TagRouterRule can be changed to ` null ` by ConfigCenter,703
"dubbo - compatible \ src \ main \ java \ com \ alibaba \ dubbo \ config \ annotation \ Service . java \n - boolean dynamic ( ) default false ; \n + boolean dynamic ( ) default true ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ AbstractServiceConfig . java \n - protected Boolean dynamic = false ; \n + protected Boolean dynamic = true ; \n dubbo - config \ dubbo - config - api \ src \ main \ java \ org \ apache \ dubbo \ config \ annotation \ Service . java \n - * Whether the service is dynamic , default value is false \n + * Whether the service is dynamic , default value is true \n - boolean dynamic ( ) default false ; \n + boolean dynamic ( ) default true ; \n",Make ` dynamic ` default true to promise that the url will delete from zk whenever provider shutdown . ( # 3824 ),703
"common \ src \ main \ java \ io \ netty \ util \ Recycler . java \n + if ( size < = 0 ) { \n + / / double check , avoid races \n + return null ; \n + } \n","Double check ` size ` to avoid ` ArrayIndexOutOfBoundsException ` ( # 9609 ) \n Motivation : \n Recycler $ Stack . pop will occurs ` ArrayIndexOutOfBoundsException ` in some race cases , we should double check ` size ` even after ` scavenge ` called . \n Modifications : \n Double check ` size ` after ` scavenge ` \n Result : \n avoid ArrayIndexOutOfBoundsException in ` pop `",703
codec \ src \ main \ java \ io \ netty \ handler \ codec \ compression \ LzfEncoder . java \n + \n + @ Override \n + public void handlerRemoved ( ChannelHandlerContext ctx ) throws Exception { \n + encoder . close ( ) ; \n + super . handlerRemoved ( ctx ) ; \n + } \n,Close encoder when handlerRemoved . ( # 9950 ) \n Motivation : \n We should close encoder when ` LzfEncoder ` was removed from pipeline . \n Modification : \n call ` encoder . close ` when ` handlerRemoved ` triggered . \n Result : \n Close encoder to release internal buffer .,703
buffer \ src \ main \ java \ io \ netty \ buffer \ PoolArena . java \n - tableIdx = elemSize > > > 4 ; \n + tableIdx = tinyIdx ( elemSize ) ; \n - tableIdx = 0 ; \n - elemSize > > > = 10 ; \n - while ( elemSize ! = 0 ) { \n - elemSize > > > = 1 ; \n - tableIdx + + ; \n - } \n + tableIdx = smallIdx ( elemSize ) ; \n,Remove duplicate code in PoolArena . ( # 10174 ) \n Motivation : \n Remove duplicate code in PoolArena . \n Modification : \n Replace duplicate code with ` tinyIdx ` and ` smallIdx ` . \n Result : \n Clean code .,703
"handler \ src \ main \ java \ io \ netty \ handler \ flush \ FlushConsolidationHandler . java \n + import io . netty . util . internal . ObjectUtil ; \n - if ( explicitFlushAfterFlushes < = 0 ) { \n - throw new IllegalArgumentException ( "" explicitFlushAfterFlushes : "" \n - + explicitFlushAfterFlushes + "" ( expected : > 0 ) "" ) ; \n - } \n - this . explicitFlushAfterFlushes = explicitFlushAfterFlushes ; \n + this . explicitFlushAfterFlushes = \n + ObjectUtil . checkPositive ( explicitFlushAfterFlushes , "" explicitFlushAfterFlushes "" ) ; \n - flushTask = consolidateWhenNoReadInProgress ? \n + this . flushTask = consolidateWhenNoReadInProgress ? \n - ctx . flush ( ) ; \n + ctx . flush ( ) ; \n handler \ src \ test \ java \ io \ netty \ handler \ flush \ FlushConsolidationHandlerTest . java \n + import io . netty . util . concurrent . Future ; \n + import io . netty . util . concurrent . GenericFutureListener ; \n + / * * \n + * See https : / / github . com / netty / netty / issues / 9923 \n + * / \n + @ Test \n + public void testResend ( ) throws Exception { \n + final AtomicInteger flushCount = new AtomicInteger ( ) ; \n + final EmbeddedChannel channel = newChannel ( flushCount , true ) ; \n + channel . writeAndFlush ( 1L ) . addListener ( new GenericFutureListener < Future < ? super Void > > ( ) { \n + @ Override \n + public void operationComplete ( Future < ? super Void > future ) throws Exception { \n + channel . writeAndFlush ( 1L ) ; \n + } \n + } ) ; \n + channel . flushOutbound ( ) ; \n + assertEquals ( 1L , channel . readOutbound ( ) ) ; \n + assertEquals ( 1L , channel . readOutbound ( ) ) ; \n + assertNull ( channel . readOutbound ( ) ) ; \n + assertFalse ( channel . finish ( ) ) ; \n + } \n + \n","FlushConsolidationHandler may suppress flushes by mistake ( # 9931 ) \n Motivation : \n When ` consolidatedWhenNoReadInProgress ` is true , ` channel . writeAndFlush ( data ) . addListener ( f - > channel . writeAndFlush ( data2 ) ) ` Will cause data2 to never be flushed . \n Because the flush operation will synchronously execute the ` channel . writeAndFlush ( data2 ) ) ` in the ` listener ` , and at this time , since the current execution thread is still an ` eventloop ` ( ` executor . inEventLoop ( ) ` was true ) , all handlers will be executed synchronously . At this time , since ` nextScheduledFlush ` is still not null , the ` flush ` operation of ` data2 ` will be ignored in ` FlushConsolidationHandler # scheduleFlush ` . \n Modification : \n - reset ` nextScheduledFlush ` before ` ctx . flush ` \n - use ` ObjectUtil ` to polish code \n Result : \n Fixes https : / / github . com / netty / netty / issues / 9923",703
"common \ src \ main \ java \ io \ netty \ util \ ResourceLeakDetector . java \n + / * * \n + * When the return value is { @ code true } , { @ link # reportTracedLeak } and { @ link # reportUntracedLeak } \n + * will be called once a leak is detected , otherwise not . \n + * \n + * @ return { @ code true } to enable leak reporting . \n + * / \n + protected boolean needReport ( ) { \n + return logger . isErrorEnabled ( ) ; \n + } \n + \n - if ( ! logger . isErrorEnabled ( ) ) { \n + if ( ! needReport ( ) ) { \n","Introduce ` needReport ` for ` ResourceLeakDetector ` . ( # 9910 ) \n Motivation : \n We can extend ` ResourceLeakDetector ` through ` ResourceLeakDetectorFactory ` , and then report the leaked information by covering ` reportTracedLeak ` and ` reportUntracedLeak ` . However , the behavior of ` reportTracedLeak ` and ` reportUntracedLeak ` is controlled by ` logger . isErrorEnabled ( ) ` , which is not reasonable . In the case of extending ` ResourceLeakDetector ` , we sometimes need ` needReport ` to always return true instead of relying on ` logger . isErrorEnabled ( ) ` . \n Modification : \n introduce ` needReport ` method and let it be ` protected ` \n Result : \n We can control the report leak behavior .",703
